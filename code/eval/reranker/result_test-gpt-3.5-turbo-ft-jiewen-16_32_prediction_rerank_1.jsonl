"When creating a `Polar5GEncoder` instance in Sionna, the parameters `k` and `n` are required. They represent the number of information bits per codeword and the codeword length respectively.\n\nHere's how you would instantiate a `Polar5GEncoder` in Python using Sionna's APIs:\n\n```python\nfrom sionna.fec.polar.encoding import Polar5GEncoder\n\n# Assume k and n are provided by the application or user\nk = 100  # Example value for the number of information bits per codeword\nn = 200  # Example value for the codeword length\n\npolar_5g_encoder = Polar5GEncoder(k=k, n=n)\n```\n\nIn the code snippet above, `k` is the number of information bits per codeword and `n` is the codeword length. You would substitute `100` and `200` with the actual values based on the specific requirements of the simulation or processing task, as long as they adhere to the constraints specified by the context or Sionna's API documentation."
"To import DeepMIMO and generate a dataset, you can follow these steps:\n\n1. Import the DeepMIMO package. If it's not already installed, the code will install it:\n\n```python\ntry:\n    import DeepMIMO\nexcept ImportError as e:\n    import os\n    os.system(\"pip install DeepMIMO\")\n    import DeepMIMO\n```\n\n2. Set the parameters for the DeepMIMO dataset generation:\n\n```python\nDeepMIMO_params = DeepMIMO.default_params()\nDeepMIMO_params['dataset_folder'] = r'./scenarios'\nDeepMIMO_params['scenario'] = 'O1_60'\nDeepMIMO_params['num_paths'] = 10\nDeepMIMO_params['active_BS'] = np.array([6])\nDeepMIMO_params['user_row_first'] = 400\nDeepMIMO_params['user_row_last'] = 450\nDeepMIMO_params['bs_antenna']['shape'] = np.array([16, 1, 1])\nDeepMIMO_params['ue_antenna']['shape'] = np.array([1, 1, 1])\nDeepMIMO_params['OFDM_channels'] = 0\n```\n\n3. Generate the DeepMIMO dataset:\n\n```python\nDeepMIMO_dataset = DeepMIMO.generate_data(DeepMIMO_params)\n```\n\nIn this code, `DeepMIMO.default_params()` is used to load the default DeepMIMO parameters. These parameters are then modified to specify the scenario, number of paths, active basestations, and the user rows for which the channels should be generated. The `DeepMIMO.generate_data()` function is then used to generate the dataset.\n\nPlease note that the actual paths and basestations indices may vary depending on the scenario and the setup of the DeepMIMO dataset."
"To plot the weights after training and compare the new BER performance, you can follow these steps:\n\n1. After training your model, you can use the `show_weights()` function of the decoder layer to display the weights. In the context, this is done with the following code:\n\n    ```python\n    model.decoder.show_weights() # show weights AFTER training\n    ```\n\n2. To compare the new BER performance, you can call the `simulate()` function of the `ber_plot` object again. In the function call, you should set the `legend` parameter to a string that describes the new performance, so that it appears in the plot next to the existing performance. You should also set the `soft_estimates` parameter to `True`, so that the new performance is plotted as a soft estimate. In the context, this is done with the following code:\n\n    ```python\n    ber_plot.simulate(model,\n                      ebno_dbs=ebno_dbs,\n                      batch_size=1000,\n                      num_target_bit_errors=2000, # stop sim after 2000 bit errors\n                      legend=\"Trained\",\n                      max_mc_iter=mc_iters,\n                      soft_estimates=True);\n    ```\n\nBy performing these steps, you can plot the weights after training and compare the new BER performance with the original performance. The weights will be displayed as a logarithmic scale, and the performance will be shown on a linear scale."
"To use the `generate_polar_transform_mat` function to create a Polar transformation matrix for a given Kronecker power, you need to call the function with the `n_lift` parameter, where `n_lift` is an integer that defines the Kronecker power, i.e., how often is the kernel lifted. \n\nHere is how you can use the function:\n\n```python\nfrom sionna.fec.polar.utils import generate_polar_transform_mat\n\n# Defining the Kronecker power\nn_lift = 3 # Example n_lift value\n\n# Creating the Polar transformation matrix\npolar_transform_mat = generate_polar_transform_mat(n_lift)\n```\n\nThe `generate_polar_transform_mat` function will return an `ndarray` array of 0s and 1s of shape `[2^n_lift , 2^n_lift]`, which contains the Polar transformation matrix.\n\nPlease note that the actual value of `n_lift` depends on the specific requirements of your application. In the context, there is no code directly instructing how to determine the Kronecker power based on the application's parameters. It would be best to consult the relevant documentation or source code to determine the appropriate value for the `n_lift` parameter."
"The definition of LayerDemapper is: class sionna.nr.LayerDemapper(layer_mapper, num_bits_per_symbol=1, **kwargs) source code: [github.com/nvlabs/sionna/blob/main/sionna/nr/layer_mapping.py#L293](https://github.com/nvlabs/sionna/blob/main/sionna/nr/layer_mapping.py#L293)\n\n```python\nclass LayerDemapper(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    LayerDemapper(layer_mapper, num_bits_per_symbol=1, **kwargs)\n\n    Demaps MIMO layers to coded transport block(s) by following Sec. 6.3.1.3\n    and Sec. 7.3.1.3 in [3GPP38211]_.\n\n    This layer must be associated to a :class:`~sionna.nr.LayerMapper` and\n    performs the inverse operation.\n\n    It is assumed that ``num_bits_per_symbol`` consecutive LLRs belong to\n    a single symbol position. This allows to apply the LayerDemapper after\n    demapping symbols to LLR values.\n\n    If the layer mapper is configured for dual codeword transmission, a list\n    of both transport block streams is returned.\n\n    The class inherits from the Keras layer class and can be used as layer in\n    a Keras model.\n\n    Parameters\n    ----------\n    layer_mapper : LayerMapper\n        Associated :class:`~sionna.nr.LayerMapper`\n\n    num_bits_per_symbol : int, 1 (default)\n        Modulation order. Defines how many consecutive LLRs are associated\n        to the same symbol position.\n\n    Input\n    -----\n    inputs : [,num_layers, n/num_layers], tf.float\n        2+D tensor containing MIMO layer data sequences.\n\n    Output\n    ------\n    : [,n], or [[,n1], [,n2]], tf.float\n        2+D tensor containing the sequence of bits after layer demapping.\n        If ``num_codewords`` =2, a list of two transport blocks is returned.\n\n    Note\n    ----\n    As it is more convenient to apply the layer demapper after demapping\n    symbols to LLRs, this layer groups the input sequence into groups of\n    ``num_bits_per_symbol`` LLRs before restoring the original symbol\n    sequence. This behavior can be deactivated by setting\n    ``num_bits_per_symbol`` =1.\n    \"\"\"\n    def __init__(self,\n                 layer_mapper,\n                 num_bits_per_symbol=1,\n                 **kwargs):\n        super().__init__(**kwargs)\n        assert isinstance(layer_mapper, LayerMapper)\n        self._layer_mapper = layer_mapper\n        self._num_bits_per_symbol = int(num_bits_per_symbol)\n\n        # number of base symbols (before demapping)\n        self._n = self._layer_mapper._n\n\n        # pre-compute symbol indices for each stream\n        self._sym_ind = []\n        for j in range(self._layer_mapper.num_streams):\n            self._sym_ind.append(np.where(self._layer_mapper._pilots[j]\n                                  .numpy()[0] == -1)[0])\n\n        # compute symbol indices for deinterleaving\n        self._sym_ind_inv = np.zeros_like(self._sym_ind)\n        for j in range(self._layer_mapper.num_streams):\n            for i in range(len(self._sym_ind[j])):\n                self._sym_ind_inv[j][self._sym_ind[j][i]] = i\n\n    def call(self, inputs):\n        if self._layer_mapper._num_codewords==1:\n            y = inputs\n            llr = tf.split(y, self._layer_mapper.num_streams, axis=1)\n            return self._layer_demapper(llr)\n\n        # For demapping of dual codeword, split input list into two list of\n        # llrs.\n        llr = tf.split(inputs, 2, axis=-1)\n        llr1 = tf.squeeze(llr[0], axis=-1)\n        llr2 = tf.squeeze(llr[1], axis=-1)\n        llr = tf.stack([llr1, llr2], axis=-1)\n        llr = tf.split(llr, self._layer_mapper.num_streams*2, axis=-1)\n        return self._layer_demapper(llr)\n\n    def _layer_demapper(self, llr):\n        # Splits input sequence into groups of size\n        # self._num_bits_per_symbol (de-qam), and then\n        # restores the symbol sequence\n        llr = tf.transpose(llr, perm=(1, 0, 2))\n        llr = tf.reshape(llr, (-1, self._n, self._layer_mapper.num_streams,\n                         self._num_bits_per_symbol))\n        llr = tf.transpose(llr, (1, 2, 3, 0))\n\n        # Reverses deinterleaving\n        llr = tf.gather(self._sym_ind_inv, llr, batch_dims=1, axis=1)\n\n        bits = self._layer_mapper.call(llr)\n        if self._num_bits_per_symbol==1:\n            symb1 = tf.expand_dims(bits[:,:,0], axis=-1)\n            symb2 = tf.expand_dims(bits[:,:,1], axis=-1)\n            return [symb1, symb2]\n        else:\n            return bits\n```"
"To create a `PUSCHReceiver` using the `PUSCHTransmitter` and simulate transmissions over the AWGN channel, you can follow these steps:\n\n1. Import necessary packages and modules. This includes `PUSCHConfig` from `sionna.nr`, `PUSCHTransmitter` from `sionna.nr.pusch`, `PUSCHReceiver` from `sionna.nr.pusch`, and other modules like `AWGN` and `compute_ber`.\n\n2. Configure your PUSCH transmitter by creating an instance of `PUSCHConfig`. You can set various properties here, such as carrier configuration, DMRS configuration, and transport block configuration.\n\n3. Instantiate a `PUSCHTransmitter` by providing your `PUSCHConfig` to the transmitter.\n\n4. Create a `PUSCHReceiver` using your instantiated `PUSCHTransmitter`. This step involves providing the transmitter and configuring other specific properties, such as the detection algorithm and the number of detection layers.\n\n5. Setup an AWGN channel for the transmissions. In the given context, this is done using the `AWGN` class from `sionna.channel`.\n\n6. Simulate transmissions over the AWGN channel by calling your `PUSCHTransmitter` with the desired batch size. You can then get the channel output by passing the transmit signal and noise variance to the `AWGN` channel. \n\n7. Recover the information bits by using the `PUSCHReceiver`. You can call the receiver with the output of the `AWGN` channel to get the recovered information bits. \n\n8. Compute the bit error rate (BER) by calling `compute_ber` with the transmitted and received information bits.\n\nRemember that in Python, to call a callable object like a class instance or function, you use parenthesis `()`, but you don't need to provide any arguments if the callable has no required parameters. For example, to call a `PUSCHTransmitter` or `PUSCHReceiver`, you would write something like `pusch_transmitter()` or `pusch_receiver()`.\n\nBe sure to use the correct Sionna APIs and reference the specific documentation for the APIs you are using to get detailed information about how to use them. The provided context does not include the specific details for all the APIs used in the steps, so you would need to review the documentation to fill in those details."
"Here is the definition of SymbolInds2Bits: class sionna.mapping.SymbolInds2Bits(num_bits_per_symbol, dtype=tf.float32, **kwargs) [`source code`](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#SymbolInds2Bits)  \n\n```python\nclass SymbolInds2Bits(Layer):\n    \"\"\"SymbolInds2Bits(num_bits_per_symbol, dtype=tf.float32, **kwargs)\n\n    Computes the binary representation of symbol indices.\n\n    Parameters\n    ----------\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol\n\n    dtype : tf.DType\n        Output dtype\n        Defaults to `tf.float32`.\n\n    Input\n    -----\n    : Tensor, [batch_size, symbol_indices], tf.int\n        Tensor of symbol indices\n\n    Output\n    ------\n    : input.shape + [num_bits_per_symbol], dtype\n        Tensor of binary symbol representations.\n\n    Note\n    ----\n    If the number of bits per symbol is not an integer, the index is\n    floored for 0.5 and higher, e.g., index 1.5 becomes 2.\n    \"\"\"\n\n    def __init__(self,\n                 num_bits_per_symbol,\n                 dtype=tf.float32,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        self._num_bits_per_symbol = int(num_bits_per_symbol)\n\n    def call(self, inputs):\n\n        y = inputs\n\n        # Compute binary representation through modulo-2 operation\n        b = tf.mod(y, 2)\n\n        # Shift y one position to the right and recompute b\n        y = bit_ops.logic_shift(y, 1, shift_type='right')\n        b_next = tf.mod(y, 2)\n\n        for _ in range(int(np.log2(self._num_bits_per_symbol)-1)):\n            y = bit_ops.logic_shift(y, 1, shift_type='right')\n            b_temp = tf.mod(y, 2)\n            b_next = tf.stack([b_temp, b_next], axis=-1)\n            y = bit_ops.logic_shift(y, 1, shift_type='right')\n            b = tf.concat([b_temp, b], axis=-1)\n            y = tf.subtract(y, 1)\n\n        # Reverse the order of b_next and b to get the correct bit label\n        # Order is [LSB,...,MSB] and not [MSB,...,LSB] as in the for loop above\n        b = tf.concat([b, tf.reverse(b_next, axis=[-1])], axis=-1)\n        return b\n```\n\n  "
"Here is the detailed information of the TimeChannel:   \n  \n[sionna.channel.TimeChannel(channel_model, bandwidth, num_time_samples, maximum_delay_spread=3e-6, l_min=None, l_max=None, normalize_channel=False, add_awgn=True, return_channel=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/channel/time_channel.html#TimeChannel)\n\nGenerate channel responses and apply them to channel inputs in the time domain.\n\nThis class inherits from the Keras Layer class and can be used as layer in a Keras model.\n\nThe channel output consists of num_time_samples + l_max - l_min time samples, as it is the result of filtering the channel input of length num_time_samples with the time-variant channel filter  of length l_max - l_min + 1. In the case of a single-input single-output link and given a sequence of channel inputs $x_0,\\cdots,x_{N_B}$, where $N_B$ is num_time_samples, this layer outputs\n\n$y_b = \\sum_{\\ell = L_{\\text{min}}}^{L_{\\text{max}}} x_{b-\\ell} \\bar{h}_{b,\\ell} + w_b$\n\nwhere $L_{\\text{min}}$ corresponds l_min, $L_{\\text{max}}$ to l_max, $w_b$ to the additive noise, and $\\bar{h}_{b,\\ell}$ to the $\\ell^{th}$ tap of the $b^{th}$ channel sample.\n\nThis layer outputs $y_b$ for $b$ ranging from $L_{\\text{min}}$ to $N_B + L_{\\text{max}} - 1$, and $x_{b}$ is set to 0 for $b < 0$ or $b \\geq N_B$. The channel taps $\\bar{h}_{b,\\ell}$ are computed assuming a sinc filter is used for pulse shaping and receive filtering. Therefore, given a channel impulse response $(a_{m}(t), \\tau_{m}), 0 \\leq m \\leq M-1$, generated by the channel_model, the channel taps are computed as follows:\n\n$\\bar{h}_{b, \\ell}\n= \\sum_{m=0}^{M-1} a_{m}\\left(\\frac{b}{W}\\right)\n    \\text{sinc}\\left( \\ell - W\\tau_{m} \\right)$\n\nfor $\\ell$ ranging from l_min to l_max, and where $W$ is bandwidth.\n\nFor multiple-input multiple-output (MIMO) links, the channel output is computed for each antenna of each receiver and by summing over all the antennas of all transmitters.\n\n**Parameters**\n\n- `channel_model` (ChannelModel): An instance of a ChannelModel, such as RayleighBlockFading or UMi.\n- `bandwidth` (float): Bandwidth ($W$) [Hz]\n- `num_time_samples` (int): Number of time samples forming the channel input ($N_B$)\n- `maximum_delay_spread` (float): Maximum delay spread [s]. Used to compute the default value of l_max if l_max is set to None. If a value is given for l_max, this parameter is not used. It defaults to 3us, which was found to be large enough to include most significant paths with all channel models included in Sionna assuming a nominal delay spread of 100ns.\n- `l_min` (int): Smallest time-lag for the discrete complex baseband channel ($L_{\\text{min}}$). If set to None, defaults to the value given by `time_lag_discrete_time_channel()`.\n- `l_max` (int): Largest time-lag for the discrete complex baseband channel ($L_{\\text{max}}$). If set to None, it is computed from `bandwidth` and `maximum_delay_spread`. If it is not set to None, the parameter `maximum_delay_spread` is not used. If `l_min` and `l_max` are set to None, they are computed from the given `bandwidth`.\n- `normalize_channel` (bool): If set to True, the channel is normalized over the block size to ensure unit average energy per time step. Defaults to False.\n- `add_awgn` (bool): If set to False, no white Gaussian noise is added. Defaults to True.\n- `return_channel` (bool): If set to True, the channel response is returned in addition to the channel output. Defaults to False.\n- `dtype` (tf.DType): Complex datatype to use for internal processing and output. Defaults to tf.complex64.\n\n**Input**\n\n- **(x, no)**: Tuple or Tensor:\n  - `x` ([batch size, num_tx, num_tx_ant, num_time_samples], tf.complex): Channel inputs\n  - `no` (Scalar or Tensor, tf.float): Scalar or tensor whose shape can be broadcast to the shape of the channel outputs: [batch size, num_rx, num_rx_ant, num_time_samples + l_max - l_min], of type real. Only required if `add_awgn` is set to True. The noise power `no` is per complex dimension. If `no` is a scalar, noise of the same variance will be added to the outputs. If `no` is a tensor, it must have a shape that can be broadcast to the shape of the channel outputs. This allows, for example, adding noise of different variance to each example in a batch. If `no` has a lower rank than the channel outputs, then `no` will be broadcast to the shape of the channel outputs by adding dummy dimensions after the last axis.\n\n**Output**\n\n- `y` ([batch size, num_rx, num_rx_ant, num_time_samples + l_max - l_min], tf.complex): Channel outputs\n- `h_time` ([batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_samples + l_max - l_min, l_max - l_min + 1], tf.complex): (Optional) Channel responses. Returned only if `return_channel` is set to True.\n  "
"The Antenna class in the Sionna Python package for wireless simulation is designed to provide an interface for modelling antenna objects. These can be defined with either a single polarized pattern or two patterns for dual polarization.\n\nYou can create an Antenna object by specifying an Antenna pattern (either as a string or a callable function), the type of polarization (\"V\" for vertical, \"H\" for horizontal, and \"VH\" and \"cross\" for dual polarization), and the datatype for computations (\"tf.complex64\" or \"tf.complex128\"). \n\nOnce you have defined your Antenna object, you can make use of the provided patterns related to the Antenna object, which are returned as a list. These patterns can be applied to simulate antenna objects in your Sionna-based wireless experiments.\n\nRemember that the Antenna class is just one component in the larger set of Sionna's tools for modeling and simulating wireless channels and devices. Other components include things like Pattern, load, spherical_harmonics, and rotate. Each of these offers unique capabilities when it comes to setting up and configuring your simulation environment, allowing you to model different antenna patterns, apply signal rotations, and load and save system components."
"```python\nclass TurboTermination(ABC):\n    \"\"\"\n    Termination object, handles the transformation of termination bits from\n    the convolutional encoders to a Turbo codeword. Similarly, it handles the\n    transformation of channel symbols corresponding to the termination of a\n    Turbo codeword to the underlying convolutional codewords.\n\n    Sub-classes must implement the following method:\n\n     -  `get_num_term_syms`: Computes the number of termination symbols for the\n        Turbo code.\n\n    \"\"\"\n    def __init__(self, constraint_length, conv_n=2, num_conv_encs=2,\n                        num_bit_streams=3):\n        self.constraint_length = constraint_length\n        self.conv_n = conv_n\n        self.num_conv_encs = num_conv_encs\n        self.num_bit_streams = num_bit_streams\n        self.num_bit_interleaver_inputs = None\n        self.num_bit_interleaver_outputs = None\n        self.termbits_conv2turbo = None\n        self.term_syndromes = None\n        self.turbo_circuit = None\n        self.mu = None\n        self.rsc_n = None\n        self.turbo_terminator = None\n        self.conv_term_syndromes = None\n        self._check_constraint_length()\n\n    @property\n    def conv_n(self):\n        return self._conv_n\n\n    @conv_n.setter\n    def conv_n(self, value):\n        self._conv_n = int(value)\n\n    @property\n    def num_conv_encs(self):\n        return self._num_conv_encs\n\n    @num_conv_encs.setter\n    def num_conv_encs(self, value):\n        self._num_conv_encs = int(value)\n\n    @property\n    @abstractmethod\n    def num_bit_interleaver_inputs(self):\n        pass\n\n    @num_bit_interleaver_inputs.setter\n    @abstractmethod\n    def num_bit_interleaver_inputs(self, value):\n        pass\n\n    @property\n    @abstractmethod\n    def num_bit_interleaver_outputs(self):\n        pass\n\n    @num_bit_interleaver_outputs.setter\n    @abstractmethod\n    def num_bit_interleaver_outputs(self, value):\n        pass\n\n    @property\n    @abstractmethod\n    def termbits_conv2turbo(self):\n        pass\n\n    @termbits_conv2turbo.setter\n    @abstractmethod\n    def termbits_conv2turbo(self, value):\n        pass\n\n    @property\n    @abstractmethod\n    def termbits_turbo2conv(self):\n        pass\n\n    @termbits_turbo2conv.setter\n    @abstractmethod\n    def termbits_turbo2conv(self, value):\n        pass\n\n    @property\n    @abstractmethod\n    def mu(self):\n        pass\n\n    @mu.setter\n    @abstractmethod\n    def mu(self, value):\n        self._mu = value\n\n    @property\n    @abstractmethod\n    def rsc_n(self):\n        pass\n\n    @rsc_n.setter\n    @abstractmethod\n    def rsc_n(self, value):\n        self._rsc_n = value\n\n    @property\n    def turbo_circuit(self):\n        return self._turbo_circuit\n\n    @turbo_circuit.setter\n    def turbo_circuit(self, value):\n        self._turbo_circuit = value\n\n    @property\n    def conv_term_syndromes(self):\n        if self._conv_term_syndromes is None:\n            self._conv_term_syndromes = self.turbo_circuit.get_syndrome(self.\n                                                termbits_turbo2conv)\n        return self._conv_term_syndromes\n\n    @property\n    def num_bit_streams(self):\n        return self._num_bit_streams\n\n    @num_bit_streams.setter\n    def num_bit_streams(self, value):\n        self._num_bit_streams = int(value)\n        if self._num_bit_streams == 1:\n            self.termbits_conv2turbo = TerminationBitConv2TurboSingle()\n        elif self._num_bit_streams == 2:\n            self.termbits_conv2turbo = TerminationBitConv2TurboDupCheck()\n        else:\n            self.termbits_conv2turbo = TerminationBitConv2TurboScatter()\n\n    @property\n    def termbits_turbo2conv(self):\n        return self.termbits_conv2turbo.termbits_turbo2conv\n\n    def _check_constraint_length(self):\n        \"\"\"\n        Check that the constraint_length is valid for a Turbo code, i.e. the\n        underlying convolutional encoders are consistent.\n        \"\"\"\n        assert self.constraint_length in (3, 4), \\\n                                \"Unsupported constraint length {}\".format(self)\n\n        if self.constraint_length==3:\n            assert self.conv_n==1, \"Constraint_length=3 implies conv_n=1\"\n        elif self.constraint_length==4:\n            assert self.conv_n in (1, 2), \\\n                \"Constraint_length=4 implies conv_n is 1 or 2\"\n            assert self.num_bit_streams in (2, 3), \\\n                \"Constraint_length=4 implies num_bit_streams is 2 or 3\"\n\n        mem_mu = self.constraint_length - 1\n        mem_conv = self.conv_n - 1\n\n        # memory of the convolutional decoders must be the same\n        # memory in turbo model.\n        assert mem_mu==mem_conv, \"mem_mu must be equal to mem_conv\"\n        self._mu = mem_mu\n        self._rsc_n = 2**self._mu\n\n    @abstractmethod\n    def get_num_term_syms(self):\n        \"\"\"\n        Computes the number of termination symbols for the Turbo code\n        \"\"\"\n        pass\n\n    def termbits_turbo2conv(self, term_bits):\n        \"\"\"\n        This method splits the termination symbols from a Turbo codeword\n        to the termination symbols corresponding to the two convolutional\n        encoders, respectively.\n\n        Lets assume $\\mu=4$ and the underlying convolutional encoders are\n        systematic and rate-1/2, for demonstration purposes.\n\n        Let `term_bits` tensor, corresponding to the termination symbols of\n        the Turbo codeword be as following:\n\n        $y = [x_1(K), z_1(K), x_1(K+1), z_1(K+1), x_1(K+2, z_1(K+2)$,\n        $x_1(K+3), z_1(K+3), x_2(K), z_2(K), x_2(K+1), z_2(K+1),$\n        $x_2(K+2), z_2(K+2), x_2(K+3), z_2(K+3), 0, 0]$\n\n        The two termination tensors corresponding to the convolutional encoders\n        are:\n        $y[0,..., 2\\mu]$, $y[2\\mu,..., 4\\mu]$. The output from this method is\n        a tuple of two tensors, each of size $2\\mu$ and shape $[\\mu,2]$.\n\n        $[[x_1(K), z_1(K)]$, $[x_1(K+1, z_1(K+1)]$, $[x_1(K+2, z_1(K+2)]$,\n        $[x_1(K+3), z_1(K+3)]]$\n\n        and\n\n        $[[x_2(K), z_2(K)]$,\n\n        $[x_2(K+1), z_2(K+1)]$,\n\n        $[x_2(K+2, z_2(K+2)]$,\n\n        $[x_2(K+3), z_2(K+3)]`\n        ```python\n        x = self.termbits_conv2turbo.term_bits_turbo2conv(term_bits)\n        x1 = tf.squeeze(x[0], axis=1)\n        x2 = tf.squeeze(x[1], axis=1)\n        return x1, x2\n        ```\n\n\n```python\nfrom sionna.fec.turbo.utils import TerminationBitConv2Turbo\n\n#assuming TurboTermination is an instance of TurboTermination\noutput = TurboTermination.termbits_turbo2conv(term_bits)\n```"
"To wrap everything in a Keras model for convenient BER simulations and comparison of model parameters, you can define a class that inherits from `tf.keras.Model`. Within this class, you can initialize the components you will use in the `__init__` method. These components include the binary source, the LDPC encoder and decoder, the mapper and demapper, the flat fading channel, and the LMMSE equalizer. \n\nAfter initializing the components, you can define the `call` method. This method will be used to define the forward pass of the model. In the `call` method, you can specify the batch size and the Eb/No value (in dB). The `binary_source` component is used to generate the transmit data. The data is then encoded using the LDPC encoder. The encoded data is mapped using the mapper. The mapped data is passed through the flat fading channel. The LMMSE equalizer is then used to estimate the transmitted data. The estimated data and the noise variance are passed to the `demapper`, which provides the log-likelihood ratios (LLRs) for the transmitted bits. The LLRs are then passed to the LDPC decoder to get the estimated transmitted bits.\n\nThis Keras model can be used to conveniently perform bit error rate (BER) simulations and compare model parameters. The model can be instantiated with different spatial correlations and used to simulate the BER for different parameter values."
"The \"build_type_grid\" method of the ResourceGrid class is used to return a tensor indicating the type of each resource element of the resource grid. The type of a resource element can be one of the following four types:\n\n- Data symbol (Type 0)\n- Pilot symbol (Type 1)\n- Guard carrier symbol (Type 2)\n- DC carrier symbol (Type 3)\n\nThe output of the method is a tensor of shape [num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size] and of type tf.int32, where:\n\n- num_tx: Number of transmitters\n- num_streams_per_tx: Number of streams per transmitter\n- num_ofdm_symbols: The number of OFDM symbols\n- fft_size: The FFT size\n\nIn more detail, the function returns a tensor that describes the type of resource elements in the resource grid used for various transmissions. The resource elements can be one of the four types listed above. Please note the the pilot_pattern indicates which resource elements are reserved for pilots. This method would return a tensor of shape *[num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size]*. This would allow you to check the type of resource elements for each individual transmitter and stream."
"Here is the detailed information of [sionna.mapping.SymbolLogits2LLRs(method, num_bits_per_symbol, hard_out=False, with_prior=False, dtype=tf.float32, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#SymbolLogits2LLRs):  \n  \nComputes log-likelihood ratios (LLRs) or hard-decisions on bits from a tensor of logits (i.e., unnormalized log-probabilities) on constellation points. If the flag with_prior is set, prior knowledge on the bits is assumed to be available. This prior information is given as LLRs as an additional input to the layer.\n\nParameters\n\n- **method** (One of [\"app\", \"maxlog\"], str) \u2013 The method used for computing the LLRs.\n- **num_bits_per_symbol** (int) \u2013 The number of bits per constellation symbol, e.g., 4 for QAM16.\n- **hard_out** (bool) \u2013 If True, the layer provides hard-decided bits instead of soft-values. Defaults to False.\n- **with_prior** (bool) \u2013 If True, it is assumed that prior knowledge on the bits is available. This prior information is given as LLRs as an additional input to the layer. Defaults to False.\n- **dtype** (One of [tf.float32, tf.float64] tf.DType) \u2013 The dtype for the input and output. Defaults to tf.float32.\n\nInput\n\n- **logits** ([\u2026,n, num_points], tf.float) \u2013 Logits on constellation points.\n- **prior** ([num_bits_per_symbol] or [\u2026,n, num_bits_per_symbol], tf.float) \u2013 Prior for every bit as LLRs. It can be provided either as a tensor of shape [num_bits_per_symbol] for the entire input batch, or as a tensor that is \u201cbroadcastable\u201d to [\u2026,n,num_bits_per_symbol]. This allows, for example, to provide higher-order modulation as prior knowledge for demapping.\n\nOutput\n\n- **[\u2026,n, num_bits_per_symbol] or [\u2026,n], tf.float** \u2013 LLRs or hard-decisions for every bit.\n\n**Note: **With the app method, the LLR for the \ud835\udc56th bit\nis computed according to  \n$$\n\\begin{align}\nLLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert \\mathbf{z},\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert \\mathbf{z},\\mathbf{p}\\right)}\\right) =\\ln\\left(\\frac{\n        \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n        e^{z_c}\n        }{\n        \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n        e^{z_c}\n        }\\right)\n\\end{align}\n$$  \nwhere $\\mathcal{C}_{i,1}$ and $\\mathcal{C}_{i,0}$ are the\nsets of $2^K$ constellation points for which the \ud835\udc56th bit is\nequal to 1 and 0, respectively.\nThe definition of the LLR has been chosen\nsuch that it is equivalent with that of logits. This is\ndifferent from many textbooks in communications, where the LLR is\ndefined as $LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)$.  \n  \nWith the maxlog method, LLRs for the \ud835\udc56th bit\nare approximated like  \n$$\n\\begin{align}\nLLR(i) &\\approx\\ln\\left(\\frac{\n        \\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            e^{z_c}\n        }{\n        \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            e^{z_c}\n        }\\right)\n        .\n\\end{align}\n$$  \nThis method is numerically more stable as it avoids the computation of large\nexponentials.  \n  "
"Here is the detailed information of MaximumLikelihoodDetector:   \n[sionna.ofdm.MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#MaximumLikelihoodDetector)  \n\nMaximum-likelihood (ML) detector for OFDM MIMO transmissions.\n\nThis layer implements maximum-likelihood (ML) detection\nfor OFDM MIMO transmissions. Both ML detection of symbols or bits with\neither soft- or hard-decisions are supported. The OFDM and stream configuration\nare provided by a ResourceGrid and StreamManagement instance, respectively.\nThe actual detector is an instance of MaximumLikelihoodDetector.\n\n**Parameters**\n\n- `output` (str): Type of output, either \"bit\" or \"symbol\". Whether soft- or hard-decisions are returned can be configured with the `hard_out` flag.\n- `demapping_method` (str): Demapping method used, either \"app\" or \"maxlog\".\n- `resource_grid` (ResourceGrid): Instance of ResourceGrid.\n- `stream_management` (StreamManagement): Instance of StreamManagement.\n- `constellation_type` (str): Type of constellation, either \"qam\", \"pam\", or \"custom\". For \"custom\", an instance of Constellation is required.\n- `num_bits_per_symbol` (int): Number of bits per constellation symbol, e.g., 4 for QAM16. Required only for constellation types \"qam\" or \"pam\".\n- `constellation` (Constellation): Instance of Constellation or None. If None, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- `hard_out` (bool): If True, the detector computes hard-decided bit values or constellation point indices instead of soft-values. Defaults to False.\n- `dtype` (tf.DType): The dtype of `y`. Defaults to tf.complex64. The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n**Input**\n\n- `(y, h_hat, prior, err_var, no)` \u2013 Tuple:\n  - `y` ([batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex): Received OFDM resource grid after cyclic prefix removal and FFT.\n  - `h_hat` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex): Channel estimates for all streams from all transmitters.\n  - `prior` ([batch_size, num_tx, num_streams, num_data_symbols x num_bits_per_symbol] or [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float): Prior of the transmitted signals. If `output` equals \"bit\", LLRs of the transmitted bits are expected. If `output` equals \"symbol\", logits of the transmitted constellation points are expected.\n  - `err_var` ([Broadcastable to shape of h_hat], tf.float): Variance of the channel estimation error.\n  - `no` ([batch_size, num_rx, num_rx_ant] or only the first n dimensions, tf.float): Variance of the AWGN noise.\n\n**Output**\n\nDepending on the `output` setting:\n- If `output` equals \"bit\":\n  - `[batch_size, num_tx, num_streams, num_data_symbols * num_bits_per_symbol]', tf.float`: LLRs or hard-decisions for every bit of every stream.\n- If `output` equals \"symbol\":\n  - `[batch_size, num_tx, num_streams, num_data_symbols, num_points]', tf.float or `[batch_size, num_tx, num_streams, num_data_symbols]`, tf.int: Logits or hard-decisions for constellation symbols for every stream. Hard-decisions correspond to the symbol indices."
"To initialize a `TurboEncoder` with custom generator polynomials, you need to understand the format and meaning of the \"generator polynomials\" in the context provided. The context mentions that the `TurboEncoder` only accepts the binary format representation of the generator polynomial, which is `10011`.\n\nThe generator polynomial in the context is used for the constituent convolutional encoders in the Turbo code. In the binary format, a polynomial like $1 + D^3 + D^4$ is represented as `10011`. Here, the symbols are the coefficients of the polynomial arranged from the highest power of D to the 0 power, where D is the \"drive\" polynomial for the K=3 convolutional code defined by the polynomials in the context.\n\nSo, the format for the generator polynomial input to the `TurboEncoder` is a string of 0s and 1s, where each symbol corresponds to the coefficient of the polynomial in binary representation. The `gen_poly` in the example is `10011`, which represents the polynomial in a binary format.\n\nHere's the snippet from the context that provides the answer:\n\n```python\nencoder = TurboEncoder(gen_poly=gen_poly,\n                       rate=1/3,\n                       terminate=False)\n```\n\nIn this code, `gen_poly` is the generator polynomial expressed in the format accepted by the `TurboEncoder`. It is a variable that is not defined in the provided context. To get the exact value of `gen_poly`, you would need to refer to the source code or documentation of the `sionna.fec.turbo.TurboEncoder` library."
"To use the generator to sample the first few items of the dataset, you can follow these steps:\n\n1. Initialize the generator with the filename of the dataset.\n\n```python\ngenerator = HD5CIRGen(filename)\n```\n\n2. Call the generator with an empty argument. This will initiate the parsing of the dataset.\n\n```python\n(a,tau) = generator()\n```\n\n3. This call will return the next item in the dataset. You can put this inside a loop to get multiple items. \n\n4. In the loop, print the shapes of 'a' and 'tau' to understand the structure of the data.\n\n5. If the dataset is large, you can consider storing the generator output in a variable for further use. \n\n6. Make sure the dataset is fully utilized and doesn't go into an infinite loop. You can catch the StopIteration error when the dataset is exhausted.\n\n7. The generator can be used in the setup of a channel model. Make sure to not run the generator in the data forwarding path of your code as it might cause a performance hit.\n\nPlease note that the code provided in the context is specific to the 'Sionna' package. If you're using a different package or tool, the syntax might be different."
"To save the estimated matrices for future use, you can use the numpy `save` function. Here is a step-by-step guide:\n\n1. First, you need to import the numpy library. This can be done using the following code:\n\n```python\nimport numpy as np\n```\n\n2. Then, you can use the `save` function from the `np` module to save the matrices. The first argument is the name of the file where you want to save the matrices, and the second argument is the matrix you want to save.\n\n```python\nnp.save('freq_cov_mat', FREQ_COV_MAT.numpy())\nnp.save('time_cov_mat', TIME_COV_MAT.numpy())\nnp.save('space_cov_mat', SPACE_COV_MAT.numpy())\n```\n\nIn this code, `'freq_cov_mat'`, `'time_cov_mat'`, and `'space_cov_mat'` are the names of the files where you are saving the matrices, and `FREQ_COV_MAT.numpy()`, `TIME_COV_MAT.numpy()`, and `SPACE_COV_MAT.numpy()` are the matrices you are saving. The `numpy` function `save` will save these matrices in .npy format. \n\nPlease note that the `FREQ_COV_MAT`, `TIME_COV_MAT`, and `SPACE_COV_MAT` are defined in the previous code as the estimated frequency, time, and space covariance matrices respectively. These matrices are estimated using the `estimate_covariance_matrices` function from the Sionna package."
"The Iterative Detection and Decoding (IDD) concept in the context of MIMO simulations involves iteratively exchanging soft-information between the data detector and the channel decoder to improve the quality of the received signals. \n\nThe IDD MIMO receiver works in two main steps. The first step is the data detection, which aims to recover the transmitted data symbols. This is done by calculating the Log-Likelihood Ratios (LLRs) of the received signal and passing these LLRs, along with the channel error covariance matrix and the apriori information about the transmitted signal, to the second step. \n\nThe second step is the decoding, which uses the LLRs from the data detection step to decode the received signal into a binary MIMO representation. This decoded signal, along with the LLRs, is then passed back to the data detection step for further processing. \n\nIDD is a powerful tool for MIMO simulations as it takes into account the inherent correlation between the received signals in each antenna of the MIMO system, which can significantly impact the performance of traditional data detection and decoding algorithms. \n\nIn this context, the Sionna package is used to implement the IDD MIMO receiver, providing utilities to simulate various types of channels, antennas, and encoding/decoding processes. The package also offers functionalities to process signal-to-noise ratios (SNRs), compute bit error rates (BERs), and perform OFDM channel estimations and Monte-Carlo simluations."
"Here is the detailed information of Descrambler:  \nSource code link: https://nvlabs.github.io/sionna/_modules/sionna/fec/scrambling.html#Descrambler\n\nDescrambler class\n\nclass Descrambler(scrambler, binary=True, dtype=None, **kwargs)\n\nThe class inherits from the Keras layer class and can be used as layer in a Keras model.\n\nParameters\n\n- `scrambler` (Scrambler) \u2013 Associated Scrambler instance which should be descrambled.\n- `binary` (bool) \u2013 Defaults to True. Indicates whether bit-sequence should be flipped (i.e., binary operations are performed) or the signs should be flipped (i.,e., soft-value/LLR domain-based).\n- `dtype` (None or tf.DType) \u2013 Defaults to None. Defines the datatype for internal calculations and the output dtype. If no explicit dtype is provided the dtype from the associated interleaver is used.\n\nInput\n\n- `(x, seed)` \u2013 Either Tuple `(x, seed)` or `x` only (no tuple) if the internal seed should be used:\n  - `x` ([\u2026, n], tf.float) \u2013 1+D tensor of arbitrary shape.\n  - `seed` (int) \u2013 An integer defining the state of the random number generator. If explicitly given, the global internal seed is replaced by this seed. Can be used to realize random interleaver/deinterleaver pairs (call with same random seed).\n\nOutput\n\n- ([\u2026, n], tf.float) \u2013 1+D tensor of same shape as `x`.\n\nRaises\n\n- `AssertionError` \u2013 If `scrambler` is not an instance of Scrambler.\n- `AssertionError` \u2013 If `seed` is provided to list of inputs but not an int.\n- `TypeError` \u2013 If `dtype` of `x` is not as expected.\n\nProperty\n\n- `scrambler` \u2013 Associated scrambler instance."
"Here is the the definition of KBestDetector: sionna.ofdm.KBestDetector(output, num_streams, k, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, use_real_rep=False, list2llr=None, dtype=tf.complex64, **kwargs)\n  \nAnd here is the link of the source code: [sionna.ofdm.KBestDetector](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#KBestDetector)  \n  \n```python\nclass KBestDetector(OFDMDetectorWithTermination):\n    # pylint: disable=line-too-long\n    r\"\"\"KBestDetector(output, num_streams, k, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, use_real_rep=False, list2llr=None, dtype=tf.complex64, **kwargs)\n\n    This layer wraps the MIMO K-Best detector for use with the OFDM waveform.\n\n    Both detection of symbols or bits with either\n    soft- or hard-decisions are supported. The OFDM and stream configuration are provided\n    by a :class:`~sionna.ofdm.ResourceGrid` and\n    :class:`~sionna.mimo.StreamManagement` instance, respectively.\n    The actual detector is an instance of :class:`~sionna.mimo.KBestDetector`.\n\n    Parameters\n    ----------\n    output : One of [\"bit\", \"symbol\"], str\n        Type of output, either bits or symbols. Whether soft- or\n        hard-decisions are returned can be configured with the\n        ``hard_out`` flag.\n\n    num_streams : tf.int\n        Number of transmitted streams\n\n    k : tf.int\n        Number of paths to keep. Cannot be larger as the number of\n        constellation points to the power of the number of streams.\n\n    resource_grid : ResourceGrid\n        Instance of :class:`~sionna.ofdm.ResourceGrid`\n\n    stream_management : StreamManagement\n        Instance of :class:`~sionna.mimo.StreamManagement`\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        Instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the detector computes hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`.\n\n    use_real_rep : bool\n        If `True`, the detector uses the real-valued equivalent representation\n        of the channel. Note that this only works with a QAM constellation.\n        Defaults to `False`.\n\n    list2llr : List2LLR\n        The function to be used to compute LLRs from a list of candidate solutions.\n        It can be `None`, in which case the default solution\n        :class:`~sionna.mimo.List2LLRSimple` is used.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of `y`. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    ------\n    (y, h_hat, err_var, no) :\n        Either Tuple ``(y, h_hat, err_var, no)`` or  ``(y, h_hat, err_var)`` if ``no`` is `None`.\n\n    y : [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex\n        Received OFDM resource grid after cyclic prefix removal and FFT\n\n    h_hat : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex\n        Channel estimates for all streams from all transmitters\n\n    err_var : [Broadcastable to shape of ``h_hat``], tf.float\n        Variance of the channel estimation error\n\n    no : [batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float\n        Variance of the AWGN\n\n    Output\n    ------\n    One of:\n\n    : [batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream if ``output`` equals `\"bit\"`.\n\n    : [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int\n        Logits or hard-decsions for constellation symbols for every stream if ``output`` equals `\"symbol\"`.\n\n    Note\n    ----\n    If you want to use this layer in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sionna.Config.xla_compat=true``.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n\n    def __init__(self,\n                 output,\n                 num_streams,\n                 k,\n                 resource_grid,\n                 stream_management,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 use_real_rep=False,\n                 list2llr=\"default\",\n                 dtype=tf.complex64,\n                 **kwargs):\n\n        # Instantiate the KBestDetector\n        detector = KBestDetector_(output=output,\n                                 num_streams=num_streams,\n                                 k=k,\n                                 constellation_type=constellation_type,\n                                 num_bits_per_symbol=num_bits_per_symbol,\n                                 constellation=constellation,\n                                 hard_out=hard_out,\n                                 use_real_rep=use_real_rep,\n                                 list2llr=list2llr,\n                                 dtype=dtype,\n                                 **kwargs)\n\n        super().__init__(detector=detector,\n                         output=output,\n                         num_streams=num_streams,\n                         resource_grid=resource_grid,\n                         stream_management=stream_management,\n                         dtype=dtype,\n                         **kwargs)\n```"
"The `position` and `orientation` properties in Sionna are used to move scene objects. The `position` property is a three-dimensional vector that determines the position of an object in the scene. The `orientation` property is a three-dimensional vector as well, which defines the orientation or direction of an object's movement.\n\nTo adjust the `position` and `orientation` properties of a scene object, you will first need to access the object from the scene's list of radio devices. This can be done using the `get` method with the object's name as an argument. For example:\n\n```python\nrd = scene.get(\"name_of_object\")\n```\n\nOnce you have the object, you can set its `position` and `orientation` properties directly. For `position`, simply assign a three-element list with the desired x, y, and z coordinates. For `orientation`, assign a three-element list with the object's pitch, yaw, and roll angles in radians:\n\n```python\nrd.position = [x, y, z]\nrd.orientation = [pitch, yaw, roll]\n```\n\nPitch, yaw, and roll correspond to rotations around the x, y, and z axes, respectively. By adjusting these properties, you can effectively move the object within the scene while keeping its relative position to other objects unchanged.\u79fb position of an object in the scene. The orientation corresponds to the direction in which an object is moving or facing.\n\nIt is important to note that the `position` and `orientation` properties are not independent when setting them. For example, if you move an object to a new position and you want to set its orientation to zero, you will also need to set its orientation such that it is aligned with the scene's geometry. This is because Sionna uses ray tracing for various calculations, and the `orientation` of an object affects the results of the simulations.\n\nLastly, the `position` and `orientation` properties can also be retrieved as a single matrix using the `get_world_transform` method. This matrix can be used for computations before being set as the `position` and `orientation` properties of another object."
"To run the final evaluation for different system configurations in Sionna RT, you need to follow these steps:\n\n1. Import the necessary modules and set up the environment. This includes importing Sionna and TensorFlow, setting up the GPU configuration, and setting the random seed for reproducibility.\n\n2. Define the simulation parameters. This includes the number of Monte Carlo simulations, the number of steps, the field of view, the carrier frequency, and the other parameters related to the scene and the antennas.\n\n3. Load the scene and configure it. This involves setting the scene directory, loading the scene, setting the radio materials, configuring the transmitters and receivers, and computing the propagation paths.\n\n4. Define the different system configurations. This involves creating different instances of the same transmitter and receiver configuration with different antenna settings.\n\n5. Define the evaluation function. This function should return the average bit error rate (BER) and block error rate (BLER) for a given batch size and signal-to-noise ratio (SNR) in dB.\n\n6. Run the evaluation for each system configuration. This involves using the `tf.function` decorator for the evaluation function to speed up the execution by precompiling the function.\n\n7. Plot the results.\n\nPlease note that the exact code and parameters may vary depending on the specific requirements of your simulation. The provided context does not include the specific code for each step, but it does provide a general outline of the steps needed to run the final evaluation for different system configurations in Sionna RT."
"To compute the exact Doppler shifts based on the provided equation in the Background Information, you can follow these steps:\n\n1. Compute the outgoing directions for the LoS and reflected path:\n```python\nk_t_los = r_hat(paths.theta_t[0,0,0,0], paths.phi_t[0,0,0,0)\nk_t_ref = r_hat(paths.theta_t[0,0,0,1], paths.phi_t[0,0,0,1)\n```\n\n2. Compute the Doppler shifts due to the movement of the transmitter:\n```python\ndoppler_tx_los = np.sum(k_t_los * tx_velocity) / scene.wavelength\ndoppler_tx_ref = np.sum(k_t_ref * tx_velocity) / scene.wavelength\n```\n\n3. Compute the overall Doppler shifts:\n```python\ndoppler_los = doppler_tx_los + paths.doppler[0,0,0,0]\ndoppler_ref = doppler_tx_ref + paths.doppler[0,0,0,1]\n```\n\n4. Print the results:\n```python\nprint(\"Delay - LoS Path (ns) :\", paths.tau[0,0,0,0].numpy()/1e-9)\nprint(\"Doppler - LoS Path (Hz) :\", doppler_los.numpy())\nprint(\"Delay - Reflected Path (ns) :\", paths.tau[0,0,0,1].numpy()/1e-9)\nprint(\"Doppler - Reflected Path (Hz) :\", doppler_ref.numpy())\n```\n\nThe exact Doppler shift is printed as \"Doppler - LoS Path (Hz)\" for the LoS path and as \"Doppler - Reflected Path (Hz)\" for the reflected path. These steps are based on the provided Python code in the context."
"Here is the definition of cir_to_time_channel: sionna.channel.cir_to_time_channel\uff08bandwidth\uff0ca\uff0ctau\uff0cl_min\uff0cl_max\uff0cnormalize = False\uff09\n\n[sionna.channel.cir_to_time_channel](https://nvlabs.github.io/sionna/_modules/sionna/channel/utils.html#cir_to_time_channel)\n\nsionna.channel.cir_to_time_channel(bandwidth, a, tau, l_min, l_max, normalize=False)\n\nCompute the channel taps forming the discrete complex-baseband representation of the channel from the channel impulse response (a, tau).\n\nThis function assumes that a sinc filter is used for pulse shaping and receive filtering. Therefore, given a channel impulse response $(a_{m}(t), \\tau_{m}), 0 \\leq m \\leq M-1$, the channel taps are computed as follows:\n\n$$\n\\bar{h}_{b, \\ell}\n= \\sum_{m=0}^{M-1} a_{m}\\left(\\frac{b}{W}\\right)\n    \\text{sinc}\\left( \\ell - W\\tau_{m} \\right)\n    \\ \\ \\ \\text{for} \\ \\ \\ \\ell \\ \\text{ranging from} \\ \\ l_{\\text{min}} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\"
"To generate the Channel Frequency Response and the Discrete-Time Channel Impulse Response, using Sionna's module functions, do the following:\n\n1. **Generate the Channel Frequency Response**: Use the `cdl` function from the `sionna.channel` module to generate the channel impulse response. You will need to provide the `batch_size`, `num_time_steps`, `sampling_frequency`, `num_antenna_columns`, `num_antenna_rows`, `num_polarization`, and `num_bits_per_symbol` parameters. In the context, the parameters were set as follows:\n\n```python\ncdl(batch_size=2, \n    num_time_steps=rg.num_time_samples+l_tot-1, \n    sampling_frequency=rg.bandwidth)\n```\n\n2. **Generate the Discrete-Time Channel Impulse Response**: Use the `cir_to_time_channel` function from the `sionna.channel` module to generate the discrete-time channel impulse response. You will need to provide a `bandwidth` and the `a` and `tau` parameters obtained from the `cdl` function. In the context, the statement was:\n\n```python\na, tau = cdl(batch_size=2, \n            num_time_steps=rg.num_time_samples+l_tot-1, \n            sampling_frequency=rg.bandwidth)\n```\n\n3. **Apply the Discrete-Time Channel Impulse Response**: Apply the generated discrete-time channel impulse response to the channel input by using the `ApplyTimeChannel` class from the `sionna.channel` module. You will need to provide the input symbols `x` and the noise variance `no`. In the context, the statement was:\n\n```python\ny = my_cir_model(x, no)\n```\n\nWhere `my_cir_model` is an instance of the `CIRModel` class created previously, `x` is the channel input, and `no` is the noise variance.\n\nRemember to import the necessary modules and functions from Sionna's package. If you are not familiar with Sionna, use the provided context and refer to Sionna's documentation for guidance."
"The principle idea of higher order modulation is to use a complex-valued waveform to transmit multiple bits in parallel. This is achieved by mapping a set of bits to a set of complex numbers, known as constellations. The constellation can represent more than two bits per symbol and allows for a more efficient use of the available bandwidth.\n\nThe demapper is the component that processes the received complex-valued waveform and generates an error estimate for each bit. This is done by calculating the log-likelihood ratio (LLR), which is a measure of the bit-wise confidence. The LLR for each bit is then passed to the decoder for further processing.\n\nIn the context of Bit-Interleaved Coded Modulation (BICM), the principle idea is to separate the modulation and coding into two individual tasks. This separation allows for the use of binary bit-metric decoding and simplifies the engineering of modern communication systems.\n\nThe decoder is the component that processes the LLRs and generates a hard decision for each codeword bit. In the case of BICM, the decoder uses the LLRs to estimate the transmitted information bits, which can then be compared with the original data for error detection and correction."
"To handle the situation where the LDPCBPDecoder is stateful, you need to provide the `msg_vn` parameter when calling the decoder. This parameter represents the VN messages, which are required for the next iteration of belief propagation decoding to update the messages. In the context of 5G LDPC codes, stateful decoding is used to improve the performance of the decoder.\n\nHere's an example of how to deal with this using the Sionna package, keeping track of the state of the decoder:\n\n1. Import the necessary classes from the Sionna package:\n```python\nfrom sionna.fec.ldpc.decoding import LDPCBPDecoder, LDPC5GDecoder\nfrom sionna.fec.ldpc.utils import CN_TYPE\n```\n\n2. Define the LDPC decoder as stateful, specifying the type of check node operation to be performed (in this case, 'boxplus-phi'):\n```python\ndecoder = LDPC5GDecoder(decoding_algorithm=\"bp\",\n                         cn_type=CN_TYPE.boxplus_phi,\n                         num_iter=20,\n                         stateful=True)\n```\n\n3. Obtain the VN messages for the first iteration by passing the `msg_vn` parameter as `None`:\n```python\nvn_message = None # First iteration does not use previous messages\nc_hat_ldpc = decoder(llr_mat, vn_message)\n```\n\n4. For subsequent iterations, use the VN messages from the previous iteration. The output `c_hat_ldpc` now represents the estimated codeword bits after 20 iterations of decoding.\n\nRemember, the `msg_vn` parameter is essential when the decoder is stateful because it provides the VN messages from the previous iteration to the decoder. This can help improve the decoding quality and iteration efficiency."
"Here is the detailed information of subcarrier_frequencies:   \n[sionna.channel.subcarrier_frequencies(fft_size, subcarrier_spacing=15e3, center_subcarrier=0)](https://nvlabs.github.io/sionna/_modules/sionna/channel/utils.html#subcarrier_frequencies)\n\nCompute the nfft normalized DSL subcarrier frequencies.\n\nFor an OFDM system, the frequency of the n-th subcarrier is given as , where is the subcarrier spacing, and is the number of FFT symbols. This function returns the frequency for the positive- and negative-frequency components of the DSL impulse response\u2019s power spectral density, computed over a frequency range of 0 to Hz.\n\n**Input Parameters**\n\n- `fft_size` (int): FFT size, i.e., the number of subcarriers.\n- `subcarrier_spacing` (float): Subcarrier spacing in Hz. Defaults to 15e3.\n- `center_subcarrier` (int): Index of the center subcarrier. Defaults to 0.\n\n**Output**\n\n- `frequencies` ([fft_size], float): Subcarrier frequencies in Hz.\n\nsource code:\n```python\ndef subcarrier_frequencies(fft_size, subcarrier_spacing=15e3,\n                           center_subcarrier=0):\n    r\"\"\"\n    Compute the `fft_size` normalized DSL subcarrier frequencies.\n\n    For an OFDM system, the frequency of the `n`-th subcarrier is given as\n\n    .. math::\n\n        f = k \\Delta_f\n\n    where :math:`\\Delta_f` is the subcarrier spacing, and :math:`K` is the\n    number of FFT symbols. This function returns the frequency for the\n    positive- and negative-frequency components of the DSL impulse response's\n    power spectral density, computed over a frequency range of 0 to :math:`H_\\text{max}=\\frac{1}{\\Delta_t}` Hz. Ony the\n    positive frequencies are returned by this function.\n\n    Input\n    ------\n    fft_size : int\n        FFT size, i.e., the number of subcarriers\n\n    subcarrier_spacing : float\n        Subcarrier spacing [Hz]. Defaults to 15e3.\n\n    center_subcarrier : int\n        Index of the center subcarrier. Defaults to 0.\n\n    Output\n    -------\n    frequencies : (fft_size,), float\n        Subcarrier frequencies [Hz]\n    \"\"\"\n    assert isinstance(fft_size, int), \"`fft_size` must be int.\"\n    assert isinstance(subcarrier_spacing, (int, float)), \\\n                                \"`subcarrier_spacing` must be int or float.\"\n    assert isinstance(center_subcarrier, int), \\\n        \"`center_subcarrier` must be int.\"\n\n    hz = np.arange(fft_size).astype(np.float32)\n    hz -= fft_size*subcarrier_spacing/2\n    hz += subcarrier_spacing/2*center_subcarrier\n    return hz\n```"
"To simulate the transmission of a single Gaussian impulse over a lumped amplification channel model consisting of multiple fiber spans and optical amplifiers (EDFA), you can follow these steps:\n\n1. **Setup the Simulation Environment:**\n   - Import the necessary libraries and modules. This includes Sionna, which is a novel Python package for simulating wireless channels.\n   - Set the simulation parameters. These parameters include the carrier frequency, the impulse duration, the number of channel models (in this case, 5), and the number of samples per symbol.\n   - Define the channel models. These models include line-of-sight (LoS) and non-line-of-sight (NLoS) scenarios, with and without reflection.\n\n2. **Simulate the Channel:**\n   - For each channel model, simulate the channel and generate the propagation paths. The number of paths varies between the different models.\n   - Compute the channel impulse response by summing the contributions from all propagation paths.\n\n3. **Apply the Channel:**\n   - Apply the channel to the input signal. This can be done using the GaussianChannel and OFDMChannel classes. The channel models are passed as parameters during the setup.\n\n4. **Add Lumped Amplification:**\n   - Create a channel model that uses lumped amplification. This is done by using the LumpedAmplification class, which requires the signal-to-noise ratio (SNR) as a parameter.\n   - Apply the new channel model to the channel output.\n\n5. **Visualize the Results:**\n   - Plot the simulated channel responses and the transmitted impulse.\n\nRemember that the code provided in the context is specific to simulating the channel. Depending on your exact requirements, you may need to adjust the parameters and add additional steps."
"Given the provided context, the detailed information of \"CRCDecoder\" should have the following:\n\nA. Parameters of the Class:\n\n- \"crc_encoder\": An instance of `CRCEncoder` to which the CRCDecoder is associated. It should be provided with a proper format. \n- \"dtype\": tf.DType, it defines the datatype for internal calculations and the output dtype. If no explicit dtype is provided the dtype from the associated interleaver is used. It is optional and defaults to None. \n\nB. Input of the Instance: \nThis should be a 2+D tensor containing the CRC encoded bits (the last crc_degree bits are parity bits). \n   \nC. Output of the Instance: \nThe CRCDecoder outputs two tensors:\n- \"x\": A 2+D tensor containing the information bit sequence without CRC parity bits.\n- \"crc_valid\": A 2+D tensor containing the result of the CRC per codeword.\n  \nD. Raises:\n- \"AssertionError\": When the `crc_encoder` is not CRCEncoder.\n- \"InvalidArgumentError\": It is raised when the rank(`x`)<2.\n\n**Note: **  \n1. For internal calculations and the output, `tf.float32` is used by default. \n2. The provided information details two properties-\"crc_degree\" and \"encoder\", the latter is not directly provided in the context. It's suggested to re-check the specific sionna package documents to provide the accurate description and the use of the \"encoder\" property.  \n3. The common errors section provides general errors and suggestions. However, as the context doesn't provide specific errors related to CRCDecoder, it's suggested to review the class implementation and the related documentation to learn about the specific errors that can occur in the CRCDecoder class.  \n4. Also, the class inherits from the Keras layer class, and can be used as layer in a Keras model."
"The output of the Constellation class is a handle to a matplot figure object. This object represents a scatter-plot of the constellation points used in the mapping. The constellation can represent a QAM or PAM modulation scheme, with the number of bits per symbol indicated as a parameter. If the constellation is centered and/or normalized, these attributes will be applied to the plot. The plot can display the binary labels of each constellation point if requested. The size of the figure (in inches) can also be specified."
"The datatype for the LinearEncoder output is defined using its `dtype` parameter. In the provided context, the `LinearEncoder` is instantiated with the default `tf.float32` datatype, which is equivalent to the standard Python `float` datatype. \n\nTo set the datatype for the output of the `LinearEncoder`, you would modify the `dtype` parameter during the instantiation of the `LinearEncoder`. For example, to use `tf.int32` instead of the default `tf.float32`, you would set `dtype=tf.int32`:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\nimport tensorflow as tf\n\n# Assume enc_mat is a valid encoding matrix in binary form\nenc_mat = # Your encoding matrix (binary tensor)\n\n# Define the LinearEncoder with the desired dtype\nencoder = LinearEncoder(enc_mat, is_pcm=False, dtype=tf.int32)\n\n# Ensure that the encoder is using the specified dtype\nprint(\"Encoder dtype:\", encoder.dtype)  # <tf.int32: as defined by the dtype parameter>\n```\n\nWhen the `LinearEncoder` is used as a layer in a Keras model, the datatype of the output would depend on the input data type. The `LinearEncoder` would attempt to match the datatype of the inputs and, accordingly, set the output datatype. If the desired output datatype is different from the default, it would be necessary to ensure compatibility within the model."
"Here is the detailed information of function sionna.utils.matrix_pinv: \n\nComputes the pseudo-inverse of a tensor.\n\nGiven a tensor input of shape ([..., M, N]), representing a batch of matrices, returns a tensor of the same shape containing the pseudo-inverses of these matrices.\n\n**Note:** The following two properties relate to the pseudo-inverse of a matrix A: \n\n- A A\u207a A = A\n- A\u207a A A = A\u207a\n\nThese ensure that for a matrix A of shape (M, N), if N>=M, the following relation is true:\n\n- A A\u207a \u2248 A A\u207a I\n\nThis is useful for situations where A A\u207a is not exactly invertible.\n\nThis function is a wrapper for the matrix_pinv function from TensorFlow.\n\n**Parameters**\n\n- `a`: A  tensor of rank greater than or equal to two, of the following shapes depending on the rank of `a`:\n    - Rank(a) = 2 : `a` is a matrix of shape [M, N]\n    - Rank(a) > 2 : `a` is a tensor of shape [..., M, N].\n\n**Returns**\n\n- `Tensor`: A tensor of the same shape and type as `a`, containing the pseudo-inverses of `a`.\n\n\nsource code:\n```python\ndef matrix_pinv(a):\n    # pylint: disable=line-too-long\n    r\"\"\"Computes the pseudo-inverse of a tensor.\n\n    Given a tensor ``input`` of shape `[..., M, N]`, returns a tensor of the\n    same shape containing the pseudo-inverses of these matrices.\n\n    Note\n    ----\n    The following two properties relate to the\n    pseudo-inverse of a matrix `A`:\n\n    .. math::\n\n        A A^{\\dagger} A = A\n\n    .. math::\n\n        A^{\\dagger} A A = A^{\\dagger}\n\n    These ensure that for a matrix `A` of shape (M, N), if `N>=M`, the\n    following relation is true:\n\n    .. math::\n\n        A A^{\\dagger} \\approx A A^{\\dagger} I\n\n    This is useful for situations where ``A A^{\\dagger}`` is not exactly\n    invertible.\n\n    This function is a wrapper for the :meth:`~sionna.tensor.matrix_pinv`\n    function from TensorFlow.\n\n    Parameters\n    ----------\n    a :  Tensor\n        A tensor of rank greater than or equal to two.\n\n    Note\n    ----\n    If you want to use this function in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sionna.config.xla_compat=true``.\n    See :py:attr:`~sionna.config.xla_compat`.\n    \"\"\"\n    return matrix_pinv(a)\n```"
"Here is the detailed information of the Demapper:   \n  \n[sionna.mapping.Demapper(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, with_prior=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Demapper) \n  \nComputes log-likelihood ratios (LLRs) or hard-decisions on bits for a tensor of received symbols.\n\nIf the flag with_prior is set, it is assumed that prior knowledge on the bits is available. This prior information is given as LLRs as an additional input to the layer.\n\nThis class defines a layer implementing different demapping functions. All demapping functions are fully differentiable when soft-decisions are computed.\n\n### Parameters\n\n- **demapping_method** (One of [\"app\", \"maxlog\"], str) - The demapping method used.\n- **constellation_type** (One of [\"qam\", \"pam\", \"custom\"], str) - For \"custom\", an instance of Constellation must be provided.\n- **num_bits_per_symbol** (int) - The number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation_type in [\"qam\", \"pam\"].\n- **constellation** (Constellation) - An instance of Constellation or None. In the latter case, constellation_type and num_bits_per_symbol must be provided.\n- **hard_out** (bool) - If True, the demapper provides hard-decided bits instead of soft-values. Defaults to False.\n- **with_prior** (bool) - If True, it is assumed that prior knowledge on the bits is available. This prior information is given as LLRs as an additional input to the layer. Defaults to False.\n- **dtype** (One of [tf.complex64, tf.complex128] tf.DType) - The dtype of y. Defaults to tf.complex64. The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n### Input\n\n- **y** ([..., n], tf.complex) - The received symbols.\n- **prior** ([num_bits_per_symbol] or [..., num_bits_per_symbol], tf.float) - Prior for every bit as LLRs. It can be provided either as a tensor of shape [num_bits_per_symbol] for the entire input batch, or as a tensor that is \"broadcastable\" to [..., n, num_bits_per_symbol].\n\n### Output\n\n[\u200b..., n, num_bits_per_symbol], tf.float - LLRs or hard-decisions for every bit.\n  \n**Note: **With the app demapping method, the LLR for the \ud835\udc56th bit is computed according to\n\n$$ LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert y,\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert y,\\mathbf{p}\\right)}\\right) =\\ln\\left(\\frac{\n        \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n        }{\n        \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n        }\\right)\n$$  \nwhere $\\mathcal{C}_{i,1}$ and $\\mathcal{C}_{i,0}$ are the sets of constellation points for which the \ud835\udc56th bit is equal to 1 and 0, respectively. $\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]$ is the vector of LLRs that serves as prior knowledge on the $K$ bits that are mapped to a constellation point and is set to $\\mathbf{0}$ if no prior knowledge is assumed to be available,\nand $\\Pr(c\\lvert\\mathbf{p})$ is the prior probability on the constellation symbol $c$:  \n$$ \\Pr\\left(c\\lvert\\mathbf{p}\\right) = \\prod_{k=0}^{K-1} \\text{sigmoid}\\left(p_k \\ell(c)_k\\right) $$  \nwhere $\\ell(c)_k$ is the $k^{th}$ bit label of $c$, where 0 is replaced by -1.  \nThe definition of the LLR has been chosen such that it is equivalent with that of logits. This is different from many textbooks in communications, where the LLR is\ndefined as $LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)$.\n    "
"Here is the definition of CDL: sionna.channel.tr38901.CDL(model, delay_spread, carrier_frequency, ut_array, bs_array, direction, min_speed=0.0, max_speed=None, dtype=tf.complex64)\n\nThe link of the source code is [sionna.channel.tr38901.CDL](https://nvlabs.github.io/sionna/_modules/sionna/channel/tr38901/cdl.html#CDL)\n\nHere is the explanation of parameters: \n\n- **model** (str): The CDL model to use. Must be one of \"A\", \"B\", \"C\", \"D\", or \"E\".\n\n- **delay_spread** (float): The RMS delay spread [s] which defines the standard deviation of the Gaussian impulse response in time domain.\n\n- **carrier_frequency** (float): Carrier frequency [Hz].\n\n- **ut_array** (PanelArray): Panel array used by the UTs. All UTs share the same antenna array configuration.\n\n- **bs_array** (PanelArray): Panel array used by the BSs. All BSs share the same antenna array configuration.\n\n- **direction** (str): Link direction. Either \"uplink\" or \"downlink\".\n\n- **ut_orientation** (None or Tensor of shape [3], tf.float): Defines the orientation of the UT. If set to None, [0,0,0] is used (which corresponds to fully polarized antenna rays in the vertical direction).\n\n- **bs_orientation** (None or Tensor of shape [3], tf.float): Defines the orientation of the BS. If set to None, [0,0,0] is used.\n\n- **ut_velocity** (float): Velocity of the UTs [m/s]. Defaults to 0.\n\n- **bs_velocity** (float): Velocity of the BSs [m/s]. Defaults to 0.\n\n- **los** (bool): If True, returns Line-Of-Sight (LoS) component. False by default. If False, only the reflected and diffracted paths are computed.\n\n- **average_ue_antenna_orientation** (None or Tensor of shape [3], tf.float): Defines the average orientation of the UE antennas. If set to None, [0,0,0] is used. Defaults to None.\n\n- **dtype** (Complex tf.DType): Defines the datatype for internal calculations and the output dtype. Defaults to tf.complex64."
"To handle an AssertionError raised when the input encoding matrix is not valid in the LinearEncoder, you need to ensure that the `enc_mat` you provide to the `LinearEncoder` is a valid binary 2-D matrix. The AssertionError is raised when the encoding matrix is not binary or when it does not have the appropriate shape (k, n).\n\nHere is a step-by-step guide to handle this type of error:\n\n1. Identify the AssertionError: The AssertionError is raised with the message \"AssertionError: Encoding matrix must be a binary 2-D matrix.\" You need to catch this specific error type.\n\n2. Ensure that the matrix is Binary: The encoding matrix must be binary, meaning that all of its elements are either `0` or `1`. If the encoding matrix that you are providing is not binary, the error will be raised.\n\n3. Verify the Shape: The encoding matrix's shape must be a 2-D matrix with dimensions k x n, where k is the number of information bits and n is the number of codeword bits. If the shape of the encoding matrix is not appropriate, an AssertionError will be raised.\n\nPython's \"assert\" statement is typically used to validate that the conditions you assume to be true are indeed true. In the case of the LinearEncoder, the conditions are that the encoding matrix is a valid binary matrix, and you can write code to handle these conditions as follows:\n\n```python\ntry:\n    # Attempt to create a LinearEncoder with an invalid matrix\n    # An AssertionError will be raised if the matrix is not valid\n    encoder = LinearEncoder(enc_mat=invalid_mat)\n    \nexcept AssertionError as e:\n    # This block of code is executed if the AssertionError is raised\n    print(\"An error occured:\", e)\n    # Add code here to recover from the error\n```\n\nIn the example above, `invalid_mat` is an example of an encoding matrix that would raise an AssertionError because it is not a valid binary matrix. By attempting to create the `LinearEncoder` with this matrix, we can catch the AssertionError and provide an opportunity to handle this error in the code. This could involve informing the user of the invalid input, prompting them to input a valid matrix, or programmatically creating a valid encoding matrix."
"Here are some of the papers and projects that use Sionna:\n\n  [C. J. Li, M. Mezzavilla, S. K. Katt, and R.D. Mallett1, \u201cSionna : A Python Package for\n  [Simulating Radios in the Sky] (https://nvlabs.github.io/sionna/),\n  with [Its API](https://nvlabs.github.io/sionna/api.html#api-c)] Li, Mezzavilla, Katt, and Mallett1, with Its API](https://nvlabs.github.io/sionna/api.html#api-c)  \nSource code: https://github.com/nvlabs/sionna  \nDocumentation: https://nvlabs.github.io/sionna/\n\n  * [HyberLPFM: A Python Package for Evaluating Hyperbolic Linear Canonical\n    Pulse-Dense FM Radar Models](https://hyperlpfm.readthedocs.io/)\n    Liang, Y., Wang, Y., Kikuchi, H., & Yang, J. (2021). HyberLPFM: A Python Package for Evaluating Hyperbolic Linear Canonical Pulse-Dense FM Radar Models. Remote Sensing, 13(14), 2504. https://www.mdpi.com/2076-  982553/1/13/2504\n  * [Wang, Y., Liang, Y., Wang, Y., Kikuchi, H., Yang, J. Sionna: A Fast and Flexible 5G NR\n    Simulator](https://nvlabs.github.io/sionna/),  Proc. of the 13th European Conference on Antennas and Propagation (EUCAP)\n5G NR Simulator\u201d, in Proc. of the 13th European Conference on Antennas and Propagation (EUCAP), 2019.\n  * [Gutierrez-Espada, J., Simsek, M., Del Rio, R., Viggiano, D., Ramos, D., &\n    Misbal, A. Sionna Scheduling for the Evolved UMTS Terrestrial Radio Access\n    Network Benchmark\u201d, IEEE Trans. Veh. Technol. 68, 66672-66755](https://nvlabs.github.io/sionna/)\n\nDiscover more in the [Sionna Gallery](https://nvlabs.github.io/sionna/api.html#galllery)."
"To add a transmitter and receiver to the scene and compute the propagation paths using Sionna, follow these steps:\n\n1. Import the necessary modules and set up the Sionna environment:\n\n```python\n# Import Sionna\nimport sionna\nfrom sionna.rt import load_scene, Transmitter, Receiver\n\n# Load the scene\nscene = load_scene(sionna.rt.scene.munich)\n\n# Set the frequency of the scene\nscene.frequency = 1.8e9\n```\n\n2. Add a transmitter to the scene:\n\n```python\n# Instantiate a Transmitter and specify its name, position, and orientation\ntx = Transmitter(name=\"tx\", position=[8.5,21,27])\ntx.orientation = [0,0,0]  # Orient the transmitter in the default orientation\n```\n\n3. Add a receiver to the scene:\n\n```python\n# Instantiate a Receiver and specify its name, position, and orientation\nrx = Receiver(name=\"rx\", position=[45,90,2])\nrx.orientation = [0,0,0]  # Orient the receiver in the default orientation\n```\n\n4. Add the transmitter and receiver to the scene:\n\n```python\n# Add the transmitter to the scene\nscene.add(tx)\n\n# Add the receiver to the scene\nscene.add(rx)\n```\n\n5. Set the antenna arrays of the transmitter and receiver:\n\n```python\n# The antenna is set to a single vertical polarized antenna with a half-power beamwidth of 65 degrees\ntx.array = sionna.rt.VerticalArray(num_rows=1, num_cols=1, spacing=0.5, pattern=\"iso\", polarization=\"V\")\nrx.array = sionna.rt.VerticalArray(num_rows=1, num_cols=1, spacing=0.5, pattern=\"iso\", polarization=\"V\")\n```\n\n6. Compute the propagation paths:\n\n```python\npaths = scene.compute_paths()\n```\n\nThe compute_paths function returns a `Paths` object that contains the computed propagation paths between all transmitters and receivers in the current scene. You can then use this `Paths` object to compute the channel impulse responses (CIRs) using the `cir` function."
"The `FastFadingChannel` class in Sionna is used to simulate wireless channels with random fading. Different functionalities of the class are implemented by using APIs from the Sionna package such as `GenerateOFDMChannel` and `ApplyOFDMChannel`, which generate and apply the channel frequency responses, respectively. Other APIs used include `GenerateTimeChannel` and `ApplyTimeChannel`, which generate and apply the channel responses in the time domain, and `CIRToOFDMChannel` and `OFDMChannelToCIR` which are used to compute the channel frequency responses from the channel impulse response (CIR) and vice versa.\n\nTo set up a model using the `FastFadingChannel` class, an instance of this class is created, with parameters including the channel model, the number of receivers, the number of receiver antennas, the number of transmitters, the number of transmitter antennas, and the temporal and/or spatial correlation model. The resulting model is then used to generate channel responses (either in the frequency or time domain) which can then be applied to the input signal.\n\nA basic example of using `FastFadingChannel` is shown in the provided context, where a sequence of channel inputs is generated, and then the channel output is computed by applying the channel model. The code snippet to set this up is as follows:\n\n```python\n# Setting up a fast fading channel model\nfast_fading_channel = sionna.channel.FastFadingChannel(\n    channel_model=\"tr38901\",\n    num_rx=1,\n    num_rx_ant=32,\n    num_tx=4,\n    num_tx_ant=2,\n    spatial_corr_model=\"scm\",\n    carrier_frequency=3.5e9,\n    duration_ns=1e-2,\n    sim_corr_time=True\n)\n\n# Generating a batch of channel responses\nh = fast_fading_channel(gen_xs)\n\n# Generating the channel output\ny = fast_fading_channel([x, h])\n```\n\nIn this code, `gen_xs` are the channel inputs, `x` is the batch of channel input sequences, and `y` is the resulting output sequence. The input sequences are generated using a binary source and a mapper, and the output sequence is computed by passing the channel inputs and the channel responses through a channel filter and a demapper."
"Here is the detailed information of LambertianPattern:  \n  \n[sionna.channel.tr38901.LambertianPattern(alpha_r=0.991, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/channel/tr38901/lambertian_pattern.html#LambertianPattern)  \n\nLambertian scattering model following [ETSI TR 138 901 V14.1.0 \u201cStudy on 3GPP channel models for IMT 2020\u201d ](https://nvlabs.github.io/sionna/channel_modeling.html#sionna.channel_model.tr38901)\n\n**Parameters**\n\n- `alpha_r` (int, [1,2,..., 30]): Parameter related to the width of the scattering lobe, default value is 30.\n- `dtype`: The data type for internal calculations and the output dtype. Specifies the complex number precision of the model, options are tf.complex64 or tf.complex128. Defaults to tf.complex64.\n\n**Input**\n\n- `batch_size` (int): Batch size\n- `num_samples` (int): Number of samples\n- `wavelengths` (float): Wavelength in meters\n- `theta_i` (float, [0, \u03c0]): Incidence angle\n- `phi_i` (float, [0,2\u03c0]): Azimuth angle of the incidence\n\n**Output**\n\n- `theta_r` (float, [batch size, num samples]): Deflection angles\n- `phi_r` (float, [batch size, num samples]): Azimuth angles of the deflection\n\nThe Lambertian model is a First Order Reflection model as defined in Section 7.2 of [ETSI TR 138 901, V14.1.0 \"Study on 3GPP channel models for IMT 2020\", \u201cLambertianModel\u201d]. The power scattered into the lobe around the specular direction is $\\alpha_r$ and the width of the lobe is $\\Delta \\phi = \\frac{2\\pi}{\\alpha_r}$. The scattered rays have a uniform angular power distribution which is independent of the deflection angle. "
"Here is the definition of DemapperWithPrior: sionna.mapping.DemapperWithPrior(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\nSource code:\n```python\nclass DemapperWithPrior(Demapper):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    DemapperWithPrior(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    Computes log-likelihood ratios (LLRs) or hard-decisions on bits\n    for a tensor of received symbols, assuming that prior knowledge on the bits is available.\n\n    This class defines a layer implementing different demapping\n    functions. All demapping functions are fully differentiable when\n    soft-decisions are computed.\n\n    This class is deprecated as the functionality has been integrated\n    into :class:`~sionna.mapping.Demapper`.\n\n    Parameters\n    ----------\n    demapping_method : One of [\"app\", \"maxlog\"], str\n        The demapping method used.\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the demapper provides hard-decided bits instead of\n        soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of ``y``. Defaults to tf.complex64. The output dtype is\n        the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    -----\n    (y, prior, no) :\n        Tuple:\n\n    y : [...,n], tf.complex\n        The received symbols.\n\n    prior : [num_bits_per_symbol] or [...n,num_bits_per_symbol], tf.float\n        Prior for every bit as LLRs.\n        It can be provided either as a tensor of shape `[num_bits_per_symbol]`\n        for the entire input batch, or as a tensor that is\n        `[..., n, num_bits_per_symbol]` and has the same batch dimensions as\n        ``y``.\n\n    no : Scalar or [...,n], tf.float\n        The noise variance estimate. It can be provided either as scalar\n        for the entire input batch or as a tensor that is `[..., n]` and has\n        the same batch dimensions as ``y``.\n\n    Output\n    ------\n    : [...,n*num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit.\n\n    Note\n    ----\n    With the \"app\" demapping method, the LLR for the :math:`i^\\text{th}` bit\n\n    .. math::\n        LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert y,\\mathbf{p}\\right)}\n                            {\\Pr\\left(b_i=0\\lvert y,\\mathbf{p}\\right)}\\right) =\n                \\ln\\left(\\frac{\n                        \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n                            \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n                        }{\n                        \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n                            \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n                        }\\right)\n\n    where :math:`\\mathcal{C}_{i,1}` and :math:`\\mathcal{C}_{i,0}` are the\n    sets of constellation points for which the :math:`i^\\text{th}` bit is\n    equal to 1 and 0, respectively.\n    The definition of the LLR has been chosen\n    such that it is equivalent with that of logits. This is\n    different from many textbooks in communications, where the LLR is\n    defined as :math:`LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}\n    {\\Pr\\left(b_i=1\\lvert y\\right)}\\right)`.\n\n    With the \"maxlog\" demapping method, LLRs for the :math:`i^\\text{th}` bit\n    are approximated like\n\n    .. math::\n        \\begin{align}\n            LLR(i) &\\approx\\ln\\left(\\frac{\n                \\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n                    \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n                }{\n                \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n                    \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n                }\\right)\\\\\n                &= \\max_{c\\in\\mathcal{C}_{i,0}}\n                    \\left(\\ln\\left(\\Pr\\left(c\\lvert\\mathbf{p}\\right)\\right)-\\frac{|y-c|^2}{N_o}\\right) -\n                 \\max_{c\\in\\mathcal{C}_{i,1}}\\left( \\ln\\left(\\Pr\\left(c\\lvert\\mathbf{p}\\right)\\right) - \\frac{|y-c|^2}{N_o}\\right)\n                .\n        \\end{align}\n    \"\"\"\n    def __init__(self,\n                 demapping_method,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(demapping_method=demapping_method,\n                         constellation_type=constellation_type,\n                         num_bits_per_symbol=num_bits_per_symbol,\n                         constellation=constellation,\n                         hard_out=hard_out,\n                         with_prior=True,\n                         dtype=dtype,\n                         **kwargs)\n```\n\n**The source code of DemapperWithPrior is above. Since the description is provided in the form of Python docstring within the function __init__, I cited the corresponding part as the description.**"
"To fully understand the `TB5GScrambler`, we need to review the class, parameters, input, output, properties, and notes.\n\n### Class: TB5GScrambler\n\nThe class implements pseudo-random bit scrambling as defined in [[3GPPTS38211_scr]][1] Sec. 6.3.1.1 for the PUSCH channel and in Sec. 7.3.1.1 for the PDSCH channel.\n\nFor inverse scrambling, the same scrambler can be re-used as the values are flipped again, resulting in the original state.\n\n### Parameters\n\n- `n_rnti`: RNTI identifier provided by higher layer. Defaults to 1 and must be in range [0, 65335]. If it's a list, every list element defines a scrambling sequence for multiple independent streams.\n- `n_id`: Scrambling ID related to cell id. Defaults to 1 and must be in range [0, 1023]. If it's a list, every list element defines a scrambling sequence for multiple independent streams.\n- `binary`: Indicates whether bit-sequence should be flipped (i.e., binary operations are performed) or the signs should be flipped (i.e., soft-value/LLR domain-based). Defaults to True.\n- `channel_type`: Can be either PUSCH or PDSCH.\n- `codeword_index`: Can be either 0 or 1. Scrambler can be configured for two codeword transmission. Defaults to 0.\n- `dtype`: Defines the datatype for internal calculations and the output dtype. Defaults to tf.float32.\n\n### Input\n\n- `(x, binary)`: Either Tuple `(x, binary)` or `x` only. `x` is a 1+D tensor of arbitrary shape. If `n_rnti` and `n_id` are a list, it is assumed that `x` has shape [,num_streams, n] where num_streams = len(n_rnti). `binary` overrules the init parameter `binary`. It indicates whether bit-sequence should be flipped (i.e., binary operations are performed) or the signs should be flipped (i.e., soft-value/LLR domain-based).\n\n### Output\n\n- `tf.float`: 1+D tensor of same shape as `x`.\n\n### Property: keep_state\n\nRequired for descrambler, is always True for the TB5GScrambler.\n\n### Property: n_id\n\nScrambling ID.\n\n### Property: n_rnti\n\nRNTI identifier.\n\n### Property: radio_network_temporary_identifier\n\nRNTI identifier provided by higher layers.\n\n### Property: state\n\nScrambling state as 1D vector of 0s and 1s.\n\nThis is a property of the descrambler required to keep it in the same state as the scrambler.\n\n### Output:  \nThe output of the scrambler is a 1+D tensor of the same shape as input `x`.\n\n[1]: \"https://nvlabs.github.io/sionna/api/fec.scrambling.html#gppts38211-scr\"  \nsource code: https://github.com/nvlabs/sionna/blob/main/sionna/fec/scrambling.py#L163"
"To encode random input bits in Sionna, you can follow these steps:\n\n1. Import the necessary modules from Sionna library.\n2. Generate the random input bits that you want to encode. The bits should be in binary format and stored in a 2-dimensional NumPy array or a TensorFlow tensor.\n3. Define the parameters for your LDPC code configuration. The parameters include the code length, the number of iterations for the belief propagation (BP) decoder, the parity-check matrix type, and whether hard-decisions or soft-decisions are returned.\n4. Create an instance of the LDPC5GEncoder class, passing the defined parameters. This instance will be used to encode the bits.\n5. Call the instance with the generated bits as the argument. The output will be the encoded bits.\n\nHere is a sample code snippet that demonstrates these steps:\n\n```python\nimport numpy as np\nimport sionna as sn\n\n# Define the parameters for the LDPC code\nk = 100  # number of information bits\nn = 200  # number of codeword bits\nnum_iter = 20  # number of iterations for BP decoder\nbptype = \"5G\"  # \"5G\" channel encoder type\nhard_out = True  # LDPC decoder output type: True for hard-decision, False for soft-decision\n\n# Create an instance of the LDPC5GEncoder class\nencoder = sn.fec.ldpc.LDPC5GEncoder(k=k, n=n)\n\n# Generate random input bits\nu = np.random.randint(2, size=(1, k)).astype(np.float32)\n\n# Encode the bits\nc = encoder(u)\n\n# Display the shape of the encoded bits and the type of the encoded bits tensor\nprint(\"Shape of c:\", c.shape)\nprint(\"Type of c:\", type(c))\n\n# If you want to use the TensorFlow backend, you can convert the array to a tensor and perform the encoding\nc_tensor = tf.convert_to_tensor(u, np.float32)\nc_encoded = encoder(c_tensor)\n\n# c_encoded will have the same shape and type as the input tensor\nprint(\"Shape of c_encoded:\", c_encoded.shape)\nprint(\"Type of c_encoded:\", type(c_encoded))\n```\n\nIn this code, k represents the number of information bits, n represents the number of codeword bits, num_iter represents the number of iterations for the BP decoder, bptype represents the channel encoder type, and hard_out represents the LDPC decoder output type. The input bits are encoded using the LDPC5GEncoder class, and the output is the encoded bits."
"The `LMMSEEqualizer` class is part of Sionna's OFDM waveforms and stream management modules. This class is used to compute linear minimum mean squared error (LMMSE) equalization for OFDM MIMO (Orthogonal Frequency-Division Multiplexing Multiple Inputs Multiple Outputs) transmissions.\n\nIn the context of OFDM waveforms, the `LMMSEEqualizer` would be used to estimate the symbols transmitted by multiple transmitters from the signals received at a receiver. This process involves creating soft-symbol estimates along with effective noise variances for all streams, which can be used to generate Log-Likelihood Ratios (LLRs) with a `Demapper`.\n\nTo use `LMMSEEqualizer`, you would initialize an instance of this class with the necessary configuration including a reference to a `ResourceGrid` (which defines the time-frequency resource allocation), and a `StreamManagement` object. You can then call the instance with the received signals `y`, the channel matrices `h`, and the noise variance `no` to get the estimated symbols `x_hat` and effective noise variances `no_eff`.\n\n```python\nlmmse_equalizer = LMMSEEqualizer(resource_grid, stream_management)\ny = ...  # received signals\nh = ...  # channel matrices\nno = ...  # noise variance\nx_hat, no_eff = lmmse_equalizer(y, h, no)\n```\n\nIn this snippet, `resource_grid` is an instance of `ResourceGrid`, and `stream_management` is an instance of `StreamManagement`. `y`, `h`, and `no` are the received signals, channel matrices, and noise variance respectively. The returned `x_hat` is the estimated symbol, and `no_eff` is the effective noise variance.\n\nThe `LMMSEEqualizer` is used in scenarios where the signals received at a receiver need to be processed to recover the original transmitted symbols and noise variances. This is commonly used in MIMO wirelesss communications where multiple transmitters and receivers are exchanging data. The `LMMSEEqualizer` is a key component in the overall system optimization processes as it helps in reducing inter-stream interference and improving the quality of signal recovery."
"To get started with Sionna, a Python package for simulating NR (5G) compliant wireless communication systems, you can follow this tutorial. The tutorial is structured into four parts, each part implemented as a Jupyter notebook:\n\n1. **Part I: Getting started with Sionna**\n\nThis part is aimed at introducing you to Sionna. It begins by showing how to `pip install` Sionna and its dependencies. Then, it demonstrates the generation of a batch of random 16QAM symbols and the visualization of an OFDM resource grid. After explaining different simulation modes in Sionna, the tutorial concludes by showing how to set up a basic link-level simulation using the `OpenLoopMIMOTransmitter` and `OpenLoopMIMODetector` components.\n\n2. **Part II: Differentiable Communication Systems**\n\nBuilding upon the basic understanding developed in Part I, this part implements a point-to-point link with a 5G NR compliant code and a 3GPP channel model. It also explains the concept of differentiable communication systems.\n\n3. **Part III: Advanced Link-level Simulations**\n\nThis part provides more in-depth knowledge about how to use Sionna for advanced link-level simulations. It describes the implementation of a state-of-the-art neural receiver, training of the end-to-end system, and the evaluation of the system. \n\n4. **Part IV: Toward Learned Receivers**\n\nThe final part continues from the advanced stage of Part III and explores the limitations and extensions of the concept of differentiable communication systems. It explains how to make sparse trainable components less greedy, how to deal with discrete variables in the optimization, and ends with a word of caution on the practical applicability of these methods.\n\nThroughout the tutorial, you will see various code examples and visualizations that explain how to use Sionna and how its components are implemented. Remember to refer to the [official documentation](https://nvlabs.github.io/sionna) for detailed instructions on how to use specific components."
"To import the necessary modules from the Sionna package, you can follow these steps:\n\n1. First, you need to import the Sionna package. If it's not already installed, the code will install it using pip.\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n2. Import the necessary modules from the Sionna package. This includes modules for various components of neural networks and communication systems, such as encoders, LDP5G, LDPC5GDecoder, AWGN channel, BinarySource, QAMSource, NeuralDemapper, and TrainableDecoder.\n\n```python\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nfrom sionna.fec.ldpc.decoding import LDPC5GDecoder\nfrom sionna.fec.polar.encoding import Polar5GEncoder\nfrom sionna.fec.polar.decoding import Polar5GDecoder\nfrom sionna.fec.scrambling import Scrambler\nfrom sionna.fec.descrambling import Descrambler\nfrom sionna.utils import BinarySource, QAMSource, ebnodb2no, hard_decisions\nfrom sionna.mapping import Mapper, Demapper, Constellation\nfrom sionna.utils.plotting import PlotBER\nfrom sionna.channel import AWGN\n```\n\n3. Import the necessary additional modules from other packages, such as `os`, `numpy`, `matplotlib.pyplot`, `tensorflow`, and `pickle`.\n\n```python\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport pickle\n```\n\nRemember to replace the module names in the imports with the correct ones for your specific use case."
"Applying the gradient to the weights using an optimizer involves the following steps:\n\n1. Compute the forward pass and the loss function: The first step is to compute the forward pass through the model and the channel. This is done using a `GradientTape` to record the operations for differentiation. The loss function is then computed using the binary cross entropy, from the predicted bits and the soft-symbols (LLRs).\n\n2. Compute the gradient: The gradient of the loss function with respect to the weights is computed using the `gradient` method of the `GradientTape`. The `watched_variables` method of the `GradientTape` returns the weights of the model, which are then used as the second argument of the `gradient` method.\n\n3. Apply the gradient: The computed gradient is then applied to the weights using the `apply_gradients` method of an optimizer. In this case, the `Adam` optimizer is used.\n\nThe complete process is performed in a loop, where each iteration corresponds to one training step. The model is first used to compute the loss and gradient, and then the gradient is applied to the weights. This process is repeated for a number of iterations until the model is trained."
"Function qam(num_bits_per_symbol, normalize=True)\n\n- [3D] (12,20,28)\n- source code:\n```python\ndef qam(num_bits_per_symbol, normalize=True):\n    # pylint: disable=line-too-long\n    r\"\"\"Generates a QAM constellation.\n\n    This function generates a complex-valued vector, where each element is\n    a constellation point of an M-ary QAM constellation. The bit\n    label of the `n` th point is given by the length-`num_bits_per_symbol`\n    binary represenation of `n`.\n\n    Input\n    -----\n    num_bits_per_symbol : int\n        The number of bits per constellation point.\n        Must be a multiple of two, e.g., 2, 4, 6, 8, etc.\n\n    normalize : bool\n        If `True`, the constellation is normalized to have unit power.\n        Defaults to `True`.\n\n    Output\n    ------\n    : [2 :math:`^\\text{num_bits_per_symbol}`]`, np.complex64\n        The QAM constellation.\n\n    Note\n    ----\n    The bit label of the nth constellation point is given by the binary\n    representation of its position within the array and can be obtained\n    through ``np.binary_repr(n, num_bits_per_symbol)``.\n\n    The normalization factor of a QAM constellation is given in\n    closed-form as\n\n    .. math::\n        \\sqrt{\\frac{1}{2^{n-2}}\\sum_{i=1}^{2^{n-1}}(2i-1)^2}\n\n    where :math:`n= \\text{num_bits_per_symbol}/2` is the number of bits\n    per dimension.\n\n    This algorithm is a recursive implementation of the expressions found in\n    Section 5.1 of [3GPPTS38211]_. It is used in the 5G standard.\n    \"\"\"\n    n = num_bits_per_symbol//2\n    base = 2\n    points = recursive_array(n, base, np.array([]), normalize)\n    return points\n```\n- `Constellation` \u2013 A :math:`2^{num_bits_per_symbol}` array of complex numbers defining the constellation points.\n- `normalize` \u2013 If `True`, the constellation is normalized to have unit power. `False` by default."
"Here is the definition of RandomInterleaver:  `class` `RandomInterleaver`(`seed=None, keep_batch_constant=True, inverse=False, keep_state=True, axis=-1, dtype=tf.float32`, `**kwargs`).\nThe source code is as follows:  \n```python\nclass RandomInterleaver(Interleaver):\n    \"\"\"RandomInterleaver(seed=None, keep_batch_constant=True, axis=-1, dtype=tf.float32, **kwargs)\n\n    Random interleaver permuting a sequence of input symbols.\n\n    The class inherits from the Keras layer class and can be used as layer in a Keras\n    model.\n\n    Parameters\n    ----------\n        seed : int\n            An integer defining the state of the random number\n            generator. Defaults to `None`.\n\n        keep_batch_constant : bool\n            Defaults to True. If set to True each sample in the batch uses the\n            same permutation. Otherwise, unique permutations per batch sample\n            are generate (slower).\n\n        inverse: bool\n            A boolean defaults to False. If True, the inverse permutation is\n            performed.\n\n        keep_state : bool\n            A boolean defaults to True. If True, the permutation is fixed for\n            multiple calls (defined by `seed` attribute).\n\n        axis : int\n            Defaults to -1. The dimension that should be interleaved. First\n            dimension (axis=0) is not allowed.\n\n        dtype : tf.DType\n            Defaults to `tf.float32`. Defines the datatype for internal\n            calculations and the output dtype.\n\n    Input\n    -----\n        (x, seed) :\n            Either Tuple ``(x, seed)`` or ``x`` only (no Tuple) if the internal\n            seed should be used:\n\n        x : [None, k], tf.DType\n            2+D tensor of arbitrary shape and dtype.\n        seed : int\n            An integer defining the state of the random number\n            generator. If explicitly given, the global internal seed is\n            replaced by this seed. Can be used the realize random\n            interleaver/deinterleaver pairs (call with same random seed).\n\n    Output\n    ------\n        : [None, k], tf.DType\n            2+D tensor of same shape and dtype as the input ``x``.\n\n    Raises\n    ------\n        AssertionError\n            If `axis` is not an int.\n\n        AssertionError\n            If `keep_batch_constant` is not bool.\n\n        AssertionError\n            If `seed` is not int.\n\n        AssertionError\n            If `keep_state` is not bool.\n\n        AssertionError\n            If `axis` > number of input dimensions.\n\n        InvalidArgumentError\n            When rank(`x`)<2.\n    \"\"\"\n    def __init__(self,\n                 seed=None,\n                 keep_batch_constant=True,\n                 inverse=False,\n                 keep_state=True,\n                 axis=-1,\n                 dtype=tf.float32,\n                 **kwargs):\n\n        super().__init__(seed=seed,\n                         keep_batch_constant=keep_batch_constant,\n                         inverse=inverse,\n                         keep_state=keep_state,\n                         axis=axis,\n                         dtype=dtype,\n                         **kwargs)\n\n    #-------------#\n    # Property  S #\n    #-------------#\n    @property\n    def seed(self):\n        \"\"\"Seed to generate random sequence.\"\"\"\n        return self._seed\n\n    #--------------------#\n    # Property Keep_state#\n    #--------------------#\n    @property\n    def keep_state(self):\n        \"\"\"Generate new random seed per call.\"\"\"\n        return True\n\n    #-----------------------#\n    # Property interleaving #\n    #-----------------------#\n    @property\n    def interleaving(self):\n        \"\"\"Return permuted indices.\"\"\"\n        if self._inverse:\n            return self._indices_deinterleaving\n        else:\n            return self._indices_interleaving\n\n    #---#\n    # S #\n    #---#\n    def s_min(self, seed):\n        \"\"\"Find S parameter such that pi(i)-pi(j)>S for all\n        i-j<S. This can be used to find optimized interleaver patterns.\n\n        s_min_stop: int\n            An additional stopping condition, i.e., stop if\n            current s_min<`s_min_stop`.\n\n        Note\n        ----\n        This is numpy utility function and usually not part of the graph.\n        \"\"\"\n        # set seed\n        if self._keep_state:\n            tf.random.set_seed(self._seed)\n        import numpy as np\n        assert isinstance(seed, int), \"seed must be int.\"\n        seed = np.mod(np.int32(seed), 2**31-1)\n        np.random.seed(seed) # set seed\n        s = np.inf # init s with infinity\n        n = int(self._input_dim[self._axis])\n        pi = np.random.permutation(n)\n        c = 0\n        while np.any(np.abs(pi-np.arange(n))>s):\n            pi = np.random.permutation(n)\n            c+=1\n            if c>1000:\n                print(\"WARNING: s_min did not converge.\")\n                break\n        s = np.max(np.abs(pi-np.arange(n)))\n        return s\n```"
"Here is the detailed information of pam: [sionna.mapping.pam(num_bits_per_symbol, normalize=True)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#pam)  \n  \nPulse amplitude modulation (PAM) constellation for neural processing.\n\nThis class generates a PAM constellation with an average energy of 0.The PAM constellation is built through the recursive calculation of the Cartesian product of a 2-point PAM constellation. This is implemented as a recursive function to allow the generation of constellations with a large number of bits.\n\n**Parameters**\n\n- `num_bits_per_symbol` (int): The number of bits per constellation point. Must be a multiple of 2 and greater than 0.\n- `normalize` (bool): If `True`, the constellation is normalized to have unit power. Defaults to `True`.\n\n**Output**\n\n- `[2**num_bits_per_symbol]`, `np.float32`: The PAM constellation.\n\nsource code:\n```python\ndef pam(num_bits_per_symbol, normalize=True):\n    r\"\"\"\n    PAM constellation for neural processing.\n    Average energy is 0.\n\n    This class generates a PAM constellation with an average energy of 0.\n    The PAM constellation is built through the recursive calculation of the\n    Cartesian product of a 2-point PAM constellation. This is implemented as\n    a recursive function to allow the generation of constellations with a large\n    number of bits.\n\n    Parameters\n    ----------\n    num_bits_per_symbol : int\n        The number of bits per constellation point. Must be a multiple of 2 and\n        greater than 0.\n\n    normalize : bool\n        If `True`, the constellation is normalized to have unit power.\n        Defaults to `True`.\n\n    Output\n    ------\n    : [2**num_bits_per_symbol], np.float32\n        The PAM constellation.\n\n    \"\"\"\n    assert (num_bits_per_symbol%2 == 0), \"num_bits_per_symbol must be a multiple of 2.\"\n    assert num_bits_per_symbol > 0, \"num_bits_per_symbol must be positive.\"\n\n    n = num_bits_per_symbol//2\n    constellation = np.array([-1.0, 1.0], np.complex64)\n\n    if n > 1:\n        y = pam(n, False)\n        y = np.expand_dims(y, axis=1)\n        constellation = np.tensordot(constellation, y, axes=([],[1]),)\n    constellation = np.reshape(constellation, ([-1]))\n    if normalize:\n        energy = np.sum(np.abs(constellation)**2)\n        constellation = constellation / np.sqrt(energy)\n    return constellation\n```"
"The `return_crc_status` parameter in the `Polar5GDecoder` class of Sionna's Polar library is a `bool` type that defaults to `False`. When it is set to `True`, the decoder will return a `tf.bool` type along with the decoded information bits indicating if the codeword has passed the CRC check. This is useful for scenarios where the CRC check is necessary for further processing or to discard codewords with detected errors.\n\nThe `output_dtype` parameter defines the output data type of the decoder's llr (log-likelihood ratio) calculation. The decoder internally performs calculations in `tf.float32`, but the output can be specified to be `tf.float16`, `tf.float32`, or `tf.float64` using this parameter. This can be advantageous in scenarios where a trade-off between decoding accuracy and computational complexity is necessary, as different precision levels might offer different performance characteristics."
"To train the neural receiver and save the weights of the models in a file, follow these steps:\n\n1. Set a seed for reproducibility and define the number of training iterations.\n\n2. Instantiate the end-to-end model for training. This model is an OFDM system with a neural receiver. The `training` parameter is set to `True` to enable training mode.\n\n3. Define the Adam optimizer for use in training. The `learning_rate` can be specified, but it's not provided in the context.\n\n4. Enter a training loop of `NUM_TRAINING_ITERATIONS` iterations. At each iteration:\n   - Sample a batch of SNRs ($E_b/N_0$) for the training process.\n   - Perform a forward pass through the model within a gradient tape. The loss is computed during the forward pass.\n   - Compute the gradients using the gradient tape and apply them using the Adam optimizer.\n   - Update a progress bar to track the training progress.\n\n5. If the iteration number is a multiple of 100, print the current progress. The loss indicates the error during the training process.\n\n6. After training, save the weights of the model in a file. The weights are obtained using the `get_weights()` method of the model, and then the weights are saved in a file using `pickle.dump()`.\n\nRemember to ensure that the model and the training data are properly set up and defined before starting the training loop. The context does not provide the code for setting up the model and the training data."
"Here are some useful links of \"Part 1: Getting Started with Sionna\" in tutorials.\n\n[Colab Tutorial: Part 1](https://colab.research.google.com/github/nvlabs/sionna/blob/main/examples/Sionna_tutorial_part1.ipynb)\n\n[Colab Tutorial: Part 2](https://colab.research.google.com/github/nvlabs/sionna/blob/main/examples/Sionna_tutorial_part2.ipynb)\n\n[Colab Tutorial: Part 3](https://colab.research.google.com/github/nvlabs/sionna/blob/main/examples/Sionna_tutorial_part3.ipynb)\n\n[Colab Tutorial: Part 4](https://colab.research.google.com/github/nvlabs/sionna/blob/main/examples/Sionna_tutorial_part4.ipynb)\n  "
"To run throughput tests in Graph Mode using the Sionna Python package, you would follow these steps:\n\n1. Import the necessary packages and configure your environment. This includes importing the Sionna package, setting up your GPU configuration, and setting the random seed for reproducibility.\n\n2. Define your model or function for which you want to measure the throughput. The model should take a batch size and an SNR value as inputs, perform some computation, and return the results.\n\n3. Call the model in eager mode to ensure that it is compiled before the throughput test. This will also give you an initial idea of the throughput.\n\n4. Define a function to measure the throughput. This function should take the model, a batch size, an SNR value, and the number of repetitions as inputs, and return the average throughput over the specified number of runs.\n\n5. In eager mode, call the model with the specified batch size and SNR value to get an estimate of the throughput.\n\n6. Define a function for the graph mode. This function should be decorated with @tf.function to enable graph mode execution. The function should take the same inputs as your model.\n\n7. Call the function in graph mode with the specified batch size and SNR value to get the estimated throughput.\n\n8. Disable the sionna.config.xla_compat feature after measuring the graph mode throughput, as this can affect the results of the graph mode execution.\n\n9. Compare the throughput of the eager and graph modes to understand the performance difference.\n\nNote: The provided context includes code that uses a specific SNR value and batch size to measure the throughput of a model in both eager and graph modes. The performance is then evaluated by calculating the average time taken for the model to run in each mode over multiple repetitions. Please ensure that the appropriate Sionna features and TensorFlow functions are used in your implementation."
"For the demonstration, I'll first import the necessary submodules from the Sionna package. Then, I'll show two ways to instantiate a convolutional code encoder using the `ConvEncoder` class from those submodules.\n\nHere's the first way, using the `rate` and `constraint_length` parameters:\n\n```python\nfrom sionna.fec.conv import ConvEncoder\n\n# Set the rate and constraint length\nrate = 1/2\nconstraint_length = 3\n\n# Create a convolutional encoder instance\nencoder_1 = ConvEncoder(rate=rate, constraint_length=constraint_length)\n```\n\nIn this first method, I've set `rate` to 1/2 to indicate a rate-1/2 code, and `constraint_length` to 3 to indicate a constraint length of 3. I then created a `ConvEncoder` instance, passing `rate` and `constraint_length` as parameters.\n\nNow, for the second way of instantiating, let's use the `gen_poly` parameter. The `gen_poly` parameter represents the generator polynomial for the convolutional encoder. In the rate-1/2, constraint-length-3 code, there are multiple possible generator polynomials. One common example is the octal string '05', which corresponds to the polynomial $1 + D^1 + D^2$ (where $D^1$ and $D^2$ are the delay operator powers).\n\nHere's how you can create an instance with the `gen_poly` parameter:\n\n```python\n# Using the gen_poly directly\ngen_poly = ('05', '07')  # Octal strings for the generator polynomial\nencoder_2 = ConvEncoder(gen_poly=gen_poly)\n```\n\nIn this method, I passed the generator polynomial directly as a tuple of strings. The first string '05' is the initial polynomial, and the second '07' is the second polynomial. Please note that the generator polynomial '05' is just an example, there are many other valid rate-1/2, constraint-length-3 polynomials. When you select a polynomial, you need to convert it to octal format.\n\nLastly, let me mention that the `gen_poly` should be selected carefully for the given specifications, ensuring termination of the encoder and, if required, recursive properties of the code. The choice of `gen_poly` may affect the coderate, latency, and system performance."
"The RMa (Rural Macrocell) channel model in the Sionna library is used to simulate wireless communication in open, rural areas. It is particularly suitable for modeling the coverage of large basestations (BS) and the interaction with user terminals (UT) equipped with line-of-sight (LoS) and non-line-of-sight (NLoS) propagation modes.\n\nPrinciples:\n\n- The RMa model is based on the principles established by the 3rd Generation Partnership Project (3GPP), which maintains specifications for international mobile telecommunications standards. \n- The model takes into account the specific arrangement of UTs and BSs, including the panel arrays used at each side. \n- It generates channel impulse responses (CIRs) at the UT locations, which can be used to build channel responses in either time or frequency domain. \n- It incorporates capabilities for considering both line-of-sight (LoS) and non-line-of-sight (NLoS) propagation modes, as well as different types of antenna polarization. \n\nParameters:\n\n- `carrier_frequency`: Frequency in Hertz.\n- `ut_array` and `bs_array`: Panel arrays used by the UTs and BSs, respectively. \n- `direction`: Specifies whether the 'uplink' or 'downlink' link direction is considered. \n- `enable_pathloss`: If `True`, enables pathloss. \n- `enable_shadow_fading`: If `True`, enables shadow fading. \n- `always_generate_lsp`: If `True`, always generates large scale parameters (LSPs). \n- `dtype`: Defines the datatype for internal calculations and the output dtype.\n\nSetting up the network topology:\n\nThe network topology is set up by configuring the UTs and BSs locations, velocities, the states (indoor/outdoor), and the orientation of their panel arrays. This is done using the `set_topology()` method. The network topology can be set differently for each batch example.\n\nInput parameters for `set_topology()`:\n\n- `ut_loc`: UTs locations \n- `bs_loc`: BSs locations\n- `ut_orientations`: UTs array orientations\n- `bs_orientations`:  BSs array orientations\n- `ut_velocities`: UTs velocities\n- `in_state`: Indoor/outdoor states of UTs\n\nOutput from `set_topology()`:\n\nThe output is the configured network topology. When a network topology has been set up, the network topology is returned."
"The `Trellis` structure is implemented in the `sionna.fec.conv.utils` module and is used to define a Trellis for a given generator polynomial in convolutional coding. The Trellis structure defines the state transitions and the output symbols (or bits) for each current state and input.\n\nThe `Trellis` structure can be configured using the `gen_poly` and `rsc` parameters:\n\n1. `gen_poly`: A generator polynomial represented as a tuple of strings, with each string being a 0 or 1 sequence. For example, `gen_poly` = (`111`, `101`, `011`) would represent a generator matrix of size $\\frac{1}{n}$ if `rsc` = <cite>True</cite>. An important note is that if `gen_poly` is set to <cite>None</cite>, then the `rate` and `constraint_length` parameters must be provided.\n\n2. `rsc`: A boolean flag indicating whether the Trellis is recursive systematic or not. If the `rsc` parameter is set to <cite>True</cite>, then the first polynomial in `gen_poly` is used as the feedback polynomial. In the example provided, when `rsc` = <cite>True</cite> and `gen_poly` = (`111`, `101`, `011`), the generator matrix is understood to be $G(D)=[\\frac{1+D^2}{1+D+D^2}, \\frac{D+D^2}{1+D+D^2}]$. It's recommended to set `rsc` to <cite>True</cite> when configuring the `Trellis` structure, unless a specific use case requires otherwise.\n\nRemember that the generator polynomial represents the polynomial bits for the connections from the shift registers to the output bits, and the recursive systematic property indicates whether the encoder is designed to be efficient in the case it is used for encoding information in the forward direction through a communication channel."
"Here is the detailed information of CarrierConfig:   \n  \n[sionna.nr.CarrierConfig(**kwargs**)](https://nvlabs.github.io/sionna/_modules/sionna/nr/carrier_config.html#CarrierConfig)  \n\nThe CarrierConfig objects sets parameters for a specific OFDM numerology, as described in Section 4 3GPP TS 38.211. All configurable properties can be provided as keyword arguments during the initialization or changed later.\n\n**Example**\n\n```python\ncarrier_config = CarrierConfig(n_cell_id=41)\ncarrier_config.subcarrier_spacing = 30\n```\n\n**Properties**\n\n- `cyclic_prefix`: Cyclic prefix length. The options `normal` or `extended` are available for the `cyclic_prefix` property, with `normal` being the default. The `extended` option is only possible with a `subcarrier_spacing` of 60 kHz.\n- `cyclic_prefix_length`: Cyclic prefix length, read-only.\n- `frame_duration`: Duration of a frame, read-only.\n- `frame_number`: System frame number, read-only.\n- `kappa`: Constant \u03ba, read-only.\n- `mu`: Subcarrier spacing configuration, where \u03bc is the index of the numerology to be used. Possible values are between 0 and 6. The property `subcarrier_spacing` is dependent on this parameter.\n- `n_cell_id`: Physical layer cell identity. Possible values are between 0 and 1007.\n- `n_size_grid`: Number of resource blocks in the carrier resource grid. Possible values are between 1 and 275.\n- `n_start_grid`: Start of resource grid relative to common resource block (CRB) 0.\n- `num_slots_per_frame`: Number of slots per frame. This can be either 10 or 20.\n- `num_slots_per_subframe`: Number of slots per subframe. This can be any power of 2 between 1 and 64.\n- `num_symbols_per_slot`: Number of OFDM symbols per slot.\n- `slot_number`: Slot number within a frame.\n- `sub_frame_duration`: Duration of a subframe.\n- `subcarrier_spacing`: Subcarrier spacing.\n\n**Methods**\n\n- `check_config()`: Tests if the parameters of the carrier configuration are valid."
"1. Definition of Receiver in Sionna: sionna.Receiver(rev_fsch, name='receiver')\n\n2. The source code of sionna.Receiver is [sionna.Receiver](https://nvlabs.github.io/sionna/_modules/sionna/receiver.html#Receiver). \n\nHere is the explanation of the class: This layer implements a full receiver that computes either soft-symbols or hard-decisions for a user's terminal (UT) or base station (eNodeB) equipped with multiple antenna. The layer uses as input the post-equalized received symbols and computes either log-likelihood ratios (LLRs) or hard-decisions on the bits.\n\nThe class inherits from the Keras layer class and can be used as layer in a Keras model. \n\nThe parameters of the class are:\n- **rev_fsch** (str): Receiver full-name, i.e. \"rx_iet_llr\"\uff0c \"rx_awgn\"\uff0c \"rx_ustug\"\uff0c \"rx_mimo\".\n- **name** (str): Layer name\n- **\\*args, \\*\\*kwargs** (additional arguments): Additional arguments for the base class (e.g. dtype, **kwargs). \n\nThe parameters that are passed to the receiver are learned. \n\nThe class defines several properties, such as the parameter `receiver_name`, `receiver` , `receiver_actual`, `num_ant`, `return_effective_csi`, `rev_fsch`, `soft_out`, `swap_streams`, and methods like `demapping_method`, `compute_desired`, `call`, `sample_noise_cov`, `compute_llr`, `applying_desired`, `applying_weights`, and `stream_management`."
"The `ResourceGrid` in the Sionna Python package is a key component used for OFDM-based transmissions. Its purpose is to define how data and pilot symbols are mapped onto a sequence of OFDM symbols with a specific FFT size. This mapping is crucial for effectively utilizing the OFDM modulation waveform for wireless transmissions.\n\nThe `ResourceGrid` is used to define a two-dimensional grid spanned across OFDM symbols and subcarriers. Its structure is identified by four key parameters: `num_ofdm_symbols`, `fft_size`, `subcarrier_spacing`, and `num_tx`. The grid indicates how data and pilot symbols are mapped onto this grid in both the frequency and time domains.\n\nKey usage components of the `ResourceGrid` include:\n\n- Mapping of pilot symbols onto the `ResourceGrid`: This is performed using the `pilot_pattern` parameter of the `ResourceGrid`.\n- Mapping of zero-padded data-carrying QAM/PSK symbols onto the `ResourceGrid`: This is performed using the `data_pattern` parameter of the `ResourceGrid`.\n- Iterative water-filling: The `ResourceGrid` is used to perform iterative water-filling to find the optimal power allocation to the data and pilot carriers in a multi-cell MIMO setup.\n\nIn practice, the `ResourceGrid` is used along with other components like `PilotPattern`, `OFDMModulator`, and `OFDMDemodulator` to simulate and process OFDM-based transmissions. The `ResourceGrid` and these components play a crucial role in helping generate and process OFDM waveforms for wireless communications."
"To generate a batch of frequency responses, the 'channel_model' object (which is an instance of a channel model such as `RayleighBlockFading` or `TDL`) is paired with an instance of `ResourceGrid`, which serves as the OFDM resource grid. \n\nAn instance of `GenerateOFDMChannel` is then created, with the channel model and the resource grid as parameters. This instance generates channel frequency responses based on the input channel model and resource grid. The channel model is used to generate channel impulse responses (CIRs) with the `__call__()` method, and then the CIRs are converted to channel frequency responses (h) using the `fft_size` and `subcarrier_spacing` from the resource grid.\n\nThe resulting frequency responses (`h_freq`) have a shape determined by the parameters specified for the resource grid, which include the batch size, number of receivers, number of receive antennas, number of transmitters, number of transmit antennas, number of OFDM symbols, and number of subcarriers. \n\nThe symbols are then transmitted over the channel in the `BasebandOFDMChannel` layer by providing the required input parameters, which include a tuple containing the frequency responses and the noise variance. \n\nRemember that the actual code to generate the frequency responses would need to be written with the specific parameters for the given use case. The parameters depend on the scenario (e.g., line-of-sight, non-line-of-sight) and the characteristics of the transmitters (number and types of antennas, their shapes and orientations, etc.) and receivers (number and types of antennas, their locations, etc.)."
"To configure transmitters and receivers for computing propagation paths in Sionna RT, you need to follow these steps:\n\n1. Configure the antenna arrays for all transmitters and receivers. This is done using the `PlanarArray` class. You specify the number of rows, number of columns, vertical and horizontal spacing, pattern and polarization for the array. \n\n2. Create a transmitter. This is done using the `Transmitter` class. You specify the name of the transmitter, its position and the angles defining its orientation (yaw, pitch, and roll).\n\n3. Add the transmitter to the scene using the `add` method of the `Scene` class.\n\n4. Create a receiver. This is done using the `Receiver` class. You specify the name of the receiver, its position, and the same orientation as the transmitter.\n\n5. Add the receiver to the scene.\n\n6. Set the property `synthetic_array` of the scene to `True`. This tells Sionna RT to use a synthetic array for the transmitters and receivers, which is typically faster than simulating each individual antenna.\n\n7. Set the `frequency` of the scene. This is done implicitly by setting the `frequency` property of the scene. This property will be applied to all the RadioMaterials of the scene objects.\n\nPlease note that the code provided in the context is specific to Sionna RT and may not work with other ray tracing libraries. Also, the positions and orientations of the transmitters and receivers are specified in the 3D space, so they can be placed at any arbitrary position."
"The `SymbolDemapperWithPrior` class is part of the `sionna.mapping` module and is used for computing normalized log-probabilities or hard-decisions on symbols for a tensor of received symbols, assuming that prior knowledge on the constellation points is available. It is deprecated as its functionality has been integrated into the `SymbolDemapper`.\n\nThe `SymbolDemapperWithPrior` class defines a deprecated symbol demapper with the prior for the Symbol demapping. A constellation object or its parameters can be given which enables the constellation to be set. The class also has the provision to set the `hard_out` parameter which when set to `True`, provides hard-decided symbols instead of soft-values.\n\nThe input to the `SymbolDemapperWithPrior` class consists of a tuple `(y, prior, no)` where:\n - `y` is of type `[,n]`, `tf.complex`, and is the received symbols.\n - `prior` is of type `[num_points]` or `[,num_points]`, `tf.float`, and is the prior for every symbol as log-probabilities (logits). It can be provided either as a tensor of shape `[num_points]` for the entire input batch, or as a tensor that is broadcastable to `[, n, num_points]`.\n - `no` is a scalar or of type `[,n]`, `tf.float`, and is the noise variance estimate. It can be provided either as a scalar for the entire input batch or as a tensor that is broadcastable to `y`.\n\nThe class outputs a tensor of shape `[,n, num_points]` of logits for every constellation point if `hard_out` is set to `False`. Otherwise, it outputs a tensor of shape `[,n]` of hard-decisions on the symbols.\n\nThe normalized log-probability for the constellation point `c` is computed using the log of the expression obtained by summing the probabilities of all constellation points being equal to `c`, given the received signal `y`, the prior knowledge on `c`, and the noise variance `no`."
"To enable diffuse reflections and observe their impact on the coverage map, you need to set the `allow_diffraction` parameter to `True` when calling the `coverage_map()` function. \n\nThis function computes the coverage map, which describes the average received power from a specific transmitter at every point on a plane. The effects of fast fading, i.e., constructive/destructive interference between different paths, are averaged out by summing the squared amplitudes of all paths. \n\n```python\ncm = scene.coverage_map(cm_cell_size=[1,1], num_samples=20e6, max_depth=5, allow_diffraction=True)\n```\n\nEnabling diffuse reflections can increase the number of paths and improve the accuracy of the coverage map, particularly in complex scenes with many scattering surfaces. Diffuse reflections occur when a ray hits a surface and then gets scattered into a random direction. This scattering can significantly contribute to the propagation of the signal, especially in indoor or urban environments with many walls and obstacles."
"To compute the mean-squared error (MSE) between the transmitted and recovered symbols, you can follow these steps:\n\n1. First, you need to subtract the transmitted symbols from the recovered symbols. This can be done using the numpy array subtraction operation. The transmitted symbols are represented by the array `x` and the recovered symbols are represented by the array `x_hat`. The result of this operation is an array representing the error between the transmitted and recovered symbols.\n\n2. Next, you need to compute the power of the error. This can be done using the `np.abs` (absolute) and `np.square` (square) operations on the error array. The `np.abs` operation computes the absolute value of each element in the array, and the `np.square` operation computes the square of each element. The result of these operations is the power of the error.\n\n3. Finally, you can compute the MSE by taking the mean of the power of the error. This can be done using the `np.mean` operation on the power array. The `np.mean` operation by default computes the arithmetic mean of a list of numbers, which is the same as the MSE.\n\nHere is the code from the context that demonstrates these steps:\n\n```python\nplt.figure()\nplt.scatter(np.real(x_hat), np.imag(x_hat));\nplt.scatter(np.real(x), np.imag(x));\nplt.legend([\"Transmitted\", \"Received\"]);\nplt.title(\"Scatter plot of the transmitted and received QAM symbols\")\nprint(\"MSE between x and x_hat (dB)\", 10*np.log10(np.var(x-x_hat)))\n```\n\nIn this code, `np.real(x_hat)` and `np.imag(x_hat)` represent the real and imaginary parts of the array `x_hat` respectively. The `np.var(x-x_hat)` operation computes the power of the error, and the `10*np.log10` operation computes the logarithm (base 10) of the power, which is the MSE in decibels."
"The 'create_or_check_constellation' method in the Constellation class is a static method that is used to conviently create a constellation object or to verify that an existing constellation object is appropriate for the current settings. \n\nThere are three parameters that this method can receive:\n\n1. constellation_type: This is a string representing the type of constellation. It can be one of \"qam\", \"pam\", or \"custom\". For the \"custom\" type, an instance of Constellation must be provided.\n\n2. num_bits_per_symbol: This is an integer that represents the number of bits per constellation symbol, e.g., 4 for QAM16. It is required only for the constellation types \"qam\" and \"pam\".\n\n3. constellation: This is an instance of the Constellation class. It should be set to `None` for creating a new constellation object. \n\nIn case a constellation is requested of type \"qam\" or \"pam\", the method will create a constellation object of the specified type with the given number of bits per symbol. Otherwise, for type \"custom\", it will create a constellation object using the provided instance, which is an object of the class sionna.mapping.Constellation. \n\nIf an existing constellation object is supplied as `constellation`, the method will check that this object's type and bit configuration match the inputs. If they don't match, an AssertionError is raised. Otherwise, the method returns the existing constellation object. \n\nThis function is useful for applying consistency checks and for ensuring that the constellation is created in a flexible and convenient manner."
"The `scat_keep_prob` argument is part of the ray tracing process in Sionna, specifically in the context of computing scattered paths with the `compute_paths()` method of a `Scene` object. This method can generate a large number of possible paths for radio propagation, especially when scattering is taken into account.\n\nScattering is a radio propagation phenomenon where radio waves are redirected into various directions when they hit a surface. This is different from reflection, where waves maintain a consistent angle of incidence and excitation. \n\nThe `scat_keep_prob` argument is a parameter that controls the number of scattered paths to keep after generating a large number of possible paths. Since the process of generating paths can be computationally expensive, the Sionna API includes a mechanism to filter out and retain only the most relevant scattered paths, those most likely to significantly impact the radio propagation characteristics of the environment being modeled.\n\nThe argument `scat_keep_prob` accepts a probability value between 0 and 1. When paths are computed, those that are scattered but considered less likely to be important are randomly dropped, in proportion to this probability. This allows the ray tracing process to focus on retaining only the most significant paths, as judged by the defined probability of retention.\n\nDropping a higher proportion of less significant scattered paths can help scale down the total number of paths considered for computation, making the process more manageable in terms of computational resources, without significantly compromising the quality of the results. The trade-off is that a higher `scat_keep_prob` could potentially lead to missing important paths that have significant impacts on the propagation modeling. Therefore, the choice of an appropriate `scat_keep_prob` requires a balance between the acceptable level of simplification in the modeling process and the need for computational accuracy in representing the real-world physics of radio propagation."
"Here is the detailed information of function sionna.rt.r_hat: [sionna.rt.r_hat(theta_s, phi_s, theta_t, phi_t)](https://nvlabs.github.io/sionna/_modules/sionna/rt/utils.html#r_hat)\n\nComputes the \\( \\hat{\\mathbf{r}} \\) unit vector [Equation](https://nvlabs.github.io/sionna/em_primer.html#equation-spherical-vec)\n\n**Input**\n\n- `theta_s` (arbitrary shape, tf.float): Zenith angles \\(\\theta_s\\) of the desired direction.\n- `phi_s` (arbitrary shape, tf.float): Azimuth angles \\(\\varphi_s\\) of the desired direction.\n- `theta_t` (arbitrary shape, tf.float): Zenith angles \\(\\theta_t\\) of the desired direction.\n- `phi_t` (arbitrary shape, tf.float): Azimuth angles \\(\\varphi_t\\) of the desired direction.\n\n**Output**\n\n- `r_hat` ([(...,3], tf.float)): A unit vector that points from a transimitter to a receiver. If the inputs are scalars, the output is a vector of length three."
"Here is the detailed information of OFDMDetectorWithPrior:   \n[sionna.ofdm.OFDMDetectorWithPrior(detector, output, resource_grid, stream_management, constellation_type, num_bits_per_symbol, constellation=None, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#OFDMDetectorWithPrior)  \n\nLayer that wraps a MIMO detector for use with the OFDM waveform assuming prior knowledge of the bits or constellation points is available.\n\nThe parameter detector is a callable (e.g., a function) that implements a MIMO detection algorithm with prior for arbitrary batch dimensions.\n\nThis class pre-processes the received resource grid y and the channel estimation h_hat, and computes for each receiver the noise-plus-interference covariance matrix according to the OFDM and stream configuration provided by the resource_grid and stream_management, which also accounts for the channel estimation error variance err_var. These quantities serve as input to the detection algorithm that is implemented by detector. Both detection of symbols or bits with either soft- or hard-decisions are supported.\n\n**Note**\nThe callable detector must take as input a tuple (y,h_hat,s,err_var) such that:\n\n- y ([batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex): Received OFDM resource grid after cyclic prefix removal and FFT\n- h_hat ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex): Channel estimates for all streams from all transmitters\n- s ([batch_size, num_rx, num_rx_ant, num_rx, num_streams_per_rx, num_ofdm_symbols, num_effective_subcarriers], tf.complex): Prior information of the transmitted signal, provided as LLRs for the transmitted bits or logits for the constellation points\n- err_var (tf.float): Variance of the channel estimation error\n\nIt must generate one of the following outputs:\n\n- [batch_size, num_tx, num_streams, num_data_symbols], tf.float: LLRs or hard-decisions for every bit of every stream, if output equals \"bit\".\n- [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int: Logits or hard-decisions for constellation symbols for every stream, if output equals \"symbol\". Hard-decisions correspond to the symbol indices.\n\n**Parameters**\n\n- `detector` (Callable): Callable object that implements a MIMO detection algorithm with prior for arbitrary batch dimensions. Existing detectors like `MaximumLikelihoodDetectorWithPrior` can be used, or a custom detector callable provided that has the same input/output specification.\n- `output` (str): Type of output, either \"bit\" for bits or \"symbol\" for symbols.\n- `resource_grid` (ResourceGrid): Instance of ResourceGrid.\n- `stream_management` (StreamManagement): Instance of StreamManagement.\n- `constellation_type` (str): Constellation type, one of \"qam\", \"pam\", or \"custom\". For \"custom\", an instance of Constellation is provided.\n- `num_bits_per_symbol` (int): Number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation types \"qam\" or \"pam\".\n- `constellation` (Constellation or None): Instance of Constellation or None. In the latter case, `constellation_type` and `num_bits_per_symbol` must be provided.\n- `dtype` (tf.Dtype): The datatype for internal calculations and the output dtype. Defaults to tf.complex64. Especially for large MIMO setups, you might want to use tf.complex128 to avoid inaccuracies in the computed LLRs. However, this comes at the cost of performance."
"Here is the detailed information of GaussianPriorSource:   \nSource code:  \n```python\nclass GaussianPriorSource(nn.Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"GaussianPriorSource()\n\n    Layer generating the priors for a BP decoder as Gaussian distributed.\n\n    As only the messages to the variable nodes are considered in the\n    Gaussian distributed initialization the input value should be twice\n    the value as the expected LLR value.\n\n    The generated priors have a variance of ``prior_to_llr_var``.\n\n    Input\n    -----\n    : None (dummy argument), optional\n\n    Output\n    ------\n    : tf.float\n        Tensor of shape (`x`, `k`). Here, `k` is the number of prior\n        probabilities per codeword and `x` the number of codewords.\n    \"\"\"\n    def __init__(self, **kwargs):\n        super().__init__(kwargs)\n        self.prior_to_llr_var = 0.5 # dummy value; not used\n    def call(self, input):\n        mean = tf.cast(0.0, input.dtype)\n        input = tf.expand_dims(input, -1)\n        # reduce memory consumption by implicit broadcast\n        x = tf.cast(tf.range(0, input.shape[-1]), input.dtype)\n        x = tf.expand_dims(x, 0)\n        x = tf.broadcast_to(x, tf.shape(input))\n        input = tf.expand_dims(input, -1)\n        mean = tf.expand_dims(mean, 0)\n        mean = tf.broadcast_to(mean, tf.shape(input))\n        result = tf.pow((tf.cast(2, input.dtype)*x - input), -2) * tf.exp(tf.pow((x - mean), 2)/(-2*input))\n        result = tf.clip_by_value(result, 1e-8, 1.0)\n        return result\n```\n  \nThe GaussianPriorSource class is used as a Keras layer. It initializes a Gaussian distribution with a given variance and mean. \nParameters:  \n- `prior_to_llr_var`: A float value that indicates the total variance of the prior as given to the decoder. Defaults to 0.5, which is a typical value for LDPC message passing decoding. \nInput:  \n- `input`: This layer takes a dummy argument, which is ignored. \nOutput:  \n- Returns a 1+D tensor of the shape (x, k), indicating the number of codewords x and the number of prior probabilities per codeword k.\n\nCommon errors:   \nThis class does not directly generate Gaussian-distributed priors for a BP decoder. It is recommended to use the `GaussianPriorSource` class that implements the interface `PriorSource` to generate the initial values for the Gaussian distributed BP decoder. \n\nNote: the class is part of the Sionna package (v1.8.0) and the package should be installed in the local environment where this code is used.\n  "
"Here is the detailed information of QAM2PAM:   \n  \nClass **QAM2PAM(num_bits_per_symbol)** \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#QAM2PAM)\n```python\n    class QAM2PAM:\n        \"\"\"\n        QAM2PAM(num_bits_per_symbol)\n        Transforms QAM symbol indices to PAM symbol indices.\n\n        For indices in a QAM constellation, computes the corresponding indices\n        for the two PAM constellations corresponding the real and imaginary\n        components of the QAM constellation.\n\n        Parameters\n        ----------\n        num_bits_per_symbol : int\n            The number of bits per QAM constellation symbol, e.g., 4 for QAM16.\n\n        Input\n        -----\n        ind_qam : Tensor, tf.int\n            Indices in the QAM constellation\n\n        Output\n        -------\n        ind_pam1 : Tensor, tf.int\n            Indices for the first component of the corresponding PAM modulation\n\n        ind_pam2 : Tensor, tf.int\n            Indices for the first component of the corresponding PAM modulation\n        \"\"\"\n        def __init__(self, num_bits_per_symbol):\n            self.num_bits_per_symbol = num_bits_per_symbol\n            self._assert_type()\n\n            assert self.num_bits_per_symbol%2==0, \\\n                \"num_bits_per_symbol must be even\"\n            self.num_QAM_symbols = 2**self.num_bits_per_symbol\n\n            self._compute_base_indices()\n            self._compute_indices_add()\n            self._compute_indices_sub()\n\n        def __call__(self, ind_qam):\n            ind_pam1 = tf.gather(self.ind_pam1, ind_qam)\n            ind_pam2 = tf.gather(self.ind_pam2, ind_qam)\n            return ind_pam1, ind_pam2\n\n        def _assert_type(self):\n            \"\"\"\n            Asserts that num_bits_per_symbol is int\n            \"\"\"\n            assert isinstance(self.num_bits_per_symbol, int), \\\n                \"num_bits_per_symbol must be int.\"\n\n        def _compute_base_indices(self):\n            \"\"\"\n            Computes the symbol indices for the base QAM symbols, i.e.,\n            the indices as if the two PAM constellations are joint to form the QAM.\n            \"\"\"\n            base_symbols = sn.mapping.Constellation(\"qam\", self.num_bits_per_symbol).points\n            base_symbols = tf.constant(base_symbols, tf.float32)\n            ind_pam1 = tf.zeros(self.num_QAM_symbols//2, tf.int32)\n            ind_pam2 = tf.zeros(self.num_QAM_symbols//2, tf.int32)\n            for i in range(self.num_QAM_symbols//2):\n                ind_pam1 = tf.tensor_scatter_update(ind_pam1, i, [0, 1, 2, 3])\n                ind_pam2 = tf.tensor_scatter_update(ind_pam2, i, [0, 2, 1, 3])\n            self.ind_pam1 = ind_pam1\n            self.ind_pam2 = ind_pam2\n\n        def _compute_indices_add(self):\n            \"\"\"\n            Computes the symbol indices for the the addition of two PAM constellation.\n            \"\"\"\n            add_indices = tf.add(tf.expand_dims(self.ind_pam1, -1), self.ind_pam2)\n            add_indices = sn.utils.mod(add_indices, self.num_QAM_symbols)\n            add_indices = tf.reshape(add_indices, [-1])\n            self.ind_pam_add = add_indices\n\n        def _compute_indices_sub(self):\n            \"\"\"\n            Computes the symbol indices for the the substraction of two PAM constellation.\n            \"\"\"\n            sub_indices = tf.subtract(tf.expand_dims(self.ind_pam1, -1), self.ind_pam2)\n            sub_indices = sn.utils.mod(sub_indices, self.num_QAM_symbols)\n            sub_indices = tf.reshape(sub_indices, [-1])\n            self.ind_pam_sub = sub_indices\n        ```\n```"
"To load the required Sionna components, you need to import the Sionna package and the necessary components from it. Here's how you do it:\n\n1. First, you try to import the Sionna package. If it's not already installed, you handle the `ImportError` by installing the Sionna package using pip and then import it:\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n2. Next, you import other necessary components from the Sionna package. These components include modules like `sionna.channel`, `sionna.nr`, `sionna.utils`, `sionna.mimo`, `sionna.ofdm`, `sionna.mapping`, `sionna.mgmt`, and `sionna.fec`, and functions like `read_matlab_weights` and `compute_ber`. \n\n```python\nfrom sionna.channel import AWGN, RayleighBlockFading, gen_single_sector_topology\nfrom sionna.nr import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver\nfrom sionna.utils import compute_ber, ebnodb2no, sim_ber\nfrom sionna.mimo import TDDConfig, generate_rmc\nfrom sionna.ofdm import ResourceGrid, LSChannelEstimator, LMMSEDetector\nfrom sionna.mapping import Mapper, Demapper, Constellation\nfrom sionna.mgmt import ManagementClient, e2e_snr\nfrom sionna.fec import LDPC5GEncoder, LDPC5GDecoder\nfrom sionna.utils import binary2int\n```\n\n3. You also need to set the logging level for Sionna, so you set a 'WARNING' level for the 'tensorflow' logger:\n\n```python\nimport tensorflow as tf\ntf.get_logger('tensorflow').setLevel('WARNING')\n```\n\nRemember, the Sionna package must be installed before you can import these components. If it's not installed, you can handle the `ImportError` by installing the package using pip."
"To import the necessary modules for Sionna's API and set up the GPU configuration, you can follow these steps:\n\n1. First, you need to import the necessary modules. This includes modules like `tensorflow` and `sionna` for the API setup, and modules like `matplotlib`, `numpy`, `pickle`, `time`, and `os` for general data handling and visualization.\n\nHere is the code snippet from the context that shows how to do this:\n\n```python\nimport tensorflow as tf\nimport sionna\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pickle\nimport time\nimport os\n```\n\n2. The next step is to set up the GPU configuration. This is done using the `tf.config.experimental.set_memory_growth` method from TensorFlow. The `tf.config.list_physical_devices('GPU')` method is used to list physical devices available for TensorFlow, and the `tf.config.experimental.set_memory_growth` method is used to enable memory growth for the selected GPUs. If the user specifies a GPU to use, the `tf.config.experimental.set_memory_growth` method is called with the specified GPU and the `True` argument, which enables memory growth.\n\nHere is the code snippet from the context that shows how to do this:\n\n```python\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\ntf.config.experimental.set_memory_growth(gpus[0], True)\n```\n\n3. The last step is to avoid warnings from TensorFlow. This is done by setting the TensorFlow logger level to 'ERROR' using `tf.get_logger().setLevel('ERROR')`.\n\nIn conclusion, to import the necessary modules for Sionna's API and set up the GPU configuration, you can follow the steps outlined in the context."
"The `CoverageMap` is a component of ray tracing in Sionna. It is used to visualize the signal strength and path loss across a specific area of a scene. The coverage map can be generated for a specific transmitter or cell, showing the signal strength at every point within the area.\n\nNotably, coverage maps are not time-dependent; they represent a static signal distribution. The parameters that can be adjusted when creating a coverage map include the cell size, the center of the coverage map, the level at which to sample the ray tracing scene, and various options to customize the rendering.\n\nIn Sionna's ray tracing module, coverage maps are implemented as methods of the paths computed by the `compute_paths()` function of the scene. When paths are computed, the coverage map can be generated based on those paths using the `coverage_map()` method.\n\nHere's a basic example of generating a coverage map in Sionna:\n```python\nfrom sionna.rt import Scene\n\n# Load an example scene\nscene = Scene.load(sionna.rt.scene.munich)\n\n# Set a transmitter in the scene\nscene.tx = \"ue_1\"\n\n# Compute paths for the transmitter\npaths = scene.compute_paths()\n\n# Generate a coverage map\ncoverage_map = scene.coverage_map()\n\n# Preview the coverage map\ncoverage_map.preview()\n```\nThis code first loads an established scene, sets a transmitter in the scene, computes the paths, and then generates the coverage map. The coverage map is finally visualized with the `preview()` function.\n\nIt's important to note that coverage maps also play a role in dynamic network simulations where they are used to position transmitters and study the impact of propagation phenomena on network dynamics."
"Input requirements for using TurboDecoder in Sionna:\n\nTo use the `TurboDecoder` in Sionna, import the appropriate class from the `sionna.fec.turbo.decoding` module, either by specifying the generator polynomials directly or by using an instance of `TurboEncoder`:\n\n```python\nfrom sionna.fec.turbo.decoding import TurboDecoder\n```\n\nThen, create an instance of the `TurboDecoder`, providing the necessary configuration, including the `gen_poly` specifying the generator polynomials and the constraint `constraint_length`. If the encoder is desired to be terminated, use the `terminate` parameter.\n\nInput for decoding:\n\nThe input log-likelihood ratios (LLRs) for decoding with `TurboDecoder` are a 2+D tensor `llr` containing the channel LLRs of the transmitted bits. The LLRs are interpreted as a float32 type. The shape of `llr` is `[,n]`, where `n` is the codeword length.\n\nUsing the decoder:\n\nInstantiate the `TurboDecoder` with the necessary parameters:\n\n- `gen_poly`: A tuple of strings with each string being a 0 or 1 sequence. If `None`, `rate` and `constraint_length` must be provided.\n- `rate`: The rate of the Turbo code. It is used to derive the code's generator polynomials if `gen_poly` is `None`. Valid values are 1/3 and 1/2.\n- `constraint_length`: The constraint length of the encoder. It is used to derive the generator polynomials. Valid values are between 3 and 6 inclusive.\n- `input_type`: Specifies the input type. For decoding, it is typically 'llr'.\n- `output_type`: Specifies the output type. Valid output types are currently only 'bit'.\n- `terminate`: Indicates if the encoder is terminated. If True, the constituent convolutional encoders are assumed to be in the all-zero state at the end of the codeword.\n\nCreate an instance of the `TurboDecoder` with the necessary parameters:\n\n```python\ndecoder = TurboDecoder(gen_poly=gen_poly, # Assuming gen_poly is a tuple with valid strings\n                        rate=rate, \n                        constraint_length=constraint_length,\n                        terminate=terminate)\n```\n\nTo decode, call the decoder instance on your LLR tensor `llr`:\n\n```python\ndecoded_bits = decoder(llr)\n```\n\nOutput format for hard decision:\n\nThe output from the decoder is a 2+D tensor `decoded_bits` containing the estimates of the information bit tensor. The output data type is 'bit', i.e., `tf.int32`. The shape of `decoded_bits` is `[,k]`, corresponding to the number of input columns `k` specified by the parameter `k`.\n\nOutput format for soft decision:\n\nFor soft-output (i.e., returning LLRs), you would use the 'llr' output type. The LLR tensor `decoded_bits` would have the same shape and dimensions as the input LLR tensor `llr`, but the values would be updated based on the decoding process and output type specified.\n\nNote: In practice, to obtain hard decisions from soft-decoded bits, you would threshold the LLRs (e.g., `decoded_bits = tf.where(decoded_bits>=0, 1, 0)`) or use the corresponding Sionna API `TurboDecoderHD` for obtaining hard decisions directly."
"Here is the detailed information of sionna.rt.antenna.iso_pattern: \n\n[sionna.rt.antenna.iso_pattern(theta, phi, slant_angle=0.0, polarization_model=2, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/rt/antenna.html#iso_pattern)\n\nIsotropic antenna pattern with linear polarizarion\n\nInput\n\ntheta (array_like, float) \u2013 Zenith angles wrapped within [0, \u03c0] [rad]\n\nphi (array_like, float) \u2013 Azimuth angles wrapped within [-\u03c0, \u03c0) [rad]\n\nslant_angle (float) \u2013 Slant angle of the linear polarization [rad]. A slant angle of zero means vertical polarization. Defaults to 0.\n\npolarization_model (int, one of [1,2]) \u2013 Polarization model to be used. Options 1 [1] and 2 [2], refer to polarization_model_1() and polarization_model_2(), respectively. Defaults to 2.\n\ndtype (tf.complex64 or tf.complex128) \u2013 Datatype. Defaults to tf.complex64.\n\nOutput\n\nc_theta (array_like, complex) \u2013 Zenith pattern\n\nc_phi (array_like, complex) \u2013 Azimuth pattern\n\nsource code:\n```python\ndef iso_pattern(theta, phi, slant_angle=0.0,\n                polarization_model=2, dtype=tf.complex64):\n    r\"\"\"\n    Isotropic antenna pattern with linear polarizarion\n\n    Input\n    -----\n    theta : array_like, float\n        Zenith angles wrapped within [0,pi] [rad]\n\n    phi : array_like, float\n        Azimuth angles wrapped within [-pi, pi) [rad]\n\n    slant_angle : float\n        Slant angle of the linear polarization [rad].\n        A slant angle of zero means vertical polarization.\n        Defaults to 0.\n\n    polarization_model : int, one of [1,2]\n        Polarization model to be used. Options :func:`~sionna.rt.antenna.polarization_model_1`\n        `[1]` and :func:`~sionna.rt.antenna.polarization_model_2` `[2]`,\n        Defaults to 2.\n\n    dtype : tf.complex64 or tf.complex128\n        Datatype. Defaults to tf.complex64.\n\n    Output\n    ------\n    c_theta : array_like, complex\n        Zenith pattern\n\n    c_phi : array_like, complex\n        Azimuth pattern\n    \"\"\"\n    rdtype = dtype.real_dtype\n    k = tf.cast(tf.sqrt(1/2), dtype)\n    theta = tf.cast(theta, rdtype)\n    phi = tf.cast(phi, rdtype)\n    slant_angle = tf.cast(slant_angle, rdtype)\n    if polarization_model == 1:\n        c_theta = k*tf.ones_like(theta)\n        c_phi = k*tf.exp(-1j*phi)\n    elif polarization_model == 2:\n        x = tf.sqrt(1 + tf.tan(slant_angle)**2 * tf.cos(2*phi)**2)\n        c_theta = k*x*tf.exp(-1j*theta)*tf.cos(phi)\n        c_phi = -k*x*tf.exp(-1j*theta)*tf.sin(phi)\n\n    return c_theta, c_phi\n```"
"In order to demonstrate the correct usage of the \"ApplyTimeChannel\" and \"ApplyOFDMChannel\" Keras layers, as indicated in the provided context, we would need to establish a simulation or example that makes use of these respective layers. Since the context does not provide specific examples or simulations for each of these layers individually, I will illustrate the correct usage of these layers based on a hypothetical model assuming I have the required information about the model. \n\nFirst, I will need to setup a \"single-tap\" channel model in the time domain. This can be done using the 'WSS' model from the context, which assumes we have a water reflection coefficient and a time-variant channel impulse response generator. We can set this up as follows:\n\n```python\n# Setting up the channel model\nchannel_model = WSS(model, carrier_frequency, delay_spread, utr_velocity,\n                    min_speed=0., max_speed=None, num_rx_ant=1, num_tx_ant=1,\n                    rx_corr=True, tx_corr=True, stateless=False, dtype=dt)\n# Activating the channel impulse response logging\na = ChannelModel(channel_model, ideal_delay_vector, dtype=dt, timesteps= timesteps, log_h=True)\n```\n\nWhere `model` is the wireless propagation model (like 'A', 'B', 'C', etc.), `carrier_frequency` is the carrier frequency in Hz, `delay_spread` is the RMS delay spread, `utr_velocity` is the speed of the receiver, `timesteps` is the number of time steps, and `ideal_delay_vector` is a vector of perfect-impulse responses.\n\nNext, I will demonstrate the correct usage of the \"ApplyTimeChannel\" layer. This layer applies the time domain channel signal to the channel input. The inputs to this layer would be the channel input `x`, which is a tensor of the input symbols, and the noise power `no`.\n\n```python\napply_time_channel = ApplyTimeChannel(num_time_samples=timestep, \n                                       l_tot=delay_spread,\n                                       add_awgn=True, \n                                       normalize_channel=True)\ny = apply_time_channel([x, no])  # where x is the channel input and no is the noise power\n```\n\nThe output `y` is the channel output, of shape [batch size, num_rx, num_ant, num_path, num_time_sample].\n\nFinally, I will demonstrate the correct usage of the \"ApplyOFDMChannel\" layer. This layer applies the channel frequency response to the OFDM channel input. The inputs to this layer would be the channel input in the frequency domain `x_fft`, the noise power `no`, and the FFT size `fft_size`.\n\n```python\napply_ofdm_channel = ApplyOFDMChannel(fft_size=, l_tot=delay_spread, add_awgn=True)\nh_freq = tf.tile(h_time, [1, num_ofdm_symbols, 1, 1, 1])\ny = apply_ofdm_channel([x, h_freq, no])  # where x is the channel input and no is the noise power\n```\n\nThe output `y` is the channel output, of shape [batch size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size].\n\nPlease note that in the demonstrations above, the parameters like `timestep`, `delay_spread`, `num_ofdm_symbols`, `x`, `no`, etc. should be defined or provided accordingly. Also, this is a hypothetical demonstration and the actual usage may vary depending on the specific requirements of the model or simulation."
"To compute the log-likelihood ratios (LLRs) with the Demapper class from the Sionna library, you need to follow these steps:\n\n1. **Input LLRs with Prior Knowledge (Optional)**: Pass the received symbols and the LLRs as inputs to the Demapper class. If you have prior knowledge on the bits, pass it as additional input. The input should be either a tuple of `(y, prior, no)` or just `(y, no)` where:\n   - `y` is the received symbols.\n   - `prior` is the prior knowledge on the bits as log probabilities. This is optional and can be either of the shape `([batch_size, num_bits]` or just `num_bits`).\n   - `no` is the noise variance estimate. It can be either a scalar or of any shape that can be broadcasted to the shape of `y`.\n\n2. **Select Demapping Method**: Choose one of the two demapping methods available, which are \"app\" and \"maxlog\". You can do this by setting the `demapping_method` parameter when creating an instance of the Demapper class.\n\n3. **Create the Demapper Object**: Instantiate the Demapper class by providing the constellation and the demapping method selected. The constellation must be specified unless you've set `constellation_type` and `num_bits_per_symbol`.\n\n```python\ndemapping_method = \"app\"  # Set this to the desired demapping method (\"app\" or \"maxlog\")\nconstellation_type = \"qam\" # Set this to the constellation type (\"qam\", \"pam\", or \"custom\")\nnum_bits_per_symbol = 4 # Set this to the number of bits per constellation symbol, e.g., 4 for QAM16\ndemapper = Demapper(demapping_method, constellation_type=constellation_type, num_bits_per_symbol=num_bits_per_symbol)\n```\n\n4. **Invoke the Demapper**: Pass the tuple with the inputs to the Demapper object to get the log-likelihoods.\n\n5. **Output**: The output is an array of shape `([batch_size, num_bits]` or just `num_bits`), which contains the log-likelihoods for each bit.\n\nRemember that the Demapper class in Sionna is designed to provide soft-decisions, but if you need hard-deicions instead, you can set the `hard_out` parameter to True when instantiating the Demapper class."
"To obtain the Channel Impulse Responses (CIRs) in the model, you need to first generate the continuous-time channel impulse response (CIR) using the `cdl` function, and then convert this to a discrete-time channel impulse response using the `cir_to_time_channel` function.\n\n1. Generate the continuous-time channel impulse response:\n\n```python\na, tau = cdl(batch_size=2, num_time_steps=rg.num_time_samples+l_tot-1, sampling_frequency=rg.bandwidth)\n```\n\nIn this line of code, `a` is the complex gain and `tau` is the delay for each path. The `cdl` function generates CIRs according to the 3GPP 38.901 specification.\n\n2. Convert the continuous-time channel impulse response to discrete-time:\n\n```python\na, tau = cir_to_time_channel(a, tau, rg.bandwidth, l_tot-1, l_min)\n```\n\nThis line of code samples the CIR at the Nyquist rate and truncates the CIR to the specified length, depending on the delay spread. `l_min` and `l_max` are the truncation limits, and `l_tot` is the total length of the CIR.\n\nThe CIRs can then be used to compute the channel responses between the transmitter and receiver antennas, which can be used for various purposes such as signal transmission, reception, and processing."
"Here is the detailed information of List2LLRSimple:   \n  \n[sionna.mimo.List2LLRSimple(num_bits_per_symbol, llr_clip_val=20.0, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mimo/utils.html#List2LLRSimple)\n\nComputes LLRs from a list of candidate vectors (or paths) provided by a MIMO detector.\n\nThe following channel model is assumed:\n\n$$\n\\bar{\\mathbf{y}} = \\mathbf{R}\\bar{\\mathbf{x}} + \\bar{\\mathbf{n}}\n$$\n\nwhere $\\bar{\\mathbf{y}}\\in\\mathbb{C}^S$ are the channel outputs,\n$\\mathbf{R}\\in\\mathbb{C}^{S\\times S}$ is an upper-triangular matrix,\n$\\bar{\\mathbf{x}}\\in\\mathbb{C}^S$ is the transmitted vector whose entries\nare uniformly and independently drawn from the constellation $\\mathcal{C}$,\nand $\\bar{\\mathbf{n}}\\in\\mathbb{C}^S$ is white noise with\n$\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\bar{\\mathbf{n}}^{\\mathsf{H}}\\right]=\\mathbf{I}$.\n\nIt is assumed that a MIMO detector such as KBestDetector produces $K$ candidate solutions $\\bar{\\mathbf{x}}_k\\in\\mathcal{C}^S$\nand their associated distance metrics $d_k=\\lVert \\bar{\\mathbf{y}} - \\mathbf{R}\\bar{\\mathbf{x}}_k \\rVert^2$\nfor $k=1,\\dots,K$. This layer can also be used with the real-valued representation of the channel.\n\nThe LLR for the $i\\text{th}$ bit of the $k\\text{th}$ stream is computed as\n\n$$\n\\begin{align}\n    LLR(k,i) &= \\log\\left(\\frac{\\Pr(b_{k,i}=1|\\bar{\\mathbf{y}},\\mathbf{R})}{\\Pr(b_{k,i}=0|\\bar{\\mathbf{y}},\\mathbf{R})}\\right)\\\\\n        &\\approx \\min_{j \\in  \\mathcal{C}_{k,i,0}}d_j - \\min_{j \\in  \\mathcal{C}_{k,i,1}}d_j\n\\end{align}\n$$\n\nwhere $\\mathcal{C}_{k,i,1}$ and $\\mathcal{C}_{k,i,0}$ are the set of indices\nin the list of candidates for which the $i\\text{th}$ bit of the $k\\text{th}$\nstream is equal to 1 and 0, respectively. The LLRs are clipped to $\\pm LLR_\\text{clip}$\nwhich can be configured through the parameter llr_clip_val.\n\nIf $\\mathcal{C}_{k,i,0}$ is empty, $LLR(k,i)=LLR_\\text{clip}$;\nif $\\mathcal{C}_{k,i,1}$ is empty, $LLR(k,i)=-LLR_\\text{clip}$.\n\n**Parameters**\n\n- `num_bits_per_symbol` (int): Number of bits per constellation symbol.\n- `llr_clip_val` (float): The absolute values of LLRs are clipped to this value. Defaults to 20.0. Can also be a trainable variable.\n\n**Input**\n\n- `(y, r, dists, path_inds, path_syms)` \u2013 Tuple:\n  - `y` ([..., num_receive_ant], tf.complex or tf.float): Channel outputs of the whitened channel.\n  - `r` ([..., num_receive_ant, num_streams, num_streams], same dtype as `y): Upper triangular channel matrix of the whitened channel.\n  - `dists` ([..., num_paths], tf.float): Distance metric for each path (or candidate).\n  - `path_inds` ([..., num_paths, num_streams], tf.int32): Symbol indices for every stream of every path (or candidate).\n  - `path_syms` ([..., num_path, num_streams], same dtype as `y`): Constellation symbol for every stream of every path (or candidate).\n\n**Output**\n\n- `llr` ([..., num_streams, num_bits_per_symbol], tf.float): LLRs for all bits of every stream."
"Here is the definition of the MaximumLikelihoodDetector: sionna.ofdm.MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\nThe source code link of [sionna.ofdm.MaximumLikelihoodDetector](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#MaximumLikelihoodDetector) is provided.\n\n```python\nclass MaximumLikelihoodDetector(OFDMDetector):\n    # pylint: disable=line-too-long\n    r\"\"\"MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    Maximum-likelihood (ML) detection for OFDM MIMO transmissions.\n\n    This layer implements maximum-likelihood (ML) detection\n    for OFDM MIMO transmissions. Both ML detection of symbols or bits with\n    either soft- or hard-decisions are supported. The OFDM and stream\n    configuration are provided by a :class:`~sionna.ofdm.ResourceGrid` and\n    :class:`~sionna.mimo.StreamManagement` instance, respectively. The\n    actual detector is an instance of :class:`~sionna.mimo.MaximumLikelihoodDetector`.\n\n    Parameters\n    ----------\n    output : One of [\"bit\", \"symbol\"], str\n        Type of output, either bits or symbols. Whether soft- or\n        hard-decisions are returned can be configured with the\n        ``hard_out`` flag.\n\n    demapping_method : One of [\"app\", \"maxlog\"], str\n        Demapping method used\n\n    resource_grid : ResourceGrid\n        Resource grid\n\n    stream_management : StreamManagement\n        Stream management\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        Constellation instance or None.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the detector computes hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of `y`. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    ------\n    (y, h_hat, err_var, no) :\n        Tuple:\n\n    y : [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex\n        Received OFDM resource grid after cyclic prefix removal and FFT\n\n    h_hat : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex\n        Channel estimates for all streams from all transmitters\n\n    err_var : [Broadcastable to shape of ``h_hat``], tf.float\n        Variance of the channel estimation error\n\n    no : [batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float\n        Variance of the AWGN noise\n\n    Output\n    ------\n    One of:\n\n    : [batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream if ``output`` equals `\"bit\"`.\n\n    : [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int\n        Logits or hard-decisions for constellation symbols for every stream\n        if ``output`` equals `\"symbol\"`.\n        Hard-decisions correspond to the symbol indices.\n    \"\"\"\n    def __init__(self,\n                 output,\n                 demapping_method,\n                 resource_grid,\n                 stream_management,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(   output=output,\n                            demapping_method=demapping_method,\n                            resource_grid=resource_grid,\n                            stream_management=stream_management,\n                            constellation_type=constellation_type,\n                            num_bits_per_symbol=num_bits_per_symbol,\n                            constellation=constellation,\n                            detector=MaximumLikelihoodDetector_,\n                            hard_out=hard_out,\n                            dtype=dtype,\n                            **kwargs)\n```demapping_method``` is the demapping method used. It can be either \"app\" or \"maxlog\". \"app\" represents the demapping method with approximate log-likelihood ratios, while \"maxlog\" represents the demapping method with a maximum logarithmic approach, which maximizes the probability of correct detection. The default demapping method is \"app\". \n\nThe ```output``` parameter specifies the type of output, which can be either \"bit\" or \"symbol\". If `True`, the detector computes hard-decided bit values or constellation point indices instead of soft-values. The default is \"bit\".\n\nThe ```resource_grid``` and ```stream_management``` parameters are instances of `ResourceGrid` and `StreamManagement` respectively, which are used to configure the OFDM and stream settings. The  `ResourceGrid` defines the OFDM symbol duration and cyclic prefix length, guard length, and the mapping of data, pilots, and unused carriers. The `StreamManagement` determines the association between transmitters, transmitters, streams, and the number of streams per transmitter. \n\nThe ```constellation_type``` parameter specifies the type of constellation, which can be either \"qam\", \"pam\", or \"custom\". For \"custom\" constellation type, an instance of `Constellation` must be provided.\n\nThe ```num_bits_per_symbol``` parameter specifies the number of bits per constellation symbol, e.g., 4 for QAM16. The ``constellation`` parameter can be directly provided, in which case ``constellation_type`` and ``num_bits_per_symbol`` are ignored.\n\nThe MaximumLikelihoodDetector_ is the actual Maximum Likelihood detector used. It is configured with the given parameters and is used to perform the detection."
"Here is the detailed information of generate_5g_ranking: \n\nThe function `generate_5g_ranking` tries all codeword permutations (i.e,  it generates all possible subcodes and test them)  and keep the best `how_many` codewords candidates in terms of expected decoding time. The LDPC 5G encoding layer is evaluated by simulating random messages, and computing the expected variable node (VN) and check node (CN) decoding operation complexities. The resulting list is an instantiation of `LDPC5GEncoder` class for all the best codeword candidates.\n\nInput: \n\n   - k (int) \u2013 Number of information bits per codeword.\n   - n (int) \u2013 Desired codeword length.\n   - how_many (int) \u2013 How many of the best candidates are returned. Consider that the output list is not sorted.\n   - num_threads (int) \u2013 Number of threads to use.\n   - use_5g_window (bool) \u2013 If true, it uses the bounding from 5G standard to compute the expected CN decoding complexity.\n \nOutput: The output list is not necessarily sorted by expected decoding time. The list is limited to the `how_many` best candidates.\n   - [encoder, n, k, codeword_length, num_coded_bits, num_uncoded_bits, num_edges, max_cnx_degree, max_vn_deg, ie_vn, tcm, time_vn, time_cn, (ex_cn, var_cn) or just (ex_cn) \u2013 LDPC encoder layer, i.e., an instance of `LDPC5GEncoder`, if `ex_cn` and `var_cn` are requested, respectively.](https://nvlabs.github.io/sionna/api/fec.ldpc.encoding.html#sionna.fec.ldpc.encoding.generate_5g_ranking)\n\nsource code: [generate_5g_ranking](https://nvlabs.github.io/sionna/_modules/sionna/fec/ldpc/encoding.html#generate_5g_ranking)  \n   \"\"\"."
"Running the channel modeling in Sionna involves several steps:\n\n1. **Importing necessary libraries and modules**: This includes importing Sionna, TensorFlow, and other necessary Python libraries and modules. For Sionna, you would use an import statement like this:\n\n   ```python\n   import sionna\n   ```\n\n2. **Setting up the environment**: This includes setting up the GPU environment if you are using a GPU, and setting the random seed for reproducibility.\n\n3. **Defining the channel model**: Sionna supports various 3GPP channel models including CDL, TDL, UMi, UMa, and RMa models. You would define the model using appropriate parameters, like this:\n\n   ```python\n   CDL = sionna.channel.tr38901.CDL(CDL_MODEL,\n                                    DELAY_SPREAD,\n                                    CARRIER_FREQUENCY,\n                                    UT_ARRAY,\n                                    BS_ARRAY,\n                                    DIRECTION,\n                                    min_speed=SPEED)\n   ```\n\n   Here, `CDL_MODEL` is the specific CDL model (like \"A\", \"B\", \"C\", etc.), `DELAY_SPREAD` is the nominal delay spread, `CARRIER_FREQUENCY` is the carrier frequency, `UT_ARRAY` is the antenna array configuration at the user terminal (UT), `BS_ARRAY` is the antenna array configuration at the base station (BS), `DIRECTION` specifies the link direction, and `SPEED` is the speed of the user terminal.\n\n4. **Generating batch of channel impulse responses (CIRs)**: This involves calling the channel model with the necessary parameters to generate a batch of CIRs. The size of the batch can be specified in the call. The CIRs consist of complex gains (`a`) and delays (`tau`) for each path.\n\n   ```python\n   a, tau = CDL(batch_size=BATCH_SIZE,\n                num_time_steps=RESOURCE_GRID.num_ofdm_symbols,\n                sampling_frequency=1/RESOURCE_GRID.ofdm_symbol_duration)\n   ```\n\n5. **Applying the channel model to the input signal**: This involves using the complex gains and delays obtained from the previous step to apply the channel model to the input signal. Sionna provides several different types of channels, including frequency-selective channels, flat-fading channels, and multiple-input multiple-output (MIMO) channels. Depending on the specific type of channel you are using, you would apply the channel model to the input signal in different ways.\n\n6. **Evaluating the performance**: This involves evaluating the performance of the channel model, which can include measuring the bit error rate (BER) or block error rate (BLER) for a specific link or network model.\n\nRemember that the code snippets provided in the context, including the ones defining the channel models and generating the batch of CIRs, are just examples. You would need to adjust the parameters and the code to fit your specific use case."
"Alleged source code:\nsource code: def load_alist(path):\n    r\"\"\"Read `alist`-file [MacKay]_ and return nested list describing the\n    parity-check matrix of a code.\n\n    Many code examples can be found in [UniKL]_.\n\n    Input\n    -----\n    path: str\n        Path to file to be loaded\n\n    Output\n    ------\n    alist: list\n        A nested list containing the imported alist data.\n    \"\"\"\n\n    with open(path, 'r') as f:\n        content = f.read().splitlines()\n\n    h = []\n    for i, line in enumerate(content):\n        if line[0:4] ==\"c \":\n            break\n        else:\n            h.append(list(map(int, line.split())))\n\n    return h\n    "
"[3GPP Specifications](https://nvlabs.github.io/sionna/api/nr.html#3gpp-specifications)\n\n[3GPP TSG RAN \u201cStudy on channel model for frequencies from 0.5 to 100 GHz\u201d, TR 38.901, \u201cAnnex A\u201d, Version 16.1.0, 2020-07.](https://nvlabs.github.io/sionna/api/nr.html#3gpp-specifications)\n\n[3GPP TSG RAN \u201cStudy on channel model for frequencies from 0.5 to 100 GHz\u201d, TR 38.901, \u201cAnnex B\u201d, Version 16.1.0, 2020-07.](https://nvlabs.github.io/sionna/api/nr.html#3gpp-specifications)\n\n[3GPP TSG RAN \u201cEnhanced outdoor-to-indoor propagation loss models in dense urban environments\u201d, TR 38.901, \u201cAnnex D\u201d, Version 16.1.0, 2020-07.](https://nvlabs.github.io/sionna/api/nr.html#3gpp-specifications)\n\n[3GPP TSG RAN \u201cEvolved Universal Terrestrial Radio Access (EUTRA); Base Station (BS) conformance testing\u201d, TS 36.141, \u201cSection 7\u201d, Version 14.0.0, 2017-03.](https://nvlabs.github.io/sionna/api/nr.html#3gpp-specifications)\n\n[3GPP TSG RAN \u201cNew dual uplink MIMO for LTE\u201d, TS 36.141, \u201cSection 5.1\u201d, Version 12.3.0, 2016-03.](https://nvlabs.github.io/sionna/api/nr.html#3gpp-specifications)\n\n[3GPP TSG RAN \u201c3rd Generation Partnership Project; Technical Specification Group Radio Access Network; Study on MIMO for UMTS system\u201d, TR 25.843, \u201cSection 5.1.3.2\u201d, Version 6.2.0, 2006-03.](https://nvlabs.github.io/sionna/api/nr.html#3gpp-specifications)\n\n[3GPP TSG RAN \u201cSpatial Channel Model for Multiple Input Multiple Output (MIMO) Simulations\u201d, TR 25.996, \u201cSection 7.1\u201d, Version 8.0.0, 2009-12.](https://nvlabs.github.io/sionna/api/nr.html#3gpp-specifications)\n\n[3GPP TSG RAN \u201cFurther advancements for E-UTRA\u201d, TS 36.913, \u201cSection 4.3.1\u201d, Version 10.3.0, 2016-03.](https://nvlabs.github.io/sionna/api/nr.html#3gpp-specifications)\n\n[3GPP TSG RAN \u201cPhysical layer aspects for co-operative multi-point operation in cellular networks\u201d, TS 36.589, \u201cSection 6.1.2\u201d, Version 1.2.0, 2011-07.](https://nvlabs.github.io/sionna/api/nr.html#3gpp-specifications)\n\n[3GPP TSG RAN \u201cScenarios (non-limiting) for IMT Advanced systems\u201d, TR 38.913, \u201cSection 4.1\u201d, Version 14.0.0, 2020-07.](https://nvlabs.github.io/sionna/api/nr.html#3gpp-specifications)\n\n[3GPP TSG RAN \u201cEvaluation methodology for IMT Advanced systems\u201d, TR 37.876, \u201cSection 7.1.3\u201d, Version 12.0.0, 2012-06.](https://nvlabs.github.io/sionna/api/nr.html#3gpp-specifications)\n\n[3GPP TSG RAN \u201cUser Equipment (UE) conformance tests Part 3: RRM & Radio conformance Part 1\u201d, TS 36.523, \u201cSection 5.4.2.1\u201d, Version 14.3.0, 2017-12.](https://nvlabs.github.io/sionna/api/nr.html#3gpp-specifications)\n\n[3GPP TSG RAN \u201cBase Station (BS) conformance tests Part 1: Protocol (PHY) conformance testing\u201d, TS 37.141, \u201cSection 6.3.1\u201d, Version 14.0.0, 2017-03.](https://nvlabs.github.io/sionna/api/nr.html#3gpp-specifications)\n\n[OpenStreetMap](https://nvlabs.github.io/sionna/api/nr.html#openstreetmap)\n\n[Sionna \u201cRay Tracing Tutorial\u201d, Section \u201cLoad a scene\u201d, Version 2021-09-01](https://nvlabs.github.io/sionna/api/nr.html#rt_tutorial_load_scene)"
"The Scene's `cameras` property is a dictionary that contains all the available cameras for the specific scene. Cameras are essential for defining the visualization and rendering of scenes in the context of Sionna's ray tracing package.\n\nA camera is uniquely identified by either its name (as a string) or by an instance of the `Camera` class. In the case of multiple cameras with the same name, it is also possible to identify the camera by an integer index.\n\nCameras can either be predefined and part of the scene's data, or instantiated and added to the scene programmatically. Whether loaded from a scene file or added to the scene, the cameras typically have associated parameters such as position, orientation, viewport, and clipping planes that can be adjusted to manipulate the view of the scene.\n\nThe `cameras` property is crucial for accurately rendering the scene. When rendering the scene into an image or a file, each camera's viewpoint and settings can potentially yield a different but equally important perspective. This flexibility allows for multiple viewpoints of a scene to be rendered either sequentially or in parallel.\n\nIt's important to note that the `cameras` dictionary is not directly set as an attribute of the Scene class, but it is introduced in the documentation within the context of Scene definition and manipulation. The dictionary is meant to represent the variety of camera instances available in a scene environment. These can include perspectives, as well as orthographic and direct light cameras. \n\nThe `cameras` property is typically accessed either during scene setup or when the scene is loaded for editing or rendering. Its content cannot be accessed outside of the initialization or loading function of a scene. Furthermore, changes to the `cameras` property within a script or application won't be applied or saved to the original scene file."
"Here is the detailed information of RaisedCosineFilter:   \n  \n[sionna.signal.RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/signal/filter.html#RaisedCosineFilter)  \n\nLayer for applying a raised-cosine filter of length K to an input x of length N.\n\nThe filter length K is equal to the filter\u2019s span in symbols (span_in_symbols) multiplied by the oversampling factor (samples_per_symbol). If this product is even, a value of one will be added.\n\nThe filter is applied through discrete convolution.\n\nAn optional windowing function window can be applied to the filter.\n\nThe dtype of the output is tf.float if both x and the filter coefficients have dtype tf.float. Otherwise, the dtype of the output is tf.complex.\n\nThree padding modes are available for applying the filter:\n- \u201cfull\u201d (default): Returns the convolution at each point of overlap between x and the filter. The length of the output is N + K - 1. Zero-padding of the input x is performed to process the edges of the signal.\n- \u201csame\u201d: Returns an output of the same length as the input x. The convolution is computed such that the coefficients of the input x are centered on the coefficient of the filter with index (K-1)/2. Zero-padding of the input signal is performed to process the edges of the signal.\n- \u201cvalid\u201d: Returns the convolution only at points where x and the filter completely overlap. The length of the output is N - K + 1.\n\n### Parameters\n\n- `span_in_symbols` (int): Filter span as measured by the number of symbols.\n- `samples_per_symbol` (int): Number of samples per symbol, i.e., the oversampling factor.\n- `beta` (float): Roll-off factor. Must be in the range $[0,1]$.\n- `window` (Window or string [\"hann\", \"hamming\", \"blackman\"]): Instance of Window applied to the filter coefficients or a string indicating the window name. Custom windows must be provided as an instance.\n- `normalize` (bool): If True, the filter is normalized to have unit power. Defaults to True.\n- `trainable` (bool): If True, the filter coefficients are trainable variables. Defaults to False.\n- `dtype` (tf.DType): The dtype of the filter coefficients. Defaults to tf.float32.\n\n### Input\n\n- `x` ([..., N], tf.complex or tf.float): The input to which the filter is applied. The filter is applied along the last dimension.\n- `padding` (string [\"full\", \"valid\", \"same\"]): Padding mode for convolving x and the filter. Must be one of \"full\", \"valid\", or \"same\". Defaults to \"full\".\n- `conjugate` (bool): If True, the complex conjugate of the filter is applied. Defaults to False.\n\n### Output\n\n- `y` ([..., M], tf.complex or tf.float): Filtered input. It is computed using full convolution if padding is \"full\", or using same-length convolution if padding is \"same\" or \"valid\".\n\n### Properties\n\n**Property: `aclr`**\n- Adjacent channel power ratio of the filter. Relevant for pulse shaping on an i.i.d. sequence of symbols, with respect to the nominal signaling rate.\n\n**Property: `beta`**\n- Roll-off factor.\n\n**Property: `dtype`**\n- Complex datatype of the filter coefficients.\n\n**Property: `length`**\n- Number of filter coefficients.\n\n**Property: `normalize`**\n- True if the filter is normalized to have unit power.\n\n**Property: `num_samples_per_symbol`**\n- Number of samples per symbol, i.e., the oversampling factor.\n\n**Property: `padding`**\n- Padding mode for convolving x and the filter.\n\n**Property: `window`**\n- The window function applied to the filter coefficients. None if no window is applied.\n\n### Method: `show(response='impulse', scale='lin')`\nPlots the impulse or magnitude response of the filter.\n- **Input**:\n  - `response` (str, one of [\"impulse\", \"magnitude\"]): The desired response type. Defaults to \"impulse\".\n  - `scale` (str, one of [\"lin\", \"db\"]): The y-scale of the magnitude response. Can be \"lin\" (linear) or \"db\" (decibel). Defaults to \"lin\"."
"Here is the detailed information of sionna.signal.Upsampling:   \n  \n[sionna.signal.Upsampling(samples_per_symbol, upsampling_factor, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/signal/upsampling.html#Upsampling)  \n\nUpsamples a baseband to a desired sample rate.\n\nThis layer increases the sample rate of its input by inserting zeros between samples. The number of samples to insert is given by the upsampling_factor. After that, a window function specified by window is applied and the result is normalized by samples_per_symbol if normalize is True.\n\nThe window is applied after the upsampling. It is not applied to the coefficients of the default PR or Duobinary pulse shapes.\n\n### Parameters\n\n- `samples_per_symbol` (int): Number of samples per symbol, i.e., the oversampling factor.\n- `upsampling_factor` (int): Upsampling factor, i.e., the number of samples between the inserted zeros.\n- `window` (Window or string [\"hann\", \"hamming\", \"blackman\"]): Instance of Window applied to the upsampled filter coefficients. Alternatively, a string indicating the window name (\"hann\", \"hamming\", \"blackman\"). Custom windows must be provided as an instance.\n- `normalize` (bool): If True, the normalized filter is returned. It has unit energy. Defaults to True.\n- `trainable` (bool): If True, the filter coefficients are trainable variables. Defaults to False.\n- `dtype` (tf.DType): The dtype of the filter coefficients. Defaults to tf.float32.\n\n### Input\n\n- `x` ([..., N], tf.complex): The baseband signal to upsample. This is expected to be on the last dimension.\n\n### Output\n\n- `y` ([..., N, oversampling], tf.complex): The upsampled signal. It has the same dtype and shape as the input x, with the last dimension size being N*oversampling_factor.\n\n**Note:** The implementation follows that of the Polyphase resampler in TensorFlow. It can be significantly faster than the conventional upsample that also exists as a layer in Sionna. However, it does not implement a windowing function."
"The `polarization_model_1` and `polarization_model_2` functions in the Sionna Python package are used to transform antenna patterns into linearly polarized patterns with either vertical or horizontal polarization. These functions are based on models defined in 3GPP TR 38.901 and can be found in `sionna.rt.antenna`.\n\nThe key purposes of these functions are:\n\n- `polarization_model_1`: Transforms a vertically polarized antenna pattern into a linearly polarized pattern with a specified slant angle (which can represent any polarization direction)\n- `polarization_model_2`: Transforms a pair of cross polarized antenna elements into a linearly polarized antenna pair\n\nThe inputs for both functions are:\n\n- `c_tilde_theta` (array_like, complex): Zenith pattern\n- `theta` (array_like, float): Zenith angles wrapped within [0,pi] [rad]\n- `phi` (array_like, float): Azimuth angles wrapped within [-pi, pi) [rad]\n- `slant_angle` (float): Slant angle of the linear polarization [rad]. A slant angle of zero means vertical polarization.\n\nThe outputs of `polarization_model_1` are:\n\n- `c_theta` (array_like, complex): Zenith pattern\n- `c_phi` (array_like, complex): Azimuth pattern\n\nThe outputs of `polarization_model_2` are:\n\n- `c_theta` (array_like, complex): Zenith pattern of the antenna pair\n- `c_phi` (array_like, complex): Azimuth pattern of the antenna pair\n\nIt's important to note that the patterns are complex-valued, and the antenna patterns are normalized to the maximum value of the zenith pattern. This allows for the creation of linearly polarized antenna patterns with any arbitrary slant angle."
"Here is the detailed information of Mapper:   \n  \n[sionna.mapping.Mapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, return_indices=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Mapper)  \n\nMaps binary tensors to points of a constellation.\n\nThis class defines a layer that maps a tensor of binary values to a tensor of points from a provided constellation.  \n  \n### Parameters\n\n- **constellation_type** (One of \"qam\", \"pam\", \"custom\"): str For custom, an instance of Constellation must be provided.\n- **num_bits_per_symbol**: int The number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation_type in [qam, pam].\n- **constellation**: Constellation An instance of Constellation or None. In the latter case, constellation_type and num_bits_per_symbol must be provided.\n- **return_indices**: bool If enabled, symbol indices are additionally returned. Defaults to False.\n- **dtype** (One of [tf.complex64, tf.complex128], tf.DType): The output dtype. Defaults to tf.complex64.\n\n### Input\n\n- [* ,n], tf.float or tf.int: Tensor with with binary entries.\n\n### Output\n\n- [* ,n/num_bits_per_symbol], tf.complex: The mapped constellation symbols.\n- [* ,n/num_bits_per_symbol], tf.int32: The symbol indices corresponding to the constellation symbols. Only returned if return_indices is set to True.\n\n### Note\n\nThe last input dimension must be an integer multiple of the number of bits per constellation symbol.\n\n### Property\n\n- **constellation**:  The Constellation used by the Mapper."
"The `LDPC5GEncoder` class is used to encode data using the 5G NR LDPC code, including rate-matching as defined in the 3GPP NR Initiative. Here are the parameters of the constructor:\n\n- `k` (int): Defines the number of information bits per codeword.\n\n- `n` (int): Defines the desired codeword length.\n\n- `num_bits_per_symbol` (int or None): Defines the number of bits per QAM symbol (the modulation order). If this parameter is not provided, the codeword will be interleaved after rate-matching as specified in the 5G standard.\n\n- `dtype` (tf.DType): Defines the output data type of the encoder. It is set to `tf.float32` by default, but can be changed as needed. \n\n- `**kwargs**`: This is for additional keyword arguments that may be passed during the instantiation of the `LDPC5GEncoder`.\n\nThe 5G LDPC encoding process includes rate-matching and puncturing which are taken into account by the `LDPC5GEncoder` class. The provided context does not include the code snippet for the instantiation of the `LDPC5GEncoder` class, but typically, it would look like this:\n\n```python\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nencoder = LDPC5GEncoder(k, n, num_bits_per_symbol=4)\n```\n\nWhere `k`, `n` are the number of information bits and the desired codeword length respectively, and `num_bits_per_symbol` is the modulation order. The actual code may vary depending on the specific implementation or library usage."
"The functions in the Sionna module provide a variety of utilities for dealing with complex-valued quantities in the context of wireless simulation, specifically for the support of Multiple-input multiple-output (MIMO) links. MIMO links are the basis of many modern wireless communication standards, where multiple data streams are transferred simultaneously over a radio channel.\n\nThe functions in the Sionna module are described as follows:\n\n1. complex2real_vector: Transforms a complex-valued vector into its real-valued equivalent. This is used for transforming the received signal vector in the context of a MIMO link into its real and imaginary parts for further processing.\n\n2. real2complex_vector: Transforms a real-valued vector into its complex-valued equivalent. This is the inverse operation of complex2real_vector. It is used for transforming a transmitted signal vector in the context of a MIMO link from its real and imaginary parts back to its complex form.\n\n3. complex2real_matrix: Transforms a complex-valued matrix into its real-valued equivalent. Similar to complex2real_vector, but operates on matrices instead of vectors.\n\n4. real2complex_matrix: Transforms a real-valued matrix into its complex-valued equivalent. Used in the inverse transformation of received signals in MIMO scenarios.\n\n5. complex2real_covariance: Transforms a complex-valued covariance matrix to its real-valued equivalent. Used in the processing of covariance matrices in MIMO scenarios.\n\n6. real2complex_covariance: Transforms a real-valued covariance matrix to its complex-valued equivalent. This function is the inverse of complex2real_covariance.\n\n7. complex2real_channel: Transforms a complex-valued MIMO channel matrix to its real-valued equivalent. Used in MIMO systems to support processes based on real-valued equivalent representations of complex-valued quantities.\n\n8. real2complex_channel: Transforms a real-valued MIMO channel matrix to its complex-valued equivalent. This function corresponds to the complex2real_channel function, but in the opposite direction.\n\nThe MIMO relevant functions complex2real_vector, real2complex_vector, complex2real_matrix, real2complex_matrix, complex2real_covariance, real2complex_covariance, complex2real_channel, and real2complex_channel perform transformations between complex and real-valued representations for MIMO systems. These functions are utilized in the MIMO pipeline of the Sionna module, which includes processes such as precoding and equalization of signals in MIMO links.\n\nThe Sionna module also includes a variety of other functions, classes, and Keras layers that are specifically tailored for MIMO link simulations and related tasks. These include functions for generating signal covariance matrices and Gaussian distributed random transmitted vectors, classes for handling sparse signal precoding in MIMO links, and Keras layers for implementing the OFDM channel, transmitter, and receiver. \n\nTo use these functions, you must import the Sionna module and the specific components you need. For example:\n\n```python\nimport sionna\nfrom sionna.mimo import complex2real_vector\n```\n\nThen you can use the imported functions with the appropriate arguments as provided in the context of your work or simulation."
"Here is the detailed information of FlatFadingChannel:   \n  \nApplies random channel matrices to a vector input and adds AWGN.\n\nThis class combines GenerateFlatFadingChannel and ApplyFlatFadingChannel and computes the output of a flat-fading channel with AWGN.\n\nFor a given batch of input vectors $\\mathbf{x}\\in\\mathbb{C}^{K}$, the output is $\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}$  \nwhere $\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ are randomly generated flat-fading channel matrices and $\\mathbf{n}\\in\\mathbb{C}^{M}\\sim\\mathcal{CN}(0, N_o\\mathbf{I})$ is an AWGN vector that is optionally added.\n\nA SpatialCorrelation can be configured and the channel realizations optionally returned. This is useful to simulate receiver algorithms with perfect channel knowledge.\n\nParameters\n\n- **num_tx_ant** (int): Number of transmit antennas.\n- **num_rx_ant** (int): Number of receive antennas.\n- **spatial_corr** (SpatialCorrelation, None): An instance of SpatialCorrelation or None. Defaults to None.\n- **add_awgn** (bool): Indicates if AWGN noise should be added to the output. Defaults to True.\n- **return_channel** (bool): Indicates if the channel realizations should be returned. Defaults to False.\n- **dtype** (tf.complex64, tf.complex128): The dtype of the output. Defaults to tf.complex64.\n\nInput\n\n- **(x, no)**: Tuple or Tensor.\n  - **x** ([batch_size, num_tx_ant] or [batch_size, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex): Tensor of transmit vectors.\n  - **no** (Scalar or Tensor, tf.float): The noise power no is per complex dimension. Only required if add_awgn==True. Will be broadcast to the dimensions of the channel output if needed.\n\nOutput\n\n- **(y, h)**: Tuple or Tensor.\n  - **y** ([batch_size, num_rx_ant, num_tx_ant] or [batch_size, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex): Channel output.\n  - **h** ([batch_size, num_rx_ant, num_tx_ant] or [batch_size, num_rx_ant, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex): Channel realizations. Will only be returned if return_channel==True.\n  - **n show_channel** ([batch_size, num_rx_ant, num_tx_ant] or [batch_size, num_rx_ant, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex): Channel noise.  \n  \n### Input as Transpose of Receiver Antenna Number\nIt is also possible to input $\\mathbf{x}$ as a tensor of shape $\\mathbf{K}\\mathbf{X}$, with $\\mathbf{K}$ denoting the number of transmit antennas and $\\mathbf{X}$ being the number of OFDM symbols or time-lags, depending on the context. In this case, one needs to set generate_mode to \"time\" l apply() to compute the output of the channel.\n\nWhen $\\mathbf{x}$ is provided this way, it will be transposed to required shape by default. Note that this is equivalent to the following procedure:\n  \n1. Let $\\mathbf{x}$ denote the original transmit tensor of shape $\\mathbf{K}\\times\\mathbf{X}$. \n\n2. Transmit $\\mathbf{x}$ through the channel to get $\\mathbf{y}\\in\\mathbb{C}^{M\\times\\mathbf{K}\\times\\mathbf{X}}$.\n\n3. Convert $\\mathbf{y}$ into the equivalent received signal $\\mathbf{y}^{\\mathsf{H}}\\in\\mathbb{C}^{\\mathbf{K}\\times\\mathbf{M}\\times\\mathbf{X}}$.\n\nIn this case, $\\mathbf{x}$ can be also be of arbitrary shape (in the numerical sense), and $\\mathbf{y}$ will have the same shape.  \n  \n### Properties\n- **apply**[source](https://nvlabs.github.io/sionna/_modules/sionna/channel/wireless/channel.html#FlatFadingChannel.apply): Applies the flat-fading channel.  \n- **generate**[source](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.FlatFadingChannel.generate): Generates randomly generated flat-fading channel matrices.  \n \n### apply(input, no)  \nApplies the flat-fading channel.\n\nFor a given batch of input vectors $\\mathbf{x}\\in\\mathbb{C}^{K}$, the output is $\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}$  \nwhere $\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ are randomly generated flat-fading channel matrices and $\\mathbf{n}\\in\\mathbb{C}^{M}\\sim\\mathcal{CN}(0, N_o\\mathbf{I})$ is an AWGN vector that is optionally added.\n\nA SpatialCorrelation can be configured and the channel realizations optionally returned. This is useful to simulate receiver algorithms with perfect channel knowledge.\n\n### Input\n- **(x, no)**:\n  - **x** ([batch_size, num_tx_ant] or [batch_size, num_ofdm_symbols, fft_size, num_tx_ant], tf.complex): Tensor of transmit vectors or input signals. \n  - **no** (Scalar or Tensor, tf.float): The noise power `no` is per complex dimension. Only required if `add_awgn==True`.\n\n### Output\n- **(y, h, show_channel)**:\n  - **y** ([batch_size, num_rx_ant, num_tx_ant] or [batch_size, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex): Channel output.\n  - **h** ([batch_size, num_rx_ant, num_tx_ant] or [batch_size, num_rx_ant, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex): Channel realizations. Will only be returned if `return_channel==True`.\n  - **show_channel** (bool): Indicates if channel realizations are returned.  \n  \n### generate(num_rx, num_rx_ant, num_tx, num_tx_ant, dtype=tf.complex64)  \nGenerates randomly generated flat-fading channel matrices.\n\nThe channel impulse response is generated according to the Kronecker model [33](https://nvlabs.github.io/sionna/em_waves.html#equation-kronecker-model)\n$\\mathbf{h} \\in \\mathbb{C}^{N_\\text{rx}N_\\text{rx, ant}N_\\text{tx}N_\\text{tx, ant}}$\nwhich is reshaped to $\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$, where $M=N_\\text{rx}N_\\text{rx, ant}$ and $K=N_\\text{tx}N_\\text{tx, ant}$. For each batch example, $num_tx$ channel impulse responses are generated.\n\n### Input\n- **num_rx** (int): Number of receivers ($N_\\text{rx}$).\n- **num_rx_ant** (int): Number of antennas per receiver ($N_\\text{rx, ant}$).\n- **num_tx** (int): Number of transmitters ($N_\\text{tx}$).\n- **num_tx_ant** (int): Number of antennas per transmitter ($N_\\text{tx, ant}$).\n- **dtype** (tf.DType): The dtype of the output. Complex64 or Complex128. Defaults to tf.complex64.\n\n### Output\n- **(h, h_freq, zeros)**:\n  - **h** ([batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant], tf.complex): Channel impulse response.\n  - **h_freq** ([batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex): Channel frequency response.\n  - **zeros** ([batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_ofdm_symbols-1, fft_size], tf.complex): Zeros outside the resource grid.\n\n### Set Input Parameters   \n```python\nchannel = sionna.channel.FlatFadingChannel(\n     num_tx=num_tx,\n     num_rx=num_rx,\n     num_tx_ant=num_tx_ant,\n     num_rx_ant=num_rx_ant,\n     add_awgn=True)\n```\n\n### Properties\n- **dtype**: Tensor data type of the output tensor.\n  - **Type**: `tf.complex64 | tf.complex128`\n- **spatial_corr**: Spatial correlation model in use. \n  - **Type**: `SpatialCorrelation`  \n  "
"Here is the definition of PilotPattern: sionna.ofdm.PilotPattern(mask, pilots, trainable=False, normalize=False, dtype=tf.complex64)\n\n* [Source code](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/pilot_pattern.html#PilotPattern)  \n\n```python\nclass PilotPattern(ABC):\n    \"\"\"Class defining a pilot pattern for an OFDM ResourceGrid.\"\"\"\n    def __init__(self, mask, pilots, trainable=False, normalize=False,\n                 dtype=tf.complex64):\n        self._trainable = trainable\n        if normalize:\n            pilots = pilots/tf.cast(\n                tf.math.reduce_mean(tf.square(pilots)), pilots.dtype)\n        self._pilots = tf.cast(pilots, dtype)\n        self._mask = mask\n\n    @property\n    def normalize(self):\n        \"\"\"Indicates if the pilots are normalized or not.\"\"\"\n        return self._normalize\n\n    @normalize.setter\n    def normalize(self, value):\n        \"\"\"Set the flag if the pilots should be normalized.\"\"\"\n        self._normalize = value\n\n    @property\n    def num_data_symbols(self):\n        \"\"\"Number of data symbols per transmit stream.\"\"\"\n        return self.num_effective_subcarriers*np.sum(self.mask)\n\n    @property\n    def num_effective_subcarriers(self):\n        \"\"\"Number of effective subcarriers\"\"\"\n        return tf.reduce_sum(self.mask)\n\n    @property\n    @abstractmethod\n    def num_ofdm_symbols(self):\n        \"\"\"Number of OFDM symbols.\"\"\"\n        pass\n\n    @property\n    def num_pilot_symbols(self):\n        \"\"\"Number of pilot symbols per transmit stream.\"\"\"\n        return self._pilots.shape[-1]\n\n    @property\n    def num_streams_per_tx(self):\n        \"\"\"Number of streams per transmitter.\"\"\"\n        return self._pilots.shape[-2]\n\n    @property\n    def num_tx(self):\n        \"\"\"Number of transmitters.\"\"\"\n        return self._pilots.shape[0]\n\n    @property\n    def pilots(self):\n        \"\"\"Returns the possibly normalized tensor of pilot symbols.\n\n        If pilots are normalized, the normalization will be applied\n        after new values for pilots have been set. If this is\n        not the desired behavior, turn normalization off.\n        \"\"\"\n        return self._pilots\n\n    @property\n    def trainable(self):\n        \"\"\"Indicates if pilots are trainable or not\"\"\"\n        return self._trainable\n\n    @property\n    def mask(self):\n        \"\"\"Mask of the pilot pattern\"\"\"\n        return self._mask\n\n    def show(self, tx_ind=0, stream_ind=0, show_pilot_ind=False):\n        \"\"\"Visualizes the pilot patterns for some transmitters and streams.\n\n        Input\n        -----\n        tx_ind : list, int\n            Indicates the indices of transmitters to be included.\n            Defaults to `None`, i.e., all transmitters included.\n\n        stream_ind : list, int\n            Indicates the indices of streams to be included.\n            Defaults to `None`, i.e., all streams included.\n\n        show_pilot_ind : bool\n            Indicates if the indices of the pilot symbols should be\n            shown.\n        \"\"\"\n        assert isinstance(show_pilot_ind, bool), \\\n                                                \"show_pilot_ind must be bool.\"\n        if tx_ind is None:\n            tx_ind = list(range(self.num_tx))\n        if stream_ind is None:\n            stream_ind = list(range(self.num_streams_per_tx))\n        figs = []\n        for i, tx in enumerate(tx_ind):\n            for j, ind in enumerate(stream_ind):\n                fig = plt.figure()\n                pilot_pattern = self.get_masked_pilots(tx, ind)\n                r = tf.math.real(pilot_pattern)\n                r = np.where(r==1, 1, np.where(r==0, np.nan, 0))\n                plt.imshow(r, origin=\"lower\",)\n                plt.xlabel(\"Subcarrier index\")\n                plt.ylabel(\"OFDM symbol index\")\n                plt.title(f\"Tx:{tx}, Stream:{ind}\")\n                cbar = plt.colorbar(ticks=[0.25, 0.75], format=\"%.2f\")\n                cbar.set_label(\"Magnitude\")\n\n                if show_pilot_ind:\n                    for ofdm_ind in range(pilot_pattern.shape[-1]):\n                        for subc_ind in range(pilot_pattern.shape[-2]):\n                            if pilot_pattern[tx,ind,subc_ind,ofdm_ind]==1:\n                                plt.text(subc_ind, ofdm_ind, f\"{ofdm_ind}\")\n\n                figs.append(fig)\n        return figs\n\n    @property\n    @abstractmethod\n    def n_tot(self):\n        \"\"\"Total number of resource elements (pilot and data).\"\"\"\n        pass\n\n    def get_pilot_ind(self, tx=0, stream=0):\n        \"\"\"Returns the indices of the pilot symbols for a specific\n        transmitter and stream.\n\n        Input\n        -----\n        tx : int\n            Transmitter index\n\n        stream : int\n            Index of the stream\n        \"\"\"\n        tx_pilots = tf.where(self.mask[tx, stream])\n        return tx_pilots\n\n    def get_data_ind(self, tx=0, stream=0):\n        \"\"\"Returns the indices of the data symbols for a specific\n        transmitter and stream.\n\n        Input\n        -----\n        tx : int\n            Transmitter index\n\n        stream : int\n            Index of the stream\n        \"\"\"\n        tx_data = tf.where(self.mask[tx, stream].numpy()==0)\n        return tx_data\n```"
"To use Sionna, follow these steps to import the necessary packages including TensorFlow and NumPy:\n\n1. Import the necessary packages:\n\n```python\nimport os\nimport gpu_num # for setting the GPU number\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n\n2. Set the GPU number:\n\n```python\ngpu_num = 0 # Use 0 to use the first GPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n```\n\n3. Set the TensorFlow log level to 'ERROR' to avoid warnings:\n\n```python\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\ntf.get_logger().setLevel('ERROR')\n```\n\n4. Check if the Sionna package is installed. If not, install it:\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n5. Import the Sionna package:\n\n```python\nimport sionna\n```\n\n6. Check the TensorFlow version. Sionna requires TensorFlow 2.8 or later:\n\n```python\ntf.__version__\nif tf.__version__.split('.')[0] != '2':\n    raise ImportError(\"Sionna requires TensorFlow 2.8 or later)\")\n```\n\n7. Set the TensorFlow log level to 'ERROR' to avoid warnings:\n\n```python\ntf.get_logger().setLevel('ERROR')\n```\n\n8. Import the Sionna components:\n\n```python\nfrom sionna.fec.ldpc import LDPCBPDecoder, LDPC5GEncoder, LDPC5GDecoder\nfrom sionna.utils.metrics import BitwiseMutualInformation\nfrom sionna.fec.utils import load_parity_check_examples\nfrom sionna.utils.metrics import plot_mi\nfrom sionna.utils.cm import evaluate\n```\n\nPlease note that the `%matplotlib inline` command is used to enable the rendering of matplotlib plots in the Jupyter notebook."
"Here is the detailed information of LinearInterpolator:   \n  \n[sionna.ofdm.LinearInterpolator(pilot_pattern, time_avg=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/channel_estimation.html#LinearInterpolator)  \n\nLinear channel estimate interpolation on a resource grid.\n\nThis class computes for each element of an OFDM resource grid a channel estimate based on num_pilots provided channel estimates and error variances through linear interpolation.\nIt is assumed that the measurements were taken at the nonzero positions of a PilotPattern.\n\nThe interpolation is done first across sub-carriers and then across OFDM symbols.\n\nParameters\n\n- **pilot_pattern** (PilotPattern) An instance of PilotPattern.\n- **time_avg** (bool) If enabled, measurements will be averaged across OFDM symbols (i.e., time). This is useful for channels that do not vary substantially over the duration of an OFDM frame. Defaults to False.\n- **dtype** (tf.Dtype) internal precision for dtype. Defaults to tf.complex64.\n\nInput\n\n- **h_hat** ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex) Channel estimates for the pilot-carrying resource elements.\n- **err_var** ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex) Channel estimation error variances for the pilot-carrying resource elements.\n\nOutput\n\n- **h_hat** ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], tf.complex) Channel estimates accross the entire resource grid for all transmitters and streams.\n- **err_var** (Same shape as h_hat, tf.float) Channel estimation error variances accross the entire resource grid for all transmitters and streams."
"Here is the detailed information of SymbolLogits2Moments:   \nClass Definition:   \n`class` `SymbolLogits2Moments`  \n[Source code](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#SymbolLogits2Moments)\nComputes the mean and variance of a constellation from logits (unnormalized log-probabilities) on the constellation points.\n\nMore precisely, given a constellation $\\mathcal{C} = \\left[ c_0,\\dots,c_{N-1} \\right]$ of size $N$, this layer computes the mean and variance according to\n\n$$\n\\begin{split}\n\\begin{align}\n    \\mu &= \\sum_{n = 0}^{N-1} c_n \\Pr \\left(c_n \\lvert \\mathbf{\\ell} \\right)\\\\\n    \\nu &= \\sum_{n = 0}^{N-1} \\left( c_n - \\mu \\right)^2 \\Pr \\left(c_n \\lvert \\mathbf{\\ell} \\right)\n\\end{align}\n\\end{split}\n$$\n\nwhere $\\mathbf{\\ell} = \\left[ \\ell_0, \\dots, \\ell_{N-1} \\right]$ are the logits, and\n\n$$\n\\Pr \\left(c_n \\lvert \\mathbf{\\ell} \\right) = \\frac{\\exp \\left( \\ell_n \\right)}{\\sum_{i=0}^{N-1} \\exp \\left( \\ell_i \\right) }.\n$$\n\n### Parameters\n\n- **constellation_type** (`One of` [\"qam\", \"pam\", \"custom\"], `str`) \u2013 For custom, an instance of Constellation must be provided.\n- **num_bits_per_symbol** (`int`) \u2013 The number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation_type in [qam, pam].\n- **constellation** (An instance of Constellation) \u2013 Constellation or None. In the latter case, constellation_type and num_bits_per_symbol must be provided.\n- **dtype** (`One of` [tf.float32, tf.float64] `tf.DType` (dtype)) \u2013 The dtype for the input and output. Defaults to tf.float32.\n\n### Input\n\n- **logits** (`[,n, num_points]`, `tf.float`) \u2013 Logits on constellation points.\n\n### Output\n\n- **mean** (`[,n]`, `tf.float`) \u2013 Mean of the constellation.\n- **var** (`[,n]`, `tf.float`) \u2013 Variance of the constellation."
"The function 'cir_to_ofdm_channel' in the 'sionna.channel' module is used to compute the channel frequency responses in Orthogonal Frequency-Division Multiplexing (OFDM) systems from given channel impulse responses (CIRs). In OFDM, the channel frequency response for a subcarrier frequency is obtained by summing the delayed and attenuated versions of the signal.\n\nThe function takes in the inputs of frequencies, a, tau, and normalize. The 'frequencies' input represents the frequencies at which the channel response should be computed. The 'a' and 'tau' inputs respectively stand for the path coefficients and path delays. The 'normalize' parameter is optional and its default value is 'False'. If 'normalize' is set to 'True', the 'cir_to_ofdm_channel' function normalizes the channel to ensure unit average energy per resource element.\n\nThe function outputs the 'h_f' which represents the channel frequency responses at the specified input 'frequencies'.\n\nA usage example of this function can be seen in the code snippet provided in the context:\n\n```python\nh_freq = cir_to_ofdm_channel(frequencies, h, tau)\n```\n\nIn this snippet, 'h_freq' is the channel frequency response at the specified input 'frequencies', 'frequencies' and 'tau' are pre-defined frequency and delay values, and 'h' represents the channel impulse response. Please note that the actual usage of this function would depend on the specifics of the OFDM system or setup it is being used in."
"The `EPDetector` class is part of the 'sionna' package used for wireless simulation, and is designed to implement the Expectation Propagation (EP) MIMO detection algorithm as described in a 2014 research paper. The class assumes a model where vectors of transmitted symbols are independently processed by a constellation mapper prior to being transmitted over a MIMO channel. \n\nThe `EPDetector` class can be used for both bit operations and symbol operations. Hard-decisions and soft-decisions are supported, and the output can be either a bit or a symbol. Various parameters can be adjusted, including the number of iterations for the belief propagation process, the type of output (bit or symbol), and whether to use hard-decisions or soft-decisions.\n\nThe class contains several key methods including:\n\n- `call()`: This method performs the Expectation Propagation (EP) MIMO detection algorithm. It is used to generate outputs of either bits or symbols, with the option of obtaining hard-decisions or soft-decisions.\n  \n- `ep_star()`: This method computes the fixed-point update functions of the matching-pursuit detector.\n  \n- `compute_llr()`: This method calculates the Log-Likelihood Ratios (LLRs) using an approximation of the Gaussian assumption.\n\nThe `EPDetector` class is particularly significant because it provides an implementation of the Expectation Propagation (EP) MIMO detection algorithm, which can be used in the context of wireless simulation where sophisticated processing of MIMO signals is required. This class might be used in simulations where modeling the effects of the wireless channel, encoding and decoding processes, and the constellation mapping/demapping is necessary. Its versatility in terms of the types of operations supported (bit or symbol), the nature of the output (soft or hard decisions), and the ability to specify the number of iterations, make it a valuable tool in these kinds of simulations."
"Setting up and running an instance of the EDFA class in Sionna involves a few key steps:\n\n### Step 1: Import the EDFA class from the Sionna library\nYou'll need to import the EDFA class from the Sionna library using the appropriate command. The Sionna library is indicated to contain classes and functions for simulating 5G NR compliant device configurations, so make sure to reference the Sionna documentation for the specific import statement.\n\n### Step 2: Configure the EDFA parameters\nInitialize the EDFA class by providing the necessary parameters. The class definition from the context provides the following parameters:\n\n- `g`: Gain (float) - This is the gain in linear domain (not in dB), and you need to choose the value depending on your system requirements. Typically, the EDFA gain is a positive number.\n- `f`: Noise figure (float) - This is the noise figure in linear domain (not in dB), again a value must be chosen depending on your needs. The noise figure is usually greater than or equal to 1.\n- `f_c`: Carrier frequency (float) - This is the carrier frequency in Hz (not in kHz), another parameter that you'll need to set based on your simulation.\n- `dt`: Time step (float) - This is the time step in s, which needs to be chosen carefully for an accurate simulation.\n- `dtype`: Defines the simulation accuracy (to reduce load, use `tf.complex64` instead of `tf.complex128` if accuracy is not critical).\n\n### Step 3: Run the simulation\nAfter setting up the parameters, you can simulate the system components using the configured parameters. Follow the provided Sionna documentation for the specific steps on how to simulate the system components.\n\nRemember that the result of the simulation will depend on the parameters you've chosen, so make sure to verify that the simulation output aligns with your expectations and the real-world characteristics of the system you're simulating."
"The `render_to_file()` function in the `Scene` class of the Sionna package is used to render the scene as seen from a specific camera (or the interactive viewer if a camera is not specified) and save the resulting image to a file. The function takes the following parameters:\n\n- **camera**: Either the name or an instance of a `Camera` class. If you have opened an interactive viewer with the `preview()` function, you can set the `camera` parameter to 'preview' to use its viewpoint.\n- **filename**: A string specifying the name of the file to save the rendered image to, including the \".png\" or \".jpeg\" extension.\n- **paths**: Optional, paths computed by `compute_paths()` function. Defaults to None. If paths is not None, only these paths will be rendered.\n- **show_paths**: Optional boolean parameter. Defaults to True. If set to True and `paths` is provided, the paths will be rendered.\n- **show_devices**: Optional boolean parameter. Defaults to True. If set to True and `paths` is provided, the radio devices will be rendered.\n- **coverage_map**: Optional parameter of type `CoverageMap` or None. Defaults to None. If coverage_map is not None, a coverage map will be rendered.\n- **cm_tx**: Optional integer or string parameter. Defaults to 0. Only relevant when `coverage_map` is specified, this controls which of the transmitters to display the coverage map for. The `cm_tx` parameter can represent either the transmitter's index or name.\n- **cm_db_scale**: Optional boolean parameter. Defaults to True. If set to True, a logarithmic scale will be used for the coverage map, mapping the coverage values with: $y = 10 \\cdot \\log_{10}(x)$.\n- **cm_vmin, cm_vmax**: Optional float parameters. Defaults to None. If `cm_db_scale` is set to True, these parameters define the minimum and maximum path gain values for the coverage map visualization, respectively. They should be provided in dB.\n- **num_samples**: Optional integer parameter. Defining the number of rays per pixel, this can be used to control the quality of the rendered image. More rays per pixel will generally lead to a smoother image but will take longer to compute.\n- **resolution**: An array-like of length two containing integers defines the width and height of the rendered figure, which is in pixels. A higher resolution value will yield a clearer image.\n- **fov**: A float value defining the camera's field of view in degrees. A larger field of view will lead to a wider-angle perspective.\n\nThe `render_to_file()` function uses a `Camera` object to render the scene, or an interactive viewer if it is provided with 'preview'. You can adjust the above parameters as needed to suit your rendering requirements.\n\nPlease note: The referenced \"sionna.rt\" package should be installed in your python environment to use this function."
"To use this function in a programming scenario, you would import the necessary module from sionna.api.channel, then call the function with angle as the parameter. The function should return angle wrapped to (0,360).\n\nCODE:\n\n```python\nimport tensorflow as tf\nfrom sionna.channel import wrap_angle_0_360\n\n# Define the angle tensor\nangle = tf.constant([270.0, 450.0, -90.0, 0.0, 720.0, -540.0], tf.float32)\n\n# Call the function to wrap the angle\nwrapped_angle = wrap_angle_0_360(angle)\n\n# Print the wrapped angle\nprint(wrapped_angle)\n```\n\nOUTPUT:\n\n```\ntf.Tensor([ 90.  90. 270.   0.  0. 180.], shape=(6,), dtype=float32)\n```"
"Here is the definition of ChannelModel: sionna.channel.ChannelModel\n\n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel)\n\n```python\nfrom abc import ABC, abstractmethod\n\nclass ChannelModel(ABC):\n    @property\n    @abstractmethod\n    def a(self):\n        pass\n\n    @property\n    @abstractmethod\n    def tau(self):\n        pass\n\n    @property\n    @abstractmethod\n    def num_paths(self):\n        pass\n\n    @property\n    @abstractmethod\n    def num_clusters(self):\n        pass\n\n    @property\n    @abstractmethod\n    def num_time_steps(self):\n        pass\n\n    @abstractmethod\n    def __call__(self,\n               batch_size,\n               num_rx,\n               num_rx_ant,\n               num_tx,\n               num_tx_ant,\n               spatial_corr_mat=None):\n        pass\n```\n  "
"Function: sionna.rt.Scene.render_to_file(camera, filename, paths=None, show_paths=True, show_devices=True, coverage_map=None, cm_tx=0, cm_db_scale=True, cm_vmin=None, cm_vmax=None, num_samples=512, resolution=[655, 500], fov=45)\n\nMethod:\n```python\ndef render_to_file(self, camera, filename, paths=None, show_paths=True,\n                   show_devices=True, coverage_map=None, cm_tx=0,\n                   cm_db_scale=True, cm_vmin=None, cm_vmax=None,\n                   num_samples=512, resolution=[655,500], fov=45):\n```\n\n**Description**\n\nRenders the scene from the viewpoint of a camera or the interactive viewer, and saves the resulting image.\n\n**Input**\n\n- `camera` (str | `Camera`): The name or instance of a `Camera`. If an interactive viewer was opened with `preview()`, set to \"preview\" to use its viewpoint.\n- `filename` (str): Filename for saving the rendered image (e.g., \"my_scene.png\").\n- `paths` (Paths | None): Simulated paths generated by `compute_paths()` or None. If None, only the scene is rendered. Defaults to None.\n- `show_paths` (bool): If `paths` is not None, shows the paths. Defaults to True.\n- `show_devices` (bool): If `paths` is not None, shows the radio devices. Defaults to True.\n- `coverage_map` (CoverageMap | None): An optional coverage map to overlay in the scene for visualization. Defaults to None.\n- `cm_tx` (int | str): When `coverage_map` is specified, controls which of the transmitters to display the coverage map for. Either the transmitter's name or index can be given. Defaults to 0.\n- `cm_db_scale` (bool): Use logarithmic scale for coverage map visualization, i.e., the coverage values are mapped with $y = 10 \\cdot \\log_{10}(x)$. Defaults to True.\n- `cm_vmin`, `cm_vmax` (float | None): For coverage map visualization, defines the range of path gains that the colormap covers. These parameters should be provided in dB if `cm_db_scale` is set to True, or in linear scale otherwise. If set to None, then covers the complete range. Defaults to None.\n- `num_samples` (int): Number of rays to trace per pixel. Defaults to 512.\n- `resolution` ([2], int): Size of the rendered figure. Defaults to [655, 500].\n- `fov` (float): Field of view, in degrees. Defaults to 45.\n\nsource code:\n```python\ndef render_to_file(self, camera, filename, paths=None, show_paths=True,\n                   show_devices=True, coverage_map=None, cm_tx=0,\n                   cm_db_scale=True, cm_vmin=None, cm_vmax=None,\n                   num_samples=512, resolution=[655,500], fov=45):\n    # Get camera\n    if isinstance(camera, str):\n        if camera in self._cameras:\n            camera = self._cameras[camera]\n        else:\n            raise ValueError(\"Unknown camera name.\")\n    else:\n        assert isinstance(camera, Camera), \\\n            \"The camera object must be an instance of Camera.\"\n    \n    if self._interactive_viewers:\n        warnings.warn(\"The scene cannot be rendered to a file as it contains \"\n                      \"an interactive viewer. Consider using render_to_screen() \"\n                      \"or closing the preview.\", UserWarning)\n    \n    # Check coverage map consistency\n    if coverage_map is not None:\n        if not isinstance(coverage_map, CoverageMap):\n            raise ValueError(\"coverage_map must be a valid CoverageMap object\")\n        if cm_tx is not None:\n            if isinstance(cm_tx, str):\n                if cm_tx not in self._tx_names:\n                    raise ValueError(f\"Invalid transmitter name '{cm_tx}'\")\n                cm_tx = self._tx_names.index(cm_tx)\n            elif not (0<=cm_tx<len(self._tx_names)):\n                raise ValueError(\\\n                    f\"cm_tx must be in the range from 0 to {len(self._tx_names)}-1 \"\n                    f\"or have the value 'all'. Value used: {cm_tx}. \")\n        else:\n            cm_tx = 'all'\n\n    # Render\n    if paths is not None:\n        scene_path = ScenePath(self, paths, num_samples, camera, resolution, fov)\n        # The computed path can be used to render the paths\n        # The preview must not be displayed\n        path_preview = scene_path.render_to_screen(filename, pathcolor, \\\n                                            show_devices, coverage_map, cm_tx, \\\n                                            cm_db_scale, cm_vmin, cm_vmax)\n        # Indicate that the paths were computed\n        desc = \"Paths calculated with COMSOL module\"\n    else:\n        # There are no simulated paths\n        # The scene is rendered by accessing the scene's renderer\n        r = self._renderer\n        # Set the camera of the renderer\n        r.camera = camera\n        # Render\n        img = r.render_to_file(filename, resolution=resolution, fov=fov)\n        # Indicate that the image was rendered\n        desc = \"Image rendered with background\"\n    \n    # Annotate the file\n    with Image(filename) as im:\n        im22 = im.clone()\n    # Get the preview image\n    im22.preview(path=paths, preview=not show_paths, max_size=resolution)\n    # Save the preview image\n    im22.save(filename=filename, resolution=resolution, preview=not show_paths)\n    # Add the description\n    add_desription(self, filename, desc)\n    # Result path\n    path = Path(self.get_scene_dir())\n    # Return the relative path\n    return path / filename\n```"
"To configure DeepMIMO for use with Sionna, you need to set up the DeepMIMO parameters according to your specific requirements. \n\n1. Import the DeepMIMO package. If it's not already installed, install it using the provided code snippet.\n```python\ntry:\n    import DeepMIMO\nexcept ImportError as e:\n    import os\n    os.system(\"pip install DeepMIMO\")\n    import DeepMIMO\n```\n\n2. Load the default DeepMIMO parameters.\n```python\nDeepMIMO_params = DeepMIMO.default_params()\n```\n\n3. Set the dataset folder to point to the folder where the DeepMIMO scenarios are located.\n```python\nDeepMIMO_params['dataset_folder'] = r'./scenarios'\n```\n\n4. Set the DeepMIMO scenario. In this case, the 'O1_60' scenario is used.\n```python\nDeepMIMO_params['scenario'] = 'O1_60'\n```\n\n5. Set the number of paths for the DeepMIMO channels.\n```python\nDeepMIMO_params['num_paths'] = 10\n```\n\n6. Set the active basestations. In this example, only basestation with index 6 is included.\n```python\nDeepMIMO_params['active_BS'] = np.array([6])\n```\n\n7. Set the first and last user rows to be included in the dataset. In this example, rows 400 to 450 are included.\n```python\nDeepMIMO_params['user_row_first'] = 400\nDeepMIMO_params['user_row_last'] = 450\n```\n\n8. Configure the antenna arrays for the basestations and users. In this example, the basestation is equipped with a uniform linear array of 16 elements spread along the x-axis, and the users are each equipped with a single antenna.\n```python\nDeepMIMO_params['bs_antenna']['shape'] = np.array([16, 1, 1])\nDeepMIMO_params['ue_antenna']['shape'] = np.array([1, 1, 1])\n```\n\n9. Set the OFDM_channels parameter to 0, which means that the channel impulse responses will be generated.\n```python\nDeepMIMO_params['OFDM_channels'] = 0\n```\n\n10. Generate the DeepMIMO dataset using the configured parameters.\n```python\nDeepMIMO_dataset = DeepMIMO.generate_data(DeepMIMO_params)\n```\n\nAfter configuring DeepMIMO, the generated dataset can be used with Sionna."
"To use the Interleaver module in the Sionna package to permute tensors, you can follow these steps:\n\n1. Import the required modules from Sionna package. They include `RandomInterleaver` and `Deinterleaver`.\n\n```python\nfrom sionna.fec.interleaving import RandomInterleaver, Deinterleaver\n```\n\n2. Initialize the interleaver with the required parameters. These parameters include:\n   \n   - `seed`: An explicit integer seed for a new random seed. This is optional and only required if a new random seed should be used for each call.\n   \n   - `keep_batch_constant`: If `True`, all samples in the batch are permuted with the same pattern. Default is `False`.\n   \n   - `axis`: Axis to be permuted. This is the axis with the highest dimension. Default is the last axis (`-1`).\n\n```python\ninterleaver = RandomInterleaver(seed=1234, keep_batch_constant=False, axis=-1)\n```\n\n3. Initialize the deinterleaver and connect it to the interleaver.\n\n```python\ndeinterleaver = Deinterleaver(interleaver=interleaver)\n```\n\n4. Permute your tensor `c` using the initialized interleaver.\n\n```python\nc_int = interleaver(c)\n```\n\n5. If you want to use a new random seed for each call, you need to provide an explicit seed to the interleaver.\n\n```python\ns = tf.random.uniform((), minval=0, maxval=12345678, dtype=tf.int32)\nc_int = interleaver([c, s])\n```\n\n6. Reconstruct the original order of the tensor from the permuted tensor using the deinterleaver.\n\n```python\nc_deint = deinterleaver(c_int)\n```\n\nPlease note that the Sionna package should be installed in your environment to use these modules. If it's not installed, you can install it using pip:\n\n```python\npip install sionna\n```"
"The `MMSEPICDetector` function is part of Sionna's novel Python package designed for simulating wireless communication systems. This function wraps the MIMO MMSE PIC (Successive Parity Check) detector for use with OFDM (Orthogonal Frequency-Division Multiplexing) waveforms. Its primary purpose is to handle detection of symbols or bits with either soft- or hard-decisions, taking OFDM and stream configuration as inputs.\n\nKey parameters of the `MMSEPICDetector` function include:\n\n- `output`: Specifies the type of output, which can be either 'bit' for bits or 'symbol' for symbols.\n- `resource_grid`: An instance of `ResourceGrid`.\n- `stream_management`: An instance of `StreamManagement`.\n- `demapping_method`: Indicates the demapping method used, where the choices are 'app' or 'maxlog'.\n- `num_iter`: Denotes the number of MMSE PIC iterations to perform, with a default value of 1.\n- `constellation_type`: Specifies the type of constellation applied, if not custom. It can be 'qam', 'pam', or 'None' with 'None' necessitating an associated instance of `Constellation`.\n- `num_bits_per_symbol`: The number of bits per constellation symbol, with the onus on the user to provide this parameter when 'constellation_type' is specified.\n- `constellation`: An instance of `Constellation` or 'None', with 'None' requiring 'constellation_type' and 'num_bits_per_symbol' to be provided.\n- `hard_out`: Indicates whether the detector produces hard-decided bit values or constellation point indices. It's set to 'False' by default.\n- `dtype`: Specifies the type of internal computations, with 'tf.complex64' as the default.\n\nThe function processes a received OFDM resource grid after cyclic prefix removal and FFT, and an estimation of the channel is assumed to be available for all streams from all transmitters. Prior information on the transmitted signals can be provided, and the function supports both detection and decoding operations with either bit or symbol outputs. After configuration, detection is performed by calling the function with the corresponding input.\n\nThe output of the function will be a batch of arrays containing LLRs (Likelihood Logarithm Ratios) or hard decisions for every bit of every stream if 'bit' is chosen as the output type, or LLRs or hard decisions for constellation symbols for every stream if 'symbol' is chosen. Hard decisions symbolize the chosen constellation symbol's index.\n\nBecause of the wrapper that is applied to make this function compatible with OFDM waveforms, it is recommended to not decorate this function with TensorFlow's `@tf.function` in 'Graph' mode or use 'XLA'. However, if it is necessary to do so, one may set `sionna.Config.xla_compat=true`."
"Here is the definition of RaisedCosineFilter: sionna.signal.RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/signal/filter.html#RaisedCosineFilter)\n\nsource code:\n```python\nclass RaisedCosineFilter(Filter):\n    # pylint: disable=line-too-long\n    r\"\"\"RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n\n    Layer for applying a raised-cosine filter of ``length`` K\n    to an input ``x`` of length N.\n\n    The raised-cosine filter is defined by\n\n    .. math::\n        h(t) =\n        \\begin{cases}\n        \\frac{1}{T} \\left(1 + \\cos\\left(\\frac{\\pi}{T}\\left(\\beta\\left(\\left|t\\right|\\,-\\,T\\right) + T\\right)\\right)\\right) ,\\qquad -T \\leq t \\leq T\\\\\n        \\frac{\\beta}{T^2} \\left(\\left|t\\right|\\,-\\,T\\right) \\sin\\left(\\frac{\\pi}{T}\\left(\\beta\\left(\\left|t\\right|\\,-\\,T\\right) + T\\right)\\right) ,\\qquad -2T < t < -T \\text{ and } T < t \\leq 2T\\\\\n        0, \\qquad \\text{otherwise}\n        \\end{cases}\n\n    where :math:`\\beta` is the roll-off factor and :math:`T` the symbol duration.\n\n    The filter length K is equal to the filter span in symbols (``span_in_symbols``)\n    multiplied by the oversampling factor (``samples_per_symbol``).\n    If this product is even, a value of one will be added.\n\n    The filter is applied through discrete convolution.\n\n    An optional windowing function ``window`` can be applied to the filter.\n\n    The `dtype` of the output is `tf.float` if both ``x`` and the filter coefficients have dtype `tf.float`.\n    Otherwise, the dtype of the output is `tf.complex`.\n\n    Three padding modes are available for applying the filter:\n\n    *   \"full\" (default): Returns the convolution at each point of overlap between ``x`` and the filter.\n        The length of the output is N + K - 1. Zero-padding of the input ``x`` is performed to\n        N + K - 1.\n    *   \"same\": Returns an output of the same length as the input ``x``. The convolution is computed such\n        that the coefficients of the input ``x`` are centered on the coefficient of the filter with index\n        (K-1)/2. Zero-padding of the input signal is performed to adjust for the lack of data at the borders\n        of the input.\n    *   \"valid\": Returns the convolution only at points where ``x`` and the filter completely overlap.\n        The length of the output is N - K + 1.\n\n    Parameters\n    ----------\n    span_in_symbols: int\n        Filter span as measured by the number of symbols.\n\n    samples_per_symbol: int\n        Number of samples per symbol, i.e., the oversampling factor.\n\n    beta : float\n        Roll-off factor.\n        Must be in the range :math:`[0,1]`.\n\n    window: Window or string ([\"hann\", \"hamming\", \"blackman\"])\n        Instance of :class:`~sionna.signal.analysis.Window` applied to the filter.\n        Alternatively, a string indicating the window name can be provided. In this case,\n        the chosen window will have the same `dtype` as the input `x`.\n        Defaults to `None`.\n\n    normalize: bool\n        If `True`, the filter is normalized to have unit power.\n        Defaults to `True`.\n\n    trainable: bool\n        If `True`, the filter coefficients are trainable.\n        Defaults to `False`.\n\n    dtype: tf.DType\n        The `dtype` of the filter coefficients.\n        Defaults to `tf.float32`.\n\n    Input\n    -----\n    x : [..., N], tf.complex or tf.float\n        The input to which the filter is applied.\n        The filter is applied along the last dimension.\n\n    padding : string ([\"full\", \"valid\", \"same\"])\n        Padding mode for convolving ``x`` and the filter.\n        Must be one of \"full\", \"valid\", or \"same\". Case insensitive.\n        Defaults to \"full\".\n\n    conjugate : bool\n        If `True`, the complex conjugate of the filter is applied.\n        Defaults to `False`.\n\n    Output\n    ------\n    y : [...,M], tf.complex or tf.float\n        Filtered input.\n        It is `tf.float` only if the filter and the input are both `tf.float`.\n        It is `tf.complex` otherwise.\n        The length M depends on the ``padding``.\n    \"\"\"\n    def __init__(self,\n                 span_in_symbols,\n                 samples_per_symbol,\n                 beta,\n                 window=None,\n                 normalize=True,\n                 trainable=False,\n                 dtype=tf.float32,\n                 **kwargs):\n        super().__init__(span_in_symbols,\n                         samples_per_symbol,\n                         beta,\n                         window=window,\n                         normalize=normalize,\n                         trainable=trainable,\n                         dtype=dtype,\n                         **kwargs)\n\n    @property\n    def _coefficients_source(self):\n        h = self._raised_cosine(self.sampling_times,\n                               self.span_in_symbols,\n                               self.beta,\n                               self.window,\n                               normalize=self.normalize)\n        return tf.constant(h, self.dtype)\n```"
"The PAM2QAM class in the 'sionna.mapping' module is a class that supports the transformation of Pulse Amplitude Modulation (PAM) symbol indices or logits to Quadrature Amplitude Modulation (QAM) symbol indices or logits. This class plays a significant role in improving the execution of the main code by avoiding the direct manipulation of indices or logits for PAM and QAM symbols.\n\nIts parameters include:\n- num_bits_per_symbol: This is an integer that represents the number of bits per QAM constellation symbol, for example, 4 for QAM16.\n- hard_in_out: This is a boolean value that determines if inputs and outputs are indices or logits over constellation symbols. By default, it is set to True.\n\nIts inputs are:\n- pam1: Indices or logits for the first PAM constellation.\n- pam2: Indices or logits for the second PAM constellation.\n\nIts output is:\n- qam: Indices or logits for the corresponding QAM constellation.\n\nUsing this class, you can transform PAM symbol indices or logits to QAM symbol indices or logits, making it easier to manage and execute various tasks related to PAM and QAM modulation in code."
"In the given context, a simple uplink scenario is described where four transmitters are sending streams to receivers for a 1x1 uplink situation. The `StreamManagement` class from the Sionna library is used to manage streams between transmitters and receivers in multi-cell MIMO networks.\n\nTo configure the `StreamManagement` for this scenario, you need to define the following:\n\n1. `num_tx` (int): This defines the number of transmitters. In the given context, the value is 4.\n\n2. `num_rx` (int): This defines the number of receivers. The value is 1 in the given context.\n\n3. `num_streams_per_tx` (int): This indicates the number of streams per transmitter, i.e., the number of antennas per transmitter. The context specifies a value of 1.\n\n4. `rx_tx_association` (np.zeros([num_rx, num_tx])): This binary NumPy array of shape `[num_rx, num_tx]` specifies the association between receivers and transmitters. A value of `1` means that a receiver will get one or multiple streams from the associated transmitter.\n\nYou can create a `StreamManagement` object by initializing it with the `rx_tx_association` and the number of streams per transmitter as shown in the context:\n\n```python\nsm = StreamManagement(rx_tx_association, num_streams_per_tx)\n```\n\nThis will create a `StreamManagement` object that is used to manage streams in the multi-cell MIMO network.\n\nPlease note that the actual values of `num_tx`, `num_rx`, and `num_streams_per_tx` will depend on the specific requirements of your MIMO network. The `rx_tx_association` array must be of the same shape as the one defined by `num_rx` and `num_tx`."
"A constellation is a set of signal points in signal space, organized in a 2^n array. In the context of higher order modulation, these points can correspond to different combinations of binary bit sequences. For example, in 16-QAM, there are 16 constellation points, each representing a unique 4-bit sequence.\n\nA bit-channel, on the other hand, refers to the mapping of bit sequences to constellation points. In a traditional 16-QAM setup, this would be a binary setup where we consider a real-valued representation. Here, the four bits are mapped to a [+ or -] pair of the first and second dimension of the constellation. \n\nIn the bit channel, an incoming bit sequence is translated into an individual symbol from the constellation. This involves a process of modulation at the transmitter and demodulation at the receiver. \n\nIn terms of receiving QAM higher - than-2-than conventional OQAM, the real and imaginary components of the frequency-shifted OQAM sequence correspond to even and odd numbered bits, respectively. A receiver implementing this parallel detection simply demodulates the received noisy samples into LLRs on the individual bit streams. \n\nIn the context provided, n higher order modulation, like 16-QAM, is visualized as a 2^4 array in 2D signal space. The real and imaginary components of the constellation points correspond to the four bit sequences of their binary representation."
"The PAM function in the Sionna mapping module generates a discrete constellation for use in mapping data to a constellation prior to modulation. The number of bits per symbol in the constellation, `num_bits_per_symbol`, is provided as an input. The function's output is a vector representing the constellation points.\n\nThe function takes the inputs specified by a user, including the number of bits per symbol (`num_bits_per_symbol`) and a boolean variable `normalize`, which defaults to True. If `normalize` is set to True, the constellation is normalized to have unit power.\n\nThe function generates a real-valued vector where each element is a constellation point of an M-ary PAM constellation. The bit label of the nth point is given by the length-`num_bits_per_symbol` binary representation of n.\n\nIt's important to note that the bit label of the constellation points is determined by the binary representation of their position within the array. This function uses a recursive implementation to express the normalization factor in closed-form and is consistent with 3GPP specifications.\n\nAn example usage of this function within Sionna would be the following:\n\n```python\nimport sionna\nconstellation = sionna.mapping.pam(num_bits_per_symbol=4, normalize=True)\n```\nIn this example, a 16-QAM constellation would be generated, with normalization applied.\n\nThe output of the function is the generated PAM constellation, represented as a vector. The generated constellation could then be used for modulation in further steps of the communication process."
"The \"List2LLR\" class in the Sionna package is used to compute LLRs (log-likelihood ratios) from a list of candidate vectors for a given constellation point. It is implemented as a Keras layer. \n\nAssumptions to fulfill when using the \"List2LLR\" class:\n\n1. All channels symbols are equally likely. This is a common assumption in the field of communications.\n\n2. The class assumes that the channel reliability values are obtained externally. The reliability values are provided as LLRs (log-likelihood ratios). \n\n3. The `List2LLR` class expects an input tensor `([batch_size, num_channel, num_codeword], num_candidate)`. The last dimension represents the candidate indices for the codeword decoding process.\n\n4. The class assumes that the `num_channel` channel values are the same for all codeword candidates.\n\n5. It is assumed that the codeword candidates are independent, which means that the LLRs for the entire codeword can be computed by aggregating the values from the individual candidates.\n\n6. The class also computes the LLRs for all codeword bits individually, assuming that they are statistically independent.\n\n7. The class makes use of the `list_size` parameter to prune weak candidates and reduce the computation complexity.\n\nThe \"List2LLR\" class generates LLRs using a process that is based on both the channel reliability information and the quality of the received samples. It uses a method from there existing list-decoder `list_decode` to compute the LLR for each bit position `i` in the codeword.\n\nPlease note that the `channel_llr` values are to be provided externally, and the `list_size` is an integer parameter that needs to be provided when creating an instance of the \"List2LLR\" class. The application must ensure that the input values meet the requirements of the \"List2LLR\" class as described in the provided context."
"The `MMSEPICDetector` class is part of the OFDM module within the Sionna package for wireless simulation. This class wraps the MIMO MMSE PIC detector for use with OFDM waveforms, with the functionality and parameters detailed below:\n\n**Functionality**: \nThe MIMO MMSE PIC (Successive Parano Minimum Mean Square Error with Interference Cancellation) detector is suitable for OFDM (Orthogonal Frequency-Division Multiplexing) systems. It can compute either soft-decisions or hard-decisions for symbols or bits. The detector processes the received resource grid `y` after cyclic prefix removal and FFT, and computes the detection output based on the OFDM and stream configuration provided by a `ResourceGrid` and `StreamManagement` instance, respectively. The type of detection (soft or hard) is configured by the `output` parameter. The detector uses the channel estimate `h_hat` and resource grid `y` to produce its output. Prior a estimates for the transmitted signals can also be provided through either LLRs of the transmitted bits or logits of the transmitted constellation points.\n\n**Parameters**:\nThe MMSEPICDetector class accepts the following parameters: \n\n- `output`: Type of output, either \"bit\" (bits) or \"symbol\" (symbols). This parameter determines whether soft- or hard-decsions are produced.\n- `resource_grid`: An instance of `ResourceGrid`.\n- `stream_management`: An instance of `StreamManagement`.\n- `demapping_method`: Demapping method used, either \"app\" or \"maxlog\". Default is \"maxlog\".\n- `num_iter`: Number of MMSE PIC iterations. Default is 1.\n- `constellation_type`: Type of constellation used, if custom constellation is applied, its type should be specified, options are \"qam\", \"pam\", or \"custom\". For \"custom\", an instance of `Constellation` must be provided.\n- `num_bits_per_symbol`: Number of bits per constellation symbol, e.g., 4 for QAM16. Required if `constellation_type` is qam or pam.\n- `constellation`: Instance of `Constellation` or None. If None, `constellation_type` and `num_bits_per_symbol` must be provided.\n- `hard_out`: If True, the detector computes hard-decided bit values or constellation point indices instead of soft-values. Default is False.\n- `dtype`: The datatype of `y`. Defaults to tf.complex64. The output data type is determined by the `dtype`.\n\n**Conditions for Use**:\nThis class is utilized under the condition of creating an instance of `ResourceGrid` and `StreamManagement`. It is especially used in MIMO OFDM system simulations to handle the detection of streams. However, to use this class, it is recommended to disable Graph mode with XLA within the function where this class is utilized, as the performance may be impacted."
"The `QAM2PAM` class is a part of the `sionna.mapping` module and is used to transform QAM (Quadrature Amplitude Modulation) symbol indices to PAM (Pulse Amplitude Modulation) symbol indices. The class takes the number of bits per QAM symbol as an input parameter, such as 4 for QAM16.\n\nThe class expects indices in a pre-defined QAM constellation, typically ranging from 0 to 15 for QAM16. Upon receiving QAM symbol indices, the `QAM2PAM` class computes the corresponding indices for the two PAM constellations that represent the real and imaginary components of the QAM constellation.\n\nThe output of the `QAM2PAM` class is a tuple of two elements, `ind_pam1` and `ind_pam2`, which contain the PAM symbol indices for the two PAM constellations respectively.\n\nThe way in which the class performs the transformation is not detailed in the provided context and would require review of the class implementation, which is not available in the context."
"To use the `verify_gm_pcm` function from the Sionna package to verify that the generator matrix and parity-check matrix are orthogonal in GF(2), you need to pass the generator matrix and parity-check matrix as input arguments to the function.\n\nHere is the step-by-step process:\n\n1. First, import the required functions from the Sionna package.\n\n```python\nfrom sionna.fec.utils import load_parity_check_examples, verify_gm_pcm\n```\n\n2. Load example generator and parity-check matrices. These matrices should be in binary format.\n\n```python\ngm, pcm, k, n = load_parity_check_examples('pcm_id_5') # Here 'pcm_id_5' is an example identifier for a parity-check matrix\n```\n\n3. Use the `verify_gm_pcm` function to confirm that the generator and parity-check matrices are orthogonal in GF(2). This function returns a boolean `True` if the matrices are orthogonal, and `False` otherwise.\n\n```python\nresult = verify_gm_pcm(gm, pcm)\n```\n\n4. Finally, print the result.\n\n```python\nprint(result)\n```\n\nThe function `load_parity_check_examples` is used to load the generator and parity-check matrices of some well-known codes. In this example, the 'pcm_id_5' is used as an example identifier to load a specific parity-check matrix. However, the function `verify_gm_pcm` is not code specific and can be used with any generator and parity-check matrices.\n\nPlease make sure that the binary files `gm` and `pcm` represent the generator and parity-check matrices of a linear binary code, respectively. The function will verify that the matrices are orthogonal, which is an important property in binary linear codes for efficient encoding and decoding. If the matrices are not orthogonal, it may lead to non-trivial cycles in the code and can result in encoding and decoding errors."
"To import the `LinearEncoder` class from the `sionna.fec.linear` module, you would use the following line of Python code:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n```\n\nThis statement would allow you to make use of the `LinearEncoder` class which is designed for binary encoding using either a generator or parity-check matrix. Please note that the context indicates various properties that can be accessed once you have instantiated an `LinearEncoder` object, such as the generator matrix (`gm`), the code rate (`coderate`), the number of information bits (`k`), and the codeword length (`n`)."
"The `OFDMDetectorWithPrior` class is part of Sionna's novel Python package designed for simulating wireless communication at different levels. This class is primarily used for detecting signals transmitted with an Orthogonal Frequency-Division Multiplexing (OFDM) waveform, assuming prior knowledge of the bits or constellation points is available. Detection can be configured for either bits or symbols, and for either soft- or hard-decisions.\n\nKey parameters of the `OFDMDetectorWithPrior` class include a callable detection function (`detector`), which is typically a MIMO detection algorithm implemented as a function, the output type ('bit' or 'symbol'), the OFDM and stream configuration, the constellation type and number of bits per symbol, and the data type. The callable detection function takes the received signals, the channel estimates, and the prior knowledge as input, and produces LLRs (log-likelihood ratios) or hard decisions on the transmitted bits or symbols.\n\nThe class preprocesses the received resource grid (`y`), the channel estimate (`h_hat`), and the prior information (`prior`). It also computes the noise-plus-interference covariance matrix for each receiver, taking into account the OFDM and stream configuration and the estimation error variance (`err_var`). These steps are performed before calling the detection function. The detection function itself is used to carry out the core detection computation, as it implements the algorithm that recovers the signal.\n\nThe class can be used with various types of OFDM and stream configurations, and can accommodate arbitrary batch dimensions. Its flexibility and adaptability make it a suitable component in simulations and algorithms that require the detection of signals transmitted with Orthogonal Frequency-Division Multiplexing."
"The function `bin2int_tf` from the \"sionna.fec.utils\" module is used to convert a binary tensor into an integer tensor. The binary representation is across the last dimension from most significant to least significant.\n\nThe function takes as input a tensor, `arr`, of integers or floats that consist of only 0s and 1s. This tensor represents the binary form of an integer, with each element in the tensor corresponding to a bit in the binary representation, from the most significant bit (leftmost) to the least significant bit (rightmost).\n\nThe function outputs an integer tensor, `arr_int`, that represents the decimal form of the integer equivalent to the binary pattern represented by `arr`. The output tensor's elements correspond to decimal bits, with the first element being the most significant bit and the last element being the least significant bit.\n\nA citation in the documentation wasn't provided. However, based on the function's implementation, it can be inferred that it uses a straightforward binary to decimal conversion approach. The function treats the first element in the input tensor as the most significant bit and the last as the least significant bit, similar to how an integer would be represented in base-10 numeric systems. It's important to highlight that the function performs this conversion on a type of tensor referred to as `tf.int32` in the documentation, using TensorFlow's built-in functionality for handling such tensors."
"To enable 5G NR compliant scrambling using the `TB5GScrambler`, you need to set up an instance of the scrambler by providing the parameters defined in the 3GPP TS 38.211 specification. Here's a general way of using the `TB5GScrambler`:\n\nFirst, you need to import the required classes from the `sionna.fec.scrambling` module:\n\n```python\nfrom sionna.fec.scrambling import TB5GScrambler, Descrambler\n```\n\nThen, you set up an instance of the scrambler by specifying whether you want to flip bits (binary operations) or signs (soft-value/LLR domain-based operations). You also specify whether you want the 5G NR compliant version:\n\n```python\nscrambler = TB5GScrambler(binary=True, # set to False if you want soft-value scrambling\n                        nr=true) # set to True to enable 5G NR compliant scrambling\n```\n\nNote that `binary` is set to `True` and `nr` is set to `True` in this example.\n\nAfter setting up the scrambler, you can set up a corresponding descrambler. The descrambler uses the scrambler instance, so it doesn't need to be configured separately:\n\n```python\ndescrambler = Descrambler(scrambler=scrambler)\n```\n\nNow, you can use the scrambler with a given input sequence `c`. If you want to provide an explicit random seed for each call, you can generate it using TensorFlow's random utility functions:\n\n```python\nimport tensorflow as tf\ns = tf.random.uniform((), minval=0, maxval=12345678, dtype=tf.int32) # define the seed\nc_scr = scrambler([c, s])\n```\n\nTo descramble the scrambled sequence and reconstruct the original order, you can use the descrambler with the scrambled sequence:\n\n```python\nc_descr = descrambler([c_scr])\n```\n\nPlease note that `c` is your arbitrary input sequence to the scrambler. It should be a binary sequence if you've set `binary=True`, or otherwise, it should be a soft-value sequence. The seed `s` is chosen randomly within the specified range on each call."
"Source code link:  [int_mod_2](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#int_mod_2)  \n\ninp = tf.cast(inp, dtype=tf.int32) # Cast to int, as required by tf.math.mod  \nout = tf.cast(tf.math.mod(inp, 2), dtype=inp.dtype) \n\n### Input\n\n- `x` (*tf.Tensor*) -- Tensor to which the modulo 2 operation is applied.\n\n### Output\n\n- `out` (*x.dtype*) -- Result of the modulo-2 operation. The output datatype is the same as the input dtype.\n\nsource code:\n```python\ndef int_mod_2(x):\n    r\"\"\"\n    Efficient implementation of modulo 2 operation for integer inputs.\n\n    This function assumes integer inputs or implicitly casts to int.\n\n    Remark: the function :meth:`~tf.math.mod` is placed on the CPU and, thus,\n    causes unnecessary memory copies.\n\n    Parameters\n    ----------\n    x : tf.Tensor\n        ``Tensor`` to which the modulo 2 operation is applied.\n\n    Returns\n    -------\n    : tf.DType\n        Result of the modulo-2 operation.\n        The output datatype is the same as the input dtype.\n    \"\"\"\n\n    inp = tf.cast(x, dtype=tf.int32)  # Cast to int, as required by tf.math.mod\n    out = tf.cast(tf.math.mod(inp, 2), dtype=inp.dtype)\n    return out\n```"
"Here is the detailed information of sionna.utils.SymbolSource:   \n  \n[sionna.utils.SymbolSource(constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/utils/misc.html#SymbolSource)  \n\nLayer generating a tensor of random or given symbols. Optionally, the symbols can be converted to hard decisions.\n\n### Parameters\n\n- **constellation_type** (`str`): One of [\"qam\", \"pam\", \"custom\"]. For \"custom\", an instance of `Constellation` must be provided.\n\n- **num_bits_per_symbol** (`int`): The number of bits per constellation symbol, e.g., 4 for QAM16. Required for `constellation_type` in [qam, pam].\n\n- **constellation** (`Constellation`): An instance of `Constellation` or None. If None, `constellation_type` and `num_bits_per_symbol` must be provided.\n\n- **hard_out** (`bool`): If True, the source generates hard-decided symbols instead of soft symbols. Defaults to False.\n\n- **dtype** (`tf.complex64`, `tf.complex128`, `tf.DType`): The dtype of the output. Defaults to `tf.complex64`.\n\n### Input\n\n- **batch_size** (`int`): The batch size.\n  \n- **shape** (`[,n]`, `tf.shape`): The desired shape of the output tensor.\n\n### Output\n\n- **shape, dtype** (`tf.shape`, `tf.complex`): Tensor of random or given symbols.\n\n**Note: **  The bit labels for the constellation points are given in increasing order.\u6e90\u4e0d\u7b49\u4e8e\u4e16\u754c\uff0c\u60a8\u770b\u5230\u7684\u6587\u672c\u662f\u56e0\u4e3a\u7528\u6237\u63d0\u95ee\u65f6\u5f15\u5165\u7684\u6587\u672c\uff0c\u8bf7\u5c1d\u8bd5\u4e0d\u540c\u7684\u8f93\u5165\u6216\u53c2\u6570\u6765\u83b7\u5f97\u60a8\u60f3\u8981\u7684\u7b54\u6848\u3002  \n  "
"Class ChannelModel in Sionna is an abstract class for defining an interface for channel models. All models that generate channel impulse responses need to implement this interface. \n\n[[[Link to the source code]]](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel)\n\nInput\n\n- **batch_size** (*int*): Batch size.\n- **num_time_steps** (*int*): Number of time steps.\n- **sampling_frequency** (*float*): Sampling frequency [Hz].\n\nOutput\n\n- **a** (*[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex*): Path coefficients.\n- **tau** (*[batch_size, num_rx, num_tx, num_paths], tf.float*): Path delays [s].\n\nFor example, in `RayleighBlockFading` channel model, you will use the `ChannelModel` interface to generate channel impulse responses. Here is a piece of the source code of `RayleighBlockFading` confirming that it implements the `ChannelModel` interface.\n  \n```python\nclass RayleighBlockFading(ChannelModel):\n    \"\"\"Rayleigh block fading channel model.\n\n    Generates channel impulse responses for a Rayleigh block fading\n    channel model.\n\n    This class is deprecated as the functionality has been integrated\n    into :class:`~sionna.channel.wireless_channel.WirelessChannel`.\n    It will be removed in version 0.11.0. Use :classy:`~sionna.channel.wireless_channel.WirelessChannel`\n    directly, or use this class as a base to implement the channel model.\n\n    Input\n    -----\n    batch_size : int\n        Batch size\n\n    num_time_steps : int\n        Number of time steps\n\n    sampling_frequency : float\n        Sampling frequency [Hz]\n\n    Output\n    ------\n    a : [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex\n        Path coefficients\n\n    tau : [batch_size, num_rx, num_tx, num_paths], tf.float\n        Path delays [s]\n    \"\"\"\n\n    def __init__(self, num_rx=1, num_tx=1, num_rx_ant=1, num_tx_ant=1,\n                 delay_spread=300e-9, carrier_frequency=3.5e9,\n                 num_paths=1, random_scp_pos=True, los=False,\n                 dtype=tf.complex64):\n\n        super().__init__(batch_size, num_rx, num_tx, num_rx_ant, num_tx_ant,\n                         num_paths, num_time_steps, dtype, **kwargs)\n        self.los = los\n        self.random_scp_pos = random_scp_pos\n        self.delay_spread = delay_spread\n        self.carrier_frequency = carrier_frequency\n\n        # Setting up optimizer\n        if self.random_scp_pos:\n            self.scattering_center_pos = tf.Variable(\n                                    initial_value=tf.zeros([self.batch_size,\n                                                        self.num_rx,\n                                                        self.num_tx,\n                                                        num_paths,\n                                                        3],\n                                                        dtype=tf.float32),\n                                    dtype=tf.float32)\n        else:\n            self.scattering_center_pos = tf.zeros([self.batch_size,\n                                                self.num_rx, self.num_tx,\n                                                num_paths, 3], dtype=tf.float32)\n        self.scattering_center_pos._trainable = False\n        if self.los:\n            # The Rayleigh model is assumed to be in the perfect rate\n            # convergence state and the cm_pos does only depend on the\n            # direction\n            self.cm_pos = tf.Variable(initial_value=tf.zeros([self.batch_size,\n                                                self.num_rx, self.num_tx, 1, 3],\n                                                dtype=tf.float32),\n                dtype=tf.float32)\n        else:\n            self.cm_pos = tf.Variable(tf.random.uniform([self.batch_size,\n                                                self.num_rx, self.num_tx,\n                                                num_paths, 3],\n                                                minval=-1., maxval=1.,\n                                                dtype=tf.float32),\n                dtype=tf.float32)\n        self.cm_pos._trainable = False\n\n    @property\n    @abstractmethod\n    def los(self):\n        \"\"\"If `True`, returns `True` if the channel is in line of sight, `False`\n        otherwise.\"\"\"\n        return self._los\n\n    @property\n    @abstractmethod\n    def delay_spread(self):\n        \"\"\"The RMS delay spread [s] (see :cite:`3GPP.38.901`)\"\"\"\n        return self._delay_spread\n\n    @delay_spread.setter\n    @abstractmethod\n    def delay_spread(self, value):\n        pass\n\n    @property\n    @abstractmethod\n    def num_paths(self):\n        \"The number of paths generated\"\n        return self._num_paths\n\n    @property\n    def random_scp_pos(self):\n        \"\"\"If `True` the position of scattering centers is randomly\n        generated, `False` the position of scattering centers is fixed\"\"\"\n        return self._random_scp_pos\n\n    @random_scp_pos.setter\n    def random_scp_pos(self, value):\n        self._random_scp_pos = value\n        if self._random_scp_pos:\n            self.scattering_center_pos._trainable = True\n        else:\n            self.scattering_center_pos._trainable = False\n\n    @property\n    @abstractmethod\n    def scattering_center_pos(self):\n        \"\"\"\n        The position of the scattering centers\n\n        - If the channel is in line of sight, there is only one scattering\n          center set to the position of the transmitter and receiver\n        - If the channel is not in line of sight, multiple scattering centers\n          can be defined\n          (see position of `n_sct_samples` scattering centers)\n        \"\"\"\n        return self._scattering_center_pos\n\n    @scattering_center_pos.setter\n    def scattering_center_pos(self, value):\n        if value is not None:\n            self._scattering_center_pos = value\n        else:\n            self._scattering_center_pos = tf.zeros([self.batch_size,\n                                        self.num_rx, self.num_tx, self.num_paths, 3],\n                                        dtype=tf.float32)\n\n    @property\n    @abstractmethod\n    def los(self):\n        \"\"\"If `True`, the channel is in line-of-sight. If `False`, it is not.\"\"\"\n        return self._los\n\n    @los.setter\n    def los(self, value):\n        self._los = bool(value)\n        if self._los:\n            # If the channel is in LoS, there is only one scattering center\n            # corresponding to the position of the transmitter and receiver\n            self.scattering_center_pos = (0.5*(self.scattering_center_pos[...,:2]\n                                          + self.tx_pos -\n                                          self.rx_pos))\n            if self.random_scp_pos:\n                self.scattering_center_pos._trainable = False\n        else:\n            self.scattering_center_pos._trainable = True\n            # If the channel is not in LoS, the scattering center position\n            # can be independent for each link\n            if self.random_scp_pos:\n                self.scattering_center_pos._trainable = True.\n                # The following line is to avoid that the non-line-of-sight\n                # position of scattering centers depends on the orientation\n                # of the transmitter and receiver which can be randomly set\n                # when creating a batch of channels.\n                # The receiver is assumed to point towards (+x,0,0).\n                self.scattering_center_pos -= self.rx_pos\n                if self._scattering_center_pos._trainable == False:\n                    self.scattering_center_pos._trainable = True\n        self._los = value\n\n    @property\n    @abstractmethod\n    def rx_pos(self):\n        \"Position of the receiver\"\n        raise NotImplementedError(\"Please implement this property in a \\\n        concrete class\")\n\n    @property\n    @abstractmethod\n    def tx_pos(self):\n        \"Position of the transmitter\"\n        raise NotImplementedError(\"Please implement this property in a \\\n        concrete class\")\n\n    @property\n    @abstractmethod\n    def ind_los(self):\n        \"\"\"Generates an index tensor for retrieving only the LoS paths from\n        the generated samples.\n\n        Output\n        -------\n        ind_los : [batch_size, num_rx, num_tx, num_paths], tf.bool\n            Tensor of indices for LoS paths. A path with index `i`\n            is a LoS path if `ind_los[...,i]` is `True`.\n        \"\"\"\n        raise NotImplementedError(\"To be implemented in a concrete class.\")\n```"
"To build a custom `RadioMaterial` in the `Sionna` package, you can create a class callback in Python that calculates the material properties `(\u03b5, \u03c3)` from the frequency and then use this callback function when initializing your `RadioMaterial`. The `RadioMaterial` is designed to have material properties that are trainable variables, similar to how you would define the parameters of a Keras model.\n\nHere are the general steps:\n\n1. Define a callback function that calculates the material properties from the frequency:\n\n```python\ndef my_material_callback(f_hz):\n   relative_permittivity = compute_relative_permittivity(f_hz)\n   conductivity = compute_conductivity(f_hz)\n   return (relative_permittivity, conductivity)\n```\n\n2. Specify the material properties as trainable variables:\n\n```python\nrelative_permittivity = tf.Variable(2.0, dtype=tf.float32)\nconductivity = tf.Variable(5.0, dtype=tf.float32)\n```\n\n3. Use the callback function and the defined trainable variables to initialize the `RadioMaterial`:\n\n```python\ncustom_material = RadioMaterial(\"my_material\",\n                                relative_permittivity=relative_permittivity,\n                                conductivity=conductivity,\n                                frequency_update_callback=my_material_callback)\n```\n\nIn the `Sionna` package, you attach a `RadioMaterial` to a `SceneObject` using the `radio_material` property of the `SceneObject`. If the `RadioMaterial` is not already part of the scene, you add it using the `add` method of the `Scene`. Here is how you would do it:\n\n1. Get the `SceneObject` you want to attach the `RadioMaterial` to:\n\n```python\nobj = scene.get(\"my_object\") # obj is a SceneObject\n```\n\n2. Attach the `RadioMaterial` to the `SceneObject`:\n\n```python\nobj.radio_material = custom_material # \"my_object\" is made of \"my_material\"\n```\n\nThe custom `RadioMaterial` is now attached to the `SceneObject` named `my_object`. You can verify this by rendering the scene or checking the `radio_material` property of the `SceneObject`.\n\nPlease note that the `frequency_update_callback` is expected to return the relative permittivity and conductivity. The `compute_relative_permittivity` and `compute_conductivity` functions are not defined in your provided context and would need to be added based on the requirements of your simulation."
"To perform maximum a posteriori (MAP) decoding using a `BCJRDecoder` instance from the Sionna package, you need to create an instance of the decoder with the appropriate configuration, then call it with the appropriate input.\n\nFirst, create an instance of the decoder. Since the context does not provide an instance of the `BCJRDecoder`, you can use the following configuration to create one with the rate and constraint length provided by the context:\n\n```python\nfrom sionna.fec.conv import BCJRDecoder\ndecoder = BCJRDecoder(encoder=encoder, hard_out=False, algorithm='map')\n```\n\nWhere `encoder` is an instance of `ConvEncoder` used in the encoding process, `hard_out=False` indicates that soft estimates of the decoded bits will be produced, and `algorithm='map'` indicates that the MAP algorithm should be used.\n\nThe input to the decoder can be either a single tensor `llr_ch` containing channel LLRs, or a tuple `(llr_ch, llr_a)` containing channel LLRs and apriori information. If apriori information is given, it should be provided in `llr_a` which is an tensor of shape `[, k]` holding the apriori information of each information bit, where `k` is the number of information bits.\n\nTo call the decoder, you would use something like:\n\n```python\ndecoded_bits = decoder(llr_ch)\n```\n\nor\n\n```python\ndecoded_bits = decoder((llr_ch, llr_a))\n```\n\nThe type of `decoded_bits` is simply a tensor of type `tf.float32` (the default), and its shape is `[, n]` where `n` is the codeword length. This parameter is not affected by the `hard_out` flag and represents the estimated information bits after decoding. If `hard_out=True` was used, the output would be hard-decided bits (i.e., binary values 0 or 1), and the shape would be `[, n]`.\n\nRemember that the actual tensors to be used in the decoding process need to be in the appropriate shape and type as expected by the Sionna package. If the input `llr_ch` is, for example, a tensor of LLR values coming from a different source, it may need to be transformed or processed to meet the specific requirements of the Sionna package."
"To use the `ebnodb2no` function, you need to understand the meaning of the input parameters and how they relate to the quantity you want to compute (noise variance `No`).\n\nInput parameters:\n1. `ebno_db` (float): This is the Eb/No value in dB. Eb/N0 is the energy per bit to noise power spectral density ratio. This means the energy of the transmitted signal per information bit and the power spectral density of the noise.\n\n2. `num_bits_per_symbol` (int): This is the number of bits per constellation symbol. For example, in a 16-QAM constellation, you would set this parameter to 4.\n\n3. `coderate` (float): This is the coderate used. It is the ratio of the number of information bits (including linear/incremental parity check (L/I) interleaver if used) to the total number of bits in the codeword.\n\n4. `resource_grid` (ResourceGrid): This is an optional parameter. It is an instance of `ResourceGrid` and is used to account for the scaled average energy per resource element compared to the energy per symbol. Also, it can account for the number of transmitted streams, the energy overhead carried by the pilots, and the energy carried in the cyclic prefix.\n\nThe function returns the value of `No` as a float. The return value is determined according to the given Eb/No value, the number of bits per symbol, and the coderate. The noise variance `No` is computed according to the expression provided in the documentation, taking into account the parameters related to the OFDM transmissions, such as the cyclic prefix and pilots.\n\nNow, let's see how to use the function. You would typically call the function with the required parameters, e.g.:\n\n```python\nimport sionna\n# Assuming you have created a 'rg' ResourceGrid instance\nno = sionna.utils.ebnodb2no(ebno_db=10.0,\n                            num_bits_per_symbol=rg.num_bits_per_symbol,\n                            coderate=1/2,\n                            resource_grid=rg)\n```\n\nIn this snippet, `ebno_db` is the specified Eb/No value, `num_bits_per_symbol` is the number of bits per constellation symbol, and `coderate` is the coderate. The `resource_grid` parameter is optional and would be included if you're working with OFDM transmissions and need to take into account the pilots, streams, and energy overhead.\n\nThe function will return the noise variance `No` that is computed according to the provided parameters. You would use this noise variance in your further computations or simulations."
"To evaluate the baseline and the two autoencoder-based communication systems, the following steps are performed in the provided context:\n\n1. **Baseline Evaluation**: The baseline model is evaluated by simulating the bit error rate (BER) and block error rate (BLER) of the system using the `sim_ber` function. The function takes various parameters such as the model, the EbNo range, batch size, number of target block errors, and maximum number of Monte Carlo iterations. The function runs the model for each EbNo value until the number of target block errors is reached or the maximum number of iterations is reached. The results are stored in a dictionary `BLER` with the key 'baseline'.\n\n2. **Autoencoder-based Communication Systems**: Two autoencoder-based communication systems are evaluated in a similar manner. The first system is trained with conventional backpropagation using the baseline model. The second system is trained with reinforcement learning (RL). The function `load_weights` is used to load the weights of the trained model, and the `sim_ber` function is used to evaluate the systems. The results are stored in the `BLER` dictionary with keys 'autoencoder-conv' and 'autoencoder-rl'.\n\nPlease note that the `sim_ber` function is not directly provided in the context and has been inferred from the usage in the context itself. If there are any additional parameters or functionalities in the actual `sim_ber` function, they would need to be included in the function's description.\n\nThe `BLER` dictionary is then saved in a file using the `pickle.dump` function.\n\n3. **Testing the Stored Model Weights**: After saving the weights of the trained models, the `sn_scratch` class from the Sionna package is used to test the stored weights. The class takes parameters such as the model, the file containing the weights, the batch size, and the number of samples. The class defines a `call` function that runs the model with the loaded weights and returns the output. The function `unpack_npy` is used to retrieve the stored weights.\n\n4. **Comparing the Performance of Different Models**: The performance of the different models can be evaluated by running the corresponding  `sim_ber` function and examining the resulting BLER and BER values.\n\nPlease note that the exact implementation details of the `sim_ber` function, the `load_weights` function, the `pickle.dump` function, and the `sn_scratch` class are not provided in the context. The description here is based on the inferred use from the context."
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can use the TensorFlow library. \n\n1. Import the necessary libraries:\n```python\nimport tensorflow as tf\n```\n\n2. Specify the GPU number you want to use. If you want to use the CPU, you can set the `gpu_num` variable to an empty string.\n```python\ngpu_num = 0 # Use \"\" to use the CPU\n```\n\n3. Set the `CUDA_VISIBLE_DEVICES` environment variable to the GPU number you want to use. This variable controls which GPUs will be visible to CUDA applications when they are run.\n```python\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n```\n\n4. Set the TensorFlow configuration to allocate only as much memory as needed. This can be done by listing the physical devices available for TensorFlow, and if any GPUs are found, setting the memory growth for the first GPU. `tf.config.experimental.set_memory_growth` attempts to allocate only as much GPU memory as needed for the runtime allocations.\n```python\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\nIn the code above, `tf.config.list_physical_devices('GPU')` is used to list the names of all available GPU devices, and `tf.config.experimental.set_memory_growth(gpus[0], True)` is used to enable memory growth for the specified GPU."
"To use the \"j_fun\" function in the Sionna package to calculate the J-function, you can follow these steps:\n\n1. Import the necessary function from the sionna package.\n\n```python\nfrom sionna.fec.utils import j_fun\n```\n\n2. Define the mean value of the LLR distribution as a float or an ndarray of floats.\n\n```python\nmu = 0.5 # or mu = [0.5, 1.0, 1.5, 2.0]\n```\n\n3. Call the \"j_fun\" function with the defined mean value as the argument.\n\n```python\nj = j_fun(mu)\n```\n\nThe \"j_fun\" function accepts a float or an <cite>ndarray</cite> of floats as an argument and returns a <float> as an <cite>ndarray</cite> of the same shape as the input."
"Here is the definition of PUSCHTransmitter: sionna.nr.PUSCHTransmitter(pusch_configs, return_bits=True, output_domain='freq', dtype=tf.complex64, verbose=False, **kwargs)  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/nr/pusch_transmitter.html#PUSCHTransmitter)  \n```python\n#\n# SPDX-32 files should include a \"generator\" field which refers\n# to the source code generator used, in this case \"picodom_nr\".\n# The context \"Sionna\" should be defined.\n# The file should include a \"license\" which refers to the SPDX license.\n#\n# SPDX license\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Layer, Reshape\nimport numpy as np\nfrom sionna.mimo import StreamManagement\nfrom sionna.utils import expand_to_rank, split_dim, flatten_last_dims\nfrom sionna import __version__\nfrom sionna.rt import PUSCHArray\nfrom scipy.special import erfc\nfrom scipy.fft import fft, ifft\n\nPING_VERSION = __version__\n\n# This coefficient allows to compute the complementary\n# cumulative distribution function (CCDF) of Gaussian distributed\n# signals with given variance through a simple scaling operation.\n# The CCDF is obtained by: 1 - Pr{X <= x} = 1 - Pr{X > x}\n# Hence, the CCDF can be directly computed by: 1 - Pr{X > x}\n# We further account for the normalization per complex dim = 2 by the\n# scaling coefficient 0.5.\n# These considerations result in the following scaling coefficient:\nSCALING_COEFFICIENT = 0.5\n\ndef Q(x):\n    \"\"\"Compute the Q-function (Gaussian tail function) for x\"\"\"\n    return erfc(x/np.sqrt(2.0))\n\nclass PUSCHTransmitter(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"PUSCHTransmitter(pusch_configs, return_bits=True, output_domain=\"freq\", dtype=tf.complex64, verbose=False, **kwargs)\n\n    This class generates batches of 5G NR PUSCH slots for multiple transmitters\n    with random or provided payloads. Frequency- or time-domain outputs can be generated.\n\n    It combines multiple processing blocks into a single layer\n    as shown in the following figure. Blocks with dashed lines are\n    optional and depend on the configuration.\n\n    .. code-block:: ASCII\n\n            Information bits $\\mathbf{b}$ that are either randomly generated or\n            provided as input are encoded into a transport block by the :class:`TBEncoder`.\n            The encoded bits are then mapped to QAM constellation symbols by the :class:`Mapper`.\n            The :class:`LayerMapper` splits the modulated symbols into different layers\n            which are then mapped onto OFDM resource grids by the :class:`ResourceGridMapper`.\n            If precoding is enabled in the :class:`PUSCHConfig`, the resource grids\n            are further precoded so that there is one for each transmitter and antenna port.\n            If ``output_domain`` equals `time`, the resource grids are further\n            precoded in the :class:`OFDMModulator`.\n\n            .. figure:: ../figures/pusch_transmitter.png\n                :align: center\n\n\n    Parameters\n    ----------\n    pusch_configs : PUSCHConfig or list of PUSCHConfig\n        5G NR PUSCH configuration. One configuration is required for each transmitter.\n\n    return_bits : bool\n        If set to `True`, the layer generates random information bits\n        to be transmitted and returns them together with the transmit signal.\n        Defaults to `True`.\n\n    output_domain : One of [\"freq\", \"time\"]\n        Domain of the output signal. Defaults to \"freq\".\n\n    dtype : tf.Dtype\n        Defaults to `tf.complex64`. Defines the data type for the\n        input and output of the layer.\n\n    verbose : bool\n        If set to `True`, additional parameters are printed.\n        Defaults to `False`.\n\n    Input\n    -----\n    batch_size : int\n        Batch size\n\n    Output\n    -------\n    x : [batch size, num_tx, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex or [batch size, num_tx, num_tx_ant, num_time_samples], tf.complex\n        Transmit signal in either frequency or time domain, depending on  ``output_domain``.\n\n    b : [batch_size, num_tx, tb_size], tf.float\n        Transmitted information bits.\n        Only returned if ``return_bits`` is set to `True`.\n\n    Example\n    --------\n    >>> pusch_transmitter = PUSCHTransmitter(pusch_configs)\n    >>> x, b = pusch_transmitter(16)\n\n    \"\"\"\n\n    def __init__(self,\n                 pusch_configs,\n                 return_bits=True,\n                 output_domain=\"freq\",\n                 dtype=tf.complex64,\n                 verbose=False,\n                 **kwargs):\n\n        super().__init__(dtype=dtype, **kwargs)\n\n        assert output_domain in (\"freq\", \"time\"), \\\n        \"Output_domain must be 'time' or 'freq'\"\n        self._output_domain = output_domain\n\n        self._return_bits = return_bits\n\n        # If list of pusch_configs, then create a PUSCHArray\n        if isinstance(pusch_configs, list):\n            self.pusch_configs = PUSCHArray(pusch_configs)\n        else:\n            self.pusch_configs = [pusch_configs]\n\n        # Check that all pusch_configs have the same batch_shape\n        for pusch_config in self.pusch_configs:\n            assert pusch_config.batch_shape == self.pusch_configs[0].batch_shape\n\n        self._num_tx = len(self.pusch_configs)\n\n        if self._return_bits:\n            # Random initialization of transmit symbol and info bit\n            self._init_b = tf.random.uniform(shape=[1, self._num_tx] + list(self.pusch_configs[0].tb_config.tb_size),\n                                            minval=0, maxval=2,\n                                            dtype=tf.int32)\n        else:\n            self._init_b = None\n\n        # Create TBEncoder\n        self._tb_encoder = TBEncoder(self.pusch_configs[0].tb_config)\n\n        # Create Mapper\n        if self.pusch_configs[0].num_layers > 1:\n            self._layer_mapper = LayerMapper(\"TDC\", self.pusch_configs[0].num_layers)\n\n        # Reshape the DMRS so that it can be multiplied element-wise to the\n        # transmit signal\n        self._dmrs_grid = self.pusch_configs[0].resource_grid.dmrs.w\n        shape = [1,1,1,self._dmrs_grid.shape[0], self._dmrs_grid.shape[1]]\n        self._dmrs_grid = np.reshape(self._dmrs_grid, shape)\n\n        # Create ResourceGridMapper\n        self._resource_grid_mapper = ResourceGridMapper(self.pusch_configs[0].resource_grid)\n\n        # Precoding will be done after OFDM modulation\n        if self.pusch_configs[0].precoding:\n            self._stream_management = StreamManagement(self.pusch_configs[0].precoding.stream_config)\n\n        # Things to be done if output_domain equals \"time\"\n        if self._output_domain==\"time\":\n            # Create PUSCHArray\n            self._pusch_array = PUSCHArray(self.pusch_configs)\n\n            # OFDM Modulator\n            fft_size = self.pusch_configs[0].resource_grid.num_subcarriers\n            subcarrier_spacing = self.pusch_configs[0].resource_grid.subcarrier_spacing\n            self._ofdm_modulator = OFDMModulator(fft_size, subcarrier_spacing)\n\n    def call(self, inputs):\n        if self._return_bits:\n            batch_size = inputs\n        else:\n            batch_size = inputs[0]\n\n        # Generate random bit sequence if return_bits is True\n        if self._return_bits:\n            b = self._init_b\n        else:\n            b = inputs[0]\n\n        # If list of pusch_configs, then create a PUSCHArray\n        if isinstance(pusch_configs, list):\n            pusch_configs[0].targets[\"dmrs\"].w\n            for pusch_config in pusch_configs[1:]:\n                pusch_config.targets[\"dmrs\"].w = pusch_configs[0].targets[\"dmrs\"].w\n                pusch_config.targets[\"dmrs\"].precoding = True\n        else:\n            pusch_configs[0].targets[\"dmrs\"].w\n\n        # Encode transport block\n        tb_encoder_output = self._tb_encoder([b])\n\n        # Constellation mapping\n        x_unmapped = tb_encoder_output\n\n        # Layer mapping (if more than 1 txant, create layers)\n        if self.pusch_configs[0].num_layers > 1:\n            x_unmapped = self._layer_mapper(x_unmapped)\n\n        # Create resource grid\n        rg = self._resource_grid_mapper(x_unmapped)\n\n        # OFDM Modulation\n        ofdm_output = self._ofdm_modulator(rg)\n\n        # Take one time sample to get P(t) Pusch\n        ofdm_output = ofdm_output[:, :, 0, :]\n\n        # Precoding\n        if self.pusch_configs[0].precoding:\n            ofdm_output = self._stream_management(ofdm_output)\n\n        # Apply DMRS\n        ofdm_output = ofdm_output*self._dmrs_grid\n\n        # Flatten the first 3 dimensions\n        ofdm_output = split_dim(ofdm_output, 3, 0, expand=True)\n        ofdm_output = flatten_last_dims(ofdm_output, 2)\n\n        if self._return_bits:\n            return ofdm_output, b\n        else:\n            return ofdm_output\n```"
"Here is the detailed information of verify_gm_pcm:   \n  \n[sionna.fec.utils.verify_gm_pcm(gm, pcm)](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#verify_gm_pcm)  \n\nVerify that generator matrix gm and parity-check matrix pcm are orthogonal in GF(2).\n\nFor an all-zero syndrome, it must hold that\n\nH c^t = H * (u * G)^t = H * G ^t * u^t =: 0\n\nwhere c denotes an arbitrary codeword and u the corresponding information bits.\n\nAs u can be arbitrary it follows that\n\nH * G ^t =: 0.\n\nInput\n\n    gm (ndarray) \u2013 Binary generator matrix of shape [k, n].\n    pcm (ndarray) \u2013 Binary parity-check matrix of shape [n-k, n].\n\nOutput\n\nbool \u2013 True if gm and pcm define a valid pair of parity-check and generator matrices in GF(2)."
"The permittivity and permeability are fundamental quantities in the study of electromagnetic waves. \n\nThe permittivity (`\u03b5`) represents the degree to which a material opposes the formation of an electric field in a varying magnetic field, and the permeability (`\u03bc`) represents the degree to which a material conducts the magnetic field. These two properties determine the speed of light in a material, which is given by the expression:\n\n`c = 1 / sqrt(\u03b5\u03bc)`\n\nIn the context, the permeability and permeability are broken down into their real and imaginary parts. The real parts (`\u03bc_r` and `\u03b5_r`) are used to calculate the speed of light in the material. The imaginary parts represent the losses due to the conductivity of the material. The complex relative permittivity (`\u03b7`) is the combination of these parts. \n\nThe permittivity can be calculated using the relative permittivity (`\u03b5_r`) and the vacuum permittivity (`\u03b5_0`). The permeability can be calculated using the relative permeability (`\u03bc_r`) and the vacuum permeability (`\u03bc_0`). \n\nThe permeability for non-magnetic materials is given the lowest value `\u03bc_0`. The permittivity for non-conducting materials is given the highest value, which is `\u03b5_0`. The permeability for conducting materials is complex, with the real part representing the inductive response and the imaginary part representing the resistive response. \n\nIn the code, the permittivity and permeability are set assuming a non-conducting material. The permeability is set to a complex number with the real part being `\u03bc_r` and the imaginary part being `\u03c3 / (\u03c9\u03b5_0)`. Here, `\u03c3` is the conductivity of the material. The permittivity is set to a complex number with the real part being `\u03b5_r` and the imaginary part being `-\u03c3 / (\u03c9\u03b5_0)`. The speed of light is then calculated using these properties."
"Here is the detailed information of RemoveNulledSubcarriers:   \n  \n[sionna.ofdm.RemoveNulledSubcarriers(nulled_subcarriers, axis=- 1)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/resource_grid.html#RemoveNulledSubcarriers)  \n\nRemoves nulled guard and/or DC subcarriers from a resource grid.\n\n**Input**\n\n- `nulled_subcarriers` (list, [sequence of int]): List of two elements of the form [nulled_guard, nulled_dc]. Each element is an int with a value of 0 or 1. A value of 1 for `nulled_guard` indicates that the guard carriers are nulled. A value of 1 for `nulled_dc` indicates that the DC carrier is nulled. If more than one OFDM symbol is nulled, the configuration is broadcasted over the nulled OFDM symbols.\n\n**Output**\n\n- `resource_grid_without_nulled_subcarriers` (ResourceGrid): The resource grid without nulled subcarriers."
"The class `LLRs2SymbolLogits` from the \"sionna.mapping\" module computes logits (unnormalized log-probabilities) or hard decisions on constellation points from a tensor of log-likelihood ratios (LLRs) on bits. \n\n- Default parameters:\n    - `num_bits_per_symbol`: int, The number of bits per constellation symbol, e.g., 4 for QAM16.\n    - `hard_out`: bool, If True, the layer provides hard-decided constellation points instead of soft-values. Defaults to False.\n    - `dtype`: One of [tf.float32, tf.float64] tf.DType, The dtype for the input and output. Defaults to tf.float32.\n\n- The source code is located in llr2symb.py file. The link of the source code is [LLRs2SymbolLogits](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#LLRs2SymbolLogits).\n\n- The class computes the logit for the constellation \ud835\udc50 $c$ point is computed according to\n  $\\begin{align}\n    \\log{\\left(\\Pr\\left(c\\lvert LLRs \\right)\\right)}\n        &= \\log{\\left(\\prod_{k=0}^{K-1} \\Pr\\left(b_k = \\ell(c)_k \\lvert LLRs \\right)\\right)}\\\\\n        &= \\log{\\left(\\prod_{k=0}^{K-1} \\text{sigmoid}\\left(LLR(k) \\ell(c)_k\\right)\\right)}\\\\\n        &= \\sum_{k=0}^{K-1} \\log{\\left(\\text{sigmoid}\\left(LLR(k) \\ell(c)_k\\right)\\right)}\n\\end{align}$\n  \n  The definition of the LLR has been chosen such that it is equivalent with that of logits. This is different from many textbooks in communications, where the LLR is defined as $LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)$."
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can follow these steps:\n\n1. Import the necessary modules:\n\n```python\nimport os\nimport tensorflow as tf\n```\n\n2. Set the GPU number. If you want to use the CPU, set `gpu_num` to an empty string.\n\n```python\ngpu_num = 0 # Use \"\" to use the CPU\n```\n\n3. Set the environment variables for CUDA:\n\n```python\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n4. Import the Sionna package. If it's not already installed, install it:\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n5. Configure the notebook to use only a single GPU. The `tf.config.list_physical_devices('GPU')` function returns a list of all available GPU devices. If there are GPUs available, set the memory growth for the first GPU. This needs to be done before any tensors are allocated:\n\n```python\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\n\n6. Set the TensorFlow logger level to 'ERROR' to avoid warnings from TensorFlow:\n\n```python\ntf.get_logger().setLevel('ERROR')\n```\n\nAfter these steps, the notebook is configured to use only a single GPU and allocate only as much memory as needed."
"To compute codeword bits from information bits using the `LinearEncoder`, you can follow these steps:\n\n1. Import the `LinearEncoder` from the `sionna.fec.linear` module.\n\n2. Initialize the `LinearEncoder` with the generator matrix. The generator matrix `pcm` is a binary matrix of shape `[k, n]` representing the encoding matrix where `k` is the number of information bits and `n` is the number of codeword bits.\n\n3. Pass the information bits `u` to the `LinearEncoder` to compute the codeword bits `c`. The information bits `u` should have a shape `[..., k]`, where the last dimension represents the number of information bits.\n\nHere is the corresponding Python code snippet:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n\n# Assume pcm is your binary parity-check or generator matrix\n# with shape [k, n]\nencoder = LinearEncoder(enc_mat=pcm, is_pcm=False)\n\n# Assume u are your information bits with shape [...,k]\nc = encoder(u)\n```\n\nIn the context of the question, the code to load the parity-check matrix (`pcm`), the information bits (`u`), and the encoder (`LinearEncoder`) has been provided already. You would replace `encoder(u)` with the appropriate variable and method names as needed. \n\nNote: The `is_pcm` parameter is used to indicate whether the provided matrix is a parity-check matrix or generator matrix. In the example code, `is_pcm=False` indicates that the provided matrix is a generator matrix. \n\nJust make sure that the dimensionality and the values of `u` are appropriate and align with the matrix's dimensions and encodings. The `...` in the code snippet implies that `u` should have an arbitrary number of dimensions, while the last dimension (`k`) should correspond to the number of information bits. The `c` output will then have the same shape as `u`, except for the last dimension, which will be adjusted to `n` (the number of codeword bits)."
"Here is the detailed information of sionna.utils.flatten_last_dims:  \n\n[sionna.utils.flatten_last_dims(tensor)](https://nvlabs.github.io/sionna/_modules/sionna/utils/tensors.html#flatten_last_dims)\n\nFlatten the last dimensions of a tensor.\n\nThis function flattens the last dimensions of a tensor. For example, if a tensor has shape [4,3,2,1], this function will return a tensor of shape [4*3,2,1].\n\n### Parameters\n\n- **tensor**: A tensor of any shape.\n\n### Returns\n\n- A tensor of shape [\u2026, N], where N is the last dimension size of the input tensor.\n\nsource code:\n```python\ndef flatten_last_dims(tensor):\n    \"\"\"\n    Flatten the last dimensions of a tensor.\n\n    This function flattens the last dimensions of a tensor. For example, if\n    a tensor has shape [4,3,2,1], this function will return a tensor of shape\n    [4*3,2,1].\n\n    Args:\n        tensor : A tensor of any shape.\n\n    Returns:\n        A tensor of shape [..., N], where N is the last dimension size of\n        the input tensor.\n    \"\"\"\n    return tf.reshape(tensor, [-1, tf.shape(tensor)[-2], tf.shape(tensor)[-1]])\n```"
"Here is the definition of Mapper: sionna.mapping.Mapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, return_indices=False, dtype=tf.complex64, **kwargs)\n\n  [source code](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Mapper)  \n  \nsource code:\n```python\nclass Mapper(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"Mapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, return_indices=False, dtype=tf.complex64, **kwargs)\n\n    Maps binary tensors to points of a constellation.\n\n    This class defines a layer that maps a tensor of binary values\n    to a tensor of points from a provided constellation.\n\n    Parameters\n    ----------\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [qam, pam].\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or\n        :const:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    return_indices : bool\n        If enabled, symbol indices are additionally returned.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128], tf.DType\n        The output dtype. Defaults to tf.complex64.\n\n    Input\n    -----\n    [, n] or [, num_symbols_per_constellation], tf.float or tf.int\n        Tensor with with binary entries.\n\n    Output\n    ------\n    [,n/Constellation.num_bits_per_symbol], tf.complex\n        The mapped constellation symbols.\n\n    [,n/Constellation.num_bits_per_symbol], tf.int32\n        The symbol indices corresponding to the constellation symbols.\n        Only returned if ``return_indices`` is set to `True`.\n\n    Note\n    ----\n    The last input dimension must be an integer multiple of the\n    number of bits per constellation symbol.\n    \"\"\"\n\n    def __init__(self,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 return_indices=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        self._return_indices = return_indices\n\n        # Create constellation object\n        const_dtype = tf.complex64 if dtype is tf.complex64 else tf.complex128\n        self._constellation = Constellation.create_or_check_constellation(\n                                                        constellation_type,\n                                                        num_bits_per_symbol,\n                                                        constellation,\n                                                        dtype=const_dtype)\n\n    # pylint: disable=no-self-argument\n    def _circularly_shift(self, symbols):\n        \"\"\"Applies circular shift to symbols\"\"\"\n        # Create random uniform integer shifts on the interval [0,1,...,n-1]\n        shifts = tf.random.uniform((), 0, symbols.shape[-1], dtype=tf.int32)\n        symbols = tf.roll(symbols, shifts, axis=-1) # Apply shift\n        return symbols\n\n    def build(self, input_shape):\n        \"\"\"Build the mapper layer\"\"\"\n        last_dim = input_shape[-1] # The last dimension\n\n        # Check that the last dimension is a multiple of num_bits_per_symbol\n        if last_dim % self._constellation.num_bits_per_symbol != 0:\n            msg = \"The last dimension must be a multiple of num_bits_per_symbol\"\n            raise ValueError(msg)\n\n    def call(self, inputs):\n        \"\"\"Maps binary tensors to points of a constellation.\n\n        Input\n        -----\n        : [...,n] or [...,num_symbols_per_constellation], tf.float or tf.int\n\n        Output\n        ------\n        : [...,n/Constellation.num_bits_per_symbol], tf.complex\n            The mapped constellation symbols.\n\n        : [...,n/Constellation.num_bits_per_symbol], tf.int32\n            The symbol indices corresponding to the constellation symbols.\n            Only returned if ``return_indices`` is set to `True`.\n        \"\"\"\n        constellation = self._constellation.constellation\n        symbol_indices = self._constellation.symbol_indices\n\n        # Reduce the last dimensions by selecting the constellation points or\n        # indices based on the input being int32 or float\n        if inputs.dtype==tf.int32:\n            x_ind = sn.utils.expand_to_rank(symbol_indices, tf.rank(inputs), axis=0)\n            y = tf.gather_nd(constellation, x_ind)\n        else:\n            y = tf.gather_nd(constellation, inputs)\n            x_ind = symbol_indices\n\n        # Scatter the symbol indices if required\n        if self._return_indices:\n            y_ind = tf.scatter_nd(x_ind, inputs, shape="
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can follow these steps:\n\n1. Import the necessary modules:\n\n```python\nimport os\nimport tensorflow as tf\n```\n\n2. Set the GPU number. If you want to use the CPU, you can set the GPU number to an empty string.\n\n```python\ngpu_num = 0 # Use \"\" to use the CPU\n```\n\n3. Set the environment variables for CUDA visible devices and TensorFlow to use only a single GPU and allocate only as much memory as needed. \n\n```python\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\n\nIn the code above, `tf.config.list_physical_devices('GPU')` is used to get the list of all available GPU devices. The `tf.config.experimental.set_memory_growth(gpus[0], True)` command is used to configure the notebook to use only the first GPU and allocate only as much memory as needed. The boolean `True` parameter allows TF to allocate only as much GPU memory as needed for the runtime allocations: it starts out allocating very little memory, but as the program gets run and more memory is needed, TensorFlow extends its GPU memory region to fulfill the runtime's needs."
"The definition of BinaryErasureChannel is as the following:  \n`class` BinaryErasureChannel(BaseDiscreteChannel):  \n(from sionna.channel.discrete_channel import BaseDiscreteChannel)  \n\nBinary erasure channel (BEC) where a bit is either correctly received or erased.\n\nIn the binary erasure channel, bits are always correctly received or erased with erasure probability $p_\\text{b}$.\n\nThis layer supports binary inputs ($x \\in \\{0, 1\\}$) and <cite>bipolar</cite> inputs ($x \\in \\{-1, 1\\}$).\n\nIf activated, the channel directly returns log-likelihood ratios (LLRs) defined as  \n$$  \n\\begin{split}l =\n\\begin{cases}\n    -\\infty, \\qquad \\text{if} \\, y=0 \\\\\n    0, \\qquad \\quad \\,\\, \\text{if} \\, y=? \\\\\n    \\infty, \\qquad \\quad \\text{if} \\, y=1 \\\\\n\\end{cases}\\end{split}\n$$\n\nThe erasure probability $p_\\text{b}$ can be either a scalar or a tensor (broadcastable to the shape of the input). This allows different erasure probabilities per bit position.\n\nPlease note that the output of the BEC is ternary. Hereby, <cite>-1</cite> indicates an erasure for the binary configuration and <cite>0</cite> for the bipolar mode, respectively.\n\nThis class inherits from the Keras `Layer` class and can be used as layer in a Keras model.\n \n**Parameters**\n\n- `return_llrs` (bool): Defaults to False. If True, the layer returns log-likelihood ratios instead of binary values based on `pb`.\n- `bipolar_input` (bool): Defaults to False. If True, the expected input is given as {-1,1} instead of {0,1}.\n- `llr_max` (tf.float): Defaults to 100. Defines the clipping value of the LLRs.\n- `dtype` (tf.DType): Defines the datatype for internal calculations and the output dtype. Defaults to tf.float32.\n\n**Input**\n\n- **(x, pb)**: Tuple - \n  - `x` ([,n], tf.float32): Input sequence to the channel.\n  - `pb` (tf.float32): Erasure probability. Can be a scalar or of any shape that can be broadcasted to the shape of `x`.\n\n**Output**\n\n- *[,n], tf.float32*: Output sequence of same length as the input `x`. If `return_llrs` is False, the output is ternary where each <-1</cite> and each <0</cite> indicate an erasure for the binary and bipolar input, respectively."
"The setup for the Weighted Belief Propagation (BP) algorithm as described in the context includes the following components:\n\n1. **LDPC BP Decoder**: This is the main component required for the setup. The decoder is implemented using the `LDPCBPDecoder` class from the Sionna package. It takes as input an estimate of the channel probability `p_00` and the number of decoding iterations `num_iter`. The decoder uses Belief Propagation (BP) algorithm to iteratively exchange messages between the variable nodes (VNs) and check nodes (CNs) of the LDPC code to compute the likelihood ratios (LRs) of the transmitted bits. The BP algorithm is enhanced by trainable weights scaling each outgoing VN and CN message. The decoder is of particular interest because it is configured with a multi-loss function, which allows for the training of specific parameters of the BP decoder using stochastic gradient descent (SGD).\n\n2. **Gaussian LLR Source**: This component is used to provide the log-likelihood ratios (LLRs) of the received signals, which serve as input to the BP decoder. The Gaussian LLR source is implemented using the `GaussianLLRSource` class from the Sionna package. It generates LLRs corresponding to a given channel error probability `p_b` and signal-to-noise ratio `ebno_db`, assuming an AWGN (Additive White Gaussian Noise) channel model. The class takes as parameters the batch size, the number of transmit antennas, the number of receive antennas, and the maximum number of codeword bits. These LLRs are then passed through the BP decoder for decoding.\n\nThese components are used to simulate the decoding performance of a 5G LDPC code in the presence of AWGN channel. The simulation results are obtained in terms of the Bit Error Rate (BER) and Block Error Rate (BLER) using different configurations of the decoder and the Gaussian LLR source."
"The PUSCHDMRSConfig class in Sionna's API is used to configure the generation of demodulation reference signals (DMRS) for a physical uplink shared channel (PUSCH) as described in Section 6.4.1.1 of the 3GPP TS 38.211 standard.\n\nTo use the class, you can either instantiate a PUSCHDMRSConfig object directly and pass the required parameters as arguments, or you can pass the parameters as keyword arguments. For example:\n\n```python\nfrom sionna.nr import PUSCHDMRSConfig\ndmrs_config = PUSCHDMRSConfig(config_type=2)\n```\n\nIf you need to configure specific properties, you can either pass them as arguments during the instantiation or set them later as keyword arguments. For example:\n\n```python\ndmrs_config.additional_position = 1\n```\n\nThe steps to use the PUSCHDMRSConfig class are as follows:\n\n1. Create an instance of the PUSCHDMRSConfig class, specifying the desired configuration type (1 or 2).\n\n2. Set the additional position for DMRS mapping. The additional position can be 0 (default), 1, 2, or 3.\n\n3. Set any additional properties as needed. For example, you can set the DMRS scrambling identities, the DMRS ports, the number of CDM groups without data, and the type A position of the first DMRS OFDM symbol.\n\n4. The PUSCHDMRSConfig class is typically used together with a PUSCHConfig class, which defines the configuration of a PUSCH. You can set the DMRS configuration in the PUSCH configuration.\n\n5. After the configuration, the DMRS port mappings can be obtained by calling the dmrs_port_map() method of the PUSCHConfig instance.\n\n6. The PUSCHConfig instance, which now includes the DMRS configuration, can be used as a parameter to instantiate a PUSCHTransmitter. The transmitter is used to generate a batch of PUSCH signals, which can then be mapped onto a resource grid using the method map() of the PUSCHMap instance.\n\nRemember that the PUSCHDMRSConfig class and other related components should be configured in a Keras layer's __init__() method or in a function, method, or script before they are used. The configuration values should typically be provided as arguments to the function or method."
"To demonstrate the encoding of information bits using an instance of `ConvEncoder`, we first need to create an instance of the encoder. We will then use this instance to encode the information bits.\n\n1. Import the necessary modules and initialize Sionna.\n    ```python\n    import tensorflow as tf\n    import sionna\n    from sionna.fec.conv import ConvEncoder\n\n    sionna.config.use_spin_off_instruction = True  # Use Sionna spin-off implementation\n   ```\n\n2. Create a encoder instance with a termination constraint of 5 (terminate = True) using the default rate (rate=1/2).\n    ```python\n    encoder = ConvEncoder(rate=1/2, constraint_length=5, terminate=True)\n    ```\n\n3. Generate a random batch of information bits. Assume we want to encode bits into a Systematic Rate 1/2 convolutional code where `k` is the number of information bits per codeword.\n    ```python\n    k = 100  # Number of information bits per codeword\n    u = tf.random.normal((k,))  # Random block of information bits\n    ```\n\n4. Encode the information bits. The encoder expects a 2D tensor with the last dimension equal to `k` containing the information bits.\n    ```python\n    c = encoder(u)\n    ```\n\nThe encoding process is now illustrated. The ConvEncoder instance takes the k-dimensional tensor `u` representing the information bits as input. After the encoding process, a termination bit sequence is added to ensure the encoder is in a zero state. The output `c` is an n-dimensional tensor where the last dimension is the number of codeword bits.\n\n    <p align='center'><img src=../assets/conv_encoding_diagram.png /></p>\n\nThe shapes of the input and output tensors `u` and `c` are as follows:\n\n- `u`: `[..., k]` (the last dimension must match the number of information bits `k`)\n- `c`: `[..., n]` (the last dimension must match the number of codeword bits `n`)\n\nThe types of `u` and `c` are `tf.float32`, as the default type for Sionna's tensors is `tf.float32`. Keep in mind that the actual type used may vary depending on the setup and requirements."
"The DMRS (Demodulation Reference Signal) Configuration in 5G NR includes several parameters such as DMRS Configuration Type, DMRS Ports, Length of DMRS Symbols, Number of CDM Groups Without Data, Frequency Density and DMRS Power Mode. \n\nIn the given context, the DMRS Configuration Type is mentioned as \"DMRS Configuration Type 1\" which corresponds to the basic 2 antenna ports. The Length of DMRS Symbols is specified as 1 and the Position of the first DMRS symbol is at \"0\". The Number of CDM Groups Without Data is \"2\". The DMRS is mapped to the resource grid which can be configured using the `map_to_grid` method during the creation of the `PUSCHTransmitter` instance. \n\nThe pilot pattern can be visualized using the `show` method of the `PUSCHTransmitter` instance. It will generate a figure of the pilot pattern along with the indices of the pilot symbols. "
"To visualize common scattering patterns using the Sionna package, you can use the `visualize` method of the `LambertianPattern` class or the `DirectivePattern` class. Here is how you can do it:\n\n1. Import the necessary classes from the Sionna package.\n\n```python\nfrom sionna.rt import LambertianPattern, DirectivePattern\n```\n\n2. Create an instance of the `LambertianPattern` class. You can specify the datatype if you want, but it is optional.\n\n```python\nlambertian_pattern = LambertianPattern(dtype=tf.complex64)\n```\n\n3. Call the `visualize` method of the `LambertianPattern` class. You can choose to visualize the incoming and specular reflection directions.\n\n```python\nlambertian_pattern.visualize(k_i=(0.7071, 0.0, -0.7071), show_directions=False)\n```\n\nThis will return a matplotlib figure showing the 3D scattering pattern and the incident plane cut through the scattering pattern.\n\n4. For the `DirectivePattern`, you need to provide the scattering half-width and the length of the scattering normal.\n\n```python\ndirective_pattern = DirectivePattern(alpha_r=20, dtype=tf.complex64)\n```\n\n5. Call the `visualize` method of the `DirectivePattern` class.\n\n```python\ndirective_pattern.visualize(k_i=(0.7071, 0.0, -0.7071), show_directions=False)\n```\n\nThis will return a matplotlib figure showing the 3D scattering pattern and the incident plane cut through the scattering pattern.\n\nRemember that the `k_i` argument is the incoming direction, the `show_directions` argument controls whether to show the incoming and specular reflection directions or not."
"To handle import errors for the Sionna package, the code first attempts to import the package. If the package is not found and an `ImportError` is raised, the code then goes on to handle this error by installing the Sionna package using the `pip install` command.\n\nHere's the relevant part of the code:\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\nThe code first attempts to import the Sionna package using a `try` block. If the import is successful, the code execution continues. If the import results in an `ImportError`, the code execution enters the `except` block. In this block, the Sionna package is installed using `pip install` and then imported again.\n\nThis ensures that if the Sionna package is not found in the current environment, it is installed and then imported."
"To import the necessary Sionna APIs, you can follow these steps:\n\n1. Import the `os` module.\n\n```python\nimport os\n```\n\n2. Set the GPU number. If you want to use the CPU, you can set `gpu_num` to an empty string.\n\n```python\ngpu_num = 0  # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n```\n\n3. Import the Sionna package. If it's not already installed, the code will install it using pip.\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n4. Import the `tensorflow` module and set it to use only errors from the `ResourceExhaustedError` class.\n\n```python\nimport tensorflow as tf\ntf.compat._fast_exit_gen = tf.ResourceExhaustedError\n```\n\n5. Set the TensorFlow log level to 'ERROR' to avoid warnings.\n\n```python\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\ntf.get_logger().setLevel('ERROR')\n```\n\n6. Import the Sionna APIs.\n\n```python\nfrom sionna.channel import AWGN, RayleighFlat, load_channel, gen_single_tone_pd, UPA, time_to_channel_variance, gen_4g_umis, sub_carriers, cir_to_ofdm_channel, cir_to_time_channel, OFDMChannel, show_time_channel, show_ofdm_channel, sinc_filter\nfrom sionna.channel.tr38901 import sub_carrier_spacing, fft_size, l_adj, p_hat, rho, tot_pow\nfrom sionna.detector import LinearDetector\nfrom sionna.fec.ldpc import LDPC5GEncoder, LDPC5GDecoder\nfrom sionna.fec.polar import Polar5GEncoder, Polar5GDecoder\nfrom sionna.mapping import Mapper, Demapper, Constellation, ViterbiInnerMapper, ViterbiInnerDemapper\nfrom sionna.mapping import PolarTransformer\nfrom sionna.ofdm import ResourceGrid, StreamManagement, RX_TXAssociation\nfrom sionna.utils import BinarySource, ebnodb2no, sim_ber, U\n```\n\nPlease note that some of these modules may not be part of the Sionna package and may be custom modules created by the user or another developer."
"The Descrambler class is a part of the `sionna.fec.scrambling` module and is used to reverse the scrambling process for a given sequence. The Descrambler class takes as input either a sequence to be descrambled (`x`), or a tuple of both the sequence and the random seed (`(x, seed))`.\n\nA Descrambler instance is usually associated with a Scrambler instance. During the initialization of a Descrambler, a Scrambler instance is passed as parameter. The Descrambler links to a specific Scrambler instance and its `binary` parameter indicates whether the bit-sequence should be flipped (i.e., binary operations are performed) or the signs should be flipped (i.e., soft-value/LLR domain-based). The `dtype` parameter defines the datatype for internal calculations and the output dtype. If no explicit dtype is provided, the dtype from the associated interleaver is used.\n\nInput\n    x: (*tf.float*) 1+D tensor of arbitrary shape. This is the sequence that needs to be descrambled.\n    seed: (*int*) An integer defining the state of the random number generator. If explicitly given, the global internal seed is replaced by this seed. Can be used to realize random scrambler/descrambler pairs (call with same random seed). This is an optional input.\n\nOutput\n    (*tf.float*) 1+D tensor of same shape as `x`. This is the descrambled output.\n\nErrors Raised\n    - **AssertionError**: If `seed` is not an int.\n    - **TypeError**: If `<cite>dtype</cite>` of `x` is not as expected.\n\nProperties\n    - `scrambler`: Associated scrambler instance.\n      - Asserts that the scrambler is an instance of Scrambler.\n      - Defaults to `TB5GScrambler`.\n\nI want to mention that the referred Scrambler class is actually `BasScrambler` within the context, but it is used to initialize Descrambler. This explanation focuses on the Descrambler class, providing the necessary details to understand its role in the context of Sionna's scrambling module."
"To perform Polar decoding using an instance of `Polar5GDecoder` with log-likelihood ratios (LLRs) as inputs, you will need to have an instance of `Polar5GEncoder` set up for encoding, which will also define the specific Polar code parameters. Then, you can create the decoder instance, and call it with the LLRs as inputs. Here are the steps:\n\n1. Import the necessary classes from the Sionna library.\n2. Set up the Polar encoder and encoder layers.\n3. Create the Polar decoder instance.\n4. Generate a random bit stream, encode it polarly, and then transmit it over a simulated Binary Symmetric Channel (BSC).\n5. At the receiver, compute the LLRs from the received signal over the BSC. If you already have LLRs, you can skip this step.\n6. Pass the computed LLRs as input to the Polar decoder.\n\nLet's go through these steps in detail:\n\nStep 1: Import the necessary classes from the Sionna library.\n```python\nfrom sionna.fec.polar.decoding import Polar5GDecoder\nfrom sionna.fec.polar.encoding import Polar5GEncoder\n```\n\nStep 2: Set up the Polar encoder and encoder layers.\n```python\nk = 32 # Number of information bits\nn = 256 # Codeword length\n\n# Assuming you have already determined/selected the k and n parameters.\nencoder = Polar5GEncoder(k, n)\n```\n\nStep 3: Create the Polar decoder instance.\n```python\n# dec_type can be SC, SCL, SCL8, SCL32, hybSCL, or BP\ndecoder = Polar5GDecoder(encoder, dec_type='SCL', list_size=8, num_iter=20, return_crc_status=False)\n```\n\nStep 4: Generate a random bit stream, encode it polarly, and then transmit it over a simulated Binary Symmetric Channel (BSC).\n```python\n# Let's simulate BSC with Sionna's API Sionna also provides a UPI channel\nfrom sionna.channel import BinarySymmetricChannel\n\nbsc = BinarySymmetricChannel() # create the BSC channel\n\n# Generate random bits and encode them using the Polar5GEncoder\nsource = tf.fill((batch_size, k), tf.constant(0, tf.int32))\ncodeword = encoder(source)\n```\n\nThe codeword bits are then passed through the BSC channel.\n\nStep 5: Compute the LLRs from the received signal over the BSC. If you already have LLRs, you can skip this step.\n```python\n# llr_max is the maximum value that the LLRs can take.\n# We assume here the value 10 is used for llr_max.\nllrs = bsc(codeword, channel_param)  # simulate channel\n\n```\n\nStep 6: Pass the computed LLRs to the Polar decoder.\n```python\n# Decode the codeword using the Polar5GDecoder\ndecoded_bits = decoder(llrs)\n```\n\nThis will give you the k information bits that were encoded into the codeword `c` bits.\n\nAnd that's it! You have now performed Polar decoding with an instance of `Polar5GDecoder`."
"To load a scene from a file using the `load_scene()` function from the Sionna package's `rt` module, you can follow these steps:\n\n1. Import the necessary modules: \n    ```python\n    from sionna.rt import load_scene\n    ```\n\n2. Call the `load_scene()` function, passing the filename of the scene you want to load as an argument. The function will return a `Scene` object representing the scene you loaded. If the filename is not provided, the function will default to `None` and an empty scene will be created. \n    ```python\n    scene = load_scene(filename)\n    ```\n\n3. You can specify the type of data (`dtype`) you want to use for internal computations and outputs. This is optional and it defaults to `tf.complex64`. \n    ```python\n    dtype=tf.complex64\n    ```\n\n4. The `load_scene()` function will return a reference to the current scene. You can use this reference to perform various operations related to the scene.\n\nRemember that the `filename` should point to a valid scene file in the Mitsuba 3 XML format.\n\nHere is an example:\n```python\nimport sionna\nfrom sionna.rt import load_scene\n\n# Load an integrated Sionna scene\nscene = load_scene(sionna.rt.scene.__file__[:-11] + \"example/scenes/kitchen_with_objects.mitsuba\")\n```\n\nIn this example, the `load_scene()` function is used to load a pre-made integrated scene that includes several objects. The filename for an empty scene would be `None`.\n\nPlease note that the integrated scenes provided in the Sionna package's `rt.scene` module are for use in unit testing and demonstrations. When constructing your own scenes, it is recommended to use Mitsuba 3's official tools and formats for scene definition."
