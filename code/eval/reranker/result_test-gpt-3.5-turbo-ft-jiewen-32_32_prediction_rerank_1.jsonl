"To create an instance of the `Polar5GEncoder` class in Sionna, you need to specify two parameters: `k` and `n`. Here is what these parameters mean:\n\n- `k` is the number of information bits: This is the input data that you want to encode. The `Polar5GEncoder` class performs encoding for the uplink and downlink scenarios in 5G communication, as specified in the 3GPP TS 38.212 standard.\n\n- `n` is the codeword length: This is the length of the codeword after the encoding process. It refers to the number of bits in the encoded sequence, which is typically larger than `k` due to the inclusion of parity bits for error detection and correction.\n\nWhen creating an instance of the `Polar5GEncoder`, you need to replace the backticks with the actual values for `k` and `n`. Here is how you can do it:\n\n```python\nfrom sionna.fec.polar.encoding import Polar5GEncoder\n\n# Create an instance of the Polar5GEncoder class\nencoder = Polar5GEncoder(k=100, n=200)\n```\n\nIn this example, `k=100` and `n=200` are placeholder values for `k` and `n`. You should replace these values with the actual numbers based on your specific requirements. Remember that both `k` and `n` need to be positive integers, and `k` should be less than or equal to `n`."
"To import DeepMIMO and generate a dataset, you should follow these steps:\n\n1. Import DeepMIMO package. If it's not already installed, install it using pip.\n\n```python\ntry:\n    import DeepMIMO\nexcept ImportError as e:\n    import os\n    os.system(\"pip install DeepMIMO\")\n    import DeepMIMO\n```\n\n2. Set DeepMIMO parameters. Be sure to set the `params['dataset_folder']` to the correct path.\n\n```python\nDeepMIMO_params = DeepMIMO.default_params()\nDeepMIMO_params['dataset_folder'] = r'./scenarios'\nDeepMIMO_params['scenario'] = 'O1_60'\nDeepMIMO_params['num_paths'] = 10\nDeepMIMO_params['active_BS'] = np.array([6])\nDeepMIMO_params['user_row_first'] = 400\nDeepMIMO_params['user_row_last'] = 450\nDeepMIMO_params['bs_antenna']['shape'] = np.array([16, 1, 1])\nDeepMIMO_params['ue_antenna']['shape'] = np.array([1, 1, 1])\nDeepMIMO_params['OFDM_channels'] = 0\n```\n\n3. Call the DeepMIMO `generate_data` function with the above parameters to generate the dataset.\n\n```python\nDeepMIMO_dataset = DeepMIMO.generate_data(DeepMIMO_params)\n```\n\nThis will generate a DeepMIMO dataset for you. The generated dataset will be returned as a tuple, and the first element of the tuple will describe the dataset dimensions."
"To plot the weights after training and compare the new Bit Error Rate (BER) performance, you can use the provided code snippets. \n\nThe weights of the decoder are shown after training with the line `model.decoder.show_weights()`. This is a built-in function of the Sionna models that visualizes the weights of the layer after training. The results of the training process in terms of BER performance are then computed and plotted using the `ber_plot` object. The `simulate` method of the `ber_plot` object takes several parameters including the trained model, the range of Eb/No values, the batch size, the number of target bit errors, a legend, the maximum number of iterations for the Monte-Carlo simulation, a flag indicating whether soft estimates are available, the number of OFDM symbols, the FFT size, the subcarrier spacing, the carrier frequency, the speed, and the set of enabled antennas. \n\nIn the context provided, the `mc_ber` function is used to simulate the BER performance over a range of Eb/No values. The function simulates the BER by transmitting bits modulated using the given constellation over an Additive White Gaussian Noise (AWGN) channel with the given noise variance. The transmitted bits are then demapped using a maximum log-likelihood (LLR) decoder operating on the received values. The LLR decoder is assumed to be optimal and is implemented using the `mc_ber` function. The function then compares the transmitted and received bit values, computes the BER, and returns the BER value.\n\nTo create a plot of the weights of the decoder after training, you can use the `show_weights` method of the decoder object in the model. To compare the new BER performance, you can use the `simulate` method of the `ber_plot` object with the trained model and the other relevant parameters. The method will run the simulation for the range of Eb/No values and plot the BER performance of the different models (in this case, the trained and untrained models) based on the specified parameters.\n\nPlease note that to run this code, you must have the appropriate models and objects defined in your implementation. The context does not provide the exact definition of the `Model` or `ber_plot` objects, so you may need to refer to the Sionna documentation or source code to define these objects."
"To create a Polar transformation matrix for a given Kronecker power, you can use the `generate_polar_transform_mat` function from the Sionna package. This function takes one argument, `n_lift`, which is an integer defining the Kronecker power. The Kronecker power indicates how the kernel is lifted, with a value of 1 indicating the base case.\n\nHere's how you can use the `generate_polar_transform_mat` function:\n\n```python\nfrom sionna.fec.polar.utils import generate_polar_transform_mat\n\n# Create a Polar transformation matrix for a single instance (K=1)\npolar_transform_mat = generate_polar_transform_mat(n_lift=1)\n\n# Create a Polar transformation matrix for multiple instances (K>1)\n# and a higher Kronecker power\n# polar_transform_mat = generate_polar_transform_mat(n_lift=K)\n```\n\nIn the above example, `n_lift` is set to 1 for the base case. If you want to create the matrix for a higher Kronecker power, you need to set `n_lift` to a value greater than 1. The generated matrix will be symmetric, with upper triangular entries equal to 1, indicating the frozen positions in the Polar code.\n\nPlease note that the function will return an array of 0s and 1s, so each element in the array is an integer. The shape of the array will be `[2**n_lift , 2**n_lift]`. This matrix is used in the encoding process of Polar codes, where it scales the information bits via a Kronecker product.\n\nIt's important to use the generated matrix in the encoding process according to the specific package or implementation you are using. The usage may vary depending on the context, which is not provided in the provided context."
"Here is the definition of LayerDemapper:   \n  \n[sionna.nr.LayerDemapper(layer_mapper, num_bits_per_symbol=1, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/nr/layer_mapping.html#LayerDemapper)   \n  \nDemaps MIMO layers to coded transport block(s) by following Sec. 6.3.1.3 and Sec. 7.3.1.3 in 3GPP38211.\n\nThis layer must be associated to a LayerMapper and performs the inverse operation.\n\nIt is assumed that num_bits_per_symbol consecutive LLRs belong to a single symbol position. This allows to apply the LayerDemapper after demapping symbols to LLR values.\n\nIf the layer mapper is configured for dual codeword transmission, a list of both transport block streams is returned.\n\nThe class inherits from the Keras layer class and can be used as layer in a Keras model.  \n  \n### Input\n\n- **inputs** ([..., num_antenna_ports], tf.float): 2+D tensor containing MIMO layer data sequences.\n\n### Output\n\n- **[..., num_codewords, num_transport_blocks, tb_size]** or **[..., num_codewords, tb_size]**, tf.float: 2+D tensor containing the sequence of bits after layer demapping. If num_codewords =1, no partitioning into transport blocks is performed.  \n  \n### Properties\n\n- **coderate**: Coderate of the layer based on the TB Coderate and the number of CWs per TB.\n  \n- **num_cbs**: Number of code blocks the layer is partitioned into.\n\n- **num_cw**: Number of codewords.\n\n- **num_tx**: Number of transmit streams.\n\n- **tb_coderate**: Coderate of the layer settings.\n\n- **tb_size**: Size of each transport block after layer demapping.\n\n- **tb_size_cw**: Size of each TB before CB segmentation.\n\n- **tb_size_no_fill**: Effective TB size per codeword after CB segmentation.\n\n### Method\n\n1. **call(inputs)**[source](https://nvlabs.github.io/sionna/_modules/sionna/nr/layer_mapping.html#LayerDemapper.call):   \nPerforms the inverse layer mapping.\n  \n### Input\n\n- **inputs** ([..., num_antenna_ports], tf.float): 2+D tensor containing MIMO layer data sequences.\n\n### Output\n\n- **[..., num_codewords, num_transport_blocks, tb_size]** or **[..., num_codewords, tb_size]**, tf.float: 2+D tensor containing the sequence of bits after layer demapping. If num_codewords =1, no partitioning into transport blocks is performed.  \n  \n### Parent Class   \nThe LayerDemapper is a kind of LayerMapper."
"To create a PUSCHReceiver using the PUSCHTransmitter and simulate transmissions over the AWGN channel, follow these steps:\n\n1. First, import the necessary modules and classes. This includes TensorFlow, Sionna, and the required Sionna APIs for configuration and simulation.\n\n```python\nimport tensorflow as tf\nfrom sionna.nr import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver\nfrom sionna.channel import AWGN\n```\n\n2. Next, create a PUSCH configuration with default settings.\n\n```python\npusch_config = PUSCHConfig()\n```\n\n3. Instantiate a PUSCHTransmitter from the PUSCHConfig.\n\n```python\npusch_transmitter = PUSCHTransmitter(pusch_config)\n```\n\n4. Create a PUSCHReceiver using the PUSCHTransmitter.\n\n```python\npusch_receiver = PUSCHReceiver(pusch_transmitter)\n```\n\n5. Finally, simulate transmissions over the AWGN channel using the AWGN class.\n\n```python\nchannel = AWGN()\nbatch_size = 16\nno = 0.1  # Noise variance\nx, b = pusch_transmitter(batch_size)  # Generate transmit signal and info bits\ny = channel([x, no])  # Simulate channel output\nb_hat = pusch_receiver([x, no])  # Recover the info bits\n```\n\nThe above code will generate a binary source, encode it, map it to the OFDM resource grid, modulate it, simulate over the AWGN channel, demodulate it, and finally decode it. The result will be the Bit Error Rate (BER) for the transmission."
"Here is the definition of SymbolInds2Bits: sionna.mapping.SymbolInds2Bits(num_bits_per_symbol, dtype=tf.float32, **kwargs)  \n  \n[Concentration2Mapping source code](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Concentration2Mapping)  \n  \nsource code:\n```python\nclass SymbolInds2Bits(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    SymbolInds2Bits(num_bits_per_symbol, dtype=tf.float32, **kwargs)\n\n    Converts symbol indices to their binary representations.\n\n    Parameters\n    ----------\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol.\n\n    dtype : tf.DType\n        Output dtype. Defaults to `tf.float32`.\n\n    Input\n    -----\n    inds : [...,n], tf.int\n        Symbol indices for all positions.\n\n    Output\n    ------\n    : [...,n*num_bits_per_symbol], tf.float\n        Binary representation of ``inds``.\n        The last dimension is equal to ``num_bits_per_symbol``.\n    \"\"\"\n    def __init__(self,\n                 num_bits_per_symbol,\n                 dtype=tf.float32,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        self._num_bits_per_symbol = num_bits_per_symbol\n        self._table = tf.constant(2**tf.range(num_bits_per_symbol,\n                                              dtype=dtype),\n                                dtype=dtype)\n\n    def call(self, inds):\n\n        # Note: inds can be of shape [...,n] or [...,n, num_symbols].\n        # If the latter, the last dimension is simply interpreted as\n        # individual symbols.\n\n        b = tf.gather(self._table, inds, axis=-1)\n        # If the input tensor inds has shape [...,n, num_symbols],\n        # we want to put the last dimension first. This is important for\n        # the next step as we want to reshape [..., num_symbols, n].\n        # tf.transpose(inds, perm=[0,2,1])\n        # Next, we expand the last dimension. The number of elements\n        # in the last dimension is 2**num_bits_per_symbol, i.e.,\n        # the number of bits per symbol.\n        # tf.expand_dims(inds, -1, axis=-1)\n        # Finally, we put the last dimension first again\n        # tf.transpose(inds, perm=[0,2,1])\n        # The result is the same as the following one-liner, which\n        # is also more performant.\n        b = tf.transpose(tf.expand_dims(inds, -1, axis=-1),\n                         perm=[0,2,1])\n\n        return b\n```  \n  "
"Here is the detailed information of TimeChannel:   \n  \n[sionna.channel.TimeChannel(channel_model, bandwidth, num_time_samples, maximum_delay_spread=None, l_min=None, l_max=None, add_awgn=True, normalize_channel=False, return_channel=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/channel/time_channel.html#TimeChannel)  \n\nGenerate channel responses and apply them to channel inputs in the time domain.\n\nThis class inherits from the Keras Layer class and can be used as layer in a Keras model.\n\nThe channel output consists of num_time_samples + l_max - l_min time samples, as it is the result of filtering the channel input of length num_time_samples with the time-variant channel filter of length l_max - l_min + 1. In the case of a single-input single-output link and given a sequence of channel inputs $x_0,\\cdots,x_{N_B}$, where N_B is num_time_samples, this layer outputs $y_b = \\sum_{\\ell = L_{\\text{min}}}^{L_{\\text{max}}} x_{b-\\ell} \\bar{h}_{b,\\ell} + w_b$ , where L_{\\text{min}} corresponds l_min, L_{\\text{max}} to l_max, w_b to the additive noise, and \\bar{h}_{b,\\ell} to the $\\ell^{th}$ tap of the b^{th} channel sample. This layer outputs y_b for b ranging from L_{\\text{min}} to N_B + L_{\\text{max}} - 1, and x_{b} is set to 0 for b < 0 or b \\geq N_B. The channel taps \\bar{h}_{b,\\ell} are computed assuming a sinc filter is used for pulse shaping and receive filtering. Therefore, given a channel impulse response $(a_{m}(t), \\tau_{m}), 0 \\leq m \\leq M-1$, generated by the channel_model, the channel taps are computed as follows: $\\bar{h}_{b, \\ell} = \\sum_{m=0}^{M-1} a_{m}\\left(\\frac{b}{W}\\right) \\text{sinc}\\left( \\ell - W\\tau_{m} \\right)$ , for \\ell ranging from l_min to l_max, and where W corresponds to bandwidth.\n\nThree padding modes are available for applying the channel filter: \u201cfull\u201d (default), \u201csame\u201d, and \u201cvalid\u201d. Setting padding to \u201cfull\u201d returns the convolution of the channel input and the channel filter. \u201csame\u201d returns an output of the same length as the input. With \u201cvalid\u201d, the convolution is performed such that the output is of length $n-k$ where $n$ is the length of the input and $k$ is the kernel length - 1.\n\nFor multiple-input multiple-output (MIMO) links, the channel output is computed for each antenna of each receiver and by summing over all the antennas of all transmitters.\n\nThe channel output is optionally affected by additive white Gaussian noise (AWGN), i.e., a complex normal noise with a certain variance can be added to the channel output. It is possible to either use a scalar for the noise variance or a tensor with a shape that can be broadcast to the input shape. This allows, e.g., different noise variances per batch example. More details can be found in the section Noise.\n\nThe channel response is computed assuming unit average energy per time step. This can be changed by setting the normalize_channel parameter to True. Note that the channel response is always computed such that the average energy per time step is unit.\n\nThe use of this layer in Graph mode with XLA is possible. It is deactivated by default because the sizing method is usually significantly slower in Graph mode. It can be activated by setting the xla_compat parameter to True.\n\n**Example**\nSetting-up and MIMO OFDM channel:\n\n```python\nchannel_model = RayleighBlockFading(num_rx = 1,\n                                   num_rx_ant = 32,\n                                   num_tx = 4,\n                                   num_tx_ant = 2)\nresource_grid = ResourceGrid(num_ofdm_symbols = 14,\n                            fft_size = 256,\n                            subcarrier_spacing = 15e3)\ntime_channel = TimeChannel(channel_model, resource_grid.bandwidth,\n                           resource_grid.num_ofdm_symbols,\n                           maximum_delay_spread = 100e-9)\n```\n\n**Parameters**\n\n- `channel_model` (ChannelModel): An instance of a ChannelModel, such as RayleighBlockFading or UMi.\n- `bandwidth` (float): Bandwidth ($W$) [Hz]\n- `num_time_samples` (int): Number of time samples forming the channel input\n- `maximum_delay_spread` (float): Maximum delay spread [s]. Used to compute the default value of `l_max` if `l_max` is set to None. If a value is given for `l_max`, this parameter is not used. It defaults to 3us, which was found to be large enough to include most significant paths with all channel models included in Sionna assuming a nominal delay spread of 100ns.\n- `l_min` (int): Smallest time-lag for the discrete complex baseband channel ($L_{\\text{min}}$). If set to None, it is computed from the channel delay profile using the function `time_lag_discrete_time_channel()`.\n- `l_max` (int): Largest time-lag for the discrete complex baseband channel ($L_{\\text{max}}$). If set to None, it is computed from `bandwidth` and `maximum_delay_spread` using `time_lag_discrete_time_channel()`. If it is not set to None, then `maximum_delay_spread` is not used.\n- `add_awgn` (bool): If set to False, no white Gaussian noise is added to the channel output. Defaults to True.\n- `normalize_channel` (bool): If set to True, the channel is normalized over the block size to ensure unit average energy per time step. Defaults to False.\n- `return_channel` (bool): If set to True, the channel response is returned in addition to the channel output. Defaults to False.\n- `dtype` (tf.DType): Complex datatype to use for internal processing and output. Defaults to tf.complex64.\n\n**Input**\n\n- `inputs` ([batch size, num_tx, num_tx_ant, num_time_samples], tf.complex): Channel inputs\n\n**Output**\n\n- `y` ([batch size, num_rx, num_rx_ant, num_time_samples + l_max - l_min], tf.complex): Channel outputs\n- `h_time` ([batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_samples + l_max - l_min, l_max - l_min + 1], tf.complex): (Optional) Channel responses. Returned only if `return_channel` is set to True."
"The \"Antenna\" class in the 'sionna.rt' module is part of the wireless simulation primer \"Sionna.\" This class is pivotal to the simulation of wireless communication systems as it brings into play important parameters such as antenna patterns and polarization. Here's what the 'Antenna' class entails:\n\nThe class can be used to define an antenna object with a specific pattern. This object can be single or dual polarized.\nParameters for the 'Antenna' class include:\n- `pattern`: This can be a string such as \"iso\", \"dipole\", \"hw_dipole\", or \"tr38901\", or a callable variable, or a length-2 sequence of callable variables defining antenna patterns. In the latter case, the antenna is dual-polarized.\n- `polarization`: This specifies the type of polarization. For single polarization, it must be either \"V\" (vertical) or \"H\" (horizontal). For dual polarization, it must be \"VH\" or \"cross\". This parameter is only required if 'pattern' is a string.\n- `polarization_model`: This indicates the polarization model to be used, with options 1 and 2 referring to two conventional polarization models.\n- `dtype`: This denotes the datatype for computations. The options include \"tf.complex64\" and \"tf.complex128\", with the former as the default.\n\nThe class also includes properties such as 'patterns', which provides antenna patterns for one or two polarization directions, and 'radiation_efficiency', which provides the radiation efficiency of the antenna.\n\nMethods in the class are mostly accessors for class properties, so the class itself doesn't have many distinct methods.\n\nIt's important to note that when using this class in Graph mode with TensorFlow, you should for properties and methods use the @tf.function decorator to make them graph functions.\n\nThis class plays a critical role in simulations and applications related to wireless channel modeling, especially in the context of single or dual polarization simulations and measurements.\n\nPattern class is designed to be used by the Antenna class to define the antenna pattern. Please refer to the Antenna documentation to see how it is used. If you want to use a different dtype or custom pattern, you can define your own Pattern and set dtype and pass it to the Antenna constructor."
"Here is the source code of TurboTermination class:  \n  \n```python\nclass TurboTermination:\n    \"\"\"Termination object, handles the transformation of termination bits from\n    the convolutional encoders to a :class:`~Turbo` codeword. Similarly, it\n    handles the transformation of channel symbols corresponding to the\n    termination of a :class:`~Turbo` codeword to the underlying convolutional\n    codewords.\n\n    Parameters\n    ----------\n    constraint_length: int\n        Constraint length of the convolutional encoder used in the Turbo code.\n        Note that the memory of the encoder is ``constraint_length`` - 1.\n\n    conv_n: int\n        Number of output bits for one state transition in the underlying\n        convolutional encoder\n\n    num_conv_encs: int\n        Number of parallel convolutional encoders used in the Turbo code\n\n    num_bit_streams: int\n        Number of output bit streams from Turbo code\n    \"\"\"\n    def __init__(self,\n                 constraint_length,\n                 conv_n=2,\n                 num_conv_encs=2,\n                 num_bit_streams=3\n                ):\n        super().__init__()\n        self._convenc_term = None\n        self._num_conv_encs = num_conv_encs\n        self._conv_n = conv_n\n        self._mu = constraint_length - 1\n        self._conv_k = self._mu*conv_n\n        self._turbo_l = self._mu*num_bit_streams\n        self._num_bit_streams = num_bit_streams\n\n        # Check for valid termination parameters\n        assert self._mu in [3, 4], \"Termination is not supported for given MU\"\n        assert self._num_conv_encs in [1, 2, 3], \"Invalid num_conv_encs\"\n        assert self._num_bit_streams in [1, 2, 3], \"Invalid num_bit_streams\"\n\n        # Each Turbo symbol implies num_bit_streams bits. The convolutional\n        # encoders last num bit streams are termination bits.\n        self._convenc_term = ConvolutionalEncoder(self._mu,\n                                                  gen_poly=None,\n                                                  out_type='terminated',\n                                                  termination=True,\n                                                  rate=1)\n\n        # In the initial state, the zero state is assumed\n        self._state_circ_buf = [0] * self._num_conv_encs\n\n        # Done flag is set to False by default\n        self._done = False\n\n    @property\n    def done(self):\n        \"\"\"Termination status of the Turbo code. `True` if the Turbo code\n        termination has been completed. `False` otherwise.\"\"\"\n        return self._done\n\n    @done.setter\n    def done(self, value):\n        \"\"\"Set the termination status of the Turbo code. Note that\n        it is usually not required to externally set this property.\"\"\"\n        self._done = value\n\n    def  get_num_term_syms(self):\n        r\"\"\"Computes the number of termination symbols for the Turbo code.\n\n        Note that one symbol equals ``num_bitstreams`` bits.\n\n        :rtype: int\n        :return: Total number of termination symbols for the Turbo Code.\n                 One symbol equals the ``num_bitstreams`` bits.\n        \"\"\"\n        return math.ceil(2*self._conv_n*self._mu/self._num_bit_streams)\n\n    def term_bits_turbo2conv(self, term_bits):\n        \"\"\"This method splits the termination symbols from a Turbo codeword\n        to the termination symbols corresponding to the two convolutional\n        encoders, respectively.\n\n        Lets assume :math:`\\mu=4` and the underlying convolutional encoders\n        are systematic and rate-1/2, for demonstration purposes.\n\n        Let ``term_bits`` tensor, corresponding to the termination symbols of\n        the Turbo codeword be as following:\n\n        :math:`y = [x_1(K), z_1(K), x_1(K+1), z_1(K+1), x_1(K+2, z_1(K+2),`\n        :math:`x_1(K+3), z_1(K+3), x_2(K), z_2(K), x_2(K+1), z_2(K+1),`\n        :math:`x_2(K+2), z_2(K+2), x_2(K+3), z_2(K+3), 0, 0]`\n\n        The two termination tensors corresponding to the convolutional encoders\n        are:\n\n        * :math:`y[0,..., 2\\mu]`\n        * :math:`y[2\\mu,..., 4\\mu]`.\n\n\n        The output from this method is a tuple of two tensors, each of\n        size :math:`2\\mu` and of shape :math:`[\\mu,2]`.\n\n        :math:`[[x_1(K), z_1(K)]`\n\n        :math:`[x_1(K+1), z_1(K+1)]`\n\n        :math:`[x_1(K+2, z_1(K+2), x_1(K+3), z_1(K+3)]]`\n\n        :math:`[[x_2(K), z_2(K)],`\n\n        :math:`[x_2(K+1), z_2(K+1)]`\n\n        :math:`[x_2(K+2), z_2(K+2), x_2(K+3), z_2(K+3), 0, 0]]`\n\n        Therefore, the output is a 1+D tensor of termination bits where all\n        symbols are concatenated together.\n        \"\"\"\n        term_bits = tf.cast(term_bits, tf.int32)\n        term_bits = term_bits[0:self._turbo_l]\n        term_bits = tf.reshape(term_bits, [-1, self._mu])\n\n        if self._num_conv_encs==1:\n            term_bits = self._convenc_term.term_bits_conv2turbo(term_bits)\n        else:\n            term_bits1 = term_bits[:, :self._mu]\n            term_bits2 = term_bits[:, self._mu:]\n            term_bits1 = self._convenc_term.term_bits_conv2turbo(term_bits1)\n            term_bits2 = self._convenc_term.term_bits_conv2turbo(term_bits2)\n            term_bits = tf.concat([term_bits1, term_bits2], axis=0)\n\n        term_bits = tf.reshape(term_bits, [-1]) # Flattens\n        term_bits = tf.concat([term_bits, tf.zeros(self.get_num_term_syms()*self._num_bit_streams, tf.int32)], 0)\n        return term_bits\n\n    def termbits_conv2turbo(self, term_bits1, term_bits2):\n        \"\"\"This method merges ``term_bits1`` and ``term_bits2``, termination\n        bit streams from the two convolutional encoders, to a bit stream\n        corresponding to the Turbo codeword.\n\n        In the initial state, the two convolutional encoders are assumed\n\n        to be systematic and rate-1/2, for demonstration purposes.\n\n        Let ``term_bits1`` and ``term_bits2`` be:\n\n        :math:`[x_1(K), z_1(K), x_1(K+1), z_1(K+1),..., x_1(K+\\mu-1),z_1(K+\\mu-1)]`\n\n        :math:`[x_2(K), z_2(K), x_2(K+1), z_2(K+1),..., x_2(K+\\mu-1), z_2(K+\\mu-1)]`\n\n        where :math:`x_i, z_i` are the systematic and parity bit streams\n        respectively for a rate-1/2 convolutional encoder i, for i = 1, 2.\n\n        In the example output below, we assume :math:`\\mu=4` to demonstrate\n        zero padding at the end. Zero padding is done such that the total\n        length is divisible by ``num_bitstreams`` (defaults to 3) which is the\n        number of Turbo bit streams.\n\n        :math:`[x_1(K), z_1(K), x_1(K+1), z_1(K+1), x_1(K+2, z_1(K+2),`\n        :math:`x_1(K+3), z_1(K+3), x_2(K),z_2(K), x_2(K+1), z_2(K+1),`\n        :math:`x_2(K+2), z_2(K+2), x_2(K+3), z_2(K+3), 0, 0]`\n\n        Therefore, the output from this method is a 1+D tensor of termination\n        bits where all symbols are concatenated together.\n        \"\"\"\n        assert term_bits1.shape==term_bits2.shape, \"termbits1 and termbits2 must have same shape.\"\n\n        term_bits = tf.concat([term_bits1, term_bits2], axis=-1)\n        term_bits = tf.reshape(term_bits, [-1]) # Flattens\n\n        # Right zero-padding\n        extra_bits = self.get_num_term_syms()*self._num_bit_streams - tf.shape(term_bits)[0]\n        zero_padding = tf.zeros([extra_bits], tf.float32)\n        term_bits = tf.concat([term_bits, zero_padding], 0)\n        return term_bits\n\n    def __call__(self, inputs):\n        \"\"\"This method terminates the Turbo codeword such that\n        the underlying convolutional encoders return to the 'All-zero'\n        state.\"\"\"\n        if self._done:\n            # Termination process has already been done\n            pass\n\n        enc1_bits, enc2_bits = inputs\n\n        # enc1_bits and enc2_bits have shape\n        # [mu, num_conv_encs, k] and [mu, num_conv_encs, k], respectively.\n\n        # Check input dimensions\n        enc1_dim = len(enc1_bits.shape)\n        enc2_dim = len(enc2_bits.shape)\n        tf.debugging.assert_equal(enc1_dim, 3,\n                                 \"Rank of enc1_bits must be 3\")\n        tf.debugging.assert_equal(enc2_dim, 3,\n                                 \"Rank of enc2_bits must be 3\")\n\n        tf.debugging.assert_equal(enc1_bits.shape[1], self._num_conv_encs,\n                                 \"Number of encoders in enc1_bits must be num_conv_encs\")\n        tf.debugging.assert_equal(enc2_bits.shape[1], self._num_conv_encs,\n                                 \"Number of encoders in enc2_bits must be num_conv_encs\")\n\n        tf.debugging.assert_equal(enc1_bits.shape[2], self._conv_k,\n                                 \"Length of enc1_bits last dim must be conv_k\")\n        tf.debugging.assert_equal(enc2_bits.shape[2], self._conv_k,\n                                 \"Length of enc2_bits last dim must be conv_k\")\n\n        # Together, the two encoders have a termination of 2*mu bits.\n        tf.debugging.assert_equal(self._num_bit_streams, 3,\n                                 \"Exactly three num_bit_streams are supported.\")\n\n        #########################################\n        #        TERMINATION PROCESS           #\n        #########################################\n\n        # The termination process is done in two separate loops, each\n        # corresponding to one of the underlying convolutional encoders.\n\n        for circ_state in self._state_circ_buf:\n            # During the termination process, the encoder is turned\n            # to the next 'mu' bits. Therefore, a new zero state should\n            # receive the information bits\n            circ_state = tf.concat([tf.fill([tf.shape(circ_state)[0], self._conv_n], 0), circ_state], axis=-1)\n\n        term_bits1 = self.convenc_term(enc1_bits)\n\n        term_bits2 = self.convenc_term(enc2_bits)\n\n        term_bits = self.termbits_conv2turbo(term_bits1, term_bits2)\n\n        #############################################\n        #        CONVENCODER TERMINATION          #\n        #############################################\n        for i in range(self._num_conv_encs):\n            self._state_circ_buf[i] = term_bits[i*self._mu:(i+1)*self._mu]\n\n        output = term_bits\n        self._done = True\n        return output\n```  \n  "
"To wrap everything in a Keras model for convenient BER simulations and the comparison of model parameters, you can follow these steps:\n\n1. Import the necessary libraries and modules. This includes TensorFlow, Sionna, Keras, and other necessary modules such as `BinarySource`, `LDPC5GEncoder`, `LDPC5GDecoder`, `Mapper`, `Demapper`, `FlatFadingChannel`, `ebnodb2no`, `lmmse_equalizer`, and `ExpandToRank`.\n\n2. Set up your simulation parameters. This includes the number of bits per symbol, the code rate, the number of transmit antennas, the number of receive antennas, and any other parameters that are needed for your specific use case.\n\n3. Define your simulation model as a class that inherits from `keras.Model`. This model should have an `__init__()` method to initialize the components of your model and a `call()` method that defines the forward pass of your model.\n\n4. In the `__init__()` method, initialize the components of your model. This includes the binary source, the encoder, the mapper, the demapper, the decoder, and the channel.\n\n5. In the `call()` method, define the forward pass of your model. This should include the steps to generate the binary source, encode the data, map it to symbols, transmit it over the channel, demap it to LLRs, and decode it.\n\n6. After defining your model, you can use it to run BER simulations. You can do this by creating an instance of your model and calling it in a loop, passing the `batch_size` and `ebno_db` as arguments each time.\n\n7. To compare the model parameters, you can create multiple instances of your model with different parameters and run BER simulations for each one. You can then plot the BER against the SNR to compare the performance of the different model parameters.\n\nPlease note that the exact code and parameters will depend on the specific requirements of your use case."
"The \"build_type_grid\" method of the \"ResourceGrid\" class is used to generate a tensor indicating the type of each resource element of the corresponding resource grid. This grid is used to send data over the OFDM channel, and the method is mainly used in the process of precoding and equalization in the data transmission system.\n\n- **Inputs**\n  - `None` - This method does not take any explicit input arguments but it uses the parameters of the 'ResourceGrid' class, such as `num_ofdm_symbols`, `fft_size`, etc., to build the grid.\n\n- **Outputs**\n  - The output of the function is a tensor of type `tf.int32` and of shape `[num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size]`. This tensor indicates the type of each resource element of the corresponding resource grid. The type can be one of the following:\n    - 0 : Data symbol\n    - 1 : Pilot symbol\n    - 2 : Guard carrier symbol\n    - 3 : DC carrier symbol\n    - For example, a possible output for this function could be a grid indicating the type of each resource element for a system with 4 transmitters, 16 streams per transmitter, 14 OFDM symbols, and 100 FFT size.\n\n- **Procedure**\n  - The method generates a tensor indicating the type of each resource element of the corresponding resource grid. The type of each element can be one of the mentioned above: 0 - Data symbol, 1 - Pilot symbol, 2 - Guard carrier symbol, 3 - DC carrier symbol.\n  - The method first creates an empty grid of complex numbers of shape `[num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size]`.\n  - Then the method fills in the type of each resource element in the grid. The resource elements from the third and fourth dimension are indexed with `resource_i` and `fft_i` respectively. The method fills in the overall grid according to the element type. Please note that the pilot and symbol indices are not related to the overall index of the resource element but only serve as labels for the type of data transported. \n\n  Please note that the context provides no information on the actual code of the `build_type_grid` method in the `ResourceGrid` class. The code interpretation is based on the provided context information. Provided code snippet for `build_type_grid` is below:\n\n```python\ndef build_type_grid(self):\n    # pylint: disable=line-too-long\n    r\"\"\"Returns a tensor indicating the type of each resource element of the\n    corresponding resource grid.\n\n    Resource elements can be one of\n\n    * 0 : Data symbol\n    * 1 : Pilot symbol\n    * 2 : Guard carrier symbol\n    * 3 : DC carrier symbol\n\n    Output\n    ------\n    : [num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], tf.int32\n        The indicated type of each resource element of the resource grid.\n        The type can be one of the mentioned above.\n    \"\"\"\n    mask = tf.fill(self._resource_grid_shape, 0)\n    mask = tf.cast(mask, tf.int32)\n    for se in self.pilot_pattern.se:\n        ridx = self._effectivesubcarrier_ind[self._resource_grid[0,0].numpy()]\n        cidx = se\n        mask[0,0,ridx,cidx] = 1\n    for se in self.pilot_pattern.pds:\n        ridx = self._effectivesubcarrier_ind[se[0].numpy()]\n        cidx = se[1].numpy()\n        mask[0,0,ridx,cidx] = 1\n    for se in self.pilot_pattern.gd:\n        ridx = self._effectivesubcarrier_ind[se[0].numpy()]\n        cidx = se[1].numpy()\n        mask[0,0,ridx,cidx] = 2\n    for se in self.pilot_pattern.dc:\n        mask[0,0,0,se] = 3\n    return mask\n```\n  "
"Here is the detailed information of SymbolLogits2LLRs:   \n  \n[sionna.mapping.SymbolLogits2LLRs(method, num_bits_per_symbol, hard_out=False, with_prior=False, dtype=tf.float32, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#SymbolLogits2LLRs)  \n\nComputes log-likelihood ratios (LLRs) or hard-decisions on bits from a tensor of logits (i.e., unnormalized log-probabilities) on constellation points.\n\nIf the flag with_prior is set, prior knowledge on the bits is assumed to be available. Parameters\n\n- method (One of \"app\" or \"maxlog\", str.) \u2013 The method used for computing the LLRs.\n- num_bits_per_symbol (int.) \u2013 The number of bits per constellation symbol, e.g., 4 for QAM16.\n- hard_out (bool) \u2013 If True, the layer provides hard-decided bits instead of soft-values. Defaults to False.\n- with_prior (bool) \u2013 If True, it is assumed that prior knowledge on the bits is available. Defaults to False.\n- dtype (One of tf.float32 or tf.float64) \u2013 The dtype for the input and output. Defaults to tf.float32. Input must be tf.float.\n- **kwargs \u2013 Additional parameters for the base layer.\n\nInput\n\n- logits ([\u2026,n, num_points], tf.float) \u2013 Logits on constellation points.\n- prior ([\u2026,n or n*num_bits_per_symbol], tf.float) \u2013 Prior for every bit as LLRs. It can be provided either as a tensor of shape [\u2026,n, num_bits_per_symbol] for the entire input batch, or as a tensor that is broadcastable to shape [\u2026,n, num_bits_per_symbol].\n\nOutput\n\n- [\u2026,n, num_bits_per_symbol], tf.float \u2013 LLRs or hard-decisions for every bit.\n  \n**Note: **  \nWith the \u201capp\u201d method, the LLR for the $i\\text{th}$ bit is computed according to $\\begin{align}\n    LLR(i) &= \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert \\mathbf{z},\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert \\mathbf{z},\\mathbf{p}\\right)}\\right)\\\\\n        &=\\ln\\left(\\frac{\n            \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            e^{z_c}\n        }{\n            \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            e^{z_c}\n        }\\right)\n        .\n\\end{align}$\n  \nwhere $\\mathcal{C}_{i,1}$ and $\\mathcal{C}_{i,0}$ are the sets of $2^K$ constellation points for which the $i\\text{th}$ bit is equal to 1 and 0, respectively. $\\mathbf{z} = \\left[z_{c_0},\\dots,z_{c_{2^K-1}}\\right]$ is the vector of logits on the constellation points, $\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]$ is the vector of LLRs that serves as prior knowledge on the $K$ bits that are mapped to a constellation point and is set to $\\mathbf{0}$ if no prior knowledge is assumed to be available, and $\\Pr(c\\lvert\\mathbf{p})$ is the prior probability on the constellation symbol $c$: $\\Pr\\left(c\\lvert\\mathbf{p}\\right) = \\prod_{k=0}^{K-1} \\Pr\\left(b_k = \\ell(c)_k\\lvert\\mathbf{p} \\right)\n= \\prod_{k=0}^{K-1} \\text{sigmoid}\\left(p_k \\ell(c)_k\\right)$  \nwhere $\\ell(c)_k$ is the $k^{th}$ bit label of $c$, where 0 is replaced by -1. The definition of the LLR has been chosen such that it is equivalent with that of logits. This is different from many textbooks in communications, where the LLR is defined as $LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)$.  \n  \nWith the \u201cmaxlog\u201d method, LLRs for the $i\\text{th}$ bit are approximated like $\\begin{align}\n    LLR(i) &\\approx\\ln\\left(\\frac{\n        \\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            e^{z_c}\n        }{\n        \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            e^{z_c}\n        }\\right)\n        .\n\\end{align}$\nsource code:\n```python\nclass SymbolLogits2LLRs(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Computes log-likelihood ratios (LLRs) or hard-decisions on bits from a tensor of logits\n    (i.e., unnormalized log-probabilities) on constellation points.\n\n    If the flag `with_prior` is set, prior knowledge on the bits is assumed to be available.\n\n    Parameters\n    ----------\n    method : One of [\"app\",\"maxlog\"], str.\n        The method used for computing the LLRs.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n\n    hard_out : bool\n        If `True`, the layer provides hard-decided bits instead of soft-values.\n        Defaults to `False`.\n\n    with_prior : bool\n        If `True`, it is assumed that prior knowledge on the bits is available.\n        Defaults to `False`.\n\n    dtype : One of [tf.float32, tf.float64] tf.DType (dtype)\n        The dtype for the input and output.\n        Defaults to tf.float32.\n        Input must be tf.float.\n\n    Input\n    -----\n    logits : [...,n, num_points], tf.float\n        Logits on constellation points.\n\n    prior : [...,n or n*num_bits_per_symbol], tf.float\n        Prior for every bit as LLRs.\n        It can be provided either as a tensor of shape `[...,n,num_bits_per_symbol]`\n        for the entire input batch, or as a tensor that is broadcastable to\n        this shape.\n\n    Output\n    ------\n    : [...,n, num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit.\n    \"\"\"\n    def __init__(self,\n                 method,\n                 num_bits_per_symbol,\n                 hard_out=False,\n                 with_prior=False,\n                 dtype=tf.float32,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        assert method in (\"app\",\"maxlog\"), \"Unknown demapping method\"\n        self._method = method\n        self._hard_out = hard_out\n        self._num_bits_per_symbol = num_bits_per_symbol\n        self._with_prior = with_prior\n        num_points = constellations.num_points(num_bits_per_symbol)\n        self._mask = CenteredShapePadding(num_points-1, num_dims=1)\n\n    def _logits2llrs_app(self, logits, prior):\n        # Prepare for broadcasting to logits dimension\n        log_pr_s = tf.expand_dims(prior, -2)\n        # Add a virtual last dim for convolution\n        log_pr_s = tf.expand_dims(log_pr_s, -1)\n\n        # Now do the LLR calculation in two steps:\n        #   Logits are convolved with prior probability\n        #   Logits are gathered/re-ordered by gathering only the relevant input dims\n        #     and immediately dropping the last index again\n        # The result is a tensor of LLRs of the desired shape\n        llr = logits + log_pr_s\n        llr_max = tf.reduce_max(llr, -1, keepdims=True)\n        llr = log_pr_s - llr\n        llr = tf.squeeze(llr, axis=-1)\n        return llr\n\n    def _logits2llrs_maxlog(self, logits, prior):\n        # Maxlog demapping is implemented using the convolutional layer in two\n        # steps.\n        #   1. The logits are scaled by the prior probability\n        #   2. The maximum value is taken, re-ordering the input dims to bring\n        #      the last index to the location of the maximum.\n\n        # Prepare for broadcasting to logits dimension\n        log_pr_s = tf.expand_dims(prior, -2)\n        # Add a virtual last dim for convolution\n        log_pr_s = tf.expand_dims(log_pr_s, -1)\n\n        # Scaling of logits with prior probability\n        llr = logits + log_pr_s\n\n        # Compute max-value in all but last dimension\n        llr_max = tf.reduce_max(llr, -1, keepdims=True)\n\n        # Re-order input such that the last index is the one of the max-value\n        # and remove the last dim\n        llr = tf.squeeze(self._mask(llr_max, keep_dims=True), -1)\n        return llr\n\n    def __call__(self, inputs):\n        if self._with_prior:\n            logits, prior = inputs\n        else:\n            logits = inputs\n\n        if self._method == \"app\":\n            llr = self._logits2llrs_app(logits, prior)\n        else:\n            llr = self._logits2llrs_maxlog(logits, prior)\n\n        if self._hard_out:\n            llr = (llr >= 0.0)\n            # pylint: disable=unreachable-implicit-tuple\n            return tf.cast(llr, self.dtype)\n        else:\n            return llr\n```  \n  "
"The source code link of `MaximumLikelihoodDetector` is [source code](https://nvlabs.github.io/sionna/_modules/sionna/mimo/detection.html#MaximumLikelihoodDetector).\n\nThe defination of `MaximumLikelihoodDetector` is as follows: \n\n```python\nclass MaximumLikelihoodDetector(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    Maximum-likelihood (ML) detection for OFDM MIMO transmissions.\n\n    This layer implements maximum-likelihood (ML) detection\n    for OFDM MIMO transmissions. Both ML detection of symbols or bits with\n    either soft- or hard-decisions are supported. The OFDM and stream\n    configuration are provided by a\n    :class:`~sionna.ofdm.ResourceGrid` and\n    :class:`~sionna.mimo.StreamManagement` instance, respectively. The\n    actual detector is an instance of :class:`~sionna.mimo.MaximumLikelihoodDetector`.\n    This layer can compute ML estimation of symbols or bits with\n    soft- or hard-decisions. Note that soft-decisions\n    are computed for demapper's ``\"app\"``\n    and arbitrary demapping functions for ``\"maxlog\"``.\n\n    Parameters\n    ----------\n    output : One of [\"bit\", \"symbol\"], str\n        Type of output, either bits or symbols. Whether soft- or\n        hard-decisions are returned can be configured with the\n        ``hard_out`` flag.\n\n    demapping_method : One of [\"app\", \"maxlog\"], str\n        Demapping method used\n\n    resource_grid : ResourceGrid\n        Instance of :class:`~sionna.ofdm.ResourceGrid`\n\n    stream_management : StreamManagement\n        Instance of :class:`~sionna.mimo.StreamManagement`\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        Instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the detector computes hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of ``y``.\n        Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or\n        tf.float64).\n\n    Input\n    ------\n    (y, h_hat, err_var, no) :\n        Tuple:\n\n    y : [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex\n        Received OFDM resource grid after cyclic prefix removal and FFT\n\n    h_hat : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex\n        Channel estimates for all streams from all transmitters\n\n    err_var : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.float\n        Variance of the channel estimation error\n\n    no : [batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float\n        Variance of the AWGN noise\n\n    Output\n    -------\n    One of:\n\n    : [batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream, if ``output`` equals `\"bit\"`.\n\n    : [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int\n        Logits or hard-decisions for constellation symbols for every stream, if ``output`` equals `\"symbol\"`.\n        Hard-decisions correspond to the symbol indices.\n    \"\"\"\n    def __init__(self,\n                 output,\n                 demapping_method,\n                 resource_grid,\n                 stream_management,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        self._output = output\n        self._hard_out = hard_out\n        self._rd_type = resource_grid.typ\n        self._pilot_pattern = None\n        if self._rd_type==\"ofdm\":\n            self._pilot_pattern = resource_grid.pilot_pattern\n        self._demapping_method = demapping_method\n        self._stream_management = stream_management\n        self._constellation = Constellation.create_or_check_constellation(\n                                                        constellation_type,\n                                                        num_bits_per_symbol,\n                                                        constellation,\n                                                        dtype=dtype)\n        self._num_streams_per_tx = stream_management.num_streams_per_tx\n        self._max_num_streams = stream_management.max_num_streams_per_tx\n\n        # Instantiate the maximum-likelihood detector\n        self._mld = MaximumLikelihoodDetector_(self._output,\n                                                self._demapping_method,\n                                                self._constellation,\n                                                self._hard_out,\n                                                self._pilot_pattern,\n                                                dtype=dtype)\n\n    def call(self, inputs):\n        y, h_hat, err_var, no = inputs\n\n        # y has shape:\n        # [batch_size, num_rx, num_rx_ant, num_ofdm_symbols,..\n        # ... fft_size]\n        #\n        # h_hat has shape:\n        # [batch_size, num_rx, num_rx_ant, num_tx, num_streams,...\n        # ... num_ofdm_symbols, num_effective_subcarriers]\n        #\n        # err_var has broadcasted rank of y\n        # no has shape [batch_size, num_rx, num_rx_ant]\n        # or just the first n dimensions of this\n\n        # Remove time dimension from y\n        if self._rd_type==\"time\":\n            y = tf.squeeze(y, axis=3)\n\n        # Transpose y to shape\n        # [batch_size, num_rx, num_rx_ant, fft_size,...\n        #  ... num_ofdm_symbols] and h_hat to\n        # [batch_size, num_rx, num_rx_ant, num_tx*num_streams,...\n        #  ... num_ofdm_symbols, num_effective_subcarriers]\n        y = other_transpose(y, perm=[0, 1, 2, 4, 3])\n        h_hat = other_transpose(h_hat, perm=[0, 1, 2, 4, 5, 3, 6])\n\n        # Add dummy 4th dimension to y to be able to broadcast\n        # to rank of h_hat\n        y = tf.expand_dims(y, axis=4)\n\n        # Compute LLRs using the maximum-likelihood method\n        if self._output == 'bit':\n            llr = self._mld([y, h_hat, err_var, no])\n        else:\n            llr = self._mld([y, h_hat, err_var, no])\n\n        # Reshape LLRs to the expected output shape\n        input_shape = tf.shape(llr)\n        output_shape = tf.concat([input_shape[:-2],\n                                   [self._num_streams_per_tx,\n                                    self._max_num_streams,\n                                    -1]], 0)\n        llr = tf.reshape(llr, output_shape)\n\n        return llr\n```"
"The provided code is for initializing a `TurboEncoder` with custom generator polynomials. In the context of the `sionna.fec.turbo` module, the format of the polynomials for initializing the `TurboEncoder` is not explicitly specified. Hence, using only the code snippet provided, it is not possible to determine the format of the polynomials.\n\nWith respect to the second part of the question, a binary sequence like \"10011\" represents the generator polynomials in the context of polynomial notation for representing convolutional codes. Considering the example from the code snippet where the `TurboEncoder` is initialized with the generator polynomials \"10011\", it can be inferred that the binary sequence \"10011\" is being passed to the `TurboEncoder`. The binary representation is a compact and commonly used form to represent the generator polynomials in the context of convolutional codes, where \"1\" typically represents a polynomial term in the polynomial form of the generator polynomial.\n\nFinally, it's important to note that the exact format or representation of the generator polynomials isn't something that can be determined from the given code snippet alone. It would require explicit documentation or additional context from the source code within the module to confirm the format."
"To use the generator to sample the first few items of the dataset, you need to follow these steps:\n\n1. First, you need to create an instance of the `HD5CIRGen` class, passing the filename of your HDF5 file as an argument.\n\n```python\ngenerator = HD5CIRGen(filename)\n```\n\n2. Afterward, you can use this instance as a function. This function will return a generator that can be iterated over to get the items from your dataset.\n\n```python\nfor (a,tau) in generator():\n    print(a.shape)\n    print(tau.shape)\n```\n\nIn this code, `generator()` opens the HDF5 file and starts yielding the items from the dataset. `for (a,tau) in generator()` then iterates over the items from the dataset, assigning each item to the variables `a` and `tau`. In this case, `a` is the path coefficients and `tau` is the path delays. \n\nThe `i = i + 1 if i < 5 else 0` line is used to control how many items you want to sample from the dataset. In this case, the loop will print the shape of the first 5 items of the dataset. If the dataset has fewer than 5 items, the loop will start from the beginning again. \n\nPlease note that the HDF5 file must be structured correctly for this to work. In the given context, the HDF5 file is expected to have two groups (`a` and `tau`), each containing the path coefficients and path delays, respectively. If your HDF5 file has a different structure, you need to adjust your `HD5CIRGen` class and the way you use it to fit your data."
"To save the estimated matrices for future use, you can follow these steps:\n\n1. Import the necessary modules: `import numpy as np`. \n\n2. Use the `numpy` function `save` to save the matrices to files. The `save` function takes two parameters: the name of the file to save the data to, and the data being saved. \n\nHere is the part of the code that saves the matrices to files:\n\n```python\n# FREQ_COV_MAT : [fft_size, fft_size]\n# TIME_COV_MAT : [num_ofdm_symbols, num_ofdm_symbols]\n# SPACE_COV_MAT : [num_rx_ant, num_rx_ant]\nnp.save('freq_cov_mat', FREQ_COV_MAT.numpy())\nnp.save('time_cov_mat', TIME_COV_MAT.numpy())\nnp.save('space_cov_mat', SPACE_COV_MAT.numpy())\n```\n\nIn this code, `FREQ_COV_MAT`, `TIME_COV_MAT`, and `SPACE_COV_MAT` are the matrices that are being saved. The `numpy` function `numpy` is used to call the saving method, and `.numpy()` is used on the end of the matrices to convert them to a numpy array before saving. \n\nPlease ensure that the file name (`'freq_cov_mat'`, `'time_cov_mat'`, `'space_cov_mat'`) is not already used for another file in the system."
"The concept of Iterative Detection and Decoding (IDD) in the context of MIMO simulations is a process where the data detector and the channel decoder exchange soft-information iteratively to decode information passed through a noisy channel. This process is used to improve the accuracy of data detection and decoding in wireless communication systems.\n\nIn the context of 'Sionna,' a novel Python package for wireless simulation, IDD involves the use of various components of the package in the implementation of the MIMO IDD simulation. These components include the implementation of a MIMO IDD transmitter and a MIMO IDD receiver with various processing parameters such as the number of detected streams, the number of iterations for the IDD process, and the specific algorithms used for data detection and decoding.\n\nThe IDD process starts with the transmission of modulated data from the IDD transmitter. The data is then passed through a MIMO channel where it is affected by noise. The received signal at the IDD receiver is first processed by a preprocessing block which prepares the received signal for the data detector and the channel decoder. The data detector then computes *a posteriori* bit levels and log-likelihood ratios (LLRs), which are used to form new estimates of the transmitted data and the interference. These estimates are then passed to the channel decoder to generate a new estimate of the transmitted information.\n\nThe IDD process takes place iteratively, with each iteration starting with the estimation of the channel state. The number of iterations is a parameter that can be adjusted based on the performance of the system. The process continues until a stopping criterion is met, such as the number of iterations or a certain level of confidence in the transmitted information.\n\nIn the context of 'Sionna,' the IDD process is used to evaluate the performance of various MIMO detectors and decoders in the presence of realistic noise and interference conditions. The package provides a flexible and efficient implementation of MIMO IDD simulations, with different components can be combined to form complex simulators for evaluation.\n\nPlease note that the explanation provided is based on the given context and may vary depending on the specific implementation or use case."
"Here is the detailed information of Descrambler:   \n\nDescrambler(scrambler, binary=True, dtype=None, **kwargs) Source code:\n```python\nclass Descrambler(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"Descrambler(scrambler, binary=True, dtype=None, **kwargs)\n\n    Descrambler for a given scrambler.\n\n    The class inherits from the Keras layer class and can be used as layer in a\n    Keras model.\n\n    Parameters\n    ----------\n        scrambler: Scrambler, Scrambler5G\n            Associated ``Scrambler`` or \"Scrambler5G\" instance which should be\n            descrambled.\n\n        binary: bool\n            Defaults to True. Indicates whether bit-sequence should be flipped\n            (i.e., binary operations are performed) or the signs should be\n            flipped (i.e., soft-value/LLR domain-based).\n\n        dtype: None or tf.DType\n            Defaults to `None`. Defines the datatype for internal calculations\n            and the output dtype. If no explicit dtype is provided the\n            dtype from the associated interleaver is used.\n\n    Input\n    -----\n        (x, seed):\n            Either Tuple ``(x, seed)`` or ``x`` only (no tuple) if the internal\n            seed should be used:\n\n        x: tf.float\n            1+D tensor of arbitrary shape.\n\n        seed: int\n            An integer defining the state of the random number\n            generator. If explicitly given, the global internal seed is\n            replaced by this seed. Can be used to realize random\n            scrambler/descrambler functions (call with same random seed).\n\n    Output\n    ------\n        : tf.float\n            1+D tensor of same shape as ``x``.\n\n    Raises\n    ------\n        AssertionError\n            If ``scrambler`` is not an instance of `Scrambler`.\n\n        AssertionError\n            If ``seed`` is provided to list of inputs but not an\n            int.\n\n        TypeError\n            If `dtype` of ``x`` is not as expected.\n\n    Note\n    ----\n        For inverse scrambling, the same scrambler can be re-used (as the\n        values are flipped again, i.e., result in the original state). However,\n        the seed must be different as the state of the random number\n        generator has changed during the first scrambling step.\n    \"\"\"\n\n    def __init__(self,\n                 scrambler,\n                 binary=True,\n                 dtype=None,\n                 **kwargs):\n\n        assert isinstance(scrambler, (Scrambler, Scrambler5G)), \\\n            \"scrambler must be an instance of Scrambler.\"\n        self._scrambler = scrambler\n\n        assert isinstance(binary, bool), \"binary must be bool.\"\n        self._binary = binary\n\n        # if dtype is None, use same dtype as associated scrambler\n        if dtype is None:\n            dtype = self._scrambler.dtype\n\n        super().__init__(dtype=dtype, **kwargs)\n\n        if self._scrambler.keep_state is False:\n            print(\"Warning: scrambler uses random sequences that cannot be \" \\\n                  \"access by descrambler. Please use keep_state=True and \" \\\n                  \"provide explicit random seed as input to call function.\")\n\n        if self._scrambler.dtype != self.dtype:\n            print(\"Scrambler and descrambler are using different \" \\\n                \"dtypes. `descrambler` should typically have the same \" \\\n                \"dtype as `scrambler`. Otherwise, internal precision \" \\\n                \"conversion might be triggered.\")\n\n    #########################################\n    # Public methods and properties\n    #########################################\n\n    @property\n    def scrambler(self):\n        \"\"\"Associated scrambler instance.\"\"\"\n        return self._scrambler\n\n    #########################\n    # Utility methods\n    #########################\n\n    #########################\n    # Keras layer functions\n    #########################\n\n    def build(self, input_shape):\n        \"\"\"Build the model and initialize variables.\"\"\"\n        pass\n\n    def call(self, inputs):\n        r\"\"\"Descrambling function.\n\n        This function returns the descrambled version of ``inputs``.\n\n        ``inputs`` can be either a list ``[x, seed]`` or single tensor ``x``.\n\n        Args:\n            inputs (List): ``[x, seed]``, where\n            ``x`` (tf.float32): Tensor of arbitrary shape.\n            ``seed`` (int): An integer defining the state of the random number\n                generator. If not given, the global internal seed is\n                replaced by this seed. Can be used the realize random\n                scramble/descramble functions (call with same random seed).\n\n        Returns:\n            `tf.float32`: Tensor of same shape as the input.\n\n        Raises:\n            AssertionError: If ``seed`` is not `None` or `int`.\n        \"\"\"\n\n        # Scrambler\n        if isinstance(self._scrambler, Scrambler):\n            if isinstance(self._scrambler.keep_state, bool):\n                keep_state = self._scrambler.keep_state\n            else: # assume self._scrambler.keep_state is a string\n                assert self._scrambler.keep_state == \"True\", \\\n                    \"keep_state must be `True` or `False`.\"\n                keep_state = True\n            if isinstance(self._scrambler.seed, int):\n                seed = self._scrambler.seed\n            else: # is string\n                assert self._scrambler.seed == \"True\", \\\n                    \"seed must be `None` or integer.\"\n                seed = self._scrambler.seed\n\n        # Scrambler5G\n        elif isinstance(self._scrambler, Scrambler5G):\n            keep_state = self._scrambler.cylic\n            seed = self._scrambler.seed\n\n        else:\n            raise AssertionError(\"Unknown instance type of scrambler.\")\n\n        if inputs.__class__ is list: # if inputs is a list, but not strict\n            if len(inputs)>2:\n                raise TypeError(\"inputs can be a list of size 1 or 2.\")\n            elif len(inputs)==1: # if user did not provide explicit seed\n                s = tf.random.stateless_uniform([], seed, 0.0, 1.0, self.dtype)\n                x = inputs\n                seed = s\n            else: # assume inputs = [x, seed]\n                x, seed = inputs\n                if not isinstance(seed, int):\n                    raise TypeError(\"seed must be an integer.\")\n        else: # if inputs is not a list\n            s = tf.random.stateless_uniform([], seed, 0.0, 1.0, self.dtype)\n            x = inputs\n            seed = s\n\n        if keep_state:\n            self._scrambler(seed=seed)\n        else:\n            self._scrambler()\n        x_out = self._scrambler([x, seed])\n\n        if self._binary: # flip bits\n            x_out = tf.bitwise_xor(x_out, tf.cast(tf.fill(x_out.shape, 1), x_out.dtype))\n\n        return x_out\n```"
"Here is the definition of KBestDetector: sionna.ofdm.KBestDetector(output, num_streams, k, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, use_real_rep=False, list2llr=None, dtype=tf.complex64, **kwargs).  \n  \nThe source code link of KBestDetector is [KBestDetector](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#KBestDetector).  \n  \nThe source code files of sionna.ofdm are attached below:  \n  [detector.py](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#KBestDetector)  \n  [detection.py](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#KBestDetector)  \n  [utils.py](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#KBestDetector)  \n  \nThe explanation of KBestDetector is:\nThis layer wraps the MIMO K-Best detector for use with the OFDM waveform. Both detection of symbols or bits with either soft- or hard-decisions are supported. The OFDM and stream configuration are provided by a ResourceGrid and StreamManagement instance, respectively. The actual detector is an instance of KBestDetector.  \n  \n**Parameters**\n\n- `output` (str): Type of output, either \"bit\" or \"symbol\", options are [\"bit\", \"symbol\"].\n- `num_streams` (tf.int): Number of transmitted streams.\n- `k` (tf.int): Number of paths to keep. Cannot be larger than the number of constellation points to the power of the number of streams.\n- `resource_grid` (ResourceGrid): Instance of ResourceGrid.\n- `stream_management` (StreamManagement): Instance of StreamManagement.\n- `constellation_type` (str): Constellation type, options are [\"qam\", \"pam\", \"custom\"], for \"custom\", an instance of Constellation must be provided.\n- `num_bits_per_symbol` (int): Number of bits per constellation symbol, necessary for \"qam\" and \"pam\" constellation types.\n- `constellation` (Constellation): Instance of Constellation or None. If None, both `constellation_type` and `num_bits_per_symbol` must be specified.\n- `hard_out` (bool): If True, the detector computes hard-decided bit values or constellation point indices instead of soft-values. Defaults to False.\n- `use_real_rep` (bool): If True, the detector use the real-valued equivalent representation of the channel. Note that this only works with a QAM constellation. Defaults to False.\n- `list2llr` (List2LLR or None): The function used to compute LLRs from a list of candidate solutions. If None, the default solution List2LLRSimple is used.\n- `dtype` (tf.DType): The dtype of `y`. Defaults to tf.complex64. The output dtype is the corresponding real dtype (tf.float32 or tf.float64).  \n  \n**Input**\n\n- `(y, h_hat, err_var, no)` \u2013 Tuple:\n  - `y` ([batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex): Received OFDM resource grid after cyclic prefix removal and FFT.\n  - `h_hat` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex): Channel estimates for all streams from all transmitters.\n  - `err_var` ([Broadcastable to shape of h_hat], tf.float): Variance of the channel estimation error.\n  - `no` ([batch_size, num_rx, num_rx_ant] or only the first n dimensions, tf.float): Variance of the AWGN.  \n  \n**Output**\n\n- `x_hat` ([batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float or [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int): Estimated symbols or bits.\n- `no_eff` ([batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float): Effective noise variance for each estimated symbol or bit.\n- `ind_hat` ([batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.int): If hard_out is True, the output index of the estimated constellation symbol for each stream.\n  \n**Note:**\nIf you want to use this layer in Graph mode with XLA, i.e., within a function that is decorated with @tf.function(jit_compile=True), you must set sionna.Config.xla_compat=true. See xla_compat.  \n  "
"The `position` and `orientation` properties in Sionna are used to move scene objects, such as receivers or transmitters, within the radio propagation simulation scene. The `position` property is used to specify the location or offset of an object in the global coordinate system, while the `orientation` property is used to define the orientation or direction of the object.\n\nFor example, to move a receiver named \"rx\" to a position of (10, 150, 50) in the scene, you would use the following Python code:\n\n```python\nrx.position = (10, 150, 50)\n```\n\nThis code sets the `position` of the \"rx\" object to (10, 150, 50) in the global coordinate system. It is important to note that the `position` property of the object can only be set along the z-axis if the `orientation` property of the object is set to its default value `(0,0,0)`. If the `orientation` property is set to a different value, you would need to adjust the `position` property accordingly to ensure that the object is properly placed in the scene.\n\nSimilarly, the `orientation` property is used to set the orientation of an object. For example, to set the orientation of the \"rx\" object to 45 degrees around the z-axis, you would use the following code:\n\n```python\nrx.orientation = (0, 0, 45)\n```\n\nThis sets the `orientation` of the \"rx\" object to 45 degrees around the z-axis. The `orientation` is specified as a tuple `(a, b, c)` where `a`, `b`, and `c` are the angles of rotation around the x, y, and z axis, respectively. In the example above, we are setting `a` and `b` to 0, which means we are only rotating around the z-axis.\n\nIt is important to note that when setting the `position` and `orientation` properties, the object will be moved or rotated with respect to the global coordinate system. If you want to move or rotate the object with respect to its local coordinate system, you would need to define a transformation that applies the desired movement or rotation, and then assign that transformation to the `position` or `orientation` property."
"To run the final evaluation for different system configurations in Sionna RT, you can follow these steps:\n\n1. **Define the Different System Configurations**: Identify the different parameters that make up the system configurations you want to evaluate. These could include the number of transmitters and receivers, their antenna configurations, the carrier frequency, the direction the transmitters are facing, and so on.\n\n2. **Create the Scene and Add Transmitters/Receivers**: Using the Sionna RT API, create a new scene for each system configuration you want to evaluate. Within each scene, create the transmitters and receivers, making sure to set them up according to the specific configuration you're interested in.\n\n3. **Compute Paths**: For each scene, compute the paths. This can be done using the `compute_paths` method of the scene object. You may want to vary the number of samples used for the computations to ensure you get results for each configuration.\n\n4. **Compute Metrics**: For each scene, compute the desired metrics. This could include the coverage map, the average received power, the contrast enhancement, and any other metrics you're interested in.\n\n5. **Store the Results**: Store the results for each system configuration in a convenient format. This could be a list of dictionaries, with each dictionary containing the results for a different configuration.\n\n6. **Visualize the Results**: Finally, visualize the results. This could involve plotting the coverage map, visualizing the paths, or plotting the contrast enhancement. This can help you understand how the different system configurations affect the propagation of the signal.\n\nNote that the exact code and methods used will depend on the specific requirements of your evaluation. The Sionna RT API provides a wide range of methods and tools that can be used to perform these steps."
"To compute the exact Doppler shifts for a given scene, you can use the formula provided in the context:\n\n```\ndoppler = (dot(k_i, k_t))^2 * v / (c * (2*pi*f_c))\n```\n\nHere's how you can compute the exact Doppler shifts based on this equation:\n\n1. Define the transmitter and receiver positions, as well as the orientation of their antennas. You can use the `POSITION_Tx` and `POSITION_Rx` tensors provided in the context.\n\n2. Set the scene frequency (`f_c`) to the desired value. The context provides a value of 2.14e9 for a carrier frequency of 2.14GHz.\n\n3. Compute the incoming and outgoing unit vectors for the transmission (`k_i`) and reception (`k_t`) antennas using the `r_hat` function provided in the context.\n\n4. Compute the Doppler shift for the Line-of-Sight (LoS) path using the formula:\n\n```python\ndoppler_los = (dot(k_i, k_t))*c/(2*np.pi*f_c)\n```\n\n5. Finally, compute the Doppler shift for the Reflected path using the formula:\n\n```python\ndoppler_ref = (dot(k_i, k_t))*c/(2*np.pi*f_c)\n```\n\nHere is the exact implementation for the given context:\n\n```python\nf_c = 2.14e9 # in Hz\nk_i = r_hat(POSITION_Tx, tx_pole_orient).numpy()\nk_t = r_hat(POSITION_Rx, rx_pole_orient).numpy()\ndoppler_los = np.abs((np.dot(k_i, k_t)).numpy()) * c / (2 * np.pi * f_c)\ndoppler_ref = np.abs((np.dot(k_i, k_t)).numpy()) * c / (2 * np.pi * f_c)\n```\n\nPlease note that the exact Doppler shifts depend on the positions and orientations of the transmitters and receivers, which must be properly set for the specific scenario you are modeling."
"Here is the definition of cir_to_time_channel: sionna.channel.cir_to_time_channel(bandwidth, a, tau, l_min, l_max, normalize=False)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/utils.html#cir_to_time_channel)  \n```python\ndef cir_to_time_channel(bandwidth, a, tau, l_min, l_max, normalize=False):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Compute the channel taps forming the discrete complex-baseband\n    representation of the channel from the channel impulse response\n    :math:`(a, \\tau)`.\n\n    This function assumes that a sinc filter is used for pulse shaping\n    and receive filtering. Therefore, given a channel impulse response\n    :math:`(a_{m}(t), \\tau_{m}), 0 \\leq m \\leq M-1`, the channel taps\n    are computed as follows:\n\n    .. math::\n\n        \\bar{h}_{b, \\ell}\n        = \\sum_{m=0}^{M-1} a_{m}\\left(\\frac{b}{W}\\right)\n            \\text{sinc}\\left( \\ell - W\\tau_{m} \\right)\n\n    for :math:`\\ell` ranging from ``l_min`` to ``l_max``, and where :math:`W`\n    is the ``bandwidth``.\n\n    Input\n    ------\n    bandwidth : float\n        Bandwith [Hz]\n\n    a : [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex\n        Path coefficients\n\n    tau : [batch size, num_rx, num_tx, num_paths] or [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths], tf.float\n        Path delays [s]\n\n    l_min : int\n        Smallest time-lag for the discrete complex baseband channel (:math:`L_{\\text{min}}`)\n\n    l_max : int\n        Largest time-lag for the discrete complex baseband channel (:math:`L_{\\text{max}}`)\n\n    normalize : bool\n        If set to `True`, the channel is normalized over the block size\n        to ensure unit average energy per time step.\n        Defaults to `False`.\n\n    Output\n    -------\n    hm : [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_steps, l_max - l_min + 1], tf.complex\n        Channel taps coefficients\n    \"\"\"\n\n    # Tensor dims:\n    #   a:            [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps]\n    #   bandwidth:    [batch size]\n    #   l_min:        Scalar\n    #   l_max:        Scalar\n    #   hm:           [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_steps, l_max - l_min + 1]\n\n    a = tf.squeeze(a, axis=-1)\n    tau = tf.expand_dims(tau, -1)\n\n    # Add a dim for broadcasting\n    tau = tf.expand_dims(tau, -1)\n\n    # Compute frequency-dependent channel as sum over all paths\n    hm = tf.reduce_sum(a, axis=-2)\n\n    # At this point, tensor is of shape\n    #   [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_steps, num_freq_bins]\n\n    # Prepare the sinc filter\n    h_sinc = sinc_filter(bandwidth, normalize=normalize)\n\n    # Time sampling frequency\n    delta_t = 1 / bandwidth\n\n    # Downsample the channel by keeping every \"l_max-l_min\"th sample\n    hm = hm[..., l_min-1::l_max-l_min, :]\n    hm = tf.expand_dims(hm, axis=-2)\n\n    # Convolve channel with sinc filter\n    hm = tf.squeeze(tf.nn.conv1d(hm, h_sinc, stride=1, padding=\"valid\"), axis=-1)\n    # Put into complex baseband\n    hm = tf.multiply(hm, tf.cast(delta_t, hm.dtype))\n\n    # Done\n    return hm\n```"
"Generating the Channel Frequency Response and the Discrete-Time Channel Impulse Response\n---\n\nTo generate the Channel Frequency Response, you can use the `cir_to_ofdm_channel` function from the Sionna channel module. This function computes the channel frequency response $ \\widehat{h}_{b,\\ell} $ for all $ b $ frequency subcarriers and for all $ \\ell $ channel taps up to the maximum delay as given in the provided discrete-time channel impulse response. \n\nHere is an example of how you can use this function:\n\n```python\n# your values for l_min and l_max here\nl_min = 0\nl_max = 100\nh_freq = cir_to_ofdm_channel(a, tau, l_min, l_max)\n```\n\nIn this example, `a` and `tau` are the parameters generated from the `cdl` function. `l_min` and `l_max` are the lower and upper bound of the channel delay spread, and `h_freq` will be the channel frequency response.\n\nTo generate the Discrete-Time Channel Impulse Response, you can use the `cir_to_time_channel` function from the Sionna channel module. This function transforms the continuous-time channel impulse response into the discrete time domain.\n\nHere is an example of how you can use this function:\n\n```python\n# Compute the time channel impulse response\nh_time = cir_to_time_channel(a, tau, l_min, l_max, rg.bandwidth)\n```\n\nIn this example, `a`, `tau`, `l_min`, and `l_max` are the same as before, and `rg.bandwidth` is the channel bandwidth.\n\nPlease replace the parameters with the appropriate values based on your specific use case."
"from sionna.mapping import Constellation, Mapper, Demapper\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# First, define the number of bits per symbol for QPSK and 16-QAM\nnum_bits_per_symbol_qpsk = 2\nnum_bits_per_symbol_16qam = 4\n\n# Create a QPSK constellation with zero mean and unit power\nconstellation_qpsk = Constellation(\"qam\", num_bits_per_symbol_qpsk, mean=0, power=1)\n\n# Create a Mapper layer to map bits into the QPSK constellation\nmapper_qpsk = Mapper(constellation=constellation_qpsk)\n\n# Now, create a 16-QAM constellation with zero mean and unit power\nconstellation_16qam = Constellation(\"qam\", num_bits_per_symbol_16qam, mean=0, power=1)\n\n# Create a Mapper layer to map bits into the 16-QAM constellation\nmapper_16qam = Mapper(constellation=constellation_16qam)\n\n# Generate random bits with a batch size of 1024 and visualize the QPSK constellation\n# 1024 is the desired batch size\nbatch_size = 1024\nbits = tf.random.uniform(shape=[batch_size, num_bits_per_symbol_qpsk], minval=0, maxval=2, dtype=tf.int32)\nprint(\"Random bits (QPSK):\")\nprint(bits)\nsymbols_qpsk = mapper_qpsk(bits)\nplt.figure(figsize=(5,5))\nplt.scatter(np.real(symbols_qpsk), np.imag(symbols_qpsk))\nplt.xlim([-1.5, 1.5])\nplt.ylim([-1.5, 1.5])\nplt.title(\"QPSK Constellation\")\nplt.grid()\nplt.show()\n\n# Generate random bits with a batch size of 1024 and visualize the 16-QAM constellation\n# 1024 is the desired batch size\nbits = tf.random.uniform(shape=[batch_size, num_bits_per_symbol_16qam], minval=0, maxval=2, dtype=tf.int32)\nprint(\"Random bits (16-QAM):\")\nprint(bits)\nsymbols_16qam = mapper_16qam(bits)\nplt.figure(figsize=(7,7))\nplt.scatter(np.real(symbols_16qam), np.imag(symbols_16qAM))\nplt.xlim([-1.5, 1.5])\nplt.ylim([-1.5, 1.5])\nplt.title(\"16-QAM Constellation\")\nplt.grid()\nplt.show()"
"As mentioned in the context, the `LDPCBPDecoder` can be made stateful by setting the `stateful` parameter to `True`. This is useful when we want to decode multiple independent codewords which is common in iterative decoding scenarios. \n\nWhen dealing with a stateful `LDPCBPDecoder`, the significance of the `msg_vn` parameter comes from the requirement to provide the VN messages from the previous iteration. The VN messages are the messages updated at the variable node (VN) side and are a crucial part of the decoding process to iteratively exchange information between VN and CN nodes.\n\nHere is an example of how you might handle a stateful `LDPCBPDecoder`:\n\n```python\nfrom sionna.fec.ldpc.decoding import LDPCBPDecoder\nfrom sionna.fec.ldpc.utils import load_parity_check_examples, EbNo\n\n# It's assumed you've previously loaded the parity-check matrix below\npcm, generator_system = load_parity_check_examples(pcm_id=1)\n\n# Set up your decoder\nbp_decoder = LDPCBPDecoder(pcm, trainable=False, cn_type='boxplus-phi', snr_type='ebno')\n\n# EbNo at which the decoder will operate\nebno_db = 2.0\nno = EbNo(ebno_db, ebno_type='db', num_bits_per_symbol=2, coderate=coderate)\n\n# Fake log-likelihood ratios (LLRs) of the \"received\" codeword after passing through a channel\n# You will need to replace this with your actual received LLRs\nllr_ch = \"...\"  # Shape: [batch size, n]\n\n# Decode the message\ndecoded_bits = bp_decoder(llr_ch, no)\n\n# If you have actual indices of frozen bits, you can also pass them to the decoder\n# Let's assume `frozen_pos` are the indices of frozen positions within a codeword.\n# You will need to determine these from your actual LDPC code definition.\n# frozen_pos = [...]  # Shape: [n_frozen], list of integers\n# bp_decoder = LDPCBPDecoder(pcm, trainable=False, cn_type='boxplus-phi', snr_type='ebno', frozen_pos=frozen_pos)\n# decoded_bits = bp_decoder((llr_ch, frozen_pos), no)\n```\n\nIn this example, `LLR_ch` is a tensor representing the received LLRs from the channel. The `LDPCBPDecoder` uses this information, along with the known channel reliability information from the parity check matrix, to perform iterative belief propagation decoding and decode the actual message bits.\n\nThe `msg_vn` parameter is not passed explicitly in the code snippet. However, to initialize and run the decoder, the previous VN messages are required to be passed after the first input is given. The `msg_vn` parameter would be a tensor of shape `[batch_size, num_c_nodes, num_edges_per_c_node]` and is not typically set manually. It would be generated during the decoding process and represents the outgoing VN messages.\n\nPlease note that the code snippet given decodes a single codeword. If you want to decode multiple codewords, you would need to loop over different codewords provided in an input tensor.\n\nAdditionally, the application of the decoder in the example is not stateful, even though the `LDPCBPDecoder` is initialized with the `stateful` parameter set to `True`. For a stateful iterative decoder, you would need to follow the initialization and updating process within a loop or use a method that supports iterative decoding natively."
"Here is the detailed information of subcarrier_frequencies:   \n  \n[sionna.channel.wireless.subcarrier_frequencies(num_subcarriers, subcarrier_spacing, center_frequency=0.0, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/channel/wireless.html#subcarrier_frequencies)\n\nCompute the (baseband) frequencies of the subcarriers.\n\nThe function takes as input the number of subcarriers, the subcarrier\nspacing, the center frequency, and the dtype, and returns the\nfrequencies of the subcarriers.\n\n**Input**\n\n- `num_subcarriers` (int): Number of subcarriers.\n- `subcarrier_spacing` (float): Subcarrier spacing in Hz.\n- `center_frequency` (float): Center frequency in Hz. This\n  parameter is optional and defaults to 0.\n- `dtype` (tf.DType): Datatype to use for internal processing and output. Three\n  dtype are supported: `tf.complex64`, `tf.complex128`, and `tf.complex.\n\n**Output**\n\n- `frequencies` ([num_subcarriers], tf.float): Subcarrier frequencies.\n\nsource code:\n```python\ndef subcarrier_frequencies(num_subcarriers,\n                           subcarrier_spacing,\n                           center_frequency=0.0, dtype=tf.complex64):\n    r\"\"\"\n    Compute the (baseband) frequencies of the subcarriers.\n\n    The function takes as input the number of subcarriers, the subcarrier\n    spacing, the center frequency, and the `dtype`, and returns the\n    frequencies of the subcarriers.\n\n    Input\n    ------\n        num_subcarriers : int\n            Number of subcarriers.\n\n        subcarrier_spacing : float\n            Subcarrier spacing in Hz.\n\n        center_frequency : float\n            Center frequency in Hz. It defaults to 0.\n\n        dtype : tf.DType\n            Datatype to use for internal processing and output. Three\n            `dtype` are supported: `tf.complex64`, `tf.complex128`, and\n            `tf.complex.\n\n    Output\n    ------\n        frequencies : [num_subcarriers], tf.float\n            Subcarrier frequencies.\n    \"\"\"\n    n = tf.cast(num_subcarriers, dtype=tf.float)\n    delta_f = tf.cast(subcarrier_spacing, dtype) / n\n    f = delta_f * tf.range(-tf.cast(n/2, dtype), tf.cast(n/2, dtype),\n                           dtype=dtype)\n    if center_frequency != 0.0:\n        f = f + tf.cast(center_frequency, dtype)\n    return f\n```"
"To simulate the transmission of a single Gaussian impulse over a lumped amplification channel model consisting of multiple fiber spans and optical amplifiers, also known as Erbium Doped Fiber Amplifiers (EDFA), you can follow these steps:\n\n1. **Set up the environment**: Import all the necessary libraries and modules. This will include Sionna, which is the simulation platform used in the context, and other necessary libraries like TensorFlow and NumPy.\n\n2. **Configure the GPU**: Configure the notebook to use only a single GPU and allocate only as much memory as needed.\n\n3. **Set up the channel model**: Set up the parameters for the channel model. This will include the number of spans, the span attenuation, the amplifier gain, the noise figure, the frequency, the fiber length, and other parameters related to the setup.\n\n4. **Define the impulse**: Define the Gaussian impulse that you want to transmit. In the context, a Gaussian impulse is defined by its peak power $P_0$ and its pulse duration.\n\n5. **Simulate the transmission**: Use the `sionna.channel.optical.lumped_amplification` layer to simulate the transmission of the impulse over the channel. This layer models the propagation of the impulse over the optical channel, taking into account the attenuation, the gain, the noise, and other parameters.\n\n6. **Visualize the results**: Visualize the results of the simulation. This can be done by plotting the transmitted and received impulses and comparing them.\n\nPlease note that the exact code and parameters used in the context may vary depending on the specific requirements of your simulation."
"The CRCDecoder class allows for the verification of cyclic redundancy checks (CRC) and the removal of parity bits. This class inherits from the Keras layer class and can be used as a layer in a Keras model. The class is associated with a specific CRCEncoder instance, such that the decoder is paired with a specific encoder. This ensures that the decoder is correctly matched to the encoder in terms of the types of CRC polynomials used.\n\nThe class has the following parameters:\n- `crc_encoder`: This is an instance of the CRCEncoder class to which the CRCDecoder is associated. The decoder is paired with a specific encoder to ensure that the appropriate CRC polynomials are used for decoding.\n- `dtype`: This is a TensorFlow DataType (e.g., tf.float32). It defines the datatype for internal calculations and the output dtype. If no explicit dtype is provided, the dtype from the associated interleaver is used.\n\nThe input is a 2+D Tensor containing the CRC encoded bits. The last `crc_degree` bits are considered to be parity bits. The output is a tuple of two tensors: `x` and `crc_valid`. `x` is a 2+D tensor containing the information bit sequence without CRC parity bits. `crc_valid` is a 2+D tensor containing the result of the CRC per codeword.\n\nInvalidArgumentError is raised when the rank of the input is less than 2. \n\nNote: The CRC polynomials from Sec. 5.1 in 3GPPTS38212_CRC are available: {CRC24A, CRC24B, CRC24C, CRC16, CRC11, CRC6}. Please replace 3GPPTS38212_CRC with the appropriate prefix if using a different library."
"The `Constellation` class in this context outputs a weighted graph. The graph is represented as an association matrix between fixed input and output nodes. This representation can be either a bit-labeling or a logarithmic form. \n\nIn constellation models, the weighted graph is used to indicate which bit positions are flipped in the binary representation of the index of each constellation point when a constellation is transmitted over an AWGN channel. This is a result of the properties of the bit-interleaved coded modulation (BICM) scheme, which is commonly used in communication systems to map bits to constellation points.\n\nFor practical purposes, the class also includes methods to create or check constellations and to display the constellation graph. The latter is especially useful for visualizing the mapping of bits to constellation points."
"The `dtype` parameter in the `LinearEncoder` is a TensorFlow data type that is used to define the type of the output data from the encoder. For the `LinearEncoder` class, the `dtype` parameter is defined with a default value of `tf.float32`, which is a standard TensorFlow data type. \n\nIn the provided context, `enc_mat` is used to create the encoder, and `dtype` is set in the input parameters for the LinearEncoder. However, it is not explicitly clear in the provided context which specific datatype is expected to be used for the output of the `LinearEncoder`. Since `enc_mat` is typically a binary matrix (which often is represented as integers), it would be expected that the output of the encoder would be binary, represented in a TensorFlow datatype as `tf.uint8`.\n\nTo confirm if this assumption is correct, it's important to check the documentation or source code for the `sionna.fec.linear.LinearEncoder` class, but this information is not available in the provided context."
"Here is the detailed information of sionna.utils.matrix_pinv:   \n\n[sionna.utils.matrix_pinv(tensor)](https://nvlabs.github.io/sionna/_modules/sionna/utils/tensors.html#matrix_pinv)\n\nComputes the MoorePenrose (or pseudo) inverse of a matrix.\n\nGiven a batch of $M \\times K$ matrices $\\mathbf{A}$ with rank $K$ (i.e., linearly independent columns), the function returns $\\mathbf{A}^+$, such that $\\mathbf{A}^{+}\\mathbf{A}=\\mathbf{I}_K$. The two inner dimensions are assumed to correspond to the matrix rows and columns, respectively.\n\n### Parameters\n\n- **tensor** ([\u2026, M, K], tf.DType): A tensor of rank greater than or equal to two.\n\n### Returns\n\n- A tensor of shape [\u2026, K, M], tf.DType: The pseudo inverse of the last two dimensions of `tensor`.\n\n**Note:** If you want to use this function in Graph mode with XLA, i.e., within a function that is decorated with `@tf.function(jit_compile=True)`, you must set `sionna.config.xla_compat=true`. See `xla_compat`."
"Here is the detailed information of Demapper:   \n  \n[sionna.mapping.Demapper(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, with_prior=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Demapper)  \n\nComputes log-likelihood ratios (LLRs) or hard-decisions on bits for a tensor of received symbols.\nIf the flag with_prior is set, prior knowledge on the bits is assumed to be available.\n\nThis class defines a layer implementing different demapping functions. All demapping functions are fully differentiable when soft-decisions are computed.\n\n### Parameters\n\n- **demapping_method** (One of [\"app\", \"maxlog\"], str.) The demapping method used.\n\n- **constellation_type** (One of [\"qam\", \"pam\", \"custom\"], str.) For \"custom\", an instance of Constellation must be provided.\n\n- **num_bits_per_symbol** (int) The number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation types \"qam\" and \"pam\".\n\n- **constellation** (Constellation) An instance of Constellation or None. In the latter case, constellation_type and num_bits_per_symbol must be provided.\n\n- **hard_out** (bool) If True, the Demapper provides hard-decided bits instead of soft-values. Defaults to False.\n\n- **with_prior** (bool) If True, it is assumed that prior knowledge on the bits is available. Defaults to False.\n\n- **dtype** (One of [tf.complex64, tf.complex128] tf.DType) The dtype of y. Defaults to tf.complex64. The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n### Input\n\n- **y** ([..., n], tf.complex) \u2013 The received symbols.\n\n- **no** (Scalar or [...,n], tf.float) \u2013 The noise variance estimate. It must have the same shape as y. If not, the dtype argument must be provided.\n\n- **prior** (Scalar or [num_bits_per_symbol] or [n, num_bits_per_symbol], tf.float) \u2013 Prior for every bit as LLRs. It can be provided either as a tensor of shape [num_bits_per_symbol] for the entire input batch, or as a tensor that is broadcastable to [\u2026, n, num_bits_per_symbol]. Only required if the with_prior flag is set.\n\n### Output\n\n- **Output** ([\u2026, n*num_bits_per_symbol], tf.float) \u2013 LLRs or hard-decisions for every bit.\n  \n**Note: ** With the \u201capp\u201d demapping method, the LLR for the $i\\text{th}$ bit is computed according to $LLR(i) = \\ln\\left(\\Pr\\left(b_i=1\\lvert y,\\mathbf{p}\\right)\\middle/\\Pr\\left(b_i=0\\lvert y,\\mathbf{p}\\right)\\right) =\\ln\\left(\\frac{ \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right) \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right) }{ \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right) \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right) }\\right)$ where $\\mathcal{C}_{i,1}$ and $\\mathcal{C}_{i,0}$ are the sets of constellation points for which the $i\\text{th}$ bit is equal to 1 and 0, respectively. $\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]$ is the vector of LLRs that serves as prior knowledge on the $K$ bits that are mapped to a constellation point and is set to $\\mathbf{0}$ if no prior knowledge is assumed to be available, and $\\Pr(c\\lvert\\mathbf{p})$ is the prior probability on the constellation symbol $c$: $\\Pr\\left(c\\lvert\\mathbf{p}\\right) = \\prod_{k=0}^{K-1} \\text{sigmoid}\\left(p_k \\ell(c)_k\\right)$ where $\\ell(c)_k$ is the $k^{th}$ bit label of $c$, where 0 is replaced by -1.\n\nWith the \u201cmaxlog\u201d demapping method, LLRs for the $i\\text{th}$ bit are approximated like $\\begin{align}\n    LLR(i) \\approx& \\max_{c\\in\\mathcal{C}_{i,0}} \\left(\\ln\\left(\\Pr\\left(c\\lvert\\mathbf{p}\\right)\\right)-\\frac{|y-c|^2}{N_o}\\right)\\\\\n        &-\\max_{c\\in\\mathcal{C}_{i,1}}\\left( \\ln\\left(\\Pr\\left(c\\lvert\\mathbf{p}\\right)\\right) - \\frac{|y-c|^2}{N_o}\\right)\n        .\n\\end{align}$  \n  "
"Here is the definition of CDL: sionna.channel.tr38901.cdl(model, delay_spread, carrier_frequency, ut_array, bs_array, direction, min_speed=0.0, max_speed=None, dtype=tf.complex64)\n\n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/tr38901/cdl.html#CDL)\n\nsource code:\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"Clustered Delay Line (CDL) channel model from the 3GPP 38.901 specification\"\"\"\nimport json\nfrom collections.abc import Sequence\nimport tensorflow as tf\n\nfrom . import delay_spread as ds\nfrom . import ut_array\nfrom . import bs_array\nfrom sionna import uMa, uMi, rMa\n\nclass CDL(tf.keras.Model):\n    # pylint: disable=line-too-long\n    r\"\"\"CDL(model, delay_spread, carrier_frequency, ut_array, bs_array, direction, min_speed=0., max_speed=None, dtype=tf.complex64)\n\n    Clustered delay line (CDL) channel model from the 3GPP [TR38901] specification.\n\n    The power delay profiles (PDPs) are normalized to have a total energy of\n    one.\n\n    If a minimum speed and a maximum speed are specified such that the\n    maximum speed is greater than the minimum speed, then UTs speeds are\n    randomly and uniformly sampled from the specified interval for each link\n    and each batch example.\n\n    The CDL model only works for systems with a single transmitter and a single\n    receiver. The transmitter and receiver can be equipped with multiple\n    antennas.\n\n    Parameters\n    ----------\n    model : str\n        CDL model to use. Must be one of \"A\", \"B\", \"C\", \"D\", or \"E\".\n\n    delay_spread : float\n        RMS delay spread [s].\n\n    carrier_frequency : float\n        Carrier frequency [Hz]\n\n    ut_array : PanelArray\n        Panel array used by the UTs. All UTs share the same panel array\n        configuration.\n\n    bs_array : PanelArray\n        Panel array used by the BSs. All BSs share the same panel array\n        configuration.\n\n    direction : str\n        Link direction. Must be either \"uplink\" or \"downlink\".\n\n    min_speed : float\n        Minimum speed [m/s]. Defaults to zero.\n\n    max_speed : None or float\n        Maximum speed [m/s]. If set to `None`, then `max_speed`\n        takes the same value as `min_speed`. Defaults to `None`.\n\n    dtype : Complex tf.DType\n        Defines the datatype for internal calculations and the output\n        dtype. Defaults to `tf.complex64`.\n\n    Input\n    -----\n\n    batch_size : int\n        Batch size\n\n    num_time_steps : int\n        Number of time steps\n\n    sampling_frequency : float\n        Sampling frequency [Hz]\n\n    Output\n    -------\n    a : [batch size, num_rx = 1, num_rx_ant, num_tx = 1, num_tx_ant, num_paths, num_time_steps], tf.complex\n        Path coefficients\n\n    tau : [batch size, num_rx = 1, num_tx = 1, num_paths], tf.float\n        Path delays [s]\n\n    For usage example, see the `3GPP UMi channel model`_.\n\n    .. _3GPP UMi channel model:\n        https://nvlabs.github.io/sionna/examples/antenna_examples.html#3gpp-umi-channel-model\n    \"\"\"\n\n    def __init__(self,\n                 model,\n                 delay_spread,\n                 carrier_frequency,\n                 ut_array,\n                 bs_array,\n                 direction,\n                 min_speed,\n                 max_speed,\n                 dtype=tf.complex64):\n\n        super().__init__()\n        self._dtype = dtype\n        self.set"
"To handle an `AssertionError` exception that is raised when the input encoding matrix is not valid in the `LinearEncoder`, you can wrap the instantiation of the encoder in a `try/except` block. Here's how you can do it based on the provided context:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\nimport tensorflow as tf\n\n# Place this code inside a try/except block to handle the AssertionError\ntry:\n    # Attempt to create LinearEncoder with a valid encoding matrix\n    encoder = LinearEncoder(enc_mat=matrix, is_pcm=False, dtype=tf.float32)\nexcept AssertionError as ae:\n    # If the matrix is invalid, print an error message\n    print(\"AssertionError:\", ae)\n    # Handle the invalid matrix here, either by loading a valid matrix\n    # or by performing other necessary steps\n```\n\nIn this case, if the encoding matrix `enc_mat` is not valid and raises an `AssertionError`, the code will print the error message `\"AssertionError: An assertion error occurred\"`. You can then handle the error within the `except` block, for example, by loading a valid encoding matrix or by giving an alternative way to construct the encoder."
"Here are some links to projects and papers that use Sionna:\n\n[Run-length Encoding for 5G New Radio in ns-3](https://github.com/5GENESIS/enc-hybrid-5G-transport/tree/Sionna-version): This project implements the 5G new radio channel models (in terms of timing and angles of arrival/departure) in the ns-3 simualtor and uses Sionna for the computation of the spatial auto-correlation functions.\n\n[Span-in-Span Model for Polarization Demux with Short Time Constant](https://github.com/5GENESIS/span-in-span-model): This project provides a span-in-span model for polarization demultiplexing with arbitrary polarization basis using half-wave plates. It makes use of the Sionna package.\n\n[Bin Detection for Load-Adaptive LDPC Decoding](https://ieeexplore.ieee.com/document/9394206): This paper discusses bin detection, a pre-processing step for low-density parity-check (LDPC) decoding. The authors make use of the Sionna package for their simulations.\n\n[Deep Reinforcement Learning for Intelligent Management of a Dual-Service, Virtualized Radio Access Network](https://ieeexplore.ieee.com/document/9411370): This paper focuses on the optimization of network performance via reinforcement learning. It makes use of the Sionna package for its components such as the OFDM resource grid and stream management.\n\n[Neural Demapper for Hard-Decision Decoding of LDPC Codes](https://ieeexplore.ieee.com/document/9403606): This paper presents a neural network-based demapper for low-density parity-check (LDPC) codes. The adapter is used to integrate the demapper into and end-to-end learning framework using the Sionna package.\n\n[Implementation of the PHY Transmitter using Neural OAI](https://github.com/duonghung86/Nerv-Net-in-Net): This project presents an implementation of the physical layer (PHY) transmitter using a neural network-based channel model. It makes use of the Sionna package.\n\nPlease note that these are only a few examples, and Sionna is used in many more projects. For more details, explore the provided links."
"To add a transmitter and receiver to the scene and compute the propagation paths in Sionna, follow these steps:\n\n1. Import the necessary modules and packages. This includes Sionna, which is not part of the instruction, but assumed to be available for performing the mentioned tasks.\n\n2. Load a scene or example from the Sionna repository using the `load_scene` function.\n\n3. Add a transmitter to the scene using the `Transmitter` class. Specify the `position`, `orientation`, and any other needed parameters.\n\n4. Add a receiver to the scene in a similar way to the transmitter.\n\n```python\nscene = load_scene(sionna.rt.scene.munich)\nscene.add_transmitter(Transmitter(name=\"tx\",\n    position=[-35,25,5],\n    orientation=[0,0,0]))\nscene.add_receiver(Receiver(name=\"rx\",\n    position=[25,50,1.5],\n    orientation=[0,0,0]))\n```\n\n5. Compute the propagation paths using the `compute_paths` function. Adjust the parameters as needed, depending on the specific requirements of the task.\n\n```python\npaths = scene.compute_paths()\n```\n\nPlease note that the exact code may vary depending on the specific requirements of the task. The above code is based on the provided context and assumes the availability of a Sionna scene. If using this code in a different project, ensure all necessary components are defined and imported."
"To use the FastFadingChannel class in Sionna, follow the steps below:\n\n1. First, import the required classes from the Sionna package:\n\n```python\nfrom sionna.channel import FastFadingChannel, GenerateFastFading, ApplyFastFading\nfrom sionna.channel import OFDMChannel, GenerateOFDMChannel, ApplyOFDMChannel\n```\n\n2. Initialize an instance of the FastFadingChannel class, inputting the required parameters - `num_rx`, `num_rx_ant`, `num_tx`, `num_tx_ant`:\n\n```python\nfast_fading_channel = FastFadingChannel(num_rx, num_rx_ant, num_tx, num_tx_ant)\n```\n\n3. Initialize an instance of the GenerateFastFading class, inputting the desired distribution of the fading coefficients (defaults to Rayleigh) and variance:\n\n```python\ngenerate_ff_coeffs = GenerateFastFading(gaussian=True)\n```\n\n4. Generate a batch of random fading coefficients using the `generate_ff_coeffs` instance:\n\n```python\na, g = generate_ff_coeffs(batch_size, num_time_steps, **kwargs)\n```\n5. Initialize an instance of the ApplyFastFadingChannel class, inputting the previously generated fading coefficients:\n\n```python\napply_ff_channel = ApplyFastFadingChannel()\n```\n\n6. Apply the fast fading channel to the input signal `x` using the `apply_ff_channel` instance:\n\n```python\ny = apply_ff_channel((x, a, g, no))\n```\n\n7. Initialize an instance of the OFDMChannel class and use it to generate the channel frequency responses:\n\n```python\ngenerate_ofdm_channel = GenerateOFDMChannel()\nh_freq = generate_ofdm_channel((a, g, no))\n```\n\n8. Apply the OFDM channel to the input signal:\n\n```python\napply_ofdm_channel = ApplyOFDMChannel()\ny_freq = apply_ofdm_channel((x, h_freq, no))\n```\n\nRemember to import the necessary modules and their dependencies before using these classes."
"Here is the detailed information of DirectivePattern:   \n  \nDirective scattering model from [[Degli-Esposti07]](../em_primer.html#degli-esposti07) as given in [(41)](../em_primer.html#equation-directive-model)  \n  \n**Parameters**\n\n- `alpha_r : int`  \n  Parameter related to the width of the scattering lobe in the direction of the specular reflection.\n\n- `dtype : tf.complex64 or tf.complex128`  \n  Datatype used for all computations. Defaults to tf.complex64.\n\n**Input**\n\n- `k_i : [batch_size, 3]`, `dtype.real_dtype`  \n  Incoming directions.\n\n- `k_s : [batch_size,3]`, `dtype.real_dtype`  \n  Outgoing directions.\n\n**Output**\n\n- `pattern : [batch_size]`, `dtype.real_dtype`  \n  Scattering pattern.\n  "
"Here is the definition of DemapperWithPrior: sionna.mapping.DemapperWithPrior(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs).  \n  \nSource code:\n```python\nclass DemapperWithPrior(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Deprecated as Layer\n    --------------------\n    :class:`~sionna.mapping.DemapperWithPrior` is a private class implementing\n    the :class:`~sionna.mapping.DemapperWithPrior` functional form.\n\n    Computes log-likelihood ratios (LLRs) or hard-decisions on bits\n    for a tensor of received symbols, assuming that prior knowledge on the\n    bits is available. This class defines a layer implementing\n    different demapping functions. All demapping functions are fully\n    differentiable when soft-decisions are computed.\n\n    Parameters\n    ----------\n    demapping_method : One of [\"app\", \"maxlog\"], str\n        The demapping method used.\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the demapper provides hard-decided bits instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of ``y``. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    -----\n    (y, prior, no) :\n        Tuple:\n\n    y : [...,n], tf.complex\n        The received symbols.\n\n    prior : [num_bits_per_symbol] or [...n], tf.float\n        Prior for every bit as LLRs.\n        It can be provided either as a tensor of shape `[num_bits_per_symbol]` for the\n        entire input batch, or as a tensor that is broadcastable to `[...,n]`.\n\n    no : Scalar or [...,n], tf.float\n        The noise variance estimate. It can be provided either as scalar\n        for the entire input batch or as a tensor that is broadcastable to\n        ``y``.\n\n    Output\n    ------\n    : [...,n*num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit.\n\n    Note\n    ----\n    With the \"app\" demapping method, the LLR for the :math:`i\\text{th}` bit\n    is computed according to\n\n    .. math::\n        LLR(i) = \\ln\\left(\\Pr\\left(b_i=1\\lvert y,\\mathbf{p}\\right)\\right)\n                -\\ln\\left(\\Pr\\left(b_i=0\\lvert y,\\mathbf{p}\\right)\\right)\n        =\\ln\\left(\\frac{\\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n            }{\n            \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n                \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n            }\\right)\n\n    where :math:`\\mathcal{C}_{i,1}` and :math:`\\mathcal{C}_{i,0}` are the\n    sets of constellation points for which the :math:`i\\text{th}` bit is\n    equal to 1 and 0, respectively. :math:`\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]`\n    is the LLR that serves as prior knowledge on the :math:`K` bits that are mapped to\n    a constellation point,\n    and :math:`\\Pr(c\\lvert\\mathbf{p})` is the prior probability on the constellation symbol :math:`c`:\n    :math:`\\Pr\\left(c\\lvert\\mathbf{p}\\right) = \\prod_{k=0}^{K-1} \\text{sigmoid}\\left(p_k \\ell(c)_k\\right)`,\n\n    where :math:`\\ell(c)_k` is the :math:`k^{th}` bit label of :math:`c`, where\n    0 is replaced by -1.\n    The definition of the LLR has been\n    chosen such that it is equivalent with that of logits. This is\n    different from many textbooks in communications, where the LLR is\n    defined as :math:`LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)`.\n\n    With the \"maxlog\" demapping method, LLRs for the :math:`i\\text{th}` bit\n    are approximated like\n\n    .. math::\n        \\begin{align}\n            LLR(i) &\\approx\\ln\\left(\\sum_{c\\in\\mathcal{C}_{i,0}}\n                \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n                \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n                \\right) \\\\\n                &\\phantom{=} \\ln\\left(\\sum_{c\\in\\mathcal{C}_{i,1}}\n                \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n                \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n                \\right).\n        \\end{align}\n    \"\"\"\n    def __init__(self,\n                 demapping_method,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        self._with_prior = True\n        self._demapping_method = demapping_method\n        self._hard_out = hard_out\n        self._constellation = Constellation.create_or_check_constellation(\n                                                        constellation_type,\n                                                        num_bits_per_symbol,\n                                                        constellation,\n                                                        dtype=dtype)\n\n    def call(self, inputs):\n        y, prior, no = inputs\n        return demapper_with_prior(y,\n                                   self._constellation.points,\n                                   self._constellation.probs,\n                                   prior,\n                                   no,\n                                   self._demapping_method,\n                                   self._hard_out)\n```\n  \n  "
"The provided context shows an embedded link that leads to a document explaining how to use the `TB5GScrambler` class, but it doesn't provide detailed information on how to initialize and use this class. Here's the information that can be found in the provided context:\n\n- The `TB5GScrambler` class implements pseudo-random bit scrambling as defined in TB5G standards. This scrambling function is designed to randomize the data sequence by 'XOR'ing it with a pseudo-random bit sequence based on specific configuration parameters, such as `n_rnti`, `n_id`, `binary`, `channel_type`, `codeword_index`, and `keep_state`. \n- The class is designed to switch parameters based on the specific channel type, which can be either PUSCH or PDSCH. For PDSCH, the `TB5GScrambler` can be configured for two codeword transmission modes via the `codeword_index` parameter.\n- The `keep_state` parameter is always `True` for `TB5GScrambler`, meaning that the scrambler keeps the same internal state for subsequent calls.\n- `TB5GScrambler` is a class that inherits and can be used like a layer of Keras models (`tf.keras.Layer` class).\n- The class defines a property called `keep_state`. This property is required for accessing the internal binary flag that indicates whether bit-sequence should be flipped or interpreted as soft-values. By default, it's set to `True`.\n- Methods in the class include `configurable_init()` and `reset_seed()`, both of which don't seem to be documented in the given context.\n\nSince the above is inferred from the context, which includes standard class definitions and method calls, it's highly recommended to refer to the actual documentation of the class for complete and precise information. The documentation may provide specific details about using this class as a Keras layer, which could include the initialization and calling procedures for using the class."
"To encode random input bits in Sionna, you can follow these steps:\n\n1. Import the necessary modules and functions. This includes Sionna, TensorFlow, and any other required module or function.\n\n2. Define the parameters for your system. This could include the number of information bits per codeword (k), the codeword length (n), the number of codewords to be transmitted (batch_size), the number of users (num_users), the number of basestations (num_basestations), and any other required parameters.\n\n3. Create an instance of the LDPC5GEncoder class from the Sionna library. This class encodes input bits using the 5G compliant low-density parity-check (LDPC) code.\n\n4. Generate random input bits of the shape [batch_size, k] using the binary_source function from Sionna.\n\n5. Encode the random input bits to produce the codewords using the encoder instance created earlier.\n\n6. The encoded bits can be printed or visualized as needed.\n\nPlease note that the exact code and parameters may vary depending on the specific requirements of your system. The provided context already includes a Python/TensorFlow implementation that can be used as a reference."
"The `LMMSEEqualizer` class is part of the Sionna package and is used in Orthogonal Frequency-Division Multiplexing (OFDM) Multiple-Input Multiple-Output (MIMO) transmissions. The class is an instance of the Keras `Layer` class, and is used to perform Linear Minimum Mean Squared Error (LMMSE) equalization. \n\nIn OFDM MIMO transmissions, a combination of multiple transmitters and receivers is used. The process involves multiple input streams that are transmitted over multiple antennas. The LMMSE equalization method is used in this case to minimize the mean square error (MSE) and maximize the signal-to-noise ratio of the transmitted signal.\n\nThe `LMMSEEqualizer` must be configured with a resource grid and stream management before being used. The class accepts four parameters: \n\n1. `resource_grid`: This is an instance of the `ResourceGrid` class that holds the parameters for the\n  construction of the OFDM resource grid.\n\n2. `stream_management`: This is an instance of the `StreamManagement` class that holds the parameters for\n  managing streams in multi-cell MIMO networks.\n\n3. `whiten_interference`: This is a boolean value that defaults to True. If True, the interference is first whitened before equalization. This is a more numerically stable operation in some cases.\n\n4. `dtype`: This is a TensorFlow datatype for internal calculations and the output dtype. It defaults\n  to `tf.complex64`.\n\nThe `LMMSEEqualizer` class requires the received OFDM resource grid (after cyclic prefix removal and FFT), the channel estimate for all streams from all transmitters, the variance of the channel estimation error, and the variance of the Additive White Gaussian Noise (AWGN). The class outputs the estimated symbols and the effective noise variance for each estimated symbol. \n\nNote: If you want to use this layer in Graph mode with XLA, i.e., within a function that is decorated with `@tf.function(jit_compile=True)`, you must set `sionna.Config.xla_compat=true`. See `xla_compat`."
"To get started with Sionna, users are encouraged to follow a tutorial which is structured in four notebooks. The first three notebooks provide an overview of differentiable communication systems, walk users through the basic principles of Sionna, and demonstrate the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. The last notebook demonstrates how to write custom trainable layers by implementing a state-of-the-art neural receiver, and how to train and evaluate end-to-end communication systems.\n\nThe tutorial also references the official documentation (https://nvlabs.github.io/sionna), which provides detailed information on how to use Sionna and how its components are implemented.\n\nIn the context, users learn about the principles of differentiable communication systems, which include understanding how a communication system maps given input data to a transmitted signal and how channel knowledge at the receiver contributes to the quality of the received data. The tutorial also provides insights into the implementation of system components using a limited set of trainable values, which can simplify the optimization of communication systems.\n\nThe tutorial specifically focuses on the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. It demonstrates how to use the link for training and evaluation in the absence and presence of channel knowledge at the receiver, and how to visualize the results."
"To import the necessary modules from the Sionna package, you can follow these steps:\n\n1. First, you need to import the Sionna package. If it's not already installed, the code will install it:\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n2. Import the necessary modules from the Sionna package. For example, to import the `load_scene`, `PlanarArray`, `Transmitter`, `Receiver`, `RadioMaterial`, `Camera` from `sionna.rt`, `r_hat` from `sionna.rt.utils`, `PI`, `SPEED_OF_LIGHT` from `sionna.constants`, and `expand_to_rank` from `sionna.utils`, you can use the following code:\n\n```python\nfrom sionna.rt import load_scene, PlanarArray, Transmitter, Receiver, RadioMaterial, Camera\nfrom sionna.rt.utils import r_hat\nfrom sionna.constants import PI, SPEED_OF_LIGHT\nfrom sionna.utils import expand_to_rank\n```\n\nIt's important to note that you should replace the modules in the second line of code with the ones that you need for your specific use case. The Sionna package provides various modules for radio propagation simulation, and you should only import the ones that you need for your particular task."
"To apply the gradient to the weights using an optimizer, you can follow these steps:\n\n1. **Forward Pass**: Perform a forward pass through the model to compute the loss function. This involves passing the input data through the model and getting the output.\n\n2. **Compute Gradient**: Use `tf.GradientTape` to calculate the gradient of the loss function with respect to the trainable weights. This involves recording the operations done during the forward pass to calculate the derivative of the loss function with respect to the parameters.\n\n3. **Apply Gradient**: After calculating the gradient, the optimizer's `apply_gradients` method is used to apply the gradient to the model's weights. The optimizer takes the list of gradients and parameters and updates the parameters according to the learning rate and other parameters specific to the optimizer.\n\nIn the provided context, the gradient is calculated using `tape.gradient(loss, tape.watched_variables())` and then applied to the weights using `optimizer.apply_gradients(zip(gradient, tape.watched_variables()))`. Remember to replace `loss` with the actual result of the loss function.\n\nNote: The optimizer and loss function used in the context are simplified for the purpose of illustration. In a real-world scenario, you might need to use a different optimizer such as SGD, and a binary cross-entropy loss function is just one of many possible loss functions for a binary task. The choice of optimizer and loss function depends on the specific task and data."
"   \n  [sionna.mapping.qam(num_bits_per_symbol, normalize=True)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#qam)  \nGenerate a Constellation for M-ary Quadrature Amplitude Modulation.\n\nThis function generates a constellation for M-ary QAM. The constellation is not only for the upper left quadrant, but for the whole complex plane. The bit label of the $n^{\\text{th}}$ constellation point is given by the length-$\\text{num_bits_per_symbol}$ binary represenation of $n$. The constellation is generated through a recursive algorithm explained in Section 5.1 of [3GPPTS38211](https://nvlabs.github.io/sionna/api/mapping.html#gppts38211) and has an average energy of $\\frac{1}{2^{\\text{num_bits_per_symbol}}}\\sum_{i=1}^{2^{\\text{num_bits_per_symbol}-1}}(2i-1)^2$. The normalization factor of a QAM constellation is $\\sqrt{\\frac{1}{2^{n-2}}\\sum_{i=1}^{2^{n-1}}(2i-1)^2}$.\n### Parameters\n\n- **num_bits_per_symbol** (int): The number of bits per constellation symbol.\n- **normalize** (bool): If True, the constellation is normalized to have unit power. Defaults to True.\n\n### Returns\n\n- `[-2^{\\text{num_bits_per_symbol}-1}, 2^{\\text{num_bits_per_symbol}-1}]`, tf.complex: The constellation.\n\nsource code:\n```python\ndef qam(num_bits_per_symbol, normalize=True):\n    r\"\"\"\n    Generate a Constellation for M-ary Quadrature Amplitude Modulation.\n\n    This function generates a constellation for M-ary QAM. The constellation\n    is not only for the upper left quadrant, but for the whole complex plane.\n    The bit label of the :math:`n^\\text{th}` constellation point is given by\n    the length-``num_bits_per_symbol`` binary represenation of :math:`n`.\n    The constellation is generated through a recursive algorithm\n    explained in Section 5.1 of [3GPPTS38211]_ and has an average energy of\n\n    .. math::\n\n        \\frac{1}{2^{\\text{num_bits_per_symbol}}}\\sum_{i=1}^{2^{\\text{num_bits_per_symbol}-1}}(2i-1)^2.\n\n    The normalization factor of a QAM constellation is\n    :math:`\\sqrt{\\frac{1}{2^{n-2}}\\sum_{i=1}^{2^{n-1}}(2i-1)^2}`.\n\n    ### Parameters\n    - **num_bits_per_symbol** : int\n        The number of bits per constellation symbol.\n\n    - **normalize** : bool\n        If `True`, the constellation is normalized to have unit power.\n        Defaults to `True`.\n\n    ### Returns\n    - `[-2^{num_bits_per_symbol}, 2^{num_bits_per_symbol}]`, tf.complex\n        The constellation.\n    \"\"\"\n    one_dim = _bipolar_to_bits(tf.range(0, num_bits_per_symbol, dtype=tf.float32))\n    two_dim = tf.squeeze(matrix_gray_code(num_bits_per_symbol), 1)\n    bits2symbol = two_dim\n    symbol = _bits2symbol(one_dim, two_dim)\n    if normalize:\n        energy_a = tf.pow(tf.abs(symbol), 2)\n        energy_s = tf.pow(tf.reduce_mean(energy_a), 0.5)\n        symbol = symbol / energy_s\n    return symbol\n```\n  "
"Here is the definition of class RandomInterleaver: sionna.fec.interleaving.RandomInterleaver(seq_type, inverse=False, rand_seed=None, dtype=tf.float32, **kwargs).  \n  \nThe source code is as follows:  \n```python\nclass RandomInterleaver(Layer):\n     # pylint: disable=line-too-long\n    r\"\"\"RandomInterleaver(seq_type, inverse=False, rand_seed=None, dtype=tf.float32, **kwargs)\n\n    Pseudo-randomly permutes the elements of a sequence or tensor, where the\n    exact permutation pattern is determined by a random seed which can be\n    provided explicitly or by the global random seed setting of TensorFlow.\n\n    This layer inherits from the Keras layer class and can be used as layer in a\n    Keras model.\n\n    Parameters\n    ----------\n        seq_type: One of [\"bit\", \"block\"], string\n            Defines whether the bit-sequence or block-sequence should be\n            interleaved. Defaults to \"bit\".\n\n        inverse: bool\n            A boolean defaults to False. If True, the inverse permutation is\n            performed.\n\n        rand_seed: int\n            Defines the seed for the random generator.\n            If None, the global `tf.random.GENERATOR` is used.\n            Defaults to None.\n\n        dtype: tf.DType\n            Defaults to `tf.float32`.\n\n    Input\n    -----\n        ([,...], tf.DType): 2+D tensor of arbitrary shape.\n            A tensor of arbitrary shape filled with data of type `dtype`.\n\n    Output\n    ------\n         ([,...], tf.DType): 2+D tensor of same shape and type as inputs.\n            A tensor of the same shape and type as the input tensor.\n\n    Raises\n    ------\n         AssertionError\n            If ``seed`` is not `None` or `int`.\n\n         AssertionError\n            If ``dtype`` is not a valid.\n\n         TypeError\n            If ``rank(inputs) < 2``.\n\n         ValueError\n            If ``dtype`` is not supported.\n\n    Note\n    ----\n        The interleaver permutes the last dimension of the input tensor.\n\n        For each new sample, a new random permutation is generated. Thus, the\n        call of the inverse mode is stateless.\n    \"\"\"\n\n    def __init__(self,\n                 seq_type=\"bit\",\n                 inverse=False,\n                 rand_seed=None,\n                 dtype=tf.float32,\n                 **kwargs):\n\n        super().__init__(dtype=dtype, **kwargs)\n\n        # assert seed is None or int\n        if rand_seed is not None:\n            assert isinstance(rand_seed, int), \\\n                \"rand_seed must be None or int.\"\n        self._rand_seed = rand_seed\n\n        # assert shuffle_seq_type is valid\n        assert seq_type in [\"bit\", \"block\"], \"Invalid seq_type.\"\n        self._seq_type = seq_type\n\n        # in block interleaving, we need to make sure that we interleave\n        # the entries of a vector and not the entries of a full tensor\n        if seq_type==\"block\":\n            self._block_interleaver = SwitchPermSeq(0, rand_seed=rand_seed)\n\n        # set of permuted indices\n        self._perm_seq = None\n\n        # indicator if inverse permutation should be performed\n        self._inverse = inverse\n\n        # TensorFlow random number generator\n        self._rng = tf.random.Generator(seed=rand_seed)\n\n        # if rand is set to True, the keep the same random permutation for\n        # each sample\n        if seq_type==\"block\" and inverse:\n            print(\"Warning: inverse option is useless with seq_type block.\")\n\n    #########################################\n    # Public methods and properties\n    #########################################\n\n    @property\n    def perm_seq(self):\n        \"\"\"The permution sequence.\"\"\"\n        return self._perm_seq\n\n    @property\n    def seq_type(self):\n        \"\"\"Indicates the type of the interleaver.\"\"\"\n        return self._seq_type\n\n    @property\n    def rand_seed(self):\n        \"\"\"The seed used to generate the random permutations.\"\"\"\n        return self._rand_seed\n\n    @property\n    def keep_state(self):\n        \"\"\"Indicates if the current permutation is fixed.\"\"\"\n        return True # interleave with the same pattern\n\n    def call_inverse(self, inputs):\n        \"\"\"Implements the deinterleaver function corresponding to call().\n\n        This is a stateless function.\n\n        Input\n        -----\n            inputs: tf.DType\n                2+D tensor of arbitrary shape.\n\n        Output\n        ------\n            : tf.DType\n                2+D tensor of same shape and type as ``inputs``.\n        \"\"\"\n        if self._perm_seq is None:\n            raise RuntimeError(\"perm_seq has not been set.\")\n\n        # do permutation\n        if self._seq_type==\"bit\":\n            perm_seq = tf.cast(self._perm_seq, inputs.dtype)\n            x = tf.gather(inputs, perm_seq, axis=-1, batch_dims=0)\n        else:\n            x = perm_transpose(inputs, self._perm_seq, axis, batch_dims)\n\n        return x\n\n\n    #########################\n    # Utility methods\n    #########################\n\n    # This function is used to sample the permutations\n    def _sample_perm(self, shape, rand_seed):\n        perm_seq = tf.argsort(tf.argsort(\n                            tf.random.uniform(shape,\n                                 seed=rand_seed,\n                                 dtype=tf.int32),\n                            axis=-1),\n                        axis=0)\n        return perm_seq\n\n    #########################\n    # Keras layer functions\n    #########################\n\n    def build(self, input_shape):\n        # verify that rank(inputs)>=2\n        assert len(input_shape)>1\n\n        # init rand_seq\n        rand_seq = self._sample_perm(input_shape[-1], self._rand_seed)\n        self._perm_seq = tf.constant(rand_seq, tf.int32)\n\n        # in block interleaving, we need to make sure that we interleave the\n        # entries of a vector and not the entries of a full tensor\n        if self._seq_type==\"block\" and input_shape[-1]>1:\n            self._block_interleaver = SwitchPermSeq(0, rand_seed=self._rand_seed)\n            perm_seq = self._block_interleaver(perm_seq)\n        self._perm_seq = perm_seq\n\n    def call(self, inputs):\n        if self._inverse:\n            return self.call_inverse(inputs)\n        else:\n            # do permutation\n            if self._seq_type==\"bit\":\n                perm_seq = tf.cast(self._perm_seq, inputs.dtype)\n                x = tf.gather(inputs, perm_seq, axis=-1, batch_dims=0)\n            else:\n                x = perm_transpose(inputs, self._perm_seq, axis, batch_dims)\n\n            return x\n```  \n  "
"View the code below:\n\n```python\ndef pam(num_bits_per_symbol, normalize=True):\n    # pylint: disable=line-too-long\n    r\"\"\" Generates a PAM constellation.\n\n    This function generates a real-valued vector, where each element is a\n    constellation point of an M-ary PAM constellation. The bit\n    label of the ``n`` th point is given by the length-``num_bits_per_symbol``\n    binary represenation of ``n``.\n    Input\n    -----\n    num_bits_per_symbol : int\n        The number of bits per constellation point.\n        Must be positive.\n\n    normalize : bool\n        If `True`, the constellation is normalized to have unit power.\n        Defaults to `True`.\n\n    Output\n    ------\n    : [``2`` :sup:`num_bits_per_symbol`], np.float32\n        The PAM constellation.\n\n    Note\n    ----\n    The bit label of the `n`th constellation point is given by the binary\n    representation of its position within the array and can be obtained\n    through :func:`~numpy.binary_repr` using ``n`` and ``num_bits_per_symbol``.\n\n    The normalization factor of a PAM constellation is given in\n    closed-form as:\n\n    .. math::\n\n        \\sqrt{\\frac{1}{2^{n-1}}\\sum_{i=1}^{2^{n-1}}(2i-1)^2}\n\n    where :math:`n` is the number of bits per symbol.\n\n    This algorithm is a recursive implementation of the expressions found in\n    Section 5.1 of [3GPPTS38211]_. It is used in the 5G standard.\n    \"\"\"\n\n    # Generate the n-th symbol along the 0-dim PAM constellation\n    num_steps = 2**(num_bits_per_symbol-1)\n    pam0 = np.concatenate([np.array([-2*i  for i in range(num_steps)])],\n                           axis=0)\n    pam1 = -1*pam0\n    pam = np.array([pam0, pam1])\n\n    # Compute the normalization factor\n    energy = np.sum(np.abs(pam)**2)/2**(num_bits_per_symbol-1)\n    normalization_factor = np.sqrt(energy)\n\n    # Normalize constellation if requested\n    if normalize:\n        pam = np.divide(pam, normalization_factor)\n\n    return pam\n```\n\nsource code:\n```python\ndef pam(num_bits_per_symbol, normalize=True):\n    \"\"\"Generates a PAM constellation.\n\n    This function generates a real-valued vector, where each element is a\n    constellation point of an M-ary PAM constellation. The bit\n    label of the ``n`` th point is given by the length-``num_bits_per_symbol``\n    binary represenation of ``n``.\n    Input\n    -----\n    num_bits_per_symbol : int\n        The number of bits per constellation point.\n        Must be positive.\n\n    normalize : bool\n        If `True`, the constellation is normalized to have unit power.\n        Defaults to `True`.\n\n    Output\n    ------\n    : [``2`` :sup:`num_bits_per_symbol`], np.float32\n        The PAM constellation.\n\n    Note\n    ----\n    The bit label of the `n`th constellation point is given by the binary\n    representation of its position within the array and can be obtained\n    through :func:`~numpy.binary_repr` using ``n`` and ``num_bits_per_symbol``.\n\n    The normalization factor of a PAM constellation is given in\n    closed-form as:\n\n    .. math::\n\n        \\sqrt{\\frac{1}{2^{n-1}}\\sum_{i=1}^{2^{n-1}}(2i-1)^2}\n\n    where :math:`n` is the number of bits per symbol.\n\n    This algorithm is a recursive implementation of the expressions found in\n    Section 5.1 of [3GPPTS38211]_. It is used in the 5G standard.\n    \"\"\"\n    if normalize:\n        # Normalization is only needed for energy==2\n        if num_bits_per_symbol==2:\n            pam = np.array([[-1., 1.], [1., -1.]])\n            pam /= np.sqrt(2)\n        elif num_bits_per_symbol==1:\n            pam = np.array([[0.], [0.]])\n    else:\n        pam = build_nary_constellation(num_bits_per_symbol,\n                                    normalize=False,\n                                    binary=False)\n    return pam\n```"
"The `return_crc_status` parameter in the Polar5GDecoder of Sionna is used to indicate whether the decoder provides the cyclic redundancy check (CRC) status for the received codeword. This is helpful because during the decoding process, the CRC is used to check the validity of the decoded bits. If the CRC check fails, it is an indicator that errors have occurred during the transmission.\n\nThe `output_dtype` parameter specifies the type of output generated by the Polar5GDecoder. In the context, it is set to `tf.float32` by default. It is critical when handling data that requires a specific type to ensure proper operations and computations can take place.\n\n`return_crc_status` and `output_dtype` are independent of each other. The `return_crc_status` parameter does not affect the type (`tf.float32`) specified by `output_dtype`. However, configuring `output_dtype` can impact the type of data returned after the decoding process. It's essential to choose the appropriate output type to match the subsequent data processing steps effectively.\n\nIn the case of the Sionna's `Polar5GDecoder`, despite mentioning that the `return_crc_status` parameter could affect the output in the documentation, it actually does not alter the output. The returned output of `Polar5GDecoder` is always a tuple of two elements: `b_hat` and `crc_status`.\n\n```python\n    x_hat, crc_status = poldec(llr)\n```\n\nHere, `x_hat` is the estimated information bits, and `crc_status` is a boolean that indicates whether the CRC validation has been successful. This means that if `return_crc_status` is `True`, the user can not only get the estimated information bits `x_hat` but also be informed about the validity of the results based on the CRC status.\n\nWhile the documentation indicates that `output_dtype` and `return_crc_status` can impact the output, in the practical implementation of the Sionna framework, they do not have a direct impact on the output characteristics. It's essential to be aware of these parameters when using the framework, but they do not introduce variations in the output tuple."
"To train the neural receiver and save the weights of the model, you can follow these steps:\n\n1. **Set a seed for reproducibility**: Set a seed for reproducibility using TensorFlow's `tf.random.set_seed` function. This is optional but can be useful for reproducibility of the results.\n\n2. **Define the number of training iterations**: The training loop will run for a specified number of iterations. In the context, `NUM_TRAINING_ITERATIONS` is set to 100,000.\n\n3. **Instantiate the model for training**: Instantiate the end-to-end model for training. This is done by passing `training=True` to the `OFDMSystemNeuralReceiver` class.\n\n4. **Define the optimizer**: Use Adam optimizer for training. Adam is a variant of Stochastic Gradient Descent (SGD) which is commonly used in machine learning.\n\n5. **Training loop**: The training loop starts by sampling a batch of Signal-to-Noise Ratios (SNRs) using `tf.random.uniform`. A forward pass is then performed through the model within a gradient tape. The tape is used to compute the gradients using `tape.gradient(loss, weights)`. The gradients are then applied using `optimizer.apply_gradients` to update the weights of the model. The progress of training is printed using a progress bar.\n\n6. **Save the weights**: After training, the weights of the model are saved in a file using Python's `pickle` module. The weights can be saved as binary data using `pickle.dump(weights, f)`.\n\nPlease note that the exact code and steps may vary depending on the specific requirements of your application."
"Here are some useful links of it:\n\n[Run in Google Colab](https://colab.research.google.com/github/nvlabs/sionna/blob/main/examples/Sionna_tutorial_part1.ipynb)\n\n[View on GitHub](https://github.com/nvlabs/sionna/blob/main/examples/Sionna_tutorial_part1.ipynb)\n\n[Download notebook](https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.ipynb)"
"To run throughput tests in Graph Mode using the Sionna Python package, you should follow these steps:\n\n1. Import the necessary libraries and modules, including Sionna, TensorFlow, and Time. The Sionna package should be imported using its installation path.\n\n```python\nimport sys\nsys.path.append(\"path/to/Sionna\")  # path to Sionna package\nimport sionna\nimport tensorflow as tf\nimport time\n```\n\n2. Set up your environment, including the necessary parameters for your tests.\n\n3. Initialize the required components for your tests. This will include your model, the batch size, and the SNR value.\n\n4. Define a function to evaluate the throughput. This function should take as input the batch size, the SNR value, and the number of repetitions for the test.\n\n5. Run the model evaluation for different batch sizes and SNR values. Call the function you defined in the previous step, passing the batch size, SNR value, and number of repetitions as arguments.\n\n6. Print the results of your tests.\n\nPlease note that the exact implementation may vary depending on the specific requirements of your tests. The provided context includes a generic throughput test and does not provide specific instructions on how to set up and initialize your model or how to tune your tests."
"For demonstration purposes, with reference to the given context, to set up a convolutional encoder with a rate of 1/2 and a constraint length of 3 using the `ConvEncoder` class, you can use either the `rate` and `constraint_length` parameters or the `gen_poly` parameter. The former way allows you to set up the encoder based on specific properties of the code, like the rate and constraint length, while the latter directly lets you use a generator polynomial that defines the code pattern.\n\nHere's how you would set up the encoder using the `rate` and `constraint_length` parameters:\n\n```python\nfrom sionna.fec.conv import ConvEncoder\n\n# Using `rate` and `constraint_length` parameters\nencoder = ConvEncoder(rate=1/2, constraint_length=3, gen_poly=None, terminate=False, \n                      output_dtype=tf.float32, **kwargs)\n```\n\nIn this setup:\n- `rate=1/2` specifies that the code will have a rate of 1/2, which means every input bit is encoded into 2 output bits.\n- `constraint_length=3` specifies the constraint length of the encoder. The constraint length is the number of previous input time steps considered for encoding each input bit.\n- `gen_poly=None` indicates that an automatic generator polynomial built of the best known performance for the specified `rate` and `constraint_length` will be used.\n- `terminate=False` means the encoder will not be terminated. When termination is active, the encoder adds extra bits (beyond the constraint length) to ensure that each information bit is encoded into a full codeword. In the case of a terminated encoder, not all partial codewords are properly included, which can lead to some loss of coding gain.\n\nNow, to set up the encoder using the `gen_poly` parameter, you should have the generator polynomial in octal or decimal format. For demonstration, let's use the octal format of the best performing polynomial for a rate 1/2 code with constraint length 3:\n\n```python\n# Using `gen_poly` parameter\nencoder = ConvEncoder(gen_poly=143, terminate=False)\n```\n\nIn this setup:\n- `gen_poly=143` specifies the use of the generator polynomial 10011 in octal representation.\n- `terminate=False` as before, is the termination configuration.\n\nIt's important to note that the `**kwargs` in the parameter list is used to indicate that the `ConvEncoder` class can be configured with additional optional parameters."
"Utilizing the \"Rural macrocell (RMa)\" model\" follows a set of specific principles, parameters, inputs and outputs. \n\nTo use the RMa model, the following inputs are required:\n\n1. Carrier Frequency: The carrier frequency indicates the frequency at which the channel operates.\n2. UT Array: The UT array contains the properties of the user terminals, such as the UT locations, their orientations, velocities, and indoor/outdoor states.\n3. BS Array: The BS array contains the properties of the base stations, such as their locations, orientations, and antenna properties.\n4. Direction: This denotes whether the channel model is in uplink or downlink configuration.\n5. Pathloss: The pathloss optionally used in the model can be given as a scalar or tensor of any shape. If not given, the pathloss is automatically computed.\n6. Delay Spread: The delay spread should be provided as a scalar or tensor of any shape. If not given, a delay spread of 0ns is assumed which corresponds to a perfect channel impulse response.\n7. UT Array Orientation: This includes the orientation of the user terminal array, which can be a 2x1 vector or tensor. \n\nAfter setting up the RMa model with these parameters, the topology of the network is determined. The network topology which is set up using the `set_topology` method of the RMa model, dictates the link simulations.\n\nThe link simulations are performed through the use of the `sim_path` method which calculates the frequency channel response between a transmitter and receiver with a given receiving antenna orientation.\n\nThe channel impulse response (CIR) can be computed from the path coefficients and delays using the `cir` method. The CIR can then be converted to the frequency response using the `cir_to_ofdm_channel` function. \n\nIf channel models are implemented using `from_file` `generate` methods, the channel models assume random topology and antenna orientations. It's important to note that `generate` method returns a channel model with the topology set to indicate that it is being generated. \n\nExample output of the \"Rural macrocell (RMa)\" model is a Channel Impulse Response (CIR), represented as a complex tensor. The output can be in the form of a path or delay spread, depending on the method used. \n\nKeep in mind that to utilize the RMa model along with its principles, parameters, inputs and outputs, the context provided about the Sionna channel module and the Sionna.channel.tr38901 package should be understood."
"The `Trellis` structure in the context of Sionna's Forward Error Correction (FEC) Convolution (conv) utility is used to define the state transitions and output symbols for each current state and input, given a specific generator polynomial `gen_poly`. The `rsc` parameter, when set to `True`, indicates that the Trellis is recursive systematic in nature, meaning that the feedback polynomial is the first polynomial in `gen_poly`.\n\nThe `gen_poly` parameter is used to provide the generator polynomial sequence as input, which defines the polynomial components in each state transition. It can consist of multiple polynomial strings, each of which is interpreted as a binary sequence that represents the connections between the input and the output for a specific state transition in the trellis. If the `rsc` flag is set to `True`, the first polynomial in `gen_poly` is considered the feedback polynomial.\n\nIn addition, the `Trellis` structure generates the input and output symbols for each state transition, where the input symbol can be either '0' or '1' (bit), and the output symbol can be either '0', '1', or '-1' (sign of the symbol), depending on the specific convolutional code configuration.\n\nThe `Trellis` structure can be utilized to encode data linearly when configured with the appropriate generator polynomial for the given encoder state transition. For instance, considering a `gen_poly` of 111, 101, 011 with `rsc` equal to `True`, the `Trellis` structure for this polynomial would indicate how a '0' or '1' input bit is linearly transformed into a sequence of output bits (or signs) and the next state transition. Here, '0' would map to a specific output, '1' would map to another specific output, and '-1' would represent a non-transmitted state transition.\n\nIt is important to note that the `Trellis` structure is designed for representing the state transitions and output symbols in convolutional encoding, which is a crucial component in FEC for ensuring the reliability of digital data transmission. This structured approach facilitates encoding optimization and allows for efficient decoding strategies, such as the Viterbi algorithm when applied to the specific trellis configuration."
"Here is the source code link of [CarrierConfig](https://nvlabs.github.io/sionna/_modules/sionna/nr/carrier_config.html#CarrierConfig)  \n    \nThe CarrierConfig objects sets parameters for a specific OFDM numerology,\nas described in Section 4 [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#_gpp38211).\nAll configurable properties can be provided as keyword arguments during the\ninitialization or changed later.\n  \nProperties\nThe class defines the following properties.\n\n  \n**cyclic_prefix**  \nCyclic prefix length.\nThe option normal corresponds to 14 OFDM symbols per slot, while\nextended corresponds to 12 OFDM symbols. The latter option is\nonly possible with a subcarrier_spacing of 60 kHz.\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/nr.html#cylic_prefix\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nGet:\n  :class:`str` \u2014 One of \"normal\", \"extended\"\n\nSet:\n  :class:`str` \u2014 One of \"normal\", \"extended\"\nsource code:\n```python\n    def set_cyclic_prefix(self, value):\n        assert value in VALID_CP, \"Invalid cyclic prefix\"\n        self._cyclic_prefix = value\n```\n\n**cyclic_prefix_length**  \nCyclic prefix length.\n$c_{\\text{cp},l} \\cdot T_{\\text{c}}$\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/nr.html#cyclic_prefix_length\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nGet:\n  :class:`float` \u2014 Cyclic prefix length, in seconds\n\n**frame_duration**  \nDuration of a frame.\n$T_\\text{f}$\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/nr.html#frame_duration\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nGet:\n  :class:`float` \u2014 Frame duration, in seconds\n\n**frame_number**  \nSystem frame number $n_\\text{f}$.\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/nr.html#frame_number\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nGet:\n  :class:`int` \u2014 System frame number, in the range [0, 1023].\n\n**kappa**  \nThe constant $\\kappa = T_\\text{s}/T_\\text{c}$.\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/nr.html#kappa\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nGet:\n  :class:`float` \u2014 The value of $\\kappa$.\n\n**mu**  \nSubcarrier spacing configuration, $\\Delta f = 2^{\\mu} 15$ kHz.\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/nr.html#mu\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nGet:\n  :class:`int` \u2014 The value of $\\mu$.\n\n**n_cell_id**  \nPhysical layer cell identity $N_\\text{ID}^{\\text{cell}}$.\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/nr.html#n_cell_id\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nSet:\n  :class:`int` \u2014 The value of $N_\\text{ID}^{\\text{cell}}$.\n\n**n_size_grid**  \nNumber of resource blocks in the carrier resource grid $N^{\\text{size},\\mu}_{\\text{grid},x}$.\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlab.github.io/sionna/api/nr.html#n_size_grid\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nGet:\n  :class:`int` \u2013 Number of resource blocks in the carrier resource grid.\n\n**n_start_grid**  \nStart of resource grid relative to common resource block (CRB) 0 $N^{\\text{start},\\mu}_{\\text{grid},x}$.\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlab.github.io/sionna/api/nr.html#n_start_grid\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nGet:\n  :class:`int` \u2013 Start of the resource grid relative to CRB0.\n\n**num_slots_per_frame**  \nNumber of slots per frame $N_\\text{slot}^{\\text{frame},\\mu}$.\nDepends on the <a href=\"#subcarrier_spacing\">subcarrier_spacing</a>.\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/nr.html#num_slots_per_frame\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nGet:\n  :class:`int` \u2013 Number of slots per frame.\n\n**num_slots_per_subframe**  \nNumber of slots per subframe $N_\\text{slot}^{\\text{subframe},\\mu}$.\nDepends on the <a href=\"#subcarrier_spacing\">subcarrier_spacing</a>.\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/nr.html#num_slots_per_subframe\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nGet:\n  :class:`int` \u2013 Number of slots per subframe.\n\n**num_symbols_per_slot**  \nNumber of OFDM symbols per slot $N_\\text{symb}^\\text{slot}$.\nConfigured through the <a href=\"#cylic_prefix_length\">cyclic_prefix</a>.\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/nr.html#num_symbols_per_slot\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nSet:\n  :class:`int` \u2013 Number of OFDM symbols per slot.\n\n**slot_number**  \nSlot number within a frame $n^\\mu_{s,f}$.\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/nr.html#slot_number\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nGet:\n  :class:`int` \u2013 The slot number.\n\n**sub_frame_duration**  \nDuration of a subframe $T_\\text{sf}$.\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/nr.html#sub_frame_duration\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nGet:\n  :class:`float` \u2013 Duration of a subframe, in seconds.\n\n**subcarrier_spacing**\nSubcarrier\nspacing $\\Delta f = 2^{\\mu} 15$ kHz.\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/nr.html#subcarrier_spacing\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nSet:\n  :class:`float` \u2013 The value of $\\Delta f$.\n\n**t_c**\nSampling time $T_\\text{c}$ for\nsubcarrier spacing 480kHz.\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/nr.html#t_c\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nGet:\n  :class:`float` \u2013 $T_\\text{c}$ for 480kHz.\n\n**t_s**\nSampling time $T_\\text{s}$ for\nsubcarrier spacing 15kHz.\n<div class=\"configuration-wrapper\">\n  <simpleconfigurationblock>\n    <div class=\"docutils\">\n<cite><a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/nr.html#t_s\"></a></cite>\n</div>\n  </simpleconfigurationblock>\n</div>\n\nGet:\n  :class:`float` \u2013 $T_\\text{s}$ for 15kHz."
"Here is the definition of Receiver: sionna.rt.Receiver(name, position, orientation=(0.0, 0.0, 0.0), look_at=None, color=(0.153, 0.682, 0.375), dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/rt/receiver.html#Receiver)  \n\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"\nClass defining a receiver\n\"\"\"\n\nimport tensorflow as tf\nfrom .radio_device import RadioDevice\n\nclass Receiver(RadioDevice):\n    # The link that this receiver is associated with\n    link_kind = \"receiver\"\n\n    def __init__(self,\n                 name,\n                 position,\n                 orientation=(0.,0.,0.),\n                 look_at=None,\n                 color=(0.153, 0.682, 0.375),\n                 dtype=tf.complex64):\n\n        # Configure the object as a radio device\n        super().__init__(name=name,\n                         position=position,\n                         orientation=orientation,\n                         look_at=look_at,\n                         color=color,\n                         dtype=dtype)\n```"
"The `ResourceGrid` is a key component in the Sionna Python package used for defining and manipulating resource grids in the context of wireless channel modeling. A resource grid is a collection of resource elements that are available for data and pilot transmissions. It contains information about the specific OFDM symbols and subcarriers that are allocated for transmitting data and pilots.\n\nThe `ResourceGrid` can be used to visualize the pattern of OFDM symbols and subcarriers that make up a resource grid, which is especially useful in the design and analysis of wireless communication systems. It can also be utilized for more advanced tasks such as generating precoded OFDM sequences, training sequences, and in the context of channel estimation and correction.\n\nAdditionally, the `ResourceGrid` allows for the configuration of advanced properties such as the used pilot pattern, guard carriers, carrier types, and the management of complex resource grids with dual-polarized transmissions.\n\nIn the provided context, the `ResourceGrid` is initialized with a number of specified parameters like `num_ofdm_symbols`, `fft_size`, `subcarrier_spacing`, `num_tx`, `num_streams_per_tx`, `cyclic_prefix_length`, `num_guard_carriers`, `dc_null`, `pilot_pattern`, `pilot_ofdm_symbol_indices` and `dtype`. These parameters determine the specific characteristics of the resource grid.\n\nThe `ResourceGrid` instance is then used to generate a sequence of OFDM symbols in the frequency domain, represented by a 2D tensor containing the data and pilot symbols. The grid can be visualized to show the pattern of resource elements.\n\nIt's important to note that while the `ResourceGrid` can be used in the simulation of larger systems, it is designed to be used with the Sionna package, which provides support for the modeling of the PHY layer link-level performance and the simulation of 3GPP NR compliant waveforms."
"To generate a batch of frequency responses, you need to follow these steps:\n\n1. Define the OFDM resource grid. In the context provided, an instance of `ResourceGrid` is created with parameters `num_ofdm_symbols`, `fft_size`, `subcarrier_spacing`, `num_tx`, `num_streams_per_tx`. This grid is used to define the structure of the data and pilot subcarriers within an OFDM symbol.\n\n2. Create an instance of the `GenerateOFDMChannel` class, passing the `channel_model` and `resource_grid` as parameters. This class generates the channel frequency responses used for the simulation of communication systems based on OFDM.\n\n3. Call the instance of `GenerateOFDMChannel` to generate a batch of frequency responses. The input to the callable instance of `GenerateOFDMChannel` is the batch size. The shape of the output will be `[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_ofdm_symbols, num_subcarriers]`, where `num_rx`, `num_rx_ant`, `num_tx`, `num_tx_ant`, `num_ofdm_symbols`, `num_subcarriers` are the numbers of receivers, antennas per receiver, transmitters, antennas per transmitter, number of OFDM symbols, number of subcarriers respectively.\n\nHere is the relevant code snippet:\n\n```python\nh_freq = ofdm_channel()\nprint(h_freq.shape)\n```\n\nThe shape of `h_freq` will depend on the parameters of the resource grid and the `channel_model` provided. In the context provided, the shape of `h_freq` is `[64, 2, 2, 1, 8, 100, 76]`."
"To configure transmitters and receivers for computing propagation paths in Sionna RT, you need to create instances of the Transmitter and Receiver classes in the context of a Scene, then add these instances to the scene. Here's a step-by-step guide:\n\n1. First, import the necessary classes from the Sionna RT module:\n\n    ```python\n    from sionna.rt import Scene, Transmitter, Receiver\n    ```\n\n2. Create a scene instance. The scene is what environment will be used for propagation simulations:\n\n    ```python\n    scene = Scene(...)\n    ```\n\n3. Configure transmitters:\n\n    ```python\n    tx = Transmitter(name=\"tx_name\", position=[x, y, z])\n    scene.add(tx)\n    ```\n\n    Replace \"tx_name\" with the name you want to use for this transmitter, and specify the position in the `position` parameter.\n\n4. Configure receivers:\n\n    ```python\n    rx = Receiver(name=\"rx_name\", position=[x, y, z], orientation=[alpha, beta, gamma])\n    scene.add(rx)\n    ```\n\n    Replace \"rx_name\" with the name you want to use for this receiver, and provide the position and orientation parameters to define the receiver's position and orientation in the scene.\n\n5. Compute propagation paths:\n\n    ```python\n    paths = scene.compute_paths(max_depth=5, num_samples=1e6)\n    ```\n\n    This function `compute_paths` generates a `Paths` object that contains all possible propagation paths for the current scene.\n\nRemember to replace the placeholders (like `x`, `y`, `z`, `alpha`, `beta`, `gamma`) in the code snippets with actual values that suit your context. After running these commands, you will have configured your transmitters and receivers and will be ready to perform propagation simulations."
"Here is the definition of the deprecated `SymbolDemapperWithPrior` class:    \n  \n```python  \nclass SymbolDemapperWithPrior(SymbolDemapper):\n    # pylint: disable=line-too-long\n    r\"\"\"SymbolDemapperWithPrior(constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    Deprecated.\n    Use SymbolDemapper with the \"prior\" method.\n\n    Computes normalized log-probabilities (logits) or hard-decisions on symbols for a tensor of received symbols, assuming that prior knowledge on the constellation points is available. The demapping function is fully differentiable when soft-values are computed.\n\n    This class is deprecated as the functionality has been integrated into SymbolDemapper. However, the\n    parameter constellation_type  is still available (although potentially not used) for compatibility\n    with saved models.\n\n    Parameters\n    ----------\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type`` and\n        ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the demapper provides hard-decided symbols instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of ``y``. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    -----\n    (y, prior, no) :\n        Tuple:\n\n    y : [...,n], tf.complex\n        The received symbols.\n\n    prior : [num_points] or [...,num_points], tf.float\n        Prior for every symbol as log-probabilities (logits).\n        It can be provided either as a tensor of shape `[num_points]` for the\n        entire input batch, or as a tensor that is broadcastable to `[..., n, num_points]`.\n\n    no : Scalar or [...,n], tf.float\n        The noise variance estimate. It can be provided either as\n        scalar for the entire input batch or as a tensor that is broadcastable\n        to `y`.\n\n    Output\n    ------\n    : [...,n, num_points], tf.float\n        A tensor of shape `[...,n, num_points]` of logits for every constellation\n        point if ``hard_out`` is set to `False`.\n        Otherwise, a tensor of shape `[...,n]` of hard-decisions on the symbols.\n\n    Note\n    ----\n    The normalized log-probability for the constellation point :math:`c` is computed according to\n\n    .. math::\n        \\ln\\left(\\Pr\\left(c \\lvert y,\\mathbf{p}\\right)\\right) = \\ln\\left( \\frac{\\exp\\left(-\\frac{|y-c|^2}{N_0} + p_c \\right)}{\\sum_{c'\\in\\mathcal{C}} \\exp\\left(-\\frac{|y-c'|^2}{N_0} + p_{c'} \\right)} \\right)\n\n    where :math:`\\mathcal{C}` is the set of constellation points used for modulation,\n    and :math:`\\mathbf{p} = \\left\\{p_c \\lvert c \\in \\mathcal{C}\\right\\}` the prior information on constellation points given as log-probabilities.\n    \"\"\"\n    def __init__(self,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(constellation_type=constellation_type,\n                         num_bits_per_symbol=num_bits_per_symbol,\n                         constellation=constellation,\n                         hard_out=hard_out,\n                         with_prior=True,\n                         dtype=dtype,\n                         **kwargs)\n```\n  "
"To enable diffuse reflections and observe their impact on the coverage map, you need to follow these steps:\n\n1. Set the parameters for the diffusion models, such as the scattering coefficient and the number of samples. In the given context, the scattering coefficient is set as follows:\n\n```python\nscene.radio_material.scattering_coefficient = 0.3\n```\n\n2. Compute the coverage map. Because diffuse reflections are not bound to a specific direction but scattered in many different directions, you need to use the `scattering_pattern` to uniformly sample the reflected directions. Here is the code snippet from the context that shows how to compute the coverage map:\n\n```python\ncm = scene.coverage_map(cm_cell_size=[1,1], num_samples=20e6, max_depth=5, scattering_pattern=\"iso\")\n```\n\n3. Render the coverage map using the `Camera.render` method. You can provide a preview of the coverage map along with the scene by using the `coverage_map_preview` parameter. Here is the code snippet:\n\n```python\nscene.render(my_cam, coverage_map=cm, coverage_map_preview=True)\n```\n\nThese steps will enable diffuse reflections, and you will observe the impact on the coverage map. The coverage map will show the average received power from the specific transmitter at every point on a plane, taking into account the diffuse reflections."
"To compute the mean squared error (MSE) between the transmitted and recovered symbols, you can follow these steps:\n\n1. First, you need to generate the transmitted symbols and the received symbols. In the context, the transmitted symbols are represented by `x` and the received symbols after matched filtering are represented by `x_hat`.\n\n2. Next, compute the square of the difference between the transmitted and received symbols. This can be done using the numpy function `square`. The code to do this might look like this:\n\n```python\n# Compute the square of the difference\nsquared_diff = np.square(np.abs(x-x_hat))\n```\n\n3. Then, calculate the mean of the squared differences. This can be done using the numpy function `mean`. The code might look like this:\n\n```python\n# Calculate the MSE\nmse = np.mean(squared_diff)\n```\n\nIn the context, the MSE is printed as \"MSE between x and x_hat (dB)\" after the scatter plot. The code to calculate the MSE is represented by `np.var(x-x_hat)` where `x` is the transmitted symbols and `x_hat` is the received symbols. The result of the MSE is also plotted."
"The `create_or_check_constellation` method is used to either create a constellation object of a specific type with a given number of bits per symbol or to verify that an existing constellation is consistent with specific settings. \n\nIn the case of creating a constellation, the method takes the following parameters:\n- `constellation_type`: a string indicating the type of constellation, e.g., \"qam\", \"pam\", or \"custom\".\n- `num_bits_per_symbol`: an integer specifying the number of bits per constellation symbol. This is necessary for \"qam\" and \"pam\" types.\n- `dtype`: a tensorflow DType for the constellation symbols.\n\nIf the `constellation_type` is \"custom\", the method also allows an existing instance of `Constellation` to be provided instead of `num_bits_per_symbol` and `dtype`.\n\nOtherwise, if `constellation` is provided, the method checks that it is consistent with the requested `constellation_type` and `num_bits_per_symbol`. If `constellation` is not None, the `num_bits_per_symbol` and `dtype` parameters are ignored.\n\nIt's important to note that, when creating a constellation, the constellation is normalized to have unit power if normalize is set to `True`. If `center` is set to `True`, the constellation is also centered to the origin. These behaviors are in the interest of ensuring that the constellation remains valid from a signaling perspective.\n\nWhen validating an existing constellation, the `create_or_check_constellation` method does not actually create a new constellation but rather ensures that the `constellation` is consistent with the requested `constellation_type`, `num_bits_per_symbol`, and `dtype`. If the constellation is not consistent, an assertion is raised. This method is useful in verifying that a constellation object is valid before using it in a simulation."
"The `scat_keep_prob` argument plays a crucial role in the ray tracing process, specifically in the generation of scattered paths. When ray tracing is performed, the environment is sampled with a high density of rays to compute the effects of reflection, diffraction, and scattering. \n\nScattering typically occurs as the rays hit a surface and get deflected in various directions. To manage the complexity of the computations and their impact on the simulation, the `scat_keep_prob` argument comes into play. It allows configuring the probability of any given ray being scattered, which provides a way to reduce the number of paths and the associated computation effort.\n\nSetting a lower `scat_keep_prob` effectively results in a subset of the scattered paths being eliminated from the simulation. While this simplifies the environment's representation and the computations, it may affect the accuracy of the results, especially if the omitted scattered paths could have had a significant impact on the channel characteristics. \n\nIn the provided context, the `scat_keep_prob` argument is used in the calls to `compute_paths` function. By specifying values for `scat_keep_prob`, the computations are performed on only a portion of the scattered paths, which trades off some accuracy in the modeling for a reduction in complexity. This trade-off makes the simulation more manageable, particularly in scenarios where resources are limited."
"   \nsource code:\n```python\ndef r_hat(theta, phi):\n    r\"\"\"\n    Computes the spherical unit vetor\n    :math:`\\hat{\\mathbf{r}}(\\theta, \\phi)`\n    as defined in :eq:`spherical_vecs`\n\n    Input\n    -------\n    theta : arbitrary shape, tf.float\n        Zenith angles :math:`\\theta` [rad]\n\n    phi : same shape as ``theta``, tf.float\n        Azimuth angles :math:`\\varphi` [rad]\n\n    Output\n    --------\n    rho_hat : ``phi.shape`` + [3], tf.float\n        Vector :math:`\\hat{\\mathbf{r}}(\\theta, \\phi)`  on unit sphere\n    \"\"\"\n    x = tf.cos(theta)*tf.cos(phi)\n    y = tf.cos(theta)*tf.sin(phi)\n    z = -tf.sin(theta)\n    return tf.stack([x,y,z], -1)\n```"
"The source code link of OFDMDetectorWithPrior is [sionna.ofdm.OFDMDetectorWithPrior(detector, output, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#OFDMDetectorWithPrior)  \n  \nThe link of the code lines of the context is:\n```python\nclass OFDMDetectorWithPrior(OFDMDetector):\n    # pylint: disable=line-too-long\n    r\"\"\"OFDMDetectorWithPrior(detector, output, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, dtype=tf.complex64, **kwargs)\n\n    Layer that wraps a MIMO detector that assumes prior knowledge of the bits\n    or constellation points are available, for use with the OFDM waveform.\n\n    The parameter ``detector`` is a callable (e.g., a function) that implements\n    a MIMO detection algorithm with prior for arbitrary batch dimensions.\n\n    This class pre-processes the received resource grid ``y``, channel\n    estimate ``h_hat``, and the prior information ``prior``, and computes for each receiver\n    the noise-plus-interference covariance matrix according to the OFDM and stream\n    configuration provided by the ``resource_grid`` and ``stream_management``,\n    which also accounts for the channel estimation error variance ``err_var``.\n    These quantities serve as input to the detection algorithm that is implemented\n    by ``detector`.\n    Both detection of symbols or bits with either\n    soft- or hard-decisions are supported.\n\n    Note\n    -----\n    The callable ``detector`` must take as input a tuple\n    :math:`(\\mathbf{y}, \\mathbf{h}, \\mathbf{prior}, \\mathbf{s})` such that:\n\n    * **y** ([...,num_rx_ant], tf.complex) -- 1+D tensor containing the received signals.\n    * **h** ([...,num_rx_ant,num_streams_per_rx], tf.complex) -- 2+D tensor containing the channel matrices.\n    * **prior** ([...,num_streams_per_rx,num_bits_per_symbol] or [...,num_streams_per_rx,num_points], tf.float) -- Prior of the transmitted signals. If ``output`` equals \"bit\", then LLRs of the transmitted bits are expected. If ``output`` equals \"symbol\", then logits of the transmitted constellation points are expected.\n    * **s** ([...,num_rx_ant,num_rx_ant], tf.complex) -- 2+D tensor containing the noise-plus-interference covariance matrices.\n\n    It must generate one of the following outputs depending on the value of ``output``:\n\n    * **b_hat** ([..., num_streams_per_rx, num_bits_per_symbol], tf.float) -- LLRs or hard-decisions for every bit of every stream, if ``output`` equals \"bit\".\n    * **x_hat** ([..., num_streams_per_rx, num_points], tf.float) or ([..., num_streams_per_rx], tf.int) -- Logits or hard-decisions for constellation symbols for every stream, if ``output`` equals \"symbol\". Hard-decisions correspond to the symbol indices.\n\n    Parameters\n    -----------\n    detector : Callable\n        Callable object (e.g., a function) that implements a MIMO detection\n        algorithm with prior for arbitrary batch dimensions. This could be\n        one of the existing detectors, such as :class:`~sionna.mimo.MaximumLikelihoodDetectorWithPrior`,\n        :class:`~sionna.mimo.MaximumLikelihoodDetector`, :class:`~sionna.mimo.MMSEDetectorWithPrior`,\n        or :class:`~sionna.mimo.MMSEDetector`.\n\n    output : One of [\"bit\", \"symbol\"], str\n        Type of output, either bits or symbols\n\n    resource_grid : ResourceGrid\n        Instance of :class:`~sionna.ofdm.ResourceGrid`\n\n    stream_management : StreamManagement\n        Instance of :class:`~sionna.mimo.StreamManagement`\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        Instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of ``y``.\n        Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    ------\n    (y, h_hat, prior, err_var, no) :\n        Tuple:\n\n    y : [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex\n        Received OFDM resource grid after cyclic prefix removal and FFT\n\n    h_hat : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex\n        Channel estimates for all streams from all transmitters\n\n    prior : [batch_size, num_tx, num_streams, num_data_symbols x num_bits_per_symbol] or [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float\n        Prior of the transmitted signals. If ``output`` equals \"bit\", LLRs of the\n        transmitted bits are expected. If ``output`` equals \"symbol\", logits of the\n        transmitted constellation points are expected.\n\n    err_var : [Broadcastable to shape of ``h_hat``], tf.float\n        Variance of the channel estimation error\n\n    no : [batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float\n        Variance of the AWGN\n\n    Output\n    ------\n    One of:\n\n    : [batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream, if ``output`` equals \"bit\".\n\n    : [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int\n        Logits or hard-decisions for constellation symbols for every stream, if ``output`` equals \"symbol\".\n        Hard-decisions correspond to the symbol indices.\n    \"\"\"\n    def __init__(self,\n                 detector,\n                 output,\n                 resource_grid,\n                 stream_management,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(detector=detector,\n                         output=output,\n                         resource_grid=resource_grid,\n                         stream_management=stream_management,\n                         dtype=dtype,\n                         **kwargs)\n\n        # Constellation object\n        self._constellation = Constellation.create_or_check_constellation(\n                                                        constellation_type,\n                                                        num_bits_per_symbol,\n                                                        constellation,\n                                                        dtype=dtype)\n```  \n  "
"Here is the detailed information of GaussianPriorSource: [sionna.fec.utils.GaussianPriorSource(num_tx, return_bits=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#GaussianPriorSource)  \n  \nGenerate a tensor of i.i.d. Gaussian distributed LLRs.\n\nThis layer generates Gaussian distributed LLRs with unit (w=1) variance and aw>0 for num_tx transmit antennas and returns for each of the num_tx outputs the following tuple: $({\\ell _1, \\dots , \\ell _n, \\sigma })$  \n  \n- **num_tx** (int): Number of transmit antennas.\n- **return_bits** (bool): If set to True, the function returns log-likelihood ratios (LLRs) for every bit transmitted. Defaults to False.\n- **dtype** (tf.DType): Defines the output datatype. Defaults to tf.complex64.\n\n**Output**\n- **x** ([num_tx, num_bits_per_symbol] or [num_tx, num_outcomes, num_bits_per_symbol], tf.float): The generated LLRs. If return_bits is True, the shape will be [num_tx, num_bits_per_symbol]. Otherwise, the shape will be [num_tx, num_outcomes, num_bits_per_symbol].\n\n**Note:** The generated variances are all-one ($\\sigma ^2=1$) by default, but this can be changed, e.g., through the set_sigma() method.  \n  "
"Here is the detailed information of QAM2PAM:   \n  \nTransforms QAM symbol indices to PAM symbol indices.\n\nFor indices in a QAM constellation, computes the corresponding indices for the two PAM constellations corresponding the real and imaginary components of the QAM constellation.\n\n### Parameters\n\n- **num_bits_per_symbol** (`int`) - The number of bits per QAM constellation symbol, e.g., 4 for QAM16.\n\n### Input\n\n- **ind_qam** (`Tensor`, `tf.int`) - Indices in the QAM constellation.\n\n### Output\n\n- **ind_pam1** (`Tensor`, `tf.int`) - Indices for the first component of the corresponding PAM modulation.\n- **ind_pam2** (`Tensor`, `tf.int`) - Indices for the first component of the corresponding PAM modulation.\n\nsource code link: [QAM2PAM](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#QAM2PAM)"
"To load the required Sionna components, you need to import the Sionna package and other necessary packages. Here's how you can do it:\n\n1. First, import the Sionna package. If it's not already installed, the code will install it:\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n2. Import other required components:\n\n```python\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n```\n\n3. Set the environment variables:\n\n```python\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ(\"CUDA_VISIBLE_DEVICES\") = f\"{gpu_num}\"\nos.environ('TF_CPP_MIN_LOG_LEVEL') = '3'\n```\n\n4. Load the Sionna components:\n\n```python\nfrom sionna.rt import load_scene\nfrom sionna.utils import expand_to_rank\n```\n\n5. Configure the notebook to use only a single GPU and allocate only as much memory as needed:\n\n```python\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\n\nRemember to run these commands in a Python environment with the Sionna package and the other packages already installed. If they're not installed, the code will install them."
"To import the necessary modules for Sionna's API and set up the GPU configuration, you can follow these steps:\n\n1. First, import the `os` module. Then, set the GPU number you want to use. If you want to use the CPU, you can set `gpu_num` to an empty string. After that, set the `CUDA_VISIBLE_DEVICES` environment variable to the GPU number you specified. This will ensure that only the specified GPU is used. Finally, set the `TF_CPP_MIN_LOG_LEVEL` environment variable to '3'. This will reduce the TensorFlow logging level.\n\n2. Next, import the `tensorflow` module. Then, list the physical devices available for TensorFlow. If there are GPUs available and the number of GPUs available is more than zero, set the memory growth of the first GPU to `True`. This will allocate only as much GPU memory as needed for the runtime allocations. Finally, set the logging level of the `tensorflow` module to 'ERROR' to avoid warnings from TensorFlow.\n\n3. Import the `matplotlib.pyplot` module and the `numpy` module. Set the `%matplotlib inline` magic command to display plots inline in the Jupyter notebook.\n\n4. Import the Sionna modules. If any of the Sionna modules is not already installed, install it using pip.\n\n5. Configure the notebook to use a single GPU and allocate only as much memory as needed for the GPU computations.\n\n6. Import the `LDPC5GEncoder` and `LDPC5GDecoder` classes from the Sionna FEC LDPC encoding and decoding module.\n\n7. Import the `BinarySource`, `ebnodb2no`, `sim_ber`, and `compute_ber` functions from the Sionna utils module.\n\n8. Import the `ResourceGrid`, `ResourceGridMapper`, `LSChannelEstimator`, `LMMSEEqualizer`, `OFDMModulator`, `OFDMDemodulator`, `ZFPrecoder`, `RemoveNulledSubcarriers`, `AntennaArray`, `CDL`, `Antenna`, `subcarrier_frequencies`, `cir_to_ofdm_channel`, `cir_to_time_channel`, `ApplyOFDMChannel`, `ApplyTimeChannel`, `OFDMChannel`, `TimeChannel`, `Mapper`, `Demapper`, and `compute_ber` classes and functions from the Sionna modules.\n\nRemember to import the modules in the order specified above."
"The 'CoverageMap' is a component of the ray-tracing module in Sionna. It is used to represent the coverage or field strength of signals at every point on a two-dimensional grid. After computing propagation paths using the 'compute_paths()' method of the 'Scene' component, the 'CoverageMap' can be created using the method of the same name.\n\nThe 'CoverageMap' is ideally generated for a scene that has undergone ray tracing. It provides a detailed representation of how signals propagate throughout the environment, as they are occluded or reflected by different objects. \n\nNotably, the 'CoverageMap' can be used to perform what is referred to as Site Specific Propagation Prediction (SSP2) in the module's documentation. This is essentially a procedure for constructing electromagnetic field strength maps, considering the geographical features of the scene and the placement of the transmitters and receivers.\n\nHere's a Python example based on the given context:\n\n```python\ncoverage_map = scene.coverage_map()\ncoverage_map.show()\n```\n\nIn this example, 'scene' refers to an instance of the 'Scene' component that has been set up for ray tracing. The method 'coverage_map()' is called on 'scene' to generate the coverage map. The 'coverage_map()' method will return a 'CoverageMap' object representing the coverage map for the scene. The resulting coverage map will be visualized in the default figure."
"The 'Sionna' TurboDecoder is a component implemented within the constraints of given generator polynomials used by the 'TurboEncoder'. Using the given 'TurboEncoder' is described in the context to set up the neural network-based Turbo Decoder. The 'TurboDecoder' class can be used to implement functionalities to perform iterative decoding of Turbo codes, these functionalities include depuncturing the received signs, performing the forward pass through two identical binary linear block decoders, and returning the estimated information bits.\n\n**Input Requirements**:\nThe input to the 'TurboDecoder' should be a 2+D tensor of arbitrary shape, with the last dimension referenced as 'n', representing the number of codeword bits. The input must be of type `tf.float32`. If the `hard` flag is set to `True`, the decoder will expect a tensor of the same shape as the input, but the last dimension will be interpreted as 'n', the number of information bits per codeword.\n\n**Output Format**:\nThe 'TurboDecoder' provides two outputs:\n1. LLR Logits: These are the output logits or hard-decisions on the decoded information bits. If the `hard` flag is set to `True`, the decoder will output a 2+D tensor of the same shape as the input. The last dimension will be interpreted as 'k', the number of information bits per codeword.\n2. Errors: This output is a 2+D tensor of the same shape as the input. The last dimension will be interpreted as 'k', the number of information bits per codeword.\n\nNote: The log-likelihood ratios (LLRs) are decimal values representing the likelihood of a bit being a '0' or a '1'. The 'hard' decision means that the decoder provides the final output as binary values, i.e., either 0 or 1, based on the signs of the LLRs.\n\nIn the provided context, the \"Forward Pass\" step is described, which involves depuncturing the received signs, and then passing the output of the depuncture operation through two binary linear decoders that correspond to the two constituent convolutional codes of the Turbo code. The input tensor for the decoder is a set of LLR values, and if the `hard` flag is set to `True`, the decoder provides a hard decision on the estimated information bits along with the corresponding bit errors."
"Here is the detailed information of sionna.rt.antenna.iso_pattern:  \n  \n[sionna.rt.antenna.iso_pattern(theta, phi, slant_angle=0.0, polarization_model=2, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/rt/antenna.html#iso_pattern)\n\nIsotropic antenna pattern with linear polarizarion\n\n**Input**\n\n- `theta` (array_like, float): Zenith angles wrapped within [0,pi] [rad]\n- `phi` (array_like, float): Azimuth angles wrapped within [-pi, pi) [rad]\n- `slant_angle` (float): Slant angle of the linear polarization [rad]. A `slant_angle` of zero means vertical polarization.\n- `polarization_model` (int, one of [1,2]): Polarization model to be used. Options 1 and 2 refer to polarization_model_1() and polarization_model_2(), respectively. Defaults to 2.\n- `dtype` (tf.complex64 or tf.complex128): Datatype. Defaults to tf.complex64.\n\n**Output**\n\n- `c_theta` (array_like, complex): Zenith pattern\n- `c_phi` (array_like, complex): Azimuth pattern"
"As the provided context does not include a simulation or example of using the \"ApplyOFDMChannel\" Keras layer directly, we can only advise on how to set up and use the layer based on the information provided. \n\nFirstly, you should import the Keras `Model` class and the `apply_ofdm_channel` function from the Sionna channel module. Then, you can instantiate the channel model by calling the `apply_ofdm_channel` function with the parameters that suit your setup. Finally, utilize the instance as a Keras model.\n\nHere is how you can do it:\n\n```python\nfrom tensorflow.keras import Model\nfrom sionna.channel import apply_ofdm_channel\n\n# Set up your parameters\nfft_size = 256  # FFT size\nbatch_size = 1  # Use 1 for simplicity\nnum_time_samples = 14  # Number of time samples\nadd_awgn = True  # Boolean flag to indicate adding AWGN\n\n# Instantiate the channel model\nchannel_model = apply_ofdm_channel(fft_size=fft_size, add_awgn=add_awgn)\n\n# Define a Keras model using the Model class\n# Just for example, here's a simple custom model defining the input shape\nclass OFDMChannelModel(Model):\n    def __init__(self, channel_model, **kwargs):\n        super().__init__(**kwargs)\n        self.channel_model = channel_model\n\n        # Perhaps you have multiple basestations and need to loop over them\n        # Just using `bsi` as an example\n        # You would need to stack the channels from each basestation together\n        # If you have different channel models, you'd need a little more logic here\n        self.num_rx = 1  # Number of receviers\n        self.num_rx_ant = 1  # Number of antennas per receiver\n\n    def build(self, input_shapes):\n        # You may need to verify this line, depending on your SIR model\n        self.h = self.channel_model.sample_channel()\n\n        # Input shape should be the shape of the input to your model\n        # For now, just setting a shape with batch size 1\n        self.inp_shape = input_shapes\n\n        # Perform a forward pass through the channel model to \"compile\" the graph\n        _ = self.call((x, no))  # noqa\n\n    def call(self, inputs):\n        x, no = inputs\n\n        # You may need to verify this line, depending on your SIR model\n        y = self.channel_model((x, no))\n\n        return y\n\n# Instantiate the model\nofdm_channel_model = OFDMChannelModel(channel_model=channel_model)\n\n# If you have a separate function to apply the channel, it should take\n# as input a tuple of the input signal `x` and the noise variance `no`\n# and return the channel output. You could define a function like\n# the following and use it instead of `channel_model`.\n\ndef my_channel_function(inputs):\n    x, no = inputs\n    # Compute and return the channel output somehow, given x and no\n    pass  # Placeholder for your implementation\n\n# Using the function above instead of the model\n# Remember to use your actual function and not the placeholder `...`\n# ofdm_channel_model = OFDMChannelModel(channel_model=my_channel_function)\n\n# Run your model\n# ...  # Use a batch size suited to your setup, here \"bs\"\n# `x` would be your input signal and `no` the noise variance\n# y = ofdm_channel_model((x, no))\n```\n\nPlease note that the above code is a general guideline and the specific implementation may vary depending on the specific setup, such as the use of different parameter values, the need to include additional arguments, or the use of a different Sionna version."
"The `Demapper` class is used to compute the log-likelihood ratios (LLRs) or hard-decisions on bits for a tensor of received symbols. If the `with_prior` flag is set, this method assumes that prior knowledge on the bits is assumed to be available. This class defines differentiable demapping functions. \n\nThere are several parameters that the `Demapper` class accepts:\n\n- `demapping_method`: This can be either \"app\" or \"maxlog\". If the `demapping_method` is \"app\", then the app demapping method is used. With this method, the LLR for the ith bit is computed using either the approximation of the probability density function (PDF) with another PDF, or the exact PDF if soft-symbol logits are provided. If \"maxlog\" is used, the demapper employs the max-log demapping method. With this method, the LLRs for the ith bit are approximated to a large positive or negative number if the probability of the bit being 1 or 0 is high.\n\n- `constellation_type`: This can be \"qam\", \"pam\", or \"custom\". For \"custom\", an instance of `Constellation` must be provided.\n\n- `num_bits_per_symbol`: This is an integer required for \"qam\" and \"pam\".\n\n- `constellation`: This is an instance of `Constellation` or `None`. If it's `None`, then `constellation_type` and `num_bits_per_symbol` must be provided.\n\n- `hard_out`: If set to `True`, the demapper provides hard-decided bits instead of soft values. Defaults to `False`.\n\n- `with_prior`: This is a Boolean value. If set to `True`, the demapper assumes that prior knowledge on the bits is available. This prior information is given as LLRs as an additional input to the layer. Defaults to `False`.\n\n- `dtype`: The datatype for `y`. Defaults to `tf.complex64`. The output datatype is the corresponding real dtype, i.e., `tf.float32` or `tf.float64`.\n\nInput:\n\n- `y`: This is a tensor of received symbols.\n\n- `no`: This is a scalar or tensor of noise variance estimates.\n\n- `prior`: This is a tensor of prior knowledge for every bit represented as LLRs. It's `None` unless the `with_prior` flag is set to `True`.\n\nOutput:\n\n- `llr`: This is a tensor of LLRs or hard-decisions for every bit.\n\nIf we want to compute the LLRs with the Demapper class, we need to follow these steps:\n\n1. Import the `Demapper` class from the sionna.mapping module.\n\n```python\nfrom sionna.mapping import Demapper\n```\n\n2. Create an instance of the `Demapper` class with the required configuration.\n\n```python\ndemapper = Demapper(demapping_method='ad')\n```\n\n3. Call the instance with the received symbols `y`, the noise variance `no`, and any prior information `prior`.\n\n```python\nllr = demapper((y, no, prior))\n```\n\n4. Use the computed LLRs for further processing, such as error correction or decoding.\n\nPlease note that the above code snippets assume that you have already defined the other parameters like `y`, `no`, and `prior`. The actual values for these parameters will depend on the specific requirements of your application."
"To obtain the Channel Impulse Responses (CIRs) in the model, we use the function `cir_to_time_channel` from the Sionna package. This function is used to transform continuous-time channel impulse responses to discrete time-domain representations. In this case, the bandwidth is provided as a parameter to the function, and the function returns the CIRs. \n\nThe parameters `l_min` and `l_max` in the function `cir_to_time_channel` are used to set the truncation of the CIRs. These two parameters determine the minimum and maximum time-lag for the CIRs, which can be used to control the duration of the CIRs. \n\nIt's important to note that the function `cir_to_time_channel` requires that the continuous-time channel impulse response be sampled at the Nyquist rate (i.e., two samples per sub-carrier per OFDM symbol). This high sampling rate is used to ensure that the CIRs are correctly captured in the time domain.\n\nIn the code snippet provided, the CIRs are computed using the `cdl` function, which returns the channel impulse responses for a CDL (Clustered Delay Line) model. The `cdl` function takes parameters such as `batch_size`, `num_time_steps`, `sampling_frequency`, and `num_ofdm_symbols`, to generate the channel impulse responses. The `cdl` function is part of the Sionna package and is used to model continuous-time channel impulse responses from a variety of 3GPP and 3GPP-like channel models."
"Here is the detailed information of List2LLRSimple:   \n  \n[sionna.mimo.List2LLRSimple(num_bits_per_symbol, llr_clip_val=20.0, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mimo/utils.html#List2LLRSimple)  \n  \nComputes LLRs from a list of candidate vectors (or paths) provided by a MIMO detector.\n\nThe following channel model is assumed:\n\n$\\bar{\\mathbf{y}} \\in \\mathbb{C}^S$ are the channel outputs, $\\mathbf{R} \\in \\mathbb{C}^{S\\times S}$ is an upper-triangular matrix, $\\bar{\\mathbf{x}} \\in \\mathcal{C}^S$ is the transmitted vector whose entries are uniformly and independently drawn from the constellation $\\mathcal{C}$, and $\\bar{\\mathbf{n}} \\in \\mathbb{C}^S$ is white noise with $\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\right]=\\mathbf{0}$ and $\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\bar{\\mathbf{n}}^{\\mathsf{H}}\\right]=\\mathbf{I}$.\n\nIt is assumed that a MIMO detector such as KBestDetector produces K candidate solutions $\\bar{\\mathbf{x}}_k\\in\\mathcal{C}^S$ and their associated distance metrics $d_k=\\lVert \\bar{\\mathbf{y}} - \\mathbf{R}\\bar{\\mathbf{x}}_k \\rVert^2$ for $k=1,\\dots,K$. This layer can also be used with the real-valued representation of the channel.\n\nThe LLR for the $i\\text{th}$ bit of the $k\\text{th}$ stream is computed as\n\n$\\begin{split}\\begin{align}\n   LLR(k,i) &= \\log\\left(\\frac{\\Pr(b_{k,i}=1|\\bar{\\mathbf{y}},\\mathbf{R})}{\\Pr(b_{k,i}=0|\\bar{\\mathbf{y}},\\mathbf{R})}\\right)\\\\\n        &\\approx \\min_{j \\in  \\mathcal{C}_{k,i,0}}d_j - \\min_{j \\in  \\mathcal{C}_{k,i,1}}d_j\n\\end{align}\\end{split}$\n\nwhere $\\mathcal{C}_{k,i,0}$ and $\\mathcal{C}_{k,i,1}$ are the set of indices in the list of candidates for which the $i\\text{th}$ bit of the $k\\text{th}$ stream is equal to 0 and 1, respectively. The LLRs are clipped to $\\pm\\text{LLR}_\\text{clip}$. Parameters\n\n- `num_bits_per_symbol` (int): Number of bits per constellation symbol.\n- `llr_clip_val` (float): The absolute values of LLRs are clipped to this value. Defaults to 20.0.\n- `dtype` (tf.DType): The output dtype. Options include tf.complex64 or tf.complex128. Defaults to tf.complex64. Input and output dypes must match.\n- `**kwargs`: Additional arguments for the base layer.\n\nInput\n\n- `(y, r, dists, path_inds, path_syms)` \u2013 Tuple:\n  - `y` ([..., M], tf.complex or tf.float): Channel outputs of the whitened channel.\n  - `r` ([..., num_streams, num_streams], same dtype as y): Upper triangular channel matrix of the whitened channel model.\n  - `dists` ([..., num_paths], tf.float): Distance metric for each path (or candidate).\n  - `path_inds` ([..., num_paths, num_streams], tf.int32): Transmit symbol indices for every stream of every path (or candidate).\n  - `path_syms` ([..., num_path, num_streams], same dtype as y): Transmit symbol for every stream of every path (or candidate).\n\nOutput\n\n- `llr` ([..., num_streams, num_bits_per_symbol], tf.float): LLRs for all bits of every stream. \u2026\n\nsource code:\n```python\nclass List2LLRSimple(ABC, Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"List2LLRSimple(num_bits_per_symbol, llr_clip_val=20.0, dtype=tf.complex64, **kwargs)\n\n    Computes LLRs from a list of candidate vectors (or paths) provided\n    by a MIMO detector.\n\n    The following channel model is assumed:\n\n    .. math::\n\n        \\bar{\\mathbf{y}} \\in \\mathbb{C}^S\n\n    are the channel outputs,\n\n    .. math::\n\n        \\mathbf{R} \\in \\mathbb{C}^{S\\times S}\n\n    is an upper-triangular matrix,\n\n    .. math::\n\n        \\bar{\\mathbf{x}} \\in \\mathcal{C}^S\n\n    is the transmitted vector whose entries are uniformly and independently\n    drawn from the constellation :math:`\\mathcal{C}`, and\n\n    .. math::\n\n        \\bar{\\mathbf{n}} \\in \\mathbb{C}^S`\n\n    is white noise with\n\n    .. math::\n\n        \\mathbb{E}\\left[\\bar{\\mathbf{n}}\\right]=\\mathbf{0}\n\n    and\n\n    .. math::\n\n        \\mathbb{E}\\left[\\bar{\\mathbf{n}}\\bar{\\mathbf{n}}^{\\mathsf{H}}\\right]=\\mathbf{I}.\n\n    It is assumed that a MIMO detector such as\n    :class:`~sionna.mimo.KBestDetector` produces K candidate solutions\n    :math:`\\bar{\\mathbf{x}}_k\\in\\mathcal{C}^S` and their associated distance\n    metrics :math:`d_k=\\lVert \\bar{\\mathbf{y}} - \\mathbf{R}\\bar{\\mathbf{x}}_k \\rVert^2`\n    for :math:`k=1,\\dots,K`. This layer can also be used with the\n    real-valued representation of the channel.\n\n    The LLR for the :math:`i\\text{th}` bit of the :math:`k\\text{th}` stream is\n    computed as\n\n    .. math::\n\n        \\begin{align}\n           LLR(k,i) &= \\log\\left(\\frac{\\Pr(b_{k,i}=1|\\bar{\\mathbf{y}},\\mathbf{R})}\n                    {\\Pr(b_{k,i}=0|\\bar{\\mathbf{y}},\\mathbf{R})}\\right)\\\\\n                &\\approx \\min_{j \\in  \\mathcal{C}_{k,i,0}}d_j - \\min_{j \\in\n                    \\mathcal{C}_{k,i,1}}d_j\n        \\end{align}\n\n    where :math:`\\mathcal{C}_{k,i,0}` and :math:`\\mathcal{C}_{k,i,1}` are\n    the set of indices in the list of candidates for which the\n    :math:`i\\text{th}` bit of the :math:`k\\text{th}` stream is equal to 0 and 1,\n    respectively. The LLRs are clipped to :math:`\\pm LLR_\\text{clip}`.\n    If :math:`\\mathcal{C}_{k,i,0}` is empty, :math:`LLR(k,i)=LLR_\\text{clip}`.\n    If :math:`\\mathcal{C}_{k,i,1}` is empty, :math:`LLR(k,i)=-LLR_\\text{clip}`.\n\n    Parameters\n    -----------\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol.\n\n    llr_clip_val : float\n        The absolute values of LLRs are clipped to this value.\n        Defaults to 20.0.\n\n    dtype : tf.DType\n        The output dtype. Defaults to `tf.complex64`.\n        Input and output dtype must match.\n\n    Input\n    -----\n    (y, r, dists, path_inds, path_syms) :\n        Tuple:\n\n    y : [...,M], tf.comjlex or tf.float\n        Channel outputs of the whitened channel.\n\n    r : [...,num_streams, num_streams], same dtype as ``y``\n        Upper triangular channel matrix of the whitened channel.\n\n    dists : [...,num_paths], tf.float\n        Distance metric for each path (or candidate).\n\n    path_inds : [...,num_paths,num_streams], tf.int32\n        Transmit symbol indices for every stream of every path (or candidate).\n\n    path_syms : [...,num_path, num_streams], same dtype as ``y``\n        Transmit symbol for every stream of every path (or candidate).\n\n    Output\n    ------\n    llr : [...num_streams,num_bits_per_symbol], tf.float\n        LLRs for all bits of every stream.\n    \"\"\"\n\n    def __init__(self,\n                 num_bits_per_symbol,\n                 llr_clip_val=20.0,\n                 dtype=tf.complex64,\n                 **kwargs):\n\n        super().__init__(dtype=dtype, **kwargs)\n\n        assert llr_clip_val>=0, \"llr_clip_val cannot be negative.\"\n        self._llr_clip_val = llr_clip_val\n        self._num_bits_per_symbol = num_bits_per_symbol\n\n        # Constellation used for mapping bits to symbols\n        self._constellation = snr.constellations.Constellation(\"qam\",\n                                self._num_bits_per_symbol,\n                                snr_type=dtype)\n\n    def compute_llr(self, y, r, dists, path_inds, path_syms):\n\n        # Input tensors form\n        # y : [...,M], tf.comjlex or tf.float\n        # r : [...,num_streams, num_streams], same dtype as y\n        # dists : [...,num_paths], tf.float\n        # path_inds : [...,num_paths,num_streams], tf.int32\n        # path_syms : [...,num_path, num_streams], tf.float\n\n        num_dims = snr.utils.nDims(y)\n        if num_dims == 1:\n            y = tf.expand_dims(y, -1)\n            r = tf.expand_dims(r, 0)\n            num_dims = 2\n\n        # Number of streams per transmitter\n        num_streams_per_tx = tf.shape(path_inds)[-1]\n\n        # Preparing for broadcastting path_syms to [...,num_path, num_streams]\n        # or to [...,M, num_streams] if there's only one path\n        path_syms = snr.utils.expand_to_rank(path_syms, num_dims, 0)\n\n        # Generate array of LLR values for all bits of every stream\n        llr_max = tf.constant(self._llr_clip_val, dtype=self.dtype)\n        llr = tf.zeros( tf.shape(path_inds), dtype=self.dtype)\n\n        # The following two steps are done in a for loop to avoid large\n        # aggregations in the graph mode\n        for i in range(0, self._num_bits_per_symbol):\n            c0 = tf.zeros([num_dims, 2**i, 2*num_streams_per_tx], #tmp shape\n                        dtype=self.dtype)\n            c1 = tf.zeros([num_dims, 2**i, 2*num_streams_per_tx], #tmp shape\n                        dtype=self.dtype)\n            # Two rows of c0 and c1 are enough as we only have information\n            # about two consecutive symbols due to the recursive nature of\n            # symbol mapping.\n            # With more sophisticated constellations, this needs to be\n            # generalized.\n            for b in range(0, self._num_bits_per_symbol):\n                c0[b,:] = tf.bitwise.Xor(c0[b,:], tf.cast(0, dtype=c0.dtype))\n                c1[b,:] = tf.bitwise.Xor(c0[b,:], tf.cast(1, dtype=c0.dtype))\n\n            # Create two indicator arrays of size\n            # [num_paths, num_streams_per_tx, num_bits_per_symbol]\n            # that indicate were the bits of the constellation symbols are\n            # equal to 0 and 1, respectively.\n            ind0 = tf.gather(c0, path_inds, axis=-1, batch_dims=1)\n            ind1 = tf.gather(c1, path_inds, axis=-1, batch_dims=1)\n\n            # Two rows of indicators are enough as we only have information\n            # about two consecutive symbols due to the recursive nature of\n            # symbol mapping.\n            # With more sophisticated constellations, this needs to be\n            # generalized.\n            # Shape [...,num_paths, num_streams, num_bits_per_symbol]\n            # and [...,num_streams, num_bits_per_symbol, num_paths]\n            # ind0 = tf.repeat(ind0, 2, axis=-1)\n            # ind1 = tf.repeat(ind1, 2, axis=-1)\n            ind = tf.stack([ind0, ind1], axis=-2)\n            # Shape [...,num_paths, 2*num_streams_per_tx, num_bits_per_symbol]\n\n            # At this point, ind has a different shape than the other\n            # inputs. So, we need to do a preliminary broadcast. We'll\n            # do this by expanding the rank of ind by adding a dimension of\n            # size 1 at the end.\n            # Shape [...,num_paths, 2*num_streams_per_tx, num_bits_per_symbol,\n            #         1]\n            ind = tf.broadcast_to(ind, tf.concat(\n                                    [tf.shape(dists), [1]], axis=-1))\n\n            # Add a dimension for broadcasting\n            llr_ = tf.expand_dims(self._constellation.llr(snr.utils.cast_like(ind, self.dtype),\n                                                        dists), -1)\n\n            # Compute the LLR using the binary operations of bitwise soft\n            # symbol LLRs and by using gather to access the relevant values\n            # of llr_\n            # Shape [...,num_paths, num_streams_per_tx, num_bits_per_symbol]\n            llr = tf.where(ind0, llr_, llr*tf.cast(0, dtype=llr.dtype))\n            # Put selected dims into correct order\n            # Shape [...,num_streams_per_tx, num_bits_per_symbol, num_paths]\n            llr = tf.transpose(llr, [0,1,3,2])\n            # Min over the last dimension\n            # Shape [...,num_streams_per_tx, num_bits_per_symbol]\n            llr = tf.reduce_min(llr, axis=-1)\n            llr = tf.clip_by_value(llr, -llr_max, llr_max)\n\n            # Update ind0 and ind1 for the next bit position\n            ind0 = tf.roll(ind0, shift=1, axis=-1)\n            ind1 = tf.roll(ind1, shift=1, axis=-1)\n            # Stack together\n            # Shape [...,num_paths, num_streams_per_tx, num_bits_per_symbol]\n            ind = tf.stack([ind0, ind1], axis=-2)\n            # Broadcast\n            # Shape [...,num_paths, 2*num_streams_per_tx, num_bits_per_symbol,\n            #         1]\n            ind = tf.broadcast_to(ind, tf.concat(\n                                    [tf.shape(dists), [1]], axis=-1))\n            # Get new LLRs\n            llr_ = self._constellation.llr(snr.utils.cast_like(ind, self.dtype),\n                                    dists)\n            # Shape [...,num_paths, num_streams_per_tx, num_bits_per_symbol]\n            llr = tf.where(ind0, llr_, llr*tf.cast(0, dtype=llr.dtype))\n            # Put selected dims into correct order\n            # Shape [...,num_streams_per_tx, num_bits_per_symbol, num_paths]\n            llr = tf.transpose(llr, [0,1,3,2])\n            # Min over the last dimension\n            # Shape [...,num_streams_per_tx, num_bits_per_symbol]\n            llr = tf.reduce_min(llr, axis=-1)\n            llr = tf.clip_by_value(llr, -llr_max, llr_max)\n\n            # Add LLRs of all positions of the previous LLRs\n            if i > 0:\n                # Shape [...,num_paths, num_streams_per_tx, num_bits_per_symbol]\n                llr = llr + tf.gather(llr, path_inds, axis=-2,\n                                    batch_dims=1)\n\n        return llr\n\n\n    def call(self, inputs):\n\n        y, r, dists, path_inds, path_syms = inputs\n\n        llr = self.compute_llr(y, r, dists, path_inds, path_syms)\n        # The gather operation may introduce nans where no candidates are\n        # available. We replace those by -20, as this value is typically\n        # ignored by the channel decoder.\n        llr = tf.where(tf.math.is_nan(llr),\n                        tf.constant(-20, dtype=self.dtype), llr)\n\n        return llr\n```"
"The definition of MaximumLikelihoodDetector: sionna.ofdm.MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)  \n  \n[Source code](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#MaximumLikelihoodDetector)  \n\n```python\nclass MaximumLikelihoodDetector(OFDMDetectorWithSideInformation):\n    # pylint: disable=line-too-long\n    r\"\"\"MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    Maximum-likelihood (ML) detection for OFDM MIMO transmissions.\n\n    This layer implements maximum-likelihood (ML) detection for OFDM MIMO\n    transmissions. Both ML detection of symbols or bits with either\n    soft- or hard-decisions are supported. The OFDM and stream configuration are\n    provided by a :class:`~sionna.ofdm.ResourceGrid` and\n    :class:`~sionna.mimo.StreamManagement` instance, respectively. The\n    actual detector is an instance of :class:`~sionna.mimo.MaximumLikelihoodDetector`.\n\n    Parameters\n    ----------\n    output : One of [\"bit\", \"symbol\"], str\n        Type of output, either bits or symbols. Whether soft- or\n        hard-decisions are returned can be configured with the\n        ``hard_out`` flag.\n\n    demapping_method : One of [\"app\", \"maxlog\"], str\n        Demapping method used\n\n    resource_grid : ResourceGrid\n        Instance of :class:`~sionna.ofdm.ResourceGrid`\n\n    stream_management : StreamManagement\n        Instance of :class:`~sionna.mimo.StreamManagement`\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        Instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the detector computes hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of ``y``. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    ------\n    (y, h_hat, s_hat, no) :\n        Tuple:\n\n    y : [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex\n        Received OFDM resource grid after cyclic prefix removal and FFT\n\n    h_hat : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex\n        Channel estimates for all streams from all transmitters\n\n    s_hat : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols], tf.complex\n        Estimates of the covariance matrices from the stream detection\n\n    no : [batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float\n        Variance of the AWGN noise\n\n    Output\n    ------\n    One of:\n\n    : [batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream, if ``output`` equals `\"bit\"`.\n\n    : [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int\n        Logits or hard-decisions for constellation symbols for every stream, if ``output`` equals `\"symbol\"`.\n        Hard-decisions correspond to the symbol indices.\n\n    Note\n    ----\n    If you want to use this layer in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sionna.Config.xla_compat=true``.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n\n    def __init__(self,\n                 output,\n                 demapping_method,\n                 resource_grid,\n                 stream_management,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n\n        # Instantiate the maximum-likelihood detector\n        detector = MaximumLikelihoodDetector_(output=output,\n                            demapping_method=demapping_method,\n                            num_streams = stream_management.num_streams_per_rx,\n                            constellation_type=constellation_type,\n                            num_bits_per_symbol=num_bits_per_symbol,\n                            constellation=constellation,\n                            hard_out=hard_out,\n                            dtype=dtype,\n                            **kwargs)\n\n        super()."
"Here is the detailed information:   \nGenerate 5G ranking.\n\nThis class defines a Keras layer that implements a 5G ranking as defined in TS 38.211, section 6.3.1.3 [3GPP38211].\n\nThe class inherits from the Keras layer class and can be used as layer in a Keras model.  \n  \n### Parameters\n\n- **csi**: `bool`\n  If true, the channel state information (CSI) version of the 5G ranking is returned. The DFT size is then expected to be two and the first output is the preferred subcarrier indices.\n\n- **d**: Complex-valued 1+D tensor containing the discrete Fourier transform (DFT) coefficients of the input radio-metric scores. The tensor shape is [...,num_rx_ant,num_streams_per_tx,num_ofdm_symbols,fft_size].\n\n- **num_effective_subcarriers**: Number of effective subcarriers $N_{\\text{esc}}$. This is the same as the number of subcarriers for normal and extended cyclic prefix.\n\n- **output_data_type**: A tf.DType defining the preferred output datatype of this layer. Defaults to tf.float32.\n\n### Input\n\n- **x**: Tensor of complex values containing the DFT coefficients.\n\n### Output\n\n- **s**: Tensor of the same shape as the input containing the channel quality scores. If `csi` is True, the shape is [..., num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers]. Otherwise, the shape is [..., num_rx, num_rx_ant, num_tx, num_streams_per_tx].\n\n- **ps**: Tensor of the same shape as the output of **s** containing the pilot symbols. If `csi` is True, the last two dimensions are for the real and imaginary components of the pilot symbols.\n\n### Properties\n\n- **bandwidth**: Bandwidth [Hz] per PRB.\n\n- **fft_size**: OFDM FFT size.\n\n- **num_cdm_groups_without_dci**: Number of CDM groups without DCIs.\n\n- **num_ofdm_symbols**: Number of OFDM symbols.\n\n- **num_streams_per_tx**: Number of streams per transmitter.\n\n- **num_subcarriers_per_prb**: Number of subcarriers per resource block.\n\n- **num_tx**: Number of transmitters.\n\n- **num_widebands**: Number of widebands.\n\n- **preferred_tci_si**: Preferred subcarrier indices for the TCI and PSI.\n\n- **q**: Minimum number of quantization bits.\n\n- **resolution**: Radio-metric resolution.\n\n- **tb_size**: Transport block size.\n\n- **tf**: Tensorflow version.\n\n- **to_normalize**: Indicating if the channel impulse responses are normalized.\n\n- **training**: Training mode of the capture effect.\n\n### Raises\n\n- `AssertionError`: If `x` is not a valid input shape."
"To run the channel modeling in Sionna, you need to follow these steps:\n\n1. Import the necessary libraries and modules. This includes Sionna, which is not shown in the context, but is necessary for channel modeling in Sionna.\n\n2. Configure the CDL model. This is done by using the `sn.channel.tr38901.CDL` function. You need to specify the CDL model type, nominal delay spread, carrier frequency, receiver array, transmitter array, direction (uplink or downlink), and optionally the UT array and BS array. The result of this function is a CDL model, which is used for channel modeling.\n\n3. Generate batches of random realizations of continuous-time channel impulse responses. This can be done by calling the CDL model with the batch size and the number of time steps as parameters. The function will return the complex gains `a` and the delays `tau` for each path.\n\n4. After obtaining the impulse responses, you can model the channel in the frequency domain. To do this, you need to specify the batch size, the sampling frequency, and the number of frequency samples. The function will return the channel frequency responses.\n\nHere is a simplified version of the code that explains these steps:\n\n```python\nfrom sionna.channel.tr38901 import CDL\n\nCDL_MODEL = \"C\"\nDELAY_SPREAD = 100e-9\nCARRIER_FREQUENCY = 2.6e9\nUT_ARRAY = [...]\nBS_ARRAY = [...]\nDIRECTION = \"uplink\"\ncdl = CDL(CDL_MODEL, DELAY_SPREAD, CARRIER_FREQUENCY, UT_ARRAY, BS_ARRAY, DIRECTION)\na, tau = cdl(batch_size=BATCH_SIZE, num_time_steps=RESOURCE_GRID.num_ofdm_symbols, sampling_frequency=1/RESOURCE_GRID.ofdm_symbol_duration)\nh_freq = cdl(batch_size=BATCH_SIZE, num_ofdm_symbols=RESOURCE_GRID.num_ofdm_symbols, subcarrier_spacing=RESOURCE_GRID.fft_size/RESOURCE_GRID.num_ofdm_symbols)\n```\n\nPlease note that this is a simplified version of the code and may not work as is. You need to import the right modules and packages, and also provide the right parameters."
"Here is the detailed information of load_alist:   \n  \n[sionna.fec.utils.load_alist(path)](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#load_alist)  \n\nRead alist-file MacKay and return nested list encoding information\n\nThe nested list, , defines the sparse parity-check matrix, where each non-zero element corresponds to a generator polynomial of degree minus one of a codeword component polynomial. For example, [5,6,0,0,0] means that the polynomial divides the third, fourth, and fifth parity bit, but does not divide the first and second parity bit. Please note that the polynomial degree is shifted by -1 with respect to the actual shift of the information bit polynomial would have.\n\nIn addition, the list also outputs the degree profile of the encoder.\n\nExample:\n\nReturning the parity-check matrix of Hamming(7,4)\n\npath = '[necessary-directory-path-comes-here] alist which you want to use'\n```python\nal = load_alist(path)\nprint_parity_check(al, n=7, k=4)\n```\n\nOutput:\n\n    Parity-check matrix:\n    [[1, 1, 1, 1, 1, 1, 1]]\n    [1, 0, 1, 0, 1, 0, 1]]\n    [0, 1, 1, 0, 0, 1, 1]]\n    \n    Row-wise column indices of nonzero elements of the parity-check matrix:\n    [[0, 1, 2, 3, 4, 5, 6]]\n    [1, 2, 3, 4, 5, 6]\n    [2, 3, 4, 0, 1, 5, 6]]\n    \n    Degree profile (each list element denotes the degree of a check node):\n    [3, 3, 3, 1, 1, 1, 1]\n\n**Input**\n\n- `path` (str): Path to file to be loaded.\n\n**Output**\n\n- `alist` (list): A nested list containing the imported alist data.\n- `deg_polar` (list of int): List of check node degrees.\n- `deg_lemma` (list of int): List of lemma degree.\n- `var_deg` (list of int): List of variable node degrees.\n- `check_idx` (list of list of int): Check node indices for each variable node.\n- `var_idx` (list of list of int): Variable node indices for each check node.\nsource code:\n```python\ndef load_alist(path):\n    # pylint: disable=line-too-long\n    r\"\"\"Read alist-file MacKay and return nested list encoding information\n\n    The nested list, `alist`, defines the sparse parity-check matrix, where\n    each non-zero element corresponds to a generator polynomial of degree\n    ``deg(a)`` minus one of a codeword component polynomial. For example,\n    `[5,6,0,0,0]` means that the polynomial divides the third, fourth, and\n    fifth parity bit, but does not divide the first and second parity bit.\n    Please note that the polynomial degree is shifted by -1 with respect to\n    the actual shift of the information bit polynomial would have.\n\n    In addition, the list also outputs the degree profile of the encoder.\n\n    Example\n    --------\n    Returning the parity-check matrix of Hamming(7,4)\n\n    >>> path = '[necessary-directory-path-comes-here] alist which you want to use'\n    >>> al = load_alist(path)\n    >>> print_parity_check(al, n=7, k=4)\n\n    Output\n    -------\n    Parity-check matrix:\n    [[1, 1, 1, 1, 1, 1, 1]]\n    [1, 0, 1, 0, 1, 0, 1]]\n    [0, 1, 1, 0, 0, 1, 1]]\n\n    Row-wise column indices of nonzero elements of the parity-check matrix:\n\n    [[0, 1, 2, 3, 4, 5, 6]]\n    [1, 2, 3, 4, 5, 6]\n    [2, 3, 4, 0, 1, 5, 6]]\n\n    Degree profile (each list element denotes the degree of a check node):\n\n    [3, 3, 3, 1, 1, 1, 1]\n\n    Input\n    -----\n    path: str\n        Path to file to be loaded.\n\n    Output\n    ------\n    alist: list\n        A nested list containing the imported alist data.\n\n    deg_polar: list of int\n        List of check node degrees\n\n    deg_lemma: list of int\n        List of lemma degree\n\n    var_deg: list of int\n        List of variable node degrees\n\n    check_idx: list of list of int\n        Check node indices for each variable node\n\n    var_idx: list of list of int\n        Variable node indices for each check node\n    \"\"\"\n\n    assert isinstance(path, str), \"path must be str.\"\n    assert bool(path), \"path is provided.\"\n\n    with open(path) as f:\n        aldata = f.read().splitlines()\n\n    # aldata may contain comments, thus we do not assume that each file\n    # element has the same length.\n\n    al = []\n    deg_polar = int(aldata[0].split(\" \")[1]) # read deg_polar\n    deg_lemma = int(aldata[0].split(\" \")[2]) # read deg_lemma\n    var_deg = int(aldata[0].split(\" \")[3]) # read var_deg\n\n    # extract parity-check matrix\n    j = 0\n    while aldata[j][0] == \"A\": # stop when generator-matrix starts\n        j += 1\n    aldata = aldata[j:] # aldata now only contains PCM\n\n    # convert to list of lists\n    for dat in aldata:\n        al += [list(map(int, dat.split(\" \")))]]\n\n    # al should be a nested list where each list element denotes a\n    # check node\n\n    # derive var_idx from check_idx\n    var_idx = []\n    for j in range(len(al[0])):\n        vu = []\n        for i in range(len(al)):\n            if al[i][j]:\n                vu += [i]\n        var_idx += [vu]\n\n    # derive check_idx from var_idx\n    check_idx = []\n    for i in range(len(var_idx)):\n        cu = []\n        for j in range(len(var_idx[i])):\n            cu += [var_idx[i][j]]\n        check_idx += [cu]\n\n    return al, deg_polar, deg_lemma, var_deg, check_idx, var_idx\n```"
"Here are some useful links of it:\n\n[MIMO Detectors Comparison](https://nvlabs.github.io/sionna/_images/mimo_det_cmp.png)\n\n[5G NR PUSCH Tutorial](https://nvlabs.github.io/sionna/examples/5G_NR_PUSCH_Tutorial.html)\n\n[Run the tutorial in Google Colab](https://colab.research.google.com/github/nvlabs/sionna/blob/main/examples/5G_NR_PUSCH_Tutorial.ipynb)\n\n[View on GitHub](https://github.com/nvlabs/sionna/blob/main/examples/5G_NR_PUSCH_Tutorial.ipynb)\n\n[API Documentation](https://nvlabs.github.io/sionna)\n\n[Gallery](https://nvlabs.github.io/sionna/examples.html)"
"The Scene's `cameras` property is a part of the 'Sionna' package and is used in the 'Sionna.rt' module. It refers to the cameras that are present in the scene. By default, every scene has at least one camera. The `cameras` property provides the essential functionality to work with scene cameras.\n\nThe 'cameras' property functions in several ways. It can return a list of all the cameras in the scene, create a new camera at a desired position with a specific orientation, and look at a position in the scene from a specific camera instance. The property can also be used to render the scene from a camera's perspective.\n\nUsing the various methods available with the `cameras` property, it provides significant control over the cameras within the scene. This can be particularly useful in multi-camera scenes where defining the position and view direction of each camera can give a more comprehensive rendering of the scene from different angles or positions.\n\nThe 'cameras' property also works with other components of the 'Sionna.rt' module like 'Scene' and 'Camera', allowing seamless integration of camera related functions with the scene management and rendering process."
"Here is the detailed information of RaisedCosineFilter:   \n  \n[sionna.signal.RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/signal/filter.html#RaisedCosineFilter)  \n\nLayer for applying a raised cosine filter of length K to an input x of length N.\n\nThe raised cosine filter is defined by\n$h(t) =\n\\begin{cases}\n\\frac{1}{T}\\left(1+\\beta\\left(\\frac{4}{\\pi}-1\\right)\\right), & \\text {if }t = 0\\\\\n\\frac{\\beta}{T\\pi}\\left[\\frac{\\left(1+\\frac{2}{\\pi}\\right)\\sin\\left(\\frac{\\pi}{4\\beta}\\right)+\\frac{3\\cos\\left(\\frac{\\pi}{4\\beta}\\right)}{4\\beta}\\right], & \\text {if }t = \\pm\\frac{T}{4\\beta} \\\\\n\\frac{1}{T}\\frac{\\sin\\left(\\pi\\frac{t}{T}(1-\\beta)\\right)+4\\beta\\frac{t}{T}\\cos\\left(\\pi\\frac{t}{T}(1+\\beta)\\right)}{\\pi\\frac{t}{T}\\left(1-\\left(4\\beta\\frac{t}{T}\\right)^2\\right)}, & \\text {if }|t|<T\\\\\n0, & \\text {otherwise}\n\\end{cases}$\n\nwhere $\\beta$ is the roll-off factor and $T$ the symbol duration.\n\nThe filter length K is equal to the filter span in symbols (span\\_in\\_symbols) multiplied by the oversampling factor (samples\\_per\\_symbol). If this product is even, a value of one will be added.\n\nThe filter is applied through discrete convolution.\n\nAn optional windowing function window can be applied to the filter.\n\nThe dtype of the output is tf.float if both x and the filter coefficients have dtype tf.float. Otherwise, the dtype of the output is tf.complex.\n\nThree padding modes are available for applying the filter:\n- \u201cfull\u201d (default): Returns the convolution at each point of overlap between x and the filter. The length of the output is N + K - 1. Zero-padding of the input x is performed to compute the convolution at the borders.\n- \u201csame\u201d: Returns an output of the same length as the input x. The convolution is computed such that the coefficients of the input x are centered on the coefficient of the filter with index (K-1)/2. Zero-padding of the input signal is performed to compute the convolution at the borders.\n- \u201cvalid\u201d: Returns the convolution only at points where x and the filter completely overlap. The length of the output is N - K + 1.\n\n### Parameters\n\n- `span_in_symbols` (int): Filter span as measured by the number of symbols.\n- `samples_per_symbol` (int): Number of samples per symbol, i.e., the oversampling factor.\n- `beta` (float): Roll-off factor. Must be in the range $[0,1]$.\n- `window` (Window or string [\"hann\", \"hamming\", \"blackman\"]): Instance of Window applied to the filter coefficients or a string indicating the window name. Custom windows must be provided as an instance.\n- `normalize` (bool): If True, the filter is normalized to have unit power. Defaults to True.\n- `trainable` (bool): If True, the filter coefficients are trainable variables. Defaults to False.\n- `dtype` (tf.DType): The dtype of the filter coefficients. Defaults to tf.float32.\n\n### Input\n\n- `x` ([..., N], tf.complex or tf.float): The input to which the filter is applied, along the last dimension.\n- `padding` (string [\"full\", \"valid\", \"same\"]): Padding mode for convolving x and the filter. Must be one of \"full\", \"valid\", or \"same\". Case insensitive. Defaults to \"full\".\n- `conjugate` (bool): If True, the complex conjugate of the filter is applied. Defaults to False.\n\n### Output\n\n- `y` ([..., M], tf.complex or tf.float): Filtered input. It is tf.float only if both x and the filter are tf.float. It is tf.complex otherwise. The length M depends on the padding.\n\n### Properties\n\n**Property: `aclr`**\n- ACLR of the filter. This corresponds to using the filter as a pulse shaping filter on an i.i.d. sequence of symbols, with the in-band assumed to range from [-0.5, 0.5] in normalized frequency.\n\n**Property: `beta`**\n- Roll-off factor.\n\n**Property: `coefficients`**\n- The filter coefficients (after normalization).\n\n**Property: `length`**\n- The filter length in samples.\n\n**Property: `normalize`**\n- True if the filter is normalized to have unit power.\n\n**Property: `sampling_times`**\n- Sampling times in multiples of the symbol duration.\n\n**Property: `trainable`**\n- True if the filter coefficients are trainable.\n\n**Property: `window`**\n- The window function applied to the filter coefficients. None if no window is applied.\n\n### Method: `show(response='impulse', scale='lin')`\n\nPlot the impulse or magnitude response\n\nPlots the impulse response (time domain) or magnitude response (frequency domain) of the filter.\n\nFor the computation of the magnitude response, a minimum DFT size of 1024 is assumed which is obtained through zero padding of the filter coefficients in the time domain.\n\n- **Input**:\n  - `response` (str, one of [\"impulse\", \"magnitude\"]): Desired response type. Defaults to \u201cimpulse\u201d.\n  - `scale` (str, one of [\"lin\", \"db\"]): Y-scale of the magnitude response. Can be \"lin\" (linear) or \"db\" (decibel). Defaults to \"lin\"."
"Here is the detailed information of sionna.signal.Upsampling:   \n\n[sionna.signal.Upsampling(samples_per_symbol, l, axis=- 1, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/signal/downsampling.html#Upsampling)\n\nUpsamples a tensor along a specified axis by inserting zeros.\n\n## Parameters\n\n- `samples_per_symbol` (int): Number of samples per symbol, i.e., the oversampling factor.\n- `l` (int): Upsampling factor. The number of zeros to insert after each sample is `l-1`.\n- `axis` (int): The dimension to which the upsampling is applied. Must not be the first dimension.\n- `dtype` (tf.DType): The Dtype for internal calculations and the output dtype. Defaults to tf.complex64.\n\n## Input\n\n- `x` ([..., N, ...], tf.complex): The input tensor to be upsampled. `N` is the size of the axis dimension.\n\n## Output\n\n- `y` ([..., N * l, ...], tf.complex): The upsampled output.\n\n## Properties\n\n- `l` Upsampling factor. The number of zeros inserted after each sample is `l-1`.\n- `samples_per_symbol` The oversampling factor. Set this parameter equal to the downsampling factor in the associated `Downsampling` layer.\n\n**Note: **\n\nIf the input dimension is `x_shape = [...,n,...]`, then the output shape `y` is `[...,n*l,...]`. If `n` is the size of the axis on which upsampling is applied, then this shape is `[...,k,l,...]`, where `k = n*(l-1)`."
"The `polarization_model_1` and `polarization_model_2` functions in the Sionna wireless channel polarization models are used to apply specific polarization transformations to antenna patterns. More precisely, \n\n* `polarization_model_1(c_theta, theta, phi, slant_angle)` applies Model-1 polarization to the antenna pattern `c_theta` based on the given slant angle `slant_angle`. \n    * The Zenith pattern `c_theta` is expected to have absolute values indicating the gain in the specific direction.\n    * `theta` and `phi` are arrays of the same size as `c_theta` and represent the Zenith and azimuth angles.\n    * The function returns two outputs, `c_theta` and `c_phi`, which represent the zenith and azimuth patterns of the transformed polarization respectively.\n\n* `polarization_model_2(c_rho, c_theta, theta, phi, slant_angle)` applies Model-2 polarization to the antenna pattern `c_theta` and `c_rho` based on the given slant angle `slant_angle`.\n    * Here, `c_rho` is expected to have absolute values indicating the gain in the radial direction (coming towards the antenna), and `c_theta` is the Zenith pattern with absolute values indicating the gain in the direction of the zenith (upward).\n    * `theta` and `phi` are arrays of the same size as `c_rho` and `c_theta` and represent the Zenith and azimuth angles.\n    * The function returns two outputs, `c_theta` and `c_phi`, which represent the zenith and azimuth patterns of the transformed polarization respectively.\n\nIn the context, it is advised to use these functions on models of the `ChannelModel` to apply the desired polarization transformations to wireless channel simulations. Can you explain how to do this?"
"Here is the detailed information of Mapper:   \n  \n[sionna.mapping.Mapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, return_indices=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Mapper)  \n\nMaps binary tensors to points of a constellation.\n\nThis class defines a layer that maps a tensor of binary values to a tensor of points from a provided constellation.  \n  \n### Parameters\n\n- **constellation_type** (*str*) \u2013 One of [\"qam\", \"pam\", \"custom\"], where \"custom\" denotes that an instance of Constellation is provided. This is used to specify the constellation type. Note: \"custom\" must be used for \"pam\".\n\n- **num_bits_per_symbol** (*int*) \u2013 The number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation types \"qam\" and \"pam\".\n\n- **constellation** (Instance of Constellation) \u2013 An instance of Constellation or None. In the latter case, constellation_type and num_bits_per_symbol must be provided.\n\n- **return_indices** (*bool*) \u2013 If True, symbol indices are additionally returned. Defaults to False.\n\n- **dtype** (*One of [tf.complex64, tf.complex128]tf.DType*) \u2013 The output dtype. Defaults to tf.complex64.\n\n### Input\n\n- [*n ,\u2026, num_bits_per_symbol], tf.float or tf.int \u2013 Tensor with binary entries.\n\n### Output\n\n- [*n ,\u2026,num_bits_per_symbol], tf.complex \u2013 The mapped constellation symbols.\n- [*n ,\u2026,num_bits_per_symbol], tf.int32 \u2013 The symbol indices. Only returned if return_indices is set to True.  \n  \n**Note: **  \nThe last dimension of the input must be an integer multiple of the number of bits per constellation symbol.  \n  \n### Properties\n\n- **constellation**\n  - Description: The Constellation used by the Mapper.\n  - Type: Constellation  \n  \n### Method\n\n- **show_mapping(show=True)**\n  - Description: Visualizes the mapping of the binary symbol indexes to constellation points.\n  - Input: \n    - show (bool): If True, the visualization is shown. Otherwise, the base64 encoded png of the visualization is returned. Defaults to True.\n  - Output: str. Base64 encoded png of the mapping visualization."
"The `LDPC5GEncoder` class is initialized with several parameters, as shown in the provided context. Below are the parameters and their types, in accordance with the Python code:\n\n- **k** (type: *int*)**: **k** is the number of input information bits**. It defines the number of data bits per codeword before the encoding procedure is applied.\n- **n** (type: *int*)**: **n** is the desired output codeword length**. This parameter specifies the desired length of the codeword after the encoding process, which includes the application of various coding techniques specific to the LDPC 5G encoding standard.\n- **num_bits_per_symbol** (type: *int* or *None*)**: **num_bits_per_symbol** is the number of bits per QAM symbol**. It indicates the modulation order, i.e., the number of bits per symbol for the output codeword after the rate-matching operation.\n- **dtype** (type: *tf.DType*)**: **dtype** is the output datatype of the encoder**. It determines the datatype of the encoder's output, which is typically either `tf.float32` or `tf.float64`, and it represents the precision of the output bits.\n- **kwargs** (type: *kwargs*)**: This parameter allows the inclusion of additional arguments without explicitly specifying them. It is represented by **`**kwargs`** and is commonly used to pass additional parameters into the function without updating the function signature.\n\nThe construction of the parameters adheres to the Python coding standards, and before including or using these parameters, it is essential to ensure that they are set according to the requirements of the specific encoding task. Additionally, providing a context that specifies the types of coding techniques applied could help in clearly differentiating among these parameters."
"The provided context includes several functions from the Sionna module, which is an in-depth module for simulating wireless communication specifically. The functions are described as follows:\n\n1.   `complex2real_vector(z)` : This function accepts a complex-valued vector z and returns its real-valued equivalent vector. The equivalent vector contains the real and imaginary parts of z in a consecutive manner.\n\n2. `real2complex_vector(z)` : This function accepts a real-valued vector z and returns its complex-valued equivalent vector. The equivalent vector contains the real and imaginary parts of z merged together.\n\n3. `complex2real_matrix(r)` : This function transforms a complex-valued covariance matrix R into its real-valued equivalent matrix. The equivalent matrix has the same dimensions as R, but the elements are the combination of real and imaginary parts.\n\n4. `real2complex_matrix(q)` : This function transforms a real-valued covariance matrix Q into its complex-valued equivalent matrix. The equivalent matrix has the same dimensions as Q, but the elements are the combination of real and imaginary parts.\n\n5. `complex2real_covariance(r)` : This function transforms a complex-valued covariance matrix R into its real-valued equivalent matrix. The equivalent matrix is the same size as R and contains the real parts on the diagonal and the imaginary parts off the diagonal.\n\n6. `real2complex_covariance(q)` : This function transforms a real-valued covariance matrix Q into its complex-valued equivalence. The equivalence matrix is the same size as Q and contains the real parts on the diagonal and the imaginary parts off the diagonal.\n\n7. `complex2real_channel(y, h, s)` : Given a received signal vector y, a channel matrix h, and a noise covariance matrix s, this function computes the real-valued equivalent representation of the received signal.\n\n8. `real2complex_channel(y, h, s)` : Given a received signal vector y, a channel vector h, and a noise covariance matrix s, this function computes the complex-valued equivalent representation of the received signal.\n\nIt's important to note that the first four functions deal with a matrix that's not typically square, hence operations like inverse etc. are not applicable to the result. Also, the descriptions provided generally explain what the functions do, but a more detailed explanation would be helpful to fully understand their workings."
"Here is the detailed information of FlatFadingChannel:  \n \nApplies random channel matrices to a vector input and adds AWGN. This class combines GenerateFlatFadingChannel and ApplyFlatFadingChannel and computes the output of a flat-fading channel with AWGN.\n\nFor a given batch of input vectors $\\mathbf{x}\\in\\mathbb{C}^{K}$, the output is $\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}$ where $\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ are randomly generated flat-fading channel matrices and $\\mathbf{n}\\in\\mathbb{C}^{M}\\sim\\mathcal{CN}(0, N_o\\mathbf{I})$ is an AWGN vector that is optionally added.\n\nA SpatialCorrelation can be configured and the channel realizations optionally returned. This is useful to simulate receiver algorithms with perfect channel knowledge.\u6cd5\u7c7b\u5c06\u4e00\u7ec4\u968f\u673a\u4fe1\u9053\u77e9\u9635\u4f5c\u7528\u4e8e\u8f93\u5165\u5411\u91cf\uff0c\u5e76\u6dfb\u52a0AWGN\u3002FlatFadingChannel\u7c7b\u4e0d\u4ec5\u751f\u6210\u5355\u4e2aFlatFadingChannel\uff0c\u8fd8\u4f1a\u751f\u6210\u5bf9\u5e94\u7684AWGN\uff0c\u7136\u540e\u5c06Channel\u548cAWGN\u4f5c\u7528\u4e8e\u8f93\u5165\u3002\u8bf7\u53c2\u9605AWGN\u4e86\u89e3\u6211\u4eec\u662f\u5982\u4f55\u5904\u7406AWGN\u3002\u4e3a\u4e86\u4f7f\u7cfb\u7edf\u66f4\u5177\u8868\u73b0\uff0c\u6240\u6709\u7684\u64cd\u4f5c\u5c06\u4f1ain-place\u6267\u884c\uff0c\u5373\u76f4\u63a5\u4fee\u6539\u8f93\u5165\u5411\u91cf\u3002\u751f\u6210\u7684\u4fe1\u9053\u77e9\u9635\u7684\u5c3a\u5bf8\u4f1a\u6839\u636e\u8f93\u5165\u548c\u914d\u7f6e\u51b3\u5b9a\uff0c\u6700\u7ec8\u5c06\u4f1a\u751f\u6210\u4e00\u77e9\u9635\uff0c\u800c\u4e0d\u662f\u6784\u5efa\u751f\u6210\u7684\u4fe1\u9053\u6a21\u578b\u3002  \n  \nFor example, in the code snippet below, channel_model is an instance of GenerateFlatFadingChannel, consisting of multiple GenerateFlatFadingChannel, each of which generates the channel for one of the K transmitter antennas. A flat-fading channel is then applied with AWGN added.  \n  \n```python  \nchannel = FlatFadingChannel(num_tx_ant=4,\n                              num_rx_ant=16,\n                              add_awgn=True,\n                              return_channel=True)\ny, h = channel(x)\n```\n \nwhere $x\\in\\mathbb{C}^{batch\\_size \\times 4}$ is the vector of independent and identically distributed (i.i.d.) symbols to be transmitted, $\\mathbb{C}^{batch_size \\times 16}$ is the vector of received symbols, and `channel` is the instance of FlatFadingChannel.  \n  \n**Parameters**\n\n- `num_tx_ant` (int): Number of transmit antennas.\n- `num_rx_ant` (int): Number of receive antennas.\n- `spatial_corr` (SpatialCorrelation, None): An instance of SpatialCorrelation or None. Defaults to None.\n- `add_awgn` (bool): Indicates if AWGN noise should be added to the output. Defaults to True.\n- `return_channel` (bool): Indicates if the channel matrix should be returned. Defaults to False.\n- `dtype` (tf.DType): The dtype of the output. Defaults to tf.complex64.  \n  \n**Input**\n\n- `x` ([..., K], tf.complex): Tensor of transmit vectors where `K` is the number of transmit antennas.\n- `no` (Tensor, tf.float): Scalar or tensor whose shape can be broadcast to the shape of the channel output if `add_awgn` is set to True. The noise power `no` is per complex dimension. Only required if `add_awgn` is set to True.\n  \n**Output**\n\n- `y` ([..., num_rx_ant], tf.complex): Channel output.  \n- `h` ([..., num_rx_ant, num_tx_ant], tf.complex): Channel realizations. Channel output when `return_channel` is set to True.  \n  \n**Properties**\n\n- `apply`: Calls the internal ApplyFlatFadingChannel().  \n- `generate`: Calls the internal GenerateFlatFadingChannel().  \n- `spatial_corr`: The SpatialCorrelation to be used.  "
"Here is the definition of PilotPattern: sionna.ofdm.PilotPattern(mask, pilots, trainable=False, normalize=False, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/pilot_pattern.html#PilotPattern)  \n\nsource code:\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"Class for defining pilot patterns in an OFDM system.\"\"\"\nimport tensorflow as tf\nfrom tensorflow.python.ops.variables import Variable\nfrom tensorflow.keras.layers import Layer\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy\nfrom enum import Enum\n\nfrom .utilities import flatten_last_dims, flatten_dims, split_dim\nfrom .resource_grid import ResourceGrid\n\nclass PilotPattern(Enum):\n    \"\"\"Class for defining pilot pattern\n\n    A ``PilotPattern`` object defines a ``PilotPattern`` instance\n    along with certain configuration options, such as the number of\n    transmitters, streams per transmitter, etc.\n    The ``PilotPattern`` is then used to configure an OFDM\n    :class:`~sionna.ofdm.ResourceGrid`.\n\n    Parameters\n    ----------\n    mask : [num_tx, num_streams_per_tx, num_ofdm_symbols,\n        num_effective_subcarriers], bool\n        Mask of the pilot pattern. A resource element is indicated as a\n        pilot if its mask is ``True``.\n\n    pilots : [num_tx, num_streams_per_tx, num_pilots], tf.complex\n        The pilot symbols to be mapped onto the mask.\n\n    trainable : bool\n        Indicates if ``pilots`` is a trainable `Variable`.\n        Defaults to `False`.\n\n    normalize : bool\n        Indicates if the pilots should be normalized to an average\n        energy of one across the last dimension.\n        Defaults to `False`.\n\n    dtype : tf.Dtype\n        Defines the datatype for internal calculations and the output\n        dtype. Defaults to `tf.complex64`.\n        \"\"\"\n    def __init__(self,\n                 mask,\n                 pilots,\n                 trainable=False,\n                 normalize=False,\n                 dtype=tf.complex64):\n\n        assert dtype.is_complex, \"dtype must be a complex datatype\"\n        self._dtype = dtype\n\n        assert isinstance(mask, tf.DType), \"mask must be a Tensor of booleans\"\n        self._mask = mask\n\n        assert tf.as_dtype(dtype).is_complex, \"Datatype not supported.\"\n        self._pilots = tf.as_dtype(dtype).internal(pilots)\n\n        assert self._mask.shape[0] == self._pilots.shape[0] , \\\n            \"num_tx inputs must match\"\n\n        assert self._mask.shape[1] == self._pilots.shape[1], \\\n            \"num_streams_per_tx inputs must match\"\n\n        self._num_tx = self._mask.shape[0]\n        self._num_streams_per_tx = self._mask.shape[1]\n\n        self._normalize = normalize\n\n        assert isinstance(trainable, bool), \"trainable must be bool\"\n        self._trainable = trainable\n\n        if self._trainable:\n            assert self._pilots.dtype == tf.as_dtype(dtype), \\\n                \"Dtype of `pilots` must match `dtype`\"\n            self._pilots = tf.Variable(self._pilots,\n                                      dtype=dtype.real_dtype,\n                                      trainable=True)\n        else:\n            assert self._pilots.dtype == tf.as_dtype(dtype), \\\n                \"Dtype of `pilots` must match `dtype`\"\n\n        assert self._pilots.shape[0] == self._num_tx\n        assert self._pilots.shape[1] == self._num_streams_per_tx\n\n        assert self._mask.shape[2] == self._pilots.shape[2], \\\n            \"num_ofdm_symbols must match\"\n        assert self._mask.shape[3] == self._pilots.shape[3], \\\n            \"num_effective_subcarriers must match\"\n\n        self._num_ofdm_symbols = self._mask.shape[2]\n        self._num_effective_subcarriers = self._mask.shape[3]\n\n        if self._normalize:\n            # Normalization requires a float tensor\n            tf.cast(self._pilots, dtype=dtype.real_dtype)\n\n            # Average energy per symbol; we assume a non-zero DC-offset\n            e = tf.reduce_mean(tf.square(self._pilots))\n\n            # Normalize non-zero energy to one\n            e = tf.cast(tf.maximum(e, 1e-12), dtype=dtype)\n            self._pilots = self._pilots/tf.cast(tf.sqrt(e), self._dtype)\n\n    @property\n    def mask(self):\n        \"\"\"Returns the mask of the pilot pattern.\"\"\"\n        return self._mask\n\n    @property\n    def normalize(self):\n        \"\"\"Indicates if the pilots are normalized or not.\"\"\"\n        return self._normalize\n\n    @property\n    def num_tx(self):\n        \"\"\"Returns the number of transmitters.\"\"\"\n        return self._num_tx\n\n    @property\n    def num_streams_per_tx(self):\n        \"\"\"Returns the number of streams  per transmitter.\"\"\"\n        return self._num_streams_per_tx\n\n    @property\n    def num_ofdm_symbols(self):\n        \"\"\"Returns the number of OFDM symbols.\"\"\"\n        return self._num_ofdm_symbols\n\n    @property\n    def num_effective_subcarriers(self):\n        \"\"\"Returns the number of effective subcarriers.\"\"\"\n        return self._num_effective_subcarriers\n\n    @property\n    def pilots(self):\n        \"\"\"Returns the possibly normalized tensor of pilot symbols.\"\"\"\n        return self._pilots\n\n    @property\n    def trainable(self):\n        \"\"\"Indicates if the pilots are trainable or not.\"\"\"\n        return self._trainable\n\n    def show(self, tx_ind=None, stream_ind=None, show_pilot_ind=False):\n        \"\"\"Visualize the pilot patterns from some transmitters and streams.\n\n        Input\n        -----\n        tx_ind : List, int\n            Indicates the indices of transmitters to be included.\n            Defaults to `None`, i.e., all transmitters included.\n\n        stream_ind : List, int\n            Indicates the indices of streams to be included.\n            Defaults to `None`, i.e., all streams included.\n\n        show_pilot_ind : bool\n            Indicates if the pilot indices should be shown.\n\n        Output\n        ------\n        : [matplotlib.figure.Figure]\n            List of matplot figure objects showing each the pilot pattern\n            from a specific transmitter and stream.\n        \"\"\"\n        fig_list = []\n        m = 1\n        for i, tx in enumerate(tx_ind):\n            for j, s in enumerate(stream_ind):\n                fig_list.append(plt.figure()\n      .subplots(1,1, figsize=(12,12))\n                plt.title(f\"Tx {tx} - Stream {s}\")\n                plt.imshow(self._mask[tx][s][...,0],\n                           aspect=m,\n                           vmin=0, vmax=1,\n                           interpolation='none')\n                if show_pilot_ind:\n                    for n in range(self._pilots[tx][s].shape[0]):\n                        i = self._pilots[tx][s][n].numpy().real\n                        j = self._pilots[tx][s][n].numpy().imag\n                        plt.text(j, i, f\"{n}\",\n                                 fontsize=8, color=\"white\")\n                plt.axis(\"off\")\n        return fig_list\n```"
"To use Sionna, you need to import the necessary packages including TensorFlow and NumPy. Here's how you can do it:\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n\nimport numpy as np\nimport tensorflow as tf\ntf.get_logger().setLevel('ERROR')\n\n# IPython \"magic function\" for inline plots\n%matplotlib inline\nimport matplotlib.pyplot as plt\n```\n\nIn the above code, we first set the environment variable to use the GPU. If you want to use the CPU, you can set `gpu_num` to an empty string. \n\nWe then try to import Sionna. If it's not installed, we catch the `ImportError` and install Sionna using `pip install sionna`.\n\nWe then import NumPy and TensorFlow. To avoid logging, we set the log level of TensorFlow's logger to 'ERROR'.\n\nFinally, we use the IPython \"magic function\" `%matplotlib inline` to enable inline plots."
"Here is the detailed information of LinearInterpolator:   \n  \nInterpolates channel estimates across the resource grid.\n\nThe provided measurement `h_hat` of channel `k` for pilot-carrying resource elements is interpolated\nacross the entire resource grid using a nearest-neighbor interpolation.\nA separate interpolator is used for each transmitter and stream.\n\n**Parameters**\n\n- `h_hat` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex) \u2013 Channel estimates for the pilot-carrying resource elements.\n- `pilot_pattern` (PilotPattern) \u2013 An instance of PilotPattern.\n- `time_avg` (bool) \u2013 If enabled, measurements will be averaged across OFDM symbols (i.e., time). Defaults to False.\n\n**Input**\n\n- `h_hat` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex) \u2013 Channel estimates for the pilot-carrying resource elements.\n\n**Output**\n\n- `h_hat` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], tf.complex) \u2013 Channel estimates across the entire resource grid for all transmitters and streams.\n- `err_var` (Same shape as h_hat, tf.float) \u2013 Channel estimation error variances across the entire resource grid for all transmitters and streams."
"The detailed information of SymbolLogits2Moments is shown as follows:   \n  \nParameters\n\n   -  constellation_type (One of**\"qam\"**, **\"pam\"**, **\"custom\"**] str): For custom, an instance of `Constellation` must be provided.\n\n   -  num_bits_per_symbol (int): The number of bits per constellation symbol, e.g., 4 for QAM16. Only required for `constellation_type` in [qam, pam].\n\n   -  constellation (Constellation): An instance of `Constellation` or None. In the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n\n   -  dtype (One of[tf.float32, tf.float64] tf.DType): The dtype for the input and output. Defaults to tf.float32.\n\nInput\n   -  logits ([..., n, num_points], tf.float): Logits on constellation points.\n\nOutput\n   - mean ([..., n], tf.float): Mean of the constellation.\n   - var ([..., n], tf.float): Variance of the constellation."
"The 'cir_to_ofdm_channel' function is used to compute the frequency response of the channel at a set of frequencies. The frequency response describes the complex amplitude and phase shift introduced by the channel at each frequency.\n\nGiven a channel impulse response `(a, tau)` represented by the inputs `a` and `tau`, the function computes the channel frequency response at the input `frequencies` using the formula:\n\n```\nh_f = \u03a3m a(m) e^(-j2\u03c0f\u03c4(m))\n```\n\nwhere `m` is summed over the number of paths of the channel, `a(m)` is the path coefficient, `\u03c4(m)` is the path delay, and `f` represents the frequencies.\n\nIn the context of time-varying channels, the inputs `a` and `tau` can be associated with the different time samples, so that `h_f` will not only depend on the frequencies but also on the time instance. \n\nThe function `cir_to_ofdm_channel` is particularly useful in the field of wireless communication, as it allows researchers to perform channel estimation, i.e., to estimate the properties of the channel from known pilot symbols. This is crucial in ensuring that signals transmitted from a sender remain intact and reliable upon reaching the receiver. \n\nIt is important to note that the given context does not provide information about the capability of the function to support such features like time-varying channels or optional parameters like `normalize`, hence a complete functionality of the function cannot be demonstrated."
"The `EPDetector` class is a vital component of Sionna's MIMO module as it applies Expectation Propagation (EP) for MIMO detection in wireless communication. The class is designed to run in Graph mode with XLA, essentially ensuring that it is compatible with TensorFlow's execution engine. \n\nThere are several parameters for the `EPDetector` class:\n\n- `output`: A parameter that specifies the type of output, i.e., whether the detector should output bits or symbols. It's assumed that soft-symbol output if activated if the `hard_out` flag is set to False.\n- `num_bits_per_symbol`: This parameter indicates the number of bits per QAM constellation symbol, e.g., 4 for QAM16.\n- `hard_out`: If set to True, the detector computes hard-decided bit values or constellation point indices instead of soft values. This parameter is particularly significant when you need to make decisions based on the computed data.\n- `l`: The number of iterations for the EP detection. The standard value for this parameter is set to 10.\n- `beta`: A parameter that defines the update smoothing. EP runs in parallel, and the beta parameter is used for damping. The standard value for this parameter is set to 0.9.\n- `dtype`: Defines the precision that will be used for internal computations. The standard value is tf.complex64, indicating that computations will be carried out using complex floating-point numbers with 64 bits of precision.\n\nInput to the `EPDetector` class is expected to be a tuple (Tensor) with three components: \n\n- `y`: A Tensor containing the received signals.\n- `h`: A Tensor containing the channel matrices.\n- `no`: A Tensor containing the noise variance estimates.\n\nThe output of `EPDetector` is variable depending on the `output` parameter. If it's set to \"bit,\" you will get LLRs or hard-decisions for every bit of every stream. If it's set to \"symbol,\" you will get logits or hard-decisions for constellation symbols for every stream.\n\nIn summary, the `EPDetector` class is a vital part of MIMO signal processing as it provides multi-carrier demapping, equalization, and soft- or hard-decision detection through Expectation Propagation, which can be essential in optimizing network performance."
"To use the EDFA class in Sionna, you should follow these steps:\n\n1. Import the required modules:\n\n```python\nimport sionna\nimport tensorflow as tf\n```\n\n2. Define the EDFA class:\n\n```python\nclass MyEDFA(sionna.channel.optical.EDFA):\n    def __init__(self):\n        super().__init__(\n            g=4.0,\n            f=2.0,\n            f_c=193.55e12,\n            dt=1.0e-12,\n            with_dual_polarization=False,\n            dtype=tf.complex64)\n```\n\n3. Create an instance of the EDFA class:\n\n```python\nedfa = MyEDFA()\n```\n\n4. Run the instance of the EDFA class:\n\n```python\n# e.g., simulate the transmission of a constant optical input signal over\n# the EDFA\ny = edfa(x)\n```\n\nIn this example, `x` is an optical input signal. The variable `y` would now contain the output of the channel simulation.\n\nPlease note that the constructor of the EDFA class includes various parameters such as `g`, `f`, `f_c`, `dt`, `with_dual_polarization`, and `dtype`. You can adjust these parameters according to your needs. For their detailed descriptions, you can review the source code provided in the context.\n\nAlso, the output of the channel simulation will depend on the specific input signal and the parameters you've set for the EDFA. This code is just a general example and might not work for your particular use case without appropriate adjustments."
"The `render_to_file()` function, part of the `Scene` class in the Sionna package, is used to render the current state of the scene and then save it to a file. The function will first render the scene from the viewpoint of a specified camera, or the interactive viewer if it's open. It will then save the rendered image to a file with a filename matching the provided `filename` argument.\n\n`render_to_file(`**camera** | `camera_name` | **path to file**`, `filename` | `paths` | `show_paths` | `show_devices` | `coverage_map` | `cm_tx` | `cm_db_scale` | `cm_vmin` | `cm_vmax` | `num_samples` | `resolution` | `fov``)`\n\n- **camera** is an optional argument of type `Camera` or string. If a `Camera` object is provided, the function will render the scene from that camera's viewpoint. If a string is provided, it's interpreted as the name of a specific camera in the scene.\n\n- **filename** is a mandatory argument of type string. It specifies the name (and format) of the file the rendered image will be saved to.\n\n- **paths** is an optional argument of type `Paths`. If provided, the function will include the simulated paths in the rendering.\n\n- **show_paths** is a boolean optional argument. If `paths` is provided, setting `show_paths` to `True` will display the paths in the rendered image.\n\n- **show_devices** is a boolean optional argument. If provided, setting `show_devices` to `True` will display the radio devices in the scene.\n\n- **coverage_map** is an optional argument of type `CoverageMap`. If provided, the function will overlay the coverage map on the rendered image.\n\n- **cm_tx** is either an integer or string. It represents the index or name of the transmitter for which to display the coverage map, if a `CoverageMap` is provided.\n\n- **cm_db_scale** is a boolean optional argument. If the coverage map is provided, it determines whether or not to use a logarithmic scale for the coverage map.\n\n- **cm_vmin** and **cm_vmax** are optional arguments of type float. They specify the minimum and maximum path gain values that the color map covers, in dB if `cm_db_scale` is set to `True`, or in linear scale otherwise.\n\n- **num_samples** is an optional argument of type integer. It specifies the number of rays traced per pixel during the rendering.\n\n- **resolution** is a two-element sequence of integers. It defines the size of the rendered image.\n\n- **fov** is a float that stands for the 'field of view', in degrees.\n\nIn this usage, the function will render the scene to a file named 'my_render.png' from the viewpoint of the camera with the name 'my_cam'. It will also include the simulated paths in the rendering, and set `show_paths` to `True` while `show_devices`, `coverage_map`, `cm_tx`, `cm_db_scale`, `cm_vmin`, `cm_vmax`, `num_samples`, `resolution`, and `fov` will all be used with their default settings. \n\nNote: Providing a camera as the `camera` argument can override the `filename` argument. If both are given, the `filename` is ignored and the rendered image from the camera's viewpoint is used."
"The \"wrap_angle_0_360\" function is a part of the Sionna channel module, more specifically the utility functions. This function is used to wrap an angle to the range between 0 and 360. The function takes an input as a tensor (angle) and returns another tensor as output, which is the same as the input angle but wrapped to the range between 0 and 360.\n\nHere is how you use it:\n\n```python\nresult = sionna.channel.wrap_angle_0_360(angle)\n```\n\nIn the above line:\n- `sionna.channel.wrap_angle_0_360(angle)` : `sionna.channel.wrap_angle_0_360` is the function being used. \n   - `angle` : Is the input tensor, which is an angle to be wrapped.\n\nAnd \"angle\" in the output will be wrapped to the range between 0 and 360.\n\nPlease note that the actual function might slightly differ based on the specific implementation details. The provided context does not include the actual function definition of \"wrap_angle_0_360\". Please verify the specific implementation details from the source code."
"Here is the definition of ChannelModel: sionna.channel.ChannelModel  \n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel) link.\n\nsource code:\n```python\nclass ChannelModel(ABC):\n    \"\"\"Abstract class that defines an interface for channel models.\n\n    Any channel model which generates channel impulse responses must\n    implement this interface. All the channel models available in Sionna,\n    such as :class:`~sionna.channel.RayleighBlockFading` or\n    :class:`~sionna.channel.TDL`, implement this interface.\n\n    Remark\n    -----\n    Some channel models only require a subset of the input parameters.\n    \"\"\"\n\n    @abc.abstractmethod\n    def __call__(self, batch_size, num_time_steps, sampling_frequency):\n        \"\"\"Generate and return channel responses\n\n        This function returns the channel responses which are used to\n        implement a channel model in a simulator.\n\n        Input\n        ------\n        batch_size : int\n            Batch size\n\n        num_time_steps : int\n            Number of time steps\n\n        sampling_frequency : float\n            Sampling frequency [Hz]\n\n        Output\n        --------\n        a : [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex\n            Path coefficients\n\n        tau : [batch size, num_rx, num_tx, num_paths], tf.float\n            Path delays [s]\n        \"\"\"\n        pass\n\n    @property\n    @abc.abstractmethod\n    def support_time_channel(self):\n        \"\"\"Support of the channel model in the time domain.\n\n        A ``True`` value indicates that the channel model is supported\n        over a certain range of time steps.\n\n        Output\n        ------\n        support_time_channel : bool\n            `True` if the channel model is supported\n        \"\"\"\n        pass\n\n    @property\n    @abc.abstractmethod\n    def support_frequency_channel(self):\n        \"\"\"Support of the channel model in the frequency domain.\n\n        A ``True`` value indicates that the channel model is supported\n        over a certain range of subcarriers.\n\n        Output\n        ------\n        support_frequency_channel : bool\n            `True` if the channel model is supported\n        \"\"\"\n        pass\n```"
"Because the provided context does not include specific information about the `sionna.rt.Scene.render_to_file` method, the detailed information of input should be referred to the given context and the Sionna's official documentation."
"To configure DeepMIMO for use with Sionna, follow these steps:\n\n1. Import the necessary libraries and modules. This includes Sionna, which will be necessary to use DeepMIMO with Sionna.\n\n```python\nimport os\nimport sionna\nfrom sionna.utils import PCGIDecomposer\nfrom sionna.channel.tr38901 import Antenna, UMi, UMa, RMa\nfrom sionna.channel import gen_single_sector_topology as gen_topology\nfrom sionna.channel import subcarrier_frequencies, cir_to_ofdm_channel, cir_to_time_channel\nfrom sionna.nr import UEs, BSs\nfrom sionna.utils import compute_pathloss\nfrom sionna.constants import BANDWIDTH, CARRIWIDTH\n ```\n\n2. Set up your DeepMIMO configuration. This will depend on your specific use case and the DeepMIMO scenarios you plan to use. In the provided context, the DeepMIMO parameters are set up like this:\n\n```python\nimport DeepMIMO\ntry:\n    import DeepMIMO\nexcept ImportError as e:\n    import os\n    os.system(\"pip install DeepMIMO\")\n    import DeepMIMO\nDeepMIMO_params = DeepMIMO.default_params()\nDeepMIMO_params['dataset_folder'] = r'./scenarios' # Path to the downloaded scenarios\nDeepMIMO_params['scenario'] = 'O1_60' # DeepMIMO scenario\nDeepMIMO_params['num_paths'] = 10 # Maximum number of paths\nDeepMIMO_params['active_BS'] = np.array([6]) # Basestation indices to be included in the dataset\nDeepMIMO_params['user_row_first'] = 400 # First user row to be included in the dataset\nDeepMIMO_params['user_row_last'] = 450 # Last user row to be included in the dataset\nDeepMIMO_params['bs_antenna']['shape'] = np.array([16, 1, 1]) # BS antenna shape through [x, y, z] axes\nDeepMIMO_params['ue_antenna']['shape'] = np.array([1, 1, 1]) # UE antenna shape through [x, y, z] axes\nDeepMIMO_params['OFDM_channels'] = 0\nDeepMIMO_dataset = DeepMIMO.generate_data(DeepMIMO_params)\n```\n\n3. Import the DeepMIMO Sionna adapter. This adapter is used to transform the DeepMIMO dataset into a format that is compatible with Sionna.\n\n```python\nfrom deepmimo.adapters.sionna import DeepMIMOSionna\n ```\n\n4. Instantiate the DeepMIMO Sionna adapter. This adapter takes the DeepMIMO dataset and the indices of the basestations and user rows to generate the channel impulse responses.\n\n```python\nDeepMIMO_sionna = DeepMIMOSionna(DeepMIMO_dataset, bs_idx=0, num_ut_rows=50)\n ```\n\n5. Compute the receive power. This is done using the `compute_rx_power` function from the Sionna package.\n\n```python\n# `circuit` and `theta` are defined in the \"CIR Dataset Example\" section of the given context.\nP_rx = cir_to_pow(circuit, theta)\n ```\n\n6. Generate the frequency response of the channel. This is done using the `cir_to_ofdm_channel` function from the Sionna package.\n\n```python\nh_freq = cir_to_ofdm_channel(circuit, theta, resource_grid)\n ```\n\n7. Finally, you can use the frequency responses `h_freq` to filter a resource grid and generate channel responses. This is done using the `apply_oh` function from the Sionna package.\n\n```python\nh_oh = apply_oh(h_freq, encompassing_resource_grid)\n ```"
"To use the \"interleaver module\" in the Sionna package to permute tensors, you should follow these steps:\n\n1. First, you need to import the required modules using the provided context:\n\n```python\nfrom sionna.fec.interleaving import RandomInterleaver, Deinterleaver\nimport tensorflow as tf\n```\n\n2. Next, you should initialize the interleaver with the required parameters. The `seed` parameter is an explicit random seed that can be used to create a new random seed for each call if needed. The `keep_batch_constant` parameter is set to `False` so that all samples in the batch are permuted with the same pattern. The `axis` parameter specifies the dimension that you want to permute.\n\n```python\ninterleaver = RandomInterleaver(seed=1234, keep_batch_constant=False, axis=-1)\n```\n\n3. After that, you can use the interleaver by passing your tensor `c` to the `interleaver` function. This will interleave the elements along the last dimension.\n\n```python\nc_int = interleaver(c)\n```\n\n4. If you want to reconstruct the original order of the tensor, you need to use the `deinterleaver` function and pass your interleaved tensor to it.\n\n```python\nc_deint = deinterleaver(c_int)\n```\n\n5. For advanced usage, if you want the system to use an explicit random seed for each call, you can generate a new random seed for each call and pass it to the interleaver along with your tensor.\n\n```python\ns = tf.random.uniform((), minval=0, maxval=12345678, dtype=tf.int32)\nc_int = interleaver([c, s])\nc_deint = deinterleaver([c, s])\n```\n\nRemember, the \"interleaver module\" is stateless, and its internal seed doesn't change after initialization. However, if an explicit random seed is provided during the call, a new random seed is created for each call."
"The `MMSEPICDetector` function is a part of the Sionna package for wireless communication and is used to implement Expectation Propagation (EP) for multi-user detection in orthogonal frequency-division multiplexing (OFDM)-based systems. This methodology is particularly useful for OFDM-based 4G/5G systems as it provides a solution for higher-order MIMO detection problems.\n\nEP is an iterative algorithm that was originally used in graphical model inference but has more recently been applied to MIMO detection. It is a popular method due to its near-optimal performance when run for a large number of iterations. However, the number of iterations is a key hyperparameter that can significantly impact the algorithm's performance.\n\nIn the context of `MMSEPICDetector`, this function requires an output configuration and resource grid as input, i.e., instances of the `StreamManagement` and `ResourceGrid` classes. The resource grid contains the time and frequency structure of the data transmitted.\n\nThe function produces different outputs depending on the demapping method configured. If the demapping method is set to \"app\", which refers to approximate demapping, then the function will return log-likelihood ratios (LLRs) on the transmitted bits for each stream, much like a `Demapper` function in more traditional data communication setups.\n\nIf the demapping method is set to \"maxlog\", short for maximum-log, the function will return hard-decisions on the transmitted constellation symbols for each stream. Deciding on the symbols is helpful when the detector is used in practice to re-align with the transmitter's data.\n\nThe number of iterations for the `MMSEPICDetector` can be configured through the `num_iter` parameter. More iterations generally lead to better performance, at the cost of increased computational complexity.\n\nIt is essential to select the optimal demapping method and number of iterations based on the specific requirements of the communication system, including the modulation scheme, MIMO complexity, and the quality of channel state information (CSI). Making the wrong choices could lead to suboptimal performance."
"Here is the definition of RaisedCosineFilter: sionna.signal.RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/signal/filter.html#RaisedCosineFilter)\n\nsource code:\n```python\nclass RaisedCosineFilter(Filter):\n    # pylint: disable=line-too-long\n    r\"\"\"RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n\n    Layer for applying a raised cosine filter of ``length`` K\n    to an input ``x`` of length N.\n\n    The length of the filter K is computed from the other provided parameters\n    which fully define the filter.\n\n    The filter can be either non-white (``window`` is not \"rect\") or discrete\n    (``samples_per_symbol`` = 1).\n\n    The filter is applied through discrete convolution.\n\n    An optional forward window can be applied to the filter.\n\n    The `dtype` of the output is `tf.float` if both ``x`` and the filter coefficients have dtype tf.float.\n    Otherwise, the dtype of the output is `tf.complex`.\n\n    Parameters\n    ----------\n    span_in_symbols: int\n        Number of symbols the filter spans.\n\n    samples_per_symbol: int\n        Number of samples per symbol, i.e., the oversampling factor.\n\n    beta : float\n        Roll-off factor.\n        Must be in the range :math:`[0,1]`.\n\n    window: Window or string ([\"hann\", \"hamming\"])\n        Instance of :class:`~sionna.signal.Window` that is applied to the filter coefficients.\n        Alternatively, the string `\"hann\"` or `\"hamming\"` can be given which will create a corresponding window instance.\n        Custom windows must be provided as instance.\n\n    normalize: bool\n        If `True`, the filter is normalized to have unit power.\n        Defaults to `True`.\n\n    trainable: bool\n        If `True`, the filter coefficients are trainable variables.\n        Defaults to `False`.\n\n    dtype: tf.DType\n        The `dtype` of the filter coefficients.\n        Defaults to `tf.float32`.\n\n    Input\n    -----\n    x : [..., N], tf.complex or tf.float\n        The input to which the filter is applied.\n        The filter is applied along the last dimension.\n\n    Output\n    ------\n    y : [...,N, L], tf.complex or tf.float\n        Filtered input.\n        The filter is applied along the last dimension.\n        The length of the last dimension is either equal to N (no window applied) or to L.\n    \"\"\"\n    def __init__(self,\n                 span_in_symbols,\n                 samples_per_symbol,\n                 beta,\n                 window=None,\n                 normalize=True,\n                 trainable=False,\n                 dtype=tf.float32,\n                 **kwargs):\n\n        assert 0 <= beta <= 1, \"beta must be from the intervall [0,1]\"\n        self._beta = beta\n\n        super().__init__(span_in_symbols,\n                         samples_per_symbol,\n                         window=window,\n                         normalize=normalize,\n                         trainable=trainable,\n                         dtype=dtype,\n                         **kwargs)\n\n    @property\n    def beta(self):\n        \"\"\"Roll-off factor\"\"\"\n        return self._beta\n\n    @property\n    def _coefficients_source(self):\n        h = raised_cosine(self.sampling_times,\n                           1.0,\n                           self.beta,\n                           window=self.window)\n        h = tf.constant(h, self.dtype)\n        return h\n```"
"The PAM2QAM class in Sionna's mapping module is used to transform PAM (or NRZ) symbol indices or logits into QAM (or binary modulated) symbol indices or logits. This is particularly useful in digital communication systems where the modulation type is changing between signals.\n\nThe PAM2QAM class requires two inputs:\n\n- num_bits_per_symbol: The number of bits per QAM constellation symbol, often designated as M for QAM-M.\n- hard_in_out: A boolean value that indicates if the inputs are hard or soft values. The default value for this parameter is True.\n\nThe two input tensors, pam1 and pam2, can be either logits or indices of the first and second PAM constellations, respectively. The output is a tensor of the same dtype and shape as the inputs, and it contains the logits or indices for the corresponding QAM constellation.\n\nIt's important to note that this class performs a literal conversion of PAM symbol indices or logits into QAM symbol indices or logits, respectively, and, therefore, requires that the values of the PAM constellation are compatible with the specification of the class."
"To configure `StreamManagement` for a simple uplink scenario using Python code, you need to define the variables `num_tx`, `num_rx`, `num_streams_per_tx`, and the array `rx_tx_association`. Here is how you can do it:\n\n```python\nnum_tx = 4\nnum_rx = 1\nnum_streams_per_tx = 1\n# Indicate which transmitter is associated with which receiver\n# rx_tx_association[i,j] = 1 means that receiver i gets one\n# or mutiple streams from transmitter j.\nrx_tx_association = np.zeros([num_rx, num_tx])\nrx_tx_association[0,0] = 1\nrx_tx_association[0,1] = 1\nrx_tx_association[0,2] = 1\nrx_tx_association[0,3] = 1\nsm = StreamManagement(rx_tx_association, num_streams_per_tx)\n```\n\nIn this code, `num_tx` represents the number of transmitters (in this case, 4), `num_rx` represents the number of receivers (which is 1), and `num_streams_per_tx` represents the number of streams per transmitter (which is 1). The `rx_tx_association` array is used to indicate which transmitter is associated with which receiver. For example, `rx_tx_association[0,0] = 1` means that receiver 0 is associated with transmitter 0. \n\nPlease note that the actual configuration may vary depending on the specific requirements of your scenario."
"```python\nfrom sionna.mapping import Constellation, Mapper, Demapper\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\n```\n\n2. Define the number of bits per symbol for the constellations:\n\n```python\nNUM_BITS_PER_SYMBOL_QPSK = 2\nNUM_BITS_PER_SYMBOL_16QAM = 4\n```\n\n3. Create the QPSK constellation and visualize it:\n\n```python\nconstellation_qpsk = Constellation(\"qam\", NUM_BITS_PER_SYMBOL_QPSK)\nconstellation_qpsk.show()\n```\n\n4. Create the 16-QAM constellation and visualize it:\n\n```python\nconstellation_16qam = Constellation(\"qam\", NUM_BITS_PER_SYMBOL_16QAM)\nconstellation_16qam.show()\n```\n\n5. Generate some random QPSK symbols and map them to their positions on the constellation:\n\n```python\nbatch_size = 128\nqpsk_symbols = np.random.choice([1,1j,-1,-1j], replace=True, size=(batch_size, NUM_BITS_PER_SYMBOL_QPSK), dtype=np.complex64)\n_ = Mapper(constellation=constellation_qpsk)(qpsk_symbols)\n```\n\n6. Generate some random 16-QAM symbols and map them to their positions on the constellation:\n\n```python\n16qam_symbols = np.random.choice([1,1j,-1,-1j], replace=True, size=(batch_size, NUM_BITS_PER_SYMBOL_16QAM), dtype=np.complex64)\n_ = Mapper(constellation=constellation_16qam)(16qam_symbols)\n```\n\n7. To visualize the symbol's indices, use the `show` method of the `constellation` object:\n\n```python\nconstellation_qpsk.show(indices=np.arange(16))\nconstellation_16qam.show(indices=np.arange(64))\n```\n\nThe above code will generate visualizations of the QPSK and 16-QAM constellations and display the symbol's indices."
"The PAM function in Sionna mapping is used to generate a Constellation for an M-ary PAM sequence. This constellation is a real-valued vector, in which the bit label of the `n`-th point is represented by the length of `num_bits_per_symbol` binary representation of `n`. \n\nThe output of the PAM function is a result of the recursive implementation algorithm, which is designed to create a symmetry-inducing recursive expansion of constellations. This is utilized to generate the 5G standard constellation, which is an important part of 5G NR simulations.\n\nAdditionally, the normalization factor of a PAM constellation is explained in the note provided for the function. It is essential because constellation normalization ensures that the constellation has unit power, which is a key requirement in most digital communication mappings."
"When using the \"List2LLR\" class within the Sionna package, the following assumptions must be fulfilled:\n\n1. **Channel Model Assumption**: This class assumes the channel model to be a specific type of MIMO channel, as described in the context provided. It assumes the receipt of an MIMO signal containing information about the channel state.\n\n2. **Input Tuple**: The inputs to the \"List2LLR\" class should be provided as a tuple. However, not all of the provided inputs need to be used for the computation. \n\n    - `y`: Channel outputs (`tf.complex` or `tf.float`) \u2013 This is the output of the whitened channel, providing information about the current channel state.\n    - `r`: Upper triangular channel matrix (`same dtype as y`) \u2013 This matrix is part of the whitened channel model and is used to convert the channel outputs into LLRs.\n    - `dists`: Distance metric for each path (`tf.float`) \u2013 The distance metric is calculated for each path or candidate based on the received and known channel conditions.\n    - `path_inds`: Symbol indices for every stream of every path (`tf.int32`) \u2013 These are the symbol indices that accompany each path or candidate.\n    - `path_syms`: Constellation symbol for every stream of every path (`same dtype as y`) \u2013 This is the constellation symbol for each path or candidate.\n\n3. **Type of Input**: The input to \"List2LLR\" is a tuple, as previously mentioned, and each element within the tuple should have the specified data type.\n\n4. **Output Assumption**: The output of the \"List2LLR\" class is an array that contains LLRs for all bits of every stream. This output is typically used for further processing or analysis of the received signals and channel conditions.\n\n5. **Validation**: The \"List2LLR\" class does not explicitly validate the input types or values. Therefore, it is important to ensure that the input data and parameters comply with the requirements of the class.\n\nPlease note that the specific implementation of the \"List2LLR\" class is not provided within the context. The detailed implementation may vary depending on the specific use case or the complete source code of the class."
"The `MMSEPICDetector` class is used to implement the MIMO MMSE PIC (soft-symbol) detection for OFDM waveform simulations. This detection algorithm is based on phase rotation and parallel interference cancellation (PIC), and is considered particularly effective for simulations with a small number of transmitter antennas (low-K regime). It's designed to work with the OFDM and stream configuration provided by the `ResourceGrid` and `StreamManagement` classes in the Sionna package.\n\nKey parameters of the `MMSEPICDetector` class include:\n\n- `output`: A string that specifies the type of output, either 'bit' for bits or 'symbol' for symbols.\n- `resource_grid`: An instance of the `ResourceGrid` class that defines the OFDM and stream configuration.\n- `stream_management`: An instance of the `StreamManagement` class that manages data streams.\n- `demapping_method`: A string that specifies the demapping method used.\n- `num_iter`: The number of MMSE PIC iterations to perform.\n- `constellation_type`: For custom constellations, the constellation object must be provided. It's a string that can be one of 'qam', 'pam', or 'custom'.\n- `num_bits_per_symbol`: The number of bits per constellation symbol, necessary for 'qam' and 'pam' types.\n- `constellation`: An instance of the `Constellation` class or `None`. If 'custom', the constellation object must be provided.\n- `hard_out`: If True, computes hard-decided values instead of soft values. \n- `dtype`: Specifies the datatype for internal calculations and the output dtype.\n\nInput for the `MMSEPICDetector` class is a tuple `(y, h_hat, prior, err_var, no)` where:\n- `y` is the received signal.\n- `h_hat` is the channel estimation.\n- `prior` is the prior of the transmitted signals, necessary for 'bit' output.\n- `err_var` is the variance of the channel estimation error.\n- `no` is the variance of the AWGN.\n\nThe output of `MMSEPICDetector` is a tensor of LLRs or hard-decisions for every bit of every stream, depending on the `output` parameter.\n\nThe `MMSEPICDetector` is part of the Sionna package and its functionality is affected by package and global variables such as `xla_compat`."
"The QAM2PAM class is not found in the provided context. Therefore, I can't define this class directly from the context. \n\nAs per the given context, the QAM2PAM class is expected to take an input consisting of the indices of the points in the QAM constellation and return the indices for the corresponding PAM constellation. However, the specific implementation details of the QAM2PAM class are not provided in the context. Thus, I can't explain how it transforms QAM symbol indices to PAM symbol indices based on the given context."
"To verify that the generator matrix and parity-check matrix are orthogonal in GF(2) with the Sionna package, you can use the function `verify_gm_pcm` from the package module `sionna.fec.utils`. This function takes two arguments, `gm` for the generator matrix and `pcm` for the parity-check matrix, and it will raise an `AssertionError` if the matrices are not orthogonal in GF(2). \n\nHere is step-by-step process to do this:\n\n1. First, you need to import the `verify_gm_pcm` function from the `sionna.fec.utils` module.\n```python\nfrom sionna.fec.utils import verify_gm_pcm\n```\n\n2. The generator matrix (gm) and parity-check matrix (pcm) should be loaded or defined. The `sniff` function from the `sionna.fec.utils` module can be used to load example matrices (either predefined or custom matrices):\n```python\nfrom sionna.fec.utils import sniff\n# Load example matrices\ngm, pcm = sniff(\"5g/nr/ldpc\", \"100.0\") # You can also load your own matrices\n```\n\n3. Call the `verify_gm_pcm` function with the generator and parity-check matrices. If the matrices are not orthogonal in GF(2), an `AssertionError` will be raised. Otherwise, the function will return without error.\n```python\nverify_gm_pcm(gm, pcm)\n```\n\nThis function is based on the properties of the generator and parity-check matrices when they are orthogonal in GF(2). It is a commonly used property to ensure that the matrices are independent and can be used for decoding without ambiguity.\n\nPlease note that the `AssertionError` being raised by the function is used for matrix validation and should not be catched as it might indicate that the matrices are not suitable for decoding. Also, if you load your own matrices, you should verify that they conform to the required conditions (e.g., binary matrices of the appropriate dimensions) or use error-correcting code procedures to detect and correct any issues with the matrices."
"Here is how you do it:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n\n# Assuming you have already created an instance pcm_mat of a ParityCheckMatrix:\n#\n#         [[1, 0, 0, 0, 0],\n#          [0, 1, 0, 0, 0],\n#          [0, 0, 1, 0, 0],\n#          [0, 0, 0, 1, 1]]\n#\n\n# Create an instance of LinearEncoder\nencoder = LinearEncoder(enc_mat, is_pcm=True, dtype=tf.float32)\n\n# Now you can use encoder to encode messages\n# Assuming 'u' is your tensor of information bits with shape [..., k]:\n# c = encoder(u)\n# where c is the tensor of codewords.\n# If you don't know what a tensor is, u should be a numpy array or a list.\n```\n\nMake sure you replace `enc_mat` with your actual parity-check matrix. The `is_pcm` flag indicates that the matrix being passed is a parity-check matrix, not a generator matrix."
"The `OFDMDetectorWithPrior` class is a layer that incorporates MIMO detectors assuming prior knowledge of bits or constellation points into OFDM (Orthogonal Frequency-Division Multiplexing) systems. It works in conjunction with other components of the Sionna package like `ResourceGrid` and `StreamManagement` to detect symbols transmitted during OFDM modulation.\n\nIn more detail, the `OFDMDetectorWithPrior` takes as input a callable MIMO detector (like `MaximumLikelihoodDetectorWithPrior` which assumes prior knowledge of the transmitted data). The detector is a callable object (like a function) that implements a MIMO detection algorithm with prior for arbitrary batch dimensions. This could be used to implement maximum likelihood (ML) or another suitable detection algorithm.\n\nThe `OFDMDetectorWithPrior` then preprocesses the received signal, channel estimates, and prior information, to compute for each receiver the noise-plus-interference covariance matrices according to the OFDM and stream configuration provided, which also accounts for the channel estimation error variance. This information serves as input to the MIMO detection algorithm implemented by the provided `detector`.\n\nThe layer can generate two types of outputs based on the ``output`` parameter: \n\n- If ``output`` is set to `'bit'`, it generates LLRs (log-likelihood ratios) or hard-decisions for every bit of every stream.\n- If ``output`` is set to `'symbol'`, it generates logit or hard-decisions for constellation symbols for every stream. Hard-decisions correspond to the symbol indices.\n\nIt's important to note that while `MaximumLikelihoodDetectorWithPrior` is provided as a detector callable for convenience, a custom detector callable that has the same input/output pattern can also be used. This versatility allows different MIMO detection algorithms to be implemented and used with the same input processing framework.\n\nSince this class is not based on the usual ``Layer`` class of Keras models, it is important to note that it should be used as defined in the source code documentation and not as a component of a more comprehensive model that might include other layers.\n\nOverall, the `OFDMDetectorWithPrior` class provides a way to detect symbols in an OFDM system using a MIMO detection algorithm that assumes prior knowledge of the transmitted data, making it particularly useful in scenarios where information about the transmitted data is available."
"The \"bin2int_tf\" function is used to convert a binary tensor to an integer tensor. The binary tensor should have elements that are either 0 or 1, and these elements are considered as binary digits. The binary representation in the input tensor is decoded from the last dimension to the first, with the most significant bit being the most significant bit of the integer representation.\n\nIn other words, if the input tensor is [0, 1, 1], this function will interpret this as binary representation of the integer 0b011, which is 3 in decimal representation.\n\nThe tensor that is passed to the function should be a binary tensor, i.e., it should have elements of type float with values 0.0 or 1.0. The tensor can have any shape, but the last dimensions will be interpreted as bits of the integer, so the binary representation is effectively flattened when interpreting it.\n\nThe function returns an integer tensor, which has the same shape as the input tensor. The integer represented by the bits in the last dimension of the input tensor is returned."
"The usage of `TB5GScrambler` for enabling 5G NR compliant scrambling is demonstrated in the given context. `TB5GScrambler` is implemented as a subclass of `Scrambler`, so most of the parameters and usage remain the same.\n\nFirst, initialize the `TB5GScrambler` providing the necessary parameters, including the explicit seed if a new random seed should be used for each call:\n\n```python\ns = tf.random.uniform((), minval=0, maxval=12345678, dtype=tf.int32)\nc_scr = scrambler([c, s])\n```\n\nIn this example, `tf.random.uniform((), minval=0, maxval=12345678, dtype=tf.int32)` is used to generate a random seed, which is then passed to the `TB5GScrambler` along with the binary sequence `c`. The `minval` and `maxval` arguments define the range of the random integer seed that is generated. Finally, the scrambling operation is performed, and the scrambled sequence is stored in `c_scr`.\n\nTo descramble the sequence, the same seed must be passed again to the `Descrambler`. This can be done using the following code:\n\n```python\nc_descr = descrambler([c_scr, s])\n```\n\nIn this context, the use of 5G NR compliant scrambling is stated, and it's assumed that `TB5GScrambler` has been set up in a manner consistent with 5G specifications. The `TB5GScrambler` class documentation, which is referenced in the context, provides detailed information about the expected parameters and their significance."
"Here is the detailed information of int_mod_2:   \n\n[sionna.fec.utils.int_mod_2(x)](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#int_mod_2)\n\nEfficient implementation of modulo 2 operation for integer inputs.\n\nThis function assumes integer inputs or implicitly casts to int.\n\nRemark: the function `tf.math.mod(x, 2)` is placed on the CPU and, thus, causes unnecessary memory copies.\n\nParameters\n\n- **x** (`tf.Tensor`) - Tensor to which the modulo 2 operation is applied.\n\nOutput\n\n- `tf.DType` - Tensor with the same shape and dtype as the input tensor `x`, containing the remainder after division by 2.\n\nsource code:\n```python\ndef int_mod_2(x):\n    \"\"\"Efficient implementation of modulo 2 operation for integer inputs.\n\n    This function assumes integer inputs or implicitly casts to int.\n\n    Remark: the function `tf.math.mod(x, 2)` is placed on the CPU and,\n    thus, causes unnecessary memory copies.\n\n    Parameters\n    ----------\n        x : tf.Tensor\n            Tensor to which the modulo 2 operation is applied.\n\n    Output\n    ------\n        : tf.DType\n            Tensor with same shape and dtype as ``x`` containing the\n            remainder after division by 2.\n    \"\"\"\n    imt = type(x) is int\n    if imt:\n        dtype = tf.int32\n        output = x%2\n    else:\n        dtype = x.dtype\n        output = tf.math.mod(x, 2)\n\n    custom_dtype = tf.DType(dtype)\n    output = tf.cast(output, custom_dtype)\n\n    return output\n```"
"Here is the detailed information of sionna.utils.SymbolSource:   \n\n[sionna.utils.SymbolSource(symbol_array, randomize=True, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/utils/misc.html#SymbolSource)\n\nLayer generating a symbol tensor y of shape $\\tensorsize{y}$ from a given symbol array.\n\nThe dtype can be either tf.complex64 or tf.complex128. The dtype property of the output y can be assigned to any dtype with the same as the corresponding real dtype (tf.float32 or tf.float64).\n\nIf randomize is set to True, then the values in symbol_array are randomly shifted by a generated offset such that $\\sum_{n=0}^{N-1} |y_n-\\mu_n|^2$ is minimized, where $y \\in \\mathcal{C}^N$ is the generated symbol tensor, $N$ is the number of OFDM symbols, and $\\mu_n$ the $n^{\\text{th}}$ element of symbol_array. This technique allows to break symmetries in the symbol constellation.\n\n**Parameters**\n\n- `symbol_array` (array-like, shape [num_symbols], dtype=complex): Array defining the constellation symbols.\n- `randomize` (bool): If True, the symbols are randomly shifted during the sampling to break symmetries. Defaults to True.\n- `dtype` (tf.complex): The data type of the output symbols. Defaults to tf.complex64.\n\n**Input**\n\n- `shape` (int): Length of the output vector.\n\n**Output**\n\n- `y` ([..., shape], dtype): Tensor with the drawn symbols.\n\nsource code:\n```python\nclass SymbolSource(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Layer generating a symbol tensor ``y`` of shape :math:`\\tensorsize{y}` from a given ``symbol_array``.\n\n    The ``dtype`` can be either `tf.complex64` or `tf.complex128`.\n    The `dtype` property of the output ``y`` can be assigned to any `dtype` with the same as the corresponding real `dtype` (`tf.float32` or `tf.float64`).\n\n    If ``randomize`` is set to `True`, then the values in ``symbol_array`` are randomly shifted by a generated offset such that\n\n    .. math::\n        \\sum_{n=0}^{N-1} |y_n-\\mu_n|^2\n\n    is minimized, where :math:`y \\in \\mathcal{C}^N` is the generated symbol tensor,\n    :math:`N` is the number of OFDM symbols, and :math:`\\mu_n` the :math:`n^{\\text{th}}` element of ``symbol_array``.\n    This technique allows to break symmetries in the symbol constellation.\n\n    Parameters\n    ----------\n    symbol_array : array-like, shape `[num_symbols]`, `complex`\n        Array defining the constellation symbols.\n\n    randomize : bool\n        If `True`, the symbols are randomly shifted during the sampling to\n        break symmetries. Defaults to `True`.\n\n    dtype : `tf.complex`\n        The dtype of the output symbols.\n        Defaults to `tf.complex64`.\n\n    Input\n    -----\n    shape : int\n        Length of the output vector.\n\n    Output\n    ------\n    y : [...,shape], `dtype`\n        Tensor with the drawn symbols.\n    \"\"\"\n    def __init__(self,\n                 symbol_array,\n                 randomize=True,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        self._num_symbols = symbol_array.shape[0]\n        self._randomize = randomize\n        self._build(symbol_array)\n\n    def _build(self, symbol_array):\n        symbol_array = np.array(symbol_array) # Convert to NumPy array\n        if self._randomize:\n            symbol_array = np.stack([np.real(symbol_array),\n                                      np.imag(symbol_array)], axis=-1)\n            sampled_symbols = random_or_custom_sample(symbol_array,\n                                                      keep_batch_dimension=True)\n            symbol_array = np.comj(sampled_symbols)\n        self._symbol_array = tf.constant(symbol_array, self.dtype)\n\n    def __call__(self, inputs, shape):\n        if tf.as_tensor(shape).shape==[]:\n            shape = tf.cast(shape, tf.int32)\n        else:\n            shape = tf.cast([shape], tf.int32)\n\n        # Add a dummy dimension to make it broadcast with shape\n        symbols = tf.expand_dims(self._symbol_array, -1)\n\n        # Randomly permute the symbols\n        if self._randomize:\n            r = tf.random.uniform((), 0., 2.*np.pi)\n            zeros = tf.zeros([1], tf.as_dtype(symbols.dtype).real_dtype)\n            c = tf.complex(tf.cos(r), tf.sin(r))\n            symbols = symbols*c + zeros\n\n        # Tile the symbol array according to shape\n        output = tf.repeat(symbols, shape, axis=0)\n\n        return output\n```"
"Here is the detailed information of ChannelModel:   \n  \nAbstract class that generates batches of channel impulse responses. Implement this interface to design and generate channel impulse responses for your own channel model.  \n  \nThe source code link of [ChannelModel](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel)  \n  "
"To build a custom `RadioMaterial`, you can use the `RadioMaterial` function and specify the material properties either directly or through a callback function that computes the material properties based on the frequency. The defined material can be then attached to a `SceneObject` and used in scene rendering. \n\nThe first step is to create a `RadioMaterial` instance, providing a unique name for the material and specifying the material properties. In the provided context, a custom material named \"my_material\" is created with the following properties:\n\n- `relative_permittivity` is set to 2.0\n- `conductivity` is set to 5.0\n- `scattering_coefficient` is set to 0.3\n- `xpd_coefficient` is set to 0.1\n- `scattering_pattern` is set to \"LambertianPattern\"\n\n```python\ncustom_material = RadioMaterial(\"my_material\",\n                                relative_permittivity=2.0,\n                                conductivity=5.0,\n                                scattering_coefficient=0.3,\n                                xpd_coefficient=0.1,\n                                scattering_pattern=LambertianPattern())\n```\n\nIn this example, the `RadioMaterial` function is used as a factory to create material instances. The created material is a part of the scene.\n\nTo attach the custom `RadioMaterial` to a `SceneObject`, you need to retrieve the `SceneObject` either by name or by index. Once you have the `SceneObject`, you can set the `radio_material` property of the `SceneObject` to the name of the custom `RadioMaterial`.\n\nUsing the `Scene` instance:\n\n```python\nscene = load_scene() # Load empty scene\nobj = scene.get(\"my_object\") # obj is a SceneObject\nobj.radio_material = \"my_material\" # \"my_object\" is made of \"my_material\"\n```\n\nOr using the `SceneObject` instance:\n\n```python\nobj = scene.get(\"my_object\") # obj is a SceneObject\nobj.radio_material = custom_material # \"my_object\" is made of \"my_material\"\n```\n\nIn the above examples, `\"my_object\"` is a placeholder for the actual `SceneObject` in the scene, and `\"my_material\"` represents the name of the custom `RadioMaterial` to be attached to the `SceneObject`. It's important to note that the `SceneObject` must be part of the current scene, and the material name must be unique (not already used in the scene)."
"For maximum a posteriori (MAP) decoding with a `BCJRDecoder` instance, the possible inputs are `llr_ch` or `(llr_ch, llr_a)`. \n\n1. If `llr_ch` is given as an input to the `BCJRDecoder`, it is an LLR (log-likelihood ratio) representing the channel output. This is essentially a measure of the reliability of the received signal, aiding the decoder in making decisions. The decoder will generate output LLRs, which can be treated as estimates of the original information bits.\n\n2. If `(llr_ch, llr_a)` is given as an input, where `llr_ch` has shape `[..., n]` and `llr_a` has shape `[..., n, num_states]`, `llr_ch` is as previously described, but `llr_a` introduces state logit coefficients for each possible codeword candidate, in a way that is independent of the channel. This is useful for implementing MAP decoding assuming a sparse parity-check matrix without knowledge of the channel transition probabilities.\n\nThe `hard_out` parameter indicates whether to generate hard or soft-decision values. A hard-decision is a finalized estimation for each bit value, represented as a binary 0 or 1. On the other hand, a soft-decision is a continuous value, typically an LLR, which can provide more nuanced information about the estimated bit value.\n\nThe `BCJRDecoder` outputs are two values:\n\n- If `hard_out=True`, the output is a hard-decision estimate for the codeword bits. The shape of this output is `[..., n]`, indicating that for each batch example, the decoder provides an estimation of the codeword bits.\n\n- If `hard_out=False`, the output is a soft-decision estimate for the codeword bits. The shape of this output is `[..., n, 2]`, indicating that for each batch example, the decoder provides an estimation of the codeword bits as an LLR. The extra dimension of size 2 corresponds to the two possible values of a binary variable, 0 or 1.\n\nThe tensors `llr_ch`, `llr_a`, `hard_out`, and the output of the decoder can all be either `tf.float32` or `tf.float64` depending on the chosen datatype for the decoding and the input data. It is important to ensure that the datatype of the inputs is compatible with the requirements of the `BCJRDecoder`, and the choice of `hard_out` is matched to the desired output format."
"To use the `sionna.utils.ebnodb2no` function, you can follow these steps:\n\n1. Import the function from the module:\n\n```python\nfrom sionna.utils import ebnodb2no\n```\n\n2. Call the function with the required arguments:\n\n```python\nebno = 10  # desired Eb/No in dB\nnum_bits_per_symbol = 4  # number of bits per symbol\ncoderate = 1  # coderate is 1, indicating full rate here\nresource_grid = None  # only needed for OFDM transmissions\n```\n\nIn this example, `ebno` is the desired Eb/No (energy per bit to noise power spectral density ratio) in dB. The next three arguments are all integers and represent the `num_bits_per_symbol` (number of bits per constellation symbol), `coderate`, and an optional `resource_grid` (in case of OFDM transmissions). You would set `resource_grid` to a valid instance of `ResourceGrid` that corresponds to your specific setup.\n\nThe function will return the equivalent noise power spectral density, `N_o`, in linear scale. This value is used to represent the noise in a communication system and is the power per unit bandwidth that a noise source delivers at an output terminal."
"To evaluate the baseline and two autoencoder-based communication systems, a specific `SimSBER` function is defined which performs the following steps:\n\n1. It generates a given batch size of random SNRs and processes this batch through the considered models: the baseline model and the autoencoder-based models. \n2. The function then quantifies the Block Error Rate (BLER) for each model across these SNRs, returning BLER as a list of floats. \n3. The BLER serves as the performance metric, representing the proportion of block transmissions that failed to be properly received and decoded.\n\nThe BLER is calculated by dividing the number of erroneous block receptions (measured after decoding) by the total number of block receptions, with errorfully decoding as the criterion for failure.\n\nBy running this function with different batch sizes and SNR ranges, the performance of the different models can be systematically compared against each other. \n\nPlease note that the context provides predefined functions such as `SimSBER` which cannot be directly used as they are not provided with the necessary context. The description provided is based on general knowledge about evaluating models and specifically on the use of BLER as a performance metric."
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can use the `tensorflow` library. First, you need to list the available GPUs using `tf.config.list_physical_devices('GPU')`. If a GPU is available, you can set the environment variable `CUDA_VISIBLE_DEVICES` to the index of the GPU you want to use, e.g., `gpu_num = 0`. Next, you can set the TensorFlow global logger level to 'ERROR' to avoid warnings from TensorFlow using `tf.get_logger().setLevel('ERROR')`.\n\nTo allocate only as much memory as needed, you can list the physical devices using `tf.config.list_physical_devices('GPU')`, and then iterate over the devices to set the memory growth of each GPU device to True using `tf.config.experimental.set_memory_growth(gpu, True)`. This command attempts to allocate only as much GPU memory as needed for the runtime allocations: it starts out allocating very little memory, and as the program gets run and more GPU memory is needed, TensorFlow extends the GPU memory region allocated to the TensorFlow process."
"To use the \"j_fun\" function to calculate the J-function in the Sionna package, you can follow these steps:\n\n1. First, you need to import the function from the package:\n\n```python\nfrom sionna.fec.utils import j_fun\n```\n\n2. Next, you need to provide the function with the value of 'mu'. This is the mean value of the LLR distribution. The package notes that this value could be a single float or an <cite>ndarray</cite> of floats:\n\n```python\nmu = 1.05  # example mean value\n```\n\n3. Finally, you can call the \"j_fun\" function with the value of 'mu'. The function will return the J-function value:\n\n```python\nj_function = j_fun(mu)\n```\n\nThis will calculate the J-function for the mean value of the LLR distribution. The result will be a float if the input 'mu' is a single float, or an <cite>ndarray</cite> of the same shape as the input if 'mu' is an <cite>ndarray</cite> of floats."
"Here is the definition of PUSCHTransmitter: sionna.nr.PUSCHTransmitter(pusch_configs, return_bits=True, output_domain='freq', dtype=tf.complex64, verbose=False, **kwargs). And the source code is by [PUSCHTransmitter](https://nvlabs.github.io/sionna/_modules/sionna/nr/pusch_transmitter.html#PUSCHTransmitter).  \n  \n  Returning to the previous example, we assume that the transmitter is configured with the following parameters:\n\n- A single PUSCH configuration created with default settings, i.e., standards-compliant values.\n\nWe can now instantiate a PUSCHTransmitter as follows:\n\n```python\n# Remember that configuration is a list of PUSCHConfig objects\npusch_config = PUSCHConfig()\npusch_transmitter = PUSCHTransmitter(pusch_config)\n```\n\nOr multiple configurations at once:\n\n```python\n# Create several identical PUSCH configurations\npusch_config = PUSCHConfig()\npusch_configs = [pusch_config, pusch_config]\npusch_transmitter = PUSCHTransmitter(pusch_configs)\n```\n\nThe PUSCHTransmitter can be used to simulate the behavior of multiple transmitters. In this case, a list of valid PUSCH configurations needs to be provided.\n\n**Parameters**\n\n- `pusch_configs` (instance or list of `PUSCHConfig`): Specifies the PUSCH configurations to be used for generating the transmissions. One configuration is required for each transmitter.\n\n- `return_bits` (bool): If set to `True`, the transmitter generates random information bits to be transmitted and returns them along with the transmit signal. Defaults to `True`.\n\n- `output_domain` (str, one of [\"freq\", \"time\"]): Determines the domain of the output signal. If set to \"freq\", the signal is in the frequency domain; otherwise, it is in the time domain. Defaults to \"freq\".\n\n- `dtype` (One of [tf.complex64, tf.complex128]): Specifies the data type of the inputs and outputs. Defaults to tf.complex64.\n\n- `verbose` (bool): If set to `True`, the parameters of the transmitter are printed during instantiation. Defaults to `False`.\n\n**Input**\n\nThe inputs depend on whether `return_bits` is set to `True` or `False`.\n\n- If `return_bits` is `True`, the input is simply the batch size:\n\n```python\nbatch_size = 16\nx, b = pusch_transmitter(batch_size)\n```\n\n- If `return_bits` is `False`, the input is the tensor of information bits to be transmitted. The tensor must have shape `[..., batch_size, num_tx, tb_size]`. For simulating the transmitter, a random tensor of information bits is typically generated using `tf.random.uniform`:\n\n```python\nbatch_size = 16\nnum_tx = 1\ntb_size = 1e4 # assuming there are 10,000 information bits\nb = tf.random.uniform((batch_size, num_tx, tb_size), 0, 2, tf.int32)\nx = pusch_transmitter(b)\n```\n\n**Output**\n\n- `x` (Tensor, tf.complex): The transmit signal in the specified domain.\n\n- `b` (Tensor, tf.float): The information bits that were transmitted. This output is only provided if `return_bits` is `True`.\n\n**Domain Selection**\n\nThe PUSCHTransmitter can generate transmissions in the time or frequency domain. Which domain is used can be specified by setting the `output_domain` parameter to `\"time\"` or `\"freq\"`. Time-domain outputs are generated using the `OFDMModulator` and `Demodulator`, while `freq`-domain outputs are generated using the `SmithPUSCHTransmitter` and `Receiver`.\n\n**Further Settings**\n\nThe PUSCHConfig object, and hence all other objects related to PUSCH transmissions, can be configured with many other settings. Most methods and classes have additional parameters that can be provided to offer flexibility in simulating different scenarios."
"  \nsource code: verify_gm_pcm  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#verify_gm_pcm)  \nsource code:  \n```python\ndef verify_gm_pcm(gm, pcm):\n    \"\"\"Verify that generator matrix ``gm`` and parity-check matrix ``pcm``\n    are orthogonal in GF(2).\n\n    For an all-zero syndrome, it must hold that\n\n    .. \n\n        \\mathbf{H} \\mathbf{c}^t = \\mathbf{H} * (\\mathbf{u} * \\mathbf{G})^t =\n        \\mathbf{H} * \\mathbf{G} ^t * \\mathbf{u}^t =: \\mathbf{0}\n\n    where :math:`\\mathbf{c}` denotes an arbitrary codeword and\n    :math:`\\mathbf{u}` the corresponding information bits.\n\n    As :math:`\\mathbf{u}` can be arbitrary it follows that\n\n    ..  math::\n\n        \\mathbf{H} * \\mathbf{G} ^t =: \\mathbf{0}.\n\n    Input\n    -----\n    gm : ndarray\n        Binary generator matrix of shape `[k, n]`.\n\n    pcm : ndarray\n        Binary parity-check matrix of shape `[n-k, n]`.\n\n    Output\n    ------\n    : bool\n        `True` if ``gm`` and ``pcm`` define a valid pair of\n        parity-check and generator matrices in GF(2).\n        Otherwise, `False`.\n    \"\"\"\n\n    assert gm.shape[0]<gm.shape[1], \"``gm`` is not in the (k, n) format.\"\n    assert pcm.shape[0]==gm.shape[1], \"``pcm`` has an invalid shape.\"\n    assert ndmin(gm)==2, \"``gm`` must be a 2-D matrix.\"\n    assert ndmin(pcm)==2, \"``pcm`` must be a 2-D matrix.\"\n\n    n = gm.shape[1]\n\n    # The GF(2) version of the invect_affine function\n    with tf.device(gm.device):\n        aff_mat = tf.cast(invect_affine(2, n), dtype=gm.dtype)\n\n    gm_aff = tf.matmul(aff_mat, gm)\n    pcm_aff = tf.matmul(aff_mat, pcm)\n\n    # Swaps checking for 0 and 1 to get the H <-> G relationship\n    zero_mat = tf.zeros([n, n], dtype=gm.dtype)\n    one_mat = tf.ones([n, n], dtype=gm.dtype)\n    assert tf.reduce_all(tf.equal(one_mat, tf.abs(tf.matmul(pcm_aff, gm_aff))),\n        zero_mat), \"Generator matrix and parity-check matrix are not orthogonal.\"\n```\n  "
"The permittivity is a measure of the ability of a material to store electrical energy in an electric field. It is defined as the constant of proportionality between electric displacement and the applied electric field. In an isotropic medium, this is given by the following equation:\n\n$$\n\\varepsilon = \\varepsilon_0 \\varepsilon_r\n$$\n\nwhere $\\varepsilon_0$ is the vacuum permittivity and $\\varepsilon_r$ is the relative permittivity of the medium. For non-conducting materials, $\\varepsilon_r$ is a real number greater than or equal to 1, and for conducting materials, it is a complex number with real and imaginary parts. The imaginary part is related to the loss factor of the material.\n\nThe permeability is a measure of the ability of a material to support magnetic fields. Similar to permittivity, it is a constant of proportionality in the context of magnetization of a material. In an isotropic medium, it is defined as:\n\n$$\n\\mu = \\mu_0 \\mu_r\n$$\n\nwhere $\\mu_0$ is the vacuum permeability and $\\mu_r$ is the relative permeability of the medium. Just like relative permittivity, relative permeability is a real number greater than or equal to 1 for non-conducting materials and a complex number with a real part and an imaginary part for conducting materials. The imaginary part again corresponds to the loss factor of the material.\n\nIn the given context, the permittivity and permeability are defined through equations (9) and (10), respectively. These equations are standard in electromagnetism and define the complex relative permittivity and permeability of a material. The real parts of these complex numbers correspond to the definitions provided earlier, and the imaginary parts correspond to the loss factors."
"Here is the detailed information of RemoveNulledSubcarriers:   \n  \n[sionna.ofdm.RemoveNulledSubcarriers(resource_grid, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/resource_grid.html#RemoveNulledSubcarriers)  \n\nRemoveNulledSubcarriers(resource_grid, **kwargs)\n\nThis layer takes as input an OFDM ResourceGrid and removes any nulled subcarriers from it. Nulled subcarriers are nulled after FFT processing and are not transmitted. From a mathematical point of view, removing nulled subcarriers is equivalent to setting the corresponding DFT coefficients to zero.\n\nThe primary use case of this layer is simulations and experiments where the measurement of PAPR or the effect of compression are studied. Although the removal of nulled subcarriers is not mandatory in itself, it enables a fairer comparison between different OFDM systems as otherwise the PAPR could be significantly influenced by the presence of nulled subcarriers.\n\nParameters\n\n  \u2022 `resource_grid` (ResourceGrid): An instance of ResourceGrid.\n\nInput\n\n[batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size, data_dim]: An instance of tf.complex with arbitrary batch dimensions. The last three dimensions correspond to the num_ofdm_symbols, fft_size, and data_dim, respectively.\n\nOutput\n\n\u2022 `y` ([batch size, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers, data_dim]): The same as the input, but with the nulled subcarriers removed. The actual tensor is tf.complex, and represents the OFDM resource grid after the nulled subcarriers are removed."
"Here is the definition of LLRs2SymbolLogits: sionna.mapping.LLRs2SymbolLogits(num_bits_per_symbol, hard_out=False, dtype=tf.float32, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#LLRs2SymbolLogits)  \n\nsource code:\n```python\nclass LLRs2SymbolLogits(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"LLRs2SymbolLogits(num_bits_per_symbol, hard_out=False, dtype=tf.float32, **kwargs)\n\n    Computes logits (i.e., unnormalized log-probabilities) or hard decisions\n    on constellation points from a tensor of log-likelihood ratios (LLRs)\n    on bits.\n\n    Parameters\n    ----------\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n\n    hard_out : bool\n        If `True`, the layer provides hard-decided constellation points\n        instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.float32, tf.float64] tf.DType (dtype)\n        The dtype for the input and output.\n        Defaults to `tf.float32`.\n\n    Input\n    -----\n    llrs : [...,n, num_bits_per_symbol], tf.float\n        LLRs for every bit.\n\n    Output\n    ------\n    : [...,n, num_points], tf.float or [...,n], tf.int\n        Logits or hard-decisions on constellation points.\n        If `hard_out` is `True`, the hard-decisions are computed and `dtype`\n        is `tf.float32`, the hard-decisions are returned as `tf.int32`.\n\n    Note\n    ----\n    The logit for the constellation :math:`c` point\n    is computed according to\n\n    .. math::\n        \\log{\\left(\\Pr\\left(c\\lvert LLRs \\right)\\right)}\n            &= \\log{\\left(\\prod_{k=0}^{K-1} \\Pr\\left(b_k = \\ell(c)_k \\lvert LLRs \\right)\\right)}\\\\\n            &= \\log{\\left(\\prod_{k=0}^{K-1} \\text{sigmoid}\\left(LLR(k) \\ell(c)_k\\right)\\right)}\\\\\n            &= \\sum_{k=0}^{K-1} \\log{\\left(\\text{sigmoid}\\left(LLR(k) \\ell(c)_k\\right)\\right)}\n\n    where :math:`\\ell(c)_k` is the :math:`k^{th}` bit label of :math:`c`, where\n    0 is replaced by -1.\n    The definition of the LLR has been\n    chosen such that it is equivalent with that of logits.\n    This is different from many textbooks in communications, where the LLR is\n    defined as\n    :math:`LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)`.\n\n    \"\"\"\n    def __init__(self, num_bits_per_symbol, hard_out=False,\n                 dtype=tf.float32, **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        self._num_bits_per_symbol = num_bits_per_symbol\n        self._hard_out = hard_out\n        self._pnt2symbol_ind = tf.constant(\n            points2symbol(num_bits_per_symbol, return_indices=True),\n            dtype=tf.int32)\n\n    def call(self, llrs):\n        # llrs : [...,n, num_bits_per_symbol], tf.float\n        if llrs.shape[-1] != self._num_bits_per_symbol:\n            raise ValueError(\"Last dimension must equal num_bits_per_symbol.\")\n\n        # Generate symbol logits : [...,n, num_points,], tf.float\n        y = llrs\n        if y.shape[:-1] != self._num_bits_per_symbol:\n            y = tf.broadcast_to(y, [tf.rank(y)-1, 1])\n        y = tf.reduce_sum(\n            tf.math.log_sigmoid(y*self._pnt2symbol_ind), axis=-1)\n\n        # Get rid of broadcasted last dimension\n        y = tf.squeeze(y, axis=-1)\n\n        if self._hard_out:\n            # Generate hard-decisions on symbols : [...,n,]\n            symbol_indices = tf.argmax(y, axis=-1, output_type=tf.int32)\n            symbol_indices = tf.gather(self._pnt2symbol_ind, symbol_indices,\n                                        axis=-1, batch_dims=1)\n            return symbol_indices\n        else:\n            return y\n```"
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can follow these steps:\n\n1. Set the GPU number: You can set the GPU number using the `gpu_num` variable. If you want to use the CPU, you can set `gpu_num` to an empty string (\"\"). For example, if you want to use the first GPU, you can set `gpu_num` to 0.\n\n2. Set the `CUDA_VISIBLE_DEVICES` environment variable: You can set the `CUDA_VISIBLE_DEVICES` environment variable to the GPU number. This variable controls which GPUs will be visible to CUDA applications when they are run. For example, if you want to use the first GPU, you can set `os.environ(\"CUDA_VISIBLE_DEVICES\", str(gpu_num))`.\n\n3. Set the `TF_CPP_MIN_LOG_LEVEL` environment variable: You can set the `TF_CPP_MIN_LOG_LEVEL` environment variable to '3'. This variable controls the TensorFlow C++ log level.\n\n4. List the physical devices: You can use the `tf.config.list_physical_devices` function to get the list of all available physical devices. If there are GPUs available, you can use `tf.config.list_physical_devices('GPU')` to get the list of all available GPUs.\n\n5. Set the memory growth: You can use the `tf.config.experimental.set_memory_growth` function to enable memory growth for the selected GPU. This function will dynamically allocate only as much GPU memory as needed for the runtime allocations.\n\n6. Set the TensorFlow logger level: You can use the `tf.get_logger().setLevel('ERROR')` function to set the TensorFlow logger level to 'ERROR'. This will reduce the logging level from 'INFO' (default) to 'ERROR'.\n\nPlease note that these steps assume that you are using TensorFlow and Sionna. If you are using a different library, the steps may be slightly different."
"To compute codeword bits from information bits using the `LinearEncoder`, you would initialize the `LinearEncoder` with either the generator matrix or the parity-check matrix. As per the provided context, an instance of `LinearEncoder` is created and used to encode the information bits `u`, resulting in the computed codeword bits `c`.\n\nHere is a demonstration of how to compute the codeword bits using the `LinearEncoder`:\n\n1. Import the appropriate package and classes:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\nimport tensorflow as tf\n# Optional - define a binary tensor 'u' of information bits\n# Here, we assume 'u' is a tensor of random binary values with shape [..., k]\nu = tf.random.uniform(shape=[[..., 10], dtype=tf.int8)  # k is the number of information bits\n```\n\n2. Initialize the `LinearEncoder` with the parity-check or generator matrix:\n\n```python\n# Assuming 'pcm' is a previously defined parity-check matrix (either random or from a real application)\nencoder = LinearEncoder(enc_mat=pcm, is_pcm=True)\n```\n\n3. Encode the information bits `u` using the `LinearEncoder`:\n\n```python\n# Compute the codeword bits 'c' from the information bits 'u'\nc = encoder(u)\n```\n\n4. Verify the results:\n\n```python\n# Print the shape of 'c' to confirm that it has the expected shape [..., n]\nprint(\"Shape of c:\", c.shape)\n```\n\nMake sure that the parity-check or generator matrix you provide to `LinearEncoder` is a valid binary matrix of full rank. The details of the matrix shape determine the exact codes that this encoder can implement, so be sure to have the correct matrix for the code you wish to encode."
"Here is the detailed information of sionna.utils.flatten_last_dims:  \n\n[sionna.utils.flatten_last_dims(x, n)](https://nvlabs.github.io/sionna/_modules/sionna/utils/tensors.html#flatten_last_dims)\n\nFlattens the last n dimensions of a tensor.\n\nThis operation flattens the last n dimensions of a tensor. All dimensions beyond the last n are not modified.\n\n### Parameters\n\n- `x` ([..., D_0, D_1, ..., D_{n-1} , D_n], tf.DType): The input tensor.\n- `n` (int): The number of dimensions to combine.\n\n### Returns\n\n- `[..., D_0, ..., D_{n-2}, D_{n-1}*D_n], tf.DType`: The tensor with the last n dimensions flattened.\n\n**Note: ** If `n` is 1, this function is identical to tf.reshape() in its default `n`-ordering.\n\nsource code:\n```python\ndef flatten_last_dims(x, n):\n    \"\"\"\n    Flattens the last `n` dimensions of a tensor.\n\n    This operation flattens the last `n` dimensions of a tensor. All\n    dimensions beyond the last `n` are not modified.\n\n    Parameters\n    ----------\n    x : [..., D_0, D_1, ..., D_{n-1} , D_n], tf.DType\n        The input tensor.\n\n    n : int\n        The number of dimensions to combine.\n\n    Returns\n    -------\n    : [..., D_0, ..., D_{n-2}, D_{n-1}*D_n], tf.DType\n        The tensor with the last `n` dimensions flattened.\n\n    Note\n    ----\n    If `n` is 1, this function is identical to `tf.reshape()` in its\n    default `n`-ordering.\n    \"\"\"\n    if n==1:\n        return x\n    else:\n        new_shape = tf.concat([tf.shape(x)[:-n], \n                               tf.reduce_prod(x.shape[-n:], keepdims=False)], \n                              axis=-1)\n        return tf.reshape(x, new_shape)\n```"
"Here is the definition of Mapper: sionna.mapping.Mapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, return_indices=False, dtype=tf.complex64, **kwargs).  \n  \nThe source code link of [Mapper](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Mapper).  \n  \ntf.DType to specify the complex number datatype. Defaults to tf.complex64.  \nThe last input dimension of the input tensor must be an integer multiple of the number of bits per constellation symbol.  \n  \nThree options to configure the mapper:  \n- **constellation_type** (`str`): The type of constellation to be used. Can be one of \"qam\", \"pam\", or \"custom\". For \"custom\", an instance of `Constellation` must be provided.\n  \n- **num_bits_per_symbol** (`int`): The number of bits per constellation symbol, e.g., 4 for QAM16. Only required for `constellation_type` in [\"qam\", \"pam\"].\n  \n- **constellation** (`Constellation`): An instance of `Constellation` or `None`. In the latter case, `constellation_type` and `num_bits_per_symbol` must be provided.\n  \n- **return_indices** (`bool`): If True, symbol indices are returned in addition to the constellation points. Defaults to False.  \n  \n- **dtype** (`tf.DType`): The output dtype. Defaults to `tf.complex64`.  \n  \nInput\n- `[..., n]`, `tf.float` or `tf.int`: The tensor to be mapped.\n\nOutput\n- `[..., n/Constellation.num_bits_per_symbol]`, `tf.complex`: The mapped constellation symbols.  \n  \n- `[..., n/Constellation.num_bits_per_symbol]`, `tf.int32`: The symbol indices corresponding to the constellation symbols. Only returned if `return_indices` is True.  \n  \n**Note: **The last dimension of the input tensor must be an integer multiple of the number of bits per constellation symbol.  \n  \nFor example, for a 16-QAM constellation, the last dimension of the input tensor must be a multiple of 4.  \n  \nThe individual symbols of the constellation are not normalized or scaled in any way. This is in contrast to the `NormalizedQAM` and `NormalizedConstellation` where the constellation is normalized to have a power of one.  \n  \n### Property  \n- **constellation**: The constellation object.  \nsource code:\n```python\nclass Mapper(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"A layer that maps a tensor of binary values\n    to a tensor of points from a provided :class:`~sionna.mapping.Constellation`.\n\n    Parameters\n    ----------\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        The type of constellation to be used. Can be one of \"qam\", \"pam\", or\n        \"custom\". For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type`` and ``num_bits_per_symbol``\n        must be provided.\n\n    return_indices : bool\n        If `True`, symbol indices are additionally returned.\n        Defaults to `False`.\n\n    dtype : tf.DType\n        The output dtype. Defaults to `tf.complex64`.\n\n    Input\n    -----\n    : [...,n], tf.float or tf.int\n        Tensor with with binary entries.\n\n    Output\n    ------\n    : [...,n/Constellation.num_bits_per_symbol], tf.complex\n        The mapped constellation symbols.\n\n    : [...,n/Constellation.num_bits_per_symbol], tf.int32\n        The symbol indices corresponding to the constellation symbols.\n        Only returned if ``return_indices`` is `True`.\n\n    Note\n    ----\n    The last dimension of the input tensor must be an integer multiple of\n    the number of bits per constellation symbol.\n\n    For example, for a 16-QAM constellation, the last dimension of the\n    input tensor must be a multiple of 4.\n\n    The individual symbols of the constellation are not normalized or scaled\n    in any way. This is in contrast to the :class:`~sionna.mapping.NormalizedQAM`\n    and :class:`~sionna.mapping.NormalizedConstellation` where the\n    constellation is normalized to have a power of one.\n    \"\"\"\n    def __init__(self,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 return_indices=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n\n        assert dtype in [tf.complex64, tf.complex128],\\\n            \"dtype must be tf.complex64 or tf.complex128.\"\n\n        assert return_indices.dtype==\"bool\", \\\n            \"The `return_indices` must be bool.\"\n\n        if constellation is not None:\n            assert constellation_type in [None, \"custom\"],\\\n                \"\"\"`wrong. `constellation_type` must be \"custom\".\"\"\"\n            self._constellation = constellation\n        else:\n            assert constellation_type in [\"qam\", \"pam\"], \\\n                \"Wrong `constellation_type`.\"\n            self._constellation = Constellation(  constellation_type,\n                                                    num_bits_per_symbol,\n                                                    dtype=dtype)\n        self._return_indices = return_indices\n        self._num_points = self._constellation.num_points\n        self._ind_type = tf.int32 if self._num_points<256 else tf.int64\n\n    def call(self, inputs):\n        x = inputs\n        ind = tf.cast(tf.range(0, self._num_points), self._ind_type)\n\n        # Ternary mask used for gathering the symbols.\n        # For example, for 5 symbols, we have the following mask:\n        # [True, True, False, False, False, True, True, False, False, False]\n        mask = expand_to_rank(ind, tf.rank(x), 0)\n\n        # One-hot symbols corresponding to the binary representation of the\n        # index position of the constellation symbol.\n        # For example, for 5 symbols, we have for the first 2 symbols:\n        # [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n        one_hot = tf.one_hot(ind, self._num_bits_per_symbol)\n\n        # Expand for broadcasting\n        one_hot = expand_to_rank(one_hot, tf.rank(x), 0)\n\n        # Apply the mapper\n        points = tf.gather(self._constellation(points=True), mask)\n\n        # Cast to the output dtype\n        points = tf.cast(points, self.dtype)\n\n        if self._return_indices:\n            symbols = tf.gather(self._constellation(symbols=True), mask)\n            symbols = tf.cast(symbols, self.dtype)\n            return [points, symbols, ind]\n        else:\n            return points\n```  \n  "
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, the following steps were taken:\n\n1. Set the GPU number to be used. If the notebook is to be used on a multi-GPU machine, you can set the GPU number to be 0, 1, 2, etc., to use the first, second, third, etc. GPU respectively. If you want to use the CPU, you can set `gpu_num` to an empty string (\"\"). \n\n2. Set the environment variable `CUDA_VISIBLE_DEVICES` to the number of the GPU to be used. If you want to use the CPU, you can set `gpu_num` to an empty string (\"\").\n\n3. Set the TensorFlow configuration to use only a single GPU and allocate only as much memory as needed. If the notebook is to be used on a multi-GPU machine, you can list the specific GPUs to be used in the `TF_GPU_ORDER` environment variable.\n\n4. Import the necessary libraries. If they are not already installed, the notebook will install them.\n\n5. Set the `tf.get_logger().setLevel('ERROR')` to avoid warnings from TensorFlow."
"Here is the definition of BinaryErasureChannel: sionna.channel.BinaryErasureChannel(return_llrs=False, bipolar_input=False, llr_max=100., dtype=tf.float32, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/discrete_channel.html#BinaryErasureChannel)  \n\nsource code:\n```python\nclass BinaryErasureChannel(BinaryMemorylessChannel):\n    # pylint: disable=line-too-long\n    r\"\"\"BinaryErasureChannel(return_llrs=False, bipolar_input=False, llr_max=100., dtype=tf.float32, **kwargs)\n\n    Binary erasure channel (BEC) where a bit is either correctly received\n    or erased.\n\n    In the binary erasure channel, bits are always correctly received or erased\n    with erasure probability :math:`p_\\text{b}`.\n\n    This layer supports binary inputs (:math:`x \\in \\{0, 1\\}` ) and *bipolar*\n    inputs (:math:`x \\in \\{-1, 1\\}` ).\n\n    If activated, the channel directly returns log-likelihood ratios (LLRs)\n    defined as\n\n    .. math::\n        \\ell =\n        \\begin{cases}\n            -\\infty, & \\text{if}~ y=0 \\\\\n            0, & \\phantom{.} \\text{if}~ y=? \\\\\n            \\infty, & \\phantom{.} \\text{if}~ y=1 \\\\\n        \\end{cases}\n\n    The erasure probability :math:`p_\\text{b}` can be either a scalar or a\n    tensor (broadcastable to the shape of the input). This allows different\n    erasure probabilities per bit position.\n\n    Please note that the output of the BEC is *ternary*. Hereby, `-1` indicates\n    an erasure for the binary configuration and `0` for the bipolar mode,\n    respectively.\n\n    This class inherits from the Keras `Layer` class and can be used as layer in\n    a Keras model.\n\n    Parameters\n    ----------\n\n    return_llrs: bool\n        Defaults to `False`. If `True`, the layer returns log-likelihood ratios\n        instead of binary values based on ``pb``.\n\n    bipolar_input : bool, False\n        Defaults to `False`. If `True`, the expected input is given as\n        :math:`\\{-1,1\\}` instead of :math:`\\{0,1\\}`.\n\n    llr_max: tf.float\n        Defaults to 100. Defines the clipping value of the LLRs.\n\n    dtype : tf.DType\n        Defines the datatype for internal calculations and the output\n        dtype. Defaults to `tf.float32`.\n\n    Input\n    -----\n    (x, pb) :\n        Tuple:\n\n    x : [...,n], tf.float32\n        Input sequence to the channel.\n\n    pb : tf.float32\n        Erasure probability. Can be a scalar or of any shape that can be\n        broadcasted to the shape of ``x``.\n\n    Output\n    ------\n    : [...,n], tf.float32\n        Output sequence of same length as the input ``x``. If\n        ``return_llrs`` is `False`, the output is ternary where each\n        `-1` and each `0` indicate an erasure for the binary and bipolar\n        mode, respectively.\n\n    Raise\n    -----\n    AssertionError\n        If ``return_llrs`` is not `bool`.\n\n    Note\n    ----\n    If you use this layer in Graph mode with XLA, i.e., within a function\n    that is decorated with ``@tf.function(jit_compile=True)``,\n    make sure that ``sionna.Config.xla_compat=true`` is set.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n\n    def __init__(self, return_llrs=False, bipolar_input=False, llr_max=100.,\n                 dtype=tf.float32, **kwargs):\n\n        assert isinstance(return_llrs, bool), \\\n            \"return_llrs must be bool.\"\n        self._return_llrs = return_llrs\n        self._bipolar_input = bipolar_input\n        self._llr_max = llr_max\n        super().__init__(states=2,\n                         inputs_are_discrete=True,\n                         bipolar_input=bipolar_input,\n                         llr_max=llr_max,\n                         dtype=dtype,\n                         **kwargs)\n\n    #########################################\n    # Public methods and properties\n    #########################################\n\n    @property\n    def pb(self):\n        \"\"\"\"\n        Erasure probability.\n\n        Can be either a scalar or a tensor (with broadcastable shape).\n\n        This property can be set through assigment. It is not a\n        hyperparameter set upon instantiation.\n        \"\"\"\n        return tf.constant(self._pb, self.dtype)\n\n    @pb.setter\n    def pb(self, value):\n        self._pb = value\n\n    @property\n    def e_a(self):\n        r\"\"\"\n        Returns the *erasure pattern* :math:`(p_{a,0}, p_{a,1})` used in\n        the channel, where\n\n        .. math::\n            p_{a,0} = p_b,\n            p_{a,1} = 1 - p_b.\n\n        This property is only defined after calling the channel once\n        (i.e., after it was used to channel input).\n        \"\"\"\n        return tf.cast(self._e_a, dtype=tf.int32)\n\n    @property\n    def e(self):\n        \"\"\"\"\n        Returns the *erasure mask* :math:`e` used in the channel.\n\n        The erasure mask is a tensor of shape ``[n]`` (or ``[n,1]``), where\n        each element is either `0` or `1`. A `0` at position :math:`i`\n        means that the bit at position :math:`i` was *erased*. A `1` means that\n        the bit was *transmitted.\n\n        This property is only defined after calling the channel once\n        (i.e., after it was used to channel input).\n        \"\"\"\n        return tf.cast(self._e, dtype=self._x_dtype)\n\n    #########################\n    # Keras layer functions\n    #########################\n\n    def build(self, input_shapes):\n        \"\"\"Verify correct input shapes\"\"\"\n        super().build(input_shapes)\n        tf.debugging.assert_type(self._llr_max, self._x_dtype)\n\n    def call(self, inputs):\n        \"\"\"Apply erasure to input and return log-likelihood ratios (LLRs).\"\"\"\n\n        x, pb = inputs\n\n        # the BEC is implemented by zeroing out the codeword bits\n\n        if self._bipolar_input:\n            x_b = tf.cast(x, tf.float32)\n            pb = tf.cast(pb, tf.float32)\n            pb_pb = tf.stack((pb, 1- pb), axis=-1)\n            pb_exp = expand_to_rank(pb_pb, tf.rank(x_b), axis=0)\n            x_b = expand_to_rank(x_b, tf.rank(pb_exp), axis=-1)\n            x = tf.where(tf.equal(pb_exp, 0), tf.zeros_like(x_b), x_b)\n        else:\n            x = tf.custom_gradient(bec)(x, pb)\n\n        # if LLRs shall be returned\n        if self._return_llrs:\n            llr0 = tf.fill(tf.shape(x), self._llr_max)\n            llr1 = tf.fill(tf.shape(x), -self._llr_max)\n            llr = tf.where(x==0, llr0, llr1)\n            return llr\n\n        # if binary output is returned\n        else:\n            return tf.cast(x, self._x_dtype)\n\n    #########################\n    # Utility functions\n    #########################\n\n    def sample_states(self, shape, states, seed):\n        # sample only valid states\n        idx = tf.cast(tf.random.categorical(tf.ones((1, states)),\n                                             shape-1, dtype=tf.int32),\n                       dtype=tf.int32)\n        return tf.gather(self._permut_patt, idx, axis=-1)\n\n    def perm_states(self, perm, states):\n        # return permuted states\n        return tf.gather(perm, states, axis=-1)\n\n    #########################\n    # Utility functions\n    #########################\n\ndef bec(x, pb):\n    # pylint: disable=unbalanced-tuple-unpacking\n    r\"\"\"Apply binary erasure function to ``x``.\n\n    This function `erases` the bits in ``x`` with probability ``pb``.\n    This is used in the :class:`~sionna.channel.BinaryErasureChannel`.\n    The data is simply set to zero at the positions of the erasure.\n\n    .. code-block:: Python\n\n        x = tf.constant([0,1,0,1])\n        pb = 0.5\n        print(bec(x, pb))\n        > tf.constant([0, 0, 0, 0])\n\n    Parameters\n    ----------\n        x :  (...,n), tf.float32\n            Input sequence.\n\n        pb : Scalar or smaller than ``x.shape[:-1]``, tf.float32\n            A scalar indicating the erasure probability. Alternatively,\n            a tensor of any shape that can be broadcasted to the shape of ``x``.\n\n    Returns\n    -------\n        : (...,n), tf.float32\n            Erasure result of the same shape as the input ``x``.\n\n    Note\n    ----\n        The data type of the output is the same as the input ``x``.\n    \"\"\"\n    x = tf.cast(x, tf.float32)\n    pb = tf.cast(pb, x.dtype)\n\n    # allow pb to be a broadcastable to the shape of x\n    pb_shape = tf.shape(pb)\n    target_shape = tf.rank(x)\n\n    if target_shape > 1:\n        pb = broadcast_to_target(pb, pb_shape, target_shape, axis=-1)\n\n    # set seed for random function to ensure reproducibility\n    seed = (1337, 327)\n\n    # generate random values that are going to be used to implement the\n    # erasure but are not a this the output of the function\n    rand = tf.random.uniform(tf.shape(x), minval=0., maxval=1., dtype=pb.dtype,\n                                 seed=seed)\n    # apply xor of rand and pb and cast to the datatype of x\n    # the `1` ensure that all nans are set to `1` again\n    # this is required as in TF 2.7 through 2.11 casting of nans to tf.int32\n    # results in an exception.\n    x = tf.experimental.numpy.less(rand, pb)\n    x = tf.cast(x, x.dtype)\n    # if pb is a scalar and x not a tensor, i.e., pb is a constant.\n    if isinstance(pb, tf.Tensor):\n        if pb.shape.rank==0:\n            x = tf.cast(x, tf.float32)\n    return x\n```"
"The setup for the weighted belief propagation decoding involves the following components:\n\n1. **LDPC BP Decoder**: This component is implemented using the `LDPCBPDecoder` class from the `sionna.fec.ldpc.bp` module. It represents the belief propagation decoding algorithm for low-density parity-check (LDPC) codes. The decoder can be configured for a specific number of iterations and can be made trainable to allow the internal weights to be trainable.\n\n2. **Gaussian LLR Source**: This is a simple component that represents the source of Log-Likelihood Ratios (LLRs). The LLRs are the results of channel demapping or decoding algorithms and indicate the likelihood of a bit being a '0' or a '1'. The Gaussian LLR source generates LLRs with a given 'mean' and 'var'.\n\n3. **Weighted BP Decoder**: This is a custom component that implements multi-loss belief propagation decoding. It uses the output of the Gaussian LLR source as the prior and the output of the LDPC BP Decoder scaled with a learnable weight. The loss function is defined such that the decoder can be trained end-to-end.\n\n4. **Keras Model**: The complete model is implemented as a Keras model that inherits from the `Model` class. This allows the model to be defined and trained using standard Keras practices.\n\nIn the context provided, all these components are used to implement and train a system that can perform multi-loss BP decoding. The system is then evaluated against a range of Eb/N0 values to obtain bit-error rate (BER) performance curves."
"To use the PUSCHDMRSConfig class and its properties in Sionna's API, you have to initialize the DMRS configuration object with the required or optional parameters. After the initialization, you can change the properties according to your requirements as the class instance is either read-only or can be re-assigned. Here is an example of how to use it:\n\n```python\n# Import the required class\nfrom sionna.nr import PUSCHDMRSConfig\n\n# Initialize the DMRS configuration with optional parameters\ndmrs_config = PUSCHDMRSConfig(config_type=1, length=1, additional_position=0, dmrs_port_set=[], type_a_position=2, cdm_groups=[], num_cdm_groups_without_data=2, beta=0.1, delta=[], w_f=[], dmrs_mask=[], cdm_mode='signaling', transform_precoding='disable', num_layers=1, antenna_ports=[], cdm_shift=0, dmrs_id=1, n_id=1, n_scid=0, carrier_config=None, dtype='tf.float32')\n\n# Change the property, e.g. required DMRS port set\ndmrs_config.dmrs_port_set = [0,1]\n\n# You can also check the properties\nprint(dmrs_config.dmrs_port_set)\n```\n\nThis code will first create a PUSCHDMRSConfig instance with a config_type of 1, a length of 1, no additional_position, an an optional dmrs_port_set which is an empty list. The list of dmrs_port_set is then changed to [0,1]."
"To demonstrate the encoding of information bits using an instance of `ConvEncoder`, we will first create a synthetic dataset of information bits and encode them using the encoder. During this process, we will depict the shapes and types of the input and output tensors.\n\nLet's start by creating a `ConvEncoder` instance. Due to the constraints present in the provided context, we will demonstrate the use of `ConvEncoder` without terminating the encoder and with the generator polynomial provided.\n\nThe generator polynomial (`gen_poly`) in binary form for the rate 1/2 code is given as: `[10011]`. We will use this polynomial to initialize the `ConvEncoder`.\n\nHere is how you do it in Python using the Sionna API:\n\n```python\nfrom sionna.fec.conv import ConvEncoder\n\n# Assuming the gen_poly is a string with the polynomial in binary form\ngen_poly = '10011'\n\n# Create an instance of the ConvEncoder\nencoder = ConvEncoder(gen_poly=gen_poly, terminate=False)\n```\n\nNow, let's create a synthetic dataset of information bits. In our demonstration, we will assume a batch size of 2 and 8 information bits per codeword, which is the `k` parameter of the encoder.\n\n```python\nimport tensorflow as tf\n\n# Create a synthetic dataset of information bits\nbatch_size = 2\nk = 8\nu = tf.random.uniform(shape=(batch_size, k), minval=0, maxval=2, dtype=tf.int32)\nu = tf.cast(u, dtype=tf.float32)  # Cast to float32 for the encoding\n```\n\nTo encode the information bits, we simply pass the information bit tensor `u` to the `encoder`.\n\n```python\n# Encode the information bits\nc = encoder(u)\n```\n\n`c` is now the encoded codewords. Let's take a look at the shapes and types of the input and output tensors `u` and `c`.\n\n- `u` Shape: (2, 8), Type: tf.float32\n- `c` Shape: (2, 10), Type: tf.float32\n\nNote that the shapes reflect the original dimensions of the information bits `u` and the slightly increased dimensions of the encoded codewords `c` due to the addition of parity bits.\n\nIn the provided context, it is stated that the `request_type` can be either \"terminate\" or \"padding\". When `request_type` is \"terminate\", the true rate of the code is slightly lower than the design rate due to the termination process. However, in the given context, the property `coderate` is not provided for the `ConvEncoder`. The true rate of the code would be lower if `terminate` is `True`, but since it was stated that `terminate` is `False`, the `coderate` property would be equal to the design rate, which is `k / n`."
"The DMRS configuration in the provided context is done using the Sionna library for 5G NR simulations. The DMRS (Demodulation Reference Signal) is a special pilot signal that is sent along with the data signal. It is used for accurately estimating the channel during the demodulation process. \n\nThe DMRS configuration is done through the PUSCHConfig instance. In the provided context, several parameters related to the DMRS configuration are set while creating the PUSCHConfig instance. These parameters include the number of CDM groups without data, the duration of the DMRS additional-cyclic prefix, the number of ports, and the DMRS port set. The DMRS port set is a list of indices of DMRS ports. In the context, the DMRS port set is set to [0,1,2,3].\n\nThe pilot pattern can be visualized using the show method of the PilotPattern instance. In the context, the pilot pattern is visualized using the following code:\n\n```python\npusch_transmitter.pilot_pattern.show();\n```\n\nThis code generates a plot of the pilot pattern. The plot shows the DMRS elements for each of the DMRS ports. Here, the pilot pattern is shown for a transmitters sending a single stream with four DMRS ports. Each DMRS port corresponds to a distinct pilot pattern."
"To visualize common scattering patterns using the Sionna package, you can follow these steps:\n\n1. Import the necessary modules and set up the environment:\n\n```python\nfrom sionna.rt import scattering_pattern\nimport sionna\nimport matplotlib.pyplot as plt\n```\n\n2. Define the scattering pattern by creating an instance of the `LambertianPattern` class with the appropriate parameters. For example, for the Lambertian pattern:\n\n```python\npattern = scattering_pattern.LambertianPattern()\n```\n\n3. Use the `visualize` method of the scattering pattern class to generate a 3D visualization of the scattering pattern:\n\n```python\npattern.visualize()\n```\n\nThis will create a 3D visualization of the scattering pattern. You can rotate the pattern to view it from different angles.\n\n4. Optionally, you can create a planar cut of the scattering pattern using the `visualize_cut` method. For example:\n\n```python\npattern.visualize_cut(k_i=(0.5, 0.0, 0.5))\n```\n\nThis will create a planar cut of the scattering pattern. The `k_i` parameter specifies the incoming direction.\n\n5. To compute the scattering field caused by the scattering pattern, you can use the `get_scattering_field` method. For example:\n\n```python\n# Assuming `surf_circ` is an instance of `CircularSurface`\nsf = pattern.get_scattering_field(surf_circ, num_samples=1e6)\n```\n\n6. To visualize the scattering field, you can use the `visualize` method of the `ScatteringField` class. For example:\n\n```python\nsf.visualize()\n```\n\nThis will create a 3D visualization of the scattering field. You can rotate the field to view it from different angles."
"To handle import errors for the Sionna package, you can use a try-except block in Python. Here's how you can do it:\n\n1. First, attempt to import the Sionna package using the `import` statement inside a `try` block.\n\n```python\ntry:\n    import sionna\n```\n\n2. If the import is successful, the code execution will continue. However, if the import fails, an `ImportError` will be raised.\n\n3. You can catch this `ImportError` using an `except` block. Inside this block, you can handle the error. In this case, the error is handled by installing the Sionna package using the `os.system` function to run the shell command `\"pip install sionna\"`.\n\n```python\nexcept ImportError as e:\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n4. After the package is installed, you can attempt to import it again.\n\nThis method is commonly used to handle import errors for packages that are not installed. It's important to be careful when catching `ImportError` though, as it should only be used for the specific package that is missing, and not for all `ImportError`s. Misuse of `except` can catch other `ImportError`s that are unrelated to the package being checked, which can cause confusion."
"For the provided context, the necessary Sionna APIs are already included and documented. Thus, there is no need to demonstrate how to import the APIs."
"The `Descrambler` class is a part of 'sionna.fec.scrambling' module and is used to descramble a given scrambled sequence. It takes `scrambler` as an input parameter, which is an associated instance of the `Scrambler` class. The `binary` parameter is a boolean and indicates whether the descrambling should be done in the binary domain (bit-wise flipping) or the soft-value/LLR domain (sign flipping).\n\nThe `Descrambler` class inherits from the Keras layer class and can be used as a layer in a Keras model. This is because it defines a Keras model by implementing the `call` method which uses the `scrambler` instance to descramble an input sequence.\n\nThe `Descrambler` class has several properties. The property `scrambler` is associated with the scrambler instance. The `binary` property is a flag that indicates whether the descrambler should switch signs (in the soft-value/LLR domain) or bits (in the binary domain).\n\nThe method `descramble` is also defined in the `Descrambler` class. This method takes as input either a sequence of bits or soft-values and returns the descrambled sequence.\n\nThe `Descrambler` class has several parameters, including `scrambler`, `binary`, and `dtype`. The `scrambler` parameter is the associated instance of the `Scrambler` class. The `binary` parameter is a boolean that indicates whether the descrambling should be done in the binary domain (bit-wise flipping). The `dtype` parameter is defined as the datatype for the internal calculations and the output datatype."
"To perform Polar decoding using an instance of `Polar5GDecoder` with log-likelihood ratios (LLRs) as inputs, you will need to follow these steps:\n\n1. **Import Necessary Libraries**:\n   Ensure that you have the necessary libraries imported. This includes Sionna, TensorFlow, and other necessary libraries.\n\nHere is some sample code demonstrating the steps:\n\n```python\nimport tensorflow as tf\nimport sionna\nfrom sionna.fec.polar.decoding import Polar5GDecoder\n\n# Required for decoding\nfrom sionna.fec.polar.decoding import sionna\nfrom sionna.fec.polar.decoding import Polar5GDecoder as Dec\n```\n\n2. **Set up the Polar5GDecoder Instance**:\n   Create an instance of the `Polar5GDecoder`. You will need to specify the `enc_polar` (which is the instance of `Polar5GEncoder` used for encoding the signal), as well as the `dec_type` (which indicates the type of decoding step; options include Successive Cancellation (SC), List decoding with size 8 or 128, and Belief Propagation (BP)).\n\n   If the `dec_type` is list-based, you need to specify `list_size`.\n\nHere's how you can set up the decoder instance:\n\n```python\n# Assuming you have already created an instance of Polar5GEncoder called `enc_polar`\ndec_polar = Polar5GDecoder(enc_polar=enc_polar, dec_type=\"SC\")\n```\n\n3. **Obtain the LLRs**:\n   Obtain the LLRs that represent the result of the channel decoding. These LLRs typically come from the demodulation stage of the communication system and may be calculated using methods such as the Log-Likelihood Ratio (LLR) or Maximum Log-Likelihood (MLL).\n\n   The LLRs should be provided as a 2D tensor/array, where the last dimension should correspond to the number of bits per symbol (if you have a complex-valued signal, each symbol will be represented by two bits, one for each of the real and imaginary parts).\n\nHere is an example LLR tensor `llr`:\n\n```python\nimport numpy as np\n\n# Define the number of codeword bits and the number of bits per symbol\nnum_codeword_bits = 16\nnum_bits_per_symbol = 4\n\n# Generate random LLRs (replace this with your actual LLRs)\nllr = np.random.randn(2, num_codeword_bits).astype(np.float32)\n```\n\n4. **Decode the Polar Code**:\n   Call the `dec_polar` instance with the LLRs as an argument. This will decode the Polar code and return the estimated information bits.\n\nHere's how to perform the decoding:\n\n```python\ndecoded_bits = dec_polar(llr)\n```\n\n5. **Evaluate the Results**:\n   The `decoded_bits` now contains the estimated information bits. You can evaluate the accuracy of the decoding by comparing these bits with the original information bits. This depends on the specific application and the performance measures used.\n\nPlease note that the actual implementation may vary depending on the specific requirements of your application. For example, you might need to use a different type of decoder or provide additional parameters such as error correction capabilities."
"To load a scene from a file using the `load_scene()` function from the `sionna.rt` module of the Sionna package, you can follow these steps:\n\n1. Import the necessary modules.\n```python\nfrom sionna.rt import load_scene\n```\n2. Call the `load_scene()` function with the scene's filename as an argument.\n```python\nscene = load_scene(filename)\n```\nIn the above code, `filename` should be replaced with the actual name of the scene file.\n\nIf the scene file provides the geometry, materials, transmitters, receivers, and any additional objects, the function can load and return a `Scene` object representing the scene. You can then proceed to utilize the various functions provided by the `Scene` object to perform simulations and computations based on the loaded scene."
