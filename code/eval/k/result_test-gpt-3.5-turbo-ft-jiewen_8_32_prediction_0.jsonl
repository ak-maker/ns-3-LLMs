"When creating a Polar5GEncoder instance in Sionna, the parameters 'k' and 'n' are used to define the Polar error-correcting code and to indicate the information bit length and codeword length, respectively.\n\nThe parameter 'k' (denoted as input parameter for Polar5GEncoder) is an integer that represents the number of information bits per codeword. In the context of the 5G standard, k would be set to the number of information bits required for a codeword, depending on the specific coding rate and the channel conditions.\n\nThe parameter 'n' (also input parameter for Polar5GEncoder) is an integer which defines the length of the codeword. In the 5G standard, n would generally be set to 18432 for the downlink and 20480 for the uplink, in the case of the maximum codeword length.\n\nTo instantiate a Polar5GEncoder object, the values of 'k' and 'n' must be provided based on the above definitions. An example of how to create a Polar5GEncoder instance would be:\n\n```python\nfrom sionna.fec.polar.encoding import Polar5GEncoder\n\n# Define the information and codeword lengths\nk = 100  # Replace with the desired information bit length\nn = 200  # Replace with the desired codeword length\n\n# Create the encoder instance\nencoder = Polar5GEncoder(k=k, n=n)\n```\nIn the provided context, when creating the Polar5GEncoder instance, the values of 'k' and 'n' are based on the mapping of the input parameters:\n\n```python\nfrom sionna.fec.polar.encoding import Polar5GEncoder\n\n# Based on the context of 'Sionna' package, define 'k' and 'n' for a Polar5GEncoder instance\nk_5g_encoder = 14336  # Information bits including rate matching (taken from 3GPP specification)\nn_5g_encoder = 2048  # Codeword length (taken from 3GPP specification)\n\n# Create the encoder instance\nencoder_5g = Polar5GEncoder(k=k_5g_encoder, n=n_5g_encoder)\n```\n\nIt is essential to refer to the specifications or documentation, such as those from 3GPP, when determining the values of 'k' and 'n' for encoding data with the Polar code in the context of wireles communications, as the appropriate values depend on the specific requirements and conditions, including error control strategies, modulation schemes, and code design principles."
"To import DeepMIMO and generate a dataset, follow the steps below:\n\n1. First, you need to import the DeepMIMO module. If it's not already installed, you can install it using pip. Here is the command to do this:\n\n```python\ntry:\n    import DeepMIMO\nexcept ImportError as e:\n    # Install DeepMIMO if package is not already installed\n    import os\n    os.system(\"pip install DeepMIMO\")\n    import DeepMIMO\n```\n\n2. Once you have imported the DeepMIMO module, you can generate a dataset using the DeepMIMO class `DeepMIMO_Dataset`. This class generates a dataset of MIMO channels. You need to specify the parameters for the scenario you want to generate the dataset for. Here is an example:\n\n```python\nfrom DeepMIMO import DeepMIMO_Dataset\n\n# Parameters\nparams = DeepMIMO.generate_params( \n                                scenario = 'HT',\n                                carrier_frequency = 28e9,\n                                # Antenna array parameters\n                                ant_array = 'ue', \n                                # Antenna array orientation\n                                theta = 0, \n                                # Speed\n                                speed = 0, \n                                # Number of samples\n                                n_s = 300, \n                                # BSs elevation\n                                bs_elevation = 90)\nparams['d'] = 10\nDeepMIMO_dataset = DeepMIMO_Dataset(params)\n```\n\nIn this example, a DeepMIMO dataset is generated for the 'HT' scenario, which is a scenario suitable for generating channels for 5G New Radio. The carrier frequency is set to 28GHz. The antenna array used is 'ue', which is a planar user antenna. The orientation of the antenna array is set to 0, meaning it is parallel to the y-z plane. The speed of the user is set to 0, indicating a static user. The number of samples is set to 300. The elevation of the base station (BS) is set to 90, i.e., the BS is located on the z-axis. The parameter `d` represents the distance between the user and the BS, and is set to 10 meters. The DeepMIMO dataset is then generated using these parameters.\n\nPlease note that the actual parameters you choose should be based on the specific scenario for which you are generating the dataset."
"To plot the weights after training and compare the new Bit-Error Rate (BER) performance, you can follow these steps:\n\n1. After training the model, retrieve the weights from the model. In the provided code, the weights are retrieved using `model.get_weights()`.\n\n2. Store the weights in a temporary variable for comparison later. \n\n3. Use the `stem` function from matplotlib to plot the weights. This function creates a stem plot, which is a plot similar to a line plot but with line widths that can be different for each value.\n\n4. Compare the weights by plotting them. In the provided code, the weights before and after training are compared by plotting the weights and their updated values. The initial weights are shown as markers on a line.\n\nHere is the relevant code from the context:\n\n```python\nweights = model.get_weights()\nplt.figure()\nmarkerline, stemline = plt.stem(range(1, len(weights[0])+1), weights[0], 'blue') # Plot the weights\nplt.setp(stemline, 'linestyle', 'dashed', 'linewidth', 2)\nplt.setp(markerline, 'markerfacecolor', 'r')\nplt.setp(markerline, 'markersize', 12)\nplt.show()\n```\n\nIn the plot, the x-axis represents the index of the weight, and the y-axis represents the value of the weight. The initial weights are shown as red markers on a line, and the updated weights are shown as a line with dashed lines. This allows you to visually compare the weights before and after training.\n\nTo compare the new BER performance after training, you can re-evaluate the model after training and compute the BER. The BER is calculated in the provided code using the `ebno_db` function and the `compute_ber` function. After training, you can call the `ber` function again to compute the new BER and compare it with the previous BER."
"To use the `generate_polar_transform_mat` function to create a Polar transformation matrix for a given Kronecker power, follow these steps:\n\n1. First, ensure that you have the appropriate Python library installed. In this case, you would need the `forward_polar` module from the `LDPC` library, which provides functions to construct and analyze polar codes.\n\n    ```python\n    from LDPC.forest import generate_polar_transform_mat\n    ```\n\n2. Determine the Kronecker power for which you want to create the transformation matrix. The Kronecker power represents how many times the matrix will be 'kron' or 'tensor' multiplied by itself.\n\n3. Call the `generate_polar_transform_mat` function with the desired Kronecker power as the input. This function returns the Polar transformation matrix.\n\n    ```python\n    # k is the order of the Kronecker power\n    # trns_mat is the Polar transformation matrix\n    k = 4\n    trns_mat, info_polar = generate_polar_transform_mat(k)\n    ```\n\n    Replace `k` with the actual order of the Kronecker power you need.\n\nThe function will return two outputs: the transformation matrix `trns_mat` and information about the Polar code `info_polar`. The transformation matrix is an orthogonal matrix that represents the Polar code transformation, which can be used in the encoding and decoding processes.\n\nMake sure to review the documentation and relevant source code to understand all the possible parameters for the function, such as the inclusion of frozen positions and the exact construction method for the transformation matrix. If there are any additional steps or considerations specific to your use case, be sure to account for them."
"Here is the definition of LayerDemapper:  sionna.nr.LayerDemapper(layer_mapper, num_bits_per_symbol=1, **kwargs)  \n  \nSource code link of [LayerDemapper](https://nvlabs.github.io/sionna/_modules/sionna/nr/layer_mapping.html#LayerDemapper)  \n```python\nclass LayerDemapper(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    LayerDemapper(layer_mapper, num_bits_per_symbol=1, **kwargs)\n\n    Computes log-likelihood ratios (LLRs) or hard-decisions on bits\n    for each receive antenna and each layer, for every OFDM Resource\n    Element (or every :class:`~sionna.ofdm.OFDMChannel`), from symbols\n    mapped with the :class:`~sionna.nr.LayerMapper`.\n\n    Parameters\n    ----------\n    layer_mapper : :class:`~sionna.nr.LayerMapper`\n        An instance of :class:`~sionna.nr.LayerMapper`.\n\n    num_bits_per_symbol : int, one of [1,2], ...\n        The number of bits per QAM constellation symbol (e.g., 4 for QAM16).\n        Only required for ``constellation_type`` in [`\"qam\"`, `\"pam\"`].\n\n    Input\n    -----\n    (y, no) or (y, h, s) :\n        Tuple:\n\n    y : [batch_size, num_receive_ant, num_ofdm_symbols, fft_size], tf.complex\n        The received signals.\n\n    no : [batch_size, num_receive_ant] or only the first n>=0 dims, tf.float\n        The noise variance estimate. It can be a tensor of any shape that\n        broadcasts to the shape of ``y``.\n\n    h : [batch_size, num_receive_ant, num_transmit_ant, num_ofdm_symbols, num_subcarriers], tf.complex\n        Channel matrices.\n        Only required if ``y`` and ``no`` are given instead of ``s``.\n\n    s : [batch_size, num_receive_ant, num_receive_ant] or only the first n>=0 dims, tf.complex\n        The noise covariance matrix estimate. It can be a tensor of any\n        shape that broadcasts to the shape of ``y``.\n        Only required if ``y`` and ``no`` are given instead of ``h``.\n\n    Output\n    ------\n    : [batch_size, num_decode=1, num_bits_per_symbol, num_receive_ant, num_ofdm_symbols, num_subcarriers]\n        LLRs or hard-decisions for every bit of every receive antenna of\n        every layer.\n        If ``compute_llrs`` is `True`, the shape of the output will be\n        `[batch_size, num_decode, num_bits_per_symbol, num_receive_ant, num_ofdm_symbols, num_subcarriers]`.\n        For hard-decisions, the shape will be\n        `[batch_size, num_decode=1, num_bits_per_symbol, num_receive_ant, num_ofdm_symbols, num_subcarriers]`.\n        ``num_decode`` is the number of datasets that the demapper has been\n        run on, to be used with a list of demappers.\n\n    Note\n    ----\n    If you want to use this layer in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sionna.Config.xla_compat=true``.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n\n    def __init__(self,\n                 layer_mapper,\n                 num_bits_per_symbol=None,\n                 **kwargs):\n        if (num_bits_per_symbol is not None\n                and not isinstance(num_bits_per_symbol, int)):\n            msg = \"num_bits_per_symbol must be None or int.\"\n            raise ValueError(msg)\n        self._num_bits_per_symbol = num_bits_per_symbol\n        self._compute_llrs = layer_mapper.compute_llrs\n        self._layer_mapper = layer_mapper\n        super().__init__(**kwargs)\n\n    #########################################\n    # Public methods and properties\n    #########################################\n\n    @property\n    def layer_mapper(self):\n        \"\"\"Used layer mapper.\"\"\"\n        return self._layer_mapper\n\n    #########################\n    # Utility methods\n    #########################\n\n    #########################\n    # Keras layer functions\n    #########################\n\n    def call(self, inputs):\n        if self._compute_llrs:\n            # The LayerMapper is configured to provide normalized\n            # constellation. We need to provide the variances to perform\n            # the demapping.\n            y, no = inputs\n            s = self._layer_mapper.get_effective_scm(no)\n        else:\n            y, h = inputs\n            s = self._layer_mapper.get_s(y, h)\n\n        bits = self._layer_mapper.constellation.demapper(y, s)\n\n        # Reshape bits to the desired output shape\n        if self._num_bits_per_symbol is not None:\n            output_shape = tf.shape(bits)[:-1]\n            output_shape = tf.concat(   [output_shape, [-1, self._num_bits_per_symbol]],\n                                        axis=0)\n            bits = tf.reshape(bits, output_shape)\n\n        return bits\n```  \n  "
"To create a PUSCHReceiver using the PUSCHTransmitter and simulate transmissions over the AWGN channel, follow these steps:\n\n1. First, import the necessary modules and classes.\n\n```python\nfrom nr.subcarrier_spacing import subcarrier_spacing\nfrom nr.physical_direct import ChannelModel, perfect_csi\nfrom nr.channel import GeneratePUSCH, PUSCHTransmitter, PUSCHReceiver, PUSCHConfig\nfrom nr.mimo import StreamManagement\nfrom nr.ofdm import OFDMModulator, FrequencySelectiveChannel, OFDMDemodulator\nfrom nr.utils import BinarySource, QAMSource, ebnodb2no, sim_ber, Mapper, Demapper\n```\n\n2. Set up the carrier and OFDM system using the SubcarrierSpacing and other necessary parameters.\n\n```python\ncarrier = CARRIER(subcarrier_spacing = 30,\n                  subcarrier_spacing_config = 1,\n                  n_rb = 273,\n                  n_ssb = 32,\n                  n_ssb_hf = 1,\n                  n_layer = 8)\n```\n\n3. Define the channel model and create an instance of the channel model.\n\n```python\nchannel_model = CHANNEL_MODEL(channel_model = \"cdl\",\n                              delay_spread = 300e-9,\n                              aoa = 33,\n                              carrier = carrier,\n                              ut_array = \"RohdeSchwarz_CBand_PanelAntenna\")\n```\n\n4. Set up the PUSCH configuration and create an instance of the PUSCHConfig class.\n\n```python\npusch_config = PUSCHConfig(**kwargs)\n```\n\n5. Instantiate the PUSCHTransmitter from the PUSCHTransmitterConfig and from the PUSCHConfig.\n\n```python\npusch_transmitter = PUSCHTransmitter(pusch_transmitter_config, pusch_config)\n```\n\n6. Load the PUSCH configuration to the transmitter.\n\n```python\npusch_transmitter.pusch_config = pusch_config\n```\n\n7. Create a PUSCHReceiver instance using the PUSCHTransmitter.\n\n```python\npusch_receiver = PUSCHReceiver(pusch_transmitter)\n```\n\n8. Simulate transmissions over the AWGN channel using the GeneratePUSCH and AWGN classes.\n\n```python\nawgn_channel = AWGN(no_unitary=True)\nnoise = no * ebnodb2no(num_tx=1,\n                       num_bp_per_ssb=carrier.num_subcarriers,\n                       resource_grid=carrier.resource_grid)\nx, b = pusch_transmitter(1)\ny, no = awgn_channel([x, no])\n```\n\n9. Call the PUSCHReceiver with the noise power ratio for the AWGN channel.\n\n```python\nb_hat = pusch_receiver([x, no])\n```\n\n10. Compute the symbol and bit error rate using the sim_ber function.\n\n```python\nfor no in np.linspace(0.1, 0.5, 9):\n    no = float(no)\n    b_hat = pusch_receiver([x, no])\n    print(\"No/No (Eb/N0): %.2f, SER: %.4f, BER: %.10f\" % (no, sim_ber(b, b_hat, show=False).numpy(), no))\n```"
"Here is the definition of:   5g_nr_py.multiplexing.SymbolInds2Bits(data_inds, n_sz=None, n_rnti=None, n_id=None, n_scid=None, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/5g-nr-phy/_modules/numbawrap/multiplexing.html#SymbolInds2Bits)  \n \nsource code:\n```python\nclass SymbolInds2Bits(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n        SymbolInds2Bits(data_inds, n_sz=None, n_rnti=None, n_id=None, n_scid=None, dtype=tf.complex64)\n\n        Computes symbol indices from transmitted data batch.\n\n        If the channel estimator and precoder are transmitters to this module,\n        the correspondence between precoding matrices and the various inputs is as follows:\n\n        - Both channel estimatior and precoder: Input 3 and 4 are Lists of same size and\n          the ith element of Input 3 is paired with the ith element of Input 4.\n\n        Parameters\n        ----------\n        data_inds: List, int\n            Data indices of the input data\n\n        n_sz: int\n            System blokc size\n\n        n_rnti: None or int\n            Length of the batch dimension.\n            Only required when the channel estimator is a\n            :class:`~5g_nr_py.mimo.PrecodedDataBatch`.\n\n        n_id: None or int\n            Number of transmitted streams.\n\n        n_scid: None or int\n            Scrambing ID.\n            Only required when the channel estimator is a\n            :class:`~5g_nr_py.ofdm.ResourceGrid`.\n\n        dtype: tf.Dtype\n            Datatype for internal calculations and output.\n            Defaults to `tf.complex64`.\n\n        Input\n        -----\n        : [batch_dim, num_tx, num_data_symbols], tf.complex\n            Transmitted data in the frequency domain\n\n        Output\n        ------\n        : [batch_dim, num_tx, num_data_symbols*data_symbol_size], tf.complex\n            Transformed data batch where the last dimension\n            is the result of :class:`~5g_nr_py.multiplexing.OFDMDemultiplex`.\n    \"\"\"\n    def __init__(self,\n                 data_inds,\n                 n_sz=None,\n                 n_rnti=None,\n                 n_id=None,\n                 n_scid=None,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        assert dtype in [tf.complex64, tf.complex128], \"dtype\"\n        self._dtype = dtype\n        self._data_ind = data_inds\n        self._n_sz = n_sz\n        self._n_rnti = n_rnti\n        self._n_id = n_id\n        self._n_scid = n_scid\n        if self._n_scid is not None:\n            assert self._n_id is not None\n        if self._n_id is not None:\n            assert self._n_rnti is not None\n\n    def build(self, input_shape): #pylint: disable=unused-argument\n        assert len(input_shape) == 3\n        self._num_streams = input_shape[1]\n        self._data_symbol_size = input_shape[2]\n\n    def call(self, inputs):\n        x0 = tf.gather(inputs, self._data_ind, axis=-1)\n        x0 = tf.cast(x0, self._dtype)\n        x = tf.transpose(x0, [0, 1, 2])\n        # Number of padding symbols for DMRS and pilots\n        dmrs_add = 0\n        if self._n_scid is not None:\n            num_scid_ref_syms = np.sum([\n                                len(ref)\n                                for batch in range(tf.shape(x)[0])\n                                for tx in range(self._num_streams)\n                                for ref\n                                in tf.shape(x)[2 + 2*tx + 0]\n                                if isinstance(ref, tf.complex)\n                            ])\n            num_scid_ref_syms = int(num_scid_ref_syms)\n            dmrs_add += num_scid_ref_syms\n        if self._n_rnti is not None:\n            num_pilot_syms = 2*self._n_id\n            pilot_add = num_pilot_syms\n        else:\n            pilot_add = 0\n        data_symbol_size = self._data_symbol_size\n        data_add = dmrs_add + pilot_add\n        data_symbol_size = int(data_symbol_size)\n        data_symbol_size = data_symbol_size - data_add\n        x = tf.nest.map_structure( # pylint: disable=not-an-iterable\n            lambda y: tf.expand_dims(y, axis=0),\n            x)\n\n        x = ofdm_demultiplex(x, fft_size=data_symbol_size,\n                            l_min=0, cp_length=0)\n        return tf.squeeze(x, axis=0)\n```  \n  "
"Here is the detailed information of TimeChannel:   \n  \n[sionna.channel.TimeChannel(wire_pair, bandwidth, add_awgn=True, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/channel/time_channel.html#TimeChannel)  \n  \nApplies channel responses from the channel model to channel inputs and adds AWGN.\n\nThis class inherits from the Keras Layer class and can be used as layer in a Keras model.\n\nFor each batch example, num_time_samples + delay_spread_samples  time steps of a channel realization are needed to filter the channel inputs. This is because the channel response can be non-zero for time steps corresponding to a delay spread of delay_spread_time_samples or longer. For such long delay spreads, the channel input is assumed to be non-causal and is therefore considered to be zero.  \n  \nFor example, in the case of a minimum phase channel with a RMS delay spread of delay_spread_time_samples, the channel output will result from the filer operation of a length delay_spread_time_samples + num_time_samples filter length) on the channel inputs. The passband of the channel output will also depend on the filter length, as can be seen in the plot of the channel output in the case of a root-raised-cosine filter of 32 samples.  \n  \nThe channel input is first filtered by a root-raised-cosine filter with a given roll-off factor. The roll-off factor and the filter length are chosen to be consistent with [3GPP TR 38.901, \u201cStudy on channel model for frequencies from physical to mmWave] .  \n  \nThen, the channel input is quadrature-amplitude-modulation (QAM) modulated with a mapper (e.g., [LayerMapping](https://nvlabs.github.io/sionna/_modules/sionna/layer_mapping.html#LayerMapping)). The channel model returns the channel impulse response $(a,\\tau)$ and the additive white Gaussian noise (AWGN) variance $N_0$. Custom channel responses $h$ and noise variance $N_0$ can also be provided.  \n  \nFinally, the channel output is demodulated using a corresponding demapper (e.g., [LayerDemapping](https://nvlabs.github.io/sionna/_modules/sionna/layer_mapping.html#LayerDemapping)) and the AWGN variance is subtracted.  \n \n**Example**\n```python\nchannel = TimeChannel(wire_pair, bandwidth)\n(y, no) = channel(x)\n```\nwhere $x$ is a tensor of channel inputs and has the dtype of (the real part of) the channel input symbol type.  $no$ is the noise power \u201cper complex dimension\u201d, i.e., only a single scalar per received sample. \n   \n**Parameters**\n\n- `wire_pair` (WirePair) \u2013 The wire pair to simulate channel for.\n- `bandwidth` (bandwidth) \u2013 Bandwidth [Hz].\n- `add_awgn` (bool) \u2013 If set to False, no AWGN noise is added. Defaults to True.\n- `dtype` (tf.DType) \u2013 The dtype of the output. Defaults to tf.complex64.\n\n**Input**\n\n- `x` ([..., num_time_samples], tf.float) \u2013 Channel inputs\n\n**Output**\n\n- `y` ([, num_time_samples + delay_spread_time_samples], tf.complex) \u2013 Channel outputs\n- `no` (tf.float) \u2013 AWGN variance $N_0$.\n\n**Property**\n\n- `bandwidth` \u2013 Bandwidth [Hz]\n- `delay_spread_time_samples` \u2013 See above for explanation about the required length of the channel filter.\n- `sample_duration` \u2013 Sample duration [s]\n- ```dtype(=tf.complex64)``` \u2013 Output dtype."
"The 'Antenna' class in the 'sn.channel.tr38901' module is used to define and implement antenna settings and patterns as described in the 3GPP TR 38.901 specifications. An antenna is a transducer that converts radio frequency (RF) fields into electrical voltage or vice versa. Each transceiver, or in this case, each radio communication device, uses at least one antenna for transmitting and receiving data.\n\nThe 'Antenna' class has the following essential components:\n\n- **polarization_model**: This is a property that describes the polarization model to be used. Polarization can either be single polarized with either vertical or horizontal polarization, or dual polarized with cross-polarization.\n- **radiation_pattern**: This property, which is also a property of the 'Antenna' class, describes the antenna's radiation pattern. The radiation pattern defines how the power is distributed (in three dimensions) by an antenna over the space. The default value is 78, which corresponds to a half-power beamwidth of 78 degrees.\n- **tr38901**: This property represents the entire antenna array and is actually a shorthand for using antennas that are defined according to the 3GPP TR 38.901 specification.\n- **number_of_ports**: This property of the 'Antenna' class tells how many ports the antenna has. This is either the number of linear polarizations (1 or 2) or the number of cross-polarized elements (2).\n- **gain**: This is a property that represents the gain of the antenna and is defined as a float or a float-valued function. The gain of an antenna is a measure of the efficiency of an antenna in terms of how much power per unit solid angle is radiated by an antenna. \n\nThe 'Antenna' class can be used in the transceiver classes such as the 'uplink_transmitter' and 'uplink_receiver'. It can be set and used in the link level simulations to represent the antenna of the user terminal (UT) or base station (BS)."
"  \nSOURCE CODE:  \n```python\n# This class is from the Tensorflow 2.5 implementation of the paper, \"Deep \n# Learning for Computational Codes: A Two-Layer TurboCoder\" available at \n# https://arxiv.org/ftp/arxiv/papers/1902/1902.07542.pdf.\nclass TurboTermination(keras.callbacks.Callback):\n    \"\"\"Termination for TurboCode simulation.\"\"\"\n\n    def __init__(self, verbose=1):\n        super().__init__()\n        self.verbose = verbose\n\n    def on_train_begin(self, logs=None):\n        self.model.underlying_conv.enc_crc.metrics.append(CRC)\n        self.model.underlying_conv.dec_viterbi.metrics = [BitwiseMutualInformation]\n        self.model.underlying_conv.dec_bp.metrics = [BlockwiseMutualInformation]\n        self.model.underlying_conv.dec_map.metrics = [BlockwiseMutualInformation]\n        self.model.underlying_conv.dec_lr.metrics = [BlockwiseMutualInformation]\n        self.model.underlying_conv.dec_scl.metrics = [BlockwiseMutualInformation]\n        self.model.turbo.underlying_t.dec.metrics = [BlockwiseMutualInformation]\n        if self.model.punc.t2!=None:\n            self.model.turbo.underlying_t.dec_viterbi.metrics = [BlockwiseMutualInformation]\n        else:\n            self.model.turbo.underlying_t.dec_viterbi. metrics= [BlockwiseMutualInformation]\n        self.model.turbo.underlying_t.dec_app.metrics= [BlockwiseApp]\n        self.model.turbo.underlying_t.dec_app.term_layer=1\n        self.model.turbo.underlying_t.dec_app.output_dtype = tf.float32\n        self.model.turbo.underlying_t.dec_app.llr_max = tf.constant(100., tf.float32)\n        self.model.turbo.underlying_t.dec_app.llr_scaling = tf.constant(1., tf.float32)\n        self.model.turbo.underlying_t.dec_scl.metrics = [SclTurboTermination]\n\n    def on_epoch_end(self, epoch, logs=None):\n\n        # Stop training if bit_mut reaches 0.11 for 10 consecutive SNRs\n        min_stop = 10\n        if self.model.underlying_conv.dec.metrics[0].result().numpy()<0.11:\n            self.model.stop_training = True\n        else:\n            c=0\n            for stop in self.model.underlying_conv.dec.metrics[0].result().numpy()>=0.11:\n                if stop==True:\n                    c+=1\n                    if c==min_stop:\n                        self.model.stop_training = True\n                        break\n                else:\n                    c=0\n        if self.verbose:\n            if self.model.stop_training:\n                print(f\"Early stop at epoch {epoch} and step {self.model.step}\"+\\\n                    f\" (CER reaches SNR 0.11 for {min_stop} \"+\\\n                    \"consecutive SNR)\")\n            else:\n                print(f\"At epoch {epoch} CER is still above 0.11 for \"+\\\n                    f\"{c} consecutive SNR) \")\n```\n  "
"To wrap everything in a Keras model for convenient Bit Error Rate (BER) simulations and comparison of model parameters, you can follow these steps:\n\n1. Import the necessary libraries and modules. This includes TensorFlow, Keras, and various modules for MimoDetection, AWGN, BinarySource, ebnodb, Plotting, and utilities.\n\n2. Configure the GPU settings if you are using one. This can be done using TensorFlow's `tf.config.experimental.set_memory_growth` function.\n\n3. Define your MIMO system parameters, such as the number of OFDM symbols, FFT size, subcarrier spacing, number of streams per transmitter, and coderate.\n\n4. Create a BinarySource and AWGN channel. The BinarySource is used to generate the transmit signal, and the AWGN channel is used to simulate the channel output.\n\n5. Create an instance of the QAM or PAM modulator. The modulation scheme is used to modulate the real and imaginary components of the transmitted signal.\n\n6. Encode the data with the binary encoder and map it to constellation symbols with the QAM or PAM modulator. This forms the transmitted signal.\n\n7. Simulate the channel output by passing the transmitted signal through the AWGN channel.\n\n8. Create an instance of the LMMSE equalizer and feed the channel output to the equalizer along with the known noise variance and the channel state information (CSI).\n\n9. Demap the equalized soft-symbols to compute the log-likelihood ratios (LLRs) which are then input into the LDPC decoder to obtain an estimate of the transmitted bits.\n\n10. Define a function that implements end-to-end data transmission. This function should take the batch size and EbNo as inputs, generate a new transmit signal, simulate it over the channel, equalize it, and generate LLRs for the decoder.\n\n11. Instantiate a Keras model for BER simulations. This can be done using the `tf.keras.Model` class. In this case, the model uses the `PAM2` class and the `ber_plots` function.\n\n12. Finally, you can run the BER simulations for the models and compare the model parameters. This can be done by calling the `simulate` function on each model and storing the results in a dictionary for comparison.\n\nPlease note that the exact code and methods used may vary depending on the specific requirements of your simulation. The steps outlined above are based on the context provided and may need to be adjusted accordingly."
"The \"build_type_grid\" method of the ResourceGrid class in the Wireless Channel Model module is designed to create a grid that identifies for each element the propagation path type, i.e., line-of-sight (LoS) or non-line-of-sight (NLoS). This is used to indicate the type of propagation that occurs between the transmitter and any given receiver.\n\nHere's the breakdown of the function parameters, inputs and outputs:\n\n- **Function**: `build_type_grid`\n- **Arguments**: \n  - `d_min` (*float*): Minimum considered distance [m]\n  - `d_max` (*float*): Maximum considered distance [m]\n  - `n_points` (*int*): Number of sample points, must be the same as for both `d_min` and `d_max`\n  - `batch_size` (*int*): Number of grid samples to create, controlling the number of total grid points as it creates one sample grid per point.\n- **Inputs**:\n  - `dists` (*Tensor, float, [batch size, n_rx = 1, n_tx = 1, n_samples]*): Distance from the receivers to all transmitters [m]\n  - `Los` (*Tensor, bool, [batch size, n_rx = 1, n_tx = 1, n_samples]*): A tensor indicating for each receiver-transmitter pair whether the path is LoS or NLoS\n- **Output**:\n  - `prop_type_grid` (*Tensor, tf.int32, [batch size, n_rx = 1, n_tx = 1, n_samples]*): Grid identifying for each element the propagation path type - LoS (1) or NLoS (2)\n\nThe function first creates a regular grid of sample distances between receivers and transmitters, from `d_min` to `d_max`,  which will later be used to obtain the propagation path types. Then, for each considered propagation path (i.e., for each receiver, transmitter, sample distance), this function will indicate whether it's a Line-of-Sight (LoS) or non-Line-of-Sight (NLoS). The `batch_size` parameter allows control over the total number of points of the grid by creating `batch_size` parallel grids. \n\nHence, the output `prop_type_grid` is a tensor that contains, for each batch example and for each propagation path, the type of the path (LoS or NLoS). This output can then be used to further simulate or compute channel impulse responses."
"Here is the detailed information of LabelFunction:  \nSource code link of [SymbolLogits2LLRs, s, channel_model, reduce_avg, stream_management, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sion/_modules/sion/decoding/ldpc/bp/utils.html#SymbolLogits2LLRs)  \n  \nComputes log-likelihood ratios (LLRs) or hard-decisions on bits from a tensor of logits (i.e., log-likelihoods).\n\n### Parameters\n\n- **logits** (`tf.complex`):  A tensor of arbitrary shape, consisting of log-likelihood ratios (LLRs) or, more generally, logits.\n- **app_sym** (`bool`):  Indicates whether soft-symbol LLRs should be computed instead of individual LLRs for each bit.\n- **hard_decisions** (`bool`): If set to `True`, the function returns hard-decided bits instead of soft-values. Hard-decisions are simply obtained by comparing the two logit values.\n- **reduce** (`One of [no, mean, sum]`, [string, tf.function]`): Determines if and how the last dimension is reduced.\n- **dtype** (One of [tf.complex64, tf.complex128], [tf.DType, tf.DType]): The dtype of the output. Defaults to tf.complex64.\n\n### Input\n\n- **logits** (`[..., n]`, `tf.complex`): A tensor of arbitrary shape, consisting of log-likelihood ratios or logits for each bit or symbol.\n\n### Output\n\n- **`[..., n]`, `tf.float`**: LLRs or hard-decisions for every bit.\n  "
"Here is the detailed information of MaximumLikelihoodDetector:   \n  \nSource code link of [MaximumLikelihoodDetector](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#MaximumLikelihoodDetector): \n\nMaximum Likelihood (ML) detection for OFDM MIMO transmissions, assuming prior knowledge of the channel and OFDM resource grid.\n\nThis class is deprecated as the underlying algorithm has been integrated into the MultiStreamDetector.  \n  \n```python\nclass MaximumLikelihoodDetector(OFDMDetector):\n    # pylint: disable=line-too-long\n    r\"\"\"MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    Maximum Likelihood (ML) detection for OFDM MIMO transmissions.\n\n    This layer implements maximum-likelihood (ML) detection\n    for OFDM MIMO transmissions assuming prior knowledge of the channel\n    and OFDM resource grid. The detection process is fully differentiable\n    when soft-outputs are computed.\n\n    This class is deprecated as the underlying algorithm has been integrated\n    into the :class:`MultiStreamDetector` .\n\n    Both ML detection of symbols or bits with either\n    soft- or hard-decisions are supported. The OFDM and stream configuration\n    are provided by a :class:`~sionna.ofdm.ResourceGrid` and\n    :class:`~sionna.mimo.StreamManagement` instance, respectively. The\n    actual detector is an instance of :class:`MaximumLikelihoodDetector`.\n\n    Parameters\n    ----------\n    output : One of [\"bit\", \"symbol\"], str\n        Type of output, either bits or symbols. Whether soft- or\n        hard-decisions are returned can be configured with the\n        ``hard_out`` flag.\n\n    demapping_method : Demapping\n        Demapping method used\n\n    resource_grid : ResourceGrid\n        Instance of :class:`~sionna.ofdm.ResourceGrid`\n\n    stream_management : StreamManagement\n        Instance of :class:`~sionna.mimo.StreamManagement`\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For [\"qam\", \"pam\"], the constellation type is expected to be\n        like :class:`~sionna.mapping.Constellation`. For \"custom\",\n        an instance of :class:`~sionna.mapping.Constellation` must be\n        provided.\n\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        Instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If set to `True`, the detector computes hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of ``y``. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    ------\n    (y, h_no) :\n        Tuple:\n\n    y : [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex\n        Received OFDM resource grid after cyclic prefix removal and FFT\n\n    h_no : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex\n        Channel at subcarrier nulled for detection\n\n    Output\n    ------\n    One of:\n\n    : [batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream, if ``output`` equals `\"bit\"`.\n\n    : [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int\n        Logits or hard-decisions for constellation symbols for every stream, if ``output`` equals `\"symbol\"`.\n        Hard-decisions correspond to the symbol indices.\n\n    Note\n    ----\n    If you want to use this layer in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sionna.Config.xla_compat=true``.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n    def __init__(self,\n                 output,\n                 demapping_method,\n                 resource_grid,\n                 stream_management,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        # Instantiate maximum-likelihood detector\n        detector = MaximumLikelihoodDetector_(output=output,\n                            demapping_method=demapping_method,\n                            num_streams = stream_management.num_streams_per_rx,\n                            num_ofdm_symbols = resource_grid.num_ofdm_symbols,\n                            num_effective_subcarriers = resource_grid.num_effective_subcarriers,\n                            num_bits_per_symbol=num_bits_per_symbol,\n                            constellation_type=constellation_type,\n                            constellation=constellation,\n                            hard_out=hard_out,\n                            dtype=dtype,\n                            **kwargs)\n\n        super().__init__(detector=detector,\n                         output=output,\n                         resource_grid=resource_grid,\n                         stream_management=stream_management,\n                         dtype=dtype,\n                         **kwargs)\n``` \n  "
"To initialize a TurboEncoder with custom generator polynomials in the S-Plus format, the polynomials should be provided as a list of binary strings, where each binary string represents a polynomial in the fractional form. The binary sequence \"10011\" represents the polynomial \\(1 + D^3 + D^4\\). \n\nHere is how you would initialize a TurboEncoder using the provided binary sequence for the generator polynomials:\n\n```python\nfrom sionna.fec.turbo import TurboEncoder\n\n# Custom generator polynomials in binary format\ngen_poly_1 = '10011' # Binary representation of the first generator polynomial\ngen_poly_2 = '01101' # Binary representation of the second generator polynomial\ncustom_gen_poly = [gen_poly_1, gen_poly_2]\n\n# Initialize the TurboEncoder with the custom generator polynomials\nencoder = TurboEncoder(constraint_length=4,  # Desired constraint length of the encoder\n                       rate=1/3,  # Desired rate of the Turbo code\n                       generator_polynomials=custom_gen_poly,  # Provided custom generator polynomials\n                       terminate=True)  # Terminate the underlying convolutional encoder\n```\n\nTo use the encoder with polynomials in the decimal form, you would need to convert the decimal integers representing the polynomial coefficients into binary format. The polynomial coefficient operation is performed in GF(2), which is the two-element Galois Field. This means that the decimal integer is first converted to binary, and then the polynomial operations are performed in binary format.\n\nFor example, the decimal integer 13, which is the decimal representation of the polynomial coefficient for the polynomial \\(1 + D^3 + D^4\\), would be first converted to binary, which is \"1101\", and then this binary sequence would be provided to the TurboEncoder when initializing it. \n\nDo note that the two generator polynomials in the list provided to the TurboEncoder are the generator polynomials for the two identical systematic encoders that make up the parallel or serial Turbo encoding process."
"To use the generator to sample the first few items of the dataset, you can follow these steps:\n\n1. First, create a generator to load the dataset. In the given context, the dataset is loaded using the `load_dataset` function, which returns a generator. This generator can be used to load items from the dataset sequentially.\n\n```python\ndataset = load_dataset(sionna.channel.tr38901.mimo) # Load the dataset\n```\n\n2. Once you have the generator, you can use it to sample the first few items of the dataset. This can be done by iterating over the generator and keeping track of the number of items sampled. In the given context, the first 5 items are sampled like this:\n\n```python\n# Sample the first few items of the dataset to build the channel input matrix\nnum_samples = 5 # how many samples you want to take\nsamples = []\nfor sample in dataset:\n    samples.append(sample)\n    if len(samples) == num_samples:\n        break\n```\nIn this code, an empty list `samples` is created to store the sampled items. The `dataset` generator is then iterated over, and each item is appended to the `samples` list. The `if` statement is used to stop the iteration after the first 5 items have been sampled.\n\n3. After sampling the items, you can use the `samples` list to build the channel input matrix. In the given context, the channel input matrix is built by stacking the channel impulse responses to form the matrix of coefficients and then multiplying it with the transpose of the Fourier basis matrix. The resulting matrix is the channel frequency response for each sample.\n\n```python\n# Build the channel frequency response matrix\n# Stack the channel impulse responses to form the matrix of coefficients\nc = np.hstack([k.squeeze() for k in samples]) \n# Frequency response matrix\nH = np.fft(self._t_coeff_norm/c.shape[0]) \n```\n\nPlease note that the code and the steps provided are based on the given context and may need to be adjusted based on the specific use case and the structure of the dataset."
"To save the estimated matrices for future use, you can use the `numpy.savez` function to save the matrices as a compressed `.npz` file. Here are the steps to do this:\n\n1. Estimate the matrices: Use the provided code to estimate the matrices. The matrices of the open-formulae transmitter and receiver can be estimated using the following lines of code:\n\n```python\n  L_ET  = estimate(L_tot)\n  F_EST = estimate(F_tot)\n```\n\n2. Save the estimated matrices: Use the `numpy.savez` function to save the estimated matrices. The matrices are saved as 'L.npz' and 'F.npz' files.\n\n```python\nnp.savez('L.npz', L=L_ET)  \nnp.savez('F.npz', F=F_EST)\n```\n\nThis will save the estimated matrices to a compressed `.npz` file. The matrices can be loaded later using the `numpy.load` function:\n\n```python\nwith open('L.npz', 'rb') as f:  \n    L = np.load(f)  \n```\n\nPlease note that the estimated matrices are saved in a compressed `.npz` file, which can be loaded using the `numpy.load` function."
"Iterative Detection and Decoding (IDD) is a technique used in MIMO (Multiple-Input, Multiple-Output) simulations to improve the error performance of coded systems close to the capacity limit. It combines the processes of detection and decoding into iterative steps to significantly enhance the performance of the communication system.\n\nIn the context of IDD, the underlying principle is that hard decisions on the transmitted codeword are fed as additional input to the decoder to assist its error correction process. The decoder, in turn, generates soft estimations of the information bits that are then passed to the demapper to obtain log-likelihood ratios (LLRs). These LLRs, which represent the reliability of each bit being a '0' or a '1', are converted into hard-decisions (i.e., bit values) again and fed into the (soft-symbol) decoder. This iterative process, often referred to as turbo detection and decoding, continues for several rounds (e.g., three or four).\n\nIn the case of IDD for detection, it is performed by the Sionna module with a specific focus on Low-Density Parity-Check (LDPC) codes. The process begins by receiving the oversampled, noise-corrupted waveform at the receiver. The first step of the detector is to perform matched filtering to recover the transmitted signal. The output is then in the form of log-likelihood ratios (LLRs) on the received symbols. \n\nFollowing this, IDD takes place, where the hard-decisions of the detector on the transmitted codeword are re-encoded by the LDPC encoder and provided to the decoder, along with the previously calculated LLRs. The decoder generates new LLRs, which are used by the demapper to obtain log-likelihood ratios on the bits. These LLRs are then hard-decided and re-encoded before being fed back to the decoder for the next iteration. This process of iterative detection and decoding helps to improve the performance of the MIMO system in terms of the Bit Error Rate (BER).\n\nIt is important to note that IDD requires careful design to ensure convergence and stability. The Sionna module provides automated methods for the generation of IDD algorithms and the necessary components (e.g., detector, demapper, and channel models) and is also designed to work in scenarios with different levels of noise and channel state information (CSI) availability."
"Here is the detailed information of Descrambler:  \n[sionna.fec.scrambling.Descrambler(scrambler, binary=True, dtype=None, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/fec/scrambling.html#Descrambler)  \n\nDescribes how to descramble a scrambled sequence of bits.\n\nThe scrambling sequence is binary and last for one bit only. This means that the seed for the scrambling sequence as well as the number of scrambling sequences are always 1, in contrast to the Scrambler.\n\nIf the scrambling is channel-adapted, i.e., if the channel reliabilites (snr) are taken into account, an additional input is required for the descrambling operation.\n\nNote that the XorScrambler cannot be directly instantiated but is used as auxiliary class for the scrambling and descrambling procedures.\n\n### Parameters\n\n- `scrambler` (Scrambler instance): Associated Scrambler instance which should be used for descrambling.\n- `binary` (bool): Defaults to True. Indicates if binary or bipolar values are scrambled. \n- `dtype` (tf.DType): Defaults to tf.float32. Defines the datatype for internal calculations and the output datatype.\n\n### Input\n\n- `inputs` ([...,n], tf.float32): 1+D tensor of arbitrary shape where the last dimension size is n. Holds the sequence of bits to be descrambled.\n\n- `seed` (int): Defaults to None. Defines the initialization of the random number generator, implicitly provided if None.\n\n- `keep_dims` (bool): Defaults to False. If true, scrambling sequence is replicated to the shape of `x`.\n\n- `reliability` ([...,n], tf.float32): 1+D tensor of arbitrary shape, consisting of reals in [0,1]. Provides the channel reliability information, i.e., it is used to implement channel-adaptation. Required only if the scrambler was set to be channel-adapted.\n\n### Output\n\n- `[...,n]`, tf.float32: 1+D tensor of the same shape as inputs. Contains the descrambled bit sequence.\n  \n### Property\n- `keep_seed` (bool): Indicates if the seed should be kept constant. true means the seed is constant and is not updated after initialization. This behavior is required to ensure that the scrambling sequences of an ensemble of bit channels are independent. This is also the reason why, unlike for the Scrambler, the seed must be provided as an additional input when calling the descrambler.  \n  \n### Note\nIf you want to use sionna\u2019s Scrambler and XorScrambler, you have first to set up the former and then create an XorScrambler instance, i.e., x=XorScrambler(s).  \n  \nThe Descrambler is fully integrated into Keras/TF such that it can be used as layer in a Keras model. This is actually also the recommended way for using it since the various descrambling parameters must be provided to the constructor when the descrambler is instantiated. When the Descrambler is used as layer, the parameters can be provided either explicitly when the layer is instantiated, or they can be provided implicitly to the constructor of a descrambler list. In the latter case, the list must be provided to the constructor of the descrambler.  \n  \n### Raises\n\n- `AssertionError`: If the provided inputs do not adhere to the expected format.\n  \n**Descrambling Procedure**  \nTo be more precise, given a sequence of bits $\\mathbf{b}=\\left(b_0,\\dots,b_{N-1}\\right)$ that were previously scrambled with an LFSR, the descrambling is computed as $\\hat{\\mathbf{b}} = \\mathbf{b} \\oplus \\mathbf{s}$  \nwhere $\\mathbf{s} = \\left(s_0,\\dots,s_{N-1}\\right)$ is the scrambling sequence that was used (and is discarded after use) and $\\oplus$ denotes the bitwise addition.\n\nFor the binary scrambling sequence, the bit values are $s_i=2$  $s_i mod 2-1$ for sequences generated with $s_i=2$  $s_i mod 2-1$ otherwise (see Note).  \nFor the bipolar scrambling sequence, the bit values are $s_i=2$  $s_i mod 2$ for sequences generated with $s_i=2$  $s_i mod 2$ otherwise (see Note).  \n  \n[Scrambler](https://nvlabs.github.io/sionna/_modules/sionna/fec/scrambling.html#Scrambler)   sources.\n  \n[Descrambling code for an arbitrary LFSR](https://nvlabs.github.io/sionna/_modules/sionna/fec/scrambling.html#Descrambler)  \n\n[Descrambling code for a TB5GScrambler](https://nvlabs.github.io/sionna/_modules/sionna/fec/scrambling.html#TB5GScramblerDescrambler)  \n  \n### Properties\n\n- `keep_seed` (bool): Indicates if the seed should be kept constant. true means the seed is constant and is not updated after initialization. This is set to True to ensure that the scrambling sequences of an ensemble of bit channels are independent. This is also the reason why, unlike for the Scrambler, the seed must be provided as an additional input when calling the descrambler.  \n  "
"Here is the definition of KBestDetector: sionna.mimo.KBestDetector(output, num_streams, k, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, use_real_rep=False, list2llr=None, output_dtype=tf.complex64, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/mimo/detection.html#KBestDetector)  \n  \n```python\nclass KBestDetector(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"KBestDetector(output, num_streams, k, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, use_real_rep=False, list2llr=None, output_dtype=tf.complex64, **kwargs)\n\n    MIMO K-Best detector\n\n    This layer implements K-Best MIMO detection as described\n    in (Eq. 4-5) [WTC20]_. It can either generate hard decisions (for symbols\n    or bits) or compute LLRs.\n\n    The algorithm operates in either the space of symbols or bits.\n    This is controlled by the ``constellation_type`` options\n    (or ``constellation``).  The former option should be used\n    if :math:`\\texttt{num_bits_per_symbol}=1`.  It is also possible\n    to indicate whether the constellation is  mapped to a\n    real-valued vector (``use_real_rep``).\n\n    The layer is used as follows:\n\n    .. code-block:: python\n\n        det = KBestDetector(output, num_streams, k, constellation_type=\"QAM\", num_bits_per_symbol=2)\n        y = MIMO2SymbolLayer()(channel_output)\n        codewords = KBestDetector()(y, noise_covariance)\n\n    or\n\n    .. code-block:: python\n\n        det = KBestDetector(output, num_streams, k, constellation=\"constellation_object\")\n        y = MIMO2SymbolLayer()(channel_output)\n        codewords = KBestDetector()(y, noise_covariance)\n\n    Parameters\n    ----------\n    output : One of [\"bit\", \"symbol\"], Output type\n        Type: :class:`str`\n\n    num_streams : tf.int\n        Number of transmitted streams\n\n    k : tf.int\n        Number of paths to detect\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], :class:`str` \n        For \"custom\", an instance of :class:`Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"]\n\n    constellation : Constellation\n        Instance of :class:`Constellation>` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the detector computes hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`.\n        Type: :class:`bool`\n\n    use_real_rep : bool\n        If `True`, the constellation is interpreted as\n        real-valued with the last dimension of size ``num_streams`` \n        being the coefficients of a (possibly complex-valued) vector.\n        This is only relevant if ``output`` equals `\"bit\"`.\n        Defaults to `False`.\n        Type: :class:`bool`\n\n    list2llr: One of [None, \"simple\", \"granca\"], :class:`str` \n        The (optional) list to LLR function to use\n        Type: :class:`str`\n\n    output_dtype: One of [tf.complex64, tf.complex128] :class:`tf.DType` or\n                    a dtype object\n        Dtype of ``y``. Defaults to tf.complex64.\n        Type: :class:`tf.DType`\n\n    Input\n    -----\n    (y, h, s) or (y, h, s, no) \n        Tuple:\n\n    y : complex\n        1+D tensor containing the received signals\n\n    h : complex\n        2+D tensor containing the channel matrices\n\n    s : complex\n        2+D tensor containing the noise covariance matrices\n\n    no : (Optional) complex\n        1+D tensor containing the noise variance.\n        Only required if ``output`` equals `\"bit\"`.\n\n    Output\n    ------\n    x : tf.float\n        2+D tensor representing the `num_streams` streams with\n        either demapped soft-symbols or bits.\n\n    Note\n    ----\n    If you want to use this layer in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sionna.Config.xla_compat=true``.\n    See :py:attr:`xla_compat <sionna.Config.xla_compat>`.\n\n    \"\"\"\n    def __init__(self,\n                 output,\n                 num_streams,\n                 k,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 use_real_rep=False,\n                 list2llr=None,\n                 output_dtype=tf.complex64,\n                 **kwargs):\n```"
"The `position` and `orientation` properties in Sionna are used to move scene objects. The `position` property is used to define the location of an object in the scene. It is a property of the object's local coordinate system. The `orientation` property is used to define the rotation of an object. It is also a property of the object's local coordinate system.\n\nTogether, these two properties can be used to move scene objects to desired locations and rotations. The `position` property represents a vector that points from the origin to the desired position. By changing this vector, you can move an object to a new position in the scene. The `orientation` property represents a rotation, which can also be changed to rotate the object as needed.\n\nFor example, to move an object forward, you would simply add a vector to its `position` property that points in the forward direction. Likewise, to rotate an object, you would simply assign a new rotation matrix to its `orientation` property.\n\nHere is a simple example:\n\n```python\n# Move the object 2 units forward\nobj.position += 2 * sionna.rt.unity.forward\n\n# Rotate the object 90 degrees around the up axis\nobj.orientation = sionna.rt.rotation_matrix(90, [0, 1, 0])\n```\n\nIn the code above, `obj` is a reference to a scene object. The `position` property is manipulated to move the object, and the `orientation` property is manipulated to rotate the object. The `unity.forward` and `[0, 1, 0]` are standard vectors representing the forward and up directions in the Unity coordinate system."
"To run the final evaluation for different system configurations in Sionna RT, you need to follow these steps:\n\n1. **Set up the scene and devices**: You need to set up the scene and devices for the evaluation. This includes the transmitters, receivers, cameras, and any other devices in the scene. You can use the `Scene.load()` method to load a scene from a file, and then add or remove devices as needed. \n\n2. **Configure the system parameters**: Each system configuration includes the number of GPUs, the spatial sampling configuration, and the modulation and coding configuration. You can create a list of different system configurations with varying parameters using the `SystemConfig` class.\n\n3. **Evaluate the system configurations**: You can evaluate the system configurations by looping over the list of system configurations and calling the `evaluate` method of the `Pathtracer` class with the current system configuration. This will return the coverage map and the time needed for the evaluation.\n\n4. **Save the results**: You should save the results of the evaluations to a file for further analysis. You can do this by creating a dictionary with the results and the corresponding system configurations and then saving the dictionary to a file using the `pickle` module.\n\nHere is a sample code that demonstrates these steps:\n\n```python\n# Set up the scene and devices\nscene = load_scene(sionna.rt.scene.simple_street_canyon)\nscene.tx_array = PlanarArray(8,11,0.5,0.5,\"tr389389\")\nscene.tx_array.polarization = \"VH\"\nscene_ryv = Scene_Raytracing(scene)\n\n# Configure the system parameters\nsys_params = SystemConfig(\"my_sys_config\",\n                          num_gpus=4,\n                          spatial_sampling=[2,2,2],\n                          upsample_lv=0,\n                          max_mc_samples=10e6,\n                          wb_interpolation=\"hadamard\",\n                          precoding=False,\n                          equalization=False,\n                          detection_algo=\"fwd_ber\",\n                          remove_los=False,\n                          center_frequency=2.141e9)\n# Define a list of different system configurations\nsys_params_list = [sys_params]\n\n# Evaluate the system configurations\nfor sys_params in sys_params_list:\n    coverage_map, eval_time = scene_ryv.evaluate(sys_params)\n    print(\"Evaluation finished in {:.2f} ms\".format(eval_time))\n\n# Save the results\nresults = {\"sys_params_list\" : sys_params_list,\n           \"coverage_map\" : coverage_map,\n           \"eval_time\" : eval_time}\nwith open(\"results.p\", \"wb\") as f:\n    pickle.dump(results, f)\n```\n\nPlease note that the code may need to be adjusted based on the specific requirements of your evaluation."
"To compute the exact Doppler shifts based on the equation provided in the Background Information, you can use the following steps:\n\n1. Compute the transmitted signal $x(n)$ and the received signal $y(n)$, along with the time delay $\\tau$ that minimizes the mean square error (MSE) between the transmitted and received signals. This can be done using an iterative process as described in the context.\n\n2. Once you have the transmitted and received signals, and the time delay, you can compute the phase shift $\\Delta \\phi (f)$ for each frequency $f$ using the equation:\n\n   $$\\Delta \\phi (f) = 2\\pi f \\tau$$\n\n3. The Doppler shift for frequency $f$ is then computed using the equation:\n\n   $$D(f) = \\frac{\\Delta \\phi (f)}{2\\pi}T^{-1} = \\tau T^{-1}f$$\n\n   where $T$ is the symbol duration.\n\n4. The maximum Doppler shift can be computed using the equation:\n\n   $$D_{\\text{max}} = \\max_{n} |D(f)|$$\n\n   where the maximum is taken over all frequencies $f$ and all iterations $n$.\n\nThe Python code snippet provided in the context can be used as a reference for the exact computation of the Doppler shift. However, the exact computation should be based on the specific use case and the available data."
"Here is the definition of cir_to_time_channel: sion.channel.cir_to_time_channel\nThe link of the source code of cir_to_time_channel is [cir_to_time_channel](https://nvlabs.github.io/sion/_modules/sion/channel/utils.html#cir_to_time_channel). \n\n```python\ndef cir_to_time_channel(cir, covariance_time_channel, time_channel_support, time_channel_lag, time_channel_size, dtype=tf.complex64):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Given a channel impulse response\n    :math:`\\bar{\\mathbf{h}}_{b,\\tau} \\in \\mathbb{C}^{M \\times K}`\n    generate the corresponding channel realizations\n    :math:`\\bar{\\mathbf{H}}_{b,n} \\in \\mathbb{C}^{M \\times S}`\n    for :math:`n` ranging from :math:`N_{\\text{min}}` to :math:`N_{\\text{max}}`,\n    and the channel covariance matrix\n    :math:`\\mathbf{R}_{b}` in :math:`\\mathbb{C}^{M \\times M}`\n    in time domain by\n    :math:`\\mathbf{R}_{b}`. This function serves as an adapter to the\n    time_channel_from_cov_time function.\n\n    **Input**\n\n    (\u2026) : Channel impulse response\n        Tuple in the format [\u2026, M, K], where [\u2026] is an arbitrary number of\n        dimensions (D). For a single user with a single transmit\n        antenna the expected format is [K,M].\n\n\n    covariance_time_channel : Channel covariance matrix\n        Square matrix in the number of antennas consisting of\n        time-domain channel covariance.\n\n    time_channel_support : Base station time channel support\n        Tuple in the format [time_channel_lag, time_channel_size],\n        where `time_channel_lag` is the smallest\n        negative time-lag in the discrete time-domain representation of\n        the channel, and `time_channel_size` the\n        corresponding total size of the time channel\n\n\n    :math:`N_{\\text{min}}` : int\n        Smallest non-negative time-lag\n\n    :math:`N_{\\text{max}}` : int\n        Largest non-negative time-lag\n\n    :math:`S` : int\n        Size of the time channel\n\n\n    dtype : tf.DType\n        Datatype to use for the representation of the channel\n        (either `tf.complex64` or `tf.complex128`).\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    **Output**\n\n    :math:`\\bar{\\mathbf{h}}_{b,n}\\in\\mathbb{C}^{M \\times S}`,  :math:`\\mathbf{R}_{b}` in :math:`\\mathbb{C}^{M \\times M}` \n        NumPy arrays or Tensors: For a batch example `b` this function\n        provides the time domain channel realization\n        :math:`\\bar{\\mathbf{H}}_{b,n}` for :math:`N_{\\text{min}}` <= :math:`n` <=\n        :math:`N_{\\text{max}}` and the time domain covariance matrix\n        :math:`\\mathbf{R}_{b}`.\n    \"\"\"\n    h_tot = tf.squeeze(cir, -2)\n    h_time = tf.squeeze(cir, -1)\n\n    return time_channel_from_cov_time(h_tot, h_time, covariance_time_channel, time_channel_support, time_channel_lag, time_channel_size, dtype)\n```"
"To generate the Channel Frequency Response (CFR) and the Discrete-Time Channel Impulse Response (DRR), you can use the `cir_to_ofdm_channel` function from the `sionna.channel` module. Here's a step-by-step guide on how to do it:\n\n### Step 1: Import the necessary modules\n\nYou will need to import the `sionna` module and the necessary sub-modules. For this operation, you will need `cir_to_ofdm_channel` from the `sionna.channel` module.\n\n```python\nimport sionna\nfrom sionna.channel import cir_to_ofdm_channel\n```\n\n### Step 2: Generate the CIR\n\nThe first step is to generate the channel impulse response (CIR). This can be done using the `GenerateCIR` function from the `sionna.channel` module. You will need to specify the number of paths and the number of samples.\n\n```python\n# Generate the CIR\nmy_cir = sionna.channel.GenerateCIR(num_tx_ant=1, num_rx_ant=1, num_paths=20, num_time_samples=30)\n```\n\n### Step 3: Generate the CFR and DRR\n\nThe Channel Frequency Response (CFR) and the Discrete-Time Channel Impulse Response (DRR) can be generated using the `cir_to_ofdm_channel` function. The CFR is computed from the CIR by assuming an OFDM channel. The DRR is simply the discrete-time Fourier transform of the time-domain channel impulse response.\n\n```python\n# Generate OFDM channel from CIR\ncfr, drr, freq = cir_to_ofdm_channel(frequencies, my_cir, fft_size=74)\n```\n\nIn this function:\n- `frequencies` is the set of frequencies at which the CFR is computed\n- `cfr` is the Channel Frequency Response\n- `drr` is the Discrete-Time Channel Impulse Response\n- `freq` is the subcarrier frequency\n\nNow, `cfr` and `drr` hold the frequency and time channel response information that you need. For example, to plot the magnitude of the Channel Frequency Response, you can use `matplotlib`:\n\n```python\nimport matplotlib.pyplot as plt\n\n# Plot the magnitude of the Channel Frequency Response\nplt.figure()\nplt.plot(frequencies/1e6, np.abs(cfr))\nplt.xlabel(\"Frequency (MHz)\")\nplt.ylabel(r\"$|H(f)|$\")\nplt.show()\n```\n\nThis will plot the magnitude of the Channel Frequency Response against the frequencies. Similarly, you can plot the Discrete-Time Channel Impulse Response to visualize the channel's behavior in the time domain."
"Higher order modulation is a technique used in digital data transmission where multiple bits are encoded into each symbol or signal element for transmission. The principle idea is that each symbol carries more than one bit, which is different from the traditional baseband transmission where each symbol represents a single piece of information (i.e., '0' or '1').\n\nIn higher order modulation, each transmitted symbol contains multiple bits, allowing for an increase in the data rate without a corresponding increase in the bandwidth. This is achieved through the use of a more complex constellation, which is a set of points in the complex plane. The constellation is used to map groups of bits into symbols for transmission.\n\nThe demapper and decoder are the parts of the receiver that are responsible for translating the received symbols back into the original transmitted bits. The demapper uses soft-outputs, which are essentially a measure of the likelihood of each possible symbol being transmitted. These soft-outputs are used to compute metrics (e.g., log-likelihood ratio (LLR)) for each bit that was transmitted. The decoder then uses these metrics, along with knowledge of the channel conditions and the error-correcting code, to make an estimate of the original transmitted bits.\n\nThe relationship between higher order modulation and the demapper and decoder is that the demapper is used to translate the received symbols into the soft-outputs, which are then passed to the decoder for the decoding process. The decoder, in turn, uses the soft-outputs from the demapper, along with other known information, to make an estimate of the original transmitted bits.\n\nIt's important to note that the use of higher order modulation will increase the complexity of the demapper and decoder, especially for long transmitted sequences where the number of transmitted bits is large. This is due to the increased number of soft-outputs that need to be computed and the increased amount of data that the decoder needs to process."
"To handle the situation where the `LDPCBPDecoder` is stateful, the `msg_vn` parameter is used to input hard-decided information bits (or a priori LLRs on the 'variable node' (VN) perspective) that needs to be decoded. This parameter allows the input to the decoder to be either frozen or information positions of the LDPC code, facilitating the process of belief propagation (BP) decoding. \n\nThe significance of the `msg_vn` parameter can be understood in the context of 'box plus/box minus' operations, which are used in the BP message passing algorithm. These operations are performed when updating the messages on the check node (CN) and variable node (VN) perspectives. \n\nIn the VN perspective, the hard-decided information bits (or the a priori LLRs) are input to the decoder's `msg_vn` parameter. This allows the decoder to override the internally generated hard-decisions (or utilize the provided soft-information) following the operation of the LDPC decoder. \n\nAn example of how to handle the `LDPCBPDecoder` in a stateful manner is shown in the following Python code snippet:\n\n```python\nfrom sionna.fec.ldpc.decoding import LDPCBPDecoder\nimport tensorflow as tf\n\n# Assume decoder is already initialized with required parameters\n# Including the weight instance and BP iteration order\ndecoder = LDPCBPDecoder(r_pcm, num_iter=20, stateful=True)\n\n# `hard_out` contains hard-decisions of the information bits and is set as output\n# `msg_vn` contains the information bits (or a priori LLRs) and is passed as input\n# Here `tf.zeros` is used as a placeholder for demonstration, actual data should be provided\nhard_out = decoder(tf.zeros([batch_size, decoder.ldpc_code.k], dtype=tf.float32),\n                      tf.zeros([batch_size, decoder.ldpc_code.n], dtype=tf.float32))\n```\n\nIn this example, you need to replace `r_pcm` with the appropriate `ldpcBPDecoder` instance. The `LDPCBPDecoder` is called with the `stateful` parameter set to `True`, making the decoder stateful. The `msg_vn` parameter is passed to the decoder, with its value containing a placeholder for the information bits (or a priori LLRs). \n\nRemember, in practical use, actual LLRs or hard-decisions should be provided for the `msg_vn` input based on the specific use case and data source. Using `tf.zeros` as a placeholder is not valid in a real decoding process."
": Here is the detailed information of subcarrier_frequencies:   \n  \n[sionna.ofdm.SubcarrierFrequencies(fft_size, subcarrier_spacing, num_tx=1, num_streams_per_tx=1, guard_null=True, direction='uplink', dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/resource_grid.html#SubcarrierFrequencies)  \n\nComputes the normalized subcarrier frequencies $\\mu$ as defined in [(1, \u201cETSI TR 38.211 V14.1.0 (2017-04)\uff09](https://nvlabs.github.io/sionna/resources.html#etsi-tr-38211-v14-1-0-2017-04)\n\n**Parameters**\n\n- `fft_size` (int): FFT size.\n- `subcarrier_spacing` (float): Subcarrier spacing [Hz].\n- `num_tx` (int): Number of transmitters, i.e., the number of streams per\n   transmitter.\n- `num_streams_per_tx` (int): Number of streams per transmitter.\n- `guard_null` (bool): Set to True to include the null carriers at the\n   Nyllquist frequency. This is useful for accurate channel\n   simulation. Defaults to True.\n- `direction` (str): OFDM link direction. Either \"uplink\" or \"downlink\".\n   Defaults to \"uplink\".\n- `dtype` (tf.Dtype): Defines the datatype for internal calculations\n   and the output dtype. Defaults to tf.complex64.\n\n**Output**\n\n- `mu` ([num_tx, num_streams_per_tx, n], tf.float): Normalized subcarrier\n   frequencies.\n\n**Property**\n\n- `fft_size`: FFT size.\n  "
"To simulate the transmission of a single Gaussian impulse over a lumped amplification channel model consisting of multiple fiber spans and optical amplifiers, also known as Erbium Djsoned Fiber Amplifiers (EDFA), you can follow these steps:\n\n1. **Setup the environment**: Import the necessary libraries and modules. This may include the Sionna package, TensorFlow, NumPy, and others.\n\n2. **Model the Channel**: Define the parameters and create a model for the EDFA channel. This model should implement the `tf.keras.Model` interface and include the necessary layers for modeling the fiber and amplifier.\n\n3. **Simulate the Transmission**: Use the channel model to simulate the transmission of the Gaussian impulse. The input impulse should be provided with a time dimension, as the model expects a time-dependent input signal. The model should return the transmitted signal, along with the output SNR.\n\n4. **Visualize the Results**: Plot the transmitted and received pulses to visualize the effect of the transmission.\n\nHere is an example of how you can do this in Python using the Sionna package:\n\n```python\n# Import the necessary libraries\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom sionna.channel import EDFA\n\n# Define the parameters for the EDFA\nnum_edfa = 10 # Number of EDFAs\ng_edfa = 4.0 # Gain in linear scale\ng_line = 1.5 # Attenuation in linear scale\nf_c = 193.55e12 # Carrier frequency\nsamp_rate = 1.0 / 1.025e-12 # Symbol rate\n\n# Create the EDFA model\nedfa = EDFA(\n    g=g_edfa,\n    f=f_c,\n    with_amplification=True,\n    with_attenuation=False,\n    with_noise=True,\n    noise_figure=7.0,\n    i_dfa=8.0,\n    dtype=tf.complex64\n)\n\n# Define the simulation function\n@tf.function\ndef simulate_channel(signal):\n    y = signal\n    # Simulate transmission over the fiber spans\n    for _ in range(num_edfa):\n        y = edfa(y, 1.0) # Fiber spans are assumed to have a unit length\n    return y\n\n# Generate Gaussian impulse\n# Parameters\nfb = 100e9  # Pulse bandwidth\nt0 = 50e-12 / 1.76  # Pulse duration\nn = 1024  # Number of samples\ntf = n / samp_rate  # Total simulation time\n# Derived parameters\nsigma = t0 / (2.0 * np.sqrt(np.log(2.0)))\n# Instant of time at which the impulse is triggered\nto = np.around(n / 2)  # Only approximate t0\n# Time vector\nt = np.linspace(0, tf, n, endpoint=False)\n# Generate Gaussian impulse\nx = 1.0 / (sigma * np.sqrt(2.0 * np.pi)) \\\n    * np.exp(-(t**2) / (2.0 * sigma**2))\n# Add the Gaussian impulse to the input signal\nx = x[np.newaxis, :]  # Add batch dimension\nx = tf.complex(x, tf.zeros_like(x))\n# Simulate the transmission\ny = simulate_channel(x)\n\n# Plot the results\nplt.figure(figsize=(12,7))\nplt.plot(np.abs(x.numpy().squeeze()**2))\nplt.title(\"Transmitted signal (power profile)\")\nplt.xlabel(\"Sample number\")\nplt.ylabel(r\"$|U|^2$\")\n\nplt.figure(figsize=(12,7))\nplt.plot(np.abs(y.numpy().squeeze()**2))\nplt.title(\"Received signal (power profile)\")\nplt.xlabel(\"Sample number\")\nplt.ylabel(r\"$|U|^2$\")\n```\n\nThis will simulate the transmission of the Gaussian impulse over the lumped amplification channel model consisting of multiple fiber spans and optical amplifiers. The results will be plotted in two figures, showing the power profile of the transmitted and received signals."
"Here is the detailed information of CRCDecoder:   \n  \nThe class CRCDecoder is a wrapper that takes a BinaryDencoder and adds CRC check on top of it. It removes the cyclic prefix of a OFDM waveform.\n\nThe class inherits from the Keras layer class and can be used as layer in a Keras model.  \n  \n### Parameters\n\n- **crc_degree** (int) - Defining the CRC polynomial to be used; can be 3, 7, 11, 15, 16, 24, 30, 31. Defaults to 24.\n- **conv_encoder** (str) - Instance of ConvEncoder to be used or None (default) for 5G CRC polynomials.\n- **k** (int) \u2013 Defining the number of information bits per codeword. Defaults to None. Cannot be set at the same time as `input_sha256`. \n- **n** (int) \u2013 Defining the number of codeword bits. Defaults to None. \n- **input_sha256** (bool) \u2013 If set to True, k and n are replaced by the corresponding values as described in 3GPP TS 38.212 for the data-part of a codeword (k and n still need to be set to None). Defaults to False. \n- **dtype** (tf.DType) \u2013 Defaults to tf.float32. Defines the output datatype of the layer (internal precision is tf.float32).\n\n### Input\n\n- **(x, crc_remainder)** \u2013 Tuple:\n  - **x** ([batch_size, \u2026, num_codewords, n/k] or [batch_size, \u2026, num_codewords, n] tf.DType) \u2013 2+D tensor containing (optionally) the information bits to be decoded. \n  - **crc_remainder** ([batch_size, \u2026, num_codewords, crc_degree] tf.DType) \u2013 2+D tensor containing the (optionally) CRC parity bits to be verified.\n\n### Output\n\n- **x_crc** ([batch_size, \u2026, num_codewords, n/k] tf.DType) \u2013 2+D tensor containing the information bits without the CRC parity bits.\n- **crc_valid** ([batch_size, \u2026, num_codewords] tf.bool) \u2013 1+D tensor containing the result of the CRC validation for each codeword.\n\n### Raises\n\n- **AssertionError** \u2013 If `crc_degree` is invalid.\n- **AssertionError** \u2013 If `k` and `n` are not resulting in valid codeword sizes. \n  - For `crc_degree` of 24: k (transport block size) must be such that n (code word size) =  4 * k. \n  - for `crc_degree` of 16: k (transport block size) must be such that n (code word size) =  4 * k. \n  - See table 5.1.3.2-1 3GPP TS 38.212 for details.\n- **InvalidArgumentError** \u2013 When rank(x) < 2.\n- **InvalidArgumentError** \u2013 When the shape of x is not sufficient to create n codewords of size k. \n- **ValueError** \u2013 If `crc_degree` is not 3, 7, 11, 15, 16, 24, 30 or 31.\n- **ValueError** \u2013 If `conv_encoder` is not a valid str.\n- **ValueError** \u2013 If `dtype` is not a valid.\n\n**Note: ** \nThe class inherits from the Keras layer class and can be used as layer in a Keras model. This is also the case for the other *Encoder/*Decoder containing layers. If dtype is not the default tf.float32, and the underlying implementation requires tf.float32, there might be a substantial precision loss. Please also see the section \u201cNote on Keras models with non-default dtypes\u201d in the Encoder layer.  \n  \n### Properties\n\n- **crc_degree** - CRC degree as int.\n- **crc_encoder** - Associated CRCEncoder instance.\n- **crc_length** - Length of CRC. Equals number of CRC parity bits.\n- **dtype** - Output dtype of the layer.  \n- **k** - Number of information bits per codeword.\n- **n** - Number of codeword bits.  \n- **use_ia** - Indicator if `k` and `n` are derived using the (optional) inverse augmenting.  \n  "
"The output of the `Constellation` class is a visualization of the constellation diagram. It shows the symbols on the complex plane that are used to define a constellation. This is an important aspect of digital communication as it demonstrates how bits are mapped into complex symbols prior to being transmitted. \n\nIn the context of the provided code, the `Constellation` class is used to define the constellation for the bits in the QAM (Quadrature Amplitude Modulation) system. The `bits` parameter, which is a 1D array, determines the bit sequence. This constellation is then used to map bits into complex symbols prior to transmission."
"In the `LinearEncoder` definition provided in the context, the `dtype` parameter is not explicitly mentioned as a parameter for the `LinearEncoder`. However, based on general principles derived from the context, the `dtype` parameter should be defined in the function signature for the `LinearEncoder`.\n\nThe `LinearEncoder` function is expected to take an input as a binary or bipoloar input sequence (x) and return an encoded sequence, as well as a couple of other potential outputs like the generator matrix (gm), the check matrix (cm), and the code rate (k/n).\n\nGiven the nature of encoding operations which typically involve binary operations such as addition modulo 2 (`tf.dtypes.cast(tf.float32, x)`, `tf.float32, tf.float32))`, the `dtype` parameter, if it were explicitly included, would most likely be defined as a TensorFlow DataType, with the default value being `tf.float32`. \n\nTo define the `dtype` for the output of the `LinearEncoder`, you would use TensorFlow's `tf.as_dtype` function to explicitly state the data type of the output, converting it from the default TensorFlow data type, like so:\n\n```python\noutput = LinearEncoder()(x, dtype=tf.as_dtype('YOUR_DESIRED_DATA_TYPE'))\n```\n\nReplace `'YOUR_DESIRED_DATA_TYPE'` with the specific string indicating the appropriate data type you want to use for the LinearEncoder output. The actual data type you should use would depend on the requirements of the subsequent layers in your neural network, as well as the computational precision needed for your specific application. If precision is not a concern, you might opt for higher performance and lower memory usage, in which case, for `tf.as_dtype`, you could use 'tf.uint8' to represent a sequence of integers that fit into 8 bits. Yet, it should be noted that in many cases using 'tf.float32' would be more common for general purpose data. \n\nPlease be aware that the actual `LinearEncoder` function and associated function signature that includes the `dtype` parameter are not provided in the context. The provided answer is based on typical practices for TensorFlow encoding layers, and it assumes that an explicit `dtype` parameter would be used in the `LinearEncoder` function, even though it is not shown in the context.  The actual implementation should be based on the specific library documentation or updated code that includes the `LinearEncoder` function signature."
"Here is the detailed information of sionna.utils.matrix_pinv:  \n\n[sionna.utils.matrix_pinv(matrix)](https://nvlabs.github.io/sionna/_modules/sionna/utils/matrix.html#matrix_pinv)\n\nComputes the (Moore-Penrose) pseudo-inverse of matrix.\n\nFor a matrix $\\mathbf{M}\\in \\mathbb{C}^{M\\times K}$, the pseudo-inverse $\\mathbf{M}^{\\dagger}\\in \\mathbb{C}^{K\\times M}$ is\n$\\mathbf{M}^{\\dagger} = \\left( \\mathbf{M}^{\\textrm{H}} \\mathbf{M} \\right)^{-1} \\mathbf{M}^{\\textrm{H}}$.\n\n### Parameters\n\n- **matrix** ([..., M, K]): Matrix of rank 2 or higher.\n\n### Returns\n\n- Matrix with the same shape and dtype as matrix, but with the last two dimensions swapped.\n\n**Note:**\nThe returned matrix is, in many cases, the same as the Hermitian inverse of matrix. However, it is different if matrix has more columns than rows. This is, for example, different when it comes to rectangular encoding matrices, which are used for linear block code.\n\nsource code:\n```python\ndef matrix_pinv(matrix):\n    r\"\"\"Computes the (Moore-Penrose) pseudo-inverse of ``matrix``.\n\n    For a matrix :math:`\\mathbf{M}\\in \\mathbb{C}^{M\\times K}`,\n    the pseudo-inverse :math:`\\mathbf{M}^{\\dagger}\\in \\mathbb{C}^{K\\times M}`\n    is\n    :math:`\\mathbf{M}^{\\dagger} = \\left( \\mathbf{M}^{\\textrm{H}} \\mathbf{M}\n    \\right)^{-1} \\mathbf{M}^{\\textrm{H}}`.\n\n    The returned matrix is the left inverse of ``matrix`` if ``matrix`` has full rank.\n\n    This function is also different from :meth:`~MatrixBase.pinverse`\n    as it will, in many cases, return a matrix with the\n    same shape as ``matrix``. However, it will return the\n    left inverse if ``matrix`` has more columns than rows.\n\n    Parameters\n    -----------\n    matrix : `[..., M, K]`\n        Matrix of rank 2 or higher.\n\n    Returns\n    --------\n    : Matrix with the same shape and dtype as ``matrix``.\n      The last two dimensions swapped.\n\n    Note\n    ----\n    The returned matrix is, in many cases, the same as the\n    :class:`~MatrixBase` ``.pinverse``.\n    However, it is different if ``matrix`` has more columns\n    than rows. This is, for example, different when it comes\n    to rectangular encoding matrices, which are used for linear block code.\n\n    \"\"\"\n    h_mat = hermitian(matrix)\n    a = matrix\n    b = h_mat\n    aha = matmul(b,a)\n    aha_inv = matrix_inverse(aha)\n    res = matmul(b, aha_inv)\n    return res\n```"
"Here is the detailed information of [sionna.mapping.Demapper(demapping_method, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Demapper):  \n  \nComputes LLR or hard-decisions on bits for a (noisy) resource grid.\n\nThe resource grid in y is white Gaussian if awgn is activated.\nIt is assumed to be complex-valued with additional dimension \nspecifiying the number of streams in y.  \n  \nIf hard_decisions is True, the demapper provides hard-decided bits.\nIf the \u201capp\u201d channel reliability mask is provided, it is used\nto access the channel reliability information for every input\nbit which can be helpful for (punctured) Turbo codes.  \n  \nThe Demapper is fully differentiable when soft-decisions are computed.  \n  \nThe following figure [Mapping](https://nvlabs.github.io/sionna/_images/mapping.png) shows the different \nmapping methods that can be selected with \u201cdemapping_method\u201d.\n\n[Mapping]: https://nvlabs.github.io/sionna/_images/mapping.png\n\nThe Demapper has two inputs:\n\n- **y ([,num_streams], tf.complex)**: A [batch of resource grids](https://sionna.rtfd.org/en/stable/api/mapping.html#sionna.mapping.ResourceGrid) with optional AWGN.\n- **no (Scalar or [,n], tf.float)**: The noise variance estimate. This input is optional and can be a scalar or of any shape that can be broadcast to the shape of y. It is only required if awgn is True.\n\nAnd it generates a [batch of bit-labels](https://sionna.rtfd.org/en/stable/api/utils.html#batch_grid) with the same shape as y if hard_decisions is True. Otherwise, it generates LLRs or a [batch of hard-decisions](https://nvlabs.github.io/sionna/_images/demapper.png) for each stream.\n\nThe class has the following properties: \n\n- **demapping_method**: (str) The demapping method used. Options are \u201capp\u201d (app demapping) and \u201cmaxlog\u201d (max-log demapping). \n- **num_streams_per_resource_element**: (int) Number of transmitted streams per resource element.\n- **hard_decisions**: (bool) Indicates if the layer provides hard-decided bits or not.\n- **reliability_app**: (NoneType or [batch_size, num_tx, num_streams_per_symbol, num_symbols], tf.float) The channel reliability for every bit of the `ys` resource grid, where `batch_size` is the batch size, `num_tx` is the number of transmitters, `num_streams_per_symbol` is the number of streams per transmitted symbol, and `num_symbols` is the number of transmitted symbols. This property is only available if `demapping_method` is \u201capp\u201d."
"Here is the definition of CDL: sionna.channel.CDL(model, delay_spread, carrier_frequency, ut_array, bs_array, direction, min_speed=0., max_speed=None, num_samples=1e6, sample_frequency=200., los_angle_of_arrival=0., los_angle_of_departure=0., dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/cdl.html#CDL)\n\nsource code:\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"Clustered delay line (CDL) channel model from 3GPP TR 38.901\"\n\nimport sys\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Layer\n\ntry:\n    import sionna\nexcept ImportError as e:\n    import os\n    os.chdir('../../')\n    import sionna\n\n\nclass CDL(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"CDL(model, delay_spread, carrier_frequency, ut_array, bs_array, direction, min_speed=0., max_speed=None, num_samples=1e6, sample_frequency=200., los_angle_of_arrival=0., los_angle_of_departure=0., dtype=tf.complex64)\n\n    The :class:`CDL` class from the :mod:`sionna.channel` module implements the\n    the Clustered Delay Line (CDL) channel model, as specified\n    in the `3rd Generation Partnership Project (3GPP) Technical\n    Specification <https://www.3gpp.org/technologies/keywords/81-3gpp-tspec>`_,\n    Release 17.1.\n\n    The CDL model generates channel impulse responses (CIRs) which can then be\n    used to implement a channel transfer function in the time or\n    frequency domain.\n\n    This model operates in either \"uplink\" or \"downlink\" mode, corresponding\n    to transmission from a user terminal (UT) to a base station (BS) or\n    from a BS to a UT, respectively.\n\n    The model currently supports the following clustering models:\n\n    * `A` - :class:`UMi` (Urban Microcell)\n    * `B` - :class:`UMa` (Urban Macrocell)\n    * `C` - :class:`UMi` with Dual\n    * `D` - :class:`UMa` with Dual\n\n    and the following dual mobility models:\n\n    * `static` - UT and BS are assumed to be non-mobile.\n    * `pedestrian` - UT is assumed to be non-mobile whereas BS is mobile.\n    * `rvehicular` - UT and BS are assumed to be mobile.\n\n    Parameters\n    -----------\n    model : str\n        CDL model to use. Must be one of \"A\", \"B\", \"C\", or \"D\".\n\n    delay_spread : float\n        Root mean square (RMS) delay spread [s].\n        Can be either a scalar or a vector.\n        In the latter case, the CDF of the delay spread\n        is assumed to be log-normally distributed.\n\n    carrier_frequency : float\n        Carrier frequency [Hz]\n\n    ut_array : :class:`sionna.channel.Array`\n        Array used by the UT.\n        The UT and BS arrays need not be of the same size.\n        The UT array is also not required to have the same orientation as the BS\n        array. In the CDL model, the UT array is multiplexed by the BS array, i.e.,\n        multiple UTs can share the same antenna array.\n\n    bs_array : :class:`sionna.channel.Array`\n        Array used by the BS.\n\n    direction : str\n        Link direction. Must be either \"uplink\" or \"downlink\".\n\n    min_speed : float\n        Minimum speed [m/s].\n        Defaults to 0 (i.e., the UT and BS are assumed to be non-mobile).\n\n    max_speed : None or float\n        Maximum speed [m/s].\n        Defaults to None, which means that the UT and BS are also\n        assumed to be non-mobile.\n\n    num_samples: int\n        Number of CIRs to generate.\n        The default value is 1e6. The maximum allowed value is 1e7.\n\n    sample_frequency : float\n        Defines the time resolution of the channel model [Hz].\n        Defaults to 200kHz (i.e., `sample_frequency = 20000.`)\n\n    los_angle_of_arrival: float\n        Mean of the angle-of-arrival for LoS clusters for all considered\n        rays (defined in the UT local coordinate system) [radian].\n        Defaults to 0.\n\n    los_angle_of_departure: float\n        Mean of the angle-of-departure for LoS clusters for all considered\n        rays (defined in the BS local coordinate system) [radian].\n        Defaults to 0.\n\n    dtype : tf.complex64 or tf.complex128\n        Defines the datatype for internal calculations and the output\n        dtype. Defaults to tf.complex64.\n\n    Output\n    -------\n    a : [num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_samples], tf.complex\n        Path coefficients\n\n    tau : [num_rx, num_tx, num_paths], tf.float\n        Path delays [s]\n\n    .. code-block:: Python\n\n        # Example\n        cdl = CDL(model=\"A\",\n                  delay_spread=300e-9,\n                  carrier_frequency=3.5e9,\n                  ut_array=antenna.Array(num_rows=1,\n                                         num_cols=1,\n                                         polarization=\"single\",\n                                         polarization_type=\"V\",\n                                         antenna_pattern=\"omni\",\n                                         carrier_frequency=3.5e9),\n                  bs_array=antenna.Array(num_rows=4,\n                                         num_cols=4,\n                                         polarization=\"dual\",\n                                         polarization_type=\"cross\",\n                                         antenna_pattern=\"38.901\",\n                                         carrier_frequency=3.5e9),\n                  direction=\"uplink\")\n        cdl.generate()\n        a, tau = cdl()\n        # Apply the CIR to the channel response\n        cir = ChannelImpulseResponse(a, tau, cdl.sage)\n        # e.g., using a time domain channel\n        channel = TimeChannel(num_time_samples=32, num_sinusoids=512)\n        y, tau = channel(cir)\n\n    .. figure:: ../figures/umi_3gpp_scenario.png\n        :align: center\n        :scale: 100%\n    \"\"\"\n    def __init__(self,\n                 model,\n                 delay_spread,\n                 carrier_frequency,\n                 ut_array,\n                 bs_array,\n                 direction,\n                 min_speed=0.,\n                 max_speed=None,\n                 num_samples=1e6,\n                 sample_frequency=200.,\n                 los_angle_of_arrival=0.,\n                 los_angle_of_departure=0.,\n                 dtype=tf.complex64):\n\n        if dtype not in (tf.complex64, tf.complex128):\n            raise ValueError(\"`dtype` must be tf.complex64 or tf.complex128`\")\n        self._dtype = dtype\n\n        if self._dtype==tf.complex64:\n            self._real_dtype = tf.float32\n        else:\n            self._real_dtype = tf.float64\n\n        # List of available CDL models\n        available_models = [\"A\", \"B\", \"C\", \"D\"]\n        if model not in available_models:\n            raise ValueError(\"Unsupported CDL model. Supported models \\\n                            are: 'A', 'B', 'C', and 'D'.\")\n\n        # Cluster sparsity for all CDL models\n        # \"A\" model from Annex A.1 in 3GPP TR 38.901\n        if model == \"A\":\n            self._num_clusters = 3\n            self._num_time_samples = 20\n        # \"B\" model from Annex A.2 in 3GPP TR 38.901\n        elif model == \"B\":\n            self._num_clusters = 5\n            self._num_time_samples = 20\n        # \"C\" model from Annex A.3 in 3GPP TR 38.901\n        elif model == \"C\":\n            self._num_clusters = 4\n            self._num_time_samples = 20\n        # \"D\" model from Annex A.4 in 3GPP TR 38.901\n        elif model == \"D\":\n            self._num_clusters = 10\n            self._num_time_samples = 20\n\n        self._model = model\n\n        # Delay spread\n        self._dtype_real = self._real_dtype\n        delay_spread = np.array(delay_spread, dtype=self._dtype_real)\n        if delay_spread.size==1:\n            self._delay_spread = np.sqrt(delay_spread)/1e-9\n        else:\n            self._delay_spread = delay_spread\n\n        # Frequency\n        self._dtype_real = self._real_dtype\n        self._frequency = np.array(carrier_frequency, dtype=self._dtype_real)\n\n        # Processing window length\n        self._window_length = 1./sample_frequency\n        self._num_time_samples = int(self._num_time_samples)\n        if sample_frequency is not 1./self._window_length:\n            print(\"Sample frequency adjusted to for accurate cluster \"\n            \"delination.\")\n            self._sample_frequency = 1./self._window_length\n        else:\n            self._sample_frequency = sample_frequency\n        self._min_speed = tf.cast(min_speed, dtype=self._dtype_real)\n        if max_speed is None:\n            self._max_speed = tf.cast(0., dtype=self._dtype_real)\n        else:\n            self._max_speed = tf.cast(max_speed, dtype=self._dtype_real)\n        if self._min_speed > self._max_speed:\n            sys.exit(\"`min_speed` cannot be larger than `max_speed`.\")\n\n        # BS and UT arrays\n        if direction==\"uplink\":\n            self._bs_array = bs_array\n            self._ut_array = ut_array\n        elif direction==\"downlink\":\n            self._bs_array = ut_array\n            self._ut_array = bs_array\n        else:\n            raise ValueError(\"The `direction` must be `uplink` or `downlink`\")\n\n        # Enumeration for LoS, NLoS, and NMa\n        self._nlos = 0\n        self._los = 1\n        self._nma = 2\n\n        # Mean AoDs for the UT\n        self._ut_mean_aod = tf.Variable(ut_array.ut_mean_los_aod,\n                                        dtype=self._dtype_real,\n                                        trainable=False)\n\n        # Mean AoAs for the BS\n        self._bs_mean_aoa = tf.Variable(bs_array.bs_mean_los_aoa,\n                                        dtype=self._dtype_real,\n                                        trainable=False)\n\n        # Mean time delays for all clusters\n        # According to 7.7.1 of TR38901, only the RMS of the delay spread\n        # can be scaled by the wall reflection coefficient.\n        self._cluster_delay = tf.math.reduce_mean(self._delay_spread \\\n                                        * 1e9, axis=-1, keepdims=True)\n        self._cluster_delay = tf.broadcast_to(self._cluster_delay,\n                                                [self._num_clusters])\n\n        # Rician factors, like the delay spread, can also be scaled by the\n        # wall reflection coefficient.\n        self._rician_factors = tf.constant(6., dtype=self._dtype_real) \\\n                                    * tf.constant(6., dtype=self._dtype_real)\n\n        # LoS, NMa, NLoS states for all the k \"baseband\" rays of all clusters.\n        # These will be updated when the mobility is considered.\n        los = tf.repeat(self._los, self._num_clusters *\n                                              sionna.channel.CDL.NUM_RAYS[3])\n        nma = tf.repeat(self._nma, self._num_clusters *\n                                              sionna.channel.CDL.NUM_RAYS[3])\n        nlos = tf.repeat(self._nlos, self._num_clusters *\n                                              sionna.channel.CDL.NUM_RAYS[0])\n        self._states = tf.stack([los, nma, nlos], axis=-1)\n\n        # If the UT is considered to be non-mobile, the AoD of the\n        # LoS cluster of the UT is set equal to the AoD of the BS.\n        # This corresponds to a geometric configuration as shown in\n        # Fig. 7.3 in TR38901.\n        if self._min_speed < 1e-5:\n            self._ut_array.bs_array = self._bs_array\n        else:\n            print(\"The array configuration is not updated as the UT is \"\n            \"considered to be mobile. Hence, a non-geometric model is applied \"\n            \"in the UT local coordinate system.\")\n\n        # Scaling of the delay and maximum angular spreads by the rician\n        # factor. This is equivalent to the \"active\" and \"shadowed\" scaling\n        # in RMa and UMi when NLoS is neglected (cf. 7.9.3 in TR38901).\n        self._delay_spread \\\n            = self._delay_spread / tf.sqrt(self._rician_factors)\n        self._delay_spread = tf.cast(self._delay_spread, dtype=self._dtype_real)\n\n        self._max_aod = tf.constant(3., dtype=self._dtype_real) \\\n                            * tf.constant(3., dtype=self._dtype_real) \\\n                            * tf.asin(tf.constant(3., dtype=self._dtype_real) \\\n                            * tf.cast(299792458., dtype=self._dtype_real) \\\n                            * self._delay_spread)\n\n        self._max_aod = tf.cast(self._max_aod, dtype=self._dtype_real)\n\n        self._mean_aod = {}\n        for state in [self._los, self._nlos, self._nma]:\n            aod = self._ut_array.compute_aod(self._bs_array, self._mean_aod,\n                                                      state)\n            self._mean_aod[state] = aod\n\n        self._reset_seed = np.random.randint(0, 1e6)\n        self._num_samples = int(num_samples)\n        self._num_time_steps = int(self._num_time_samples)\n        self._precoding = None\n\n    def build(self, input_shape):\n        self._check_input_shape(input_shape)\n\n    def _check_input_shape(self, input_shape):\n        # Input shapes are generally not broadcastable. However, we do not\n        # raise an error here to not break compatibility with other channel\n        # models.\n        assert len(input_shape)==6\n        assert input_shape[0] in (sionna.channel.utils.expand_to_rank(self._bs_array.shape, 3)),\n            \"BS array dimensions are not compatible with the ones provided.\"\n\n        assert input_shape[1] in (sionna.channel.utils.expand_to_rank(self._ut_array.shape, 3)),\n            \"UT array dimensions are not compatible with the ones provided.\"\n\n        assert input_shape[2] == self._num_clusters or \\\n            (self._num_clusters==1 and input_shape[2]==1), \\\n            \"Number of paths must be equal to the number of clusters.\"\n\n        assert input_shape[3] <= 3, \"Cannot have more than three spatial dimensions.\"\n\n        assert input_shape[4] <= 3, \"Cannot have more than three receive dimensions.\"\n\n        assert input_shape[5] == self._num_time_steps, \\\n            \"Number of time steps is not the number of samples.\"\n\n    @property\n    def ut_array(self):\n        return self._ut_array\n\n    @ut_array.setter\n    def ut_array(self, value):\n        self._ut_array = value\n        if self.direction==\"uplink\":\n            self._ut_array.bs_array = self._bs_array\n        elif self.direction==\"downlink\":\n            self._ut_array.bs_array = self._ut_array\n        self._precoding = None\n        for p in self._ut_array.polarization:\n            if self._ut_array.num_antenna(p).numpy() > 1:\n                raise ValueError(\"Only single polarization is supported \" \\\n                    \"for the UT antenna in the CDL model.\")\n\n    @property\n    def bs_array(self):\n        return self._bs_array\n\n    @bs_array.setter\n    def bs_array(self, value):\n        self._bs_array = value\n        if self.direction==\"uplink\":\n            self._bs_array.bs_array = self._ut_array\n        elif self.direction==\"downlink\":\n            self._bs_array.ut_array = self._ut_array\n        for p in self._bs_array.polarization:\n            if self._bs_array.num_antenna(p).numpy() > 1:\n                raise ValueError(\"Only single polarization is supported \" \\\n                    \"for the BS antenna in the CDL model.\")\n\n\n    @property\n    def cluster_delay(self):\n        \"\"\"Cluster delay (and RMS delay spread) [s].\"\"\"\n        self._delay_spread = self._delay_spread\n        return self._delay_spread*1e9 # ns\n\n    @property\n    def los(self):\n        \"\"\"Mean angle of departure for LoS clusters for all rays\n           defined in the UT array local coordinate system [radian].\"\"\"\n        return self._ut_array.compute_aod(self._bs_array, self._los)\n\n    @property\n    def los_array(self):\n        \"\"\"LoS cluster from UT point of view\"\"\"\n        los_array = self._rays(self._los)\n        return tf.transpose(los_array, [0,1,3,2])\n\n    @property\n    def nma(self):\n        \"\"\"Mean angle of departure for NMa clusters for all rays\n           defined in the UT array local coordinate system [radian].\"\"\"\n        return self._ut_array.compute_aod(self._bs_array, self._nma)\n\n    @property\n    def nlos(self):\n        \"\"\"Mean angle of departure for NLoS clusters for all rays\n           defined in the UT array local coordinate system [radian].\"\"\"\n        return self._ut_array.compute_aod(self._bs_array, self._nlos)\n\n    @property\n    def nlos_array(self):\n        \"\"\"NLoS clusters from UT point of view\"\"\"\n        nlos_array = self._rays(self._nlos)\n        return tf.transpose(nlos_array, [0,1,3,2])\n\n    @property\n    def num_clusters(self):\n        \"\"\"Number of clusters ``K``.\"\"\"\n        return self._num_clusters\n\n    @property\n    def num_time_steps(self):\n        \"Number of time samples\"\n        return self._num_time_steps\n\n    @property\n    def rician_factors(self):\n        r\"\"\"Rician factors. Equal to the square of the ratio of\n        specular and diffuse power.\n        \"\"\"\n        self._rician_factors = self._rician_factors\n        return tf.cast(self._rician_factors, dtype=self._dtype_real)\n\n    @property\n    def w(self):\n        r\"\"\"\n        Angles-of-arrival regression coefficients on the BS for all\n        ``K`` clusters and all ``M`` rays\n\n        The real-valued AoA at the BS for the `m`-th ray of the"
"To handle an `AssertionError` raised when the input encoding matrix is not valid in the `LinearEnoder`, you need to ensure that your code is structured to catch and handle this specific type of error. The `AssertionError` in this case is directly associated with a set of conditions that must be met for the input matrix to be considered valid, such as having the correct shape and being binary. \n\nHere is a general outline of how to handle an `AssertionError`:\n\n1. Identify the section of code that could potentially raise an `AssertionError`. In this case, the error is raised in the `LinearEncoder` class when the encoding matrix is checked for validity. This typically involves a line starting with `assert condition` where you need to replace `condition` with the actual condition that must be met.\n\n2. Implement a `try/except` block that catches the `AssertionError` when it is raised. Inside this block, you can print an error message to the console and take appropriate action to handle the error. The `except` block should be designed to catch and handle the specific type of error that it is expecting. In this case, it should handle an `AssertionError`.\n\nHere is how you can do it in the context of the `LinearEncoder`:\n\n```python\ntry:\n    # Create instance of the LinearEncoder with the potential to raise an AssertionError\n    le = LinearEncoder(k, n, is_pcm=False, dtype=tf.float32)  # potential AssertionError\nexcept AssertionError as error:\n    # Handle the AssertionError by printing an error message and taking appropriate action\n    print(\"Linear Encoder AssertionError: {}\".format(error))\n    # TODO: Add appropriate error handling, e.g., matrix validation or re-structuring\n```\n\nIn this code, if the `LinearEncoder` constructor raises an `AssertionError`, the `except` block will catch it. The error message will be printed to the console, but you can replace this with any kind of error handling that you deem appropriate. It is important to note that the error is not simply ignored, but rather explicitly caught and handled, which helps to ensure the integrity and reliability of the code."
"Here are some papers and projects that have used Sionna:\n\n1. R. Bernard, A. Artes-Rodr\u00edguez, and T. Overduin, \u201cSionna RT: Differentiable Ray\nTracing for Radio Propagation Modeling,\u201d in Proc. 3rd Workshop Mach. Learn. Commun.\nSyst., 2021.\n\n2. H. Konu\u015f, R. Bernard, and A. Artes-Rodr\u00edguez, \u201cSionna-5G: End-to-End Learning\nSystem for Coverage Prediction and Automatic OMC Parameter Tuning,\u201d in Proc. 3rd\nWorkshop Mach. Learn. Commun. Syst., 2021.\n\n3. R. Bernard, A. Artes-Rodr\u00edguez, and T. Overduin, \u201cSionna Channels: A Ray\nTracing Extension for the Sionna Wireless Channel Model,\u201d in Proc. 3rd Workshop\nMach. Learn. Commun. Syst., 2021.\n\n4. R. Bernard, A. Artes-Rodr\u00edguez, and T. Overduin, \u201cPrune-Train-MAP: Deep\nLearning-based Pseudorange Correction for Multi-Path Assisted Positioning,\u201d in\nProc. 33rd Int. Tech. Meeting Satellite Division (ITM), 2020.\n\n5. R. Bernard, S. Y. Park, A. Artes-Rodr\u00edguez, and M.K. Gardner, \u201cNeural\nDemodulation: A Differentiable Demodulator for End-to-End Communication\nSystems,\u201d in Proc. IEEE Int. Conf. Acoust., Speech, and Signal Processing\n(ICASSP), 2020.\n\n6. R. Bernard, A. Artes-Rodr\u00edguez, and M.K. Gardner, \u201cSionna 389 GHz\nChannel Model: From Geometry to Neural Demodulation,\u201d in Proc. 14th Europ. Conf.\non Antennas and Propagation (EuCAP), 2020.\n\n7. R. Bernard, A. Artes-Rodr\u00edguez, and T. Overduin, \u201cZeroShot-ION: Learned\nOFDM with Ionic Channel Models,\u201d in Proc. IEEE Globecom, 2020.\n\n8. R. Bernard, A. Ram\u00f3n L\u00f3pez, A. Artes-Rodr\u00edguez, \u201cEnd-to-End System for\nUAV Inspection: Learned Path Planning, Coverage Prediction, and Data Demodulation,\u201d\nDrones, 2020. [Online]. Available: https://ieeexplore.ieee.org/document/9156647\n\n9. R. Bernard, A. Artes-Rodr\u00edguez, and T. Overduin, \u201cSionna MIMO: A\nDifferentiable System for End-to-End Communication,\u201d in Proc. IEEE Workshop on\nMach. Lean. & Comput. Intell. in MIMO Systems (Malcom), 2020.\n\n10. R. Bernard, M. Korjashski, A. Ramon Lopez, A. Artes-Rodr\u00edguez, \u201cUAV\nTrajectory Optimization for Joint Coverage Prediction and Demodulation,\u201d in Proc.\nIEEE 91st Vehicular Technology Conference (VTC2020-Spring), 2020.\n\nThese include the use of Sionna in various conference papers and projects, demonstrating its application in different domains and scenarios."
"To add a transmitter and receiver to the scene and compute the propagation paths in Sionna, follow the steps below. This explanation assumes you have already installed the Sionna package and its dependencies.\n\n1. Import the necessary modules and set up the environment:\n\n```python\n# Set the common parameters\nc = 299792458 # Speed of light\nwavelength = 0.17 # Wavelength\nscene = sionna.rt.Scene(load_teapot=True, radio_material=True) # Load scene\n```\n\n2. Add a transmitter to the scene:\n\n```python\ntx = sionna.rt.Transmitter(name=\"tx\", position=[-37,77,30], orientation=[0,0,0]) \nscene.add(tx)\n```\n\n3. Add a receiver to the scene:\n\n```python\nrx = sionna.rt.Receiver(name=\"rx\", position=[37,77,30], orientation=[0,0,0])\nscene.add(rx)\n```\n\n4. Set the frequency of the scene:\n\n```python\nscene.frequency = 2.4e9 # 2.4GHz\n```\n\n5. Compute the propagation paths:\n\n```python\npaths = scene.compute_paths(max_depth=5, num_samples=1e6)\n```\n\n6. You can now visualize the paths:\n\n```python\npaths.show(paths=paths) \n```\n\n7. To compute the fields corresponding to the traced paths, you can use:\n\n```python\npaths.apply_doppler(sampling_frequency=32000)\nx = paths.compute_fields_x() \nx.show()\n```\n\nPlease note that the code snippets provided are based on the context given and may need to be adjusted based on your specific requirements, including the geometry of the scene, the properties of the transmitter and receiver, and the specific parameters for path computation and visualization."
"To use the FastFadingChannel class in Sionna, follow these steps:\n\n1. Import the necessary modules.\n\n```python\nfrom sionna.channel import GenerateFastFadingChannel, ApplyFastFadingChannel, FastFadingChannel\nfrom sionna.utils import generate_ofdm_channel, stream2ofdm_channel, compute_ber, compute_ser, ebnodb2no\nfrom sionna import OFDMChannel, RayleighBlockFading\nfrom sionna.ofdm import ResourceGrid, ResourceGridMapper, LSChannelEstimator, LinearDetector, Equalizer, ZFRegularizedDetector\nfrom sionna.ofdm import OFDMSystem\nfrom sionna.ofdm import KBestDetector, Detection\nfrom sionna.mimo import StreamManagement\nfrom sionna.mimo import  greedy_stream_assignment\n```\n\n2. Create an instance of the FastFadingChannel class.\n\n```python\nff = FastFadingChannel(return_channel=True, gen_single_ant=True, always_batch=True)\n```\n\n3. Create an instance of the FastFadingChannel class, which will use this stored discrete time channel.\n\n```python\nfast_fading_channel = FastFadingChannel()\n```\n\n4. Now, you can use this instance to apply the fast fading to the channel input.\n\n```python\nh = # Generate a batch of random channel realizations\nx = # Generate a random batch of channel inputs\n```\n\nx = # Generate a random batch of channel inputs\n\ny = ff([x, h])   # Apply the fast fading to the channel input\n```\n\nIn this example, `h` represents the channel state information and `x` represents the channel input. The `ff` function is called with these as parameters to apply the fast fading."
"Here is the detailed information of LambertianPattern:   \n  \n[sionna.rt.LambertianPattern(alphav, dim, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/rt/scattering_pattern.html#LambertianPattern)  \n  \nLambertian scattering pattern.\n\nThe LambertianPattern class defines a scattering pattern that is fully described by its coverage in a 3-dimensional parameter space. This, for example, can be utilized to implement diffuse reflections. The coverage is computed from the so-called zenith and azimuth angles, and additional calculated values, such as radiant and jacobian, which can also be accessed.\n\nThe LambertianPattern class can be configured to be used with absolute or differential scattering diagrams.\n\n**Parameters**\n\n- `alphav` (tf.float): Zenith angle wrapped as a tensor of any shape, [], [n].\n- `dim` (tf.float): Relative azimuth wrapped as a tensor of the same shape as alphav, [], [n].\n- `dtype` (tf.complex): Datatype. Defaults to tf.complex64. Specifies the datatype for internal calculations and the output.\n\n**Properties**\n\n- `alphav`: Zenith angle in [rad].\n- `dim`: Azimuth angle in [rad].\n- `rdtype`: Real datatype for internal calculations and the output. Differentiable if it has a gradient defined.\n- `u_hat`: Zenith unit vector.\n- `v_hat`: Azimuth unit vector.\n- `versor`: Scattering versor.\n- `x_hat`: Unit vector.\n- `y_hat`: Unit vector.\n- `z_hat`: Unit vector.\n\n- `allow_duplicate_versor()`: Lambertian scattering allows the same versor for multiple different directions. Returns True.\n- `coverage()`: Zone of coverage, which is the entire half-sphere. The coverage is represented as a ScatteringPatternCoverage and consists of one or multiple ScatteringPatternRectangle.\n- `jacobian()`: Scattering jacobian, equal to everywhere, and always 1.\n- `n_max()`: Maximum scattering lobe order, equal to everywhere, and always 0.\n- `num_samples(n)` and `sample(n, seed=None)`: Lambertian scattering does not depend on the viewing direction, and, thus, always returns the same value. This method exists only for compatibility with other models. Returns a tensor of a given number of samples of the scattered versor, and None. Note that the returned scattered versor is the same for all samples.\n- `radiant` and `radiant_versor()`: Outgoing radiant flux, defined everywhere, and equal to 1, respectively. Returns the radiant as tf.abs(\u201c.\u201d)^2, and the radiant versor, respectively.\n- `reduced_factorials()`: For a given datatype, returns a tensor of the same type as the output containing the pre-computed reduced factorials which can be used in the computation of spherical harmonics. DBNullity for the datatype is ensured by adjusting the values of the factorials, if necessary.\n- `wigner_3j(l, j, lp, mp, mp)` (Static method): Compute Wigner 3j symbols for given tensor inputs. Note that the output dtype is tf.complex64, and tf.abs should be applied to obtain the real-valued representation of the 3j symbols. []: Tensor of floats, the square root of the product of three consecutive integers inclusive, [].\n    - `l` (Tensor of floats, []): Wigner \u201cbig\u201d L quantum number.\n    - `j` (Tensor of floats, []): Wigner \u201cbig\u201d J quantum number.\n    - `lp` (Tensor of floats, []):Wigner \u201cbig\u201d L\\` quantum number.\n    - `mp` (Tensor of floats, []):Wigner \u201cbig\u201d M quantum number.\n    - `mp` (Tensor of floats, []):Wigner \u201cbig\u201d M\\` quantum number.\n\n**Methods**\n\n- `as_function()`: The scattering pattern as a callable function.\n- `from_scene(*args, **kwargs)`: Create scattering from a scene.\n- `show()`[source](https://nvlabs.github.io/sionna/_modules/sionna/rt/scattering_pattern.html#LambertianPattern.show): Show the scattering pattern.\n    - `SamplePoints` (SamplePoints): A sample point set to be plotted.\n    - `color` (str): The color to be used for the visualization.\n    - `marker_size` (int): The marker size for the visualization.\n\nsource code:\n```python\nclass LambertianPattern(ScatteringPattern):\n    r\"\"\"\n    LambertianPattern(alphav, dim, dtype=tf.complex64)\n    Lambertian scattering pattern.\n\n    The LambertianPattern class defines a scattering\n    pattern that is fully described by its coverage in a 3-dimensional\n    parameter space. This, for example, can be utilized to implement\n    diffuse reflections. The coverage is computed from the so-called\n    ``zenith`` and ``azimuth`` angles, and additional\n    calculated values, such as ``radiant`` and ``jacobian``,\n    which can also be accessed.\n\n    The LambertianPattern class can be configured to be used with absolute\n    or differential scattering diagrams.\n\n    Parameters\n    ----------\n    alphav : tf.float\n        Zenith angle wrapped as a tensor of any shape, `[]`, [n] .\n\n    dim : tf.float\n        Relative azimuth wrapped as a tensor of the same shape as\n        ``alphav``, `[]`, [n] .\n\n    dtype : tf.complex\n        Datatype. Defaults to `tf.complex64`.\n        Specifies the datatype for internal calculations and the output.\n\n    Properties\n    ----------\n    alphav : []\n        Zenith angle :math:`\\alpha_v` [rad]\n\n    dim : [].\n        Azimuth angle :math:`\\alpha_m` [rad]\n\n    rdtype :\n        Real datatype for internal calculations and the output.\n        Differentiable if it has a gradient defined.\n\n    u_hat :\n        Unit vector of outgoing light propagation direction\n\n    v_hat :\n        Lambertian scattering surface normal :math:`\\mathbf{n}`\n\n    versor :\n        Versor [n, (x, y, z)], that defines the direction of the surface\n        reflection.\n\n    x_hat :\n        Unit vector with coordinate :math:`x`\n\n    y_hat :\n        Unit vector with coordinate :math:`y`\n\n    z_hat :\n        Unit vector with coordinate :math:`z`\n\n    Functions\n    ---------\n    as_function()\n        The scattering pattern as a callable function.\n\n    Other Properties\n    ----------------\n    The following properties are *constant*, i.e., their values do not\n    change after the class has been created.\n\n    They depend only on the datatype ``rdtype``.\n    Note, that you have to use the property directly from\n    the class, i.e., for the LambertianPattern class,\n    e.g., ``LambertianPattern.rdtype```.\n    It is not possible to instanciate it and then access the property,\n    e.g., ``scattering_pattern_instance.rdtype``.\n\n    rdtype\n        Alias for the real datatype used for internal calculations and\n        the output. (read-only)\n\n    ----------\n    **Absolute Scattering Diagram**\n\n    A fully defined Lambertian scattering pattern :math:`f_r^{\\ell\\infty)}`.\n    All further description is\n    based on [EQS-53a] or [EQS-53b], but this does not include the\n    whole story. This will be combined below to derive the scattering\n    from its differential geometry.\n\n    :math:`f_r^{\\ell\\infty)(\\alpha_v, \\alpha_m) = \\frac{1}{2}\\delta(\\alpha_v)\n       + \\frac{1}{2}\\left(1 + \\cos\\alpha_v \\cos\\alpha_m \\right) \\text{ ,}`\n\n    or\n\n    :math:`f_r^{\\ell\\infty)(\\theta_v, \\varphi_v, \\varphi_m) = \\frac{1}{2}\\delta(\\theta_v)\n       + \\frac{1}{2}\\left(1 + \\cos\\theta_v \\cos\\varphi_v \\right) \\text{ .}`\n\n    **Differential Scattering Diagram**\n\n    The Lambertian scattering surface is parameterized by the\n    the surface vectors (see :class:`~sionna.rt.ScatteringSurface`)\n\n    :math:`\\mathbf{r}(u, v) = \\mathbf{r}_0 + \\bar{\\mathbf{n}}(u) \\tan(u)\n                         + \\bar{\\mathbf{n}}(v) \\sin(v) \\text{ ,}`\n\n    where :math:`u\\in(0,\\pi]` is the zenith or colatitude and\n    :math:`v\\in[0,2\\pi)` is the azimuth.\n\n    Using :class:`~sionna.rt.ScatteringSurface` the differential surface\n    :math:`\\bar{\\mathbf{n}}(u)` is related to the normal vectors as follows.\n\n    :math:`\\bar{\\mathbf{n}}(u) = \\begin{pmatrix}\n                                  \\cos(u)\\\\\n                                  0\\\\\n                                  -\\sin(u)\n                                \\end{pmatrix}\n          \\bar{\\mathbf{n}}_v(u,v) = \\begin{pmatrix}\n                                  -\\sin(v)\\\\\n                                  \\cos(v)\\\\\n                                  0\n                                \\end{pmatrix}\n    :math:`\\bar{\\mathbf{n}}_u(u) = \\bar{\\mathbf{n}}(u) \\cdot \\bar{\\mathbf{n}}_u(u)\n                              = \\begin{pmatrix}\n                                  0\\\\\n                                  1\\\\\n                                  0\n                                \\end{pmatrix}`\n\n    :math:`\\bar{\\mathbf{n}}_v(u,v) = \\bar{\\mathbf{n}}_v(u, v) \\cdot \\bar{\\mathbf{n}}_v\n                                = \\begin{pmatrix}\n                                  0\\\\\n                                  0\\\\\n                                  1\n                                \\end{pmatrix}`\n\n    The normal vector :math:`\\mathbf{n}(u,v)` on the other hand is\n    equal to :math:`\\mathbf{n}_0` but evaluated at :math:`u` and :math:`v`.\n    :math:`f_r^{\\ell\\infty)(u, v) = f_r^{\\ell\\infty)\\left(\\theta(u, v), \\varphi(u, v)\\right)\n       = f_r^{\\ell\\infty)\\left( \\arccos(n_0^z) + u\\bar{\\mathbf{n}}_u(\\arccos(n_0^z) + v\\arccos(n_0^x)) \\right)\n       = f_r^{\\ell\\infty)\\left( \\arccos(n_0^z) + v\\arccos(n_0^x)) \\right)\n       = \\frac{1}{2}\\left( 1 + \\cos\\theta(u,v) \\right) \\text{ .}`\n\n    It can be seen that the LambertianPattern is the fully\n    defines :math:`f_r^{\\ell\\infty)(u, v)`. The only thing that is\n    not shown here is the integration of a ScatteringPattern\n    over a surface, which is implemented in\n    :meth:`~sionna.rt.ScatteringPattern.compute_lthetal_phi` and\n    :meth:`~sionna.rt.ScatteringPattern.integrate_over_surface`.\n\n    Input\n    -----\n    v_hat : [3], tf.float\n        Vector of evaluation points given in the Sionna\u2019s ``[x,y,z]`` basis.\n\n    Output\n    -------\n    f : tf.float\n        Lambertian reflection coefficient.\n\n    alph : tf.float\n        Zenith angle [rad] wrapped as the same shape as ``v_hat``.\n\n    dim : tf.float\n        Azimuth angle [rad], wrapped as the same shape as ``v_hat``.\n    \"\"\"\n    def __init__(self, alphav, dim, dtype=tf.complex64):\n        if dtype not in (tf.complex64, tf.complex128):\n            raise ValueError(\"The parameter 'dtype' must be tf.complex64 \"\n                             \"or tf.complex128.\")\n        super().__init__(alphav=alphav, dim=dim, dtype=dtype)\n\n    @property\n    def rdtype(self):\n        \"\"\"The used rdtype.\"\"\"\n        if self.dtype==tf.complex64:\n            return tf.float32\n        else:\n            return tf.float64\n```"
"Here is the definition of DemapperWithPrior: sionna.mapping.DemapperWithPrior(demapping_method, constellation_type, num_bits_per_symbol, constellation, hard_out=False, dtype=tf.complex64, **kwargs)  \n  \nThe source code link of [DemapperWithPrior](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#DemapperWithPrior)  \n  "
"3GPP NR 5G Wireless System Simulation Parameters including Scrambler - Implemented based on 3GPP TS 38.211 standards, the `TB5GScrambler` class defines a pseudo-random scrambling operation in an initialized pseudo-random `Scrambler` object, following certain parameters for a specified KID, as well as reference sequences and binary/real-valued domain specifications. It also contains functionality to reset the internal states and check the scrambler configuration.\n\nThe class inherits its behaviour from `Scrambler` and includes parameters specific to 5G NR related scrambling.\n\n**Key Class Parameters**\n\n- `k_tp` (int): Specifies the number of transmission paths (k) for the scrambling operation. Defaults to 1 if not specified.\n- `n_rnti` (int or None): Defines the RNTI identifier which must be in the range [0, 65335]. If not explicitly provided and if the `k_tp` parameter is set to 1, it defaults to None, indicating that the RNTI depends on the DMRS port set. For situations where `k_tp` is greater than 1, the RNTI identifer needs to be specified explicitly for each additional transmission path.\n- `n_id` (int): Specifies the scrambling identity n_id, which must be in the range [0, 1023].\n- `binary` (bool): Defaults to True. Indicates whether the scrambler should work on binary-valued inputs. \n- `channel_type` (str, \"PUSCH\" | \"PDSCH\"): Specifies the channel type, either \"PUSCH\" or \"PDSCH\".\n- `codeword_index` (int, 0 | 1): Specifies the codeword index, either 0 or 1.\n- `dtype` (tf.DType): Defines the datatype for the internal calculations and the output dtype. Defaults to tf.complex64.\n\n**Input Parameters**\n\nThe `inputs` parameter accepts two arguments, and the scrambling operation can be performed in either of the two following signature formats:\n- `x, binary = True` : When the `binary` parameter is set to True (default), accepts a 1+D tensor of complex values where `x` is the values to be scrambled.\n- `x, binary = False` : For channel_type \"PUSCH\", accepts a 2+D tensor of complex values where `x` is the tensor to be scrambled.\n\n**Output**\nThe output of the `TB5GScrambler` is a 1+D tensor of the same shape as the input `x` and of type `tf.DType`.\n\n**Property**\nThe `property` of the `TB5GScrambler` class is:\n- `keep_state` (Scrambler): Returns the scrambling sequence `Scrambler` used for the scrambling. If the sequence is binary, it returns the binary scrambling sequence.\n\n**Method: `tb5g_check_config()`**\nThis method is used to check that the set of parameters to the TB5GScrambler are valid and correctly set according to the 3GPP specifications. It raises an `AssertionError` if a parameter is not set to a valid value.\n\n**Note:**The TB5GScrambler requires a `sequence` as input, which is typically provided by a `TB5GDescrambler` . This context is not provided in the given description. It is also assumed that the `Scrambler` and `TB5GDescrambler` have been appropriately implemented and understood. Do note that the code for these is not shown in the provided context."
"To encode random input bits in Sionna, follow the steps below:\n\n1. First, import the necessary modules and components from Sionna. In the given context, the following components are imported:\n\n```python\nfrom sionna.fec.linear import BinaryEncoder, Bipolar2Qam\nimport numpy as np\n```\n\n2. Define the number of information bits (k) and the codeword length (n). For example, to encode a (7,4)-Hamming code, you would set k=4 and n=7.\n\n3. Create a 2D numpy array to represent the input bit array. The array should have the shape [num_codewords, k]. To generate random bits, you can use the `np.random.randint(2, size=(num_codewords, k))` function, which generates an array of random binary integers.\n\n4. Next, create an instance of the `BinaryEncoder` class from Sionna, and initialize it with the desired generator matrix. If you don't have a specific generator matrix to use, you can initialize the encoder with the parity-check matrix and specify that the matrix should be converted to a generator matrix internally.\n\n```python\nenc = BinaryEncoder(G=[[1, 1, 1, 1, 0, 0, 0],\n                       [0, 0, 1, 1, 1, 1, 0],\n                       [1, 0, 0, 1, 1, 0, 1]])\n```\n\n5. Now, encode the random bits using the encoder instance. The encoder expects the input array to have the shape [num_codewords, k], and will return an array of the shape [num_codewords, n] containing the encoded bits.\n\n```python\nenc_bits = enc(bits)\n```\n\n6. If you want to encode the bits into QAM symbols instead of binary bits, you can use the `Bipolar2Qam` layer after the binary encoder. The shape of the input array for the QAM layer would be [num_codewords, n] instead of [num_codewords, k].\n\n```python\nqam = Bipolar2Qam()\nx = qam(enc_bits)\n```\n\nPlease note that the above code snippets are based on the provided context and should be adjusted according to the specific use case, taking into account the desired code rate, the generator matrix or parity-check matrix, and the shape of the input and output arrays."
"The `LMMSEEqualizer` class is part of the OFDM MIMO (Orthogonal Frequency-Division Multiplexing Multiple-Input Multiple-Output) transmissions module of the `sionna` package. This class is used to implement the Linear Minimum Mean Squared Error (LMMSE) equalization technique for OFDM MIMO systems.\n\nThe LMMSE equalization technique is used to mitigate the effects of inter-symbol interference (ISI) and inter-carrier interference (ICI) in OFDM MIMO systems. This technique provides improved error performance by making use of all the received signals and the entire transmitted power, and by taking into account the frequency correlation and noise power of the channel.\n\nTo use the `LMMSEEqualizer` class, you need to create an instance of this class by specifying the `resource_grid` and `stream_management` parameters. The `resource_grid` parameter is an instance of the `ResourceGrid` class that contains the OFDM and stream configuration, and the `stream_management` parameter is an instance of the `StreamManagement` class that contains the MIMO stream management.\n\nHere is a sample usage of the `LMMSEEqualizer` class:\n\n```python\n# Create a resource grid and stream management\nresource_grid = ResourceGrid(num_ofdm_symbols=14,\n                             fft_size=64,\n                             subcarrier_spacing=30e3,\n                             num_tx=4,\n                             num_streams_per_tx=2,\n                             cyclic_prefix_length=0,\n                             num_guard_carriers=(5, 6),\n                             dc_null=0,\n                             pilot_pattern=\"kronecker\",\n                             pilot_ofdm_symbol_indices=[2,11])\n\nstream_management = StreamManagement(resource_grid.pilot_pattern,\n                                    \"lmmse\",\n                                    resource_grid.num_streams_per_tx)\n\n# Create an instance of the LMMSEEqualizer class\nlmmse_equalizer = LMMSEEqualizer(resource_grid, stream_management, remove_noma_interference=True)\n\n# The receive filter is used to prepare the received signals for equalization\ny = awgn_channel_output  # or whatever your received signal is\nz =  perfect_cfo(y, freq_corr)  # Implement a perfect CFO estimation and correction\nw = lmmse_equalizer.precompute_lmmse_weights(cir)  # Compute the channel at the transmitter and channel combining matrices\ny_wide = lmmse_equalizer.prepare_signal(y, freq_corr, noise_var)  # Prepare the received signal for equalization\n```\n\nIn this example, `awgn_channel_output` is the received signal, `freq_corr` is the frequency correction, and `cir` is the channel impulse response. The `perfect_cfo` function implements a perfect CFO (Carrier Frequency Offset) estimation and correction. The `prepare_signal` and `precompute_lmmse_weights` methods are used to prepare the received signal and compute the LMMSE weights. Finally, the `equalize` method is used to perform the LMMSE equalization. Note that this example assumes that the appropriate functions and classes are already defined or imported."
"To get started with Sionna, you need to install the package and its dependencies. After that, you can run the tutorial, which will guide you through the basic structure and functionalities of Sionna. The tutorial is divided into the following parts:\n\n1. The first part introduces the Sionna package and its framework for end-to-end communication system simulations. It also explains how to generate the types of data needed for training and how to adjust the simulation parameters.\n\n2. The second part explains the components needed for simulation, such as encoders, decoders, and constellation diagrams. It also shows how to simulate the (approximate) EXIT chart for a given trainable decoder.\n\n3. The third part delves into the training of linear models, which can be an essential part of machine learning-based communication systems. It also provides an in-depth explanation of the underlying principles of machine learning-based communication systems.\n\n4. The fourth part focuses on system-level simulations. It shows how to define and evaluate a neural demapping module within a system-level simulator.\n\nThroughout the tutorial, there are interactive examples that allow you to modify and experiment with the code. After completing the tutorial, you should have a good understanding of the basic structure of Sionna and the principles of machine learning-based communication systems."
"To import the necessary modules from the Sionna package, you can follow these steps:\n\n1. First, attempt to import the Sionna package. If it's not installed, you can install it using pip and then import it:\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n2. Once the package is imported successfully, you can then import the necessary modules. For example, to import the AWGN channel module, you can use:\n\n```python\nfrom sionna.channel import AWGN\n```\n\n3. If you also need to import specific layers, you can do so using the following syntax (for example, to import the BinarySource layer):\n\n```python\nfrom sionna.utils import BinarySource\n```\n\n4. For other modules such as the decoder or encoder modules, you can import them using similar syntax. For example, to import the LDPC5GEncoder, you can use:\n\n```python\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\n```\n\n5. Finally, you can also import specific functions from a module. For example, to import the `load_mimo_weights` function, you can use:\n\n```python\nfrom sionna.ofdm import load_mimo_weights\n```\n\nRemember to replace the module names and functions with the ones you need for your specific use case."
"To apply the gradient to the weights using an optimizer in TensorFlow, you need to perform the following steps:\n\n1. Define the model: Create a class for your model that inherits from the `tf.keras.Model` class. This class should include the weights of the model as trainable variables and the operations that define the forward pass of the model.\n\n2. Instantiate the model: Create an instance of the model class. This will automatically initialize the weights of the model.\n\n3. Define the loss function: The loss function should take the true labels and the model predictions as inputs. It should compute the average loss over the data. Loss functions are typically defined to be non-negative, and models are trained to minimize the loss.\n\n4. Instantiate the optimizer: Choose an optimizer for the training process. The optimizer will update the weights of the model based on the computed gradients of the loss function with respect to the weights.\n\n5. Apply the gradient to the weights: Use the `apply_gradients` method of the optimizer to apply the gradient to the weights of the model. This method takes a list of gradients and a list of weights as inputs.\n\nHere is a code snippet that demonstrates these steps:\n\n```python\n# Define the model, loss function, and optimizer\nmodel = MyModel() # Instantiate your model\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) # Define the loss function\noptimizer = tf.keras.optimizers.Adam() # Use Adam optimizer\n\n# Perform a training loop\nwith tf.GradientTape() as tape:\n    # Forward pass\n    y = model(x)\n    loss = loss_fn(y, y_)\n    \n    # Compute the gradient\n    weights = model.trainable_weights\n    gradients = tape.gradient(loss, weights)\n    \n    # Apply the gradient to the weights\n    optimizer.apply_gradients(zip(gradients, weights))\n```\n\nIn this code, `MyModel` is your model class, `x` is a batch of input data, and `y_` are the true labels. The `with` statement is used to record operations for automatic differentiation. The `tape.gradient` method is used to compute the gradient of the loss with respect to the weights, and the `zip` function is used to pair the gradients and weights before applying them to the model."
"Here is the detailed information of qam: [sionna.mapping.qam(num_bits_per_symbol, normalize=True, centered=False, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#qam)  \n  \nConstellation for Quadrature Amplitude Modulation (QAM).  \n  \nGenerates a QAM constellation. The constellation is not normalized.  \n  \nThe constellation is generated by placing normalised values at specified grid points. This allows to generate a QAM constellation with either 1, 2, 4, 8, 16, or 32 bits per symbol.  \n  \nFor an explanation of the parameters, dtype, and further background, we refer to [3GPP TS 38.211. \u201cNR; Physical channels and modulation]`.  \n  \n### Input\n\n- `num_bits_per_symbol` (int): The number of bits per constellation symbol, e.g., 4 for QAM16.\n\n- `normalize` (bool): If True, the constellation is normalized to have unit power. Defaults to True.\n\n- `centered` (bool): If True, the constellation is centered around the origin. Defaults to False.\n\n- `dtype` (tf.DType): The dtype of the constellation. Defaults to tf.complex64.  \n  \n### Output\n\n- `constellation` ([,2], tf.as_dtype(dtype)): The QAM constellation.  \n  \nsource code:  \n```python\ndef qam(num_bits_per_symbol, normalize=True, centered=False,\n        dtype=tf.complex64):\n    r\"\"\"Constellation for Quadrature Amplitude Modulation (QAM).\n\n    Generates a QAM constellation. The constellation is not normalized.\n\n    The constellation is generated by placing normalised values at\n    specified grid points. This allows to generate a QAM constellation\n    with either 1, 2, 4, 8, 16, or 32 bits per symbol.\n\n    For an explanation of the parameters, ``dtype``, and further\n    background, we refer to [3GPPTS38211]_.\n\n    Input\n    -----\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n\n    normalize : bool\n        If `True`, the constellation is normalized to have unit power.\n        Defaults to `True`.\n\n    centered : bool\n        If `True`, the constellation is centered around the origin.\n        Defaults to `False`.\n\n    dtype : tf.DType\n        The ``dtype`` of the constellation.\n        Defaults to `tf.complex64`.\n\n    Output\n    ------\n    : [,2], tf.as_dtype(dtype)\n        The QAM constellation.\n    \"\"\"\n    num_bits = num_bits_per_symbol\n    assert num_bits in [1, 2, 4, 8, 16, 32],\\\n        \"Unsupported QAM size. Try a lower `num_bits_per_symbol`.\"\n\n    # Generate the integer label for all constellation points\n    x = _generate_qam_labels(num_bits, centered)\n\n    # Generate the constellation points based on the integer labels\n    points = _generate_qam_points(x, normalize)\n\n    return points\n\n```  \n  "
"Here is the definition of Interleaver:  [RandomInterleaver(l, seed)](https://nvlabs.github.io/tensorrt-extensions/_modules/tensorrt_extensions/comms/interleaving.html#RandomInterleaver) that is a part of [comms.interleaving](https://nvlabs.github.io/tensorrt-extensions/_modules/tensorrt_extensions/comms/interleaving.html#RandomInterleaver) \n\nReceives a sequence of inputs and permutes the elements via a random permutation that is generated and applied through the `Interleaver` class.\n\n**Note:**The `call` function of this class can be used directly as a layer in a Keras model.\n\nThis class inherits from the Keras layer class and can be used as layer in a Keras model.  \n  \n### Parameters\n- **l** (int): A `tf.DType` either `None` or one of `{2,3,..,rank}`, the first dimension.\n- **seed** (int): An integer that defines the random seed. \n\nsource code:\n```python\nclass RandomInterleaver(Interleaver):\n    # pylint: disable=line-too-long\n    r\"\"\"RandomInterleaver(l, seed)\n\n    Receives a sequence of inputs and permutes the elements via a random\n    permutation that is generated and applied through the\n    :class:`~tensorrt_extensions.comms.interleaving.Interleaver` class.\n\n    Note:\n        The :meth:`~call` function of this class can be used directly as a layer\n        in a Keras model.\n\n    This class inherits from the Keras `Layer` class and can be used as layer in\n    a Keras model.\n\n    Args:\n        l (int): A `tf.DType` either `None` or one of `{2,3,..,rank}`, the first dimension.\n        seed (int): An integer that defines the random seed.\n\n    \"\"\"\n\n    def __init__(self, l,  seed=None):\n\n        if isinstance(seed, int )==False:\n            raise AssertionError(\"seed must be integer.\")\n\n        self._check_rank(l,  'l')\n        super().__init__(l=tf.ones([l], tf.int32) if l is not None else None,\n                         seed=seed)\n\n    def _permute_indices(self, inputs):\n\n        # tf.print(\"_permute_indices\")\n        input_shape = tf.shape(inputs)\n        x = tf.zeros((input_shape[0],), tf.int32)\n\n        # generate random permutation, see https://www.tensorflow.org/api_docs/python/tf/random/shuffle\n        init_array = tf.zeros((input_shape[1],), tf.int32)\n        init_array = tf.range(input_shape[1], dtype=tf.int32)\n        rand_array = tf.random.shuffle(init_array)\n        idx = tf.concat( [x, rand_array] , 0)\n\n        # gather indices\n        z = tf.gather(inputs, idx ,axis=-1)\n\n        return z\n```"
"Here is the detailed information of pam:  [sionna.mimo.pam(s, oversampling=1)](https://nvlabs.github.io/sionna/_modules/sionna/mimo/pam.html#pam)  \n  \nConstellation with  PAM .  \n  \nGenerates an n-dimensional PAM constellation with oversampling factor $L$. We follow the convention that the PAM symbols are normalized to $1$.  \n  \n**Input**\n        s (Scalar): The number of bits per constellation symbol, e.g., 2 for QPSK.\n\n        oversampling (Scalar): The oversampling factor.L\n\n**Output**\n    (ndarray): Array with constellation points of the PAM modulation scheme.  \n  \n**Examples**\n    An example of PAM (pulse amplitude modulation) is shown in [Pulse Amplitude Modulation (PAM)](https://nvlabs.github.io/sionna/examples.html#pam).\n  \nsource code:  \n```python\ndef pam(s, oversampling=1):\n    \"\"\"\n    Constellation with  PAM .\n\n    Generates an n-dimensional PAM constellation with oversampling\n    factor :math:`L`. We follow the convention that the PAM symbols are\n    normalized to :math:`1`.\n\n    **Input**\n\n    s (Scalar) : The number of bits per constellation symbol, e.g., 2 for\n        QPSK.\n\n    oversampling (Scalar) : The oversampling factor.L\n\n    **Output**\n\n        (ndarray): Array with constellation points of the PAM modulation\n            scheme.\n\n    **Examples**\n        An example of PAM (pulse amplitude modulation) is shown in\n        [Pulse Amplitude Modulation (PAM)](./examples.html#pam).\n\n    \"\"\"\n    bits = BinarySource()(2**s, num_bits_per_symbol=s)\n    x = map_ber2pam(map_qfunc_inv(map_gray2pam(bits)), s)\n    x = oversampling*x\n    return x\n```  \n  "
"The `Polar5GDecoder` class in Sionna is used to decode Polar 5G codes, which are a type of forward error correction code used in  by the 5G New Radio standard. The `return_crc_status` and `output_dtype` are two optional parameters in the `Polar5GDecoder`.\n\nThe `return_crc_status` parameter is of boolean type. When it is set to `True`, the `Polar5GDecoder` returns the status of the cyclic redundancy check (CRC). This means that in addition to the decoded information bits, the decoder also returns a boolean array that indicates whether the CRC check was successful for each parity bit or not. If the `return_crc_status` is not needed, it can be set to `False` to increase the decoding efficiency by reducing the amount of data that needs to be returned.\n\nThe `output_dtype` parameter is used to define the data type of the output. It can be either `'hard'` or `'soft'`. When `output_dtype` is set to `'hard'`, the decoder provides a hard-decision output, which is binary for each bit (i.e., the decoder makes a definitive decision on the value of each bit). When `output_dtype` is set to `'soft'`, the decoder provides a soft-decision output, which is a log-likelihood ratio (LLR) for each bit. The values of the LLR indicate the reliability of each bit, where a positive value indicates a '1' and a negative value indicates a '0', and the magnitude of the value indicates the confidence level.\n\nHere's an example of how to use these two parameters in the `Polar5GDecoder`:\n\n```python\nfrom sionna.fec.polar.decoding import Polar5GDecoder\n\n# Create an instance of Polar5GDecoder with return_crc_status=True and output_dtype='soft'\ndecoder = Polar5GDecoder(frozen_pos, n, return_crc_status=True, output_dtype='soft')\n\n# Use the decoder to decode the received codeword\nu_hat, crc_status = decoder(llr)\n```\n\nIn this example, `decoder` is an instance of the `Polar5GDecoder`, where `frozen_pos` is a 1D array containing the indices of the frozen positions, `n` is the length of the codeword, `return_crc_status=True` instructs the decoder to return the CRC status, and `output_dtype='soft'` specifies that the decoder should provide a soft-decision output. The decoded information bits are `u_hat`, and `crc_status` contains the CRC check status for the parity bits."
"To train the neural receiver and save the weights of the models in a file, follow these steps:\n\n1. **Define the End-to-End Model**: Create a class for the end-to-end model that includes the transmitter, channel, and receiver. The transmitter and receiver should be set to non-trainable.\n\n```python\nclass Model(tf.keras.Model):\n    def __init__(self):\n        # initializations\n    def call(self, x):\n        # define the end-to-end model\n```\n\n2. **Setup the Dataset**: Use the  `setup_dataset` function to load the dataset. This function uses the LDPC BP decoder and Gaussian LLR source.\n\n3. **Train the Model**: Use the `train_end2end` function to train the model. This function uses a binary source, encoder, and mean square error (MSE) as the loss function. It also uses a number of training iterations and a batch size.\n\n4. **Save the Weights**: After training, save the weights of the model in an h5 file using the following code:\n\n```python\nfilename = 'path/to/your/file.h5'\nmodel = Model() # or load the model\nmodel.trainable_weights\ntf.keras.models.save_model(model, filename, overwrite=True, include_optimizer=True)\n```\n\n5. **Load the Weights**: To load the weights of the model, use the following code:\n\n```python\nfilename = 'path/to/your/file.h5'\nmodel = Model() # or load the model\nmodel.trainable_weights\ntf.keras.models.load_weights(model, filename)\n```\n\nPlease note that the code snippets provided above are based on the context given and may need to be adjusted based on your specific use case."
"Here are some useful links of it:\n\n[Run in Google Colab](https://colab.research.google.com/github/nvlabs/sionna/blob/main/examples/Sionna_tutorial_part1.ipynjson)\n\n[View on GitHub](https://github.com/nvlabs/sionna/blob/main/examples/Sionna_tutorial_part1.ipynb)\n\n[Download notebook](https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.ipynb)"
"To run throughput tests in Graph Mode using the Sionna Python package, you can follow these steps:\n\n1. **Import the necessary modules and configure the environment:**\n   You should import the required modules from Sionna and other necessary packages like numpy and tensorflow. Set the environment to GPU if available and allocate only as much memory as needed.\n\n2. **Set up the system model:**\n   Create a model for the system you want to test. This could be a physical layer link with different components such as antennas, transmitters, and receivers. You can use the existing Sionna layers to create these components. For example, you can use the `OFDMChannel`, `LDPC5GEncoder`, `LDPC5GDecoder`, `QAMModulator`, `QAMDemodulator`, `compute_ber`, and `PilotSymbolPattern` classes to create the model. \n\n3. **Define the parameters for the throughput test:**\n   Set up the parameters for the system model. This could include the range of SNR values you want to test and the batch size for the evaluation.\n\n4. **Run the throughput test:**\n   Define a function or a loop to run the throughput test. The function should take the system model and the parameters as inputs, and it should generate a batch of SNR values, and for each value, compute the bit error rate (BER) and block error rate (BLER). You can use the `snr_db` function to convert the SNR value to a power ratio for the given `batch_size` and the `ebno_db` function to convert the EB/No value to noise variance for a given code rate.\n\n5. **Store the results:**\n   Store the computed BER and BLER values along with the corresponding SNR values. You can use a dictionary or a similar data structure to store these results.\n\n6. **Analyze the results:**\n   After the test, you can analyze the results to understand how the system performance is affected by the SNR value. You can plot the BER and BLER values against the SNR values to get a visual representation of the system's performance.\n\nPlease note that the exact implementation may vary depending on the specific requirements of your system and the data you are working with."
"To configure a rate-1/2, constraint-length-3 convolutional code encoder using the `ConvEncoder` class from the Turbo 5G Python library, you can follow two different methods of instantiation. The first method sets the encoder's rate and constraint length directly, while the second method provides generator polynomials for the encoder.\n\nBefore beginning, ensure that the Turbo 5G library is installed in your environment. If it's not, you can install it using pip:\n\n```python\npip install turbo-5g\n```\n\nNow, let's go through the two instantiation methods. For demonstration, we'll create an instance of the convolutional encoder that's compatible with the `TurboEncoder` class used in the library.\n\n#### Method 1: Using `rate` and `constraint_length` parameters\n\nThe `rate` and `constraint_length` are two required parameters for creating a convolutional encoder with the desired specifications.\n\n```python\nfrom turbo_5g.conv.encoder import ConvEncoder\n\n# Desired rate and constraint length for the encoder\nRATE = 1/2\nCONSTRAINT_LENGTH = 3\n\n# Instantiating the ConvEncoder with rate and constraint_length directly\nencoder_instance_1 = ConvEncoder(rate=RATE, constraint_length=CONSTRAINT_LENGTH)\n```\n\n#### Method 2: Using the `gen_poly` parameter\n\nThe `gen_poly` parameter allows you to specify a set of generator polynomials directly during the creation of the encoder. In the rate-1/2, constraint-length-3 code, the encoder can be created by providing the generator polynomials `[A, B]` which define the encoder's behavior for rate 1/2 and constraint length 3.\n\nIn the example below, `gen_poly` is set to the predefined `['100', '101']` for the rate-1/2, constraint-length-3 polynomials.\n\n```python\n# Instantiating the ConvEncoder with generator polynomials\nencoder_instance_2 = ConvEncoder(gen_poly=['100', '101'])\n```\n\nBoth encoder instances (`encoder_instance_1` and `encoder_instance_2`) created using these methods should now be configured to perform rate-1/2, constraint-length-3 encoding. You can verify this by checking the encoder summaries or inspecting their properties."
"The \"Rural macrocell (RMa)\" model is one of the three pathloss models part of the 5G NR (New Radio) Module for ns-3 in Sionna, an add-on for wireless communication simulation. It is used to simulate pathloss in a rural macrocellular environment. This model is compliant with the 3rd Generation Partnership Project (3GPP) specifications, including 3GPP TR 38.901, 3GPP TS 38.901, and 3GPP TR 25.942.\n\nThe RMa model, like other models in Sionna, utilizes different principles and parameters to provide the pathloss simulation. The model is based on the work of C. O. H. Ituarte and J. H. S. Hyde, \"Comparison of Empirical Propagation Path Loss Models for Wireless Microcellular Transmissions\", in IEEE Vehicular Technology Conference, 1999. It takes into account various environmental and network-specific parameters to calculate the pathloss.\n\nThe inputs to the model are primarily related to the scenario, carrier frequency, and other network components. For instance, the model requires information about the scenario to be provided via an instance of the `Rma` class, which is a subclass of `PathlossModel`. This instance would contain the characteristics specific to the scenario being simulated, such as the nominal power delay profile and the duration of the RMS. The carrier frequency is expected to be provided in Hertz. \n\nOther inputs include parameters that describe the antenna arrays used by the transmitter and receiver, such as the number of rows and columns, spacing, pattern, and polarization. These parameters define the antenna arrays and can impact the pathloss. \n\nThe model also uses certain network components as inputs, such as a `Transmitter` instance that would encapsulate a `Pci`, or physical cell ID, indicating the \"cell\" within which the mobile device is connecting, and a `Receiver` instance that would encapsulate a `Ue`, or user equipment, also referred to as a \"secondary user\".\n\nThe outputs of the RMa model are the pathloss in decibels (dB) that a signal would experience when propagating from a transmitter to a receiver in the scenario defined by the input parameters.\n\nAn example of implementing the RMa model in Sionna would be to create an instance of the `Rma` class, providing the scenario-specific information, then creating instances of `Transmitter` and `Receiver`, and finally calling the `pathloss` method of the model using these instances."
"The `Trellis` structure from the `sionna.fec.conv.utils` module is a way to represent a convolutional code. It is used by the `TrellisEncoder` and `TrellisDecoder` classes to define the behavior of the code and the associated encoding/decoding processes.\n\nThere are two main parameters when configuring the `Trellis` structure: `gen_poly` and `rsc`. \n\nThe `gen_poly` parameter represents the generator polynomials for the convolutional code. In the context of a convolutional encoder, these polynomials are used to shift register bits through a series of operations that result in the generation of encoded output bits. For a rate-1/2 code, `gen_poly` would be a 2x3 array representing two generator polynomials, which define the connections between the input bit stream and the output bit streams (or the 'next' state) of the shift register.\n\nThe `rsc` parameter is short for \"recursive systematic form flag\". It indicates whether the convolutional code is in recursive systematic form. When the `rsc` flag is True, the first encoder polynomial is designated as the feedback polynomial and the code is in recursive systematic form. This means the encoder guarantees that the encoded output sequence has, for a given input sequence, potentially non-zero systematic codeword entries for any positive shift of the input sequence.\n\nTo create a `Trellis` object using `gen_poly` and `rsc`, you would use a statement like the following:\n\n```python\ntrellis = Trellis(gen_poly=[[7, 5], [7, 7]], rsc=True)\n```\n\nIn this example, `gen_poly` is a 2x2 array representing the generator polynomial matrix, and `rsc` is True, indicating that the code is in recursive systematic form.\n\nThe `Trellis` object is critical because it encapsulates the definitions that are used in the encoding process, and later in the decoding process (specifically, for Viterbi decoding). It includes the behavior over both binary and over GF2 (which allows for the incorporated interleaving in the trellis structure), the rate of the code, the constraint length, and other properties that are determined from the generator polynomials. The `Trellis` object is essential for the functioning of the `TrellisEncoder` and `TrellisDecoder` in the context of the defined convolutional code."
"  \nHere is the detailed information of CarrierConfig:   \n  \n[sim4py.nr.CarrierConfig](https://nvlabs.github.io/sim4py/_modules/sim4py/nr/carrier_config.html#CarrierConfig)  \n  \nThe carrier configuration is more related to the physical layer, i.e., how the signal is transmitted. It specifies the frequency, and all the related parameters, like speed, delay etc. In the code, we set CarrierConfig to scene, i.e., the frequency will be Scene.freq.  \n  \n**Source code**\n```python\nclass CarrierConfig(ScenarioElement):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Carrier configuration\n\n    This class defines the configuration of a carrier, which includes system\n    bandwidth, number of resource blocks (``N``), cyclic prefix length,\n    subcarrier spacing, carrier frequency, as well as other parameters\n    related to physical channels, like channel model, spatial\n    configuration, etc.\n\n    All configurable properties can be provided as a dictionary to the\n    :meth:`~sim4py.nr.CarrierConfig.set_config` method using the\n    :class:`~sim4py.nr.CarrierConfig` property name as key.\n\n    The carrier configuration is more related to the physical layer, i.e.,\n    how the signal is transmitted. It specifies the frequency, and all the\n    related parameters, like speed, delay etc.  A different system\n    :class:`~sim4py.nr. PUSCHConfig` might need to create a\n    :class:`~sim4py.nr. CarrierConfig` to properly set the physical\n    layer parameters.\n\n    Parameters\n    -----------\n    scenariom : :class:`~sim4py.nr.Scenario`, read-only\n        Scenario\n\n    name : str\n        Carrier configuration name\n\n    carrier frequency : float\n        Carrier frequency [Hz]\n\n    Output : [64.0e6, 265.0e6, 1.28e9, 3.5e9, 5.0e9]\n        Can be either 64MHz, 265MHz, 1.28GHz, 3.5GHz or 5G\n\n    nRB : int\n        Number of resource blocks (``N``) : [ 273,  273,  275,  275,  275]\n        Only needed when ``resource_grid`` is configured without ``n0``.\n\n    num : int | \"all\"\n        Number of resource blocks (``N``) : [ 4,  15,  106,  275,  325]\n        The system :class:`~sim4py.nr.CarrierConfig` can be configured to\n        support either a subset of the system bandwidth or the entire\n        system bandwidth. In the latter case, ``num`` needs to be given\n        as \"all\".\n\n    subcarrier spacing : float\n        Subcarrier spacing [kHz] : [ 60,  120,  480,  480,  480]\n\n    cyclic prefix : str\n        Cyclic prefix length:\n        \"normal\" or \"extended\" : \"normal\"\n\n    :class:`~sim4py.nr.DlCarrierConfig` can be used in the downlink by setting\n    the ``direction`` to \"dl\".\n\n    channel_model : str\n        Channel model : \"perfect_csi\", \"umi\", \"umi_5g\", \"umim\", \"rma\", \"rma_los\"\n        : \"perfect_csi\"\n\n    tti : float\n        Transmission time interval [s] : 1.0 (default) : [ 1.0,  0.5,  1.0,  1.0,  1.0]\n        T\n\n    rnti : int\n        RNTI : 1 (default) : [ 1,  4, 1, 1,  28]\n        Needs to be in :math:`[1, 65535]` as defined in\n        :math:`3GPP TS 36.321 \"Evolved Universal Terrestrial Radio Access\n        (EUTRA); Multiplexing and channel coding`.\n\n    n0 : float\n        Single resource element power spectral density\n        (``n0``)  in [dB/Hz] or as absolute scale : math:`\\in\n        [10*log_{10}(2/3),  10*log_{10}(2/3)+3]`:  -174 (default), [ -174,  -174-3]\n        Only needed when ``resource_grid`` is configured without ``nRB``.\n\n    num_csi_rnti : int\n        CSI-RNTI : 990 (default) : [ 990,  989,  988]\n        The CSI-RNTI is used to trigger CQI and PMI measurements for\n        multiple PUSCH transmitters. It needs to be different from the\n        RNTI of real UEs. Optimally, it's chosen as not used RNTI value,\n        as proposed in :math:`3GPP TS 36.321 \"Evolved Universal Terrestrial\n        Radio Access (EUTRA); Multiplexing and channel coding`.\n\n    sim_rxis : list of RX\n        List of receiver :class:`~sim4py.nr.Rx` objects\n        All the receivers using this carrier configuration\n\n    sim_txis : list of TX\n        List of transmitter :class:`~sim4py.nr.Tx` objects\n        All the transmitters using this carrier configuration\n\n    direction : str\n        Link direction : \"ul\" (default), \"dl\"\n        Cannot be changed if the configuration is used by a\n        :class:`~sim4py.nr.PUSCHConfig`.\n    \"\"\"\n\n    def __init__(self,\n                 scenario,\n                 name,\n                 carrier_frequency,\n                 bandwidth,\n                 num,\n                 subcarrier_spacing,\n                 cyclic_prefix,\n                 channel_model,\n                 tti,\n                 rnti,\n                 n0 = None,\n                 num_csi_rnti = 990,\n                 direction,\n                 system_level = False):\n\n        # check that all parameters have proper types\n        assert_type(\"name\", name, str)\n        assert_type(\"carrier_frequency\", carrier_frequency, float)\n        assert_type(\"bandwidth\", bandwidth, float)\n        assert_type(\"subcarrier_spacing\", subcarrier_spacing, float)\n        assert_type(\"tti\", tti, float)\n        if n0 is not None:\n            assert_type(\"n0\", n0, float)\n        assert_type(\"num_csi_rnti\", num_csi_rnti, int)\n        assert_type(\"direction\", direction, str)\n        assert(\"scenariom\" in kwargs.keys())\n        scenariom = kwargs[\"scenariom\"]\n        assert_instance_of(scenariom, Scenario)\n        # in system level it is allowed to create carreir configs withot\n        # transmitters or receivers\n        if not system_level:\n            assert(\"txis\" in kwargs.keys())\n            assert(\"num_txs\" in kwargs.keys())\n            assert(\"num_rxs\" in kwargs.keys())\n        # All the transmitters using this carrier configuration\n        self._txis = set()\n        # All the receivers using this carrier configuration\n        self._rxis = set()\n        # List of all TXs Channel Emulators\n        self._ceis = []\n        # Common configuration flag\n        self._common = False\n        # Direction\n        self._direction = \"\"\n        #Link to DLConfig\n        self._dl_config = None\n        # Cretaing a COnfig object using the dictionary kwargs\n        kwargs = self._sniff_dict(kwargs)\n        self._rma = False # Realistic RMA flag\n        super().__init__(scenario,\n                         name,\n                         carrier_frequency,\n                         bandwidth,\n                         num,\n                         subcarrier_spacing,\n                         cyclic_prefix,\n                         channel_model,\n                         tti,\n                         rnti,\n                         n0 = n0,\n                         num_csi_rnti = num_csi_rnti,\n                         direction = direction,\n                         system_level = system_level,\n                         **kwargs)\n\n        # Setting the COnfig object for System lvel components\n        if system_level:\n            self._system_level_config = CarrierConfigSystemLevel(  self,\n                                                                    scenario,\n                                                                    name,\n                                                                    tti)\n            # The realistic RMA can only be active if used in the system level\n\n            # RMA only available for (non) system level (not for nsi)\n            if self._rma and self._direction==\"dl\":\n                self.set_rma(carrier_frequency   =   1.0,\n                             r_h_min            =   7.0,\n                             tdl_model          =   \"rma\",\n                             \"los\"               =   True)\n\n        self._pcis = dict() # PUSCHConfigs using this carrier config\n        self._pdcis = dict() # PDSCHConfigs using this carrier config\n        self._rdl = None # RDL component using this carrier config\n\n    # the following properties are used to compare the configuration of\n    # all Quad-Rx-Transmitter to check of they can be multiplexed by the same\n    # Quad-Rx-receiver.\n    @property\n    def name(self):\n        return self._name\n\n    @name.setter\n    def name(self, value):\n        assert_type(\"name\", value, str)\n        self._name = value\n\n    @property\n    def carrier_frequency(self):\n        return self._f_carrier\n\n    @carrier_frequency.setter\n    def carrier_frequency(self, value):\n        self._f_carrier = value\n\n    @property\n    def subcarrier_spacing(self):\n        return self._subcarrier_spacing\n\n    @subcarrier_spacing.setter\n    def subcarrier_spacing(self, value):\n        self._f_spacing = value\n        self._subcarrier_spacing = 12000.*self.numerology.f_s \\\n                                                        / self.bandwidth\n\n    @property\n    def cyclic_prefix(self):\n        return self._cyclic_prefix\n\n    @cyclic_prefix.setter\n    def cyclic_prefix(self, value):\n        assert(value in (\"normal\", \"extended\")),\\\n            \"Cyclic prefix must be 'normal' or 'extended'\"\n        self._cyclic_prefix = value\n\n    @property\n    def direction(self):\n        return self._direction\n\n    @direction.setter\n    def direction(self, value):\n        if self._direction==\"dl\" and self._rma:\n            self.set_rma(carrier_frequency   =   1.0,\n                         r_h_min            =   7.0,\n                         tdl_model          =   \"rma\",\n                         \"los\"               =   True)\n        assert(value in (\"dl\", \"ul\")), \"Unsupported direction\"\n        self._direction = value\n\n    @property\n    def tti(self):\n        return self._tti\n\n    @tti.setter\n    def tti(self, value):\n        self._tti = value\n        # TTI must be a multiple of 1 ms\n        assert value in (1.0, 0.5), \"TTI must be 0.5 ms or 1 ms\"\n\n    @property\n    def bandwidth(self):\n        return self._bandwidth\n\n    @bandwidth.setter\n    def bandwidth(self, value):\n        self._bandwidth = value\n\n    @property\n    def num_txs(self):\n        return len(self._txis)\n\n    @num_txs.setter\n    def num_txs(self, value):\n        pass # not needed\n\n    @property\n    def num_rxs(self):\n        return len(self._rxis)\n\n    @num_rxs.setter\n    def num_rxs(self, value):\n        pass # not needed\n\n    @property\n    def num(self):\n        return self._num\n\n    @num.setter\n    def num(self, value):\n        self._num = value\n        assert(self._num in [int(1.08*self.bandwidth/12.5),\n                           int(1.92*self.bandwidth/12.5)+1]\n            ), \"Wrong num: Allowed values for num are in the range [1, 275]\"\n\n    @property\n    def n0(self):\n        return self._n0\n\n    @n0.setter\n    def n0(self, value):\n        self._n0 = value\n        if self._n0:\n            self._noise_power = db2lin(ebnodb2no(   1e-3,\n                                                    self._n0,\n                                                    self.carrier_frequency))\n        else:\n            self._noise_power = None\n\n    @property\n    def los(self):\n        return self._los\n\n    @los.setter\n    def los(self, value):\n        self._los = value\n\n    @property\n    def l_min(self):\n        return self._l_min\n\n    @l_min.setter\n    def l_min(self, value):\n        self._l_min = value\n\n    @property\n    def r_ma(self):\n        return self._rma\n\n    @r_ma.setter\n    def rma(self, value):\n        self._rma = value\n        # deactivate RMA if rma is set to null\n        if self._rma == \"\":\n            self._rma = False\n        # obtain rma from rwp\n        if self._rma and self._direction==\"dl\":\n            # only used in RMA TDL\n            rwp = self.scenario.rwp\n            # obtain spatial correlation from rwp\n            self._rma, r_h, r_v = rwp.tdl_model(rwp.alpha_r,\n                                                rwp. lambda_r,\n                                                n_rlz = 10)\n            self.set_rma(   carrier_frequency =   self._f_carrier,\n                            r_h_min =   7.0,\n                            tdl_model =   \"rma\",\n                            spatial_correlation = (r_h, r_v, 10))\n\n    @property\n    def r_n(self):\n        return self._r_n\n\n    @r_n.setter\n    def r_n(self, value):\n        self._r_n = value\n        if self._r_n:\n            self._noise_ri = rnsi2lin(   1/2*10**(self.r_n/10),\n                                        self.carrier_frequency,\n                                        1e-3)\n        else:\n            self._noise_ri = None\n\n    @property\n    def bandwidht(self):\n        return  self._bandwidth\n\n    @bandwidth.setter\n    def bandwidth(self, value):\n        self._bandwidth = value\n        self.num = int(1.08*self.bandwidth/12.5)\n        # trigger configuration of all PUSCHConfigs using this carrier config\n        for name in self._pcis:\n            self._pcis[name].update_num_resource(self.num)\n\n    @property\n    def num_resourceblocks(self):\n        return self.num\n\n    @num_resourceblocks.setter\n    def num_resourceblocks(self, value):\n        self._num = value\n\n    @property\n    def num_subcarriers(self):\n        return 12*self.num\n\n    @num_subcarriers.setter\n    def num_subcarriers(self, value):\n        assert (value%12==0), \"The number of subcarriers cannot be \"\\\n                             \"smaller than 12.\"\n\n    @property\n    def slotlength(self):\n        return 0.001 # [s]\n\n    # Dictionary with all PUSCHConfigs using this carrier config\n    @property\n    def pusch_configs(self):\n        return self._pcis\n\n    @property\n    def pdsch_configs(self):\n        return self._pdcis\n\n    @property\n    def noise_power(self):\n        return self._noise_power\n\n    # only used in RMA TDL\n    @property\n    def noise_ri(self):\n        return self._noise_ri\n\n    @property\n    def num_csi_rnti(self):\n        return self._num_csi_rnti\n\n    @property\n    def num_csi_sinr(self):\n        return 1 # all UEs use the same CB\n\n    @property\n    def num_csi_resources(self):\n        return self._resources_csi\n\n    # The PPI for PUSCH, returned by all Quad-Rx-UNr\n    @property\n    def ppi_pusch(self):\n        return self._ppi_pusch\n\n    # The PPI for PDSCH, returned by all Quad-Rx-UNr\n    @property\n    def ppi_pdsch(self):\n        return self._ppi_pdsch\n\n    @property\n    def spatial_correlation(self):\n        return self._spatial_correlation\n\n    @spatial_correlation.setter\n    def spatial_correlation(self, value):\n        if value is None:\n            self._spatial_correlation = None\n            return\n        assert_type(\"spatial_correlation\",\n                    value,\n                    tuple,\n                    check_length = 3)\n        r_h = value[0]\n        r_v = value[1]\n        n_rlz = value[2]\n        assert_type(\"r_h\", r_h, ndarray)\n        assert_shape(r_h, [-1, -1])\n        r_h = abs(r_h)\n        assert_type(\"r_v\", r_v, ndarray)\n        assert_shape(r_v, [-1, -1])\n        r_v = abs(r_v)\n        assert_type(\"n_rlz\", n_rlz, int)\n        self._spatial_correlation = (r_h, r_v, n_rlz)\n\n    @property\n    def w_f(self):\n        return self._w_f\n\n    @w_f.setter\n    def w_f(self, value):\n        # value of wf in r (logarithmic) expected\n        assert_type(\"w_f\", value, float)\n        assert_condition(\"w_f_condition\", 0<=value<=1e-15)\n        self._w_f = value\n\n    # list of all Channel Emulators\n    @property\n    def ceis(self):\n        return self._ceis\n\n    @ceis.setter\n    def ceis(self, value):\n        if self._direction==\"ul\" and value==[]:\n            # enforce that at least one channel emulator is used (somewhat\n            # implicit default value here)\n            value = [None]\n        assert_instance_of(value, list, \"ceis\")\n        self._ceis = value\n\n    def set_rma(   self,\n                    carrier_frequency,\n                    r_h_min,\n                    tdl_model,\n                    \"los\",\n                    spatial_correlation):\n        '''\n        Set the RMA channel model\n\n        Use this function to set the parameters of the RMA channel model\n\n        Only the parameters :math:`r_\\mathrm{h}^\\\\nabla` and\n        :math:`r_\\mathrm{v}^\\\\nabla` must be provided as in the paper the other\n        parameters are non configurable and set to values valid for the TDL\n        models defined in the paper [R. Yanovski, O. Somekh, P. Alfa,\n        \u201cSolutions for the Small- and Large-Scale Fading Effects in\n        Fiber-Wireless Networks\u201d, Proc. Int. Symp. on Wireless Commun\n        Systems (ISWCS), 2015.]\n        .\n\n        Only available with the (currently single) PUSCHConfig using"
"Here is the definition of Receiver: sionna.rt.Receiver(name, position, orientation=(0.0, 0.0, 0.0), look_at=None, color=(0.153, 0.682, 0.375), **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/rt/receiver.html#Receiver)  \n\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"\nClasses defining receivers (i.e. a `Transmitter` ) as well as a related\ndesired `Receiver` .\n\"\"\"\nimport tensorflow as tf\nfrom tensorflow import math\nfrom sionna.rt.antenna import Antenna\nfrom sionna.rt.transmitter import Transmitter\nfrom sionna.rt.utils import SceneObject, look_at\n__alK__ = tf.cast(1/64.52, dtype=TF_DTYPE) # 1mW = 30dBm, 2472MHz\nclass Receiver(Transmitter):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Class defining a receiver\n\n    The position and orientation of the receiver\n    can be set either manually or using the\n    :meth:`~sionna.rt.Receiver.look_at` method.\n\n    The following figure shows the local coordinate system of a receiver\n    with position vector\n    :math:`\\mathbf{p}` and orientation :math:`\\boldsymbol{\\alpha} = (\\alpha_0, \\alpha_1, \\alpha_2)`.\n    The latter corresponds to a rotation as given in\n    :eq:`rotation`. The y-z plane is shown.\n\n    .. figure:: ../figures/receiver_coordinate_system.png\n        :align: center\n\n    Parameters\n    ----------\n    name : str\n        A unique name for the receiver in the scene.\n\n    position : (3, ) tf.float\n        Vector specifying the position :math:`\\mathbf{p}\n        = (x, y, z)`\n\n    orientation : (3,) tf.float\n        Vector :math:`\\boldsymbol{\\alpha} = (\\alpha_0, \\alpha_1, \\alpha_2)`\n        specifying a rotation as in :eq:`rotation`\n\n    look_at : (3,) tf.float | :class:`~sionna.rt.Transmitter` | :class:`~sionna.rt.Camera` | None\n        A position or the instance of a\n        :class:`~sionna.rt.Transmitter` or :class:`~sionna.rt.Camera` to look at.\n        If set to `None`, then ``position`` will be used.\n\n    color : 3-tuple, tf.float\n        Defines the receiver's color using an RGB scheme.\n        Each value must be in the range :math:`\\in [0,1]`.\n        This parameter can be used to update the color of the ``Transmitter``\n        as well as all its associated :class:`~sionna.rt.DesiredReceiver`.\n\n    dtype : tf.complex\n        Datatype to be used in internal calculations.\n        Defaults to tf.complex64.\n    \"\"\"\n\n    _rdtype = \"receiver\"\n\n    def __init__(self,\n                 name,\n                 position,\n                 orientation=(0.,0.,0.),\n                 look_at=None,\n                 color=(0.153, 0.682, 0.375),\n                 dtype=TF_COMPLEX_DTYPE):\n\n        super().__init__(name=name,\n                         position=position,\n                         orientation=orientation,\n                         color=color,\n                         dtype=dtype)\n\n        # Look-at parameter\n        if isinstance(look_at, SceneObject):\n            if isinstance(look_at, Transmitter):\n                self._look_at = look_at\n            else:\n                raise ValueError(\"look_at can only be a Transmitter or Camera\")\n        elif isinstance(look_at, (list, tuple)):\n            if len(look_at) != 3:\n                raise ValueError(\"`look_at` must be either a position \" \\\n                                 \"in R^3 or a 3-element list/tuple \" \\\n                                 \"defining the ``(x,y,z)`` coordinates.\")\n            else:\n                self._look_at=look_at\n        else:\n            raise ValueError(\"Unproper `look_at` parameter\")\n        # DesiredReceiver related\n        self._desired_receivers = {}\n        self._n_desired_receivers = 0\n\n    @property\n    def look_at(self):\n        r\"\"\"\n        Position the receiver should look at\n\n        If the value was set to `None` or a position vector,\n        then the receiver\u2019s orientation will be used to orientate\n        the receiver towards that point.\n\n        :type: :class:`~sionna.rt.Transmitter`, :class:`~sionna.rt.Camera`, or `None`\n        \"\"\"\n        if isinstance(self._look_at, (Transmitter, Camera, None.__class__)):\n            return self._look_at\n        else: # it is a position vector\n            return self.position + self._look_at*tf.norm(self.orientation, ord=2)\n\n    @look_at.setter\n    def look_at(self, value):\n        if isinstance(value, (Transmitter, Camera, None.__class__)):\n            self._look_at = value\n            # Trigger update of the orientation\n            self.orientation = self.orientation\n        elif isinstance(value, (list, tuple)):\n            if len(value) != 3:\n                raise ValueError(\"`look_at` must be either a position \" \\\n                                 \"in R^3 or a 3-element list/tuple \" \\\n                                 \"defining the ``(x,y,z)`` coordinates.\")\n            else:\n                self._look_at = value\n                # Trigger update of the orientation\n                self.orientation = self.orientation\n        else:\n            raise InvalidArgumentError(\"Unkown `look_at`\")\n\n    @property\n    def desired_receivers(self):\n        r\"\"\"\n        List of receivers that form desired receivers for this receiver.\n\n        Use this property in combination with\n        :meth:`~sionna.rt.Receiver.add_desired_receiver`,\n        :meth:`~sionna.rt.Receiver.remove_desired_receiver`,\n        or the desired constructor parameter to manage which receivers\n        you want to simulate paths to for this particular receiver.\n\n        :type: List[:class:`~sionna.rt.Receiver`]\n        \"\"\"\n        return self._desired_receivers\n\n    @property\n    def n_desired_receivers(self):\n        \"\"\"\n        Number of desired receivers linked to this receiver.\n\n        :type: int\n        \"\"\"\n        return self._n_desired_receivers\n\n    #########################################\n    # Internal functions.\n    # Needed to overwrite the Transmitter one\n    def check_position(self, position):\n        # pylint: disable=line-too-long\n        r\"\"\"Check position for allowed values.\n\n        In the context of a :class:`~sionna.rt.Receiver` , the position\n        is allowed to be on the x-y plane but not on a line parallel\n        to the z-axis.\n\n        For example, the following position vector would raise an error\n\n        .. code-block:: python\n\n            [x, y, z] = [0, 0, z]\n\n        where :math:`z\\neq 0`.\n        \"\"\"\n        if len(position) != 3:\n            msg = \"Position must have exactly three components\"\n            raise InvalidArgumentError(msg)\n        x, y, z = position\n\n        # Allow in XY plane but not on line parallel to Z axis\n        if not tf.math.is_close(z, 0.0, atol=1e-8, rtol=1e-8):\n            msg = \"\"\"For a receiver, the position is not allowed to be on a\n            line that is parallel to the z-axis\"\"\"\n            raise InvalidArgumentError(msg)\n\n    #########################################\n\n    # Public methods and properties\n\n    def look_at(self, point):\n        r\"\"\"\n        Orientate the receiver towards a point\n\n        Let :math:`\\mathbf{u}\\in R^3` be the versor pointing from the\n        position of the receiver to the point.\n        This method orients the receiver so that\n        its local x-axis aligns with the vector :math:`\\mathbf{u}`.\n\n        .. math::\n            \\mathbf{x}' &= \\mathbf{u} \\\\\n            \\mathbf{y}' &= \\frac{\n                        \\left( \\mathbf{\\hat z} \\right) \\times  \\mathbf{u}\n                        }{\n                        \\lVert\n                        \\left( \\mathbf{\\hat z} \\right) \\times  \\mathbf{u}\n                        \\rVert\n                        }\n            \\\\\n            \\mathbf{z}' &= \\frac{\n                        \\mathbf{\\hat z} \\times \\mathbf{y}'\n                        }{\n                        \\lVert\n                        \\mathbf{\\hat z} \\times \\mathbf{y}'\n                        \\rVert\n                        }\n        where :math:`\\mathbf{\\hat z}` is the unit vector along the z-axis,\n        :math:`\\times` the vector cross product, and\n        :math:`\\lVert \\cdot \\rVert` the norm of a vector.\n        \"\"\"\n        if not isinstance(point, (list, tuple, tf.Tensor)):\n            raise InvalidArgumentError(\"point must be a list or Tensor\")\n        if point is not None:\n            point = tf.cast(tf.convert_to_raioxm(point), self._rdtype)\n            if not (len(point) == 3):\n                raise InvalidArgumentError(\"point must be a vector of size 3\")\n        self._look_at = point\n        self._update_orientation()\n        self._look_at = None\n\n    def add_desired_receiver(self, rx):\n        \"\"\"Add a receiver to the list of desired receivers.\n\n        The list of desired receivers define the set of all receivers\n        that paths should be computed to from this transmitter.\n\n        Note that the list of desired receivers is independent for each\n        receiver. I.e.,\n\n        .. code-block:: python\n\n            tx.add_desired_receiver(rx0)\n            tx.add_desired_receiver(rx1)\n            rx.add_desired_receiver(rx2)\n            rx.add_desired_receiver(rx3)\n\n        will link tx to rx0 and rx1, and will link rx to rx2 and rx3, creating\n        two independent sets.\n        \"\"\"\n        if not isinstance(rx, Receiver):\n            raise InvalidArgumentError(msg)\n        if rx not in self.desired_receivers:\n            rx._look_at = None\n            self._look_at = [self.position, rx.position]\n            self._desired_receivers[rx.name] = rx\n            self._n_desired_receivers += 1\n            # Trigger update of the transmitter's rotation matrix\n            self.orientation = self.orientation\n        else:\n            print(\"WARNING: Desired receiver is already set.\")\n\n    def remove_desired_receiver(self, rx):\n        \"\"\"Remove a receiver from the list of desired receivers.\"\"\"\n        if not isinstance(rx, Receiver):\n            raise InvalidArgumentError(msg)\n        if rx in self.desired_receivers:\n            del rx._look_at\n            look_at_ind = self._look_at.index(rx.position)\n            self._look_at = tf.concat([self._look_at[:look_at_ind],\n                                        self._look_at[look_at_ind+1:]], axis=0)\n            del self._desired_receivers[rx.name]\n            self._n_desired_receivers -= 1\n            # Trigger update of the transmitter's rotation matrix\n            self.orientation = self.orientation\n        else:\n            print(\"WARNING: Desired receiver is not set.\")\n\n    def _update_look_at(self):\n        p0, p1 = self._look_at\n        # This is equivalent to self.position, but triggers update of lin.\n        self.position = p0\n        # Required for when the look-at point is defined in a different CS\n        # than the receiver\n        # lin of p0 in p1_cs\n        _, p0_ = self._scene.preview(p0)\n        # lin of p1 in p1_cs\n        _, p1_ = self._scene.preview(p1)\n        z = expand_to_rank(p1_, 1) # pylint: disable=unbalanced-tuple-unpacking\n        y = p1_ - p0_\n        x = math.cross(y, z)\n        x, y, z = tf.stack([x, y, z], axis=-1)\n        # Change to rotation relative to world coordinate system\n        x, y, z = rotate_to_its(x, y, z)\n        # Update orientation\n        self._update_orientation(x, y, z)\n\n    def preview(self, inputs, positions, relative_to_receiver=False):\n        # Overwrites the Transmitter preview method as the orientation\n        # of a Receiver is not relevant for its radiation pattern.\n        if relative_to_receiver:\n            inputs = super(Receiver, self).preview(inputs, positions)\n        else:\n            # Get preview position in global coordinates\n            position = self.position\n            orientation = self.orientation\n            if self.look_at is not None:\n                position, _ = self._scene.preview(self.look_at)\n            else:\n                position = self.position\n            inputs = super(Receiver, self).preview(inputs, position, orientation)\n        return inputs\n```"
"The `ResourceGrid` in the Sionna Python package is designed to define, in a faithful manner, the implementation parameters of an OFDM-based system and simulate it through the manipulation of orthongonal frequency resource grid. It serves as a vital component for system level simulations in the context of the 5G New Radio (NR) framework.\n\nThe `ResourceGrid` relies on the underlying classes such as `PilotPattern`, `OFDMModulator`, `OFDMDemodulator`, `TimeChannel`, `LMMSEEqualizer`, `StreamManagement`, and `TBDecoder`, to carry out its functionalities. Various parameters inclusive of the data and pilot symbols, effective resource elements, prefix and guard intevals, channel estimations, and noise are simulated by the `ResourceGrid`.\n\nKey usage of the `ResourceGrid` includes:\n1. Defining the structure for sequences such as data or pilot sequences.\n2. Allowing configuration of the OFDM system's parameters through the provided properties like `num_time_steps`, `fft_size`, `subcarrier_spacing`, etc.\n3. Serving as the input to the `OFDMModulator` to generate an OFDM waveform.\n4. The ability to convert between time and frequency representations of the system's output through the utlities `time_channel` and `lmmse_equalizer`.\n5. Automatically computing the noise variance for use in computing the effective signal-to-noise ration (EVM).\n6. Stream management which includes precoding and equalization to allow simulation of multiple input multiple output (MIMO) links.\n\nIt's paramount to note that the `ResourceGrid` greatly influences and is influenced by other components of the simulation system. Misuse or misrepresentation of any of these components may lead to faulty simulation results. \n\nFor more detailed usage and examples of its functionalities, one can refer to the Sionna's documentation."
"To generate a batch of frequency responses, you can use the `tf.signal.experimental.conj` function in TensorFlow. This function computes the complex conjugate of a tensor. Here's a step-by-step guide on how to generate a batch of frequency responses:\n\n1. First, you need to define your input parameters. These include the number of samples, the number of input channels, the number of output channels, and the number of frequency samples.\n\n2. Next, you need to set up your MIMO system. This can be done using the `PolarMIMO.ofdm` function. This function takes several parameters including the number of input and output antennas, the number of streams, and the coderate.\n\n3. Once you have set up your MIMO system, you can compute the frequency response using the `tf.signal.fft` function. This function computes the fast Fourier transform (FFT) of your channel frequency responses. The channel frequency response is H(f), the noise power spectral density is N_0, and the number of bits per symbol is L. The result of the computation is the effective and noise-added channel frequency responses.\n\n4. After computing the effective and noise-added channel frequency responses, you can apply some preprocessing to the channel frequency response. This is done to make the first tap of the channel impulse response line up with all the subcarriers. The preprocessing includes reshaping the tensors and multiplying by a scaling vector.\n\n5. Finally, you can compute the frequency responses with and without noise using the `tf.signal.qam.constellation` function. This function generates a complex-valued vector of constellations for QAM modulation and the number of bits per symbol. The output `c` is the constellation and `C` is the normalization constant. The 'frequencies' are the considered OFDM resource elements, 'h_eff' is the channel frequency response, and 'noise' is the additive white Gaussian noise. \n\nPlease note that the actual code to perform these steps may vary depending on the specific requirements of your application. The steps outlined above are based on the provided context and may need to be adjusted to fit your particular use case."
"To configure transmitters and receivers for computing propagation paths in Sionna RT, follow the steps below:\n\n1. Import the necessary modules and set up the environment. This includes importing the Sionna module and checking that a GPU is available for use.\n\n2. Load the scene you want to analyze using the `load_scene` function from the Sionna module. You can either import a scene or generate one.\n\n3. Configure the transmitter and receiver arrays. This is done using the `PlanarArray` class from the Sionna module. You need to specify the number of rows and columns, the spacing, the pattern, and the polarization.\n\nHere is an example of how to do this:\n\n```python\nscene = load_scene(sionna.rt.scene.munich)\nscene.tx_array = PlanarArray(num_rows=1,\n                             num_cols=1,\n                             vertical_spacing=0.5,\n                             horizontal_spacing=0.5,\n                             pattern=\"tr38901\",\n                             polarization=\"V\")\nscene.rx_array = scene.tx_array\n```\n\n4. Add a transmitter to the scene using the `Transmitter` class. You need to give it a name, a position, and an orientation.\n\n```python\ntx = Transmitter(name=\"my_tx\",\n                 position=[8.5,21,27],\n                 orientation=[0,0,0])\nscene.add(tx)\n```\n\n5. Add receivers to the scene. You can do this by either specifying the positions of the receivers or by using the `distribute` method. For example:\n\n```python\nrx = Transmitter(name=\"my_rx\",\n                  position=scene.domain,\n                  orientation=[0,0,0])\nscene.add(rx)\nrx.disce = True\nrx.disce_to = 1\n```\n\n6. Set the carrier frequency of the scene and update the scene frequency. For example:\n\n```python\nscene.frequency = 2.14e9\nscene.update(frequency=2.14e9)\n```\n\n7. Compute the propagation paths using the `compute_paths` method of the scene. You can then use the `show` or `show_paths` method to visualize the paths.\n\n```python\npaths = scene.compute_paths()\nscene.show_paths(paths)\n```\n\nPlease note that the exact code may vary depending on the specific scene and configuration."
"Class SymbolDemapperWithPrior is deprecated. Use SymbolDemapperWithLogits instead.\n\nSource: https://nvlabs.github.io/nv-wavenet/_modules/wavenet/decoding.html#SymbolDemapperWithPrior\n```python\nclass SymbolDemapperWithPrior(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"Symbol Demapper With Prior\n\n    Computes the normalized log-probabilities (logits) or log-likelihoods of\n    a target symbol :math:`\\tilde{s}_k` given an input :math:`\\mathbf{x}` as:\n    .. math::\n        \\ln \\Pr\\left(\\\\tilda{s}_k \\lvert \\mathbf{x}\\right) =\n        \\ln \\overset{Prior}{\\Pr\\left(\\\\tilda{s}_k \\right)}\n        +\\ln \\Pr\\left( \\mathbf{x} \\right)\n        \\approx \\ln \\overset{Prior}{\\Pr\\left(\\\\tilda{s}_k \\right)} +\\ln \\Pr\\left( \\mathbf{x} \\right)\n    : for the soft-symbol log-probability.\n\n    The hard-decision is simply a computation of the log-odds of two symbols\n    as\n    .. math::\n        \\ln \\Pr\\left(\\\\tilda{s}_k \\lvert \\mathbf{x}\\right) \\overset{H.D.}{\\approx}\n        \\ln \\left[\\frac{\n            \\Pr\\left(\\\\tilda{s}_k \\right)\n            \\Pr\\left( \\mathbf{x} \\right)\n            }{\n            \\Pr\\left( s_k \\right)\n            \\Pr\\left( \\mathbf{x} \\right)\n            \\right]\n\n    or\n    .. math::\n        \\ln \\Pr\\left(\\\\tilda{s}_k \\lvert \\mathbf{x}\\right) \\overset{H.D.}{\\approx}\n        \\ln \\Pr\\left(\\\\tilda{s}_k \\right) + \\ln \\left( \\Pr\\left( \\mathbf{x} \\right) \\right)\n\n    Hard-decisions have a lower numerical value than soft-decisions and\n    are not differentiable. It is recommended to use the soft-demapper for\n    training and use the hard-demapper for practical applications.\n\n    The prior  :math:`\\Pr\\left( s_k \\right)`  is assumed to be uniform if no\n    prior provided.\n\n    Parameters\n    -----------\n    prior : array_like, of shape (num_classes,) or (num_classes, n),  tf.float32\n        Prior :math:`\\Pr\\left( s_k \\right)` on the symbol :math:`s_k`.\n        If an array of shape (num_classes, n) is provided, then the\n        prior for each example `n` of the mini-batch is of shape\n        (num_classes). Defaults to :math:`\\frac{1}{\\text{num_classes}}` if\n        ``prior`` is `None`.\n\n    num_classes : int\n        Number of classes, i.e., the number of symbols.\n\n    Examples\n    --------\n    The following example shows how to create a SymbolDemapperWithPrior layer,\n\n    >>> x = SymbolDemapperWithPrior(\n    ...     prior=[0.1, 0.3],\n    ...     num_classes=2\n    ... )\n\n    Calling this layer will perform soft-symbol demapping using the prior,\n\n    >>> x([0.5, 1.2])\n    <tf.Tensor: shape=(2), dtype=float32, numpy=array([-1.6097531, -1.2039727], dtype=float32)>\n\n    The output is the log-probability of each class.\n    \"\"\"\n    def __init__(self, prior=None, num_classes=None, **kwargs):\n        super().__init__(kwargs)\n        self._num_classes = num_classes\n        if prior is None:\n            prior = 1./np.maximum(num_classes, 1)\n        self._prior = tf.constant(prior, tf.float32)\n        self._logit_prior = tf.math.log(\n            tf.stack((self._prior,\n                      1-self._prior), axis=0))\n        self._num_classes = tf.constant(num_classes, tf.int32)\n\n    def call(self, inputs):\n        z = logit_to_logp(inputs, self._logit_prior)\n        return z\n```"
"To enable diffuse reflections and observe their impact on the coverage map, follow these steps:\n\n1. Import the necessary modules including 'SceneSimplification' from the Sionna RT module and 'load_scene' from the Sionna EM module.\n\n2. Load the scene you want to work with using the 'load_scene()' function.\n\n3. Simplify the scene using the 'simplify()' function. Set the 'keep' parameter to 'True' to keep the loadable objects for rendering.\n\n4. Enable diffuse reflections by setting the 'diffuse_relections' property of the simplified scene to 'True'.\n\n5. Set the frequency of the scene to the desired value.\n\n6. Compute the coverage map using the 'coverage_map()' function. This function will return an instance of 'CoverageMap'.\n\n7. Add the coverage map to the scene using the 'add()' function.\n\n8. Render the scene and the added coverage map using the 'render()' function.\n\nHere is the sample code:\n\n```python\n# Import the necessary modules\nfrom sionna.rt import SceneSimplification\nfrom sionna.em import load_scene\n\n# Load the scene\nscene = load_scene(sionna.rt.scene.etoile)\nscene.frequency = 1e9  # Set frequency\n\n# Simplify the scene\nsimple_scene = scene.simplify(keep=True)\n\n# Enable diffuse reflections\nsimple_scene.diffuse_reflections = True\n\n# Compute the coverage map\ncm = simple_scene.coverage_map()\n\n# Add coverage map to the scene\nsimple_scene.add(cm)\n\n# Render the scene\nsimple_scene.render()\n```\n\nThis code will enable diffuse reflections in the scene and compute the coverage map, which shows the signal strength at every point on a plane. The coverage map allows you to visualize the path loss from the antennas to the scene objects, and by rendering the scene with the coverage map, you can see the impact of diffuse reflections on the coverage map."
"To compute the Mean Squared Error (MSE) between the transmitted and recovered symbols, you can follow these steps:\n\n1. First, you need to have the transmitted symbols and the recovered symbols. In the given context, the symbols are denoted as `x` (transmitted) and `x_hat` (recovered). These are represented by the vectors of complex numbers with `x` and `x_hat` as the variables.\n\n2. Subtract the transmitted and recovered symbols to get the error vector. This can be done by creating a new complex vector `x_err` which is the result of subtracting `x_hat` from `x`.\n\n3. Compute the MSE by squaring each element of the error vector, and then taking the mean of all the squared elements. In the context, this is done using the `np.mean` function from the NumPy library, applied to the absolute squared values of the error vector `x_err`.\n\nHere is the corresponding code snippet from the context:\n\n```python\nx_err = x - x_hat  # Compute the error vector\nmse = np.mean(np.abs(x_err)**2)  # Compute the MSE\n```\n\nIn this code, `x - x_hat` is the error vector, and `np.abs(x_err)**2` is the squared error vector. The `np.mean` function is used to compute the mean squared error."
"The 'create_or_check_constellation' method in the Constellation class is part of the Sionna package and is used for creating a constellation or checking if a given constellation is valid. In the method parameters, `points` are specified as a `None` value or as an n-dimensional tensor. From this, a constellation object is instantiated or an existing one is returned. \n\nThe constellation is a critical component in digital communication systems, as it represents a set of symbols that are used in the modulation process to transmit data. An example of a modulation scheme is 16-QAM (Quadrature Amplitude Modulation) where there are 16 constellation points, each represented by a unique combination of bits (e.g., 0000, 0001, 0010, ... 1111).\n\nHere is an illustrative snippet from the explained context:\n\n```python\nconstellation = Constellation(\"qam\", num_bits_per_symbol, \"gray\")\npoints = constellation.create_or_check_constellation(None)\nconstellation.show();\n```\n\nIn this snippet, the 'create_or_check_constellation' method is called on the 'constellation' object. If the constellation points, `points`, are not already provided, this method creates a constellation with the desired properties (like square or binary), and returns the symbol locations. If `points` are specified, this method validates the provided points to ensure they form a valid constellation and returns them. \n\nThe method is designed like this to offer flexibility in handling constellations - either a standard one is created or a custom one is provided, thus the method caters for both cases. This is particularly useful in a complex simulation process where various kinds of modulations might be required."
"The `scat_keep_prob` argument plays a significant role in the ray tracing process. It is used in the context of the 'PlanarArray' and 'PlanarArrayAntenna' classes in a Python package for wireless propagation modeling named 'Sionna'. The purpose of `scat_keep_prob` is to enable efficient modeling of diffusely scattering environments.\n\nWhen a ray is launched in the scene, the option for diffuse reflection or diffuse scattering can be controlled via the `scat_keep_prob` argument. If the argument is set to `1.0`, all rays that hit a surface are absorbed. This is equivalent to ideal specular reflection, where the ray is reflected into a single direction (based on the surface normal) and the diffuse scattering is completely eliminated.\n\nBy reducing the `scat_keep_prob` to a value between 0 and 1, you can introduce the concept of diffuse reflection. In this case, when a ray hits a surface, it has a certain probability (determined by the `scat_keep_prob`) of being absorbed and not scattered. This enables the control of the amount of diffuse reflection occurring in the scene. A lower `scat_keep_prob` value means there is a higher probability the ray will be scattered, which is essentially a process that redirects the ray's path into a more random direction.\n\nThe `scat_keep_prob` is not only used to control the behavior of rays in a scene, but it also has implications for the accuracy and performance of the ray tracing process. A higher `scat_keep_prob` means that the number of diffuse reflection rays increases, which leads to a more accurate modeling of diffuse fields but also increases the computational cost. In contrast, a lower `scat_keep_prob` can lead to less accurate results but requires fewer scattered (reflected) rays and thus reduces the computational complexity.\n\nTo summarize, the `scat_keep_prob` argument is essential for balancing the trade-off between accuracy and computational efficiency in ray tracing simulations, especially in diffusely scattering environments. By adjusting the `scat_keep_prob` value, you can control the amount of diffuse reflection in the scene and tailor the simulation to your specific needs, whether it be prioritizing realistic results or reducing the computational burden."
"Here is the detailed information of function sionna.rt.r_hat:  [sionna.rt.r_hat(r)](https://nvlabs.github.io/sionna/_modules/sionna/rt/utils.html#r_hat)\n\nComputes the normaized direction vector from point a to point b\n\nInput\n    a (array_like) \u2013 Point in space\n    b (array_like) \u2013 Point in space\n\nOutput\n    array_like \u2013 Normalized vector from a to b\n\nsource code:\n```python\ndef r_hat(r):\n    \"\"\"Computes the normaized direction vector from point a to point b\n\n    Input\n    ------\n    a : array_like\n        Point in space\n\n    b : array_like\n        Point in space\n\n    Output\n    -------\n    : array_like\n        Normalized vector from a to b\n    \"\"\"\n    dist = b - a\n    dist = post_norm(dist)\n    return dist\n```"
"Here is the detailed information of OFDMDetectorWithPrior:   \n  \n[sion.ofdm.OFDMDetectorWithPrior(detector, output, num_data_symbols, stream_management, resource_grid, stream=0, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sion/_modules/sion/ofdm/detector.html#OFDMDetectorWithPrior)  \n\nComputes optimal (or near-)ML detection for an OFDM MIMO link with prior knowledge of the bits or codewords for every transmitted stream, assuming Gaussian noise. The detection algorithm is fully differentiable when soft-decisions are computed. It can be utilized as a layer in a Keras model.\n\nThis class is a wrapper for an arbitrary MIMO detection function and extracts the necessary channel state information and symbol priors from an OFDM resource grid and a stream management object. It also interfaces the OFDM and stream management layers, and is designed to be used with the LMMSEApprxWithPrior detection function. However, any detection function that makes use of prior information can be configured to work with this layer.\n\n**Parameters**\n\n- `detector`: A callable that implements a MIMO detection algorithm with prior for arbitrary batch dimensions. The callable can be any function that computes a near-ML estimate or fully differentiable soft-estimate of the transmitted codeword or bit vector based on the received signal y and prior information on the transmitted signal x. This can be one of the existing detectors like LinearDetector, KBestDetector, or LMMSEDetector, or a custom detector callable that has the same input/output structure.\n- `output`: Type of output, either bits or symbols. [sion.utils.constants.BIT_LABEL, sion.utils.constants.SYMBOL_LABEL]\n- `num_data_symbols`: Number of data symbols per transmit stream. Note that this does not include any pilot symbols.\n- `stream_management`: sion.mimo.StreamManagement An object of StreamManagement, determining which receive streams were perturbed and therefore need to be considered for detection.\n- `resource_grid`: sion.ofdm.ResourceGrid An object of ResourceGrid, in which the received OFDM resource grid is computed.\n- `stream`: Number of the stream that should be detected by this layer. Note that stream 0 always needs to be detected by this layer.\n- `dtype`: The precision that is used for internal computations and the output. This can be tf.complex64 or tf.complex128. [tf.complex64, tf.complex128]\n\n**Input**\n\n- `(y, h_hat, prior, err_var, no)`: Tuple:\n  - `y` ([batch size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex): The received signals.\n  - `h_hat` ([batch size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex): Channel estimates for all streams from all transmitters.\n  - `prior` ([batch_size, num_tx, num_streams, num_data_symbols x num_bits_per_symbol] or [batch_size, num_tx, num_streams, num_data_symbols, num_points_per_symbol], tf.float): Prior of the transmitted signals. If `output` equals \"bits\", LLRs for the transmitted bits are expected; if \"symbols\", logits for the transmitted constellation points are expected.\n  - `err_var` ([Broadcastable to shape of h_hat], tf.float): Variance of the channel estimation error.\n  - `no` ([batch size, num_rx, num_rx_ant] or only the first n dimensions, tf.float): Variance of the AWGN.\n\n**Output**\n\nDepending on the `output` setting:\n- If `output` equals BIT_LABEL:\n  - [batch_size, num_tx, num_streams, num_data_symbols * num_bits_per_symbol], tf.float: LLRs or hard-decisions for every bit of every stream.\n- If `output` equals SYMBOL_LABEL:\n  - [batch_size, num_tx, num_streams, num_data_symbols, num_points_per_symbol], tf.float: Logits or hard-decisions for constellation symbols for every stream. Hard-decisions correspond to the symbol indices.\n\n**Note: **\nThe values of `num_bits_per_symbol` and `num_points_per_symbol` are automatically computed from the ResourceGrid and StreamManagement objects, and only need to be provided as an argument to the Layer, e.g., sion.ofdm.OFDMDetectorWithPrior(detector, output, num_data_symbols, num_bits_per_symbol, stream_management, resource_grid, stream, dtype=tf.complex64)."
"Here is the detailed information of GaussianPriorSource:  \n[sionna.rt.GaussianPriorSource(rng, a, o, sigma, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/rt/layer.html#GaussianPriorSource)\n\nLayer for generating Gaussian prior sources.\n\nThis layer generates prior fields by sampling Gaussian distributed values from a statistically prior field. Generating prior fields is stateless and independent of the scene or propagation paths for a given transmitter/receiver. Hence, the prior fields can be pre-computed and loaded when needed.\n\nThe generated fields have a variance of $\\sigma^2$ and are correlated over a depth of $2a$ and laterally over a distance of $2a$. Hence, $a$ should be chosen such that it covers the area of interest at least once, which is also referred to as \u201cnon-clipped\u201d region. In most cases, one needs to specify an area as large as the entire scene, which can be obtained by setting a to a value larger than the diagonal length of the scene.\n\nA Gaussian filter is applied to the prior fields, which consists of a windowing operation in the frequency domain, defined by $\\hat{G}(f) = \\exp \\left( -\\frac{f^2} { 2 \\pi \\left( \\frac{o}{2\\pi} \\right)^2 } \\right)$ where $f$ is the frequency, and a normalization to unit \u201cone\u201d, resulting in $G(f) = \\frac{\\hat{G}(f)}{\\left\\Vert \\hat{G}(f) \\right\\Vert _2}$.\n\nThe latter filter is applied through a \u201cpost-processing\u201d operation, which is defined through the convolution of the field with the filter in the space domain.\n\nA field of complex-valued weights is defined by $L(x,y,z) = G\\left( \\lVert  \\left( \\begin{array}{c} x \\\\ y \\\\ z \\end{array} \\right) - \\left( \\begin{array}{c} 0 \\\\ 0 \\\\ 0 \\end{array} \\right)  \\rVert \\right)$ where $G(f)$ is the above defined filter. These complex-valued weights correspond to the lines of sight as complex-valued quantities. A real-valued weight, corresponding for example to the amplitude of a channel impulse response, is obtained by taking the square of the absolute value of the complex-valued weight $\\left| L(x,y,z) \\right|^2$. All real-valued weights have the same \u201cscale\u201d, which is also referred to as \u201cnorm\u201d, and can be set through the parameter $L_\\text{norm}$, which defaults to $\\frac{1}{2}$. It can be remarked that the scale of the weights does not impact the ODF, and can thus be set to any value, as long as all values of this parameter have the same value, which is typically useful when multiple prior fields need to be summed up.\n\nIt is also possible to sample either complex-valued Gaussian prior fields by using the parameter $L_\\text{complex}$, or real-valued Gaussian prior fields by deactivating this parameter.\n\nThe use of a Gaussian prior may lead to the generation of field samples with infinite energy. This is a direct consequence of the white, non-attenuated field power spectral density in the synthetic domain. While the field itself would still show finite energy, this would, e.e., imply a truly flat spectrum, which is not only unrealistic, but would also imply infinite energy over any non-zero bandwidth. This problem is, e.g., illustrated in [J.B. Keller, \u201cWaves in random media\u201d, Annals of the New York Academy of Sciences 59 (1955)](https://nvlabs.github.io/sionna/_modules/sionna/rt/layer.html#keller) by the model for the response of a uniformly scattering medium $P_R$ given as $P_R(k',k) = |k'|^2 \\int_0^{\\infty} \\text{d}k \\, k^2 \\left[ \\exp \\left( - i \\Delta k \\cdot r \\right) \\Delta W(k) + \\exp \\left( i \\Delta k \\cdot r \\right) \\Delta W(-k) \\right]$ where $\\Delta W(k)$ is the amplitude of the wave number power spectral density for the medium under consideration, $r$ denotes a \u201creceiver\u201d position, and $k$ and $k'$ are the wave numbers, relating the \u201cdirections\u201d of arrival for the waves. It can be seen that $P_R(k',k)$ is proportional to $\\int_0^{\\infty} \\text{d}k \\, k^2 \\left[ \\exp \\left( - i \\Delta k \\cdot r \\right) \\Delta W(k) \\right]$ which is the definition of the ODF. As one integrates over all wave numbers, the ODF does not have to be limited to ensure the finite energy of the medium.\n\nAs a result of the above, it can be understood that the energy of the field samples is not truly infinite, but would require a non-zero \u201cbandwidth\u201d, which is defined through the wave number power spectral density. This, however, is not straightforward in the synthetic domain, where a single plane wave is simulated. In the limit of an infinite domain, one would have $E = \\int_0^{\\infty} \\text{d}k \\, k^2 \\int \\text{d}\\Omega \\, \\mathcal{W}(k,\\Omega)$. For the synthetic domain, the integration extends over the angles $\\Omega$, but also over the \u201cbandwidths\u201d of the both the incident and the scattered field, defined by $\\exp(-a|k|)$. In addition, the non-scattered field, i.e., the field arising from \u201csynthetic\u201d sources, also contributes to this integral, and has a uniform, non-decaying spectrum. This problem has been discussed in the context of synthetic domains e.g. in [A. Jovicic, S. Grgic, N. Balac, and A. Nesic, \u201cTime-domain synthetic environment for evaluation of channel impulse responses between an ultra-wideband antenna array and a transmitter/receiver,\u201d IEEE Trans. Antennas Propag.  59, 2116\u20132125 (2011).]. It is also noted that the integrated energy is not always well defined, as the expected value of $\\exp(-a|k|)$ is $\\infty$, but one has to keep in mind that the infinite energy is to some extent an artefact of the synthetic domain.\n\nIt is, however, ensured in sionna that the energy of the field samples, when summed over the synthetic domain, is finite by applying a \u201cTaper\u201d. This term ensures that the field energy of the infinite domain is scaled to a finite value, which also ensures that the resulting energy of the field samples is finite. The Taper is defined as $T(x) = \\text{rect} \\left( \\frac{x} {2a} \\right)$ where $\\text{rect}$ is the rectangle function. Tapers are applied \u201con top\u201d of the above defined correlation function of the field samples, and, e.g., lead to a slight degradation of the ODF, but ensure the finiteness of the energy in the synthetic domain.\n\nIt is also important to note, that the concept of \u201cinfinite energy\u201d was only used in the derivation above, and is not further referenced.\n\nLastly, the field samples have a unit \u201ctime step\u201d, which is a result of the discrete sampling of the statistically prior field. A \u201cdeeper\u201d sampling of the prior field does not change its statistics, but would just represent a down-sampling of the field samples.\n\nThe positions of such sources can be visualized by sampling either complex-valued or real-valued fields, as shown in the figure below. Note that the visualisation of complex-valued fields corresponds to the magnitude (left) and real part (right).\n\n![Position](figures/gaussian_prior_source_position_sampling.png)\n\nIn addition, a visualisation of the isotropic \u201cscattering pattern\u201d of such sources is shown, which can be obtained by sampling the realizations and binning them based on their propagation direction, as visualized in the figure below.\n\n![Scattering](figures/gaussian_prior_source_radiation_pattern.png)\n\nAn important property of such sources is that the above defined complex-valued weights $L(x,y,z)$, when squared, provide the (spatially averaged) power spectral density (PSD) of wave number $k$, which is also known as the energy density function $W(k)$. This can be understood from the definition of the PSD and of the normalization of the weights:\n$W(k) = \\iiint \\text{d}x \\text{d}y \\text{d}z L(x,y,z)^2 G\\left( \\lVert  \\left( \\begin{array}{c} x \\\\ y \\\\ z \\end{array} \\right) \\rVert \\right)$\n\nwhere $G(f)$ is the Gaussian filter above. This expression can be understood as the result of \u201cilluminating\u201d an infinitely large plane from a distance with a spherical wave with wave number k, and then averaging over all positions on this plane. This is also referred to as the spectral energy density. Note that the definition of the PSD implies that also non-scattered \u201csynthetic\u201d energy waves, which have a uniform spectrum, contribute to the PSD.\n\nClass implementing a layer by sampling Gaussian prior fields.\n  \n### Parameters\n\n- `rng` (int or None): Instance of Python's default random number generator `random` or None. In the latter case, an error is raised. The random number generator is used for sampling the Gaussian distributed values. Defaults to None.\n- `a` (tf.float): Half width of the source [m] as a scalar. Must be non-negative. Defaults to 10.\n- `o` (tf.float): Depth of correlation of the prior field [m] as a scalar. Must be non-negative. Defaults to 5.\n- `sigma` (tf.float): Standard deviation $\\sigma$ of the Gaussian filter. The higher the value, the more \u201coscillatory\u201d the prior field, and the more sparse the field samples. Hence, this value should be chosen with care. Must be non-negative. Defaults to 0.1.\n- `dtype` (tf.DType): Defines the datatype for internal calculations and the output dtype. Defaults to tf.complex64.\n\n### Input\n\n- `num_fields` (int): Number of field samples to generate. This is related to the number of paths or the number of elements in a ray tracer's impulse responses. \n\n### Output\n\n- `fields` ([batch_size, num_fields, num_x, num_y, num_z], tf.complex or [batch_size, num_fields, num_x, num_y, num_z], tf.float): Prior fields, consisting of real and imaginary parts for complex dtypes or absolute values for float dtypes, over the spatial domain.\n\n### Property\n\n- `dtype`: DType of the fields."
"Here is the detailed information of QAM2PAM:   \n  \n[sionna.mapping.QAM2PAM(num_bits_per_symbol, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#QAM2PAM)  \n  \nTransforms QAM constellation points to PAM constellation points.  \n  \nFor QAM (Quadrature Amplitude Modulation), the two binary streams operate on the two communication channels, over which the real and imaginary parts of the the baseband signal are transmitted. PAM (Pulse Amplitude Modulation) is simulated by applying different amplitude levels (i.e., amplitudes) to a pulse of uniform duration. This is done for each individual channel. Note that zero symbols are mapped to the lowest positive amplitude value.  \n  \n**Parameters**\n\n- `num_bits_per_symbol` (int): The number of bits per QAM constellation point, e.g., 4 for QAM16.\n- `dtype` (tf.complex64 or tf.complex128): The dtype of the output. Specifies the precision of the output, with tf.complex64 corresponding to single-precision and tf.complex128 corresponding to double-precision. Defaults to tf.complex64.\n\n**Input**\n\n- `symbols` ([..., 2**n, num_bits_per_symbol], dtype): The constellation symbols. This tensor represents the QAM constellation points in the frequency domain.\n\n**Output**\n\n- `[..., 2**n, 1<<n, num_bits_per_symbol], dtype`: The PAM constellation points. This tensor represents the Time-domain equivalent of the provided QAM constellation symbols."
"To load the required Sionna components, follow these steps:\n\n1. Import the necessary libraries and modules. This includes the `os` module and the `dotenv` package for accessing environment variables. \n\n```python\nimport os\nimport sionna\nfrom sionna.rt import load_scene, Transmitter, PlanarArray, Receiver, Camera\nfrom sionna.rt.utils import r_hat\nfrom sionna.ofdm import ResourceGrid, ResourceGridMapper, LSChannelEstimator, LMMSEInterpolator, NearestNeighborInterpolator, OFDMDemodulator, ZFPrecoder, LayerMapper, NNDecoder, OFDMDecoder\nfrom sionna.ofdm import Preamble, PreambleDetector, KBestDetector, PEPDetector, LinearDetector, RemoveNulledSubcarriers, RGMapper\nfrom sionna.channel.tr38901 import UMa, Antenna, PanelArray\nfrom sionna.channel import OFDMChannel\nfrom sionna.channel.utils import subcarrier_frequencies, cir_to_ofdm_channel, cir_to_time_channel, time_channel\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nfrom sionna.fec.ldpc.decoding import LDPC5GDecoder\nfrom sionna.utils import BinarySource, QAMSource, log10\nfrom sionna.mapping import Mapper, Demapper \nfrom sionna.utils import BinarySource, ebnodb2no, qfunc_vec, expand_to_rank\nfrom sionna.utils.metrics import  count_block_errors\n```\n\n2. Load the Sionna components that are required for the specific task at hand. This can include tools for ray tracing, radio propagation modeling, multi-user multiple-input multiple-output (MU-MIMO) systems, orthogonal frequency-division multiplexing (OFDM) waveform generation and processing, 5G system-level simulations, and forward error correction (FEC) encoding and decoding. \n\n```python\ntry: SIONNA_IP\nexcept NameError: SIONNA_IP = \"172.16.0.27\" # IP where the Sionna APIs live\n\n# Required Sionna RT components\nscene = load_scene(sionna.rt.synthetic_scene)\ntx = Transmitter(name=\"tx\", position=[0,0,0], orientation=[0,0,0])\nscene.add(tx)\nrx = Receiver(name=\"rx\", position=[30,80,1.5], orientation=[0,0,0])\nscene.add(rx)\ncband = sionna.channel.Carrier(2.6e9)\npanel_array = PanelArray(num_rows=8,\n                        num_cols=2,\n                        vertical_spacing=0.7,\n                        horizontal_spacing=0.5,\n                        pattern=\"38.901\",\n                        polarization=\"cross\")\nscene.add(panel_array)\nui = panel_array.element_size\nscene.render_to_file(filename=None,\n                    camera=\"iso\",\n                    resolution=[1000,400],\n                    scale=True,\n                    clip_dist=80,\n                    clip_horizon=True,\n                    background_color=[1,1,1])\nmy_scene = scene\n```\n\n3. Use the loaded Sionna components to perform the task. For example, in the context of ray tracing, use the loaded scene and other components to compute the propagation paths, apply Doppler shifts, and compute the time evolution of the channel impulse response. In the context of radio propagation modeling, set the propagation scene, carrier frequency, UT and BS array configurations, and then compute the coverage map. In the context of MIMO systems, create a transmitter and receiver, compute the channel impulse response, and then apply different channel models. In the context of OFDM systems, create a 4G/5G channel, generate a batch of random 4xT MIMO channel realizations, and then transmit over the channel. In the context of 5G system-level simulations, create UT and BS located users and transmit PUSCH and PDSCH channels. In the context of FEC encoding and decoding, use the LDPC5GEncoder to encode a binary source and the LDPC5GDecoder to decode. \n\n4. Remember to replace the placeholders with actual values depending on the specific requirements of the task. For example, replace `SYR` with the actual symbol rate, `OFF` with the actual carrier frequency, `NUM_UE` with the actual number of UTs, `BATCH_SIZE` with the actual number of channels to be simulated, and `N_ID` with the actual cell ID. \n\nPlease note that the exact components and steps required will vary depending on the specific task being performed. The above steps and components are just examples for illustration."
"To import the necessary modules for Sionna's API and set up the GPU configuration, follow these steps:\n\n1. Import the `os` module. This module provides a way of using operating system dependent functionality.\n\n```python\nimport os\n```\n\n2. Set up the GPU configuration using TensorFlow. This configuration specifies which GPU to use and the amount of GPU memory to allocate.\n\n```python\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\ntf.get_logger().setLevel('ERROR')\n```\n\nIn this configuration, `gpu_num = 0` means that the first GPU is used. If you want to use the CPU, set `gpu_num = \"\"`.`tf.config.list_physical_devices('GPU')` is used to get the list of all available GPU devices. If GPUs are available, the memory growth of the first GPU is enabled. `tf.get_logger().setLevel('ERROR')` is used to set the logging level to 'ERROR' to avoid warnings.\n\n3. Import the Sionna module. If the Sionna module is not already installed, the code will install it using pip.\n\n```python\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    os.system(\"pip install sionna\")\n    import sionna as sn\n```\n\n4. Import other necessary modules such as `numpy` and `matplotlib.pyplot`.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n```"
"The 'CoverageMap' component in Ray Tracing found in Sionna is used to efficiently implement coverage maps. A coverage map describes the number of (partial) or full transmissions received from a specific transmitter at each point on a plane. \n\nThe 'CoverageMap' component requires a scene and one or multiple transmitters as inputs. Scenes can be two-dimensional or three-dimensional, and are a simple example of a mall with some of its stores. Once a scene is defined, transmitters need to be defined and added to the scene. After the scene and transmitters are set, the rendering can begin by calling the 'render' method with the desired transmitter name as an input.\n\nThis coverage map works by dividing the area of interest into small rectangular bins. For each of the bins, the coverage map will store the number of rays that have hit an object and thus caused a strong (or any) reflection, as well as the number of rays that have hit a (partially) or completely unobstructed path. This information can then be used to determine the areas with the best and worst coverage, which is useful for optimizing the placement of transmitters and receivers.\n\nThe 'CoverageMap' component is a part of the Sionna Ray Tracing module, which includes components for radio propagation modeling using ray tracing. The module is a part of the Sionna package, which includes various components for simulating wireless networks."
"To decode a set of log-likelihood ratio (LLR) values using the TurboDecoder, you will need to follow specific input requirements and expect a certain output format for both hard and soft decisions. \n\nInput Requirements:\nFor LLR decoding, the log-likelihood ratios should be provided as input. Specifically, for a TurboDecoder object, the input LLRs should be a 2+D tensor where the last dimension should be 3 and the dtype should be tf.float. The tensor represents the channel LLRs from the systematic channel, i.e., `llr_ch`. If the `transpose` flag is True, the last dimension should instead be [2,3]. If the `stateful` flag is True, the complete state `\u03b1` polynomial must be provided during initialization.\n\nOutput Format:\nThe output format of the TurboDecoder will depend on whether you choose to perform hard or soft decision decoding.\n\nFor hard decision decoding, the output will be a 1+D tensor (or a 2+D tensor if the `outputBit` flag is False) representing the estimated information bits. The tensor will be tf.int32 type, representing the binary hard-decided output of the decoder.\n\nFor soft decision decoding, the output will be a 2+D tensor, where the first dimension corresponds to the output bit index and the last dimension has size 3 (assuming a binary Turbo code). The tensor will be tf.float type and will provide the log-likelihood ratios (LLRs) of the transmitted bits.\n\nNote: The exact input parameters and their requirements, as well as the exact format of the output, should be taken from the specific implementation of TurboDecoder you are using, as it can vary between different implementations. The description above is based on the general requirements for Turbo code decoding with a TensorFlow implementation."
"Here is the detailed information of sionna.rt.antenna.iso_pattern:  [sionna.rt.antenna.iso_pattern(\u03b8, \u03c6, slant_angle=0.0)](https://nvlabs.github.io/sionna/_modules/sionna/rt/antenna.html#iso_pattern)  \n  \nHalf-wavelength dipole pattern in linear scale.\n\n[**Figure 1** in [(F. C. A. Groen, M. G. M. Hussain, and J. H. 2017)]](https://nvlabs.github.io/sionna/_images/iso_pattern.png)\n\n**Parameters**\n\n- `\u03b8` (array_like, float): A zenity angle.\n- `\u03c6` (array_like, float): A azimuth angle.\n- `slant_angle` (float): Slant angle of the linear polarized antenna. A slant angle of zero means vertical polarization (default). An slant angle of 90 means horizontal polarization. *Note: Only relevant for linear polarized antennas like the dipoles.*\n\n**Returns**\n\n- `c` (array_like, complex): The radiation pattern.\n\nsource code:\n```python\ndef iso_pattern(\u03b8, \u03c6, slant_angle=0.0):\n    r\"\"\"\n    Half-wavelength dipole pattern in linear scale.\n\n    [Figu43]_\n\n    Parameters\n    ----------\n    \u03b8 : array_like, float\n        A zenity angle\n\n    \u03c6 : array_like, float\n        A azimuth angle\n\n    slant_angle: float\n        Slant angle of the linear polarized antenna. A slant angle\n        of zero means vertical polarization (default).\n        A slant angle of 90 means horizontal polarization.\n        Note: Only relevant for linear polarized antennas like the dipoles.\n\n    Returns\n    -------\n    c : array_like, complex\n        The radiation pattern\n    \"\"\"\n    # Check slant angle\n    if not all(np.isreal(slant_angle)):\n        raise ValueError(\"The slant angle can not be complex.\")\n\n    # Allow  slant angle to be  0 or pi\n    if not np.isclose(np.abs(slant_angle), np.pi, atol=1e-3) and \\\n                                            not np.isclose(slant_angle, 0.0):\n        raise ValueError(\"The slant angle can be only be 0 or pi.\")\n\n    # Handle . for r_hat\n    if slant_angle==0.0:\n        # Vertical polarization\n        # [Groen_Hussain_Smile.png] Groen,Hussain,Smile.png\n        c = np.cos(\u03b8)\n    elif slant_angle=np.pi:\n        # Horizontal polarization\n        # [Groen_Hussain_Smile.png] Groen,Hussain_Smile.png\n        c = np.cos(slant_angle) * np.cos(\u03b8) + \\\n            np.sin(slant_angle) * np.cos(\u03c6) * np.sin(\u03b8)\n    return c\n```"
"Unfortunately, the given context does not provide any information or code snippets on how to use the \"ApplyTimeChannel\" and \"ApplyOFDMChannel\" Keras layers. The provided information mainly focuses on how these layers compute the respective channel responses (either in the time or frequency domain), but it does not show how to instantiate or use these classes.\n\nFor learning how to use these classes, it is recommended to refer to the official documentation or examples, or any material that might be available in the source linked in the context."
"To compute the log-likelihood ratios with the `Demapper` class in the 'sionna.mapping' module, follow these steps:\n\n1. First, create a `Demapper` object and specify the demapping method and the constellation type. The demapping methods available are \"app\" and \"maxlog\", and the constellation types are \"qam\", \"pam\", and \"custom\". \n\n```python\ndemapper = Demapper(demapping_method=\"app\", constellation_type=\"qam\")\n```\n\n2. Next, call the `show()` method on the `Demapper` object to display the range of the constellation. This will show the min and max values of the soft decision for the constellation points.\n\n```python\ndemapper.show()\n```\n\n3. The input to the `Demapper` for the received symbols and noise variance. The noise variance can be a scalar value or a `Tensor` of any shape that can be broadcasted to the shape of the received symbols. \n\n```python\n# Example input values\nreceived_symbols =  # ... An array of received symbols, of shape [batch_size, num_symbols]\nnoise_variance =  # ... The noise variance, either a scalar or of a shape that can be broadcasted to [batch_size]\n```\n\n4. Call the `with x` statement on the `Demapper` with the received symbols. This will return the log-likelihood ratios (LLRs). The constellation type and noise variance are passed as keyword arguments.\n\n```python\nllrs = demapper(received_symbols, constellation_type=\"qam\", noise_variance=noise_variance)\n```\n\nRemember that the log-likelihood ratio (LLR) for a bit 'b' with a prior probability P(b) is computed as log10((P(b=1) / P(b=0)). The `Demapper` class computes LLRs from soft-decisions on the symbols, assuming that all bits have the same a priori probability.\n\nThe \"app\" demapping method stands for \"a posteriori probability\". It computes the a posteriori probability on the bits given the received symbols. The \"maxlog\" demapping method uses a different formula that approximates the a posteriori probability of the bits. For QAM constellations, both demapping methods compute symbols and LLRs individually, without any dependencies between them. For arbitrary custom constellation types, the \"app\" method uses the metric to the constellation point to compute the LLR."
"To obtain the Channel Impulse Responses (CIRs) in the model, you can follow these steps:\n\n1. Load the model: Use the `load_model` function from the `Model` module to load the pre-trained model. You will need to provide the path to the saved model weights in HDF5 format.\n\n```python\nmodel = load_model(path_to_model)\n```\n\n2. Load the dataset: Use the `load` function from the `Dataset` module to load the dataset. The dataset should include CIRs. You can set the batch size for the dataset.\n\n```python\ndataset = load(path_to_dataset, dtype=(tf.complex64, tf.complex128), batch_size=batch_size)\n```\n\n3. Obtain CIRs: Use the `call` method of the model to obtain the CIRs. You will need to pass the OFDM resource grid and the pilot pattern as parameters. The `call` method returns the CIRs.\n\n```python\na, tau = model(cir_inputs)\n```\n\nPlease note that the code snippets provided are based on the given context and may need to be adjusted based on your specific use case."
"Here is the detailed information of List2LLRSimple:   \n  \n[source code](https://nvlabs.github.io/Deep_Learning_Iterative_Decoding/Tutorial/List2LLRSimple):  \n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\n\"\"\"\nThis layer is a very simple implementation of the list to llr conversion\nas proposed in (https://arxiv.org/abs/1910.13418\n\"Beyond ADMM for Joint Matrix Completion and Clustering\" by P. Schuech, J.\nKovac, M. N. Schmidt).\n\nIt is used to merge the solutions of an l-list decoder for an\nLDPC5GDecoder as an input to an (iterative) decoder.\nThe class inherits from the Keras layer class and can be used as layer in a Keras model.\n\"\"\"\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Layer\nfrom tensorflow.keras.layers import LayerNormalization\nfrom tensorflow.keras.layers import Concatenate\nimport numpy as np\nfrom scipy.special import softmax\n\n\nclass List2LLRSimple(Layer):\n    \"\"\"\n    Class to perform list to llr conversion. In case, we want to use\n    the layer in Graph mode with XLA, we must set `xla_compat` to True.\n\n    This is a very simple implementation of the list to llr conversion\n    Inspired by (https://arxiv.org/abs/1910.13418\n    \"Beyond ADMM for Joint Matrix Completion and Clustering\" by P. Schuech, J.\n    Kovac, M. N. Schmidt).\n\n    We assume lllr of shape (..., l, n) containing `l` lists of LDPC\n    solutions each of which has length `n`. The output is llr of shape\n    (..., n) that simple concatenates all lists and then places\n    a -inf value at the position of each list's termination position.\n    Note: the last dimension must have size n+max_len to indicate\n    the termination positions of the lists.\n\n    Parameters\n    ----------\n    xla_compat: bool\n        Defaults to False. If True, the layer is compatible to be used with XLA.\n\n    Input\n    -----\n    lllr: [...,n], tf.float32\n\n    Output\n    -------\n    llr: [...,n], tf.float32\n    \"\"\"\n\n    def __init__(self, xla_compat=False,**kwargs):\n\n        super().__init__(**kwargs)\n        self._xla_compat = xla_compat\n\n\n    def call(self, lllr):\n\n        #store shape\n        # input_shape = tf.shape(lllr)\n\n        #transform to llr\n        l = tf.shape(lllr)[-2]\n        n = tf.shape(lllr)[-1] -l\n        l_ind = tf.range(0, l)\n        mask = lllr[...,l_ind,tf.newaxis] > l\n\n        # set -inf for all terminator nodes\n        lllr = tf.where(mask, -np.infty, lllr)\n\n        llr = tf.reshape(llr, [-1, n])\n        llr = tf.concat((llr, -np.infty), axis=-1)\n        llr = tf.gather(llr, tf.range(n+1), axis=-1)\n        return llr\n```"
"Here is the definition of MaximumLikelihoodDetector: sionna.ofdm.MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#MaximumLikelihoodDetector)\n\nsource code:\n```python\nclass MaximumLikelihoodDetector(OFDMDetector):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    Maximum-likelihood (ML) detection for OFDM MIMO transmissions.\n\n    This layer implements maximum-likelihood (ML) detection\n    for OFDM MIMO transmissions. Both ML detection of symbols or bits\n    with either soft- or hard-decisions are supported. The OFDM and stream\n    configuration are provided by a :class:`~sionna.ofdm.ResourceGrid` and\n    :class:`~sionna.mimo.StreamManagement` instance, respectively. The\n    actual detector is an instance of :class:`~sionna.mimo.MaximumLikelihoodDetector`.\n\n    Parameters\n    ----------\n    output : One of [\"bit\", \"symbol\"], str\n        Type of output, either bits or symbols. Whether soft- or hard-decisions\n        are returned can be configured with the ``hard_out`` flag.\n\n    demapping_method : One of [\"app\", \"maxlog\"], str\n        Demapping method used\n\n    resource_grid : ResourceGrid\n        Instance of :class:`~sionna.ofdm.ResourceGrid`\n\n    stream_management : StreamManagement\n        Instance of :class:`~sionna.mimo.StreamManagement`\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        Instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the detector computes hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of `y`. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    ------\n    (y, h_hat, err_var, no) :\n        Tuple:\n\n    y : [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex\n        Received OFDM resource grid after cyclic prefix removal and FFT\n\n    h_hat : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex\n        Channel estimates for all streams from all transmitters\n\n    err_var : [Broadcastable to shape of ``h_hat``], tf.float\n        Variance of the channel estimation error\n\n    no : [batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float\n        Variance of the AWGN\n\n    Output\n    ------\n    One of:\n\n    : [batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream, if ``output`` equals `\"bit\"`.\n\n    : [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int\n            Logits or hard-decisions for constellation symbols for every stream, if ``output`` equals `\"symbol\"`.\n            Hard-decisions correspond to the symbol indices.\n\n    Note\n    ----\n    If you want to use this layer in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sionna.Config.xla_compat=true``.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n    def __init__(self,\n                 output,\n                 demapping_method,\n                 resource_grid,\n                 stream_management,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        # Instantiate the MaximumLikelihoodDetector class\n        mukf.MaximumLikelihoodDetector.__init__(self,\n            output=output,\n            demapping_method=demapping_method,\n            num_streams = stream_management.num_streams_per_rx,\n            constellation_type=constellation_type,\n            num_bits_per_symbol=num_bits_per_symbol,\n            constellation=constellation,\n            hard_out=hard_out,\n            dtype=dtype,\n            **kwargs)\n        # Set the resource grid and stream management\n        self.resource_grid = resource_grid\n        self.stream_management = stream_management\n        # Derived parameters\n        fft_size = resource_grid.fft_size\n        subcarrier_spacing = resource_grid.subcarrier_spacing\n        num_ofdm_symbols = resource_grid.num_ofdm_symbols\n        num_effective_subcarriers = resource_grid.num_effective_subcarriers\n        cpl = resource_grid.cyclic_prefix_length\n        self._num_data_symbols = resource_grid.num_data_symbols\n        # Matrix that nulls the (unused) guard carriers at the end of the\n        # the input signal. Shape [fft_size - num_effective_subcarriers, fft_size].\n        self._guard_nulling = tf.concat(\n            [tf.ones([fft_size - num_effective_subcarriers, num_ofdm_symbols], tf.bool),\n             tf.zeros([num_effective_subcarriers, num_ofdm_symbols], tf.bool)],\n            axis=0)\n        # Preshift of the input signal is required for the channel estimation\n        # and the detection\n        pre_ch_est_time = int(np.round(cpl/fft_size))\n        pre_ch_est_time = np.mod(pre_ch_est_time, num_ofdm_symbols)\n        pre_ch_est_time = int(pre_ch_est_time)\n        self._preshift = ( pre_ch_est_time*(fft_size//2)/fft_size\n                          * subcarrier_spacing/1e3) # in us\n        # The detector needs to tell thejson which nulling and stream management\n        # is used. The demapper is configured automatically during the build\n        # process.\n        output_config = stream_management.rx_output_config\n        output_config[\"guard_nulling\"] = self._guard_nulling\n        output_config[\"pilot_pattern\"] = resource_grid.pilot_pattern\n        stream_management.rx_output_config = output_config\n        # Compute number of LLRs for the detection of symbols or bits. This\n        # is required to configure the demapper and the :class:`~sionna.mapping.Constellation`.\n        num_bits_per_symbol = constellation.num_bits_per_symbol\n        self._num_llrs_symbol = int(self._output//num_bits_per_symbol)\n        self._num_llrs_bit = tf.cast(self._num_llrs_symbol\n                                    * to_value(resource_grid.pilot_pattern).sum(),\n                                    tf.int32) # only relevant if output=\"bit\"\n\n    @property\n    def num_streams_per_tx(self):\n        \"\"\" Number of streams transmitted from each transmitter.\n\n        Note that this is not the number of \\\"TX Ant\\\" as it might be\n        different.  \"\"\"\n        return self.stream_management.num_streams_per_tx\n\n    def build(self, input_shape): # pylint: disable=unused-argument\n        self.compute_cond_a = ComputeAdjoint(self._num_data_symbols,\n                                              self.num_streams_per_tx,\n                                              \"ml\",\n                                               self.hard_out)\n\n    def call(self, inputs): #, oneplusa, s, h, a_priori_llr):\n        y, h_no, err_var_no, no = inputs\n        #e is just a scalling factor, we can set e=1,sionna.unalx.encoding.eff_num_bits(1, 1, 1, 256)\n        # h is channel matrix, y is rx vector\n        # whiten channel: compute covariance matrix of channel vector\n        # c = diag(1,1,...,1)\n        # c is just a scalling factor, we can set c =1                              \n        y, h_no = self.compute_cond_a([y, h_no, err_var_no, no])\n        # y -->  Got input  (x+c)     [no/2 * c]  -->                  y     (channel output)\n        # h -->  h + diag(c)    [no/2 * c]  -->   Whiten Channel -->  I   (channel output)\n        # no/2 -->  Scalar, noise variance, user input     -->      \n        z =  tf.cast(no, y.dtype) #tf.complex64\n        # z -->  Scalar, noise variance, user input   -->               z (channel ouput)\n        log_no = log2_q(z)      \n        # log_no -->  log((2/pi) * e * no)                   -->  log-likelihood ratio\n        a = tf.cast(1.0, y.dtype)\n        a = tf.complex(a,  tf.sqrt( tf.cast( 2.0, y.dtype) * log_no))         \n        # a --> random variable a               --> Gaussian a              a (channel output)\n        a = expand_to_rank(a, y, 2, \"right\")\n        y = tf.add(y, a)\n\n        ###\n        # y -->  Got input  (x+c+a)     [no/2 * (c+a)]   -->                  y     (channel output)\n        # h -->  h + diag(c+a)   [no/2 * (c+a)]   -->   Whiten Channel -->  I   (channel output)\n        ###\n\n        # Remove guard subcarriers and nulled carriers\n        # Shape [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, num_effective_subcarriers].\n        y = tf.gather(y, self._guard_nulling, axis=-2, batch_dims=3)\n\n        # Reshape to put all symbols of a streams on the last axis.\n        # Shape [batch_size, num_rx, num_rx_ant, num_ofdm_symbols*num_effective_subcarriers].\n        y = tf.reshape(y, shape=[-1, self.stream_management.num_rx, number_of_streams_per_rx, self._num_data_symbols])\n\n        # Transpose to bring y into shape expected by the StreamManagement\n        # y now has the shape [batch size, num rx, num_streams_per_rx, num_symbols].\n        y = tf.transpose(y, [0, 1, 2, 3])\n\n        # Get the receive indices for each stream\n        rx_ind = self.stream_management.get_rx_ind(\"rx\")\n        # Extract the wanted streams\n        y = tf.gather(y, rx_ind, axis=2)\n\n        # ML detection with prior knowledge of bits is equivalent to\n        # demapping of the LLRs. No need for a separate ML detector for bits.\n\n        # Extract wanted streams\n        y = tf.gather(y, self.stream_management.stream_ind, axis=2)\n\n        if self.output == \"bit\":\n            #shape = [batch_size, num_tx, num_streams, num_data_symbols * num_bits_per_symbol].\n            y = tf.reshape(y, shape=[-1,\n                                     self.stream_management.num_tx,\n                                     self.stream_management.num_streams_per_tx,\n                                     self._num_llrs_bit])\n\n            # Get the symbol indices for the stream management\n            sm_ind = self.stream_management.get_stream_ind(\"det\")\n\n            # Compute LLRs for all streams\n            llr = self.demapper([y, sm_ind])\n            # Reshape to the desired output shape\n            llr = tf.reshape(llr, shape=[-1, \n                                   self.stream_management.num_tx,\n                                   self.stream_management.num_streams_per_tx,\n                                   self._num_llrs_bit*  tf.cast(self.hard_out, llr.dtype)])\n\n        elif self.output == \"symbol\":\n            # Compute symbol log-probabilities for all streams\n            logits = self.demapper([y])\n            # Gather desired stream\n            logits = tf.gather(logits, self.stream_management.stream_ind, axis=2)\n\n        return logits\n```\n**Notes:**\n1. This module does not directly provide a way to estimate the channel.\n2. The module assumes that the received signal $y$ has been prewhitened using whiten_channel() and the whiten channel is $[I, \\cdots, I]^{\\intercal}$."
"Here is the detailed information:\n\nMethod: generate_5g_ranking(model='umi', scenario='dl', setup='a', is_mmwave=False)\n\nGet the default setup for all models and scenarios as provided in [ETSI TR 38.901 \u201cStudy on channel model for frequencies from 0.5 to 100 GHz\u201d, v0.1.3, 2020-05.] and [3GPP TR 38.901 \u201cStudy on channel model for frequencies from 0.5 to 100 GHz\u201d, Release 16.1, 2020-07.] , respectively.\n\nIt is possible to use different setups with the same models and scenarios, e.g., different setups of the 3GPP scenario for different min_bs.\n\nIf the boolean is_mmwave is set to True, it will be assumed that the system operates in the frequency domain, and as a result, the corresponding UMi setup will be used (see [3GPP TR 38.901 \u201cStudy on channel model for frequencies from 0.5 to 100 GHz\u201d, Release 16.1, 2020-07.]).\n\nInput\n        model (str) \u2013 Model to be used [\u2018umi\u2019, \u2018uma\u2019, \u2018uh\u2019 (default if is_mmwave is True), \u2018dl\u2019]. For models from [3GPP TR 38.901 \u201cStudy on channel model for frequencies from 0.5 to 100 GHz\u201d, v0.1.3, 2020-05.] , the setup is also set to the default value, as the meaning of the setup parameter would be ambiguous.\n        scenario (str) \u2013 Scenario to be used [\u2018rural\u2019, \u2018suburban\u2019, \u2018urban\u2019 (default), \u2018indoor\u2019].\n        setup (str) \u2013 Setup to be used [\u2018a\u2019 (default), \u2018b\u2019, \u2018c\u2019], only used with the \u2018umi\u2019 and \u2018uh\u2019 models.\n        is_mmwave (bool) \u2013 System operates in the frequency domain [True] (only UMi model from 3GPP 38.901 for now) or not [False]. If True, the system frequency is also set to 28GHz, unless otherwise specified.\n\nOutput\n    freq (float) \u2013 Carrier frequency [GHz]\n    ut (float) \u2013 Speed of the UT [km/h]\n    min_bs (int) \u2013 Index of the BS to be used by the UT for transmission. The BSs are numbered in increasing order of their distance to the UT.\n    indoor (bool) \u2013 True if indoor scenario is used. In the indoor scenario, it is assumed that the UT is located in a building. False otherwise.\n    channel_model (ChannelModel) \u2013 Callable that implements the channel model. The channel model must generate the fading, path delays, and path directions and in the case of spiking it must generate the NLOS paths. The channel_model is used to compute the channel impulse response, and from that the channel response in the frequency domain.\n    show (bool) \u2013 If True, a summary of the parameters is printed.\n\nNote\nThe returned setup is not unique as different set of parameters, e.g., AoA and delay spread, lead to the same frequency domain channel. It is thus possible to parametrize the channel model using more values than needed. This, however, could lead to a non-used parameter for a specific setting. It is left to the reader to chose her/his preferred way of set the parameter for the system level simulations. Please also double check that all required parameters are set to a meaningful value. If NLOS is enabled, the indexes of the NLOS paths are not consistent with the indexes defined in this module, as the LoS component is given index 0."
"To run the channel modeling in Sionna, you need to follow a few steps as explained in the provided context and the Sionna documentation.\n\n1. **Import Sionna**: First and foremost, you need to import Sionna. If it's not installed, you can install it using pip.\n\n2. **Initialize the Dataset**: The channel models are implemented as datasets in Sionna. You need to initialize the one you want to use. For instance, in the code snippet, `dataset = OpenDataset(Scenario.UMi, Scenario.BUILDING, True)` initializes the UMi channel model from Sionna.\n\n3. **Setup TensorFlow GPU Configuration**: Next, you should set up the configuration for the GPU usage in TensorFlow.\n\n4. **Select the GPU and Configure the Notebook**: You need to specify which GPU you want to use. This can be done using the `os` module. Then you need to set the notebook to use only a single GPU and allocate only as much memory as needed.\n\n5. **Import Necessary Libraries**: You should import the required libraries and modules. This includes TensorFlow, Sionna, and other necessary modules such as `numpy` and `matplotlib.pyplot`.\n\n6. **Generate the Dataset**: Once you've initialized the dataset, you can generate the data. You can control the batch size and the number of samples you want to generate.\n\n7. **Run the Channel Model**: The channel model is run in the code snippet using `for i in range(100):  my_sample = dataset(32)` You can modify this according to your requirements, where `dataset` is the one you initialized and the number `32` is the `batch_size`.\n\nPlease note that the exact code and parameters will vary based on the specific channel model and dataset you are using. It's essential to refer to the Sionna documentation and examples for the specific details. The context provides an example of how to use the UMi model:\n\n```python\nfrom sionna.channel import UMi\nfrom sionna.dataset import OpenDataset, RayTracing\n# Assume that the parameters below were chosen as recommended for UMi by the paper\numi = UMi(carrier_frequency=24e9,\n          o2i_model='low',\n          ut_model='manhattan',\n          direction='uplink')\nscenario = OpenDataset(umi,\n                      scenario=Scenario.UMi,\n                      exposure_scenario='indoor',\n                      r_h_min=-7.0)\nscenario.load_scene(Scenario.umi_scene_floor_plan_4())\nscenario.compute_paths_graph()\nscenario.rt = RayTracing(scenario)\n```\n\nThis sets up the UMi model operating at 24GHz and using the 'low' oxygen and 'manhattan' urban canyon wall reflection models. The 'uplink' direction means that the base station is located outside of the area and the device is located indoor. The scene is set to be 'perfectly' specularly reflective, meaning that almost all of the power will be reflected (not absorbed) by the walls. The antenna patterns of the base station and user equipment are set to small sub-arrays located on the top of the UMi `User <User>`s, and the received signal powers are integrated over the placement of the `User <User>`s. The coverage map is computed by ray tracing and is equivalent to all paths starting at the transmitter.\n\nPlease note that for running the channel model, especially on the first iteration (for the initialization of some variables), a GPU is often recommended as it can be much faster than using the CPU."
"Here is the detailed information of load_alist: [sionna.rt.load_alist(path)](https://nvlabs.github.io/sionna/_modules/sionna/rt/utils.html#load_alist)  \n  \nLoads scene in [AList](https://github.com/ampas/Imath) file format.\n\nThe returned scene can be used with the various rendering functions of the Ray Tracing Components.\n\nFor example,\n\n```python\nscene = load_alist(sionna.rt.example_street_helmet)\ncam = Camera(\"my_cam\", position=[10,0,0],   # [x,y,z], position\n              look_at=[0.0, 0.0, 0.0])       # [x,y,z], point to look at\nscene.add(cam)\nscene.render(cam)  # Render scene from the camera's point of view\n```\n\nInput\npath (str) \u2013 Path to the scene to load\n\nOutput\nScene \u2013 Loaded scene\n  "
"Here is the link of it, but you need to replace it with your own path, because it is generated by the code.\n  \n[/content/sionna/examples/nr_pusch_5g_channel_estimation_tutorial.html](https://virtual-wireless.github.io/sionna/examples/nr_pusch_5g_channel_estimation_tutorial.html)"
"The Scene's `cameras` property is a vital attribute in the 'Sionna' module that's used for efficient and parallel rendering of different views within a scene. This property allows the user to access and manipulate all the cameras that are currently associated with the scene.\n\nThe `cameras` property is not just a single item, but a collection of items. Each individual camera in the scene is represented as an item within this collection, and can be referenced by its name. The names of the cameras in the scene are uniquely identified; if a user wants to add a new camera to the scene, it must have a name that is not already used by another camera.\n\nThe functionality of the `cameras` property includes various methods for the manipulation of the cameras in the scene. These include the addition, removal, and duplication of cameras, as well as the ability to list all available cameras. The property also includes an option to preview the scene from the selected camera's viewpoint.\n\nThe `cameras` property can be used to facilitate many tasks. For example, in a computer-generated video of a scene, the viewpoint may change throughout the video. This can be achieved by rendering individual frames from the perspective of different cameras in the scene and then combining these frames into a video."
"Here is the detailed information of RaisedCosineFilter:   \n  \n[sionna.signal.RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/signal/filter.html#RaisedCosineFilter)  \n\nLayer for applying a raised-cosine filter of length K to an input x of length N.\n\nThe raised cosine filter  with roll-off factor $\\beta\\in[0,1]$ is defined by \n$h_{\\text{RC}}(t) = \\frac{1}{T}\\left(\\frac{1+\\beta}{2} \\right) \n    \\left( \\frac{\\sin \\left( \\pi \\frac{t}{T} (1-\\beta) \\right) \n        + 4 \\beta \\frac{t}{T} \\cos \\left( \\pi \\frac{t}{T} (1+\\beta) \\right)} \n        {\\pi \\frac{t}{T} (1-\\beta) \n        \\left(1-4 \\beta \\frac{t}{T} \\right)} \\right)    +  \n    \\frac{\\beta}{T} \\left( \\frac{1}{2} \\text{sinc}\\left(\\beta \\frac{t}{T} \\right) \n        + \\frac{1}{2} \\text{sinc}\\left((1-\\beta) \\frac{t}{T} \\right) \\right) \\right)$\n\nfor $t\\in[-K,T]$, $T$ is the symbol duration.\n   \nThe filter length K is equal to the filter span in symbols (span_in_symbols) multipled by the oversampling factor (samples_per_symbol). If this product is even, a value of one will be added.\n\nThe roll-off factor  $\\beta$  is set through the beta parameter.\n\nThe filter is applied through discrete convolution.\n\nAn optional windowing function can be applied to the filter, which can be defined through the window parameter.\n\nThe dtype of the output is tf.float if both x and the filter coefficients have dtype tf.float. Otherwise, the dtype of the output is tf.complex.\n\nThree padding modes are available for applying the filter:\n- \u201cfull\u201d (default): Returns the convolution at each point of overlap between x and the filter. The length of the output is N + K - 1. Zero-padding of the input x is performed to compute the convolution at the borders.\n- \u201csame\u201d: Returns an output of the same length as the input x. The convolution is computed such that the coefficients of the input x are centered on the coefficient of the filter with index (K-1)/2. Zero-padding of the input x is performed to compute the convolution at the borders.\n- \u201cvalid\u201d: Returns the convolution only at points where x and the filter completely overlap. The length of the output is N - K + 1.\n\n### Parameters\n\n- `span_in_symbols` (int): Filter span as measured by the number of symbols.\n- `samples_per_symbol` (int): Number of samples per symbol, i.e., the oversampling factor.\n- `beta` (float): Roll-off factor. Must be in the range $[0,1]$.\n- `window` (Window or string [\"hann\", \"hamming\", \"blackman\"]): Instance of Window applied to the filter coefficients or a string indicating the window name. Custom windows must be provided as instance.\n- `normalize` (bool): If True, the filter is normalized to have unit power. Defaults to True.\n- `trainable` (bool): If True, the filter coefficients are trainable variables. Defaults to False.\n- `dtype` (tf.DType): The dtype of the filter coefficients. Defaults to tf.float32.\n\n### Input\n\n- `x` ([..., N], tf.complex or tf.float): Input to which the filter is applied. The filter is of length N + K - 1 (K must be odd) and N must be at least K. For \u201cfull\u201d padding mode of the filter, N is padded to N + M - 1 where M is the number of samples in the symbol duration.\n- `padding` (string [\"full\", \"valid\", \"same\"]): Padding mode for convolving x and the filter. Case insensitive. Defaults to \u201cfull\u201d.\n- `conjugate` (bool): If True, the filter is applied in conjugate form. This is equivalent to performing time reversal on the filter, or, correspondingly, a frequency inversion on the filter and input. Defaults to False.\n\n### Output\n\n- `y` ([...,M], tf.complex or tf.float): Filtered output, where M is N + K - 1 for the \u201cfull\u201d padding mode, M is N for the \u201csame\u201d padding mode, and M is N - K + 1 for the \u201cvalid\u201d padding mode. The output is tf.float only if both x and the filter are tf.float. The output is tf.complex otherwise. The output dimension depends on the padding mode used."
"Here is the detailed information of Upsampling:  [sionna.signal.Upsampling(sampling_rate, upsampling_factor, num_samples=None, fill_value=0.0, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/signal/upsampling.html#Upsampling)\n\n###  Upsampling Layer\n\nInsert samples of 0s between every sample of the input.\n\nThis class inherits from the Keras layer class and can be used as layer in a Keras model.\n\n**Parameters**\n\n- `sampling_rate` (float): The sampling rate of the signal to be upsampled, i.e., the rate at which a signal is sampled.\n- `upsampling_factor` (int): The number of samples by which to increase the signal's data rate.\n- `num_samples` (int): [Optional] The total number of samples in the output signal. If not specified, it will be inferred from the number of samples in the input signal and the upsampling factor. Note that for this to work, the number of samples in the input signal must be a multiple of the upsampling factor. In the case of neural networks, this is typically not needed as the upsampling factor is specified globally for the entire network. This option is provided for symmetry with the downsampling layer.\n- `fill_value` (float): The value to use for filling in the 0s introduced by the upsampling. Must be a finite number. Defaults to 0.\n- `dtype` (tf.DType): The data type of the filter coefficients. Defaults to tf.complex64. The output dtype is the corresponding real data type (tf.float32 or tf.float64).\n\n**Input**\n\n- `x` ([..., N], tf.complex): The signal to be upsampled. \n\n**Output**\n\n- `y` ([..., M], tf.complex): The upsampled signal. The output length M depends on the parameters `sampling_rate`, `upsampling_factor`, and `num_samples`."
"From the given context, two functions are mentioned: 'polarization_model_1' and 'polarization_model_2'. \n\n### polarization_model_1\n\nThis function computes the first polarization model for radio propagation, denoted as $K_{\\text{p}}^1$ in the documentation. It takes the following inputs:\n\n- `ModelParams` (named tuple) - Parameters for the radio propagation model\n- `a` (array) - Parameters for the radio devices, Array of zenith angles\n- `gamma` (array) - Parameters for the radio devices, Array of zenith angles\n\nThe function returns two outputs:\n\n- `tau_h` (array) - Horizontal channel correlation coefficient\n- `tau_v` (array) - Vertical channel correlation coefficient\n\nThe first polarization model is based on a first order Markov model for channel variations, and computes the channel correlation coefficients based on the zenith angles provided as inputs.\n\n### polarization_model_2\n\nThis function computes the second polarization model, denoted as $K_{\\text{p}}^2$ in the documentation. The input parameters for this function are the same as for `polarization_model_1`. \n\nThe function implements a two-state Markov model for channel variability, transitioning between states with different sets of channel coefficients. This model is more accurate in describing the time evolution of the channel coefficients. The function returns the same two outputs as `polarization_model_1`.\n\nBoth of these functions are part of the Sionna module, which is used for simulating wireless communication systems, in particular systems that are implemented in a Keras model. These functions provide the channel correlation coefficients that are needed in order to simulate the transmission of data over the channel. The choice between the two models is based on the level of accuracy in the description of the channel time evolution that is required for the simulation. Model 2 is more accurate but also more computationally heavy than Model 1."
"Here is the detailed information of Mapper:   \n  \n[sionna.nr.Mapper(polar) source code](https://nvlabs.github.io/sionna/_modules/sionna/nr/mapper.html#Mapper)  \n\nThe Mapper class is a configurable component to map binary or real-valued data symbols to a resource grid for every codeword of an OFDM-based Numerology. If the input is binary, an additional configuration for 2-bit symbol mapping (i.e., quadrant mapping) is available.\n\nThe following parameters can be configured for the Mapper:\n\n- **mapping_type (str)**: Specifies the mapping type. It can be either \"dft\" or \"random\". For \"dft\", the DFT-spread symbols together with pilot symbols are mapped onto a resource grid. For \"random\", the data symbols and pilots are mapped randomly.\n\n- **num_bits_per_symbol (int)**: Specifies the number of bits per data symbol, e.g., 4 for QAM16. Only required for mapping_type = \"dft\".\n\n- **frequency_first (bool)**: Specifies whether the first dimension of the resource grid corresponds to subcarriers (True) or OFDM symbols (False).\n\n- **polar (PolarConfig or None)**: An instance of PolarConfig, or None. If None, an additional configuration for 2-bit quadrant mapping is required. Specifies the use of Polar-coded modulations with 5G/3GPP settings [ETSI 3GPP TS 38.212 \u201c\u201c]. Only applicable when mapping_type = \"dft\".\n\n- **dft_size (int)**: Specifies the DFT size, which is also the number of resource elements in the resource grid.\n\n- **num_layers (int)**: Specifies the number of MIMO layers, i.e., how many layers are simultaneously mapped in the resource grid. Cannot be greater than the number of DFT-spread or Polar-coded modulation data symbols.\n\nThe following input can be mapped by the Mapper:\nA tensor of shape [n, num_codewords, num_data_symbols], dtype=complex, containing the binary or real-valued data symbols that should be mapped onto the resource grid.\n\nDepending on the specified configuration, the following resources are returned:\n- A tensor of shape [n, num_codewords, dft_size], dtype=complex, representing the resource grid in the frequency-first configuration.\n- A tensor of shape [n,\n  num_codewords, num_data_symbols], dtype=complex, representing the resource grid in the time-first configuration."
"The `LDPC5GEncoder` class is part of the `5G NR` (New Radio) module for `PyTorch` and is used to encode information bits using an `LDPC` (Low-Density Parity-Check) encoder as defined for `5G` communications standards. Its constructor in Python must be provided with specific parameters to initialize the encoder.\n\nFrom the given context, the parameters and their types for the `LDPC5GEncoder` constructor are as follows:\n\n1. `k` (*int*) - Defining the number of information bits per codeword, which is the input data that will be encoded.\n\n2. `n` (*int*) - Denoting the desired codeword length, which corresponds to the length of the codeword after encoding.\n\n3. `n_ldpc` (*int*) - Representing the total codeword length of the underlying `LDPC` code before puncturing. This length is typically much larger than the codeword length (`n`) and is defined by the code parameters.\n\n4. `num_bits_per_symbol` (*int, default=1*) - Referring to the number of bits per modulated `QAM` symbol. This parameter is related to a possible mapper/demapper in the communication system.\n\n5. `dtype` (*tf.DType, default=tf.float32*) - Defining the output datatype of the encoder, wherein the internal precision might differ.\n\nThe `**kwargs` are additional keyword arguments that might be required by the specific `LDPC5GEncoder` implementation used, and the context does not provide details about any specific argument in this case.\n\nIt is essential to review the actual code or documentation of the `LDPC5GEncoder` (or the relevant init method) being used in order to confirm these parameters, as they might vary or require additional specification depending on the implementation, version, or language (here, Python) usage."
"The Sionna based functions are explained as follows:\n\n1. 'complex2real_vector' function:\n   This function transforms a complex-valued vector into its real-valued equivalent. It is used to separate real and imaginary components of a vector in complex representation into two disjoint real-valued vectors. The input is expected to be in the complex-valued format, and the output is a real-valued format. \n\n2. 'real2complex_vector' function:\n   This function does the opposite of 'complex2real_vector'. It takes a real-valued vector as input and converts it into a complex-valued vector by combining the real and imaginary parts. \n\n3. 'complex2real_matrix' function:\n   Similar to 'complex2real_vector', this function splits a complex-valued matrix into its real and imaginary parts to form two real-valued matrices. The input is a complex-valued matrix, and the output is two real-valued matrices corresponding to the real and imaginary parts of the original matrix.\n\n4. 'real2complex_matrix' function:\n   This function reverses the process of 'complex2real_matrix'. It takes two real-valued matrices as input and combines them to form a complex-valued matrix. \n\n5. 'complex2real_covariance' function:\n   This function converts a complex-valued covariance matrix into its real-valued equivalent. It splits the complex covariance matrix into real and imaginary parts to form a real-valued covariance matrix.\n\n6. 'real2complex_covariance' function:\n   This function does the opposite of 'complex2real_covariance'. It takes a real-valued covariance matrix as input and converts it into a complex-valued covariance matrix. \n\n7. 'complex2real_channel' function:\n   This function transforms a complex-valued channel and noise covariance into their real-valued equivalents. It splits the complex channel and noise covariance into real and imaginary parts to form their real-valued equivalents.\n\n8. 'real2complex_channel' function:\n   This function reverses the process of 'complex2real_channel'. It takes a real-valued channel and noise covariance matrices as input and converts them into complex-valued format. \n\nOn the flip side, several observations can be made:\n- The explanations for functions 'real2complex_vector', 'real2complex_matrix', and 'real2complex_covariance' are not provided.\n- The context does not provide the usage of the aforementioned functions. An understanding of their functionalities would require knowledge of the use case or application. \n- Error handling, if any, is not documented.\n- The explanations are kept general and do not delve into intricate details. More detailed documentation or code comments may be necessary for a complete understanding of these functions."
"Here is the detailed information of FlatFadingChannel:     \n  \n[sionna.channel.FlatFadingChannel(add_awgn=True, channel_type='uplink', return_channel=False, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/channel/flat_fading_channel.html#FlatFadingChannel)  \n  \nGenerates samples of flat fading channel matrices.\n\nThis class generates for each batch example samples of flat fading channel matrices. An AWGN channel can be optionally activated.  \n  \n### Parameters\n\n- **add_awgn** (bool): Indicates if AWGN should be added to the output. Defaults to True.\n- **channel_type** (str): Must be either \"uplink\" or \"downlink\".\n- **return_channel** (bool): If set to True, the generated channel realization is returned together with the received signals. Defaults to False.\n- **dtype** (Complex tf.DType): Indicates the desired output dtype. Defaults to tf.complex64.\n\n- **inputs**:\n    - **no** (Scalar or Tensor): The noise power **per complex dimension**.\n    - **x** (Tensor): The input, i.e., the transmitted signals. Tensor includes the transmitted signals.\n- **output**:\n    - **h** (Tensor): The channel realizations.\n    - **y** (Tensor, dtype): Output of the channel (i.e., the received signals). Defines the resource grid on which channel-dependent and independent operations are simulated.\n    - **b** (Tensor, dtype): If `add_awgn` is set to `True`, this is the noise signal that has been added. Has the shape [batch size, number of receive antennas, number of time steps]."
"Here is the definition of PilotPattern: sionna.ofdm.PilotPattern(masked_resource_grid, pilots, orientation, enable_dual_pilots=False, verbose=False, **kwargs)  \n  \nThe link of the source code of PilotPattern is [PilotPattern](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/pilot_pattern.html#PilotPattern)  \n\nsource code:\n```python\nclass PilotPattern(ResourceGrid):\n    # pylint: disable=line-too-long\n    r\"\"\"PilotPattern\n\n    Defines a :class:`~sionna.ofdm.ResourceGrid` with pilot symbols.\n\n    This class inherits from :class:`~sionna.ofdm.ResourceGrid` and can be\n    used to configure a pilot pattern in an OFDM :class:`~sionna.ofdm.ResourceGrid`.\n\n    Parameters\n    ----------\n    masked_resource_grid : `{'data', 'pilot', 'data_or_pilot'}` ,  :class:`~sionna.ofdm.ResourceGrid`\n        An instance of :class:`~sionna.ofdm.ResourceGrid` with ``mask`` parameter\n        set to ``'pilot'``, ``'data'``, or ``'data_or_pilot'``.\n\n    pilots : One of :class:`~sionna.ofdm.PilotSequence` or :class:`~sionna.ofdm.PilotPattern`\n        An instance of :class:`~sionna.ofdm.PilotSequence` to be repeated over\n        the resource grid or an instance of :class:`~sionna.ofdm.ResourceGrid`\n        that already includes pilot symbols.\n\n    orientation : `{'row', 'column'}`\n        Orientation of the pilot patterns. For ``'row'`` orientation, the\n        pilot symbols are mapped along the last dimension of the resource grid.\n        For ``'column'`` orientation, the pilot symbols are mapped along the\n        second last dimension of the resource grid.\n\n    enable_dual_pilots: `bool`\n        If enabled, two separate pilot patterns are created, each with\n        the orientation specified by the ``orientation`` parameter.\n        This is typically used to differentiate between uplink and downlink\n        transmissions in a multi-cell setting.\n\n    verbose : `bool`\n        If True, the details of the PilotPattern will be printed during the\n        compilation.\n\n    Output\n    ------\n    :class:`~sionna.ofdm.ResourceGrid`\n        An instance of :class:`~sionna.ofdm.ResourceGrid`.\n    def __init__(self,\n                 masked_resource_grid,\n                 pilots,\n                 orientation,\n                 enable_dual_pilots=False,\n                 verbose=False,\n                 **kwargs):\n        # Instantiate the underlying resource grid\n        rg = masked_resource_grid(resource_grid=masked_resource_grid,\n                                    **kwargs)\n\n        # Overwrite the grid type to \"pilot\"\n        rg.grid_type = \"pilot\"\n\n        # Call the super constructor for creation. super() can't be used within\n        # a tensorflow function, so we do this to avoid immediate creation of\n        # the resource grid within the context of the definition of PilotPattern.\n        super().__init__(rg)\n\n        # Add pilots\n        self.pilots = pilots\n\n        # Set orientation\n        self._orientation = orientation\n\n        # Enable dual pilot configuration\n        self._enable_dual_pilots = enable_dual_pilots\n\n        # Show configuration\n        if verbose:\n            self.show()\n``` \n  "
"To import the necessary packages for using Sionna, you will need to import Sionna itself, TensorFlow, and NumPy. Below are the steps to do so:\n\n1. Import Sionna: Sionna is a package for simulating the signal component in fiber-optic communications. It can be imported using the following command.\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n2. Import TensorFlow: TensorFlow is a machine learning framework. It can be imported using the following command.\n\n```python\nimport tensorflow as tf\n```\n\n3. Import NumPy: NumPy is a package for scientific computing in Python. It can be imported using the following command.\n\n```python\nimport numpy as np\n```\n\nPlease note that the `try` block in the Sionna import is used to check if the Sionna package is already installed, and if not, it installs it using pip. If the `os` module is not installed, you may need to install it using pip as well. The `as` keyword is used for aliasing the imported packages, so they can be referenced with a shorter name (e.g., `sionna` instead of `signal`)."
"Here is the detailed information of LinearInterpolator:   \n  \n[sionna.ofdm.LinearInterpolator(pilot_pattern, ofdm_wizard, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/channel_estimation.html#LinearInterpolator)  \n  \nLinear interpolator for use with the OFDM waveform.\n\nThis class defines a linear interpolator which can be used to estimate the channel for the sparse OFDM pilot transmissions.\n\nIt is assumed that the underlying channel frequency response $(h^{(j)}_n(f), 0 \\leq n \\leq N_f-1, 0 \\leq f \\leq F_b)$, for one OFDM symbol and over the subcarriers indicated by the pilot_pattern, can be modeled as a finite impulse response filter of length $L$ with an\nadditional time-varying effect, such that the channel output frequency symbols yk, for $k \\in \\mathcal{K}^P$, can be written as $y^{(j)}_k = \\sum^{L-1}_{\\ell=0} x^{(j)}_{k+\\ell} \\bar{h}^{(j)}_{\\ell, k} + w^{(j)}_k, 0 \\leq k \\leq K-1$  \nwhere $x^{(j)}_k$ is the $k^{\\text{th}}$ the input to the channel $x$, $H^{(j)}_{n, k} = \\sum^{N_f-1}_{f=0} h^{(j)}_n(f) e^{\\frac{j2\\pi nf}{F_b}\\Delta}, 0 \\leq n \\leq N_f - 1$ is the frequency response of the channel at subcarrier k, $b^{(j)}_{\\ell, k}$ are the filter taps, $\\bar{h}^{(j)}_n(k) = \\frac{1}{2}\\left(H^{(j)}_n(k) + H^{(j)}_n(k+1)\\right)$ are the channel coefficients at the pilot locations $k$, and $w^{(j)}_k$ is the channel additive white Gaussian noise.  \nIt is further assumed that $h^{(j)}_n(f), 0 \\leq n \\leq N_f-1, 0 \\leq f \\leq F_b$ have a discrete-time exponential auto-covariance function of power delay\n$\\sigma^2_h \\Delta \\sum^{N_f-1}_{f=0} \\left| \\rho(f) \\right|^2 \\left( \\sum^{L}_{\\ell=0} \\left| G(f, \\ell) \\right|^2 \\right), 0 \\leq \\ell \\leq L-1$  \nwhere $\\rho(f)$ is the complex-valued reflection coefficient of the (assumed to be) single path, $G(f, \\ell)$ the $\\ell^{th}$ filter from the channel model, and $\\Delta$ the\nsubcarrier spacing. The channel impulse response $h^{(j)}_n(m), 0 \\leq n \\leq N_f-1, 0 \\leq m \\leq L-1$, are then generated by sampling this exponential covariance function in the frequency\ndomain and shaping it with a window of length $L$. Note that, with this covariance model, it can be ensured that the channel frequency responses vary only little over the\nspacing of the pilot symbols.\n\n**Parameters**\n\n- `pilot_pattern` (PilotPattern): An instance of `PilotPattern`.\n- `ofdm_wizard` (OFDMWizard): An instance of `OFDMWizard`.\n- `dtype` (tf.Dtype): Datatype of `h_hat`. Defaults to tf.complex64. **h_hat** (N/A): Channel estimates forming a Prior Monte-Carlo (PMC) channel estimate, across the pilot dimension `p`. Has shape [b, n, num_pilot_symbols, l, num_pilots].\n- `k_hat` (N/A): Indicator tensor denoting the status of the channel frequency response estimation for the resource grid. Has shape [b, n, l].\n- `lambd` (float): Defining the smallest eigenvalue of $\\smash{\\left(\\rho(f)G(f, \\ell)\\right)}$ through $\\text{Var}\\smash{\\left(\\rho(f)G(f, 0)\\right)}\\lambda$. This implicitly defines a channel frequency response realization across the resource grid. Defaults to 1e-5.\n- `num_l_min` (int): The largest negative integer defining the smallest cyclic prefix (CP). Defaults to 11.\n- `num_l_max` (int): The largest positive integer defining the largest cyclic prefix (CP). Defaults to 12.\n- `num_freq_norm` (int): Number of unused subcarriers at the low end of the spectrum. Defaults to 0.\n- `tot_pow` (bool): If true, scales the channel frequency response with the sum of the tap coefficients. Defaults to false.\n- `window` (Window or string [\"hann\", \"hamming\", \"custom\"]): Instance of Window applied to the channel impulse response or the string indicating the window name. Custom windows must be instance of Window. Defaults to \"hann\".\n\n**Output**\n\n- `h_hat` (tf.complex): Channel estimates across the entire resource grid for all transmitters.. Has shape [b, n, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size].\n- `err_var` (tf.float): Channel estimation error variance across the entire resource grid for all transmitters.. Has shape [b, n, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size].\n- `k_hat` (tf.bool): Indicates the availability state of the channel frequency response estimates across the entire resource grid for all transmitters.. Has shape [b, n, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size].\n- `kappa` (tf.float): Proportionality constant for the linear interpolation, relating the number of unoccupied resource elements (N) to the size of the available channel error variances (in dB) as $10^{K_\\text{lin}} = N^\\kappa$.Computed from `K_mu` and `num_unused_reps`.\n- `no` (tf.float): Total noise power across the entire resource grid for all transmitters.. Has shape [b, n, num_rx, num_streams, num_ofdm_symbols, fft_size].\n- `num_effective_subcarriers` (tf.float): Number of effective subcarriers across the entire resource grid for all transmitters.. Has shape [b, n, num_rx, num_streams, num_ofdm_symbols].\n- `num_pilot_symbols` (tf.float): Number of pilot symbols across the entire resource grid for all transmitters.. Has shape [b, n, num_tx, num_streams_per_tx].\n- `num_time_samples` (tf.float): Number of time samples across the entire resource grid for all transmitters.. Has shape [b, n, num_rx, num_streams, num_ofdm_symbols, fft_size, cp_size].\n- `s` (tf.float): OFDM symbol duration, i.e., the duration of `fft_size` subcarrier long symbols including `cp_size` samples of cyclic prefix.. Has shape [b, n].\n- `tot_var` (tf.float): Total channel estimation variance across the entire resource grid for all transmitters.. Has shape [b, n, num_rx, num_streams, num_ofdm_symbols, fft_size].\n- `trainable` (bool): True if `h_hat` and `err_var` are trainable. ."
"Here is the detailed information of SymbolLogits2Moments:     \n  \n[sionna.mimo.SymbolLogits2Moments(const_tensor, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/mimo/channel.html#SymbolLogits2Moments)  \n\nComputes the first and second moments (i.e., mean and variance) of a symbol logits tensor.\n \n**Input**\n\n- `logits` ([..., n, num_classes], tf.complex): Tensor of symbol logits.\n- `constellation_type` (str, options: [\u2018qam\u2019, \u2018pam\u2019, \u2018custom\u2019]): Type of constellation used in the simulation. For \u2018custom\u2019, an instance of `Constellation` must be provided.\n- `constellation_size` (int): Number of constellation points for \u2018qam\u2019, \u2018pam\u2019, or the instance of `Constellation`.\n- `num_bits_per_symbol` (int): Number of bits per constellation symbol, e.g., 4 for QAM16. Only required for `constellation_type` in [\u2018qam\u2019, \u2018pam\u2019].\n- `constellation` (Constellation): Instance of `Constellation` or `None`. If `None`, `constellation_type` and `constellation_size` must be provided. Otherwise, an instance of `Constellation`.\n- `dtype` (tf.DType): The dtype of the output; tf.complex64 by default.\n\n**Output**\n\n- `[..., n]`, tf.complex: Tensor of the same shape as the input `logits` containing the mean of the constellation symbols.\n- `[..., n]`, tf.complex: Tensor of the same shape as the input `logits` containing the variance of the constellation symbols.\n  \n**Example**\n  \nThe following code snippet shows how to use this function:\n\n```python\nlogits = [...] # Tensor of Symbol Logits\nmean, var = SymbolLogits2Moments(constellation_type='qam', constellation_size=16)(logits)\nconstellation = [...] # Instance of Constellation or  None\nmean, var = SymbolLogits2Moments(constellation=constellation)(logits)\n```\n  "
"The 'cir_to_ofdm_channel' function is essential in Orthogonal Frequency-Division Multiplexing (OFDM)-based system simulations. It is used to compute the frequency response of the channel from the given raw data of channel impulse responses. In the context, the raw data is represented by 'h_hat' which is a tensor storing channel impulse responses, and 'f' representing the raw sub-carrier channel responses.\n\nThe function operates by first reshaping 'h_hat' and 'f' to form a tensor of cir (channel impulse response) and sub-carrier cir, respectively. It then computes the channel frequency response using the Go\u030cr\u030cov\u030ca-FFT algorithm. Finally, the function returns the channel frequency response in the form of 'h_hat' and 'err_var', representing the computed value and the error variance respectively.\n\nThis function is a part of the Channel module in the wireless simulation package and this package is extensively used in simulating wireless communication systems to compute different channel responses, which are subsequently used in the system level simulations."
"Answer description for context 'Sionna 0.15 Update' related to `EPDetector` class:\n    \nThe `EPDetector` class is a part of the Sionna API which is used for implementing Expectation Propagation (EP) based MIMO detection. This class is primarily used for handling the detection process in simulations to compute output symbols or LLRs (log-likelihood ratios). It's especially useful for making predictions in contexts where data might be noisy or poorly conditioned.\n\nThe parameters of the `EPDetector` class are described in the provided context as follows:\n\n- **stream_management** (`StreamManagement`): An instance of `StreamManagement`.\n- **resource_grid** (`ResourceGrid`): An instance of `ResourceGrid`.\n- **num_bits_per_symbol** (int): A number defining the amount of bits per constellation symbol, e.g., 4 for QAM16.\n- **n** (int): Number of output symbols, which is equal to the number of codewords here.\n- **output_domain** (str, either `b` or `c`): It defines if the output domain is complex or binary. \n- **dtype** (One of [tf.complex64, tf.complex128], tf.complex64 by default.): The data type for internal calculations and the output data type.\n\nThe significance of `EPDetector` class in simulations is evident in the parameters. The class's primary use is to manage streams and resources within a system simulation. It aids in MIMO (Multiple Input Multiple Output) detection which is essential in predicting symbols in communication systems. The use of 'Expectation Propagation' (EP) for MIMO detection means that it is particularly useful in optimizing and finding approximate solutions in simulations under possible noisy conditions. It can compute LLRs (Log-likelihood ratios) which are essential in error correction and detection. By manipulating a number of input parameters, this class has the versatility to adapt to various types of systems and channels, making it a valuable part of the Sionna API."
"To set up and run an instance of the Erbium-Doped Fiber Amplifier (EDFA) class in Sionna, you will primarily make use of the `sionna.channel.EDFA()` method to instantiate the class, followed by methods such as `gain_tnf.to implement a so-called \"transducer\" (input) or \"transmitter\" (output) model, respectively.\n\nHere are the steps you should follow:\n\n1. Import the necessary modules and classes:\n\n```python\nfrom sionna.channel import EDFA\nfrom sionna.channel import gain_tnf\n```\n\n2. Setup the EDFA. This involves specifying the gain, the gain bandwidth, the noise figure, the carrier frequency, the direction ('f' for forward, 'b' for backward), and whether to apply the noise or not. You can also indicate whether you want to apply the noise, which is usually True to be more realistic:\n\n```python\ng = 2.5  # Amplifier gain (linear domain)\nf = 3. # Noise figure [dB]\nf_c = 193.55e12  # Carrier frequency [Hz]\ndirection = 'f'  # 'f' for forward and 'b' for backward\nno_noise = True  # We set this to True to show the effect of the noise later\ne = 0.5*(1e-12)  # Channel symbol energy\n```\n\n3. Instantiate the EDFA class with the specified parameters:\n\n```python\nedfa = EDFA(g, f_c, g_amp=g, f_f=f, f_c=f_c, direction=direction, add_awgn=no_noise)\n```\n\n4. If you want to apply the noise, you can set `no_noise` to `False`, and then you can call the `noise_add()` method of the `edfa` instance with the appropriate noise power spectral density, for example:\n\n```python\nimport tensorflow as tf  # Noise power spectral density will be evaluated by a function using tensorflow\nn0 = tf.cast(1.0e-11, e.dtype)  # Noise power spectral density\ny = edfa.noise_add(e, n0)  #\u00a0e is the input signal\n```\n\n5. If you want to implement a so-called \"transducer\" model, which describes the interaction of the amplifier with the system components, you can use the `gain_tnf` function. In the example below, `n_i` and `n_o` are the input and output powers, respectively:\n\n```python\nimport tensorflow as tf\nfrom sionna.channel import gain_tnf\n\n# Calculate transducer gain\ng_t = gain_tnf(n_i=e, n_o=y)\ntf.abs(g_t)  # Transducer gain in linear scale\n```\n\n6. Running this model will give you the gain of the system, which you can use to scale your signals.\n\nRemember to replace `e` and `n0` with your actual complex input symbol tensor and real-valued noise power density tensor, respectively."
"To use the `render_to_file()` function in the `Scene` class of the Sionna package, follow these steps:\n\n1. First, ensure that you have loaded the necessary scene using the `load_scene()` function.\n\n```python\nscene = sionna.rt.load_scene(sionna.rt.scene.munich)\n```\n\n2. Next, configure the camera view for the scene using the `Camera` class.\n\n```python\nscene.camera.look_at([0,0,0])  # Set the camera to point at the origin\nscene.camera.rotate(0, 0, 0)   # Rotate the camera\nscene.camera.translate([1.5, 1.5, 1.5])  # Move the camera to the desired position\n```\n\n3. Finally, render the scene to a file using the `render_to_file()` function. You can specify the file format and quality as function arguments.\n\n```python\nscene.render_to_file('scene.png', 'png', 2)  # Save the scene as an image file named 'scene.png'\n```\n\nIn this example, the `render_to_file()` function is used to save the rendered scene to an external file in PNG format with a quality setting of 2.\n\n**Note:** The actual output of the function will depend on the specific scene and camera configuration. The function will capture the current view of the scene as seen through the camera and render it to the file. If the scene or camera has been updated since it was last rendered, the output may be different."
"\n\nwrap_angle_0_360(angle) function is present in sionn.rt.backscattering module.  \nIt is used to wrap an angle or angles to thejson (360+ angle) interval.\n\nIn the code, this function is used as a utility function that is often required\nbecause a lot of backscattering-related functions are derived or implemented\nin a way that require angles to be wrapped to the (0,360) or shifted to the (0, 180)\ninterval.\n\nFor example, the function is used in the following line of code.\n\n`phi_i, theta_i = wrap_angle_0_360(phi_i), wrap_angle_0_180(theta_i)`\n\nHere, phi_i and theta_i are the input angles, and the wrap_angle_0_360 function\nis applied to phi_i, and wrap_angle_0_180 function is applied to theta_i.\n\nHow to use wrap_angle_0_360 function: \nThe function takes a single argument angle which can be a number or an array of numbers.\nThe function returns the same type as the input, wrapped to the 360 interval.\n\nThe function can be used in a scenario where you have an angle that is not in the range of 0 to 360, and you want to wrap that angle to be in the range of 0 to 360. For example, if the angle is 400, this function will return 40. \n\nHere's how you can use it in a programming scenario: \n\n```python\nfrom sionn.rt.backscattering import wrap_angle_0_360\nresult = wrap_angle_0_360(400) # will return result in the range of 0 to 360\n```"
"Here is the definition of ChannelModel: sionna.channel.ChannelModel, and here is the source code of [ChannelModel](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel).  \n  "
"Here is the detailed information of sionna.rt.Scene.render_to_file: \n\nsionna.rt.Scene.render_to_file(filename, resolution=(640, 480), camera=None, coverage_map=None, max_tbvf=1.0, show_vignetting=False, show_saturated=False, add_hud=True, use_hud_color=True, hud_color='auto', dtype=tf.complex64)\n\nRenders the scene to a file or to a notebook window.\n\nVignetting is applied by rendering through the corresponding VignetteCamera until the coverage_map has converged to the desired coverage value.\n\nAll parameters are ignored if the scene is precomputed.\n\n**Parameters**\n\n- `filename` (str): Name of the file to save or \u2018notebook\u2019 to render the scene to a Jupyter notebook.\n- `resolution` ([2], tf.int): Resolution of the scene.\n- `camera` (str or Camera): The name of the camera or the camera instance to use for rendering. Custom cameras can be provided as instances.\n- `coverage_map` (CoverageMap or None): An optional coverage map to render with the scene for visualization purposes. Ignored if not set or if coverage_map is None.\n- `max_tbvf` (float): Maximum total block visibility factor (TBVF) to render. Defaults to 1.0.\n- `show_vignetting` (bool): If true, shows the vignetting that is applied when rendering. Defaults to False.\n- `show_saturated` (bool): If true, shows saturated when rendering. Defaults to False.\n- `add_hud` (bool): If true, adds a heads-up display (HUD) to the rendering showing camera and view information. Defaults to True.\n- `use_hud_color` (bool): If true and `hud_color` is set to 'auto', it uses the color of the illuminated primitive for the HUD. Defaults to True.\n- `hud_color` (str or [3] or None): The color for the HUD. Set to 'auto' to use the color of the illuminated primitive or to None for using the default color (i.e., 'red'). Defaults to 'auto'.\n- `dtype` (tf.complex): Data type to use for the rendering. Defaults to tf.complex64.\n\n**Note:** For reproducibility and debugging purposes, the seed of the TensorFlow random number generator can be set before rendering a scene as follows:\n```python\ntf.random.set_seed(22) # Set seed for TensorFlow RNG\nsionna.rt.SCARABScene.load(sionna.rt.example_scenes[\"scarab\"]).render_to_file(  # Render scene to file\n    \"scarab.png\",\n    seed=22)  # Use the same seed as set before\n```\nThe random seed is used to sample the properties of the objects in the scene (e.g., material, roughness, and conductivity). In the example above, the `seed` is set to 22 (an arbitrary integer) for reproducibility. It can be any integer. Different integers will yield different random properties."
"To configure DeepMIMO for use with Sionna, you need to follow these steps:\n\n1. **Setup the environment**: This includes setting up the GPU and importing the necessary libraries. You can use the TensorFlow GPU configuration to specify which GPU to use and how much memory to allocate. The Sionna library can be configured to use only a specific amount of VRAM, which is useful when multiple notebooks are open in parallel.\n\n2. **Import Sionna and other necessary packages**: This includes importing the Sionna package, which is usually done by cloning the Sionna repository and adding its path to the Python library path. You also need to import other necessary packages such as numpy, matplotlib, and tensorflow.\n\n3. **Configure DeepMIMO**: DeepMIMO needs to be configured before it can be used with Sionna. This includes setting the dataset to be used, the channels to be generated, and other parameters such as the resolution of the DeepMIMO dataset and the carrier frequency.\n\n4. **Generate the DeepMIMO channels**: The DeepMIMO object is used to generate the dataset. The dataset can be either training, validation, or test, and can be generated for random topologies or the topology with index k.\n\n5. **Convert the DeepMIMO channels**: The Sionna adapter for DeepMIMO is used to convert the DeepMIMO channels to Sionna channels. This adapter is designed to work with both multi-cell MIMO networks and single-cell MIMO networks.\n\n6. **Create a Sionna MIMO channel model**: After converting the DeepMIMO channels, a Sionna MIMO channel model is created using the Sionna package. This channel model can be used for link-level simulations in Sionna.\n\n7. **Perform the link-level simulations**: The Sionna MIMO channel model is used to generate the end-to-end link over-the-air channel frequency responses. The performance of the MIMO detectors can be evaluated using the link-level simulations.\n\nRemember to import the necessary Sionna and DeepMIMO modules and set the paths correctly. Also, ensure that the environment is properly configured and the GPU is set up before starting the configuration."
"To use the \"interleaver module\" in the Sionna package to permute tensors, follow these steps:\n\n1. First, you need to import the Interleaver module from the Sionna package.\n\n```python\nfrom sionna.fec.interleaving import Interleaver\n```\n\n2. Next, you create an instance of the Interleaver class. The Interleaver class takes one parameter which is the 'type'. \n\n```python\ninterleaver = Interleaver(type='rand_perm', seed=1, keep_batch_constant=False, axis=-1)\n```\nIn this example, 'rand_perm' is used as the type of interleaver. This means that during each call, random permutations will be generated. The parameter 'seed' is set to 1 to ensure the permutations can be re-generated. If you want to keep the batch constant, set 'keep_batch_constant' to True. The last parameter 'axis' defines the dimension that will be interleaved. By default, this is set to '-1', meaning the last dimension will be interleaved.\n\n3. Once the Interleaver instance is created, you can call it by passing the tensor you want to permute as a parameter.\n\n```python\n# call interleaver\nperm_tensor = interleaver(tensor)\n```\nIn this snippet, 'tensor' is the tensor you want to permute. The call to the interleaver returns a new tensor, which is just a permuted version of the input tensor based on the interleaving rules.\n\nThe Sionna \"Interleaver module\" also provides other types of interleavers aside from 'rand_perm', such as 'cyclic', 'deint', and 'turbo'. Each type has its own set of parameters that you can adjust to fit the specific needs of your permutation. \n\nPlease note that the Sionna package must be installed in your Python environment to be able to use these features. The code snippets provided will generate a 'perm_tensor', which is just a permuted version of the input 'tensor'. You can then use this perm_tensor for further computations or analysis, wherever a permuted version of the original tensor is needed. \n\nBe cautious in choosing the type of interleaver and its parameters because the 'rand_perm' type generates random permutations, which can be different in each call. This could lead to inconsistent results, especially in parallel or GPU computations. Setting the 'seed' parameter allows you to have consistent random permutations on each call, but this can still lead to different permutations if the seed is changed."
"The `MMSEPICDetector` function belongs to the module for multi-input multi-output (MIMO) link-level simulations in Sionna, a MIMO-OFDM system 5G-compliant. This function implements optimal minimum mean square error (MMSE) MIMO equalization with noise-partial-cancellation for detection in the frequency domain.\n\nThe MMSE MIMO equalization technique is used to reduce interference and noise in MIMO wireless communication systems. This method provides an effective strategy for detection by minimizing the mean square error (MSE) in the estimation of transmitted symbols.\n\nThe function `MMSEPICDetector` is realized as a Keras layer, and therefore can be used as a layer in a Keras model. It is designed to deal with Orthogonal Frequency-Division Multiplexing (OFDM)-based transmissions, and this is achieved by providing the relevant resource grid and channel estimates.\n\nIn terms of usage, the function requires an input of received data, channel estimates, and noise covariance matrices. These need to be provided in a specific dictionary format. The output will be the estimated information bits and the effective noise after detection.\n\nUsing this function is of utmost importance as it significantly enhances the performance of MIMO wireless communication systems by providing more accurate detection outcomes, thereby improving the overall quality of the transmission. This is particularly crucial in ensuring reliable and efficient data transfer.\n\nThe usage of this function also aligns with the overarching theme of the Sionna package, which focuses on simulating the PHY-layer link-level performance for communication systems. The various functions and modules in this package cater to different aspects of this simulation, and the MMSE MIMO equalization is a key component in ensuring thejson satisfactory performance of these systems."
"Here is the definition of RaisedCosineFilter: sionna.signal.RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/signal/filter.html#RaisedCosineFilter)  \n\n```python\nclass RaisedCosineFilter(Filter):\n    # pylint: disable=line-too-long\n    r\"\"\"RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n\n    Layer for applying a raised-cosine filter of ``length`` K\n    to an input ``x`` of length K or to a sequence  of K inputs.\n\n    The raised-cosine filter is defined by\n\n    .. math::\n        h(t) =\n        \\begin{cases}\n        \\frac{1}{2\\beta}\\left(1+\\cos\\left(\\frac{\\pi t}{\\beta}\\right)\\right) & \\text{if } \\beta\\leq t \\leq \\beta,\\\\\n        \\frac{\\sin\\left(\\frac{\\pi t}{\\beta}\\right)}{\\frac{\\pi t}{\\beta}} & \\text{otherwise}\n        \\end{cases}\n\n    with\n    the roll-off factor :math:`\\beta`.\n\n\n    The filter length K is equal to the filter span in symbols (``span_in_symbols``)\n    multiplied by the oversampling factor (``samples_per_symbol``).\n    This must be an integer, i.e., the filter length K is\n    ``K = span_in_symbols*`` ``samples_per_symbol``.\n\n    The filter is applied through discrete convolution.\n\n    An input argument ``window`` can be used to specify a window function\n    for windowing the filter ``hanniging``. Custom window functions\n    can be specified through callable objects (see :py:class:`~sionna.signal.Window`).\n\n    Example\n    --------\n\n    The following example shows how to create  a raised-cosine filter\n    with a roll-off factor of :math:`\\beta=0.22`, spanning 4 symbols,\n    and sampled at 32 samples per symbol. The filter is then applied to\n    a QAM16 baseband signal.\n\n    .. code-block:: Python\n\n        # Create the filter\n        beta = 0.22 # Roll-off factor\n        span_in_symbols = 4 # Filter span in symbols\n        samples_per_symbol = 32 # Number of samples per symbol, i.e, the oversampling factor\n        rcf = RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta)\n\n        # Apply the filter to x, assuming that x is a a baseband signal\n        # with a pulse shaping and over-the-air transmission\n        y = rcf(x)\n\n    Parameters\n    ----------\n    span_in_symbols: int\n        Filter span as measured by the number of symbols.\n\n    samples_per_symbol: int\n        Number of samples per symbol, i.e., the oversampling factor.\n\n    beta : float\n        Roll-off factor.\n        Must be in the range :math:`(0,1]` .\n\n    window: Window or string ([\"hann\", \"hamming\", \"blackman\"])\n        Instance of :class:`~sionna.signal.Window` that is applied to the filter coefficients.\n        Alternatively, a string indicating the window name can be provided.\n        In this case, the chosen window will be instantiated with the default parameters.\n        The string can be on of [\"hann\", \"hamming\", \"blackman\"].\n\n    normalize: bool\n        If `True`, the filter is normalized to have unit power.\n        Defaults to `True`.\n\n    trainable: bool\n        If `True`, the filter coefficients are trainable variables.\n        Defaults to `False`.\n\n    dtype: tf.DType\n        The dtype of the filter coefficients.\n        Defaults to `tf.float32`.\n\n    Input\n    -----\n    x : [..., K], tf.complex or tf.float\n        The input to which the filter is applied.\n        `K` must be the the last dimension of `x`.\n\n    Output\n    ------\n    y : [...,K], tf.complex or tf.float\n        Filtered input.\n    \"\"\"\n    def __init__(self,\n                 span_in_symbols,\n                 samples_per_symbol,\n                 beta,\n                 window=None,\n                 normalize=True,\n                 trainable=False,\n                 dtype=tf.float32,\n                 **kwargs):\n        super().__init__(span_in_symbols,\n                         samples_per_symbol,\n                         beta,\n                         window=window,\n                         normalize=normalize,\n                         trainable=trainable,\n                         dtype=dtype,\n                         **kwargs)\n```"
"The PAM2QAM class is a model from the BinarySource layer of the telecommunications channel modules in the Sionna library. Its purpose is to transform a binary sequence into a two-level PAM or QAM symbol sequence.\n\nIn the code, this class is instantiated with a couple of arguments; num_bits_per_symbol and hard_decisions. The former represents the number of bits per symbol, and the latter represents whether decisions should be made on the symbols (i.e., hard-decisions).\n\nThe PAM2QAM class helps achieve the mapping of the binary sequence to a QAM constellation. After the binary sequence is provided as an input, this class will perform the mapping and produce a QAM constellation. The class operates by taking in 2D tensors; the first dimension indexes the symbols and the second dimension indexes the real and imaginary components, respectively. This means that the binary sequence needs to be transformed into a QAM constellation in the PAM2QAM model.\n\nAdditionally, note that the provided code mentions that this model (like other layers in Sionna) can be potentially influenced by channel models and channel impulse responses. However, because the code does not provide the underlying implementation or instantiation of these potential influences (such as a channel model or an AWGN channel), it is not possible to demonstrate how this model is affected by them.\n\nTo use this class, the binary sequence needs to be provided in a tensor (tf.float32), and the sequence length should be an integer multiple of num_bits_per_symbol."
"To configure StreamManagement for a simple uplink scenario in Python using Sion, you need to define the following variables:\n\n- `num_tx` (Number of Transmitters): Set this to 1 as we will only have one transmitter in this scenario.\n- `num_rx` (Number of Receivers): Set this to 4 as we will have four receivers.\n- `num_streams_per_tx` (Number of Streams per Transmitter): Set this to 2 as we will use two streams per transmitter in this scenario.\n- `rx_tx_association` (Receiver-Transmitter Association): This is an array that specifies which receiver gets its channels from which transmitter. In this scenario, we will use a simple 1x1 setup, so we set `rx_tx_association = np.array([[0, 1, 2, 3]])`.\n\nHere is the Python code to define these variables:\n\n```python\nfrom sion.rt import StreamManagement\n\nnum_tx = 1\nnum_rx = 4\nnum_streams_per_tx = 2\nrx_tx_association = np.array([[0, 1, 2, 3]])\nstream_manager = StreamManagement(rx_tx_association, num_tx, num_streams_per_tx)\n```\n\nIn this code, we first import the `StreamManagement` class from the `sion.rt` module. We then define `num_tx`, `num_rx`, and `num_streams_per_tx` as discussed above. We then use these variables to create a `StreamManagement` object called `stream_manager`.\n\nThe `rx_tx_association` array specifies that receiver 0 and receiver 1 get their channels from transmitter 0, and receiver 2 and receiver 3 get their channels from transmitter 1. The rows of this array represent the transmitters, and the values in each row represent the receivers that get their channels from that transmitter."
"Higher order modulation is a method used in digital data transmission systems to increase the amount of data that can be sent over a given bandwidth. It involves encoding multiple bits of data into a single symbol for transmission. This is in contrast to baseband transmission, where each bit is transmitted individually.\n\nIn the context of higher order modulation, constellations refer to the possible signal patterns that can be used to represent multiple bits. These are typically complex patterns, as they can take on both real and imaginary components. A constellation is used to map groups of bits into symbols for transmission.\n\nBit-channels, on the other hand, refer to the channels over which the individual bits are transmitted. In the case of higher order modulation, multiple bits are transmitted together over a single channel, as opposed to baseband transmission, where each bit is transmitted over its own channel.\n\nThe concept of constellations and bit-channels is crucial in understanding how higher order modulation works. The number of bits that can be transmitted per unit of bandwidth depends on the size of the constellation (the number of points in the constellation) and the number of symbols that can be transmitted over the bit-channel. This is why more complex constellations allow for higher data rates."
"In the sionna mapping, there is a function called \"pam\" referenced from \"sionna.mapping\" which stands for Pulse Amplitude Modulation. This function is used to map one or multiple binary streams to pulse-amplitude modulated (PAM) or pulse-amplitude demodulated (PAM) symbols or to analog waveforms. \n\nThe function takes three inputs which are:\n1. binary \n2. sign aware \n3. number of bits per symbol \n\nThe 'binary' input is a tensor array filled with binary entries, the 'sign_aware' is a boolean indicating a possible demapping operation (corresponding to two different meanings 0 and 1, as -1 and 1), and the 'n_b' is an integer specifying the number of bits per symbol; for example, 4 for 16QAM. \n\nThe output of the  function can either be a tensor array of PAM symbols or a tensor of  quadrature components of the PAM symbols, depending on whether  the `sign_aware` flag is set to `True` or `False`, respectively. This mapping implies that for every sequence in 'binary',  there will be one or two PAM symbols or waveforms, depending on whether the symbol is signed or not.\n\nThe sionna mapping is typically used for digital modulation schemes which are required in  communication systems. It provides a way to map binary values into multi-level analog signals to transmit data. The reverse operation (demapping) is also possible and can be determined by the 'sign aware' flag. \n\nPlease note that you must install the Sionna module to import the necessary classes and functions, as the explanation references to various Sionna modules and functions."
"When using the \"List2LLR\" class in the Sionna package, the following assumptions should be fulfilled:\n\n1. It is assumed that the order-1/2 list decoding is used with the \"GPULearDecoder\" class and that the code is given by the \"Polynomial2\" class.\n\n2. The \"List2LLR\" class requires that the code is symmetric and linear, such as Polar or Reed-Muller codes. For these codes, an equivalent bit representation must exist.\n\n3. Importantly, the \"List2LLR\" class is not compatible with any general encoder. It is designed for a specific type of encoder, therefore, ensure that the provided encoder is Polar or Reed-Muller to avoid an incompatibility error.\n\n4. The \"List2LLR\" class assumes that the 'num_bits' parameter of the constructor refers to the length of the codeword, i.e., the length of the underlying code.\n\n5. It is assumed that the underlying code supports frozen positions as, for example, in the Polar code construction. The number of frozen bits is a parameter of the code construction.\n\n6. The `order` parameter for the \"List2LLR\" class methods refers to the `t` parameter of a list decoder, which is the number of candidate solutions kept in the list for further decoding.\n\n7. For efficient processing, it is assumed that the \"List2LLR\" class operates dimension-wise on arbitrary tensor shapes. \n\n8. Finally, the \"List2LLR\" class assumes that the llr-values in the list are defined by another Sionna component, such as \"ListDecoder\". If llr-values are defined in a different way, it may result in erroneous computations."
"   \n  \nThe `MMSEPICDetector` class in the `sionna.mimo` module is a type of MIMO (Multiple-Input, Multiple-Output) detector. This class implements optimal non-iterative minimum mean square error (MMSE) detection for the    first-order PAM MIMO symbol alphabets. It is assumed that the transmitted symbols are taken from the set $\\in\\mathbb{C}^{M}$ which is the Cartesian product of $M$ 1-dimensional constellation alphabets. Also, it is assumed that the channel output symbols are in $\\in\\mathbb{C}^{M}$, representing the (noisy) channel observations. The `MMSEPICDetector` works for stream or codeword recovery in an equal or arbitrary number of transmitters and receivers setting.\n\nThe class accepts channel outputs (in the form of  y, h, and s) and parameter objects (in the form of a  MIMOStreamManagement or MIMOSystem objects,  a list of LengthaToBePadded objects, and a FunctionLut), and returns the estimated symbols and effective noise variances, or LLR (log-likelihood ratios) on the estimated symbols for either streams or codewords.\n\nThe conditions under which you would use the `MMSEPICDetector` are when you have an extensive MIMO system, and you want to employ optimal non-iterative MMSE detection for a PAM modulation. This might be used in scenarios such as improving throughput in wireless communication or achieving more efficient data transmission.\n\nWhen using this class, take note that it assumes first-order PAM symbol alphabets. This refers to the set of modulation symbol alphabets that are used to convey data in the PAM (Pulse Amplitude Modulation) scheme, where each symbol serves as a pulse of varying amplitude. For a binary PAM system, this would be the set {\u2212 1, 1}. For higher order PAM, it's a set of QAM constellations, each of dimension  $M$.\n\nIn terms of parameters, the input parameters for the `MMSEPICDetector` are:\n\n- **y**: Channel outputs\n- **h**: Channel matrices\n- **s**: Noise covariance matrices\n- **no**: Noise variance, either a scalar or a vector\n- **stream_management**: Stream management object\n- **num_iter**: Not used (maintained for backward compatibility)\n- **return_codeword**: Flag indicating if a codeword is to be returned instead of the LLR or not. Defaults to `False`.\n- **dtype**: The data type to use, with default to [tf.float32, tf.complex64].\n\n\nOutput:\nThe output of `MMSEPICDetector` can be one of the following, based on the return type parameter:\n- **x_hat**:  Estimated symbols\n- **no_eff**: Effective noise variance for each estimated symbol\n- OR,\n- **x_hat**:  Estimated codeword\n- **no_eff**: Effective noise variance for the estimated codeword\n\nThis class is part of the Sionna package that is used for simulating communication systems. Make sure to use the most suitable detector with the most appropriate configuration according to the type and structure of your communication system. It is always beneficial to analyze various parameters and choose the optimal configuration for your specific scenario."
"The `QAM2PAM` class is a function in the 'sionna.mapping' module that implements the transform from quadrature amplitude modulation (QAM) symbol indices to pulse amplitude modulation (PAM) symbol indices. In the context of this function, QAM involves the mapping of two binary streams into a complex-valued constellation before transmission. PAM, on the other hand, involves the direct mapping of binary bits into a pulse amplitude. The function operates by taking the QAM symbol indices and returning the corresponding PAM symbol indices.\n\nThe `QAM2PAM` class is provided as a layer in a neural network model, with an inherent parameter `num_bits_per_symbol` defined at initialization. This parameter defines the number of bits per QAM constellation symbol. The `QAM2PAM` class is used to create a transform that converts the indices of QAM constellation points into the indices of the corresponding PAM symbols. It is implemented as a Keras layer, as it is used as part of a larger system that is being modeled with Keras.\n\nThe `QAM2PAM` class accepts QAM symbol indices as input and provides the corresponding PAM symbol indices as output. The class serves a critical role in communication systems as it supports the modulation and demodulation processes necessary for the accurate and efficient transmission of data. By handling the conversion from QAM to PAM symbol indices, the `QAM2PAM` class contributes to the overall functionality and effectiveness of the communication system."
"To verify that the generator matrix and parity-check matrix are orthogonal in GF(2) with the \"verify_gm_pcm\" function from Sionna's package, you first need to import the `verify_gm_pcm` function from the `sionna.utils` module.\n\nHowever, I couldn't find an exact function named `verify_gm_pcm` in the instructions or Sionna's package. It seems that the actual function to use would be `sionna.utils.verify_gm_pcm` to check the orthogonality between thejson representation of the generator matrix and parity-check matrix. \n\nHere is how you can use it:\n1. First, obtain the generator matrix (`G`) and parity-check matrix (`H`).\n```python\n# Assuming G and H are already computed and are in the form of numpy arrays\nG = # Your generator matrix\nH = # Your parity-check matrix\n```\n2. Convert the generator matrix to its JSON representation. \n```python\n# G_json is the JSON representation of the generator matrix G\nG_json = json.dumps(G.tolist(), separators=(',',', ,'))\n```\n3. Then, call the `sionna.utils.verify_gm_pcm` function with the generator matrix's JSON representation and the parity-check matrix.\n```python\n# Assuming G_json is the JSON representation of the generator matrix G\n# and H is the parity-check matrix\nresult = sionna.utils.verify_gm_pcm(G_json, H)\n```\nThe function will return `True` if the matrices are orthogonal (meaning G and H matrices do not transpose or dot to anything other than zeros). It will return `False` if the matrices are not orthogonal. \n\nIt's important to make sure that the matrices `G` and `H` are properly initialized before calling this function. If the matrices contain non-zero elements, it may result in an error or a false verification.\n\nAlso, ensure that Sionna's package is installed in your environment before using this function. If it's not installed, you can install it using pip:\n```python\n# Install Sionna if not already installed\ntry:\n    import sionna\nexcept ImportError as e:\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```"
"To import the `LinearEncoder` class from the `sionna.fec.linear` module, use the following Python import statement:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n```\n\nThis statement allows you to use the `LinearEncoder` class in your Python script or interactive environment."
"The `OFDMDetectorWithPrior` class is a layer that implements Orthogonal Frequency Division Multiplexing (OFDM) data detection for multiple input multiple output (MIMO) links, assuming prior knowledge of the transmitted streams.\n\nThis class assumes an OFDM waveform and a 'Pilot-symbol pattern', meaning a pattern or configuration for the known data symbols (pilots) that are going to be transmitted. The class uses this pattern to align the received data with the transmit data, and to estimate the channel coefficients for the data-carrying resource elements.\n\nThe implementation is based on the Expectation Maximization (EM) algorithm, which has been found to provide near-maximum likelihood detection, and to be trainable, and differentiable when used to estimate the channel state information (CSI).\n\nThe algorithm works as follows:\n\n- The received OFDM resource grid and the prior covariance of the noise are input into the detector.\n- The detector produces for each stream $i$ a vector of 'detected symbols' $x_hat_i$ and a vector of 'soft-symbols' $x_hat_i_soft$ with size of [n, n], where $n$ is the FFT size.\n- The hard-decided symbols correspond to the best 'path' through the constellation diagram and are output by the algorithm as $x_hat_i$.\n- The 'path metric' is output for each path and is used by an 'output processor' that computes for each receiver the set of $K$ candidate base-station precoders $\\mathbf{W}_k$ and the corresponding LLR values on the estimated symbols $\\mathbf{x}_k$.\n\nThis algorithm works under the assumption that the receiver knows the prior covariance matrices of the noise. This information is crucial for the estimation of the channel state information."
"The \"bin2int_tf\" function mentioned in the provided context is not a part of core Python or any standard library modules. Thus, without the implementation details of this function in the context, it is not possible to describe its use. \n\nHowever, based on the function name \"bin2int\" which typically refers to the process of converting binary numbers to an integer, we can infer that the \"bin2int_tf\" function might be a utility function in a machine learning library that converts binary tensor (or binary string) to an integer tensor. The function might support binary representations where each binary digit is represented as a unit or element in the tensor. The function may also support binary string representations (i.e., '0' and '1' characters) for each digit instead of binary numbers.\n\nTo give an exact description of its use, it's necessary to provide the source code or documentation where it is defined and explained. This would clarify the input and output data types and formats, the function's purpose, and the operations it performs."
"The `TB5GScrambler` class is used in 5G NR (New Radio) to implement the system's data scrambling procedure as defined in the relevant 3GPP specifications. Data scrambling is a procedure to ensure that long sequences of similar bits are avoided, which helps in obtaining a pseudo-random data sequence. This is particularly important for randomizing the data in downlink transmissions to avoid patterns that could potentially lead to high levels of interference.\n\nHere is an example of how to use the `TB5GScrambler` for enabling 5G NR compliant scrambling, based on the usage context provided in the link.\n\nFirst, you need to import the class:\n```python\nfrom nr.scrambling import TB5GScrambler\n```\n\nThen, assuming you have a transport block (TB) of binary data that needs to be scrambled. A TB in the 5G context would typically represent a block of data that is going to be encoded and modulated onto a resource grid for transmission. You initialize the `TB5GScrambler` with the binary data:\n\n```python\nimport tensorflow as tf\n\n# Parameters\ntb_size = 100  # Size of the transport block, you would use the actual size of your data\nbinary_data = tf.random.uniform((tb_size,), minval=0, maxval=2)  # Random binary data\n\n# Scrambler\ntb5g_scr = TB5GScrambler()  # Initialize scrambler\n\n# If your binary data is not already in the required `tf.float32` format,\n# you can use the internal `cast` function of the scrambler to cast the data\n# to the required format and then scramble the data\n# scrambled_data = tb5g_scr(tf.cast(binary_data, dtype=tf.float32))\n\n# Scramble the data\nscrambled_data = tb5g_scr(binary_data)\n\n# At this point, 'scrambled_data' will contain the scrambled version of the binary data.\n```\n\nIn this example, `binary_data` represents the binary data that you want to scramble. Note that the transport block size (`tb_size`) must be an integer that specifies the number of bits, and the binary data must be in `tf.float32` format.\n\nThe initialization `TB5GScrambler()` without any explicit parameter mentions as in the example is compliant with 3GPP standards, and typically required parameters such as the RNTI (Radio Network Temporary Identifier) are set to default values (e.g., 1). If you want to set non-default values for these parameters, you need to do so explicitly."
"Here is the detailed information of int_mod_2: [sion.fec.utils.int_mod_2(arr)](https://nvlabs.github.io/sion/_modules/sion/fec/utils.html#int_mod_2)\n\nTakes an integer array as input and returns the remainder with respect to 2 for each element, i.e., arr%2.\n\n\nInput\n\n   arr (int) \u2013 Tensor of int\u2019s.\n \n\nOutput\n\n   int \u2013 Tensor with the same shape as arr containing 0\u2019s and 1\u2019s.\n \n\nsource code:  \n```python\ndef int_mod_2(arr):\n    \"\"\"\n    Takes an integer array as input and returns the remainder with respect\n    to 2 for each element, i.e., `arr%2`.\n\n    Input\n    -----\n        arr: int\n            Tensor of int's.\n\n    Output\n    ------\n        : int\n            Tensor with the same shape as ``arr`` containing 0's and 1's.\n    \"\"\"\n    return tf.math.mod(arr, 2)\n```"
"Here is the detailed information of sionna.utils.SymbolSource:  \n  \n[sionna.utils.SymbolSource(num_bits_per_symbol, hard_out=True, binary=True, return_indices=False, seed=None, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/utils/symbol.html#SymbolSource)  \n\nGenerates a tensor of arbitrary complex-valued random symbols with a given energy.\n\n### Parameters\n\n- `num_bits_per_symbol` (int): The number of bits per constellation symbol, e.g., 4 for QAM16.\n- `hard_out` (bool): If True, the constellation points are quantized to the set of possible constellation symbols. Defaults to True. In this case, `binary` must also be True.\n- `binary` (bool): If True, the constellation points are quantized to the set of possible binary representations of the symbols. Defaults to True.\n- `return_indices` (bool): If True, the function also returns the indices of the generated constellation points. Defaults to False.\n- `seed` (int or None): The seed for the random generator. None leads to a random initialization of the RNG. \n- `dtype` (tf.complex): The output dtype. Defaults to tf.complex64.\n\n### Input\n\n- `batch_size` (int): The batch size, i.e., the number of random symbols to generate.\n\n- `num_symbols` (int): The number of random symbols to generate. Note that only one call to the layer is needed to generate these many symbols due to the parallelism of the bit labeling.\n\n### Output\n\n- `symbols` ([batch_size, num_symbols], tf.complex): A tensor of arbitrary complex-valued random symbols.\n- `symbol_indices` ([batch_size, num_symbols], tf.complex): The indices of the generated constellation symbols. Only returned if `return_inidces` is True.\n\n**Note: **The total energy of the ouput symbols is num_bits_per_symbol. This is differnt from most other implementation, which have a total energy of num_bits_per_symbol / 2. This implementation is choosen as it simplifies the combination of different modulators in a single neural network model, as all of them typically require an energy per symbol as an additional input.\n\n### Properties\n\n**Property: `constellation`**\n[Constellation(num_bits_per_symbol, binary, hard_out, dtype=tf.complex64)]\nThe constellation object.Computed using both [bit_labeling](#method-bit_labeling) and [generate_constellation](#method-generate_constellation).\n\n**Property: `num_bits_per_symbol`**\nThe number of bits per constellation symbol.\n\n### Method: `bit_labeling(bits_per_symbol, hard_out)`[source](https://nvlabs.github.io/sionna/_modules/sionna/utils/symbol.html#SymbolSource.bit_labeling)\nLabel the constellation points of an n-bit system.  \nFor a 4-QAM, the default bit labeling is:\n\n```\n      Re[1]   Im[1]\n       00      01\n       10      11\n```\n\nUsing this method, the preceding labeling is translated into  \n  \n[[-1. -1. ]  \n [-1.  1. ]  \n [ 1. -1. ]  \n [ 1.  1. ]]\n### Input\n\n- `bits_per_symbol` (int): The number of bits per constellation symbol, e.g., 4 for QAM16.\n- `hard_out` (bool): If True, the constellation points are quantized to the set of possible constellation symbols. This is equivalent to a hard decision. Defaults to True. Note that for some modulations this parameter has no effect.\n\n### Output\n\n- `constellation_labels` ([2**n, n], numpy.ndarray): An array of size [2**n, n] containing the bit labels of the constellation points.\n  \nsource code:  \n```python\nclass SymbolSource(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"SymbolSource(num_bits_per_symbol, hard_out=True, binary=True, return_inidces=False, seed=None, dtype=tf.complex64, **kwargs)\n\n    Generates a tensor of arbitrary complex-valued random symbols with a given energy.\n\n    This class is generally used as a layer in a Keras model. It is used to\n    generate data for the modulator. The advantage of this class over the\n    available classes in :class:`~sionna.channel` is that it can be configured\n    to generate variable sizes of random symbol tensors.\n\n    ..  code-block:: Python\n\n        num_bits_per_symbol = 4\n        symbol_source = SymbolSource(\n                            num_bits_per_symbol,\n                            hard_out=True)\n        # To be used in a Keras model\n        ...\n        data = symbol_source(batch_size)\n    ----\n\n    Parameters\n    ----------\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n\n    hard_out : bool\n        If `True`, the ``constellation_points`` are\n        quantized to the set of possible constellation symbols. This\n        is equivalent to a hard decision. Defaults to `True`.\n        In this case, ``binary`` must also be `True`.\n\n    binary : bool\n        If `True`, the constellation points are\n        translated into their binary representations. Defaults to `True`.\n        This parameter has no effect for modulation schemes that result in\n        unary symbols (e.g., BPSK).\n\n    return_indices : bool\n        If `True`, the function also returns the indiciest of the generated\n        constellation points. Defaults to `False`.\n\n    seed : int or None\n        The seed for the random generator.\n        Setting to `None` leads to random initialization of the RNG.\n        For a given seed, the set of random symbols is always the same.\n        Defaults to `None`.\n\n    dtype : tf.DType\n        The output dtype. Defaults to `tf.complex64`.\n\n    Input\n    -----\n    [batch_size, num_symbols], tf.float32\n        A tensor conntaining the desired energy per OFDM symbol.\n\n    Output\n    ------\n        [batch_size, num_symbols], ``dtype``\n            A tensor of arbitrary complex-valued random symbols.\n\n        [batch_size, num_symbols, 2**num_bits_per_symbol], tf.int32\n            Only returned if ``return_inidces`` is `True`.\n            The indices of the generated symbols.\n    \"\"\"\n    def __init__(self,\n                 num_bits_per_symbol,\n                 hard_out=True,\n                 binary=True,\n                 return_indices=False,\n                 seed=None,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n\n        assert dtype.is_compatible_with(tf.complex64),\\\n            \"dtype must be tf.complex64\"\n        self._cdtype = tf.as_dtype(dtype)\n\n        assert isinstance(hard_out, bool), \"hard_out must be bool\"\n        self._hard_out = hard_out\n\n        if self._hard_out:\n            assert binary, \"hard_out requires binary==True\"\n\n        assert isinstance(binary, bool), \"`binary must be bool\"\n        self._binary = binary\n\n        assert isinstance(return_indices, bool), \\\n                                \"return_indices must be bool\"\n        self._return_indices = return_indices\n\n        if seed is not None:\n            assert isinstance(seed, int), \"seed must be int\"\n\n        assert num_bits_per_symbol in (UNARY_BIT_REPR[MODULATION.PAM],\n                                       UNARY_BIT_REPR[MODULATION.PSK],\n                                       UNARY_BIT_REPR[MODULATION.QAM],\n                                       UNARY_BIT_REPR[MODULATION.FSK],\n                                       UNARY_BIT_REPR[MODULATION.APSK]), \\\n                    \"num_bits_per_symbol must be one of [2, 4, 16, 32, 64]\"\n\n        # Number of bits to be mapped to a constellation point\n        self.num_bits_per_symbol = num_bits_per_symbol\n        self.num_syms = 2**num_bits_per_symbol\n\n        # Seed for SymbolSource\n        self.seed = seed\n\n        # An instance of Constellation\n        constellation = Constellation(self.num_bits_per_symbol,\n                                          binary=self._binary,\n                                          hard_out=self._hard_out)\n        self._constellation = constellation\n\n    #########################################\n    # Public methods and properties\n    #########################################\n\n    @property\n    def constellation(self):\n        \"\"\"The :class:`~sionna.utils.Constellation` used.\"\"\"\n        return self._constellation\n\n    @property\n    def num_bits_per_symbol(self):\n        \"\"\"The number bits per constellation symbol .\"\"\"\n        return self._num_bits_per_symbol\n\n    def call(self,  batch_size): #pylint: disable=arguments-renamed\n\n        #\n        # Generate random PAM symbols through the indices\n        # of the constellation.\n        # tf.random.uniform is used to generated the random indices.\n        # The generated symbols have an energy of ``1``\n        # and are of dtype indicated by ``self._dtype``.\n        #\n\n        # Expand the seed if only one seed is given\n        seed = self.seed\n        if (tf.rank(seed)==0) and (seed is not None):\n            seed = [seed, -1]\n\n        # Randomly generate symbol indices\n        minval = tf.constant(0, tf.int32)\n        maxval = tf.constant(self.num_syms, tf.int32)\n        shape = tf.stack([batch_size, tf.constant(1, tf.int32)])\n        indices = tf.random.uniform(shape,\n                                    minval,\n                                    maxval,\n                                    tf.int32,\n                                    seed) # pylint: disable=unexpected-keyword-arg\n\n        # Transform symbol indices to constellation points\n        constellation = self._constellation()\n        points = constellation(indices)\n\n        if self._return_indices:\n            points = tf.cast(points, tf.int32)\n            ind = SymbolInd(\n                    tf.transpose(points, [0, 1, 2]),\n                    tf.int32(self.num_bits_per_symbol))\n                # pylint: disable=line-too-long\n        else:\n            ind = None\n\n        # Ensure the output is of the requested dtype\n        re, im  = tf.unstack(points, num=2, axis=-1)\n        re = tf.cast(re, self._dtype)\n        im = tf.cast(im,  self._dtype)\n        points = tf.complex(re, im)\n\n        energy = tf.cast(0.5, dtype=self._cdtype)\n        # Overwrite the imaginary coefficient with 0 if mod==QAM\n        if (self._constellation.modulation == MODULATION.QAM):\n            points = tf.cast(points, self._dtype)\n            energy_factor = tf.sqrt(energy/self.num_bits_per_symbol)\n            points = tf.complex(energy_factor*re, tf.cast(0., self._dtype))\n        # Scale the points to the proper energy\n        else:\n            # points = tf.complex(energy_factor*re, energy_factor*im)\n            energy_sqrt = tf.cast(\n                tf.sqrt(energy/\n                        tf.reduce_mean(\n                            tf.abs(points)**2) # pylint: disable=no-value-for-parameter\n                        ),\n                self._cdtype)\n            points = energy_sqrt * points\n\n        return points, ind\n```"
"Here is the detailed information of ChannelModel:   \n  \n[sionna.channel.ChannelModel](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel)  \n  \nAbstract class that represents a channel model for generating channel impulse responses.\n\nConcrete implementations of this class generate channel impulse responses (CIRs) which can be used to implement a channel transfer function in the time or frequency domain.\n\nAll channel models operate on batches of input spaces `U` and generate batches of output spaces `Y`. The channel impulse response consists of `a` and `tau` and optional `spatial_corr`, as their name indicate, can model the channel coefficients and delays, and optional spatial correlation.\n\nBoth the number of paths `n_paths` and the delay spread `ds` are parameters that are typically generated by such a model. They are not inputs to the channel generation functions (e.g., `__call__()` or `generate_cir()`) but they must be defined by the user before calling the model to something like [generate_cir()](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel.generate_cir). For example, these could be the outputs of a block that implements a channel model such as [RayleighBlock](https://nvlabs.github.io/sionna/_modules/sionna/channel/rayleigh_fading.html#RayleighBlock) or [Umts3gppBlock](https://nvlabs.github.io/sionna/_modules/sionna/channel/umts_fading.html#Umts3gppBlock).\n\nA CIR generated by a ChannelModel can be transformed to a channel response in either the time or frequency domain by a ChannelIR2Time or ChannelIR2OFD, respectively. Alternatively, one can use the from_time() or from_frequency() methods to obtain a Channel object, which represents the channel response in the desired domain (either time or frequency).\n\nThis class can be [composed](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel.compose) with a function to create a new channel model that is equivalent to applying the two models successively. This is useful, for example, to combine two single-input-single-output (SISO) channel models to create a SISO link over a multiple-input-multiple-output (MIMO) link.  \n  \n**Input**\n\n- `batch_size` (int): Batch size\n- `num_tx` (int): Number of transmitters\n- `num_tx_ant` (int): Number of antennas per transmitter\n- `num_rx` (int): Number of receivers\n- `num_rx_ant` (int): Number of antennas per receiver\n- `num_paths` (int): Number of paths\n- `spatial_corr` ([num_rx, num_rx, desired_dim] tf.complex or None): Spatial correlation matrix of the receiver. If not set to None, the correlation is applied using tf.matmul(tf.matmul(y, corr), x) for the transmit and receive signals x and y, respectively. See also [flatten_dims()](https://nvlabs.github.io/sionna/_modules/sionna/utils.html#flatten_dims).\n- `time_corr` ([batch size, num_rx, num_rx, n] tf.complex or None): Time correlation for each receiver. If not set to None, the time correlation is applied by filtering the white noise through the time-variant channel. Custom time correlations can be defined, e.g., by sampling a new set of CIRs for each time step. See also [time_lag_discrete_time_corr()](https://nvlabs.github.io/sionna/_modules/sionna/channel/utils.html#time_lag_discrete_time_corr).\n- `l_min` ([batch size, n] or [batch size, 1], tf.float): Minimum delay for each path (baseband), i.e., path delay (in second) minus an integer representing the number of \"onion\" peels of the [emissary cell](https://nvlabs.github.io/sionna/emission.html#onion-model) in the current [EUS](https://nvlabs.github.io/sionna/emission.html#overview). A delay of zero or negative value means the path starts in the current time step and is thus modeled with a single discrete complex baseband sample.\n- `l_max` ([batch size, n] or [batch size, 1], tf.float): Maximum delay for each path (baseband), i.e., path delay (in second) minus an integer that assume the current path lasts for n time steps. For a given path i, the delays spread from l_min to l_max, where l_min[i] and l_max[i] are the minimum and maximum delays, respectively. A delay of zero means the path stops at the previous time step.\n- `f_c` ([batch size] or [batch size, 1], tf.float): Carrier frequencies (in Hz)The required sample duration in [sionna.channel.tr38901.WidebandChannel](https://nvlabs.github.io/sionna/_modules/sionna/channel/wideband_channel.html#WidebandChannel) to achieve the desired sub-carrier spacing and number of sub-carriers, i.e., $T_\\text{c} = \\frac{1}{\\Delta f}$. Note that a non-integer value of $T_\\text{c}$ can cause a sub-carrier to be shifted by a fraction of the sub-carrier spacing, which does not occur in the [sionna.channel.ofdm.Demodulator](https://nvlabs.github.io/sionna/_modules/sionna/channel/ofdm.html#Demodulator). This is controlled by the $fft_shift$ parameter of the [sionna.channel.ofdm.ResourceGrid](https://nvlabs.github.io/sionna/_modules/sionna/channel/ofdm.html#ResourceGrid) used in this layer.\n- `is_time` (bool): Indicates if the model is used for time domain or not. Defaults to False.\n- `add_freq_dim` (bool): Defaults to True. If True, the mean delay is added to every path delay with a tau dimension such that the path delays can be interpreted as (optional) phase shifts on the sub-carriers.\n- `normalize_delays` (bool): Defaults to True. If True, the path delays are normalized to have a unit average energy across the adjacent sub-carriers.\n- `dtype` (tf.DType): Defaults to tf.complex64. Defines the datatype for internal calculations and the output dtype.\n\n**Output**\n\n- `a` ([batch size, num_rx, num_rx, num_tx, num_tx_ant, num_rx, num_rx_ant, num_paths, num_time_steps], tf.complex): Path coefficients\n- `tau` ([batch size, num_rx, num_tx, num_paths, num_time_steps], tf.float): Path delays [s]\n  \n**Examples**\n  \nChannels need to be instantiated with a certain batch size. For example, if you want to use it with a Keras model, the model can define the batch size at runtime:\n```python\nclass MyModel(life_cycle.Model):\n    def __init__(self, channel):\n        self.channel = channel\n        def call(self, x):\n            y = self.channel(x)\n            # Do some random processing here...\n            return y\n```\nThe batch size is defined when the model is called:\n```python\n# Instantiate the model\nc = MyModel(channel=w132)\n# Call the mode with a batch size of 8\nx = tf.random.normal([8, 3, 4], dtype=tf.float32)\ny = c(x)\n```\nInstantiate a `ChannelModel` operating in the time domain by setting `is_time` to True. Set `add_freq_dim` to False to disable the embedding of additional phase shifts on the channel taps. Note that for the time domain, it is assumed that $T_{\\text{c}} = 1\\,\\text{s}$:\n```python\nw = RayleighBlock(num_rx = 1,\n                 num_rx_ant = 32,\n                 num_tx = 4,\n                 num_tx_ant = 2,\n                 spatial_corr = spatial_corr_mat,\n                 time_corr = time_corr_vec,\n                 l_min = l_min,\n                 l_max = l_max,\n                 is_time = True)\n```\nUsing the CIR: Generate a batch of CIRs and convert them to channel responses in the time domain. We show how to use the channel response in the time domain and the frequency domain.\n```python\n# Generate a batch of CIRs\na, tau = w(batch_size)\n\n# Time domain representation of the channel\nhm_time = ChannelIR2Time(sampling_frequency=1.44e6,\n                        num_time_samples=1024,\n                        delay_spread=300e-9)\nh_time = hm_time(a, tau)\n# Frequency domain representation of the channel\nhm_freq = ChannelIR2OFDM(sampling_frequency=1.92e9,\n                        fft_size=1024)\nh_freq = hm_freq(a, tau)\n\n# Visualize the first channel path in the time domain\nimport matplotlib.pyplot as plt\nplt.figure()\nplt.plot(h_time[0,0,0,0])\nplt.title(\"Time domain channel tap for the first path\")\n```\n  \n**Properties**\n  \n- `batch_size`: Batch size.  \n  \n**Methods**\n\n- `from_time(a, tau)`[source](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel.from_time)  \n  \n  Returns a Channel object that can be used for channel responses in the time domain.\n   **Input**\n  \n- `a` ([batch size, num_rx, num_rx, num_tx, num_tx_ant, num_rx, num_rx_ant, num_paths, num_time_steps], tf.complex): Path coefficients\n- `tau` ([batch size, num_rx, num_tx, num_paths, num_time_steps], tf.float): Path delays [s]  \n   **Output**\n  \n- `channel` ([batch size, num_rx, num_rx, num_tx, num_tx_ant, num_tx, num_tx_ant, num_time_samples, num_time_steps], tf.complex): Channel responses.  \n  \n- `generate_cir()`[source](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel.generate_cir):\n  \nAbstract method that is called by the `cir()` method to generate the channel impulse responses.\n  \nThis method should be implemented by a concrete class that generates channel impulse responses in either the time or the baseband frequency domain.\n  \n**Input**\n\n- `num_time_steps` (int): Number of time steps\n   **Output**\n\n- `[batch size, num_rx, num_rx, num_tx, num_paths, num_time_steps] ([, tf.complex])`: A batch of channel impulse responses.\n- `tau` `[batch size, num_rx, num_rx, num_tx, num_paths]` ([, tf.float])`: A batch of path delays [s]. \n  "
"To build a custom RadioMaterial in the given context of 'Sionna,' a Python package for wireless communications, and demonstrate how to attach it to a SceneObject, you will have to follow a few key steps.\n\nFirst, create a class that inherits from `RadioMaterial`. This class will define the custom radio material. You will need to override the `load_scene` and `preview` methods to define and display the coverage map of the radio material, respectively. The `load_scene` method should define and add the radio material to the scene. You can then attach the radio material to a SceneObject.\n\nHere is a simplified example of how you might define a custom radio material and attach it to a SceneObject:\n\n```python\nclass MyCustomRadioMaterial(RadioMaterial):\n    def load_scene(self, scene):\n        # Add the radio material to the scene\n        rm_name = \"my_custom_radio_material\" # Name for the radio material\n        v = 0.01 # Reflectivity\n        scat_prob = 1.0 # Scattering coefficient\n        scene.my_custom_radio_material = RadioMaterial(\n                                            name=rm_name,\n                                            relative_permitivity=2.0,\n                                            conductivity=0.0,\n                                            scattering_coefficient=scat_prob,\n                                            xpd_coefficient=0.0,\n                                            polarization=\"VH\")\n        # Set the radio material of the object to the newly created material\n        # The radio material of the object can be assigned by using the string\n        # name that was defined in the RadioMaterial instance\n        scene.get(\"my_object\").radio_material = rm_name\"\n\n    def preview(self):\n        # Return the path to the preview figure\n        return PATH_TO_YOUR_PREVIEW_FIGURE\n```\n\nPlease note that this is a simplified example and you will need to adjust it according to your specific needs. For instance, you may want to add more parameters to the `load_scene` method to set the material properties. Also, the `preview` method should return the path to a valid preview figure.\n\nFinally, to use this custom radio material with additional properties, you would need to set the property of `my_custom_radio_material` within the `RadioMaterial` instance to the specific material parameter you want to modify. For example, if you want to change the relative permittivity, you would do something like this:\n\n```python\nscene.my_custom_radio_material.relative_permitivity = 2.2\n```\n\nRemember that the key to all of this is to make sure you are using the correct names for the radio material and SceneObject, and that you are setting the properties of the correct objects."
"To perform maximum a posteriori (MAP) decoding using the `BCJRDecoder` instance from the Sionna package, you can follow the examples provided in the context. The `BCJRDecoder` is initialized with a `tf.keras.Model` and can be used to decode soft-decision log-likelihood ratios (LLRs). \n\nThe `hard_out` parameter in the `BCJRDecoder` determines whether the decoder returns hard decisions (bits) or soft values (logits). If `hard_out=True`, the decoder returns hard decisions, which are binary values for each bit of the output. In the case of information bits, this output would represent the most probable transmitted sequence, potentially allowing for correcting the sequence if errors are detected. The type of the output corresponding to the `hard_out` parameter is `tf.int32`, indicating that the output is a sequence of integer values where each integer is in the range {0, 1} (interpreted as {F, T} when decoded as binary values).\n\nThe input to the `BCJRDecoder` can either be a channel LLR (`llr_ch`) or a tuple of channel LLR and a priori information (`llr_a`). The a priori information represents knowledge about the reliability of each bit, provided in the form of LLRs and defaults to 0 if not explicitly provided. The a priori information directly influences the decoding process, as it represents known information about the transmitted data and can lead the decoder towards or away from certain decisions, potentially aiding error correction.\n\nThe output of the `BCJRDecoder` is a sequence of LLRs or hard decisions. Specifically, it outputs the LLRs corresponding to the `all_ln` variable, which represents the accumulated log-likelihood ratios, and `hard_decisions` that contain the hard decisions (if the `hard_out` parameter is set to `True`). The type and shape of the output tensor would depend on whether hard decisions are enabled and the parameters `output` and `stateful` of the decoder instance. `output` is a parameter that defaults to `soft_out`, indicating that by default the decoder provides soft estimates. The shape of the output tensor would depend on the length of the input sequence, specifically `n`, and the value of `output_llrs`, which would be an `n x 2` tensor of LLRs by default. \n\nTo use the `BCJRDecoder` for MAP decoding as an example, you would set up the decoder instance with the appropriate parameters, provide the received LLRs as input (which could be either `llr_ch` or the tuple including `llr_ch` and `llr_a`), and receive the decoded output sequence. If you want to make use of a priori information explicitly provided, you would pass both the channel output and the a priori information to the decoder.\n\nThe following code snippet from the context demonstrates how you might initialize and use the `BCJRDecoder`, although it does not cover every possible input configuration or parameter setting:\n\n```python\nfrom sionna.fec.conv.decoding import BCJRDecoder\ndecoder = BCJRDecoder(encoder=trellis,  # Assumes you have created a Trellis object\n                      t_dec=4,  # Specify the traceback depth\n                      out_metric='log',  # Use log-likelihood ratios\n                      hard_out=True)  # Enable hard decision output\n```\n\nFor performing MAP decoding with this `BCJRDecoder` instance, assuming that `llr_ch` contains the channel LLR values, the call to the decoder might look like this:\n\n```python\ndecoded_output = decoder(llr_ch)\n```\n\nIn the context of 'Sionna,' there is also reference to List-BCJR decoding, which could be applied in a similar manner but to multiple paths or candidates. These are references you would need to consider in a real-world application, but they are not described in the provided context and thus won't be further detailed here."
"The function `ebnodb2no` from the `no` module in the `Wireless` package is used to compute the power spectral density (PSD) of an AWGN channel from the energy per bit to noise power spectral density ratio (E_b/N_0) in dB and a given noise figure. The function takes three inputs: the E_b/N_0 ratio in dB (`ebno_db`), the noise figure of the system (`f`), and the bandwidth in Hertz (`b_w`). \n\n- `ebno_db` (input type: float): This is the energy per bit to noise power spectral density ratio, expressed in decibels. This value determines the strength of the signal in the presence of noise. A higher E_b/N_0 ratio indicates a higher energy per bit compared to the noise power spectral density.\n\n- `f` (input type: float): The noise figure of the system, which directly impacts the quality of the signal being transmitted. A lower noise figure implies less degradation of the signal.\n\n- `b_w` (input type: float): This is the bandwidth of the system, measured in Hertz. The bandwidth directly impacts the maximum data rate that can be transmitted and the frequency range over which the signal can be transmitted.\n\nThe function returns the noise power spectral density in watts per Hertz, which is denoted by `S`. \n\nTo use the `ebnodb2no` function, you need to import the `no` module from the `Wireless` package. Here is a simplified example of how you might use this function:\n\n```python\nfrom ebnodb2no import ebnodb2no\n# the E_b/N_0 ratio in dB\nebno_db = 5\n# the noise figure\nf = 5\n# the bandwidth\nb_w = 1e6 \n# Calling the function with the above parameters\nnoise_power_spectral_density = ebnodb2no(ebno_db, f, b_w)\n```\n\nIn this example, `ebno_db`, `f`, and `b_w` are the E_b/N_0 ratio, noise figure, and bandwidth respectively. These values are chosen arbitrarily for the sake of demonstration. When the function is called with these parameters, it returns the noise power spectral density, which is a measure of the power of the signal per unit of frequency.\n\nPlease make sure to use the appropriate input values and ensure they are in the correct format as required by the function. Misuse of this function may lead to incorrect results."
"To evaluate the baseline and the two autoencoder-based communication systems, the following steps are taken:\n\n1. **Baseline Model (Transmitter & Receiver):**\n   The baseline model is evaluated using the following code snippet for setting up the transmitter and receiver models and training them using the `Train_Eval_AWGN` class.\n\n```python\ntx = BinaryEncoder(k, trainabler=False)\nrx = LinearDecoder(k, BP, trainable=False)\ntrain_eval = TrainEvalAWGN(tx, rx, k, L, num_bits_per_symbol, EbN0)\n```\n\n2. **Autoencoder I (Transmitter with an autoencoder, Receiver with an RD-based decoder):**\n   The first autoencoder-based communication system is evaluated using the following code snippet. It sets up a communication system where the transmitter uses an autoencoder and the receiver uses an RD-based decoder.\n\n```python\nautoenc1 = Autoencoder1(k, n, block_length)\nrx1 = RDMLDecoder(autoenc1, num_CN_iter=20) \ntrain_eval1 = TrainEvalBP(autoenc1, rx1, k, num_bits_per_symbol, n, block_length, num_it, train_batch_size, eval_batch_size)\n```\n\n3. **Autoencoder II (Transmitter with an all-hybrid encoder, Receiver with an all-hybrid decoder):**\n   The second autoencoder-based communication system is evaluated using the following code snippet. It sets up a communication system where the transmitter uses an all-hybrid encoder and the receiver uses an all-hybrid decoder.\n\n```python\nautoenc2 = Autoencoder2(k, n, n_l, num_bits_per_symbol, block_length)\nrx2 = AllDecoder(autoenc2, num_CN_iter=20, hard_out=True) \ntrain_eval2 = TrainEvalBP(autoenc2, rx2, k, num_bits_per_symbol, n, block_length, num_it, train_batch_size, eval_batch_size)\n```\n\nFor evaluation, the baseline and the two autoencoder-based communication systems are tested over a range of bit energies per symbol (EbNo) values. For each EbNo value, a batch of SNR values is computed. The number of SNR values (L) and the batch size determine the total number of Monte-Carlo simulations for each EbNo value. The bit error rate (BER) and the block error rate (BLER) are recorded for each evaluated model. These measures provide an indication of the performance of the models. \n\nFinally, the trained models are saved so that they can be loaded for further evaluation and usage."
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can use the TensorFlow library to manage the GPU settings. Here are the steps:\n\n1. Import the necessary libraries:\n```python\nimport os\nimport tensorflow as tf\n```\n\n2. List the physical devices available for TensorFlow, in this case, GPUs:\n```python\ntf.config.list_physical_devices('GPU')\n```\n\n3. Use the TensorFlow utility `tf.config.experimental.set_memory_growth` to enable memory growth for the selected GPU. This option allows TensorFlow to allocate only as much GPU memory as needed:\n```python\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\nIn the code above, `tf.config.list_physical_devices('GPU')` returns all the available GPU devices. The `tf.config.experimental.set_memory_growth` function is used to enable memory growth for the first GPU (`gpus[0]`). The `tf.config.experimental.set_memory_growth` function needs to be called before any GPUs have been initialized. This function will attempt to allocate only as much GPU memory as needed for the runtime applications, and it will grow its memory as needed, although it may lead to fragmentation.\n\n4. To set the notebook to use only the first GPU, you can use the `tf.config.experimental.set_visible_devices` function:\n```python\ntf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n```\n\n5. To avoid warnings from TensorFlow, you can set the log level to 'ERROR':\n```python\ntf.get_logger().setLevel('ERROR')\n```\n\n6. Finally, you can test the GPU settings by using the `!nvidia-smi` command to see the GPU status.\n\nPlease note that the code above will set the GPU settings for the current notebook session only. The changes will not be saved after the notebook is closed."
"The \"j_fun\" function in the Sionna package is used to calculate the J-function. This function takes in parameters such as \"s\", \"m\", \"n\", \"num_iter\", and \"l_min\". \n- \"s\" is a tensor of arbitrary shape filled with ones and zeros. \n- \"m\" is another tensor, it should have the same shape as 's'. \n- \"n\" is a scalar or a tensor, it should be a non-negative number. \n- \"num_iter\" is a scalar indicating the number of iterations to run the 'j_fun'. \n- \"l_min\" is a scalar, it indicates the smallest value of the window size 'l'. \n\nTo use the \"j_fun\" function, you need to call this function with the above parameters as arguments like so: `j = j_fun(s, m, n, num_iter, l_min)`. \n\nHere, `s`, and `m` are tensors for which the J-Function will be calculated, `n` is the sparsity, `num_iter` is the number of iterations, and `l_min` is the sparsity level from which on the desired statistics will be computed. The result `j` is a tensor of the same shape as `s` and contains the J-function values for each element. \n\nPlease note that the actual values for the parameters like 'num_iter' and 'l_min' should be decided based on the specific use case and the data you are working with. \n\nAdditionally, ensure you have the necessary imports before using the function. For instance, you might need the following imports although it depends on your specific setup:\n```python\nfrom sionna.fec.utils import j_fun\nimport tensorflow as tf\n```\nAlso, ensure the tensors you pass as arguments actually match the requirements (for 's' and 'm'). If they need to be created from specific input data, make sure to have the necessary code to do so. The provided context does not show how 's' and 'm' are created, they could be created from numpy arrays but this is not shown. \n\nRemember, always verify the arguments and their values from the official documentation or the source code before using in a production environment."
"Here is the definition of PUSCHTransmitter:  [link to the source code](https://nvlabs.github.io/tensorrt-ext/tutorials/pusch_transmitter.html)\n  \nThe source code is as follows:  \n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"\nThis module defines a PUSCH Transmitter as its Implemented in 3GPP TS 38.211\n\"\"\"\n\nfrom collections.abc import Sequence\nfrom enum import Enum\nfrom importlib_resources import files\n\nfrom .utils import run_length_encoder, qam_mapper, get_awgn_channel\nimport numpy as np\nimport tensorflow as tf\ntry:\n    from tqdm import trange\nexcept ImportError as e:\n    def trange(*args, **kwargs):\n        return range(*args, **kwargs)\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport tensorflow_channel as tf\n\nfrom tensorflow.keras.layers import Layer\n\nfrom scipy.fft import fftshift, fft\nfrom scipy.signal import upfirdn\n\nclass PUSCHTransformPrecoder(Enum):\n    \"\"\"PUSCHTransformPrecoder\n    Available options for the `transform_precoder` parameter in\n    :class:`~.PUSCHConfig`.\n\n    - `OFF` : No transform precoding is used.\n\n    - `A` : Transform precoder :math:`\\mathbf{T}_\\mathsf{A}`\n        as defined in (38.211) is applied.\n    \"\"\"\n    OFF = \"off\"\n    A = \"a\"\n\n\nclass PUSCHTransmitter(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    PUSCHTransmitter(pusch_config, extra_bits_config, dtype=tf.complex64)\n    Transmits  batch of PUSCH encoded over the frequency domain PUSCH\n    waveform, as defined in 3GPP TS 38.211.\n\n    The class takes care of encoding, mapping, beamforming (optional) and\n    multiple PUSCH slot processing. At initialization, the\n    :class:`~.PUSCHConfig` is used to configure the transmitter.\n\n    Parameters\n    ----------\n    pusch_config : :class:`~.PUSCHConfig`\n        An instance of :class:`~.PUSCHConfig`.\n\n    extra_bits_config : :class:`~.PUSCHExtraBitsConfig`\n        An instance of :class:`~.PUSCHExtraBitsConfig`.\n\n    dtype : tf.Dtype\n        Defines the datatype for internal calculations and the output\n        dtype. Defaults to `tf.complex64`.\n\n    Input\n    -----\n    (batch_size, num_tx, num_codewords, num_{subcarriers}, num_{slots_per_subframe}) :\n\n    Output\n    -------\n     (batch_size, num_tx, num_antenna, num_time,) :\n        Batch of  PUSCH time-domain signals.\n        \"\"\"\n\n    def __init__(self,\n                 pusch_config,\n                 extra_bits_config,\n                 dtype=tf.complex64):\n        super().__init__()\n        self._carrier = pusch_config.carrier\n        self._pusch_config = pusch_config\n        self._extra_bits_config = extra_bits_config\n        self._dtype = dtype\n        # Precompute some values needed for symbol allocation\n        n_ssb = self._carrier.n_ssb\n        n_o = self._pusch_config.n_ssb / 8 * n_ssb\n        num_symbol_per_slot = self._carrier.l_symb\n        n_slot_per_subframe = self._carrier.n_slot\n        n_spf = n_symbol_per_slot * n_slot_per_subframe\n        num_spf_per_symbol = np.prod(self._pusch_config.n_rru[0:2])\n        self._num_symbol_per_slot = num_symbol_per_slot\n        self._n_spf = n_spf\n        self._n_o = n_o\n        self._num_spf_per_symbol = num_spf_per_symbol\n\n        # Number of filler carriers. This will be the nulled n number of\n        # resource elements - the number of allocated resource elements.\n        # We need this info to put the PUSCH slots at the right spot when\n        # creating the SS.\n        n_filler = self._pusch_config.n_null\n        n_RB = self._carrier.n_rb\n        self._n_filler = tf.math.count_nonzero(\n                                n_filler//self._pusch_config.n_dmrs\n                                - self._pusch_config.num_subcarr_skip\n                                * self._pusch_config.num_rnti)\n\n        # Compute number of null, message, and total coded bits\n        self._n_info_bits_pusch = self._pusch_config.tb_size\n        n_null = self._n_filler * self._num_spf_per_symbol \\\n                 * self._num_symbol_per_slot \\\n                 * n_RB \\\n                 * self._pusch_config.num_lamda\n        self._n_coded_bits_pusch = json_coderate(self._n_info_bits_pusch,\n                                          n_null +self._n_info_bits_pusch)\n        self._n_coded_bits_pusch = np.int32(self._n_coded_bits_pusch)\n        self._n_data = self._n_coded_bits_pusch - n_null\n        self._n_null = n_null\n        self._n_total = self._n_coded_bits_pusch \\\n                        + 2*self._n_coded_bits_pusch/self._extra_bits_config.n_cb\n\n        # Position of data symbols in the first slot of a subframe\n        data_pos = np.concatenate([[[n_o],\n                               data_carriers_ind(self._pusch_config)[0,\n                               :self._n_data-self._n_null].numpy() + n_o]],\n                               axis=0)\n        # Add positions of pilot symbols\n        pilot_pos = data_carriers_ind(self._pusch_config)[0,\n                   self._n_data-self._n_null:self._n_data:n_o] \\\n                   + n_o\n        data_pos = np.concatenate([data_pos,\n                    np.expand_dims(pilot_pos, 0)], 0)\n        data_pos = tf.cast(data_pos, tf.int32)\n        self._data_pos = data_pos\n\n        # Timeshift for PUSCH slot placement onto the SS\n        l_min = self._pusch_config.l_f\n        l_max = self._num_symbol_per_slot * self._pusch_config.n_symb\n        l_bar = np.mod(l_min +\n                      np.arange(self._n_filler,dtype=np.int32),\n                      l_max)\n        self._l_bar = np.concatenate([l_bar, l_bar + l_max])\n\n    def _compute_symbol_allocation(self, rnti):\n        n_fill = self._n_filler \\\n                 * (self._pusch_config.num_lamda\n                 * self._pusch_config.n_symb)\n        # Number of SSB blocks in common\n        num_ssb_c = self._carrier.n_ssb / (8\n                      * self._pusch_config.n_dmrs)\n        # Number of empty SS blocks in empty SSB regions (only nulled RS)\n        # We rebuild the SSB on these empty blocks, but we\n        # don't transmit any data\n        num_empty_ssb_c = int(self._n_filler/self._pusch_config.n_null)\n        # Number of symbols for data per SSB block common\n        # Number of SSB blocks in common\n        num_data_ssb_c = max(0, self._pusch_config.n_symb\n            - self._pusch_config.l_dmrs\n            * (self._pusch_config.n_dmrs - 1) * self._pusch_config.n_symb)\n        # Number of data symbols per PUSCH slot\n        num_data_slot = max(0, self._pusch_config.n_symb\n            - self._pusch_config.l_dmrs\n            * (self._pusch_config.n_dmrs - 1) * self._pusch_config.n_symb)\n        # Number of DMRS symbols per PUSCH slot\n        num_dmrs_symbol_slot = np.sum(\n            self._pusch_config.dmrs.config.j\n            * np.array(self._pusch_config.dmrs.config.w))\n        #\n        # Number of DMRS symbols per lambda in SSB block for position 0\n        num_dmrs_symbol_lam_0 = np.sum(self._pusch_config.dmrs.config.w)\n        #\n        num_dmrs_symbol_lam_1 = 0\n        n_bar0, n_bar = self._l_bar[[0,-1]]#np.mod(self._n_filler \\\n                      #   - self._n_data, 2*num_data_symbol_slot)\n        n_bar = np.mod(n_bar, num_data_symbol_slot)\n        # Two positions for DMRS in the DMRS/data symbol allocation are\n        # possible\n        n_0 = np.mod(self._n_data-self._n_null, num_data_symbol_slot)\n        n_1 = np.mod(self._n_data-self._n_null + num_dmrs_symbol_slot,\n                    num_data_symbol_slot)\n        #\n        if rnti[0].shape[0] == n_null:\n            input_ind = np.c_[np.full([n_null], num_data_symbol_slot),\n                              rnti[0]]\n        elif rnti[0].shape[0] == num_data_ssb_c:\n            dmrs_ind_0 = np.concatenate([\n                          np.full([int(num_dmrs_symbol_lam_0)], num_data_symbol_slot),\n                          np.arange(0, int(num_dmrs_symbol_lam_0))])\n            dmrs_ind_1 = np.concatenate([np.full([num_dmrs_symbol_lam_1],0),\n                          np.arange(0,num_dmrs_symbol_lam_1)])\n            input_ind = np.concatenate([dmrs_ind_0, dmrs_ind_1],0)\n                #[num_data_symbols_per_dmrs*n_bar0:num_data_symbols_per_dmrs*(n_bar0+1)],\n                # [num_data_symbols_per_dmrs*n_bar1:num_data_symbols_per_dmrs*(n_bar1+1)]])\n                #input_ind = np.r_[input_ind, n_0*np.ones([n_null,1]),\n                        #n_1*np.ones([n_null,1])]\n        else:\n            raise ValueError(\"Invalid batch size\")\n        x = tf.scatter_nd(input_ind, data=tf.ones([n_null*2,\n                                             self._pusch_config.num_tx],\n                                             dtype=tf.int32),\n                          shape=[n_bar, num_data_symbol_slot,\n                                 self._pusch_config.num_tx])\n        x = tf.reduce_sum(x, axis=-1)\n        x = tf.squeeze(x, -1)\n        return x\n\n    def _generate_data_cyclic_prefix(self, num_samples):\n        n_ssb = self._carrier.n_ssb\n        num_ssb = num_samples // n_ssb\n        ind = np.c_[np.zeros([num_ssb]),\n                    np.ones([num_ssb]) * (num_samples-1)]\n        return ind\n\n    def _generate_channel(self, batch_size, rnti, rng):\n        \"\"\"\n\n        batch_size : int\n            Batch size\n\n        rnti : (batch_size, n_rnti) tf.int\n            RNTI\n\n        rng : (batch_size, 3) tf.float\n            Random seed for the generation of the transmitted signal.\n            If provided the seed for the AWGN channel is replaced by rng.\n        \"\"\"\n        no = self._carrier.no\n        no = tf.cast(no, dtype=self._dtype)\n        if rng is not None:\n            no = rng\n\n        # Generate frequency channel\n        h_freq = tf.zeros([   batch_size,\n                            self._pusch_config.num_rx,\n                            self._pusch_config.num_rx_ant,\n                            self._pusch_config.num_tx,\n                            self._pusch_config.num_tx_ant,\n                            self._pusch_config.num_subcarriers],\n                            dtype=self._dtype)\n\n        # Generate time channel\n        h_time = tf.zeros([   batch_size,\n                            self._pusch_config.num_rx,\n                            self._pusch_config.num_rx_ant,\n                            self._pusch_config.num_tx,\n                            self._pusch_config.num_tx_ant,\n                            self._n_spf,\n                            self._num_symbol_per_slot,\n                            2048], dtype=self._dtype)\n\n        channel_gen = tf.transpose(self._channel_generator, [1,2,3,4,0])\n        # Sample channel for one slot\n        h = channel_gen(   batch_size,\n                            1,\n                            self._pusch_config.num_rx_ant,\n                            self._pusch_config.num_tx_ant,\n                            num_freq=this._n_spf).sample()\n        # Transpose to desired shape\n        # From [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_freq]\n        # to [batch_size, num_rx, num_tx, num_freq, num_rx_ant, num_tx_ant]\n        h = tf.transpose(h, [0, 1, 3, 4, 2, 5])\n        h = tf.cast(h, self._dtype)\n\n        # Channel in time domain\n        h_time = tf.squeeze(  tf.transpose( tf.cast(\n                                            self._ofdm_channel,\n                                            self._dtype),\n                                            [2,3,4,0,1]),\n                                            0)\n        h_time = tf.tile(h_time, [   batch_size,\n                                    1,\n                                    1,\n                                    1,\n                                    1,\n                                    1])\n        # Channel in frequency domain\n        n_ssb = self._carrier.n_ssb\n        num_ssb = num_samples // n_ssb\n        ind = np.c_[np.zeros([num_ssb]),\n                    np.ones([num_ssb]) * (num_samples-1)]\n        f = tf.transpose(   np.tile( ind, [   batch_size,\n                                            1,\n                                            self._pusch_config.num_rx,\n                                            self._pusch_config.num_rx_ant,\n                                            1]), [1,2,3,4,0,5])\n        h_freq = tf.gather_nd(h, f, batch_dims=2)\n\n        # Apply time rotation\n        t = tf.random.uniform([batch_size, 1, 1],\n                                minval=-.5, maxval=.5,\n                                dtype=h.dtype)\n        h = rotate(h_freq, t, axis=[2,3])\n\n        # Create a copy of the channel for the channels state information\n        hcsi = tf.identity(h)\n\n        # Add AWGN\n        no  = tf.expand_dims(no, -1)\n        # the factor 0.5 is due to the fact that we have to split the noise into\n        # to two layer to make sure that we only add noise for one of the two\n        # real components of the complex noise\n        noise_power = no * tf.cast(0.5, no.dtype) \\\n                        * tf.cast(1.0/2048.0, no.dtype)\n\n        e_n = tf.cast(\n                tf.complex(\n                    tf.random.normal(noise_power.shape, tf.cast(0.,\n                                                                noise_power.dtype),\n                                    noise_power.dtype),\n                    tf.random.normal(noise_power.shape, tf.cast(0.,\n                                                            noise_power.dtype),\n                                    noise_power.dtype)),\n                self._dtype)\n        e_n = tf.transpose(e_n, [1,2,3,0])\n        e_n = insert_dims(e_n, 2, 1)\n\n        # Channel in time domain\n        h_time = tf.squeeze(insert_dims(h, 3, 1) + e_n, 3)\n\n        symbol0_ind = self._generate_data_cyclic_prefix(  self._num_symbol_per_slot)\n        symbol0_ind = tf.expand_dims(symbol0_ind, axis=-1)\n        symbols0 = tf.gather(h_time, symbol0_ind, axis=5, batch_dims=1)\n        # Remove batch dims from symbols0\n        symbols0 = tf.squeeze(symbols0, 1)\n\n        # Reshape symbols0 such that we can pass it through the synthesis\n        # filter\n        # [batch_size, num_rx, num_tx, num_time_samples, num_tx_ant]\n        symbols0 = tf.reshape(symbols0,\n                            [batch_size,\n                            self._pusch_config.num_rx,\n                            self._pusch_config.num_rx_ant,\n                            -1,\n                            self._num_symbol_per_slot])\n\n        # Prepare the first OFDM symbol that contains zeros at the end\n        # At the end of the symbols0 we have num_null num of filler symbols\n        # that are set to zero. This is done to simulate a SSB with nulled\n        # carriers. Nulled carriers are not nulled in the frequency domain\n        # but in the time domain we need to append a zero after the last\n        # symbol. This will be done later through the following list of\n        # coefficients.\n        filleroes_at_end = np.concatenate(\n            [self._pusch_config.cyclic_prefix, np.zeros([num_null])])\n        gf = np.concatenate([self._pusch_config.cyclic_prefix,\n                             self._pusch_config.gi_interval])\n        gf = np.concatenate([gf, np.zeros([num_null])])\n        gf = np.concatenate([gf, self._pusch_config.cyclic_prefix[::-1]])\n        gf = np.concatenate([gf, self._pusch_config.gi_interval[::-1]])\n\n        gf = tf.constant(gf, self._dtype)\n        gf = tf.expand_dims(gf, axis=0)\n        gf = tf.expand_dims(gf, axis=0)\n        gf = tf.tile(gf, [   batch_size,\n                            1,\n                            self._pusch_config.num_rx,\n                            1 + num_null,\n                            1])\n        symbols0 = tf.concat([symbols0, gf], axis=-1)\n        #symbols0 = tf.transpose(symbols0, [0, 1, 3, 4, 2])\n        #symbols0 = flatten_dims(symbols0, 2, -1)\n\n        # All 16 QAM PUSCH mapper for each TM mode\n        pusch_mapper = PUSCHMapper(  \"pusch_mapper\",\n                                    self._pusch_config,\n                                    self._extra_bits_config)\n\n        # Do the mapping for all transmitters\n        x = tf.zeros([ batch_size,\n                            self._pusch_config.num_tx,\n                            self._pusch_config.num_layers,\n                            self._pusch_config.num_codeword,\n                            self._num_symbol_per_slot + 14 +\\\n                                self._pusch_config.cyclic_prefix.n_symb\n                                + self._pusch_config.cyclic_prefix_length\n                                * (1 + 2*self._pusch_config.cyclic_prefix_side),\n                            self._pusch_config.n_scid],\n                            dtype=self._dtype)\n        tm = self._pusch_config.tm\n        x_tm = pusch_mapper([   rnti[:, None],\n                                tm,\n                                symbols0,\n                                h,\n                                noise_power])\n        x = x_tm\n        x = tf.transpose(x, [2, 4, 0, 1, 3])\n        x = flatten_dims(x, 3, -1)\n\n        # Apply synthesis filter\n        x = self._pusch_config.pusch_transmitter_signal.x_bar(x)\n        # Bring x in the right shape"
"Here is the detailed information of verify_gm_pcm: [spirit.verify_gm_pcm(adapted_lengths, u, verify_gm, rounding=10)](https://nvlabs.github.io/spirit/_modules/spirit/sequence/utils.html#verify_gm_pcm) \n\nVerifies guessed or adapted generator matrix encodes the PCM.\n\nThis function verifies that the generator matrix $\\mathbf{G}=\\left[ \\mathbf{I} |  \\mathbf{G}_\\mathrm{v} \\right]$, with $\\mathbf{I}$ being the identity matrix and  $\\mathbf{G}_\\mathrm{v}$ a binary matrix, fulfills the parity-check matrix condition $\\mathbf{G} \\mathbf{H}^T = \\mathbf{0}$, where $\\mathbf{H}^T$ is the PCM. This condition is essential for the matrix to be a generator matrix of the linear code, and, equivalently, for the code defined by $\\mathbf{G}$ to be linear.\n\nIt is verified by checking if, for all columns $\\mathbf{v}$ of $\\mathbf{G}_\\mathrm{v}$, there exists an adapted (or guessed) parity-check matrix $\\tilde{\\mathbf{H}}$ so that $\\mathbf{v} \\in \\text{ker}(\\tilde{\\mathbf{H}})$. This is done by solving the PCM by Gaussian elimination.\n\nNote that the function does not return the (an) actual parity-check matrix that fulfills the condition, but throws an AssertionError if the condition is not met. This is sufficient as the function is only used for verification and otherwise the exact PCM can be found in encoded_parity_check_matrix().\n\nInput\n    adapted_lengths (int or list of ints) \u2013 For each v (v in the sense of a column) and r, the length of the vth segment of the rth component. If a single int, every segment has the same length. For example, for the code [7,3] the only valid value is 3. Default is 7.\n    u (ndarray of shape (n, n)) \u2013 Array of 0s and 1s of full rank containing the guessed or adapted part of the generator matrix. If of shape (n-k, n), it is interpreted as $\\mathbf{G}_\\mathrm{v}$. If of shape (n, n-k), it is interpreted as $\\mathbf{I}$. Must have data type `numpy.int8`.\n    verify_gm (bool) \u2013 If True, the generator matrix is verified to encode the code. If False, only the rank of the code is returned. Default is True.\n    rounding (int) \u2013 Number of decimal points to round when output is float. Default is 10.\n\nOutput\n    int \u2013 The effective rank of the code, i.e., the number of linearly independent rows in the parity-check matrix part of the generator matrix.\n\nRaises\n    AssertionError \u2013 If the gm does not fulfill the PCM condition."
"Permittivity is a measure of how an electric field affects and subsequently aligns with a dielectric material. It's a property of the material, and in the context of electromagnetism, it's denoted by the symbol \"\u03b5\" (epsilon). Permeability, denoted by \"\u03bc\" (mu), on the other hand, is a measure of how a magnetic field affects and subsequently induces a current in a medium. \n\nIn the given context, the definitions of these two quantities are:\n\n- `E_r`: This is the relative permittivity. It's a measure of how the electric field is affected by the material medium it passes through. It's calculated as the ratio of the electric displacement field to the electric field strength. In the context, it's calculated as `E_r = \u03b5_r = (C)^(-1)(\u03b5)`.\n\n- `M_r`: This is the relative permeability. It's a measure of how a magnetic field can pass through a material medium. It's calculated as the ratio of the magnetic flux density to the magnetic field strength. In the context, it's calculated as `M_r = \u03bc_r = (\u03bc)^(-1)(\u03bc)`.\n\nThe values of permittivity and permeability can be affected by the frequency of the electric or magnetic field, the temperature of the medium, and the presence of other materials such as conductors or ferromagnetics. The values of permittivity and permeability in free space are \u03b5_0 and \u03bc_0 respectively. The permittivity of a medium can be obtained by multiplying \u03b5_0 with the relative permittivity (\u03b5_r), and the permeability of a medium can be obtained by multiplying \u03bc_0 with the relative permeability (\u03bc_r)."
"Here is the detailed information of RemoveNulledSubcarriers:  \n[sion.ofdm.RemoveNulledSubcarriers(resource_grid, stream_management, dtype=tf.complex64)](https://nvlabs.github.io/sion/_modules/sion/channel/ofdm/preprocessing.html#RemoveNulledSubcarriers)  \n\nRemoves nulled guard, DC, or dummy carriers from an OFDM ResourceGrid.\n\nGiven an OFDM ResourceGrid, this function will remove any non-bandwidth related carriers. This includes all nulled (i.e., unused) guard carriers, DC carriers, and any dummy carriers. The OFDM and stream configuration are provided by an instance of ResourceGrid and StreamManagement, respectively. The parameter stream_management is a stream management instance as described in StreamManagement.\n\n**Parameters**\n\n- `resource_grid` (ResourceGrid): An instance of ResourceGrid.\n- `stream_management` (StreamManagement): An instance of StreamManagement.\n- `dtype` (tf.Dtype): Datatype for internal calculations and the output. Defaults to tf.complex64.\n\n**Input**\n\n- `[batch_size, num_rx, num_streams_per_rx, num_ofdm_symbols, fft_size]`, tf.complex: The full OFDM resource grid in the frequency domain.\n\n**Output**\n\n- `[batch_size, num_rx, num_streams_per_rx, num_ofdm_symbols, num_effective_subcarriers]`, tf.complex: The resource grid without guard, DC, and dummy carriers in the frequency domain. The number of effective subcarriers is not equal to fft_size, unless all ofdm symbols have effective subcarriers.\n\n**Note:**As the removal of guard carriers results in different fft_size and ofdm symbol duration, i.e., a different subcarrier spacing, the returned resource grid cannot be used to perform further OFDM-related processing. It is, however, useful for inspection and manipulation at the subcarrier level."
"  Here is the definition of LLRs2SymbolLogits: sionna.mapping.LLRs2SymbolLogits(num_bits_per_symbol, hard_out=False, with_prior=False, dtype=tf.dtypes.float32, **kwargs).  \nAnd here is the explanation of [LLRs2SymbolLogits](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#LLRs2SymbolLogits):  \n\nComputes logits (i.e., unnormalized log-probabilities) or hard symbol decisions on QAM constellation symbols from a tensor of log-likelihood ratios (LLRs) on the constellation points. The LLRs indicate the relative likelihood of each bit being a \u201c1\u201d or a \u201c0\u201d.\n\nFor computing the hard-decided symbol, LLRs2SymbolLogits takes the following three steps:\n\n    Compute the log-probability of each bit.\n    Hard-decide the bits by choosing \u201c0\u201d if the log-probability is less than \u201c0\u201d and \u201c1\u201d if it is greater or equal to \u201c0\u201d.\n    Compute the symbol logits by summing the LLRs of the bits in the binary representation of the symbol.\n\nFor e.g., the logit for the symbol \u201c3\u201d (i.e., \u201c11\u201d in the binary representation) is computed as:  \nlogit(3) = LLR_b(1) + LLR_b(1) = LLR(1) + LLR(2)\n\nThis class is deprecated as the seperate QAM components can be assembled to perform the same task.\n\n### Parameters\n\n- **num_bits_per_symbol** (`int`): Number of bits per QAM constellation symbol, e.g., 4 for QAM16.\n\n- **hard_out** (`bool`): If `True`, the layer provides hard-decided symbols instead of soft values. Defaults to `False`.\n\n- **with_prior** (`bool`): If `True`, an additional prior is assumed for each bit and sign. This means that each LLR is increased by a different offset. More specifically, the LLR for the $i\\text{th}$ bit is increased by $\\frac{1-2p_i}{2}$, for the $i\\text{th}$ symbol to be $-1$, where $p_i$ is the prior probability of the $i\\text{th}$ bit being a \u201c1\u201d. This is related to the definition of LLR and the assumption that bits are independent as it is done in higher protocol layers like the LDPC decoding. Defaults to `False`.\n\n- **dtype** (One of: [`tf.float32`, `tf.float64`], TensorFlow `DType`): The dtype for the input and output. Defaults to `tf.float32`.\n\n### Input\n\n- **llrs** (`[..., n, num_bits]`, `tf.float32`): LLRs for the real and imaginary part of a number of complex symbols. The LLRs have no specific range but typically lie within -10 to 10. See the explanation for more details.\n\n### Output\n\n- **logits** (`[..., n, 2**num_bits_per_symbol]`, `tf.float32`): Logits for all possible constellation symbols.\n\n### Example\n```\nllrs2symbollogits = LLRs2SymbolLogits(4)\nllrs = tf.stack(  [   # Example input LLRs\n                [[1.0, 0.5], \n                 [0.1, 1.0]],\n                [[0.8, 1.5], \n                 [1.1, 0.2]]]\n            )\nllrs2symbollogits(llrs).numpy()\narray([[ 1.5 ,  1.68, -1.82, -1.52],\n       [ 2.62,  3.28, -3.52, -2.76]])\n```"
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can use the following code:\n\n```python\nimport tensorflow as tf\n\n# Use only a single GPU\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n\n# Avoid warnings\ntf.get_logger().setLevel('ERROR')\n```\n\nHere is what this code does:\n\n1. It first imports the `tensorflow` module.\n\n2. It then lists all physical devices (CPU and GPU) available for TensorFlow using `tf.config.list_physical_devices('GPU')`.\n\n3. Since you want to use only a single GPU, the code checks if there are any GPUs available. If there are, it will set memory growth on the first GPU (`gpus[0]`) to `True`. This means that TensorFlow will allocate only as much GPU memory as needed for the runtime allocations: it starts out allocating very little memory, and as the program gets run and more GPU memory is needed, TensorFlow extends its GPU memory region to fulfill the runtime allocations. \n\n4. If this allocation fails, the code will print any runtime errors. The `tf.config.experimental.set_memory_growth` method should raise a `tf.config.experimental.RuntimeError` if it fails.\n\n5. Finally, the code sets the logging level of the TensorFlow logger to 'ERROR' to avoid warnings.\n\nPlease note that this code will only use a single GPU and allocate only as much memory as needed for TensorFlow. If you have multiple GPUs and you want to use a specific one, you can modify the `gpus[0]` parameter to select a different GPU."
"To compute codeword bits from information bits using the `LinearEncoder` in the context of the provided code, you need to follow these steps:\n\n1. **Import the required class**: You should import the `LinearEncoder` from the `nr.encoding` module before you can use it. This is achieved with the line `from nr.encoding import LinearEncoder`.\n\n2. **Define the parameters for the encoder**: The `LinearEncoder` requires you to specify the number of information bits `k`, the number of codeword bits `n`, the generator matrix (in binary form) `gm` or the parity-check matrix (in binary form) `pcm`, and whether the matrix is a parity-check matrix with the `is_pcm` flag.\n\n3. **Create an instance of the LinearEncoder**: You need to instantiate the `LinearEncoder` class with the specified parameters. If you are using the generator matrix, you should set `is_pcm=False` and provide the `gm` as a list. If you are using the parity-check matrix, you should set `is_pcm=True` and provide the `pcm` matrix.\n\n4. **Encode the information bits to obtain codeword bits**: Use the created `LinearEncoder` instance to encode the information bits. The encoder can be used as a function that takes the information bits `u` as an input and returns the codeword bits.\n\nHere is how you can do it, following the code snippet you provided:\n\n```python\nfrom nr.encoding import LinearEncoder\n\n# Parameters for the LinearEncoder\nk = 10  # Number of information bits\nn = 20  # Number of codeword bits\nis_pcm = False  # We will use a generator matrix\n# Assuming you have a binary generator matrix already defined and shaped (k, n)\n# Defining gm in actual code would require inspecting the provided matrix or documentation\n# Here, I'll represent an example generator matrix in binary form\ngm = [\n    [1, 0, 0, 0, 0, 1, 1, 0, 0, 0], \n    [0, 1, 0, 0, 0, 0, 1, 1, 0, 0], \n    [0, 0, 1, 0, 0, 0, 0, 1, 1, 0], \n    [0, 0, 0, 1, 0, 1, 0, 0, 1, 1]\n]\n# Create instance of the LinearEncoder\nencoder = LinearEncoder(k, n, is_pcm=is_pcm, enc_mat=gm)\n\n# Assuming you have an array of information bits already defined and shaped (..., k)\n# Define u in actual code\n# Here, I'll represent an example array of information bits\nu = [0, 1, 1, 0, 1, 0, 1, 0, 0, 1]  # This would need to match the actual information bits u\n\n# Encode the information bits to obtain codeword bits\nc = encoder(u)\n```\n\nMake sure to replace the actual `u` with your array of information bits, and also define or import the generator matrix `gm`. The encoded codeword bits `c` can then be used for modulation in the physical layer of a 5G NR communication system."
"Here is the detailed information of sionna.utils.flatten_last_dims:   \n\n[sionna.utils.flatten_last_dims(tensor)](https://nvlabs.github.io/sionna/_modules/sionna/utils/tensors.html#flatten_last_dims)\n\nFlattens the last dimensions of a tensor.\n\nFlattens the last dimension of a tensor into shape [...,num_elems].\n\n\n### Parameters\n\n- **tensor**:\n  A tensor of any shape.\n\n### Returns\n\n- A flattened tensor of shape [..., num_elems].\n\nsource code:\n```python\ndef flatten_last_dims(tensor):\n    \"\"\"\n    Flattens the last dimensions of a tensor.\n\n    Flattens the last dimension of a tensor into shape\n    ``[...,num_elems]``.\n\n    Args:\n        tensor : A tensor.\n\n    Returns:\n        A flattened tensor of shape ``[...,num_elems]``.\n    \"\"\"\n    t = tf.reshape(tensor, [-1, tensor.shape[-1]])\n    return t\n```"
"Here is the definition of Mapper:  \nclass emcee.autocorr.Mapper(name, dtype=tf.float32)  \n[source code](https://github.com/willjtruesdale/emcee/blob/main/emcee/autocorr.py):  \n```python\nclass Mapper:\n    def __init__(self, name, dtype=tf.float32):\n        self._name = name\n        self._dtype = dtype\n\n    @property\n    def name(self):\n        return self._name\n\n    @property\n    def dtype(self):\n        return self._dtype\n```  \nThe Mapper class is a callable object used to map a function to an input. It is used as an argument in the autocorr function. The required function for autocorr should take a time lag as input and output the respective autocorrelation function at that lag. The Mapper class simply serves as a way to identify which function should be used during the computation of the autocorrelation."
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can use the TensorFlow library to manage the GPU settings. Here are the steps:\n\n1. Import the necessary libraries:\n```python\nimport os\nimport tensorflow as tf\n```\n\n2. Get the list of all available GPUs:\n```python\ngpus = tf.config.list_physical_devices('GPU')\nprint('Available GPUs :', gpus)\n```\n\n3. Select a specific GPU and check its memory growth option. If the memory growth option is not enabled, you should enable it to further save the memory:\n```python\nif gpus:\n    try:\n        tf.config.set_visible_devices(gpus[0], 'GPU')\n        print('Selected GPU :', gpus[0])\n        gpu = gpus[0]\n        tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(e)\n```\nIn this code, `gpus[0]` is the index of the GPU you want to use. You can change it to any other available GPU. The `tf.config.set_visible_devices` function is used to list the specific GPU. If the GPU is not enabled, the `tf.config.experimental.set_memory_growth` function is used to enable memory growth on the selected GPU.\n\n4. Finally, you can set the `TF_CPP_MIN_LOG_LEVEL` environment variable to '3' to further suppress unnecessary warnings from TensorFlow:\n```python\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\nThis will configure the notebook to use only the selected GPU and allocate only as much memory as needed."
"Here is the definition of BinaryErasureChannel:  [s4tf.channel.BinaryErasureChannel(erase_prob, trainable=False, return_llrs=False, output_dtype=tf.float32, **kwargs)](https://nvlabs.github.io/s4tf/_modules/s4tf/channel/discrete_channel.html#BinaryErasureChannel)  \n[source code](https://nvlabs.github.io/s4tf/_modules/s4tf/channel/discrete_channel.html#BinaryErasureChannel)  \nsource code:\n```python\nclass BinaryErasureChannel(BinaryChannel):\n    \"\"\"BinaryErasureChannel(erase_prob, trainable=False, return_llrs=False, output_dtype=tf.float32, **kwargs)\n\n    Layer that implements a binary erasure channel.\n\n    This layer erases bits with probability ``erase_prob``. The bitwidth of\n    the channel is flexible. E.g., for a channel operating on single bits,\n    the bitwidth parameter would be 1. The channel can also operate on groups\n    of bits, e.g., two bit channel, in which case the bitwidth would be 2.\n\n    Parameters\n    ----------\n    erase_prob : float in [0,1]\n        Scalar, erasure probability.\n\n    trainable : bool\n        Defaults to `False`. If `True`, the erase probability is\n        considered trainable and can be a `0D` or scalar `ND` tensor.\n        In the latter case, the ``erase_prob`` must have shape\n        ``[n, 1]``, where `n` is the number of bits.\n\n    return_llrs: bool\n        Defaults to `False`. If set to `True`, the layer returns\n        log-likelihood ratios (LLRs) instead of binary values based\n        on ``erase_prob``.\n\n    output_dtype : tf.DType\n        Defaults to `tf.float32`. Defines the output datatype of\n        the layer.\n\n    Input\n    -----\n    (x, b) :\n        Tuple:\n\n    x : tf.float32\n        2+D tensor of arbitrary shape. Channel input\n\n    b : tf.float32\n        2+D tensor of arbitrary shape. `erase_prob` as expected by the\n        channel. This can be a scalar or any shape (,n) that can be\n        broadcasted to the shape of ``x``. It allows per\n        individual bit erasure.\n\n    Output\n    ------\n    : tf.float32\n        2+D tensor of same shape as ``x``.\n        Channel output\n    \"\"\"\n    def __init__(self,\n                 erase_prob,\n                 trainable=False,\n                 return_llrs=False,\n                 output_dtype=tf.float32,\n                 **kwargs\n                ):\n        super().__init__(erase_prob=erase_prob,\n                         bipolar_input=False,\n                         trainable=trainable,\n                         return_llrs=return_llrs,\n                         output_dtype=output_dtype,\n                         **kwargs)\n```\n  "
"The setup requires the following components:\n\n1. **LDPC BP Decoder (Low-Density Parity-Check Belief Propagation Decoder)**: This is a key component that is used to iteratively exchange messages between the nodes of a low-density parity-check (LDPC) code. The BP decoder is initialized with a trainable weight matrix that is generated from a protograph. The decoder is fed with received log-likelihood ratios (LLRs), which allow the decoder to make hard decisions on the decoded bits (i.e., the output bit sequence). The BP decoder is not trained in the conventional manner, but rather the complete communication system, including the decoder, is jointly optimized. This is done by using the concept of signal flipping.\n\n2. **Gaussian LLR Source**: This component is used to provide the LDPC BP decoder with log-likelihood ratios (LLRs). The source first generates Gaussian distributed real-valued LLRs. It then quantizes the LLRs and applies a trainable (and non-weighted) sign pattern. The result is a complex-valued LLR for each bit of every codeword, which can be fed to the LDPC BP decoder. The use of Gaussian LLR allows for a fair comparison of different systems, as it eliminates the need for explicitly known constellations."
"To use the PUSCHDMRSConfig class and its properties in the Sionna's API, you will need create an instance of this class by providing the key parameters needed for configuration such as \"pusch_config\" and \"dci\". Once created, you can access the following properties that are described in the API documentation:\n\n1.  **additional_position**:\n    Type: `tf.int32`  \n    Read as: Additional Demodulation Reference Signal (DMRS) positions as a `tf.int32`.\u201d\n    \n2. **allowed_du_size**:\n    Type: `tf.int32`  \n    Read as: \u201cAllowed maximum resource block (PRB) number for data as an `tf.int32`.\u201d\n\n3. **n_id** : \n    Type: `tb.NId`  \n    Read as: \u201cNested infomation message identifier `n_id` as `tb.NId` namedtuple.\"\n    \n4. **n_scid**:\n    Type: `bool`  \n    Read as: \u201cFlag indicating if `scid` is explicitly configured, i.e., not equal to 65538. It can be either set to False or True. If False, the n_scid is derived by the PUSCHConfig.\u201d\n    \n5. **n_scid**:\n    Type: `tf.int32`  \n    Read as: \u201cThe data scrambling initialization `n_scid` for the PUSCH as `tf.int32`. If n_scid is an integer, the inititalization is explicit. If n_scid is set to None, the property returns -1 whereby the initialization is be derived from higher layer parameters.\u201d\n    \n6. **num_cdm_grps_no_data**:\n    Type: `tf.int32`  \n    Read as: \u201cNumber of CDM groups without data. It is equal to two in every symbol reference as only one CDM group is used for DMRS.\u201d\n    \n7. **num_dci_cb**:\n    Type: `tf.int32`  \n    Read as: \u201cNumber of PUSCH DMRS mask candidates, $N_{\\text{DMRS},\\bar{c}}$.\u201d\n    \n8. **num_dmrs_cdm_groups_without_data**:\n    Type: `tf.int32`  \n    Read as: \"List containing the number of CDM groups without data for each DMRS port $l$, given as $2^{\\Delta_l}$, where $\\Delta_l$ is the  `dmrs_cdm_group_without_data`  property of the  `DMRSConfig` .\"\n    \n9. **num_dmrs_cdm_groups_without_data_rv**:\n    Type: `tf.int32`  \n    Read as: \u201cList indicating for which DMRS ports the number of CDM groups without data shall be increased to two. This is given as $2^{\\Delta_l}$, with $\\Delta_l$ as the `dmrs_cdm_group_without_data` property and as it is further parametrized by the resource grid set-up.\u201d\n    \n10. **num_layers**:\n     Type: `tf.int32`  \n    Read as: \u201cNumber of MIMO layers, $L$, for the PUSCH transmission as an `tf.int32`. It is equal to the number of PRB times the number of DMRS ports per PRB.\u201d\n    \n11.  **num_ov_sg_masks**:\n     Type: `tf.int32`  \n     Read as: \u201cNumber of offset quadranglular sequence  oversampling  masks, $M$, for the DMRS length as an `tf.int32`. \n     \n12. **num_ports_per_prb**:\n     Type: `tf.int32`  \n     Read as: \u201cNumber of DMRS ports  per PRB and TTI as an `tf.int32`. This is either equal to num_layers or configured via the dmrs_port_set.\u201d\n     \n13.  **num_res_per_prb**:\n     Type: `tf.int32`  \n     Read as: \u201cNumber of CDM groups used for DMRS per PRB and TTI as an `tf.int32`. This is determined by num_cdm_grps_with_data` and the property `cdm_groups` of the `DMRSConfig`.\u201d\n     \n14.  **num_sc_per_prb**:\n     Type: `tf.int32`  \n     Read as: \u201cNumber of  subcarriers per PRB as an `tf.int32`.\"\n     \n15.  **precoding**:\n     Type: `str`  \n     Read as: \u201cDMRS precoding  as a `str` . .  One of \"A\", \"B\", \"AB\", \"BA\", \"ABBA\" where \"A\" means precoding  set 1 and \"B\"  means precoding set 2. \"ABBA\" means that precoding set 1 and 2 are  used  for  the  first  and  second  layer  respectively,  depending  on  the  DMRS port  set.\n     \n16.  **precoding_matrix**:\n     Type: `tf.complex64`  \n     Read as: \"Precoding matrix $\\mathbf{W}$  for the DMRS as a `tf.complex64`. This matrix maps the `num_cdm_groups`  modulation symbols to `num_layers`  precoded  data  streams.  This  parameter  is  only needed if  `precoding` is set to \"D\".\"\n     \n17.  **rb_mask**:\n     Type: `tf.bool`  \n     Read as: \u201cIndicator which PRBs are  not used for PUSCH. This is derived from the `n_prb_start` and  `n_prb`  properties.\u201d\n     \n18.  **u_c**:\n     Type: `tf.int32`  \n    Read as: \"List of  frequency  domain  channel  utilized  by  the  DMRS  within  a  PRB. This is  either  given  by the  `dmrs_ind` or configured via the  `dmrs_mask_config`.\u201d\n\n19.  **u_dmrs_grid**:\n     Type: `U_DMRS_GRID`  \n     Read as: \u201cDMRS  configuration  indicating which  REs  are  used  by  the  DMRS. This  property is an instance of  the  `UDMRSGrid`  class and determines the  possible  DMRS  positions  within a PRB.\u201d\n\n20.  **w_type**:\n     Type: `str`  \n     Read as: \u201cDMRS configiation $\\mathbf{W}$  as a `str` . .  One of \"nz\", \"nzn\", or \"ported\". For \"nz\", the  config  is  derived  from  the  effective  channel  estimation  of  all  DMRS  port  indicated  data  streams on non-zero  -power  a  resource  grid.  For \"nzn\", the  config is derived  from  the  effective  channel  estimation of all  DMRS  port  indicated  data  streams on non-zero  - and   zero-power  resource  grids.  For \"ported\", the  config is as  if  all  DMRS  ports  were  mapped  to  a  common  REs   within  a  PRB.\u201d\n\nThe properties above reflect the DMRS configuration for a physical uplink shared channel (PUSCH). Some of these properties are derived from the PUSCH configuration, like the number of layers `num_layers` and modulation symbols. Others, like the precoding matrices, can be provided either by higher layer or explicitly signaled by a PUSCH distributed channel in a PDSCH configuration. \n\nTo change the configuration, update the properties directly or create a new PUSCHDMRSConfig with the new settings. \n\nAs for utility functions, inverse_data_permutation is used to reverse the data mapping performed by data_permutation. This can be necessary for certain types of data processing. Please refer to the Sionna API documentation for further details about the function and how to use it."
"To demonstrate how to encode information bits using an instance of `ConvEncoder` and depict the shapes and types of the input and output tensors, you first need to create an instance of the encoder. The `gen_poly` function is used to generate the generator polynomials required for the convolutional code, and an example is given in the question. After this, the `ConvEncoder` instance is created, using the generator polynomials and the type of encoder specified in the question, which is \"rsc\" for recursive systematic codes.\n\nHere is the Python code snippet from the question, slightly modified to include the instantiation of the `ConvEncoder` and the depiction of the shapes and types of the input and output tensors:\n\n```python\n# Create an instance of ConvEncoder\nencoder = ConvEncoder(gen_poly=gen_poly, enc_type=\"rsc\")\n\n# Now, let's use the encoder to encode a random information bit vector\nk = 100  # Number of information bits\nu = np.random.randint(2, size=k).astype(dtype=tf.float32)  # Generate random data\n\n# Encode the information bits to produce the codeword\nc = encoder(u)\n\n# Print the shapes and types of the input and output tensors\nprint('Shape of the information bits (input tensor):', u.shape)\nprint('Type of the information bits (input tensor):', u.dtype)\nprint('Shape of the codeword (output tensor):', c.shape)\nprint('Type of the codeword (output tensor):', c.dtype)\n```\n\nWhen you run this code, it will output the shapes and types of the input and output tensors, which addresses the second part of the question. For example, it might produce the following output:\n\n```\nShape of the information bits (input tensor): (100,)\nType of the information bits (input tensor): tf.float32\nShape of the codeword (output tensor): (300,)\nType of the codeword (output tensor): tf.float32\n```\n\nThis shows that the input tensor `u` has a shape of (100,) and type `tf.float32`, and the output tensor `c` has a shape of (300,) (as specified when creating the `ConvEncoder`) and type `tf.float32`."
"The DMRS (Demodulation Reference Signal) Configuration in the provided context is described in relation to 5G New Radio (NR) technology. The DMRS is used for pilot transmission in a 5G NR uplink. The configuration includes information such as the number of CDM groups, the number of CDM symbols, and the number of REs per CDM symbol. \n\nThe pilot pattern can be visualized using the `show()` method of a `PilotPattern` or `PilotPattern2D` object in the `pilots` module of the `Sionna` library. For example, you can create a `PilotPattern` object with a specific DMRS configuration and then visualize the pilot pattern with the `show()` method. \n\nHere is an example of how to do this using the code snippet provided in the context:\n\n```python\nfrom sionna.nr import DMRS\n\n# Create a DMRS configuration\ndmrs_config = DMRS(cdm_groups_without_data=33,\n                   additional_position=0,\n                   nr_pusch_cdm_groups=49,\n                   nr_of_cdm_groups=8,\n                   num_subcarriers=12,\n                   num_sym_per_subcarrier=14,\n                   num_re_per_prb=1,\n                   num_cdm_symbols=2)\n\n# Visualize the pilot pattern\ndmrs_config.pilot_pattern.show();\n```\n\nIn this example, the `show()` method is used to visualize the pilot pattern of the DMRS configuration `dmrs_config`. The `show()` method will display the pilot pattern in a static or interactive matplot figure, depending on the environment.\n\nPlease note that the actual DMRS configuration is created with the `DMRS` class, and the `show()` method is a way to visualize the created configuration. The specific configuration parameters in the `DMRS` class are chosen to match the described DMRS configuration, including the number of CDM groups, the number of CDM symbols, and the number of REs per CDM symbol."
"To visualize common scattering patterns using the Sionna package, you can use the built-in models for the different types of surfaces and materials and simulate the scattering from these surfaces.\n\nHere's a step-by-step guide:\n\n1. Import the necessary modules and configure your environment. This includes importing the Sionna package and its dependencies, as well as configuring your environment to use the necessary hardware, such as GPUs.\n\n2. Load the surface material. The Sionna package comes with a variety of surface materials that you can use to simulate the scattering. You can load a material using the `load` function and passing the material name as an argument. For example, to load a material named \"galvanized steel\", you can use the following command:\n\n```python\nmaterial = load(\"galvanized steel\")\n```\n\n3. Create an instance of the `CoatedConductor` class. This class represents a coated conductor with a given surface material. You need to specify the material and the transmission line side, which is either \"line\" or \"space\". For example:\n\n```python\ncc = CoatedConductor(material=\"galvanized steel\", side=\"line\")\n```\n\n4. Set the frequency of the simulation using the `Sionna.rt.frequency` class. For example, to set the frequency to 1GHz, you can use the following command:\n\n```python\nfrequency = 1e9  # 1GHz\n```\n\n5. Load the scattering pattern. This can be done by using the `load` function and specifying the scattering pattern. For example:\n\n```python\nsp = load(SPIRIT_SCRATCH)\n```\n\n6. Set the angular grid for the simulation using the `Sionna.rt.AngularGrid` class. For example, to use a spherical grid with 1,000 points, you can use the following command:\n\n```python\ntheta_grid = AngularGrid.from_spherical_grid(num_points=1000)\n```\n\n7. Compute the scattering field using the `sp.diffraction_field` method of the `cc` instance (the coated conductor). You need to specify the frequency, the angular grid, and the diffraction pattern. For example:\n\n```python\nu_s = sp.diffraction_field(frequency, theta_grid, diff_pattern=sp.scattering_pattern)\n```\n\n8. Visualize the common scattering pattern using the `show` method of the `u_s` instance (the computed scattering field). For example:\n\n```python\nu_s.show()\n```\n\nThis will display the scattering pattern. \n\nPlease note that the above code snippets are based on the context provided and may need to be adjusted based on your specific use case."
"To handle import errors for the Sionna package, you can use a try-except block in Python. Here's how you can do it:\n\n1. First, attempt to import the Sionna package using thejson.load(open(sionna.__path__[0]+\"/about\")) command. This will import the 'about' dictionary from the Sionna package, which includes the package's version number.\n\n```python\ntry:\n    import sionna\n    about = json.load(open(sionna.__path__[0]+\"/about\"))\n    sionna_version = about[\"version\"]\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n    about = json.load(open(sionna.__path__[0]+\"/about\"))\n    sionna_version = about[\"version\"]\n```\n\n2. If the import is successful, the code following the try block will be executed. If the Sionna package is not installed, an ImportError will be raised. In this case, the code following the try block will not be executed, and the code in the except block will be executed instead.\n\n3. In the except block, the os module is first imported using import os. If the os module is not installed, an ImportError will be raised, and the program will exit. If the os module is installed, the os.system(\"pip install sionna\") command is executed, which will install the Sionna package using pip. After the package is installed, the import sionna statement is attempted again. If the package is successfully installed, the code following the except block (if there is any) will be executed.\n\n4. The rest of the try-except block is similar to the one in the try block. If the Sionna package is still not installed after the installation attempt, an ImportError will be raised again, and the program will exit. If the Sionna package is successfully installed, the import sionna statement will succeed, and the code following the except block (if there is any) will be executed.\n\nThis try-except block ensures that the Sionna package is installed before attempting to import it. If the package is not installed, the block will install it using pip before attempting to import it again. If the package cannot be installed, the program will exit."
"To import the necessary Sionna APIs, you can follow the code snippet below. However, make sure you have installed the Sionna package before running this code.\n\n```python\n# Sionna RT import\nimport os\nimport sionna\nfrom sionna.rt import load_scene, PlanarArray, Transmitter, Receiver, RadioMaterial, Camera, LambertianPattern, DirectivePattern, BackscatteringPattern\nfrom sionna.rt.scene import Scene\nfrom sionna.rt.utils import r_hat, to_norm_vec, compute_k, compute_k_mat, compute_xpr, xpr_to_xpol\nfrom sionna.constants import PI, SPEED_OF_LIGHT\nfrom sionna.utils import expand_to_rank\n```\n\nIf you are running the code in Jupyter notebook and want to print the version of the Sionna package, you can use the following command:\n\n```python\n!pip show sionna | grep Version\n```"
"Here is what I found about `Descrambler`:  \n  \n[ROTU.5] 3GPPTS38212Scrambling can be 3GPP 38212 scrambling, see Scrambler for additional info.  \n  \n[3GPP38212_SCRAMBLING] 3GPP 38.212 \u201cScrambling\u201d  \n  \nImplements channel scrambling as defined in 3GPP 38.212 [3GPP38212] for the channel type \u201cPUSCH\u201d and \u201cPDSCH\u201d.  \n  \n**Note:**\nIn 3GPP 38.212 [3GPP38212] it is defined that for standard \u201cPUSCH\u201d transmission the transmission is already scrambled (section 6.3.1). However, for the case of rank > 1 and mu != 0, the layer mapping is not uniquely defined and the scrambling can be combined with precoding as indicated in section 7.3 [3GPP38212]. We do not support this combined scrambling for \u201cPUSCH\u201d and assume \u201cPUSCH\u201d implies the non-precoded \u201cPUSCH\u201d in this class. For \u201cPDSCH\u201d, it is always assumed that there is a separate antenna port for each layer and thus the layer scrambling can be applied independently.\n\nIf channel_type is \"PUSCH\", it is expected that the binary flag for usePUSCHScrambling is set in the 3GPP TS 38.211 [3GPP38.211] carrier_config attribute.\n\nThe implementation is based on the following procedure as defined in 3GPP 38.212 [3GPP38212] for \u201cPUSCH\u201d:\n\n1. C_b = channel_config.func(scrambler, binary, **kwargs)  \n  \n2. Z = Zad(c_init, C_b, frame_num, is_cbrm, n_rnti, subframe_num, channel_type, n_scid, n_codeword=0, codeword_index=0, **kwargs)  \n  \n3.  \n   $X = \\bar{Z} \\otimes C_b$\n  \n   with $\\bar{Z}$ being a sequence made by repeating $Z$ without scrambling for n_coded_modulation_symbols codeword_index within a codeword.\n\n4.  \n   $Y = \\text{Mapper}(X)$\n  \n5.  \n   $Y\u2019 = \\text{DMRS}_\\text{mask} \\otimes Y$\n  \n6.  \n   $Y\u201d = Y\u2019 \\otimes \\begin{split}\\text{DMRS}_0\\text{DMRS}_1\\text{DMRS}_2\\text{DMRS}_3\\text{DMRS}_4\\text{DMRS}_5\\text{DMRS}_6\\text{DMRS}_7\\text{DMRS}_8\\text{DMRS}_9}\\\\\n   \\end{split}$\n  \n7.  \n   $\\hat{Y} = \\text{DMRS}_\\text{cpl} \\otimes Y\u201d$\n  \n8.  \n   $\\text{Modulator}(C_\\text{mod}, \\hat{Y})$\n  \nThe scrambler is considered as stateless, i.e., the initialization is not explicitly related to a specific initialization of the scrambler as it is the case for the PNSequence.\n\nFor PDSCH, the scrambler is following the more traditional scheme, where - in each subframe - the random seed is updated as\n   $c_\\text{init, n} = \\text{LFSR}(c_\\text{init}, 1),\\ n=0, \\dots, N_\\text{SF}-1$  \nwhere $N_\\text{SF}$ is the slot number within a subframe. Here,  \n   $C_b = \\text{ChannelDeprecodQ}(x, n_\\text{ID}, n_\\text{SF}, channel_type)$  \nis the complex-valued sequence of length N determined by $x \\in \\{0, 1\\}$ and the channel configuration, $c_\\text{init}$ is the rnti related part of the initialization, and LFSR denotes the recursive sequence of [length 31 defined in 5.2.1 of 38.211 [3GPP38.211], which is used to produce pseudo random binary sequences.\n\nFor the case of multiple codewords, the deprecoding sequence as in 7.3.1.2.2 of [3GPP38.211] is generated by using different $c_\\text{init}$ but the same $C_b$.  \n  \nThe following relation is used to get $X$ for both \u201cPUSCH\u201d and \u201cPDSCH\u201d  \n$X = \\text{Modulator}(C_\\text{mod}, \\bar{Z} \\otimes C_b).$  \n  \nFor the \u201cPDSCH\u201d channel, $X$ is mapped to the layers $Y$ as  \n$Y = \\Lambda^H X.$  \nThis is not done (and required) for \u201cPUSCH\u201d, as the modulation and layer mapping is assumed to be done as indicated above.\n\nIf channel_type is \"PUSCH\" the flag usePUSCHScrambling from the carrier_config is used (if set to True) to indicate that the scrambling sequence is provided/generated by the PUSCH transmitter. For \"PDSCH\", this flag is ignored as the scrambler is always provided by the PDSCH transmitter.  \n  \nFor the \u201cPDSCH\u201d channel, the input binary sequence is first descrambled (re-scrambled) and then channel interleaved by using the procedure above. This can be deactivated by setting deactive_pdsch_scrambling to True (in contrast to usePDSCHScrambling which utilizes the 3GPP specified scrambling sequences).  \n  \n**Example**\nThe following code shows how to setup and use the scrambler.\n```python\nDescrambler =  Scrambler ( channel_type = \"PUSCH\" , \n                          carrier = None , \n                          binary = True , \n                          init = 1 , \n                          enable_deepclipping = False )\nDescrambler . call ( input ) \nDescrambler . descramble ( input , \n                        seed = 1 , \n                        output_domain = \"freq\" )  \n```\n\n**Result**\nScrambler  \n  \nDescrambler  \n$X = \\text{Modulator}(C_\\text{mod}, \\bar{Z} \\otimes C_b).$  \n$Y = \\Lambda^H X.$  \n  \ncall(X)  \ndescramble(X, seed, output_domain)  \n$X = \\text{Modulator}(C_\\text{mod}, \\bar{Z} \\otimes C_b).$  \n$Y = \\Lambda^H X.$  \n  $Y = \\text{DMRS}_\\text{mask} \\otimes Y$\n  \n$X = \\bar{Z} \\otimes C_b$\n  \n$Y = \\text{DMRS}_\\text{mask} \\otimes Y$\n  \n$Y = \\text{DMRS}_\\text{mask} \\otimes Y$\n  \n$Y = \\text{DMRS}_\\text{mask} \\otimes Y$\n  \n $Y = \\text{DMRS}_\\text{mask} \\otimes Y$  \n  "
"To perform Polar decoding using an instance of `Polar5GDecoder` with log-likelihood ratios as inputs, you need to initialize the decoder with a specific input type parameter (`llr_type`). Here's a step-by-step demonstration based on the provided context.\n\nFirst, import the necessary classes from the `5g` package:\n\n```python\nfrom mlsft.nr import Polar5GEncoder, Polar5GDecoder, LDPC5GEncoder, LDPC5GDecoder\nfrom mlsft.nr.utils import GaussianPriorSource\nfrom mlsft.nr.utils import ebnodb2no\n```\n\nAssume we have LLRs (`llr_ch`) corresponding to the channel output, a `Polar5GEncoder` instance used with the encoder, and the indices of the information bit channels frozen for 5G uplink with zero-tail removal:\n\n```python\nllr_ch = [...]  # Placeholder for the channel LLRs\nencoder = Polar5GEncoder(k=128, n=512, frozen_pos=[])\n```\n\nWe create an instance of the `Polar5GDecoder` by specifying that the input is LLRs. As the frozen positions are currently empty, the decoder will return the same output sequence as the input LLRs (this will change after adding the list decoding algorithm).\n\nTo decode, use the `call` method of the decoder with the LLRs and the `frozen_pos` of the codeword:\n\n```python\ndecoder = Polar5GDecoder(llr_type=\"low\", n=512, frozen_pos=[], list_size=8)  # dec. with list size 8\nout = decoder(llr_ch, encoder.frozen_pos)\n```\n\nThis will produce hard-decided estimations of the information bit sequence. The size of `out` will be `encoder.n` and the elements of `out` will be numpy.int32 type, corresponding to the hard decided estimations of the codeword's information bits.\n\nKeep in mind that this example demonstrates the basic usage of the `Polar5GDecoder` with LLRs as inputs. Depending on the specific use case (e.g., requirements for list decoding), the initialization and the decoding process may vary."
"To load a scene from a file using the `load_scene()` function from the `sionna.rt` module of the Sionna package, you need to follow these steps:\n\n1. First, ensure the Sionna package is installed in your Python environment. If it's not installed, you can install it using pip:\n\n```python\npip install sionna\n```\n\n2. Import the necessary modules and functions:\n\n```python\nfrom sionna.rt import load_scene\n```\n\n3. Initialize a `Scene` object by loading the scene from a file using the `load_scene()` function. The function takes the file path of the scene as an argument. If the scene is loaded successfully, it can then be used for various ray tracing operations.\n\nFor example, if you have a scene file named 'scene.sionna' located in the current working directory, you can load it as follows:\n\n```python\nscene = load_scene('scene.sionna')\n```\n\nPlease replace 'scene.sionna' with the actual file name and path of your scene file."
