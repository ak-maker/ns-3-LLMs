"When creating a `Polar5GEncoder` instance in Sionna to perform 5G Polar encoding, the parameters `k` and `n` refer to the number of information bits and the codeword length, respectively. These two parameters define the input data dimensions for the encoding operation.\n\nHere is how these parameters are defined in the given context:\n\n```python\nfrom sionna.fec.polar.encoding import Polar5GEncoder\nencoder = Polar5GEncoder(k = ..., n = ...)\n```\n\nReplace the ellipses (`...`) with the required values:\n\n- `k`: This should be replaced with the number of information bits you want to encode. It is an integer value that depends on your specific encoding needs. The 5G standards allow flexibility of `k` depending on the specified channel bandwidths (from 1 to 5), where `k` can be chosen to be between 100 and 8424, inclusive.\n\n- `n`: This should be replaced with the codeword length, which is the desired length of the codeword after encoding. Like `k`, it is also a flexible parameter and can be any value between 100 and 256, corresponding to the number of input bits (k) plus the number of parity bits.\n\nSo, to create a `Polar5GEncoder` instance in Sionna, you need to define `k` and `n` based on the bandwidth configuration you are simulating according to the 5G standard:\n\n```python\nfrom sionna.fec.polar.encoding import Polar5GEncoder\n# Define k and n based on the bandwidth configuration\nk = ...    # Define the number of information bits\nn = ...    # Define the codeword length\n\n# Create the encoder instance\nencoder = Polar5GEncoder(k=k, n=n)\n```"
"To import DeepMIMO and generate a dataset, follow these steps:\n\n1. Import the `deep_mimo` module. If it's not already installed, you can install it using pip:\n\n```python\ntry:\n    import deep_mimo\nexcept ImportError as e:\n    # Install DeepMIMO if package is not already installed\n    import os\n    os.system(\"pip install deep-mimo\")\n    import deep_mimo\n```\n\n2. Initialize the DeepMIMO dataset that you want to generate. You need to specify the scenario, the user array, the base station array, and the number of paths. For example, if you want to generate the O1_scenario dataset, with 11 user antennas and a 5G NR base station, with 32 transmitter (TX) paths, you can do it like this:\n\n```python\n# Initialize the DeepMIMO dataset\ndm = deep_mimo.DeepMIMO(\"O1_scenario\", num_user_ant=11, num_tx_ant=32)\n```\n\n3. Generate the dataset. The dataset will contain the channel impulse responses (CIRs) for the specified scenario. You can control the batch size and the `ebno_db` parameter for the SNR (signal-to-noise ratio) of the dataset:\n\n```python\n# Number of examples to generate\ndataset_size = 1000\n# Generate the dataset\nchannels = dm(dataset_size, batch_size=dataset_size, ebno_db=7)\n```\n\nIn this example, the `dm` object is the DeepMIMO dataset, `dataset_size` is the number of CIRs you want to generate, `batch_size` is the number of examples in the dataset, and `ebno_db` is the SNR value. The `__call__` method of the `dm` object is used to generate the dataset.\n\nThe generated dataset (`channels` in this example) will be an array of complex-valued CIRs for each link between a transmitter and a receiver. The shape of the dataset will be `[dataset_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps]`, where `num_rx` is the number of receivers, `num_rx_ant` is the number of antennas per receiver, `num_tx` is the number of transmitters, `num_tx_ant` is the number of antennas per transmitter, `num_paths` is the number of paths per link, `num_time_steps` is the number of time steps."
"To plot the weights after training and compare the new Bit Error Rate (BER) performance, you need to simulate the model after training and then extract the weights from the model. Here are the steps to follow:\n\n1. **Train the model**: Use an appropriate training algorithm to train the model. In the provided context, the model was trained using the `train_coder_bp()` function.\n\n2. **Simulation**: Simulate the model for a range of SNR values. This can be done using the `simulate()` function with the appropriate parameters. The results of the simulation will give you the BER performance after training.\n\n3. **Extracting weights**: After training, you can extract the weights of the model to visualize them. The weights of the model are equivalent to the LLR values after the trained VN, which can be obtained using the `all_vn_weights()` function. These weights can be plotted to visualize their distribution.\n\nHere is the code snippet from the provided context that shows how to do this:\n\n```python\n# Simulate the model after training\nber_plot.simulate(model, num_bit_eval=10000, ecm=True,\n                ebno_dbs=np.arange(2, 8, 1).astype(float), # from 2 to 7 dB in steps of 1 (floats are required by 7.0)\n                show_fig=False,\n                forward_keyboard_interrupt=True,\n                batch_size=batch_size)\n\n# plot the weights after training\nfig=plt.figure();\nplt.plot(model.decoder.all_vn_weights().flatten());\nplt.title(\"VN Weights after Training\");\nplt.grid(True);\nplt.xlabel(\"Weight Index\");\nplt.ylabel(\"Weight Value\");\n```\n\nThis will plot the weights after training. The performance of the model can be evaluated by examining the plot. The spread of the weights indicates the part of the hypergraph that was activated during the training. The lower the weight values, the \"less\" the channel reliability information is propagated through the graph, which correlates with a lower expected decoding performance."
"To use the `generate_polar_transform_mat` function to create a Polar transformation matrix for a given Kronecker power, follow these steps:\n\n1. Import the function from the relevant module.\n   \n    ```python\n    from sionna.fec.polar.utils import generate_polar_transform_mat\n    ```\n\n2. Define the Kronecker power you wish to create the transformation matrix for, by setting the `n_lift` parameter. `n_lift` refers to the number of times the kernel is lifted.\n   \n    ```python\n    n_lift = 3  # for example, lift the kernel three times\n    ```\n\n3. Call the function `generate_polar_transform_mat` with `n_lift` as the argument to receive the Polar transformation matrix.\n   \n    ```python\n    polar_transform_mat = generate_polar_transform_mat(n_lift)\n    ```\n   \n    In this example, `polar_transform_mat` will be the Polar transformation matrix for `n_lift` Kronecker power. The matrix will be an array of `0`s and `1`s of shape `[2^(n_lift), 2^(n_lift)]`.\n\nMake sure to replace `3` in `n_lift = 3` with the actual integer value for which you want to create the transformation matrix."
"The definition of LayerDemapper is:\n[sionna.nr.LayerDemapper(layer_mapper, num_bits_per_symbol=1, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/nr/layer_mapping.html#LayerDemapper)"
"To create a PUSCHReceiver using the PUSCHTransmitter and simulate transmissions over the AWGN channel, follow these steps:\n\n1. First, you need to create a PUSCH configuration with default settings:\n```python\npusch_config = PUSCHConfig()\n```\n\n2. Instantiate a PUSCHTransmitter from the PUSCHConfig:\n```python\npusch_transmitter = PUSCHTransmitter(pusch_config)\n```\n\n3. Create a PUSCHReceiver using the PUSCHTransmitter:\n```python\npusch_receiver = PUSCHReceiver(pusch_transmitter)\n```\n\n4. Then, you need to set up the AWGN channel. For this, you can use the AWGN class. You need to set the noise power `no`:\n```python\nchannel = AWGN()\nno = 0.1 # Noise variance\n```\n\n5. Now you can simulate transmissions over the AWGN channel. Let's say you want to simulate 16 transmissions. You can do this by generating a batch of transmit signals and information bits, then passing them through the channel, and finally recovering the information bits:\n```python\nbatch_size = 16\nx, b = pusch_transmitter(batch_size)  # Generate transmit signal and info bits\ny = channel([x, no])  # Simulate channel output\nb_hat = pusch_receiver([x, no])  # Recover the info bits\n```\n\n6. After the transmissions, you can compute the Bit Error Rate (BER) by comparing the transmitted and the received information bits:\n```python\nprint(\"BER:\", compute_ber(b, b_hat).numpy())\n```\n\nThis is a basic example of how to create a PUSCHReceiver using the PUSCHTransmitter and simulate transmissions over the AWGN channel. Depending on your specific requirements, you might need to adjust the configuration and the parameters."
"The definition of SymbolInds2Bits is: class sionna.mapping.SymbolInds2Bits(num_bits_per_symbol, dtype=tf.float32, **kwargs)  \n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#SymbolInds2Bits)  \n\nsource code:\n```python\nclass SymbolInds2Bits(Layer):\n    \"\"\"    \n    SymbolInds2Bits(num_bits_per_symbol, dtype=tf.float32, **kwargs)\n  \n    Transforms symbol indices to their binary representations.\n  \n    Parameters\n    ----------\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol, e.g., 4 for\n        QAM16.    \n    \n    Output\n    ------\n    : [n], n>=num_bits_per_symbol tf.float\n        Binary representation of the symbol indices.\n\n    \"\"\"\n  \n    def __init__(self, num_bits_per_symbol, dtype=tf.float32, **kwargs): \n        super().__init__(dtype=dtype, **kwargs)\n        self._num_bits_per_symbol = num_bits_per_symbol\n\n    def build(self, input_shape):\n        \n        binary_table = sequence([]) # Store the binary representation here\n\n        # Create a binary representation for each index\n        for i in range(2**self._num_bits_per_symbol):\n            bin_str = format(i, f\"0{self._num_bits_per_symbol}b\")\n            bin_ = np.array([int(x) for x in bin_str])\n            bin_.view(dtype=tf.float32)\n            binary_table.write(bin_str)\n        \n        self._binary_table = binary_table\n\n    def call(self, inputs):\n        # Use modulo to ensure that 0<= inputs < 2^num_bits_per_symbol. \n        # This is important in case that the number of symbols is \n        # larger than the number of symbols that are actually mapped.\n        # E.g., num_bits_per_symbol=4 =>  inputs \\in [0,...,15]  \n        z = tf.math.floormod(inputs, 2**self._num_bits_per_symbol) \n        bits =  self._binary_table[z]\n        return tf.dtypes.cast(bits, self.dtype)\n```\n  "
"Here is the detailed information of TimeChannel:   \n  \n[sionna.channel.TimeChannel( bandwidth, max_delay_spread, l_min=-6, l_max=None, normalize_channel=False, add_white_noise=True, dtype=tf.complex64, **kwargs )](https://nvlabs.github.io/sionna/_modules/sionna/channel/time_channel.html#TimeChannel)  \n\nApply channel filter $h_{\\text{time}}(b)$ in the time domain for $L_{\\text{max}} =L_{\\text{min}}$ it is the sum of sinc filters applied to each of the $M \\leq N$ delays corresponding to the $M$ taps of the channel filter.  For $L_{\\text{max}} >L_{\\text{min}}$ it is the sum of sinc filters applied to each symbol from $b$ to $b+L_{\\text{max}}$ symbols.\n\nThe sinc filter is defined as: \n$$\nh_{\\text{time}}(b) = \\sum_{m=0}^{M-1} a_m(b) \\text{sinc}\\left( \\ell - W\\tau_m \\right)\n$$\nwhere $\\ell$ is the time step, $W$ the bandwidth, and $\\tau_m$ the mth delay seen channel. The $a_m(b)$ are the amplitudes of the channel taps at the begin of the $mth$ symbol (or sample) of the mth path, which we here approximate by the value of the channel tap at the middle of the $mth$ symbol (or sample).  \n  \nFor every time step $b$, the channel output is computed as: \n$$\n\\begin{split}\ny_{b} &= \\sum_{\\ell =L_{\\text{min}}}^{L_{\\text{max}}} \\sum_{m=0}^{M-1}  \\\\ \n      & \\qquad a_m(b-\\ell) \\text{sinc}\\left( \\ell - W\\tau_m \\right) x_{m, b-\\ell}\n\\end{split}\n$$\nwhere $x_{m, k}$ the the kth symbol (or sample) in the mth path (or tap). If $L_{\\text{max}} -L_{\\text{min}} + 1 = M = N$, this equation is equivalent to a..  \n\n\nFor every time step $b$, the channel output is computed as: \n$$\n\\begin{split}\ny_{b, l} &= \\sum_{m=0}^{M-1}  \\\\ \n      & \\qquad a_m\\left(b-(L_{\\text{max}}-L_{\\text{min}})/2 \\right) \\text{sinc}\\left( l - W\\tau_m + (L_{\\text{max}}-L_{\\text{min}})/2 \\right)\n\\end{split}\n$$\nwhere $l$ is $l \\in [\\![ L_{\\text{min}}, L_{\\text{max}} ]\\!]$ the discrete-time channel filter is $h_{\\text{time}}(b)$. For the special case that $N=1$ and $L_{\\text{min}} =L_{\\text{max}}$, the channel filter in continuous time is a sum of M sinc filters, each sinc filter is applied to one of M delays, and the above equation is not needed.  \n  \n**Parameters**\n\n- `bandwidth` (float): Bandwidth [Hz]\n- `max_delay_spread` (float): Maximum delay spread [s]\n- `l_min` (int): Smallest time-lag for the discrete-time channel filter ($L_{\\text{min}}$) [symbol], defaults to -6 symbols.\n- `l_max` (int): Largest time-lag for the discrete-time channel filter ($L_{\\text{max}}$) [symbol], defaults to None. If None, then defaults to the value of l_min plus the number of symbols per filter plus the oversampling factor. \n- `normalize_channel` (bool): If set to True, the channel is normalized over the block size to ensure unit average energy per time step. Defaults to False.\n- `add_white_noise` (bool): If set to True, white Gaussian noise with variance `noise_var` is added to the output. Defaults to True.\n- `dtype` (tf.DType): Complex datatype to use for internal processing and output. Defaults to tf.complex64.\n\n**Input**\n\n- `inputs` ([..., num_tx, num_tx_ant, num_samps], tf.complex): Tensor containing the symbols or samples.\n\n**Output**\n\n- `output` ([..., num_rx, num_rx_ant, num_samps + l_max - l_min], tf.complex): Channel output. The output sequence is delayed by `l_min` time steps compared to the input sequence, to account for the smallest time-lag of the discrete-time channel filter $h_{\\text{time}}(b)$. If `l_min` has been set to -6 (the default value), this means that the output sequence starts 6 symbols after the input sequence, to ensure that all symbols have been passed through the channel filter. Note that to compute the output at time step $b$ and coefficient index $l$ with respect to a time step $b'$ and coefficient index $l'$ of the input, one needs to add `l_min` to $b$ and $l$ to obtain $b\"$ and $l$. $l$ is then the time-lag (in symbols) that the coefficient $l$ of the channel filter has been set to for the computation of the output coefficient $l'$. $b$ and $b\"$ are the the time steps of the input and output sequences between which the channel impulse response is computed. Time-lags of the channel filter correspond to a delay of the symbols passed through the filter. This scheme is used to implement the channel filter (on the baseband symbols) with a single-tap channel at time $b\"$ for the highest coefficient index $l$ of the channel filter. A similar approach is used in the channel_equalization module to implement the channel equalization. Note that a single-tap channel is used to filter the symbols, because the waveform to symbol mapping is assumed to produce the \"sinc\" shaped symbols, which ensures that the channel output symbols are (ideally) uncorrelated. This also means that the power-delay profile, i.e., the time-averaged power of the path coefficients (square of the magnitude of the path gains) as a function of the path delays, is flat for the (ideally) sinc-shaped constellation. This is also the reason why the sinc shaping is used, as it was also explained in the section on channel modeling.\n\n**Property**\n\n- `sampling_frequency`: Sampling frequency in Hz.Computed from the product of the bandwidth and the oversampling factor.\n\n**Method: `apply_channel(response, inputs)`**\n\nApply the channel response function to channel inputs.\n\nThis function computes the output of a frequency domain channel for a given set of channel inputs, i.e., baseband symbols. It is assumed that for each time step $b$ the channel output can be computed as follows:\n  $y_b = \\sum_{u} \\sum_{\\ell = L_{\\text{min}}}^{L_{\\text{max}}}  \\sum_{k}  \\bar{h}_{u, k} \\tilde{h}_{u, k, b, \\ell} x_{k, b} + w_b$\nwhere $\\tilde{h}_{u, k, b, \\ell}$ are the channel taps computed with sinc normalization (Equation 1), and $w_b$ is the optionally add white noise.\n\n**Input**\n\n- `response` ([num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex): Channel responses.\n- `inputs` ([..., num_tx, num_tx_ant, num_time_steps], tf.complex): Channel inputs.\n\n**Output**\n\n- `output` ([..., num_rx, num_rx_ant, num_time_steps + l_max - l_min], tf.complex): Channel outputs. The output sequence is delayed by `l_min` time steps compared to the input sequence, to account for the smallest time-lag of the discrete-time channel filter $h_{\\text{time}}(b)$. If `l_min` has been set to -6 (the default value), this means that the output sequence starts 6 symbols after the input sequence, to ensure that all symbols have been passed through the channel filter. Note that to compute the output at time step \ud835\udc4f and coefficient index \ud835\udc59 with respect to a time step \ud835\udc4f\u2032 and coefficient index \ud835\udc59\u2032 of the input, one needs to add `l_min` to \ud835\udc4f and \ud835\udc59` to obtain \ud835\udc4f\u2032 and \ud835\udc59. \ud835\udc59` is the the time-lag (in symbols) that the coefficient \ud835\udc59 of the channel filter has been set to for the computation of the output \ud835\udc59\u2032. \ud835\udc4f and \ud835\udc4f\u2032 are the the time steps of the input and output sequences between which the channel impulse response is computed. Time-lags of the channel filter correspond to a delay of the symbols passed through the filter. This is used to implement the channel filter (on the baseband symbols) with a single-tap channel at time \ud835\udc4f\u2032 for the highest coefficient \ud835\udc59 of the channel filter. A similar approach is used in the channel_equalization module to implement the channel equalization. Note that a single-tap channel is used to filter the symbols, because the waveform to symbol mapping is assumed to produce the \"sinc\" shaped symbols, which ensures that the channel output symbols are (ideally) uncorrelated. This also means that the power-delay profile, i.e., the time-averaged power of the path coefficients (square of the magnitude of the path gains) as a function of the path delays, is flat for the (ideally) sinc-shaped constellation. This is also the reason why the sinc shaping is used, as it was also explained in the section on channel modeling."
"The 'Antenna' class belongs to the 'sionna.rt' module and is used to represent an antenna in a wireless simulation. It can be either single- or dual-polarized and has for each polarization direction a possibly different antenna pattern. An instance of the 'Antenna' class can be created by either using a predefined antenna model (like \"dipole\", \"hw_dipole\", \"cross_polarized_dipole\") or by specifying a  zenith and azimuth pattern or a zenith and azimuth pattern together.\n\nHere are the key aspects of the 'Antenna' class:\n\n- **Attributes**: \n  - `zenith_pattern`: Zenith pattern of the antenna\n  - `azimuth_pattern`: Azimuth pattern of the antenna\n  - `zenith_pattern_cross`: Zenith cross-polarization pattern\n  - `azimuth_pattern_cross`: Azimuth cross-polarization pattern\n  -  These attributes define the field-pattern of the antenna in the spherical unit vector coordinate as its output  would be on the surface of a unit sphere.\n-  For each of the above field, there is a corresponding field in complex-values. These fields allow modeling of the antenna's radiation and reception characteristics. \n-  **Antenna Arrays**: The Antenna class can be used to create models of individual antennas, and in addition to that, the real-world antennas are typically mounted on an array. The simulation allows specification of this array, and the arrays are defined in the  x7x (length x width)  3D AntennaArray  which is then assigned to the tx_array or rx_array \n\n- **Properties**:\n  - `polarization`: The polarization of the antenna, either single or dual\n  - `zenith_pattern`: Zenith pattern of the antenna\n  - `azimuth_pattern`: Azimuth pattern of the antenna\n  - `zenith_pattern_cross`: Zenith cross-polarization pattern\n  - `azimuth_pattern_cross`: Azimuth cross-polarization pattern\n\n- **Methods**:\n\n  -  `show()`: This function is used to visualize the antenna's pattern \n   - input : array describing the points on a sphere to be evaluated \n   - output: The values of the field at these points which give the radiation or reception pattern of the antenna.\n\nIn summary, an 'Antenna' class can be used to create a single- or dual-polarized antenna with one or more field patterns which affect how the antenna radiates or receives. This class is a part of the 'sionna.rt' module which is used for wireless ray tracing."
"source code:  \n```python\nclass TurboTermination:\n    # pylint: disable=line-too-long\n    r\"\"\"Termination object, handles the transformation of termination bits from\n        the convolutional encoders to a Turbo codeword. Similarly, it handles the\n        transformation of channel symbols corresponding to the termination of a\n        Turbo codeword to the underlying convolutional codewords.\n\n    Terminates bits that are left in the convolutional encoders to\n    form a Turbo codeword. Also, takes Turbo codeword splits from the\n    channel demodulator and feeds them back to the underlying convolutional\n    encoders for further decoding.\n\n    Properties\n    -----------\n    :attr:`num_term_bits_turbo` : int\n        Total number of termination bits for the Turbo Code. One symbol equals\n        :attr:`num_bitstreams` bits.\n\n    Methods\n    -----------\n    :meth:`get_num_term_syms`()\n        Compute the number of termination symbols for the Turbo Code based\n        on the underlying convolutional code parameters, primarily the memory\n        :math:`\\mu`. Note that it is assumed that one Turbo symbol implies\n        :attr:`num_bitstreams` bits.\n\n    :meth:`term_bits_turbo2conv`(*term_bits*)[source]\n        Split the termination symbols from a Turbo codeword to the termination\n        symbols corresponding to the two convolutional encoders, respectively.\n\n        Lets assume :math:`\\mu=4` and the underlying convolutional encoders\n        are systematic and rate-1/2, for demonstration purposes.\n\n        Let ``term_bits`` tensor, corresponding to the termination symbols of\n        the Turbo codeword be as following:\n\n        .. math::\n\n            y = [x_1(K), z_1(K), x_1(K+1), z_1(K+1), x_1(K+2), z_1(K+2)\n            x_1(K+3), z_1(K+3), x_2(K), z_2(K), x_2(K+1), z_2(K+1),\n            x_2(K+2), z_2(K+2), x_2(K+3), z_2(K+3), 0, 0]\n\n        The two termination tensors corresponding to the convolutional encoders\n        are:\n\n        :math:`y[0,..., 2\\mu]`, :math:`y[2\\mu,..., 4\\mu]`. The output from this\n        method is a tuple of two tensors, ``y1`` and ``y2``, each of\n        size :math:`2\\mu` and shape :math:`[\\mu,2]`.\n\n        :math:`[[x_1(K), z_1(K)]`,\n\n        :math:`[x_1(K+1), z_1(K+1)]`,\n\n        :math:`[x_1(K+2, z_1(K+2), x_1(K+3), z_1(K+3)]`,\n\n        :math:`[x_2(K), z_2(K)],`\n\n        :math:`[x_2(K+1), z_2(K+1)]`,\n\n        :math:`[x_2(K+2), z_2(K+2)]`,\n\n        :math:`[x_2(K+3), z_2(K+3)]`,\n\n        :math:`0, 0]`\n\n        and\n\n        :math:`[z_2(K), x_2(K+1), z_2(K+1)]`,\n\n        :math:`[x_2(K+2), z_2(K+2), x_2(K+3), z_2(K+3)]`,\n\n        :math:`0, 0]`\n\n        The two methods :class:`~sionna.fec.turbo.utils.TurboTermination.term_bits_turbo2conv`\n        and :class:`~sionna.fec.turbo.utils.TurboTermination.termbits_conv2turbo`\n        are exact inverses, i.e., their compositions return the same tensors\n        (up to zero-padding).\n    \"\"\"\n    def __init__(self, constraint_length, conv_n=2, num_conv_encs=2, num_bit_streams=3):\n        super().__init__()\n        self._mu = constraint_length - 1\n        self._conv_n = conv_n\n        self._num_conv_encs = num_conv_encs\n        self._num_bit_streams = num_bit_streams\n        self._conv_k = self._mu + 1\n        self._k = self._conv_k * self._num_conv_encs\n        self._conv_rate = 1 / self._conv_k\n        self._gen_poly = None\n        self._gen_poly_conv = None\n        self._gen_poly_terminate = None\n        self._gen_poly_conv_terminate = None\n        self._trellis = None\n        self._trellis_conv = polynomial_selector.find_first_order_polynomial(self._mu)\n        self._output_turbo_conv = None\n        self._output_turbo_conv_terminate = None\n        self._sysind_turbo = None\n        self._termind_turbo = None\n        self._sysind_conv = None\n        self._termind_conv = None\n        self._emu = None\n        self.get_num_term_syms()\n\n    def __call__(self, *inputs):\n        # this function is not used, __call__ is implemented for documentation\n        pass\n\n    def get_num_term_syms(self):\n        r\"\"\"Compute the number of termination symbols for the Turbo\n        code based on the underlying convolutional code parameters,\n        primarily the memory :math:`\\mu`.\n\n        Note\n        ----\n        It is assumed that one Turbo symbol implies :math:`num\\_bitstreams`\n        bits.\n        \"\"\"\n        cc = ConvolutionalEncoder(self._gen_poly,\n                                 self._gen_poly,\n                                 k=self._conv_k,\n                                 n=self._conv_n)\n        turbo_coder = TurboEncoder([cc])\n        turbo_coder(Il = self._sysind_turbo,\n                    # note: here we provide the indices w.r.t. the\n                    # interleaver, as done in TurboEncoder.__call__()\n                    sys_ind=Selector(self._trellis, self._sysind_turbo),\n                    terminate=True)\n        # the output generator polynomial may be different to the underlying\n        # convolutional code, we need to compute the termination\n        # code for each possible output of the Turbo code.\n        # For simplicity, we denote the two underlying encoders by\n        # C1 and C2 and denote the termination encoders by TC1 and TC2.\n        # A TurboEncoder may produce the Turbo symbols as\n        # [C1]* -> [TC1]*  ____\\____\n        #            |       |\n        #          [C2]* -> [TC2]*\n        # The true Turbo codeword support is obtained by interleaving and\n        # puncturing the true codeword support obtained by the TurboEncoder.\n        # However, from the view of the termination encoders, for example\n        # TC1, the termination symbols of C2 are not available.\n        # Therefore, we need to simulate encodings for the termination\n        # symbols of C2 where the corresponding input x of C2 is set to\n        # zero. For the true Turbo codeword support, this is not required\n        # as the two convolutional encoders are properly interleaved and\n        # the termination symbols of C1 are run through the termination\n        # interleaver to form the termination symbols of the Turbo code.\n        # For example, the output Turbo symbols * of TC1 are obtained by\n        # [C1]* -> [TC1]*   ____\\______\n        #              |            |\n        # The output symbols * of the TurboEncoder are obtained from the\n        # two termination encoders. For example, in the 4x repetition case\n        # we have\n        # [TC1]* -> [TC1]*  __________\\__________\n        #              |            |\n        # [TC2]* -> [TC2]*\n        #\n        # C2 runs through the precoded output symbols of the TurboEncoder.\n        # For example output symbol * corresponding to encoder input 0 is\n        #       * = [x0, 0, x0, 0, x0, 0].\n        # Only the systematic part from C2 is taken as the termination\n        # symbols from C1 are not available.\n        # For example, for the 4x repetition we have\n        #  [y2, 0, y2, 0, y2, 0, y2, 0]\n        #   = 4*[x0, 0, x0, 0].\n        #\n        # In the code below, we simulate encodings for the termination symbols\n        # of C2 by setting x0 (i.e., the input to C2 at rate 1/2) to zero.\n        # For example for rate 1/2 we have\n        # gen_poly is C2 polynomial\n        #  ---- gen_poly is rate 1/2 polynomial\n        #   e.g., [1, 1, 1] denotes the polynomal :math:`1 + D^1 + D^2`\n        #   for rate 1/2.\n        # Then the termination polynomial is\n        #  ---- gen_poly_terminate is the corresponding termination polynomial\n        # [1, 0, 1]  e.g., denotes the polynomial :math:`1 + D^2`\n        #   for the example above.\n        # Also the true output polynomial of the Turbo code is [1, 1, 1, 1, 1, 1]\n        # we need to compute for each possible output of the Turbo code\n        # the termination bits. In the example above, we denote\n        # the output bit stream of the Turbo code by U*\n        #        * = [x0, y0, x1, y1, x2, y2].\n        # Then the corresponding termination bits are\n        # term_bits_turbo = gen_poly_terminate(*u)  # TerminationEncoder object\n        # term_bits_turbo2conv = r_['0,2', term_bits_turbo, tf.zeros([2*num_bitstreams])]\n\n        zero = tf.zeros(self._gen_poly_terminate.shape, dtype=tf.int32) # e.g., [2*rate, 0]\n        ee = tf.expand_dims(zero, axis=0)\n        gen_poly_terminate1 = tf.concat([self._gen_poly_terminate, ee], axis=0)\n        term_bits_turbo2conv1 = tf.squeeze(gen_poly_terminate1(*zero),axis=0)\n        gen_poly_terminate2 = r_['0,2', self._gen_poly_terminate, zero]\n        term_bits_turbo2conv2 = tf.squeeze(gen_poly_terminate2(*zero),axis=0)\n        num_term_syms_turbo = 2*self._emu* self._num_bit_streams\n        self._num_term_syms_turbo = num_term_syms_turbo\n        self._term_bits_turbo2conv = [term_bits_turbo2conv1, term_bits_turbo2conv2]\n        return num_term_syms_turbo\n\n    def termbits_conv2turbo(self, term_bits1, term_bits2):\n        # pylint: disable=unwanted-keyword-arg\n        r\"\"\"This method merges ``term_bits1`` and ``term_bits2``, termination\n        bit streams from the two convolutional encoders, to a bit stream\n        corresponding to the Turbo codeword.\n\n        Let ``term_bits1`` and ``term_bits2`` be:\n\n        :math:`[x_1(K), z_1(K), x_1(K+1), z_1(K+1),..., x_1(K+\\mu-1),z_1(K+\\mu-1)]`\n\n        :math:`[x_2(K), z_2(K), x_2(K+1), z_2(K+1),..., x_2(K+\\mu-1), z_2(K+\\mu-1)]`\n\n        where :math:`x_i, z_i` are the systematic and parity bit streams\n        respectively for a rate-1/2 convolutional encoder i, for i = 1, 2.\n\n        In the example output below, we  simulate encodings for the\n        termination symbols of ``encoder`` by setting ``x0`` (i.e., the input\n        to ``encoder`` at rate 1/2) to zero.\n\n        For example for rate 1/2 we have\n\n        ``gen_poly`` is ``encoder`` polynomial\n\n        ---- ``gen_poly`` is rate 1/2 polynomial\n\n        e.g., :math:`[1, 1, 1]` denotes the polynomial ....:.\n\n        Then the termination polynomial is\n\n        ---- ``gen_poly_terminate`` is the corresponding termination polynomial\n\n        :math:`[1, 0, 1]` e.g., denotes the polynomial ....:.\n\n        Also the true output polynomial of the Turbo code is\n\n        :math:`[1, 1, 1, 1, 1, 1]`\n\n        We need to compute for each possible output of the Turbo code\n        the termination bits. In the example below, we denote\n        the output bit stream of the Turbo code by U*\n\n        :math:`* = [x0, y0, x1, y1, x2, y2]`\n\n        Then the corresponding termination bits are\n\n        :math:`term\\_bits\\_turbo = gen\\_poly\\_terminate(*U*)`  # TerminationEncoder object\n\n        :math:`term\\_bits\\_turbo2conv = r_['0,2', term\\_bits\\_turbo, tf.zeros([2*num\\_bitstreams])`\n\n        The output from this method is a `tf.int32` vector of termination bits of the Turbo codeword.\n\n        :math:`[x_1(K), z_1(K), x_1(K+1), z_1(K+1), x_1(K+2, z_1(K+2), x_1(K+3),`\n\n        :math:`z_1(K+3), x_2(K),z_2(K), x_2(K+1), z_2(K+1), x_2(K+2), z_2(K+2),`\n\n        :math:`x_2(K+3), z_2(K+3), 0, 0]`\n\n        \"\"\"\n        if self._gen_poly is None:\n            raise ValueError(\"Please set gen_poly\")\n        if self._gen_poly_terminate is None:\n            raise ValueError(\"Please set gen_poly_terminate\")\n        if self._output_turbo_conv is None:\n            raise ValueError(\"Please set output_turbo_conv\")\n        if self._sysind_turbo is None:\n            raise ValueError(\"Please set sysind_turbo\")\n        if self._termind_turbo is None:\n            raise ValueError(\"Please set termind_turbo\")\n        if self._output_turbo_conv_terminate is None:\n            raise ValueError(\"Please set output_turbo_conv_terminate\")\n        if self._gen_poly_conv is None:\n            raise ValueError(\"Please set gen_poly_conv\")\n        if self._gen_poly_conv_terminate is None:\n            raise ValueError(\"Please set gen_poly_conv_terminate\")\n        if self._sysind_conv is None:\n            raise ValueError(\"Please set sysind_conv\")\n        if self._termind_conv is None:\n            raise ValueError(\"Please set termind_conv\")\n\n        zero = tf.zeros(self._gen_poly_terminate.shape, dtype = tf.int32)\n        ee = tf.expand_dims(zero, axis=0)\n        gen_poly_terminate1 = tf.concat([self._gen_poly_terminate, ee], axis =0)\n        term_bits_turbo2conv1 = tf.squeeze(gen_poly_terminate1(*zero),axis=0)\n        gen_poly_terminate2 = r_['0,2', self._gen_poly_terminate, zero]\n        term_bits_turbo2conv2 = tf.squeeze(gen_poly_terminate2(*zero),axis=0)\n\n        num_term_syms_turbo = 2* self._emu* self._num_bit_streams\n        term_bits_turbo = tf.concat([term_bits_turbo2conv1, term_bits_turbo2conv2, zero, zero],\n                                        axis=0)\n        term_bits_turbo = term_bits_turbo[:num_term_syms_turbo]\n\n        output_ = tf.split(term_bits_turbo,   # pylint: disable=unused-variable\n                          self._output_turbo_conv.output_enc_punct.ind, axis=0)\n        output_ = tf.stack(output_[:-1], axis=0)\n        output_ = tf.squeeze(output_)\n\n        input_ = tf.concat([term_bits1, term_bits2], axis=-1)\n        input_ = tf.split(input_,\n                         self._gen_poly_conv.ind, axis=-1)\n        input_ = tf.map_fn(\n                    lambda x: x*2-1, input_, dtype=tf.int32)\n        input_ = tf.stack(input_, axis=0)\n\n        input_enc_ = tf.squeeze(self._gen_poly_conv(*input_))\n        input_enc_punct_ = tf.squeeze(self._gen_poly_conv_terminate(*input_enc_))\n        # pylint: disable=assignment-from-no-return\n        output_enc_ = self._output_turbo_conv(input_enc_)\n        output_enc_punct_ = self._output_turbo_conv_terminate(input_enc_punct_)\n        #output_enc_punct_ = tf.squeeze(output_enc_punct_)\n        output_enc_bits_ = output_enc_.numpy() # output enc in bits\n\n        # merge enc1 and enc2 to the Turbo codeword.\n        # Also terminate info from termination encoders is set to zero\n        # as it is not available for the true Turbo codeword.\n        output_bits = tf.concat([output_enc_bits_,\n                                self._output_turbo_conv_terminate.all_zero()],\n                                axis=0)\n        output_bits = tf.gather(output_bits, self._sysind_turbo, axis=0,\n                                batch_dims=0)\n        output_bits = tf.where(tf.math.is_nan(output_bits),\n                                tf.zeros_like(output_bits), output_bits)\n        # add termination symbols to systematic part\n\n        term_syms = tf.reshape(self.termbits_turbo2conv(term_bits2),\n                                [1, -1])\n        term_syms = tf.repeat(term_syms, self._num_bit_streams, axis=1)\n        output_bits = tf.concat([output_bits, term_syms], axis=0)\n\n        # terminate to conv 1 and 2\n        output_bits_1 = tf.gather(output_bits, self._output_turbo_conv.term_ind[0], axis=0)\n        output_bits_2 = tf.gather(output_bits, self"
"To wrap everything in a Keras model for convenient Bit Error Rate (BER) simulations and comparison of model parameters, you can follow these steps:\n\n1. Define a BER simulation function: This function should create the necessary components for the end-to-end simulation of BER. In the function, you can initialize the spatial correlation model, create a dataset of binary sources, encode the data, map it to symbols, transmit it over a channel, demap it to LLRs, and finally decode it.\n\n2. Create a Keras model: You can define a new class that inherits from `tf.keras.Model`. In the `__init__()` method, you can initialize the various components used in the simulation. In the `call()` method, you can define the forward pass of the model, which simulates the transmission of data and the subsequent decoding.\n\n3. Compare model parameters: Once you have defined the Keras model, you can create multiple instances of this model with different parameters. You can then run the BER simulation for each instance and compare the results.\n\nHere is a simplified example of how you might define the BER simulation function and the Keras model:\n\n```python\ndef create_ber_simulation(spatial_corr=None):\n    # Define spatial correlation if provided\n    correlation = None\n    if spatial_corr is not None:\n        correlation = KroneckerModel(*spatial_corr)\n\n    # Initialize other components\n    binary_source = BinarySource()\n    encoder = LDPC5GEncoder(k, n)\n    mapper = Mapper(\"qam\", num_bits_per_symbol)\n    channel = FlatFadingChannel(num_tx, num_rx, add_awgn=True, return_channel=True, spatial_corr=correlation)\n    demapper = Demapper(\"app\", \"qam\", num_bits_per_symbol)\n    decoder = LDPC5GDecoder(encoder, hard_out=True)\n\n    # Function to simulate BER\n    @tf.function(jit_compile=True)\n    def simulate_ber(ebnodb):\n        # Generate a batch of binary data\n        b = binary_source([batch_size, k])\n        # Encode the data\n        c = encoder(b)\n        # Map the encoded data to symbols\n        x = mapper(c)\n        # Simulate the transmission of the data over the channel\n        y, _ = channel([x, ebnodb])\n        # Demap the received symbols to LLRs\n        llr = demapper([y, ebnodb])\n        # Decode the LLRs\n        b_hat = decoder(llr)\n        # Compute the BER\n        return compute_ber(b, b_hat)\n\n    return simulate_ber\n\nclass End2EndSystemKeras(tf.keras.Model):\n    def __init__(self, spatial_corr=None):\n        super().__init__()\n        self.ber_simulation = create_ber_simulation(spatial_corr)\n\n    def call(self, batch_size, ebnodb):\n        return self.ber_simulation(ebnodb)\n```\n\nPlease note that the actual implementation may vary depending on the specific requirements of your system and the components you are using."
"Method:  build_type_grid() of the ResourceGrid class\n\nThis method is used to get the type of resource elements in a resource grid. \n\nSince the grid is pre-defined to carry various kinds of data, this method is crucial as it can help in identifying the nature and type of elements (data, pilot, guard, etc.) being carried by the grid, especially in an event when the grid itself is not visualized directly.\n\nFor instance, if we were to execute this method on a pre-defined resource grid object `g`, the output will be a 4D tensor, showing the type of each and every resource element in the grid for all transmitters and streams. \n\nExample Output: \n`[tx_ind=0, tx_stream_ind=0] : [tx_ind=0, tx_stream_ind=1] : \n[0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0]\n[0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0]\n[0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0]\n[0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 "
"Params:\n\n- num_symbols (int) : Number of symbols in the constellation, which is equal to the length of 'symbol_points'.\n- hard_out (bool) : If True, the layer provides hard-decided values instead of soft-values.\n- dtype (One of [tf.float32, tf.float64] tf.DType) : Type for the input and output, tf.float32 by default.\n\nInput:\n- x ([\u2026,n], tf.float) : Logits on constellation points.\n\nOutput:\n- [\u2026,n, num_bits_per_symbol], tf.float or tf.int : LLRs or hard-decisions for every bit. Hard-decisions correspond to a bit value of 0.5 or greater."
"Here is the detailed information of MaximumLikelihoodDetector:   \n  \n[sionna.ofdm.MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#MaximumLikelihoodDetector) \n\nMaximum-likelihood (ML) detection for OFDM MIMO transmissions. Both ML detection of symbols or bits with either soft- or hard-decisions are supported. The OFDM and stream configuration are provided by a ResourceGrid and StreamManagement instance, respectively. This layer implements maximum-likelihood (ML) detection for OFDM MIMO transmissions. Both ML detection of symbols or bits with either soft- or hard-decisions are supported. The OFDM and stream configuration are provided by a ResourceGrid and StreamManagement instance, respectively. The actual detector is an instance of MaximumLikelihoodDetector.\n\n**Parameters**\n\n- `output` (str): Type of output, either \"bit\" for bits or \"symbol\" for symbols. Whether soft- or hard-decisions are returned can be configured with the `hard_out` flag.\n- `demapping_method` (str): Demapping method used, which is either \"app\" or \"maxlog\".\n- `resource_grid` (ResourceGrid): Instance of ResourceGrid.\n- `stream_management` (StreamManagement): Instance of StreamManagement.\n- `constellation_type` (str): For example, \"qam\", \"pam\", or \"custom\". For custom types, an instance of Constellation must be provided.\n- `num_bits_per_symbol` (int): Number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation types \"qam\" and \"pam\".\n- `constellation` (Constellation): Instance of Constellation or None. If None, `constellation_type` and `num_bits_per_symbol` must be specified.\n- `hard_out` (bool): If True, the detector outputs hard-decided bit values or constellation point indices instead of soft-values. Defaults to False.\n- `dtype` (tf.DType): The dtype of `y`. Defaults to tf.complex64. The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n**Input**\n\n- `(y, h_hat, err_var, no)` \u2013 Tuple:\n  - `y` ([..., num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex): Received OFDM resource grid after cyclic prefix removal and FFT.\n  - `h_hat` ([..., num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex): Channel estimates for all streams from all transmitters.\n  - `err_var` ([..., num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.float): Variance of the channel estimation error.\n  - `no` ([..., num_rx, num_rx_ant] or just the first n dimensions, tf.float): Variance of the AWGN.\n\n**Output**\n\nDepending on the `output` setting:\n- If `output` equals \"bit\":\n  - [..., num_tx, num_streams, num_data_symbols * num_bits_per_symbol], tf.float: LLRs or hard-decisions for every bit of every stream.\n- If `output` equals \"symbol\":\n  - [..., num_tx, num_streams, num_data_symbols, num_points], tf.float or [..., num_tx, num_streams, num_data_symbols], tf.int: Logits or hard-decisions for constellation symbols for every stream. Hard-decisions correspond to the symbol indices."
"To initialize a `TurboEncoder` with custom generator polynomials, the `gen_poly` argument should be provided with a tuple of strings for the generator polynomials in binary format. Each string within the tuple represents a generator polynomial in binary form. \n\nFor instance, a `gen_poly` argument for a TurboEncoder in binary format would resemble the following:\n\n```python\ngen_poly = ('10011','11101','10101')\nencoder = TurboEncoder(constraint_length=4, rate=1/3, terminate=True, gen_poly=gen_poly)\n```\n\nHere, the `gen_poly` tuple represents three generator polynomials in binary form.\n\nAs for a binary sequence like \"10011\", these generator polynomials are used by the Turbo code to perform the encoding process. The sequence is processed by each encoder in turn, with each encoder using one of the specified generator polynomials. The outputs from the encoders are then interleaved and further encoded by the second encoder (or by the first encoder with the interleaving pattern updated). \n\nIn the context of Turbo code, a binary sequence like \"10011\" would be represented as a state diagram in the encoder. This sequence would transition the encoder from one state to another, and the encoder would also produce the corresponding output. The generator polynomial  \"10011\" in binary form would be specific to the particular encoder and the particular state transition."
"To use the generator to sample the first few items of the dataset, you can follow these steps:\n\n1. In the generator function, create a loop that iterates over the items in the dataset. In the provided context, the generator function is `__call__()` method of the `HD5CIRGen` class.\n\n2. Within the loop, yield the item from the dataset. This will make the generator function return the next item in the sequence each time it is called.\n\n3. In the main program, call the generator function to get the generator object. For example, in the provided context, you would call `HD5CIRGen(filename)` to create a generator from an HDF5 file storing path coefficients and delays.\n\n4. Finally, you can iterate over the generator object to sample the first few items of the dataset. You can do this by using a loop or by using the `take` method on the generator object. For example, in the provided context, you can use a loop such as `for (a,tau) in generator():` to iterate over the items.\n\nPlease note that the number of items sampled is controlled by the batch size specified when creating the generator. If the batch size is 64, as in the provided context, then the generator will return 64 items each time it is called. If you want to sample fewer items, you can decrease the batch size. \n\nAlso, note that the code in the provided context that uses a loop to sample the first 5 items of the dataset is incorrect. The loop should iterate over the generator object, not over the dataset directly. The line `for (a,tau) in generator():` should be used instead of `for (a,tau) in dataset:`."
"To save the estimated matrices for future use, you can use the `np.save` function from the `numpy` library. In the given context, the estimated frequency-time, time-lag, and space covariance matrices (FREQ_COV_MAT, TIME_COV_MAT, and SPACE_COV_MAT) are saved as numpy arrays. Here's how it's done:\n\n```python\nnp.save('freq_cov_mat', FREQ_COV_MAT.numpy())\nnp.save('time_cov_mat', TIME_COV_MAT.numpy())\nnp.save('space_cov_mat', SPACE_COV_MAT.numpy())\n```\n\nIn this code, the first argument is the file name and the second argument is the actual data that needs to be saved. The `FREQ_COV_MAT`, `TIME_COV_MAT`, and `SPACE_COV_MAT` are the matrices that were estimated in the previous steps of the computation. The `numpy()` function is used to extract the data from the tensors, which is then saved as a numpy array.\n\nThe matrices are saved as three separate files, each with a different name. The names used in this example are 'freq_cov_mat', 'time_cov_mat', and 'space_cov_mat', but you can use any names you prefer. The data from the tensors is converted to numpy arrays before saving the files. This is important because the `np.save` function does not accept tensors as arguments."
"Iterative Detection and Decoding (IDD) is a technique used in MIMO (Multiple-Input, Multiple-Output) systems to improve the quality of data transmission. It involves the repeated exchange of soft information between a detector (which decodes the received signal into estimated bits or symbols) and a decoder (which uses these estimates to correct errors and recover the original data).\n\nThe basic process of IDD can be understood in the following steps:\n\n1. The received signal is pre-processed by the LLLR (Log-Likelihood Ratio) calculation block to obtain the likelihood values on the transmitted bits or symbols.\n\n2. The detector uses these likelihood values to produce an estimate of the transmitted bits or symbols in the form of LLRs. This is the \"hard\" estimate of the data.\n\n3. The estimated data is then re-encoded into a codeword by the mapper and transmitted through the channel.\n\n4. At the receiver, the transmitted signal is demapped and deinterleaved, then the received LLRs are calculated in the L2 block.\n\n5. The decoder uses these received LLRs, along with its knowledge of the channel and noise characteristics, to produce updated estimates of the original data in the form of LLRs. These are the \"soft\" estimates of the data.\n\n6. The process is repeated iteratively, with the updated LLRs from the decoder being used to produce new estimates at the detector, and vice versa.\n\nIn traditional IDD, a hard-decision detector such as the MMSE (Minimum Mean Square Error) PIC (Parallel Interference Cancellation) detector is used. However, the SISO MMSE-PIC detector has been found to work better when provided with the full *a posteriori* information from the decoder. Therefore, in some implementations of IDD, the detector and decoder are coupled to improve the performance.\n\nThe concept of IDD is not limited to traditional binary block codes and decoders. It can also be applied to more general codes, including in the context of MIMO systems as presented in the provided context. The concept of IDD has been found to be beneficial in improving error rates and reducing the number of iterations required for reliable data recovery in such systems."
"The Descrambler class details:\n- **Parameters**:\n  - `scrambler`: Associated Scrambler or TB5GScrambler instance which should be descrambled. \n  - `binary` (bool): Defaults to True. Indicates whether bit-sequence should be flipped (i.e., binary operations are performed) or the signs should be flipped (i.e., soft-value/LLR domain-based).\n  - `dtype` (None or tf.DType): Defaults to None. Defines the datatype for internal calculations and the output dtype. If no explicit dtype is provided the dtype from the associated interleaver is used.\n- **Input**: \n  - It can either take a tuple `(x, seed)` or `x` only (no tuple) if the internal seed should be used. \n  - `x` (tf.float32): 1+D tensor of arbitrary shape.\n  - `seed` (int): An integer defining the state of the random number generator. If explicitly given, the global internal seed is replaced by this seed. Can be used to realize random scrambler/descrambler pairs (call with same random seed).\n- **Output**: `x` (tf.float32): 1+D tensor of same shape as input `x`.\n- **Exception**: AssertionError: If `scrambler` is not an instance of Scrambler. TypeError: If dtype of `x` is not as expected.\n\n- **Properties**:\n  - `scrambler`: Associated scrambler instance."
"Here is the definition of KBestDetector: sionna.mimo.KBestDetector(output, num_streams, k, constellation_type, num_bits_per_symbol, constellation, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/mimo/detection.html#KBestDetector)  \n\nsource code:\n```python\nclass KBestDetector(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"KBestDetector(output, num_streams, k, constellation_type, num_bits_per_symbol, constellation, dtype=tf.complex64)\n\n    MIMO K-Best detector\n\n    This layer implements K-Best MIMO detection as described in (Eq. 4)\n    in [FT2014](https://nvlabs.github.io/sionna/emmi-papers.html#barbero_ft2014)\n    and [S1998](https://nvlabs.github.io/sionna/emmi-papers.html#santalab1998)\n    .\n\n    The constellation symbols are either real-valued or complex-valued.\n    In the latter case, the `constellation` object defines the\n    constellation.\n\n    The detection algorithm is fully differentiable when the\n    soft-symbol output is differentiable w.r.t. the received signals.\n    This is the case for the ``l2`` and ``MSE`` losses. It is,\n    however, not differentiable with the ``SymbolCrossentropy``\n    as it does not provide a\n    explicit gradient w.r.t. the transmitted symbols.\n\n    Parameters\n    ----------\n    output : One of [\"bit\", \"symbol\"], str\n        Type of output, either LLRs on bits or logits on constellation symbols.\n\n    num_streams : tf.int\n        Number of transmitted streams\n\n    k : tf.int\n        Number of retained paths\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type``\n        in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        Instance of :class:`~sionna.mapping.Constellation` or None.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of `y`. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    ------\n    (y, h, prior, err_var, no) :\n        Tuple:\n\n    y : [...,num_rx,], tf.complex\n        1+D tensor containing the received signals\n\n    h : [...,num_rx,num_streams], tf.complex\n        2+D tensor containing the channel matrices\n\n    prior : [...,num_streams,num_bits_per_symbol] or [...,num_streams,num_points], tf.float\n        Prior of the transmitted signals.\n        If ``output`` equals \"bit\", LLRs of the transmitted bits are expected.\n        If ``output`` equals \"symbol\", logits of the transmitted constellation points are expected.\n\n    err_var : Scalar or [...,num_rx,num_rx], tf.float\n        Variance of the channel estimation error.\n        This can be a scalar or must have a broadcastable shape.\n\n    no : Scalar or [...,num_rx], tf.float\n        Variance of the AWGN. This can be a scalar or must have a\n        broadcastable shape.\n\n    Output\n    ------\n    One of:\n\n    : [...,num_streams,num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream, if ``output`` equals `\"bit\"`.\n\n    : [...,num_streams,num_points], tf.float\n       Logits for or hard-decisions of constellation symbols for every stream, if ``output`` equals `\"symbol\"`.\n       Hard-decisions correspond to the symbol indices.\n\n    Note\n    ----\n    If you want to use this layer in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sionna.Config.xla_compat=true``.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n    def __init__(self,\n                 output,\n                 num_streams,\n                 k,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 dtype=tf.complex64):\n        super().__init__()\n\n        # Initialize PAM or QAM constellation if required\n        if constellation_type is not None:\n            assert constellation_type in [\"qam\", \"pam\"],\\\n                \"Wrong constellation type\"\n            assert constellation is not None, \"Constellation must be provided\"\n            c = Constellation.create(  constellation_type,\n                                        num_bits_per_symbol,\n                                        dtype=dtype)\n        else:\n            c = constellation\n\n        #  Instantiate the KBestDetectorLayer\n        self._detector = KBestDetectorLayer( output=output,\n                                              num_streams=num_streams,\n                                              k=k,\n                                              constellation=c,\n                                              dtype=dtype)\n\n    @property\n    def constellation(self):\n        return self._detector.constellation\n\n    def call(self, inputs):\n        x = self._detector(inputs)\n        return x\n```"
"Using the `position` and `orientation` properties to move scene objects in Sionna is a fundamental concept in using Sionna's Ray Tracing API for wireless propagation simulation. It allows users to adjust the location and orientation of the desired objects within the scene to suit the simulation requirements. \n\nThe `position` property is used to represent the 3D Cartesian coordinate vector of the translated origin, and is used to move the object within the scene relative to its current position. \n\nThe `orientation` property, on the other hand, represents a unit vector that's used to define the direction of the object. This property allows the user to rotate the object as required. \n\nBoth of these properties can be assigned to any scene object, allowing you to effectively move each object to the desired location and orient it as needed.  These properties can also be used to animate scene objects by updating them at different simulation steps. \n\nHere's an example of how you could use `position` and `orientation` to move an object in the scene:\n\n```python\n# Set the position and orientation\nscene_objects(\"my_object\").position = [0.0, 0.0, 10.0]  # Move along the z-axis\nscene_objects(\"my_object\").orientation = [np.pi, 0.0, 0.0]  # Rotate 180 degrees around the x-axis\n```\n\nIn the provided context, the use of these properties is described in the context of mobility simulation. In a mobility scenario, you might simulate the movement of objects over time, and therefore, you might assign changing values to these properties at different simulation steps. \n\nRemember that directly setting the `position` and `orientation` properties of a radio device is not recommended. Instead, it is advised to attach the device to a scene object, and then set the `position` and `orientation` of the scene object. The `position` and `orientation` properties of the scene object represent the final position and orientation in the scene for all of the objects attached to it. \n\nFor more complex movements, you might also consider using a trajectory, which is a sequence of points in the 3D space. You can then move objects along this trajectory over a desired duration."
"To run the final evaluation for different system configurations in Sionna RT, you can follow these steps:\n\n1. **Set up the environment**: Import the necessary libraries and modules. This includes Sionna RT and other necessary modules like numpy, matplotlib, and others. Also, ensure that the necessary data and scene files are available.\n\n2. **Define the system configurations**: Define the different system configurations that you want to evaluate. This could include variations in the number of antennas, modulation schemes, coderates, and other parameters. \n\n3. **Run the final evaluation for different system configurations**: Use the `evaluate_system_tf` function from the Sionna RT library to run the final evaluation for different system configurations. This function takes as input a list of system configurations, the scene, and other parameters like the number of bits per symbol and the batch size. The function will return the BLER for each system configuration.\n\nHere is a code snippet that demonstrates these steps:\n\n```python\n# Define the system configurations\nconfig1 = {...} # First system configuration\nconfig2 = {...} # Second system configuration\n...\n\n# List of all system configurations\nall_configs = [config1, config2, ...]\n\n# Run the final evaluation for different system configurations\neval_results = evaluate_system_tf(all_configs, scene, opts.eval_bits_per_symbol, opts.batch_size)\n```\n\nIn this code, `eval_results` will contain the BLER for each system configuration. These results can then be analyzed to compare the performance of different system configurations."
"To compute the exact Doppler shifts based on the equation provided in the Background Information, you can use the equation under the assumption that you know the exact velocity vector $v=(v_x,v_y,v_z)$ for the direction in which the transmitting terminal is moving. The equation is given as:\n\n$f_\\text{D}(x, y, z) = x \\cdot f_\\text{D, x} + y \\cdot f_\\text{D, y} + z \\cdot f_\\text{D, z}$\n\nHere, $f_\\text{D, x} = \\dfrac{-k_\\text{r}v_\\text{x}}{4 \\pi}$, $f_\\text{D, y} = \\dfrac{-k_\\text{r}v_\\text{y}}{4 \\pi}$, and $f_\\text{D, z} = \\dfrac{-k_\\text{r}v_\\text{z}}{4 \\pi}$.\n\nThe function `column_dims()` is provided in the context, which can be used to repeat the velocity components in the needed columns without the need of writing a loop. \n\nHere is how you can compute the exact Doppler shifts using the above equation, assuming that you have the velocity vector for the direction in which your object is moving:\n\n```python\n# Compute exact Doppler shifts\nexp_dop = exact_doppler(rg_scene, config)\nx, y, z = exp_dop[1]['pos'] # Transmitter position\nx = column_dims(x, nb_cols=rg_scene.path_num - 1, dim=0)\ny = column_dims(y, nb_cols=rg_scene.path_num - 1, dim=1)\nz = column_dims(z, nb_cols=rg_scene.path_num - 1, dim=2)\nf_d_x = exp_dop[1]['f_dop'][0]*x\nf_d_y = exp_dop[1]['f_dop'][1]*y\nf_d_z = exp_dop[1]['f_dop'][2]*z\nf_dop = tf.reduce_sum(tf.stack([f_d_x, f_d_y, f_d_z], axis=-1), axis=-1)\n```\n\nIn the code above, `exp_dop[1]['pos']` returns the position of the transmitter. We then repeat the velocity vector in the columns using the `column_dims()` function. After that, we use the equation to compute the exact Doppler shift for each column. We finally sum the components along the last dimension to get the exact Doppler shift for each column."
"Here is the definition of cir_to_time_channel: sionna.channel.cir_to_time_channel(channel_model, bandwidth, samples_per_symbol, num_symbols, delay_spread, add_awgn=True, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/utils.html#cir_to_time_channel)\n\nsource code:\n```python\ndef cir_to_time_channel(channel_model, bandwidth, samples_per_symbol,\n                        num_symbols, delay_spread, add_awgn=True,\n                        dtype=tf.complex64):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Generate a channel in the time domain by sampling the continuous-time\n    channel with the help of a  discrete sinc filter.\n    The channel input consists of a block of symbols.\n    For each symbol in the block, the channel output is computed\n    by filtering this block with the  discrete filter\n    and summing over the filter length. AWGN noise is  optionally   add  to the output.\n\n    More formally, this function generates channels :math:`\\bar{\\mathbf{H}}^{(i)}` in the time domain\n    for each of the :math:`K`  taps of the :math:`M`  taps wide discrete sinc filter :math:`\\bar{h}_{\\text{filt}}`\n    from the continuous-time channel  :math:`\\bar{\\mathbf{H}}_C(t)` as follows:\n\n    .. math::\n        \\bar{\\mathbf{H}}^{(i)} = \\sum_{k=0}^{M-1} \\bar{\\mathbf{H}}_C\\left(\\frac{i}{M}\\right) \\bar{h}_{\\text{filt}}\\left(1-\\frac{i}{M}\\right)\n\n    where\n    :math:`\\bar{\\mathbf{H}}_C(t)` is the continuous-time channel,\n    :math:`\\bar{\\mathbf{H}}^{(i)}` the discrete-time channel in the time domain,\n    and :math:`\\bar{\\mathbf{H}}_C(t)` given by :eq:`h_time`.\n\n\n    For multiple-input multiple-output (MIMO) channels, the channel for the :math:`k^{th}` stream  is computed by multiplying :math:`\\bar{\\mathbf{H}}^{(i)}` by :math:`\\mathbf{x}_k`, and then summing over all streams\n    (akin to the procedure in :class:`~sionna.channel.OFDMChannel`).\n\n\n    The block length :math:`L` of the channel in number of symbols must be an integer that results in\n    the same number of time samples for each block. It cannot be inferred\n    from the filter length since the filter length is always equal to the filter\n    width :math:`(M)` in number of symbols. Hence, :math:`L` needs to be specified\n    by the user and typically results from rounding up the channel model parameter :math:`K_{\\text{max}}}`\n    to the next integer that is a multiple of the filter length\n    (e.g., see :class:`~sionna.channel.Tr38901Channel`).\n\n    The discrete sinc filter is defined as\n\n    .. math::\n        \\bar{h}_{\\text{filt}}(t)\n        = \\frac{1}{T}\\text{sinc}\\left(\\frac{t}{T}\\right)\n\n    where :math:`T` is the symbol duration.\n\n\n    Input\n    ------\n     channel_model : :class:`~sionna.channel.ChannelModel` object\n        An instance of a :class:`~sionna.channel.ChannelModel` object,\n        such as :class:`~sionna.channel.RayleighBlockFading`.\n\n\n     bandwidth : float\n        Bandwidth (:math:`B`) [Hz]\n\n     samples_per_symbol : int\n        Number of samples per symbol (:math:`N_S`)\n\n     num_symbols : int\n        Number of symbols forming the channel input block (:math:`N`)\n\n     delay_spread : float\n        Delay spread (:math:`\\tau_D`) [s]\n\n     add_awgn : bool\n        If set to `False`, no white Gaussian noise is added.\n        Defaults to `True`.\n\n    dtype : tf.DType\n        Datatype to use for the filter.\n        Must be either `tf.complex64` or `tf.complex128.\n        Defaults to `tf.complex64`.\n\n    Output\n    -------\n    h_time : [num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_samples, num_symbols], tf.complex\n        Channel in time domain\n\n     no : [num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_samples, num_symbols], tf.complex\n         Additive white Gaussian noise (AWGN) power spectral density per\n         symbol\n\n    Note\n    ----\n    For the sinc filter, a filter length of :math:`M=7` and\n    a sample duration of :math:`T=1` are assumed, which result in\n    a filter width of :math:`M` in symbols. These settings cannot be\n    modified by the user. They ensure that the discrete-time channel\n    is (nearly) time-invariant from the beginning to the end of each\n    block. This is important for many algorithms that operate on\n    block of data, such as the [https://nvlabs.github.io/sionna/api/mimo.html#stream_management \"stream management\"]\n    in the case of MIMO systems.\n\n    Example\n    --------\n\n    The following code snippet shows how to setup and use this function.\n\n    .. code-block:: Python\n\n        # the channel_model object (in this example Rayleigh block fading)\n        # can be replaced by another `ChannelModel`, e.g., `AWGN` or `UHFChannel`\n        >>> channel_model = RayleighBlockFading(num_rx = 1,\n        >>>                                       num_rx_ant = 32,\n        >>>                                       num_tx = 4,\n        >>>                                       num_tx_ant = 2)\n        >>> # bandwidth\n        >>> bandwidth = 8e6\n        >>> # samples per symbol\n        >>> samples_per_symbol = 4\n        >>> # number of symbols per block\n        >>> num_symbols = 2**10\n        >>> # max delay spread\n        >>> delay_spread = 30e-6\n        >>> # compute the channel in time domain\n        >>> h_time, no = cir_to_time_channel(channel_model,\n        >>>                                   bandwidth,\n        >>>                                   samples_per_symbol,\n        >>>                                   num_symbols,\n        >>>                                   delay_spread)\n\n        >>> # Then use h_time and no in your time-domain processing\n        >>> y = tf.signal.convolve(h_time, x)\n        >>> # Add AWGN\n        >>> no_half = tf.cast(no, y.dtype)\n        >>> y = y + (no_half**0.5) * (tf.random.normal(tf.shape(y)[0:3]) +\n        >>>                           1j*tf.random.normal(tf.shape(y)[0:3]))\n\n    \"\"\"\n    # Filter to resample the continuous-time channel to\n    # discrete-time\n    sinc = _sinc(1., np.floor(num_symbols*(bandwidth/channel_model.w_c)/samples_per_symbol))\n\n    h_sinc = tf.constant(sinc, dtype=dtype)\n    h_sinc = tf.signal.expand_dims(h_sinc, axis=0)\n\n    # Channel to time domain\n    h_time = tf.vectorized_map(_cir_to_time_channel,\n                                (channel_model, h_sinc, bandwidth,\n                                 samples_per_symbol, num_symbols, delay_spread))\n\n    h_time, no = h_time\n    return h_time, no\n\n\ndef _cir_to_time_channel(channel_model, h_sinc, bandwidth, samples_per_symbol,\n    num_symbols, delay_spread):\n    w = channel_model.w\n\n    # T in seconds (sampling time)\n    t_c = 1/w\n    time_steps_per_symbol = samples_per_symbol\n    symbol_duration = time_steps_per_symbol*t_c\n\n    delay = np.linspace(0., num_symbols-1, num_symbols)\n    delay_spread = np.maximum(delay_spread, 1e-6) # 1us\n    h_delay = channel_model.delay_spread(\n                                delay,\n                                channel_model.sp_corr_mat,\n                                channel_model.co_freq,\n                                channel_model.antenna_polar,\n                                dtype=h_sinc.dtype)\n    h_delay = tf.constant(h_delay, h_sinc.dtype)\n    h_delay = tf.signal.expand_dims(h_delay, axis=-1)\n    h_delay = tf.tile(h_delay, [1, 1, 1, 1, 1, num_symbols])\n\n    # Compute sinc channel\n    h_sinc = tf.cast(h_sinc, h_sinc.dtype)\n    h_sinc = tf.signal.pad(h_sinc, [[0, h_delay.shape[-2]-1],\n                                [0, 0]], constant_values=0)\n    h_sinc = tf.signal.convolve(h_sinc, h_delay, strides=[1,1], padding='full')\n\n    # Channel impulse response\n    # (resampling from sinc filter, symbol duration is 1)\n    a = bandwidth*symbol_duration\n    h_a = np.sinc(delay/a)\n\n    # Half symbol duration\n    half_symbol_duration = (symbol_duration-1)/2\n    a = bandwidth*half_symbol_duration\n    h_half = np.sinc(delay/a)\n    h_half = tf.constant(h_half, h_sinc.dtype)\n    h_half = tf.signal.expand_dims(h_half, axis=0)\n    h_half = tf.signal.expand_dims(h_half, axis=0)\n    h_half = tf.tile(h_half, [h_sinc.shape[0], 1, 1, 1])\n\n    # Channel output at the samples where the symbols are assumed to\n    # occur is equal to the sum of the sinc at the ``sampled symbol\n    # locations'' scaled by the amplitude of the channel taps.\n    # We must thus compute the indices of the samples where the\n    # channel impulse response is evaluated\n    ind_min = np.int32(np.floor(h_sinc.shape[1]/2))\n    # The index of the sample right after the observation of the\n    # symbol\n    ind_beyond = ind_min + samples_per_symbol\n    symbol_ind = np.arange(ind_min, ind_beyond)\n    # Evaluating the channel for all symbol locations\n    h_s = tf.reduce_sum(h_sinc[:,symbol_ind,:], axis=1)\n    h_s = tf.squeeze(h_s, axis=1)\n\n    # Same for the half symbol\n    h_sh = tf.reduce_sum(h_sinc[:,symbol_ind+1,:], axis=1)\n    h_sh = tf.squeeze(h_sh, axis=1)\n\n    # The channel output results from the difference of the  baseband\n    # channel responses at the samples where the symbols were\n    # observed.\n    # We also need to add the amplitude of the channel tap to the\n    # half symbol value.\n    h_s = h_s - 2.*h_a\n    # and the amplitude of the tap corresponding to the half symbol\n    h_s = tf.math.divide_no_nan(h_s, 2.)  + h_sh\n\n    # Compute the noise variance as the energy of the channel output\n    no =  channel_model.compute_noise_var(bandwidth, symbol_duration,\n                                          samples_per_symbol, num_symbols,\n                                          delay_spread)\n    return (h_s, no)\n```"
"To generate the Channel Frequency Response, you can follow these steps:\n\n1. Load the scene using the `load_scene` function.\n2. Set the frequency of the scene using the `frequency` attribute of the scene object. This represents the carrier frequency in Hertz.\n3. Configure the transmitters and receivers using the `PlanarArray` class. You can specify the number of rows and columns, spacing, pattern, and polarization for each antenna.\n4. Add a transmitter to the scene using the `Transmitter` class. You can specify the name, position, and orientation of the transmitter.\n5. Add a receiver to the scene using the `Receiver` class. You can specify the name, position, and orientation of the receiver.\n6. Run the simulation using the `scene.simulate` function. You can specify the output format of the simulation.\n\nThis will generate the Channel Frequency Response. The Channel Frequency Response is the part of the overall link-level channel response that depends on the frequency and direction of propagation, as well as the characteristics of the antennas used at the transmitter and receiver. This is essentially the transfer function of the channel in the frequency domain.\n\nTo generate the Discrete-Time Channel Impulse Response, you can follow these steps:\n\n1. Load the scene using the `load_scene` function.\n2. Set the frequency of the scene using the `frequency` attribute of the scene object.\n3. Configure the transmitters and receivers using the `PlanarArray` class.\n4. Add a transmitter and a receiver to the scene.\n5. Run the simulation using the `scene.simulate` function. You can specify the output format of the simulation.\n\nThe Discrete-Time Channel Impulse Response is a representation of the channel response in the time domain. It describes the effect of the channel on a signal transmitted from the transmitter to the receiver. The channel response can be influenced by various factors such as the propagation environment, the antennas used, and the motion of the transmitters and receivers."
"The principle idea of higher order modulation involves mapping multiple bits to one complex-valued symbol. This is achieved through the use of a modulation scheme, which enables the transmission of multiple bits in each symbol. This is in contrast to simpler schemes like binary phase shift keying (BPSK) where each transmitted symbol represents one bit.\n\nThe demapper and decoder are key components that are used to reverse the process of the modulation and encoding stages. The demapper uses the received signal to estimate the a priori or a posteriori probability of each bit or constellation point. These estimates are then passed to the decoder, which uses them, along with the knowledge of the specific code used, to generate an estimate of the originally transmitted bits.\n\nIn the context of higher order modulation, the demapper and decoder play interconnected roles. The demapper is used to translate the received signal into a form that is suitable for the decoder. For example, in the case of Binary Labeling, the demapper would produce Log-Likelihood Ratios (LLRs) for each 'C' bit. These LLRs, along with the specific knowledge of the code used, are then passed to the decoder to produce estimates of the original information bits.\n\nThe principle idea of higher order modulation can be understood in the context of various components of a communication system, including the demapper and decoder, which play crucial roles in accurately estimating the transmitted information in the presence of noise and other impairments."
"Example to be Provided\n\nAn example will be provided in the answer showing how to handle the situation where the `LDPCBPDecoder` is stateful and explaining the significance of the `msg_vn` parameter. However it is not included in the answered extract. \n\nThe `msg_vn` (a list of all variable node messages) parameter in the `call` method of the `LDPCBPDecoder` is a way to maintain the decoder's internal VN messages, but also a potential source of errors and repetition of computation as it overrides the internal VN messages if provided by the user and not checked. \n\nTo handle this parameter properly: \n- The function that calls the decoder should compute the messages that need to be passed among the variable nodes and check that `msg_vn` is not provided, or it will raise an error and not use the internal messages. \n- This ensures the integrity of the decoder's state, and avoids redundancy and potential errors in passing VN messages. \n- The `msg_vn` parameter is optional, giving the flexibility of reprogramming all messages if needed, but users must be careful to provide the right message indexes and not to trigger errors.\n\nHere is an hypothetical example to illustrate how you might handle the `msg_vn` parameter in Python:\n\n```python\nfrom sionna.fec.ldpc import LDPCBPDecoder, LDPC5GEncoder\n\n# assume we have an encoder for a known PCM model and an all-zero codeword for simplcity\nencoder = LDPC5GEncoder(n=100, k=20) # initialize encoder with required parameters\n\n# All-zero codeword\ncw = encoder(np.zeros(20))\n\n# Create an instance of the LDPCBPDecoder\nbp_decoder = LDPCBPDecoder(encoder, num_iter=20, stateful=True)  # instantiate BP decoder, set stateful=True\n\n# example of VN messages to decode with (randomly generated)\n# Ensure the correct dimension and type for the message as it's just a hypothetical illustration\n# VN message corresponding to check node c input in log domain\nmsg_vn = tf.ones((1, encoder.n), dtype=tf.float32)  # 1 is just a filler here, use your actual data\n\n# result = bp_decoder(msg_vn)  # if you want to use your own VN messages, it will fail as it's not checking for an explicit msg_vn input\n\ntry:\n    result = bp_decoder()  # call decoder without an explicit msg_vn input, this will use the internal VN messages\nexcept TypeError as te:\n    print(\"Error message:\", te)\nexcept Exception as e:\n    print(\"Another error, decoder() failed:\", e)\n```\n\nIn the example, the code first initializes an instance of the BPDecoder with `stateful=True`, which allows the decoder to store and utilize previous messages, enabling the implementation of more advanced BP algorithms like the weighted BP decoding. \n\nThe optional `msg_vn` parameter is then initialized with hypothetical VN messages, which here is a tensor of ones. \n\nFollowing this, an attempt to call the decoder using the `msg_vn` parameter is made. This would not be recommended in a production environment, as it doesn't check the type or dimensions of `msg_vn` which could lead to errors, but it demonstrates how it could be used: \n- If the `msg_vn` parameter is passed along with the call to the `LDPCBPDecoder`, the decoder will use these messages instead of its internal messages. \n- If `msg_vn` is set to `None` or not provided, the decoder will use its internal messages. This is why the example is set to explicitly raise an error to show the potential issue with providing `msg_vn` in this way. \n- The TypeError caught here is used to explain that the explicitly provided `msg_vn` is not the correct type or format. \n- The other type of errors would be handled in a production setting, they are printed as an explanation here. \n\nThis is a hypothetical example that illustrates how to handle the `msg_vn` parameter, it should be adjusted according to the actual application and data. \n\nNote: \n- As the context doesn't provide details on the specific use of the `msg_vn` parameter in the `call` method, this is a general illustration focusing on proper error handling to safeguard against errors and misuse of `msg_vn`. Please cross-verify from the official documentation or update the answer from a more reliable source if available in your context. \n- The actual code and patterns on how to use the `msg_vn` parameter may vary depending on how `LDPCBPDecoder` is instantiated and utilized, and any handling of VN messages in a specific application or framework, which would require a detailed knowledge of the specific use case and framework. \n   "
"Here is the detailed information of subcarrier_frequencies:   \n  \n[sionna.channel.subcarrier_frequencies(subcarrier_spacing, num_subcarriers, offset=0.0, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/channel/utils.html#subcarrier_frequencies)\n\nCompute the normalized subcarrier frequencies.\n\nThe first subcarrier is assumed to be centered at DC.\n\n#### Input\n\n- `subcarrier_spacing` (float): Subcarrier spacing $f_\\text{sc}$ in Hz.\n- `num_subcarriers` (int): Number of subcarriers $N$.\n- `offset` (float): Guard-carrier offset in multiples of subcarrier spacing.\n- `dtype` (tf.DType): Datatype to for the output. Defaults to tf.complex64.\n\n#### Output\n\n- `frequencies`: 1D tensor containing the normalized subcarrier frequencies.\n\nsource code:\n```python\ndef subcarrier_frequencies(subcarrier_spacing, num_subcarriers,\n                           offset=0.0, dtype=tf.complex64):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Compute the normalized subcarrier frequencies.\n\n    The first subcarrier is assumed to be centered at `DC`.\n\n    Input\n    ------\n    subcarrier_spacing : float\n        Subcarrier spacing :math:`f_\\text{sc}` in Hz.\n\n    num_subcarriers : int\n        Number of  subcarriers :math:`N`.\n\n    offset : float\n        Guard-carrier offset in multiples of subcarrier spacing.\n\n    dtype : tf.DType\n        Datatype to for the output.\n        Defaults to `tf.complex64`.\n\n    Output\n    --------\n    frequencies: 1D tensor\n        :math:`N` 1D tensor containing the normalized subcarrier frequencies.\n    \"\"\"\n    assert num_subcarriers%2==1, \\\n        \"num_subcarriers must be odd.\"\n\n    n = tf.cast(num_subcarriers, dtype)\n\n    # The n normalized subcarrier frequencies go from\n    #  -n/2 to n/2 in steps of 1.\n    # The subcarrier spacing is 1.\n    # The DC is at 0.\n    # We add the offset to the frequencies.\n    # In case of a null offset, the index of the DC depends if N is even or\n    #  odd.\n    # If N is even, we add 0.5 to the DC index.\n    # If N is odd, the DC index is simply (n-1)/2.\n\n    # Index of the DC subcarrier\n    ind = tf.range(-n/2, n/2, 1., dtype=dtype)\n\n    # Adding the offset\n    ind = tf.map_fn(lambda x: x*subcarrier_spacing*(1+offset), ind)\n\n    # Adding the pilot OFDM symbol indices\n    # Pilot OFDM symbols are located at n/2 +/- n_p where n_p is the set of\n    # pilot indices.\n    # This is done to ensure that the pilot indices are separated by at least\n    # one from the DC.\n    # We assume that n_p has been generated with the previous rules in mind,\n    # and thus n_p%2==1 and the first pilot index is n/2 and the last\n    # one -n/2.\n    num_pilot = tf.shape( tf.range(-n/2, n/2, 2., dtype=dtype) )[0]\n    pilot_frequencies = tf.abs(subcarrier_spacing) * tf.cast(\n        tf.range(-num_pilot, num_pilot, 2.) , dtype=dtype)\n\n    return tf.sort(tf.concat([ind, pilot_frequencies], 0))\n```"
"To simulate the transmission of a single Gaussian impulse over a lumped amplification channel model consisting of multiple fiber spans and optical amplifiers (EDFA), you can follow these steps:\n\n1. **Initialize the System Parameters**: Define the parameters for the EDFA and fiber. The EDFA parameters include the gain (in linear domain), noise figure, amplifier spontaneous emission factor, carrier frequency, and time duration of the impulse. The fiber parameters include the dispersion coefficient, fiber length, and the ratio of the nonlinear coefficient to the linear coefficient.\n\n2. **Generate the Gaussian Input**: Create a Gaussian impulse as the input signal. The impulse should have a peak power of 1 mW, and its instantaneous frequency is 193.55 THz.\n\n3. **Simulate the Linear Fiber Propagation**: Propagate the Gaussian impulse through the fiber. This can be done by using the `simulate` method of the fiber object. This method uses the split-step Fourier method (SSFM) to numerically solve the generalized nonlinear Schr\u00f6dinger equation (NLSE). The parameters to pass to this method include the input signal, the number of steps, and the fiber length.\n\n4. **Simulate the Amplified Spontaneous Emission**: Add the amplified spontaneous emission (ASE) of the EDFAs to the signal after propagation through the fiber. This can be done using the `ase` method of the EDFA object. The parameters to pass to this method include the signal and the noise figure.\n\n5. **Simulate the Gaussian Receiver**: Receive the signal using a perfect photodiode. This can be done using the `gaussian_receiver` function. The parameters to pass to this function include the signal and the sampling frequency.\n\n6. **Apply the Nonlinear Fourier Transform (NFT)**: Apply the NFT to the received signal to mitigate the impact of the chromatic dispersion. The NFT is applied using the `nft` function and the nonlinear coefficient of the fiber.\n\n7. **Apply the Discrete Fourier Transform (DFT)**: Transform the signal from the time domain to the frequency domain using the DFT. This can be done using the `fft` function.\n\n8. **Apply the Sliding Discrete Fourier Transform (SDFT)**: Apply the SDFT to further reduce the effect of the Kerr nonlinearity. The SDFT is applied using the `sdft` function and the number of steps and the nonlinearity coefficient.\n\n9. **Apply the Known Operator Inversion (K-1)**: Apply the inverse of the channel's SDFT matrix on the ideal discrete Fourier transform to recover the transmitted signal.\n\n10. **Assess the Quality of Transmission**: Compute the bit error rate (BER) and the error vector magnitude (EVM) to evaluate the quality of the transmitted signal.\n\nRemember to enable the corresponding impairments (attenuation, noise, dispersion, nonlinearity) as you simulate them. You can disable the single-sideband modulation for the simulation using the 'with_ssb' parameter."
"PARAMETERS:\n\n- **crc_encoder:** `CRCEncoder`\n  - An instance of CRCEncoder to which the CRCDecoder is associated.\n\n- **dtype:** `tf.DType`\n  - (Optional) Defaults to `None`. Defines the datatype for internal calculations and the output dtype. If no explicit dtype is provided, the dtype from the associated interleaver is used.\n\nINPUT\n\n- **inputs: **`[,k+crc_degree], tf.float32`  \n  2+D Tensor containing the CRC encoded bits (i.e., the last crc_degree bits are parity bits). Must have at least rank two.\n\nOUTPUT\n\n- `x: [,k], tf.float32`  \n  2+D tensor containing the information bit sequence without CRC parity bits.\n\n- `crc_valid: [,1], tf.bool`  \n  2+D tensor containing the result of the CRC per codeword.\n\nERRORS:\n  \n- InvalidArgumentError  \n  When rank(`x`)<2.\n\nCOMMON INPUT for inherited classes:\n \n  inputs : [,n], tf.float32  \n    A 2+D tensor containing the result of the demodulation process. This tensor captures the effect of the channel and noise on the transmitted signal. The input tensor contains hard-decided bit values (or constellation point indices) and, for the specific implementation, bit or symbol values.\n\n  he_ind : [batch_size, num_he_per_codeword], tf.int32  \n    Tensor that has the indices of the transport block segments with additional parity, as done by the LDPCEncoder. This parameter is only required for processing data that was generated by LDPC codes and has a non-zero value only if LDPC scrambling is used. The datatype and structure of this tensor is not required, as it is only used to skip (most of) the transport block segments during the processing of the additional parity, which is only relevant for the downlink.\n\n  uti_coded : float  \n    The average channel reliablity of the (un)bundled LDPC codeword, as quantified by the mean value if the Q-value, see [T. Keller](https://ieeexplore.ieee.org/document/7950757)_, only required for (un)bundled LDPC codes.\n\n  inverse : bool  \n    (Defaults to `False`.) Indicated whether the demapper or the mapper was used. This parameter is only required for consistency of the LDPC code implementation and is not used in the actual decoding process. \n\n  Output: [,k], tf.float32  \n   A 2+D tensor containing hard-decided estimations of the k information bits. The output bitstream has been reordered as defined by the corresponding CBCR."
"The Constellation class in Sionna's mapping module outputs a constellation object. This is a complex-valued vector of points. After the creation of the constellation, the user can decide whether this should be a trainable variable or if it should be initialized with specific values. The constellation can be normalized and centered, if required. The number of bits per symbol is an important parameter for this class, which the Constellation class takes as an input. The constellation can be of QAM, PAM, or a custom type.\n\nThe constellation object can be shown in a scatter plot where the symbols are displayed as a vector of constellation points. This can be useful for a visual representation of the data."
"The datatype for the LinearEncoder output is defined as `tf.float32` using the `dtype` parameter of the LinearEncoder instantiation. \n```python\nencoder = LinearEncoder(enc_mat, dtype=tf.float32)\n```"
"Here is the detailed information of sionna.utils.matrix_pinv:  \n\n[sionna.utils.matrix_pinv(tensor)](https://nvlabs.github.io/sionna/_modules/sionna/utils/tensors.html#matrix_pinv)\n\nComputes the (Moore-Penrose) pseudo-inverse of a matrix.\n\nGiven a matrix $\\mathbf{A}\\in\\mathbb{C}^{M\\times N}$, the pseudo-inverse $\\mathbf{A}^{\\dagger}\\in\\mathbb{C}^{N\\times M}$ is $\\mathbf{A}^{\\dagger} = \\bigl(\\mathbf{A}^{\\mathsf{H}}\\mathbf{A}\\bigr)^{-1} \\mathbf{A}^{\\mathsf{H}}$.\n\n### Parameters\n\n- **tensor (tf.complex)**: Rank 2+ tensor of shape [...,M, K] containing matrices.\n\n### Returns\n\n- `tf.complex`: A tensor of shape [..., K, M] containing the pseudo-inverse of the matrices given as `tensor`.\n\n**Note:** \n\nThe pseudo-inverse is such that $\\mathbf{A}\\mathbf{A}^{\\dagger}\\mathbf{A} = \\mathbf{A}$.\n  \nsource code:\n```python\ndef matrix_pinv(tensor):\n    r\"\"\" Computes the (Moore-Penrose) pseudo-inverse of a matrix.\n\n    Given a matrix :math:`\\mathbf{A}\\in\\mathbb{C}^{M\\times N}`, the\n    pseudo-inverse :math:`\\mathbf{A}^{\\dagger}\\in\\mathbb{C}^{N\\times M}`\n    is :math:`\\mathbf{A}^{\\dagger} = \\bigl(\\mathbf{A}^{\\mathsf{H}}\\mathbf{A}\\bigr)^{-1}\n    \\mathbf{A}^{\\mathsf{H}}`.\n\n    This function only differs from :meth:`pinv` in that\n    it is not differentiable but usually more\n    numerically stable.\n\n    Parameters\n    ----------\n    tensor : tf.complex\n        Rank 2+ tensor of shape [...,M, K] containing\n        matrices.\n\n    Returns\n    -------\n    : tf.complex\n        A tensor of shape [..., K, M] containing the\n        pseudo-inverse of the matrices given as ``tensor``.\n    \"\"\"\n    t, s, _ = tf.linalg.svd(tensor)\n\n    # Compute pseudo inverse as v * r-1 * u\n    r_inv = tf.cast(1/s, t.dtype)\n    tensor_pinv = tf.reduce_sum(t[...,tf.newaxis,:]*r_inv[tf.newaxis,...], axis=-1)\n    tensor_pinv = tf.matmul(tensor, tensor_pinv, adjoint_a=True)\n\n    return tensor_pinv\n```"
"Here is the detailed information of the:  \n[sionna.mapping.Demapper(constellation_type, num_bits_per_symbol, constellation, hard_out=False, with_prior=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Demapper) \n\nComputes log-likelihood ratios (LLRs) or hard-decisions on bits for a\n  tensor of received symbols.\n\n**Parameters**\n\n- `constellation_type` (One of [\"qam\", \"pam\", \"custom\"]): The type of the constellation. For \"custom\", an instance of `Constellation` must be provided.\n- `num_bits_per_symbol` (int): The number of bits per constellation symbol, e.g., 4 for QAM16. Must be a power of two if `constellation_type` is not \"custom\".\n- `constellation` (Constellation): An instance of `Constellation` or `None`. If `None`, `constellation_type` and `num_bits_per_symbol` must be provided to create the constellation.\n- `hard_out` (bool): If `True`, the demapper provides hard-decided bits instead of soft-values. Defaults to `False`.\n- `with_prior` (bool): If `True`, the demapper assumes that prior knowledge on the bits is available. This prior information is provided as LLRs as an additional input. Defaults to `False`.\n- `dtype` (One of [tf.complex64, tf.complex128], tf.DType): The dtype of `y`. Defaults to tf.complex64. The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n**Input**\n\n- `(y, no)` or `(y, prior, no)` \u2013 Tuple:\n  - `y` ([, n], tf.complex): The received symbols.\n  - `prior` ([,num_bits_per_symbol] or [,n], tf.float): Prior for the received symbols as LLRs. This is an optional argument that is only required if the demapper is set to with_prior.\n  - `no` ([,n] or scalar, tf.float): The noise variance estimate. This can be a tensor of any shape that can be broadcast to the shape of the input `y`. It includes an additional last dimension that can be used for broadcasting, e.g., for different noise variance estimates for each individual symbol. Alternatively, no can also be a scalar.\n\n**Output**\n\n- `[,n * num_bits_per_symbol]`, tf.float: LLRs or hard decisions for each bit.\n  \n**Note: **\nThe demapping is designed to work with \u2018cyclic\u2019 channel estimates h that are of the same length as y, or, in other words, that assume the channel to be \u2018cyclic\u2019. This is typically the case for a Keras model of a communication system where the number of channel taps is equal to the number of delay spreads. However, this is not the number of samples, but typically an integer much smaller, e.g., 4. If h and y have different lengths, the demapper will produce an error.  \n  \nThe LLR for the ith bit is computed asymbol as  \n$L = \\\\ln\\\\left(\\\\frac{\\\\Pr(b_i=1 \\\\lvert y)}{\\\\Pr(b_i=0 \\\\lvert y)}\\\\right) =\\\\ln\\\\left(\\\\frac{\\\\sum_{y \\\\in \\\\mathcal{Y}_{i,1}} \\\\Pr(y) }{\\\\sum_{y \\\\in \\\\mathcal{Y}_{i,0}} \\\\Pr(y) }\\\\right)$  \n  \nwhere $\\mathcal{Y}_{i,1}$ and $\\mathcal{Y}_{i,0}$ are the sets of constellation points for which the ith bit is equal to 1 and 0, respectively. $\\Pr(y)$ is the prior distribution of the constellation symbol y. It is assumed to be uniform if no prior knowledge on the bits is assumed to be available.  \n  \nHard decisions are, however, not recommended as they cause a loss in performance. Please note that the Demapper object (as all other modulation-related components) is fully integrated into thejson [sionna.Com](https://nvlabs.github.io/sionna/api/utils.html#sionna.Com) layer and its corresponding Keras layer. Therefore, the typical and recommended way of using the various components of a modulation scheme is not to interact with them directly as it is shown in the example below.  \n  \nA \u201ccustom\u201d constellation can be created with `Constellation(constellation_type=\"custom\", points=...)`. For example, the points can be set to snarky [n (int), dtype (tf.complex), tf.float] to allow for a \u201ccategorical\u201d point. It is a tensor that defines arbitrary constellation points. The dtype field determines that the required complex dtype for the bits to be modulated is only a tf.float (and not tf.complex). The tf.float indicates the arbitrary real-valued mapping of the bits to the constellation points.  \n  \nAn instance of `Constellation` can be used to configure the modulation and demapping process. The `Constellation` takes as an argument a tensor of constellation points specified in Hertz and optional LLRs. This means that is can be used to implement nearly all custom modulation schemes with a trainable pointy.  \n  \n### Properties\n\n**Property: `num_bits_per_symbol`**\nThe number of bits per constellation symbol, i.e., the modulation order.\n\n**Property: `constellation`**\nAn instance of `Constellation`.\n\n**Property: `hard_out`**\nIndicates if the layer provides hard-decided bit values instead of soft-values.\n- **Type**: `bool`\n\n**Property: `with_prior`**\nIndicates if prior knowledge on the bits is expected to be available.\n- **Type**: `bool`\n\n### Example\nThe following code example demonstrates how to create and use the PAM Modulator and Demapper. We first import the necessary modules.\n\n```python\nimport tensorflow as tf\nimport numpy as np\nfrom sionna.mapping import Constellation, Mapper, Demapper\n```\n\nWe create a constellation and map it to a tensor of bits.\n\n```python\npoints = Constellation(\"pam\", 16, [-1,3])\nmapper = Mapper(constellation=points)\nmapper\n```\n[<sionna.mapping.Mapper at 0x7f48805209e8>]\n\n```python\nbits = tf.random.uniform(shape=(10, 100), minval=0, maxval=2, dtype=tf.int32)\nx = mapper(bits)\nx.shape, x.dtype\n```\n(TensorShape([10, 100]), tf.complex64)\n\nWe then create a neural demapper and obtain LLRs.\n\n```python\nfrom sionna.mapping import  Demapper\n\nneural_demapper = Demapper(\"no\",-1,\"pam\", num_bits_per_symbol=4)\nneural_demapper\n```\n[<sionna.mapping.Demapper at 0x7f484e4885e0>]\n\nObtain the LLRs from the neural Demapper.\n**Note:**The input to the neural demapper is $\\\\left[\\\\mathbf{y},\\\\mathbf{h},\\\\mathbf{no}]\\\\right]$ but we don't provide the channel matrix $\\mathbf{h}$ or call it with the channel matrix for simplicity as we are in a single-user scenario. \n```python\ny = tf.random.normal(shape=(10, 16), dtype=tf.complex64)\nno = tf.random.uniform(shape=(10, 16), minval=0.0, maxval=2.0, dtype=tf.complex64)\nllr = neural_demapper([y, no])\nllr.shape\n```\n(TensorShape([10, 16]), tf.float32)\n```python\nllr\n<tf.RaggedTensor [[-0.030273438, -0.062866211, 0.020019531, -0.012207031, 0.096679688, 0.2397461, 0.11425781, 0.008544922, 0.030273438, 0.062866211, -0.020019531, 0.012207031, -0.096679688, -0.2397461, -0.11425781, -0.008544922]]>\n```\n  "
"Here is the definition of CDL: sionna.channel.tr38901.CDL(model, delay_spread, carrier_frequency, ut_array, bs_array, direction, min_speed=0., max_speed=None, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/tr38901/cdl.html#CDL)  \n\nsource code:\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"CDL channel model from 3GPP TR38.901\"\n\nimport os\nfrom functools import lru_cache\nimport numpy as np\nimport tensorflow as tf\n\nfrom sionna.constants import SPEED_OF_LIGHT\nfrom sionna.utils import generate_circular_umi_topology\nfrom . import RicianBlockFading\n\n# The path to the directory containing the CDL .npz files\nCDL_DB_PATH = os.path.join(os.path.dirname(__file__), 'cdl_files');\n\n\nclass CDL:\n    # pylint: disable=line-too-long\n    r\"\"\"CDL model from 3GPP [TR38901]_\"\n\n    Available versions are \"A\", \"B\", \"C\", \"D\", \"E\", \"A30\", \"B100\". These\n    must be set using the ``model`` parameter.\n\n    The nominal delay spread is set to 300ns by default. It can be\n    set to any value between 100ns and 3000ns.\n\n    The carrier frequency is set to 3.5GHz by default. It can be\n    any value between 0.5GHz and 6GHz.\n\n    The arrays panel arrays for the user terminal (UT) and the base station (BS)\n    are provided as parameter. Those must be set to instances of\n    :class:`~sionna.channel.tr38901.PanelArray` and can be reused with\n    different parameters for several models.\n\n    The `direction` parameter is used to set the link direction, with\n    \"uplink\" corresponding to transmission from the UT to the BS, and\n    \"downlink\" to the opposite direction.\n\n    Users are simulated to be equipped with a single antenna, but it\n    can be either vertically or horizontally polarized. This is\n    configured with the ``polarization`` parameter, with \"V\" corresponding\n    to \"vertical\" and \"H\" corresponding to \"horizontal\".\n\n    For the \"uplink\", the `position` of the UT is defined to be the\n    $z$ axis [,x,y,z], and the `orientation` is set equal to the BS,\n    as in :math:`\\hat{\\mathbf{p}}_{\\text{u}} = [\\bar{x},\\bar{y},\\bar{z}]`,\n    and\n    :math:`\\hat{\\boldsymbol{\\tau}}_{\\text{u}} = 0`.\n\n\n    .. tabularcolumns:: |l|l|\n\n    .. note::\n        Parameters related to the antenna arrays and the time- and\n        spatial correlation functions are not implemented in this\n        model, as they are not needed for the single UT / single cell\n        use case.\n\n    .. note::\n        This class inherits from the Keras `Layer` class and can be used\n        as layer in a Keras model.\n\n    Parameters\n    -----------\n\n    model : str\n        CDL model to use. Must be one of \"A\", \"B\", \"C\", \"D\", \"E\", \"A30\", \"B100\".\n        The \"A30\" and \"B100\" models are only valid for carrier frequencies\n        of 2.5GHz and 3.5GHz, respectively.\n\n    delay_spread : float\n        RMS delay spread [s].\n        The value must be in the range of 100ns to 3000ns.\n\n    carrier_frequency : float\n        Carrier frequency [Hz].\n\n    ut_array : PanelArray\n        Panel array used by the UT.\n        PanelArray objects can be reused for several models.\n\n    bs_array : PanelArray\n        Panel array used by the BS.\n        PanelArray objects can be reused for several models.\n\n    direction : str\n        Link direction. Must be either \"uplink\" or \"downlink\".\n\n    min_speed : float\n        Minimum speed [m/s].\n        Defaults to 0.\n\n    max_speed : None, float\n        Maximum speed [m/s].\n        Defaults to None, i.e., the maximum speed is 150m/s\n        (only valid for \"A\" model).\n\n    dtype : Complex\n        Defines the datatype for internal calculations and the output\n        dtype. Defaults to `tf.complex64`.\n\n    Input\n    -----\n\n    batch_size : int\n        Batch size\n\n    num_time_steps : int\n        Number of time steps\n\n    output_sampling_frequency : float\n        Output sample frequency [Hz]\n\n    Output\n    -------\n        a:[batch size,  num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps ] tf.complex\n            Path coefficients\n\n        b:[batch size,  num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps ]\n            Path coefficients\n\n        tau:[batch size,  num_rx, num_tx, num_paths ]\n            Path delays [s]\n    \"\"\"\n\n    def __init__(   self,\n                    model,\n                    delay_spread,\n                    carrier_frequency,\n                    ut_array,\n                    bs_array,\n                    direction,\n                    min_speed=0.,\n                    max_speed=None,\n                    dtype=tf.complex64):\n\n        assert direction in (\"uplink\", \"downlink\"), \\\n            \"The `direction` must be 'uplink' or 'downlink'\"\n        self.direction = direction\n\n        # Set the file from which to load the model\n        if model == \"A30\" or model == \"B100\":\n            if model == \"A30\":\n                assert carrier_frequency==2500e6, \\\n                \"The `A30` model only valid for carrier frequency 2.5GHz\"\n            if model == \"B100\":\n                assert carrier_frequency==3500e6, \\\n                \"The `B100` model only valid for carrier frequency 3.5GHz\"\n            model_file = \"A\"\n        else:\n            model_file = model\n\n        self._load_model(model_file, delay_spread)\n\n        # Setting the antenna arrays for the BS and the UT\n        self._set_array(ut_array, bs_array)\n\n        # Frequency in [Hz]\n        self.carrier_frequency = carrier_frequency\n\n        # Panel polarizarion setting. \"V\" for the UT arrays means \"crossVH\"\n        if ut_array.polarization == \"V\":\n            ut_array.polar_pattern = \"crossVH\"\n        # \"H\"  means \"crossHV\"\n        elif ut_array.polarization == \"H\":\n            ut_array.polar_pattern = \"crossHV\"\n        else:\n            ut_array.polar_pattern = ut_array.polarization\n\n        # Minimum / Maximum speed of the UT\n        self.min_speed = tf.cast( min_speed, dtype.real_dtype)\n        if max_speed is None:\n            # Value of None is casted to tf.float32 for XLA compatibility\n            self.max_speed = tf.cast( 120. / 3.6, dtype.real_dtype)\n        else:\n            self.max_speed = tf.cast( max_speed, dtype.real_dtype)\n\n        # The spatial correlation is not implemented. The following\n        # variables would be needed.\n        # self._rho_v = rho_v\n        # self._rho_h = rho_h\n        # self .l_v  = l_v\n        # self.l_h  = l_h\n\n        # Delay spread in [s]\n        self._delay_spread = delay_spread\n\n        # RMS delay spread (std. deviation) for the rician and non-rician\n        # components. In the event of a Rician distribution, this is\n        # the standard definition of the RMS delay spread [3GPP TR 38.901,\n        # V16.1.0, \"R1-28a (RMS)\"].\n        d = self._delay_spread*1e9    # in ns\n        self.rms_delay_spread_rician = np.sqrt( (d/12.)**2 + (d/10.)**2 )\n        self.rms_delay_spread_nonrician = self.rms_delay_spread_rician\n\n        # Rician factor\n        self.rician_factor = self.r_0**2 / ( self.r_0**2 + self.a**2)\n\n        self.dtype = dtype\n        if dtype.is_complex:\n            self._j = tf.complex(0,1)\n        super().__init__(dtype=dtype)\n\n#     @property\n#     def delay_spread(self):\n#         \"\"\"RMS delay spread [s]\"\"\"\n#         return self._delay_spread\n#\n#     @property\n#     def cluster_delay_spread(self):\n#         \"\"\"Cluster delay spread [s]\"\"\"\n#         return self._cluster_delay_spread\n#\n#     @property\n#     def n_rician_channels(self):\n#         \"\"\"Number of Rician channels. 0,1, or 2\"\"\"\n#         return self._n_rician_channels\n\n    def __call__(self, batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant,\n                        num_time_steps, output_sampling_frequency):\n\n        if self.direction == \"uplink\":\n            num_ut = num_tx\n            ut_array = True\n            bs_array = False\n        elif self.direction == \"downlink\":\n            num_ut = num_rx\n            ut_array = False\n            bs_array = True\n        rician = RicianBlockFading( rician_factor=self.rician_factor,\n                                    time_sampling=output_sampling_frequency,\n                                    num_time_steps=num_time_steps,\n                                    delay_s=self._delay,\n                                    delay_spread=self._delay_spread,\n                                    los=False,\n                                    specular_runners=0,\n                                    num_tx = 1,\n                                    num_rx = num_ut,\n                                    tx_array=ut_array,\n                                    rx_array=bs_array,\n                                    spatial_correlation=None,\n                                    disable_automatic_shape_inference=True,\n                                    dtype = self.dtype)\n        channel_coeff, channel_delay = rician( batch_size,\n                                                num_rx,\n                                                num_rx_ant,\n                                                num_tx,\n                                                num_tx_ant)\n\n        # Rotate the phase of the channel coefficients based on the\n        # scattering objects angles\n        channel_coeff = self._phi0_ao + self._phi_diff_a * channel_coeff\n\n        # Add non-line-of-sight component (only valid for the uplink)\n        if self.direction == \"uplink\":\n            a = self.a\n            phi_r = tf.random.uniform(  (   batch_size,\n                                            1,\n                                            1,\n                                            1,\n                                            num_rx,\n                                            num_rx_ant,\n                                            num_tx,\n                                            num_tx_ant),\n                                            minval = -tf.constant(np.pi, self.dtype),\n                                            maxval = tf.constant(np.pi, self.dtype) )\n            x_nlos =   (   a*tf.exp((1/self.rms_delay_spread_nonrician)\n                                    * (   self._delay_ung_rn\n                                        * tf.cast(   tf.range( 0, self.n_nlos ),\n                                                    dtype=self.dtype)\n                                        - phi_r)\n                                * (   2.*np.pi\n                                    * tf.cast(   tf.range( 0, self.n_nlos ),\n                                                        dtype=self.dtype)\n                                    / self.carrier_frequency) )\n                        / tf.cast(tf.sqrt(   tf.range(0, self.n_nlos+1,\n                                                    dtype=self.dtype)),\n                                    self.dtype)\n                    )\n            x_nlos = tf.complex(x_nlos, tf.zeros_like(x_nlos))\n            x_nlos = tf.reduce_sum(x_nlos, axis=-2)\n            x_nlos = tf.transpose(x_nlos, [0, 1, 2, 5, 6, 3, 4])\n            channel_coeff = tf.concat([channel_coeff, x_nlos], axis=-2)\n\n        # Normalize energy. The energy per channel tap is 1/2 as the\n        # channel coefficients are the real and imaginary\n        # components of a CN random variable with variance 1.\n        # The total energy is 1, but we want the energy per real\n        # valued coefficient.\n        e = tf.constant(1./tf.cast(2., self.dtype.real_dtype),\n                        shape= tf.shape(channel_coeff)[:-1])\n        channel_coeff = tf.complex( tf.multiply(e,tf.math.cos(channel_coeff)),\n                                    tf.multiply(e,tf.math.sin(channel_coeff)) )\n\n        # Keep the delay of the first sample constant by adding\n        # the phase shift, as the channel_delay can be negative.\n        # This does not change the statistics of the channel, but\n        # all the channel taps of a single path arrive now\n        # slightly earlier.\n        channel_coeff *= tf.exp( -self._j * self._phi_diff_a * channel_delay[0])\n\n        # If the UT is moving, the receive spatial correlation becomes\n        # temporally uncorrelated after a certain number of\n        # time steps. To simulate this, we update the spatial\n        # covariance matrix of the receiver for every\n        # sampling instant. Please note that this is only an\n        # approximation. The position of the transmitter would also\n        # have an impact, but this is not considered here.\n        if self.min_speed > 0.:\n            c_time = tf.mod(   tf.range(num_time_steps)\n                                /output_sampling_frequency, self._delay_spread)\n            exp = tf.exp(-self._j*2.*np.pi\n                        * self._phi_diff_a * c_time)\n            exp = tf.complex(exp, tf.zeros_like(exp))\n            r =  self._l * self._l \\\n                    * exp \\\n                    * tf.transpose(channel_coeff, [0,1,5,2,6,3,4])\n            r = tf.matmul(r, channel_coeff, adjoint_a=True)\n            r = tf.ensure_shape(r, [   batch_size,\n                                    num_rx,\n                                    num_rx_ant,\n                                    num_rx,\n                                    num_rx_ant])\n            r = tf.cast(r, self.dtype)\n            channel_coeff = r + self._g\n\n        # Spatial correlation\n        # We do not need to apply the spatial covariance matrix to the\n        # channel coefficients as there is only a single RX and TX.\n        # Therefore, this is left un-implemented.\n\n        # Generate the topology\n        # The UT and the BS are equipped with multiple antenna panels\n        # that are regularly spaced\n\n        if self.direction == \"uplink\":\n            bs_panel = PanelArray( num_rows_per_panel = 1,\n                                    num_cols_per_panel = bs_array.num_cols,\n                                    polarization = \"cross\",\n                                    polarization_type = \"V\",\n                                    antenna_pattern = \"38.901\",\n                                    carrier_frequency = self.carrier_frequency)\n            ut_panel = PanelArray(   num_rows_per_panel = 1,\n                                    num_cols_per_panel = ut_array.num_cols,\n                                    polarization = ut_array.polarization,\n                                    polarization_type = ut_array.polarization_type,\n                                    antenna_pattern = ut_array.antenna_pattern,\n                                    carrier_frequency = self.carrier_frequency)\n        else:\n            ut_panel = PanelArray(   num_rows_per_panel = ut_array.num_rows,\n                                    num_cols_per_panel = 1,\n                                    polarization = \"cross\",\n                                    polarization_type = \"V\",\n                                    antenna_pattern = \"38.901\",\n                                    carrier_frequency = self.carrier_frequency)\n            bs_panel = PanelArray(   num_rows_per_panel = bs_array.num_rows,\n                                    num_cols_per_panel = 1,\n                                    polarization = bs_array.polarization,\n                                    polarization_type = bs_array.polarization_type,\n                                    antenna_pattern = bs_array.antenna_pattern,\n                                    carrier_frequency = self.carrier_frequency)\n\n        # the UT and the BS are equipped with antenna panels that are\n        # regularly spaced\n        sep = self._pi * self.inter_panel_sep / self.carrier_frequency\n        bs_panel.set_discretized_pattern(\"38.901\", \"V\", sep=sep)\n        ut_panel.set_discretized_pattern(\"38.901\", ut_array.polarization,\n                                            sep=sep)\n\n        # the orientation of the antenna panels is controlled via the\n        # angle alpha. A single UT is served by a single BS panel\n        # ut_array = PanelArray(1,1,\"V\",\"V\",\"38.901\",3.5e9)\n        # bs_array = PanelArray(1,1,\"dual\",\"VH\",\"38.901\",3.5e9)\n        # c = Channel(   r_0 = 10.0,\n        #                 r_v = r_v,\n        #                 r_h = r_h,\n        #                 ut_array = ut_array,\n        #                 bs_array = bs_array,\n        #                 scenario = \"0\",\n        #                 carrier_frequency = 3.5e9)\n        # t,l = c.tr38901_topology(8,0,90)\n        # [panel,panel] transmitters = t\n        # [panel,panel] receivers = l\n        # [n_rx, n_rx_ant, n_tx, n_tx_ant, n_paths, n_time_steps]\n        # tf_cov_mat   = c.spatial_covariance_matrix(  [16, 2, 1, 2, 28, 1])\n        #               .\n        #               .\n        #               .\n        #               .\n        #               .\n        #               .\n        #               .\n        #           .\n        #       .\n\n        if self.direction == \"uplink\":\n            ut_sep = self._pi*ut_array.num_rows/bs_array.num_cols\n            r = tf.range(ut_array.num_rows)\n            t, l = tf.linalg.eigh_cov(self._phi_diff_los_cov(\n                                            r,\n                                            \"ut\",\n                                            \"panel\",\n                                            ut_sep,\n                                            \"V\"))\n        else:\n            bs_sep = self._pi*bs_array.num_cols/ut_array.num_rows\n            c = tf.expand_dims(tf.range(bs_array.num_cols), -1)\n            t, l = tf.linalg.eigh_cov(self._phi_diff_los_cov( c,\n                                            \"bs\",\n                                            \"panel\",\n                                            bs_sep,\n                                            \"V\"))\n        t = tf.cast(t, dtype.real_dtype)\n        l = tf.cast(l, dtype.real_dtype)\n        t = tf.expand_dims(t, axis=-1)\n        t = tf.tile(t, [ batch_size, 1, num_rx, num_rx_ant*num_tx, 1])\n        l = tf.expand_dims(l, axis=-1)\n        l = tf.tile(l, [ batch_size, 1, num_rx, num_rx_ant*num_tx, 1])\n        l = tf.sqrt(l)\n\n        if self.direction == \"uplink\":\n            ut_sep = self._pi*ut_array.num_rows/bs_array.num_cols\n            r = tf.range(ut_array.num_rows)\n            t, l = self._dumps_diff_los_cov(   r,\n                                                ut_sep,\n                                                \"V\",\n                                                t,\n                                                l)\n        else:\n            bs_sep = self._pi*bs_array.num_cols/ut_array.num_rows\n            c = tf.expand_dims(tf"
"To handle an AssertionError raised when the input encoding matrix is not valid in the `LinearEncoder`, you can use a try-except block. In the try block, you can attempt to create an instance of the `LinearEncoder` with the provided matrix input. If the matrix is not valid, this would raise an AssertionError. In the except block, you can catch this error and handle it, for example, by printing an error message to the console.\n\nHere is an illustrative Python code snippet:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n\n# Attempt to create a LinearEncoder instance with a potentially invalid matrix\ntry:\n    # Provide your matrix, this is a placeholder (you should provide a real matrix)\n    enc = LinearEncoder(enc_mat = [[1, 1, 1, 1], \n                                   [1, 0, 1, 0]])\n\n# Handle an AssertionError if the matrix is not valid\nexcept AssertionError as e:\n    # Print an error message to the console\n    print(\"An AssertionError occurred when using LinearEncoder:\", e)\n    # Additional error handling code can be added here as per the requirements\n    ...\n```\n\nIn this code: \n\n1. The `LinearEncoder` is initialized with a matrix that might not be valid. \n2. If the matrix is valid, the code execution will continue. \n3. If the matrix is not valid and an `AssertionError` is raised, the code execution will jump to the except block.\n4. In the except block, the `AssertionError` and its message are printed. \n\nPlease note that you should replace the `enc_mat` with a valid encoding matrix in the actual code. The matrix provided in the snippet is just a placeholder and might not be valid in the context of the `LinearEncoder`. When a valid encoding matrix is provided, the code execution following the try-except block will depend on the rest of the code and the context in which the `LinearEncoder` is used."
"7.4 - Given the context information and the provided code snippet, the most likely use of 'Sionna' is for wireless channel modeling since the code snippet is a part of an implementation for simulating wireless communication. \n\nHere is an example of a paper utilizing 'Sionna':\n\nT. Hejazi, P. Baracchi, M. Hettiarachchi, V. Giannini, F. Rusek, and M. Zorzi, \u201cDeepMIMO: A Generic Deep Learning Dataset for Millimeter Wave and Massive MIMO Applications\u201d, in Proc. of Int. Conf. Mach. Learn., Workshop on Mach. Learn. for SM"
"To add a transmitter and receiver to the scene and compute the propagation paths in Sionna, follow these steps:\n\n1. **Import necessary modules and set up environment**:\n   You need to import the necessary Sionna modules. Also, set the environment variables if required.\n\n2. **Create a Scene**:\n   First, you need to create a scene. A scene consists of multiple scene objects like buildings, cars, etc. You can create a scene using the `Scene` class of the `sionna.rt` module. Then, add scene objects to the created scene.\n\n3. **Add a Transmitter**:\n   To add a transmitter to the scene, create a `Transmitter` instance and add it to the `Scene` instance. The transmitter needs a unique name, a position, and an orientation. The `Transmitter` class is a predefined class in the Sionna API.\n\n4. **Add a Receiver**:\n   Similar to adding a transmitter, you can add a receiver. Create a `Receiver` instance and add it to the `Scene` instance. The receiver needs a unique name, a position, and an orientation. \n\n5. **Set Frequency**:\n   Set the frequency of the scene to the desired value. All propagation paths will be computed for this frequency.\n\n6. **Compute Propagation Paths**:\n   After adding the transmitter and receiver to the scene, you can compute the propagation paths. Use the `compute_paths()` method of the `Scene` instance to compute the paths for a specific configuration. \n\n7. **(Optional) Set Simulation Parameters**:\n   You can set simulation parameters like the number of samples, whether to apply Doppler, and other parameters as per your requirement.\n\nThe code snippets provided in the 'For demonstration, let us consider the following:' section can be used as a reference. Also, the context provides code for each of the above steps. Make sure to adapt the code to match your specific use case. \n\nRemember, the Sionna API may get updated, and the code referenced in the context may become outdated. Thus, it's essential to refer to the latest version of the Sionna documentation or release notes for any API changes."
"To use the FastFadingChannel class in Sionna, follow these steps:\n\n1. Import the FastFadingChannel class from the sionna.channel module.\n\n```python\nfrom sionna.channel import FastFadingChannel\n```\n\n2. Create an instance of the FastFadingChannel, providing the necessary arguments. The `generator` argument should be set to a string indicating which fast fading generator to use. Options include `tf` for using TensorFlow's own implementation of the Rayleigh fading, and `keras` for using an implementation based on Keras layer.  \n\n```python\nff = FastFadingChannel(generator=\"tf\")\n```\n\n3. Initialize the channel with parameters such as the number of receivers (`num_rx`), number of antennas per receiver (`num_rx_ant`), number of transmitters (`num_tx`), number of antennas per transmitter (`num_tx_ant`), and the spatial correlation (`spatial_corr`). \n\n```python\nNUM_RX = 1\nNUM_RX_ANT = 1\nNUM_TX = 1\nNUM_TX_ANT = 1\nspatial_corr = \"no_corr\"\nff.init(sizes=[batch_size, num_rx, NUM_RX_ANT, num_tx, NUM_TX_ANT, num_streams_per_tx], spatial_corr=spatial_corr)\n```\n\n4. Implement a FOFM channel, the so-called OFDMChannel, by reshaping the channel frequency responses and applying them to the channel inputs. \n\n```python\nchannel_freq = tf.constant(h, dtype=Out.dtype)\nchannel_freq = tf.cast(channel_freq, dtype=Out.dtype)\nx = tf.constant([[\n    [[1+1j, 1+1j, 1+1j]],\n    [[1+1j, 1+1j, 1+1j]]\n]]*batch_size, dtype=channel_freq.dtype)\n\nX = tf.reshape(x, [-1, num_tx, num_streams_per_tx])\nx_cp = tf.cast(tf.expand_dims(X, 2), dtype=Out.dtype)\ny = tf.squeeze(tf.matmul(channel_freq, x_cp), 2)\n\nh_hat = tf.squeeze(ff.h_hat, axis=-1)\ny = tf.expand_dims(y, -1)\ny_bar = tf.squeeze(tf.matmul(h, y), -1)\n```\n\nEnsure you replace the placeholders such as `batch_size`, `h`, and `Out` with actual values as per your implementation. \n\nThe details of `spatial_corr` and `num_streams_per_tx` have not been provided and would need to be defined based on the specific use case. \n\nFor simulating channel (for instance, with the function `cir_to_ofdm_channel`), utilizing the channel model, and applying the channel to channel inputs,  is shown:\n\n5. Simulate a channel time sample by sample using `__call__()` method. \n\n```python\ncir = [a, tau]\na = tf.cast(tf.expand_dims(cir, axis=-1), dtype=channel_freq.dtype)\ntau = tf.cast(tau, dtype=channel_freq.dtype)\nh = a * tf.exp(-tau * time / (1e-9))\nh = tf.squeeze(h, axis=-1)\nh = tf.expand_dims(h, axis=-2)\n```\n\n6. Compute the channel frequency response. \n\n```python\n    h = tf.squeeze(h, axis=-2)\n    h = tf.expand_dims(h, axis=-1)\n    f = exp(j 2 pi fo t)  # Transmitter\n    h_f = h * f\n```\n\n7. Apply the channel to channel inputs. \n\n```python\nx = tf.squeeze(x, axis=-1)\nx_bar = x  # Remember to use the \u201c\u201d\u201dx\u201d\u201d corresponding to your system.\ny_tilde = tf.expand_dims(tf.reduce_sum(h_f * x_bar, axis=-1), axis=-1)\n```\n\nThis is a basic example, and the actual implementation may vary based on the specific requirements, data types, and other parameters of the communication system."
"Here is the detailed information of  LambertianPattern:   \n  \n[sionna.rt.LambertianPattern(dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/rt/scattering_pattern.html#LambertianPattern)  \nLambertian scattering model from Degli-Esposti07 as given in (40)\n  \nAs in [Degli-Esposti07], we assume the surface normal of the scattering surface is $\\hat{\\mathbf{z}}$.\n  \nParameters\n\n- **dtype** (tf.complex64 or tf.complex128) \u2013 Defines the datatype for internal calculations and the output datatype. Defaults to tf.complex64.\n\nInput\n\n- **k_i** ([batch_size, 3], tf.float) \u2013 The incoming direction.\n- **k_s** ([batch_size,3], tf.float) \u2013 The outgoing direction.\n\nOutput\n\n- **pattern** ([batch_size], tf.float) \u2013 The scattering pattern.\n\nExample\n```python\nLambertianPattern().visualize()\n```\n\n[Result](https://nvlabs.github.io/sionna/_images/LambertianPattern_3D-1.png)\n3D visualization of the scattering pattern.  \n  \n[Result](https://nvlabs.github.io/sionna/_images/LambertianPattern_cut-1.png)  \nVisualization of the incident plane cut through the scattering pattern.  \n  \n\n**Note:**\nThe ScatteringPatternModule makes a LambertianPattern uniquely differentiable, by approximating the scattering lobe with a differentiable function. This is, however, only an approximation of the true scattering pattern. For training highly oblique models, this approximation may lead to a practical disadvantage.\n\nThis module is automatically used by the ScatteringLayer if you set the parameter diffable to True.  \n  "
"source code:  [DemapperWithPrior](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#DemapperWithPrior)  \n```python\n#\n# SPDX-3.0 License\n#\n# Copyright 2021-2024 The Sionna Authors. All rights reserved.\n#\n# https://sionna.rtfd.org/\n#\n\"\"\"Class and function definitions for the sionna mapping component.\n\"\"\"\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Layer\nimport numpy as np\n\nfrom . import  Constellation\n\nclass DemapperWithPrior(Layer):\n    r\"\"\"\n    DemapperWithPrior(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    Computes log-probabilities (logits) or hard-decisions on bits for a\n    tensor of received symbols, assuming that prior knowledge on the bits is available.\n\n    This class defines a demapper that produces `logits` on bits\n    when soft-decisions are requested. Hard-decisions are simply the\n    (bit-)  output of the :math:`\\operatorname{signum}` function applied to the real\n    and imaginary parts of the demapped symbol, respectively.\n    Prior to demapping, the received symbols are whitened (or\n    equivalently the constellation is pre-processed, see :func:`~sionna.mapping.Constellation.whiten`).\n    An option is provided to indicate whether the constellation should be\n    flipped to for example enable Demapper II decoding.\n    Using the prior information, the Demapper computes log-probabilities according to\n\n    .. math::\n        \\ln\\left(\\Pr\\left(b = 1 \\lvert y,\\mathbf{p}\\right)\\right) = \\ln\\left(\\Pr\\left(y \\lvert b = 1, \\mathbf{p}\\right)\\right) + \\ln\\left(\\Pr\\left(b=1 \\right)\\right)\n    :   = \\ln\\left(\\sum_{c \\in \\mathcal{C}_{b}} \\Pr\\left(y \\lvert c,\\mathbf{p}\\right) \\right) +\\ln\\left(\\Pr\\left(b=1 \\right)\\right)\n    where :math:`\\mathcal{C}_{b}` is the set of constellation points for which the bit value equal to :math:`b`.\n    The probability mass function of the constellation point :math:`c` is assumed to be\n    :math:`\\Pr\\left(c\\right)`, the prior of the bit value :math:`b` is taken to be\n    either 0 or 1 and is denoted by :math:`\\Pr\\left(b\\right) = e^{p_b}`.\n    It is assumed that the symbol ``y`` is the result of :func:`~sionna.mapping.SymbolWithPrior`\n    where the prior information on the constellation point is provided.\n    Using the above definition, the logits for the $i\\text{th}$ bit of the\n    vector of bits $\\mathbf{b}$ just prior to demapping are\n\n    .. math::\n        \\ln\\left(\\frac{\\Pr\\left(b_i=1 \\lvert \\mathbf{y},\\mathbf{p}\\right)}\n                {\\Pr\\left(b_i=0 \\lvert \\mathbf{y},\\mathbf{p}\\right)}\\right)\n        =\\ln\\left(\\frac{\n            \\sum_{c \\in \\mathcal{C}_{i,1}} \\Pr\\left(y \\lvert c,\\mathbf{p}\\right)\n            \\exp\\left(p_c\\right)\n            }{\n            \\sum_{c \\in \\mathcal{C}_{i,0}} \\Pr\\left(y \\lvert c,\\mathbf{p}\\right)\n            \\exp\\left(p_c\\right)\n            }\\right)\n\n    The class can be configured with the :class:`~sionna.mapping.Constellation`\n    object or by explicitly setting ``constellation_type``\n    or ``num_bits_per_symbol``.\n\n    Parameters\n    -----------\n    demapping_method : str, one of [\"app\", \"maxlog\"]\n        The demapping method used.\n\n    constellation_type : str, one of [\"qam\", \"pam\", \"custom\"], None\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or None.\n        If None, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If True, the demapper provides hard-decided bits instead of soft-values.\n        Defaults to False.\n\n    dtype : tf.complex64, tf.complex128\n        The dtype of ``y``. Defaults to tf.complex64.\n\n    Input\n    -----\n    (y, prior, no) :\n        Tuple:\n\n    y : [...,n], tf.complex\n        The received symbols.\n\n    prior : [num_bits_per_symbol] or [...,num_bits_per_symbol], tf.float\n        Prior for every bit as log-probabilities (logits).\n        It can be provided either as a tensor of shape\n        ``[num_bits_per_symbol]`` for the entire input batch, or\n        as a tensor that is broadcastable to\n        ``[..., n, num_bits_per_symbol]``.\n\n    no : Scalar or [...,n], tf.float\n        The noise variance estimate. It can be provided either as scalar\n        for the entire input batch or as a tensor that is broadcastable to\n        ``y``.\n\n    Output\n    ------\n    : [...,n*num_bits_per_symbol], tf.float\n        Logits or hard decisions for every demapped bit.\n\n    Note\n    ----\n    With the \"app\" demapping method, prior information is not exploited for\n    demapping to individual bits to avoid potential labeling conflicts\n    (see [JHGT2017]_ for details).\n    \"\"\"\n    def __init__(self,\n                 demapping_method,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        assert dtype in [tf.complex64, tf.complex128],\\\n            \"dtype must be tf.complex64 or tf.complex128.\"\n\n        # Create constellation object\n        self._constellation = Constellation.create_or_check_constellation(\n                                                        constellation_type,\n                                                        num_bits_per_symbol,\n                                                        constellation,\n                                                        dtype=dtype)\n\n        self.demapping_method = demapping_method\n        self.hard_out = hard_out\n\n    # Property\n    @property\n    def constellation(self):\n        return self._constellation\n\n    def call(self, inputs):\n        if self.demapping_method==\"maxlog\":\n            llr = self._constellation.maxlog_exponent(inputs,\n                                                       hard_out=self.hard_out)\n        else:\n            llr = self._constellation.approximate_llr(inputs,\n                                                      prior=None,\n                                                      hard_out=self.hard_out)\n\n        return tf.reshape(llr, [-1, self._constellation.num_bits_per_symbol])\n\n    @property\n    def num_bits_per_symbol(self):\n        if self._constellation is not None:\n            return self._constellation.num_bits_per_symbol\n        else:\n            return None\n\n    # The following code is required to enable setting the constellation\n    # through the Keras layer set method. We cannot simply set\n    # self.constellation because an assertion is raised.\n\n    def set_constellation(self, value):\n        if isinstance(value, Constellation):\n            assert value._dtype==self.dtype,\\\n                \"Constellation has not the correct dtype.\"\n            self._constellation = value\n        else:\n            raise TypeError(\"Wrong type. Constellation must be an instance of Constellation.\")\n\n\n    @property\n    def demapping_method(self):\n        return self._demapping_method\n\n    @demapping_method.setter\n    def demapping_method(self, value):\n        assert value in [\"app\",\"maxlog\"], \"Invalid demapping method.\"\n        self._demapping_method = value\n\n    @property\n    def hard_out(self):\n        return self._hard_out\n\n    @hard_out.setter\n    def hard_out(self, value):\n        assert isinstance(value, bool), \"hard_out must be bool.\"\n        self._hard_out = value\n        self._constellation.hard_out = value\n```  \n  "
"To understand the `TB5GScrambler` class, we should look into several aspects:\n\n### I. Class and Parameters\n\n1. **Class Name in the Module**: The provided context shows that the class belongs to `sionna.fec.scrambling` module. The class name is `TB5GScrambler`.\n\n2. **Instantiation Parameters**: During the creation of the class instance, these parameters are needed:\n    - `n_rnti` (int or list of ints): RNTI identifier. Defaults to 1. Range is [0, 65335].\n    - `n_id` (int or list of ints): Scrambling ID related to cell id. Defaults to 1. Range is [0, 1023].\n    - `binary` (bool): If False, the scrambler uses $+$-1 values instead of 0,1. Defaults to True.\n    - `channel_type` (str): Can be \"PUSCH\" or \"PDSCH\".\n    - `codeword_index` (int): Can be 0 or 1. Only needed for PDSCH.\n    - `dtype` (tf.DType): Specifies the datatype for internal calculations and the output.\n\n### II. Input and Output\n\n1. **Inputs**:\n    - (x, binary): Tuple or Tensor:\n        - `x` (tf.float): Tensor of arbitrary shape.\n        - `binary` (bool): Overrules the init parameter 'binary' if explicitly given. Indicates whether bit-sequence should be flipped (i.e., binary operations are performed) or the signs should be flipped (i.e., soft-value/LLR domain-based).\n\n2. **Output**:\n    - `Output (tf.float)`: 1+D tensor of same shape as input `x`.\n\n### III. Properties\n\n1. **Property: `keep_state`**.\n    - Required for descrambler, is always True for the `TB5GScrambler`.\n\n### IV. Method: `descrambler()`\n\nThe class provides a related Descrambler. This function implements the inverse scrambling operation. It can be provided with the parameters and called to get the descrambled output.\n\n### V. Related Configs and Constants: Radio Network Temporary Identifier (RNTI), Scrambling ID (`n_id`), Datascrambling ID (`n_id`), PUSCH Configuration, PDSCH Configuration.\n\nAs you get more familiar with the class, you should also explore how it's used in the system, how the parameters influence the class behavior, and any requirements on the data you're processing. \n\nThis analysis could be supplemented by looking into the actual code of the class, if available, and observing how it's used in the larger context of the project. \n\nAs shown in the code, typical usage within a Keras model would be something like this:\n\n```python\ntb_scrambler = TB5GScrambler()\ntb_descrambler = tb_scrambler.descrambler()\nscrambled_bits = tb_scrambler([cw, rnti])\n# Use within a Keras model.\ndescrambled_bits = tb_descrambler(scrambled_bits)\n```"
"To encode random input bits in Sionna, follow the steps below:\n\n1. First, set up the environment and import the necessary packages. This includes importing the Sionna package and all its sub-packages. If the Sionna package is not already installed, you can install it using pip.\n\n2. Initialize the binary source. This is done using the `sionna.utils.BinarySource()` function. The binary source is used to generate the random input bits.\n\n3. Next, create the encoder. In the context, an LDPC5G encoder is created using the `sionna.fec.ldpc.encoding.LDPC5GEncoder(k_ldpc, n_ldpc)` function, where `k_ldpc` and `n_ldpc` are the number of information bits and the codeword length respectively. You need to replace these parameters with the ones required by your specific encoding needs.\n\n4. Finally, encode the random bits using the encoder created in the previous step. The encoder is called with the random bits `b` as an argument to encode them into LDPC codewords. The LDPC codewords are then mapped to QAM constellation symbols prior to further processing.\n\nHere is the python code snippet from the context that describes the above steps:\n\n```python\nimport sionna\nimport numpy as np\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nfrom sionna.utils import BinarySource\n\n# initialize binary source\nbinary_source = BinarySource()\n\n# create encoder\nk_ldpc = 200 # Number of information bits\nn_ldpc = 500 # Codeword length\nencoder = LDPC5GEncoder(k_ldpc, n_ldpc)\n\n# generate random bit vector\nbatch_size = 8\nb = binary_source([batch_size, k_ldpc])\n\n# encode bits\nc = encoder(b)\n```\n\nPlease note that the above code is written exactly as it appeared in the context. Be sure to use the appropriate parameters for `k_ldpc` and `n_ldpc` that suit your needs. \n\nAdditionally, note that the LDPC5GEncoder is a specific encoder for 5G New Radio (LDPC) communications and may not be suitable for all kinds of binary bit encodings. Be sure to use the appropriate encoder for your specific use case."
"The `LMMSEEqualizer` class is part of the 'sionna.ofdm' module and is used for handling Orthogonal Frequency-Division Multiplexing (OFDM) Multiple-Input Multiple-Output (MIMO) transmissions. This class implements the Linear Minimum Mean Squared Error (LMMSE) equalization algorithm for OFDM MIMO systems.\n\nIn an OFDM MIMO system, a LMMSE equalizer is used to process the received signal. The received signal captures the data transmitted over multiple antennas and potentially from multiple input streams. The LMMSE equalizer uses the received signal along with some other parameters like the channel state information (CSI) and the noise variance to produce an estimate of the transmitted data. This estimation can subsequently be used for further data processing or decoding.\n\nSpecifically, the `LMMSEEqualizer` class accepts as parameters a resource grid and a stream management instance. The resource grid parameter, an instance of the `ResourceGrid` class, facilitates the manipulation of data and pilot symbols in the OFDM system. The stream management instance, employing the `StreamManagement` class, dictates which transmitters and streams are received by the current receiver, forming a decision rule for reception.\n\nThe `LMMSEEqualizer` must be fed with the received signals `y`, channel matrices `h_mat`, and noise variance `no`, which it uses to perform the LMMSE equalization, generating an estimate of the transmitted symbols `x_hat` and an estimate of the effective noise variance `no_eff`.\n\nAs the decision rules for stream reception in OFDM MIMO systems as well as the detection algorithm (e.g., LMMSE equalizer) might be different for individual receivers, it is essential to note that the `LMMSEEqualizer` class should be configured according to the specific OFDM MIMO setup and system specifications, which may vary."
"To get started with Sionna, you need to follow the installation guide on the official Sionna documentation (https://nvlabs.github.io/sionna/installation.html). This typically involves setting up your Python environment, CUDA, and cuDNN. Once that is done, you can proceed with installing Sionna and other necessary libraries. The documentation provides the code to install Sionna via pip:\n\n```python\npip install sionna\n```\n\nAs for the tutorial structure, it is divided into four parts:\n\n1. **Part I: Getting started with Sionna**\n\nThis part introduces the basic principles of Sionna, including the concept of differentiable communication systems. It guides users through the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. The tutorial also explains how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n\n2. **Part II: Differentiable Communication Systems**\n\nThis part delves into the principles of learning communication systems. It explains how to adapt the previously learned weights in the transmitter and receiver to a new setting. The tutorial also demonstrates the advantages of using eager execution, and shows how to evaluate the performance of a learned model.\n\n3. **Part III: Advanced Link-level Simulations**\n\nThis part focuses on advanced link-level simulations. It explains how to simulate the BER over a range of Eb/No, and how to find the best set of parameters for a model. The tutorial also shows how to implement a Keras model that stacks layers on top of each other, and how to use this model to make end-to-end link-level simulations.\n\n4. **Part IV: Toward Learned Receivers**\n\nThis part explores different design choices for neural receivers. It explains how to make a conventional receiver accessible to Keras, and how to implement the proposed neural receiver. The tutorial also shows how to train the end-to-end communication system using RL, and how to define a Keras layer from a mathematical formula.\n\nEach part is structured into different sections that explain various concepts and techniques. The tutorial also includes interactive examples that users can run and experiment with."
"To import the necessary modules from the Sionna package, you can follow these steps:\n\n1. Import the entire package using the `import` statement. In this case, you would use `sionna` as the package name.\n\n```python\nimport sionna\n```\n\n2. Import the required modules from the Sionna package. You can either import them individually or all at once. For individual import, you would use the `from ... import ...` statement.\n\n```python\nfrom sionna.nr import NRScrambler, Scrambler, \\\n                      NRDescrambler, Descrambler, \\\n                      LDPC5GEncoder, LDPC5GDecoder, \\\n                      Mapper, Demapper, \\\n                      MIMOChannel, MIMOChannelFrequencyDomain, \\\n                      OFDMChannel, OFDMChannelFrequencyDomain, \\\n                      GenerateOFDMChannel, ApplyOFDMChannel, \\\n                      Detection3GPPSymbol, DetectionLayer, \\\n                      Equalization3GPPSymbol, EqualizationLayer, \\\n                      KBestDetector, LinearDetector, \\\n                      NonlinearityDetector, PAMSource, \\\n                      Pairing\n```\n\nOr you can import all the necessary modules at once using the `*` wildcard.\n\n```python\nfrom sionna.nr import *\n```\n\n3. Additionally, you might need to import other modules that are not part of the Sionna package, such as `numpy`, `matplotlib.pyplot`, `tensorflow`, and `pickle`. These can be imported in a similar way.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport pickle\n``` \n\nPlease note that the above code assumes that the Sionna package is installed and configured correctly in your Python environment. If it's not, you would need to follow the package installation instructions and make sure that the necessary Sionna modules are accessible in your current Python session."
"To apply the gradient to the weights using an optimizer, you can follow these steps:\n\n1. First, you need to compute the gradient. This is done using the `tape.gradient` method inside a `with` block. This method takes the loss and the weights as inputs and returns the computed gradient.\n\nHere is the code snippet for computing the gradient:\n\n```python\nwith tf.GradientTape() as tape:\n    bits = binary_source([BATCH_SIZE, 1200]) # Blocklength\n    x = mapper(bits)\n    y = awgn_channel([x, no])\n    llr = demapper([y,no])\n    loss = bce(bits, llr)\ngradient = tape.gradient(loss, tape.watched_variables())\n```\n\n2. Once you have the gradient, you can apply it to the weights. This is done using the `apply_gradients` method of the optimizer. This method takes the gradient and the weights as inputs and applies the gradient to the weights.\n\nHere is the code snippet for applying the gradient:\n\n```python\noptimizer.apply_gradients(zip(gradient, tape.watched_variables()))\n```\n\n3. After applying the gradient, the weights are updated and you can use them for the next iteration.\n\nPlease note that the `optimizer` is an instance of the optimizer you want to use (in this case, `tf.keras.optimizers.Adam`), the `binary_source` is a layer that generates binary symbols, and the `bce` is the binary cross-entropy loss function. The `with` block is used to record the operations for computing the gradient."
"Here is the detailed information of qam:  [sionna.mapping.qam(num_bits_per_symbol, normalize=True, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#QAM)\n\nComputes the normalized QAM constellation. Normalization implies that $\\mathbb{E}\\left[|X|^2\\right]=1$.\n\n**Input**\n\n- `num_bits_per_symbol` (int): The number of bits per symbol, e.g., 4 for QAM16.\n- `normalize` (bool): If True, the constellation is normalized to have unit power. Defaults to True.\n- `dtype` (tf.DType): The dtype of the constellation. Defaults to tf.complex64.\n\n**Output**\n\n- `constellation` (1D array): An array of length 2^`num_bits_per_symbol` representing the constellation points.\n\nsource code:\n```python\ndef qam(num_bits_per_symbol, normalize=True, dtype=tf.complex64):\n    # pylint: disable=line-too-long\n    r\"\"\"Computes the normalized QAM constellation. Normalization implies that :math:`\\mathbb{E}\\left[|X|^2\\right]=1`.\n\n    Input\n    -----\n    num_bits_per_symbol : int\n        The number of bits per symbol, e.g., 4 for QAM16.\n\n    normalize : bool\n        If `True`, the constellation is normalized to have unit power.\n        Defaults to `True`.\n\n    dtype : tf.DType\n        The dtype of the constellation. Defaults to `tf.complex64`.\n\n    Output\n    ------\n    : [2^num_bits_per_symbol], tf.complex\n        The normalized QAM constellation.\n\n    \"\"\"\n    # Constellation values\n    symbols = _generate_qam_constellation(num_bits_per_symbol, dtype)\n\n    # Normalize if requested\n    if normalize:\n        symbols = normalize_power(symbols, reduce_dims=True)\n\n    return tf.cast(symbols, dtype)\n```"
"CLASS DEFINITION:\nHere is the definition of RandomInterleaver:\n```python\nclass RandomInterleaver(Layer):\n    \"\"\"RandomInterleaver(interleaver, seed=None, keep_batch_constant=True)\n    Interleaver that permutes a tensor with a random permutation.\n\n    The class inherits from the Keras layer class and can be used as layer\n    in a Keras model.\n\n    At instantiation, the class is configured with an \"interleaver\" configuration:\n    The ``interleaver`` can be any of the provided \"interleaver\" functions,\n    such as :func:`~interleaving.random_interleaver`, :func:`~interleaving.inverse_random_interleaver`,\n    :func:`~interleaving.binary_pseudo_ici`, or :func:`~interleaving.ici`,\n    or a custom :class:`~interleaving.Interleaver` callable object.\n    The callable object must implement the same input/output\n    data format as the ``interleaver`` function.\n\n    An optional seed ``seed`` can be used to get a repeatable random sequence.\n\n    Note that this layer does not support all-zero tensors ``c``.\n\n    Parameters\n    ----------\n    interleaver : callable\n        Fuction that interleaves the input tensor ``c`` of arbitrary shape.\n        The function must accept either a list ``[c, seed]`` or a ``[c, keep_batch_constant, seed]`` as inputs.\n        The parameter ``seed`` is optional and defaults to None.\n        ``seed`` is an integer and if set to `None`, a unique internal seed is used.\n\n    keep_batch_constant : bool\n        If set to `True`, the entire batch will be intereleaved with the same\n        permutation (seed must not be `None` in this case).\n        This is realized by using the same random seed for all samples in the\n        batch. Defaults to `True`.\n\n    seed : int\n        Integer that defines the random seed.\n        If set to `None`, a unique internal seed is used.\n        Note that the seed can be explicitly set for each call of the layer.\n        Defaults to `None`.\n\n    Input\n    -----\n    (c, seed) or c\n        Tensor of arbitrary shape ``c`` with arbitrary dtype.\n        ``seed`` is an integer defining the random seed and can be provided\n        as additional input to the list ``[c, seed]``.\n        Note that ``seed`` can be a list of integers for arbitrary rank to\n        broadcast to the rank of ``c``.\n\n    Output\n    ------\n    c'\n        Permuted tensor of the same shape and dtype as ``c``.\n\n    Raises\n    ------\n    AssertionError\n        If ``c`` is an all-zero tensor (while this is generally allowed, it\n        is explicitly disallowed for the `RandomInterleaver`).\n\n    Note\n    ----\n    If you want to use this layer in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sionna.Config.xla_compat=true``.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n    def __init__(self,\n                 interleaver,\n                 seed=None,\n                 keep_batch_constant=True,\n                 dtype=tf.float32,\n                 **kwargs):\n\n        if dtype not in (tf.float16, tf.float32, tf.float64, tf.int32,\n            tf.int64, tf.uint8, tf.uint16, tf.uint32):\n            raise TypeError(\"Unsupported dtype.\")\n\n        # as callable layer\n        super().__init__(dtype=dtype, **kwargs)\n\n        if not callable(interleaver):\n            if  interleaver not in _interleaver_dict[self._dtype]:\n                raise ValueError(\"Unknown interleaver.\")\n            _fn =  _interleaver_dict[self._dtype][interleaver]\n            (interleaver, _) = _fn(keep_batch_constant=keep_batch_constant,\n                                   seed=seed,\n                                   dtype=dtype)\n        else:\n            _ = interleaver(keep_batch_constant=keep_batch_constant,\n                             seed=seed,\n                             dtype=dtype)\n\n        self._interleaver = interleaver\n\n        if  isinstance( self._interleaver, list):\n            self._interleaver =  FunctionInterpolator( self._interleaver,\n                                                 axis=-1,\n                                                 output_dtype=dtype)\n\n##- if_devel_begin\n        if seed is not None:\n            if isinstance(seed, (tuple, list)):\n                if isinstance(keep_batch_constant, (tuple, list)):\n                    if not set(keep_batch_constant).issubset(set(seed)):\n                        raise ValueError(\"seed and keep_batch_constant \" \\\n                                          \"must have at least a common element.\")\n                else:\n                    keep_batch_constant = tf.cast(keep_batch_constant,\n                                                   dtype=seed[0].dtype)\n            else:\n                keep_batch_constant = tf.cast(keep_batch_constant,\n                                               dtype=seed.dtyp)\n                seed = (seed, keep_batch_constant)\n            broadcast_shape = tf.broadcast_to( tf.shape(seed[0]),\n                                                tf.shape(c))\n            c = tf.stack([c, broadcast_shape], axis=0)\n        ##- keep snapshot of seed (and adjust rank of c)\n            self._seed = seed\n            c = tf.stack([c, self._seed[0]], axis=0)\n        else: # create unique seed\n            self._seed = tf.stack([tf.fill(tf.shape(c), -1, c.dtype),\n                                   tf.fill(tf.shape(c), -1, c.dtype)], axis=0)\n\n        self._c = c\n##- else\n        self._seed = seed\n        self._c = tf.stack([c, tf.zeros_like(c)], axis=0)\n##- if_devel_end\n\n    #########################################\n    # Public methods and properties\n    #########################################\n\n    @property\n    def seed(self):\n        \"\"\"Seed used for the random permutation.\"\"\"\n        return self._seed[0] if self._seed is not None else None\n\n    def call(self, inputs):\n#         inputs,_ =  tf.unstack(inputs, 2) # ignore seed\n\n        if tf.reduce_min(inputs).numpy()==0:\n            raise AssertionError('All-zero tensors not supported by ' \\\n                                 'RandomInterleaver.')\n\n        # input must be at least 2D\n        if len(inputs.shape) < 2:\n            msg = 'c must be at least 2D (permutedim and batch-dim).'\n            tf_logger.warning(msg)\n            inputs = tf.reshape(inputs, (tf.reduce_prod(inputs.shape[:-1]), -1]))\n\n#         input_dtype = inputs.dtype\n#         if not isinstance(self._dtype, type(inputs) ):\n#             self._c = tf.cast(self._c, input_dtype)\n\n        x =  self._interleaver([inputs, self._seed], exact=True)\n\n        ##- keep seeding constant for all samples in batch\n        ### requires re-interleaving for each new random seed\n        ### x =  self._interleaver([inputs, self._seed, tf.constant(True)], exact=True)\n        return x\n```"
"Here is the detailed information of pam:   \n  \n[sionna.mapping.pam(num_bits_per_symbol, normalize=True)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#pam)  \n\nGenerates a PAM constellation. This function generates a real-valued vector, where each element is a constellation point of an M-ary PAM constellation. The bit label of the n th point is given by the length- num_bits_per_symbol binary represenation of n.\n\nInput\n\n    num_bits_per_symbol (int) \u2013 The number of bits per constellation point. Must be positive.\n    normalize (bool) \u2013 If True, the constellation is normalized to have unit power. Defaults to True.\n\nOutput\n\n    [2num_bits_per_symbol], np.float32 \u2013 The PAM constellation.\n\nNote\n\nThe constellation is not normalized as per the 3GPP standard. Please consider the normalization factor as $\\sqrt{\\frac{1}{2^{n-1}}\\sum_{i=1}^{2^{n-1}}(2i-1)^2}$ where $n$ is num_bits_per_symbol.  \nsource code:  \n```python\ndef pam(num_bits_per_symbol, normalize=True):\n    # pylint: disable=line-too-long\n    r\"\"\"Generates a PAM constellation.\n\n    This function generates a real-valued vector, where each element is\n    a constellation point of an M-ary PAM constellation. The bit\n    label of the `n` th point is given by the length-`num_bits_per_symbol`\n    binary represenation of `n`.\n\n    Input\n    -----\n        num_bits_per_symbol : int\n            The number of bits per constellation point.\n            Must be positive.\n\n        normalize : bool\n            If `True`, the constellation is normalized to have unit power.\n            Defaults to `True`.\n\n    Output\n    ------\n    : [2**num_bits_per_symbol], np.float32\n        The PAM constellation.\n\n    Note\n    ----\n     The constellation is not normalized as per the 3GPP standard [W38211]_.\n     Please consider the normalization factor as\n\n     .. math::\n\n        \\sqrt{\\frac{1}{2^{n-1}}\\sum_{i=1}^{2^{n-1}}(2i-1)^2}\n\n     where :math:`n` is ``num_bits_per_symbol``.\n    \"\"\"\n    # The 3GPP normalization factor for PAM constellations\n    norm_factor = np.sqrt(1/np.var(np.arange(-2,2,4/2**num_bits_per_symbol),ddof=1))\n\n    points = np.array( [2*i + 1 for i in range(2**num_bits_per_symbol//2)]  , np.float32)\n    points = points*norm_factor\n\n    # Binary label\n    bin_label = np.array( format(i, '0'+str(num_bits_per_symbol)+'b') for i in range(2**num_bits_per_symbol))\n    bin_label = np.array(list(map(int, bin_label)))\n    points = np.stack((points, bin_label),  axis=-1 )\n\n    # Flatten the last dimensions\n    points =  points.reshape((-1, 2))\n\n    # Gray mapping\n    if num_bits_per_symbol>1:\n        last = np.copy(points)\n        # pylint: disable=unspecified-encoding\n        points = graycode.bin2gray(last[:,-1::-1])\n        points = points.astype(np.float32)\n        # Flip MSB as its actually LSB and flip the array\n        points = np.concatenate([ (1-last[:,0:1]).numpy()[:,::-1], points], axis=1)\n\n    if normalize:\n        # Normalize the energy per symbol to 1\n        e = np.var(points,  ddof=1)\n        e = np.sqrt(e)\n        e = np.cast[np.float32](1)/e\n        points = tf.cast(e, points.dtype) * points\n\n    return points\n```  \n  "
"The parameters `return_crc_status` and `output_dtype` in the class `Polar5GDecoder` of the Sionna library are used for setting specific properties in the decoder.\n\nThe `return_crc_status` parameter is a boolean type, meaning it can either be `True` or `False`. This parameter is used to request the decoder to return the Cyclic Redundancy Check (CRC) status after the decoding process. The returned CRC status indicates whether the decoded codeword has a successful CRC check, which implies that the codeword was likely correctly recovered, or an unsuccessful CRC check, which implies that the codeword has likely not been correctly decoded. \n\nBy setting `return_crc_status` to `True`, the decoder will not only provide the information bits of the Polar encoded data as the output, but it will also provide the CRC status, which can be particularly useful in scenarios where it's important to ensure the integrity of the data, such as in data transmission over a noisy channel where errors are likely to occur.\n\nThe `output_dtype` parameter is used to specify the data type of the output that the decoder will return. It defaults to `tf.float32`, which is a 32-bit floating point tensor in TensorFlow. The `output_dtype` parameter allows flexibility in the type of data that the decoder will produce, which might be necessary depending on the specific requirements of the application using the decoded data.\n\nHere's how these parameters are used in the class initialization:\n\n```python\nfrom sionna.fec.polar.decoding import Polar5GDecoder\n\n# Setting the parameters\nreturn_crc_status = True\noutput_dtype = tf.float32  # Use tf data type for output\n\n# Initializing the Polar5GDecoder with the specified parameters\npolar_decoder = Polar5GDecoder(enc_polar=encoder_polar,\n                                return_crc_status=return_crc_status,\n                                output_dtype=output_dtype)\n```\n\nIn this example, a `Polar5GDecoder` instance is created with the `return_crc_status` set to `True` and the `output_dtype` set to `tf.float32`. This instance of the decoder will perform the decoding process and also return the CRC status along with the information bits."
"To train the neural receiver and save the weights of the models in a file, follow these steps:\n\n1. Instantiate the end-to-end model for training. This can be done using the `OFDMSystemNeuralReceiver` class, passing `training=True` as an argument.\n\n```python\nmodel = OFDMSystemNeuralReceiver(training=True)\n```\n\n2. Define the Adam optimizer. This is done using the `tf.keras.optimizers.Adam` class.\n\n```python\noptimizer = tf.keras.optimizers.Adam()\n```\n\n3. Define the training loop. The loop should sample a batch of SNRs, perform a forward pass through the model within a `tf.GradientTape()`, compute the gradients, and apply them using the optimizer.\n\n4. After each training iteration, print the progress and save the weights of the model. The weights can be obtained using the `model.trainable_weights` attribute. Convert the weights to a list and save the list in a file using the `pickle` module.\n\n```python\nweights = model.trainable_weights\nweights = [w.numpy() for w in weights]\nwith open('weights-ofdm-neuralrx', 'wb') as f:\n    pickle.dump(weights, f)\n```\n\n5. Save the weights of the Adam optimizer as well. The weights of the optimizer can be obtained using the `optimizer.get_weights()` method, and they can be directly saved to a file.\n\n```python\noptimizer_weights = optimizer.get_weights()\nwith open('weights-ofdm-neuralrx-optimizer', 'wb') as f:\n    pickle.dump(optimizer_weights, f)\n```\n\nRemember to ensure that the `OFDMSystemNeuralReceiver` class is properly defined and used in the training loop. The implementation of the class and the training loop may vary depending on the specific requirements of your project."
"Here are some useful links of it:\n\n[Part 1: Getting Started with Sionna](https://colab.research.google.com/github/nvlabs/sionna/blob/main/examples/Sionna_tutorial_part1.ipynb)\n\n[Part 1: Getting Started with Sionna](https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html)\n\n[Part 1: Getting Started with Sionna](https://nvlabs.github.io/sionna/_examples/Sionna_tutorial_part1.html)"
"To run throughput tests in Graph Mode using the Sionna Python package, you can follow the steps below:\n\n1. Import the required packages including Sionna. If Sionna is not installed, you can install it using pip.\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n2. Load the Sionna package and other required packages.\n\n```python\nimport sionna as sn\nimport tensorflow as tf\nimport numpy as np\n```\n\n3. You may need to set the GPU number depending on your system configuration.\n\n```python\ngpu_num = 0\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n    except RuntimeError as e:\n        print(e)\n```\n\n4. Initialize the required components such as QAM Source, Mapper, Demapper, and the Binary Source. You can also choose the AWGN channel and the corresponding encoder and decoder if needed.\n\n```python\nNUM_BITS_PER_SYMBOL = 2\nsource = sn.utils.BinarySource()\nqam = sn.modulation.QAM(NUM_BITS_PER_SYMBOL)\nmapper = sn.mapping.Mapper(\"qam\", NUM_BITS_PER_SYMBOL)\ndemapper = sn.mapping.Demapper(\"qam\", NUM_BITS_PER_SYMBOL, \"maxlog\")\nawgn_channel = sn.channel.AWGN()\nencoder = sn.fec.ldpc.LDPC5GEncoder(k_ldpc, n_ldpc)\ndecoder = sn.fec.ldpc.LDPC5GDecoder(encoder, num_iter=20, calc_llr=\"harddec\")\n```\n\n5. Generate a batch of random bit vectors, encode them, map them to constellation symbols, transmit them over an AWGN channel, demap them to log-likelihood ratios (LLRs), and finally decode them.\n\n```python\nbatch_size = 128\nebno_db = np.arange(0, 10, 0.5)  # evaluation SNR\nno = sn.utils.ebnodb2no(ebno_db, num_bits_per_symbol=NUM_BITS_PER_SYMBOL, coderate=1)\nbit_stream = source([batch_size, k_ldpc])\nc = encoder(bit_stream)\nx = mapper(c)\ny = awgn_channel([x, no])\nllr = demapper([y, no])\n```\n\n6. After decoding the symbols to LLRs, you can calculate the Bit Error Rate (BER) or Bitwise Mutual Information (BMI) to evaluate the performance of the system.\n\n```python\nb_hat = decoder(llr)\nber = sn.utils.metrics.BER()(bit_stream, b_hat).numpy()\nprint(\"BER: \", ber)\n```\n\nPlease note that the above code snippets are based on the provided context and may need to be adjusted based on your specific use case."
"To create a rate-1/2, constraint-length-3 convolutional code encoder using the `ConvEncoder` class from the `sionna.fec.conv` package, you can use either the `rate` and `constraint_length` parameters or the `gen_poly` parameter. The following Python code demonstrates both methods of instantiation.\n\nFirst, ensure you have the correct imports:\n```python\nfrom sionna.fec.conv import ConvEncoder\n```\n\nNow, let's create an encoder instance using the `rate` and `constraint_length` parameters. Note that the `gen_poly` method is not used in this case.\n\n```python\n# Creating a rate-1/2, constraint-length-3 convolutional code encoder\nencoder_rl = ConvEncoder(rate=1/2, constraint_length=3)\n```\n\nTo instantiate the `ConvEncoder` using the `gen_poly` parameter, you need to specify the generator polynomials directly.\n\nThe rate and constraint length can also be specified when calling the `gen_poly` function. For a rate-1/2, constraint-length-3 code, you can make the call as shown below:\n\n```python\n# Generator polynomials for a rate-1/2 code\ngen_poly = [\"100\", \"110\"]\n\n# Creating a rate-1/2, constraint-length-3 convolutional code encoder with gen_poly\nencoder_gp = ConvEncoder(gen_poly=gen_poly, rate=1/2, constraint_length=3)\n```\n\nBoth of these methods will create a rate-1/2, constraint-length-3 `ConvEncoder`. You can then use this encoder instance to encode data, for example:\n\n```python\n# bits to be encoded (let's say we have a binary source)\nu = np.random.randint(0, 2**k, size=(batch_size, k), dtype=np.uint8)\n# c = encoded bits\nc = encoder(u)\n```\n\nPlease replace `k` with the number of information bits per codeword. The generated `c` will contain the encoded bits.\n\nRemember, in the `gen_poly` method, the generator polynomials are specified in a way that is suitable for the convolutional code structure. The provided polynomials `[\"100\", \"110\"]` are valid for creating a rate-1/2, constraint-length-3 convolutional code; however, it is essential to confirm their validity based on the specific code parameters being used."
"Here is how to utilize it:\n\n1. Import the class using: `from sionna.channel.tr38901 import RMa`\n\n2. Initialize the model, you need to provide the carrier frequency in Hertz,  the `PanelArray` used by the transmitters, the `PanelArray` used by the receivers, the direction of the link (either \"uplink\" or \"downlink\"), whether to enable path loss (this is optional and the default value is `True`), whether to enable shadow fading (this is optional and the default value is `True`),and whether to always generate path loss coefficients (this is optional and the default value is `False`). An instance of this class can be called like a function to generate a batch of impulse responses once it has been initialized.\n\n3. Set up the topology. This is done using the `set_topology` method. You need to provide the locations of the transmitters and receivers, the orientations of the antenna arrays, the velocity vectors of the receivers, and the indoor/outdoor state of the receivers.\n\n4. Generate a batch of propagation paths. This can be done by calling the instance with the batch size and the maximum number of propagation steps as arguments. The call will return the path gain in linear scale and path delay in seconds. If desired, you can also write a batch receiver function that performs one receiver-end trace and processes the data. \n\n5. Use the propagation paths to compute channel impulse responses. This can be done using the `compute_h_cir` method. You will get the coefficients and delays of the paths from this method. You can then use these coefficients and delays for whatever purpose you have, such as simulating a channel in the time or frequency domain.\n\n6. If you want to use this in the frequency domain, you can utilize the `compute_ofdm_channel` method which returns the channel frequency response at subcarrier frequencies.\n\n7. There are several additional methods that can be used to get parameters such as path delays, path powers in dB scale, etc. You can utilize these methods as per your needs.\n\nRemember, the principles of the \"Rural macrocell (RMa)\" model include the consideration of outdoor environment, like the weather and the rough ground conditions. The model also applies techniques like shadowing to simulate the effects of large objects in the environment. Time-varying path loss could also be simulated if required, based on the changes in the environment and the movement of the users or systems.\n\nThe parameters of the \"Rural macrocell (RMa)\" model include the carrier frequency, the `PanelArray` used by the transmitters, the `PanelArray` used by the receivers, the direction of the link (uplink or downlink), whether to enable path loss, whether to enable shadow fading, and the receivers' mobility state (i.e., indoor or outdoor). The inputs to the `set_topology` method also include the locations and orientations of the transmitters and receivers, and the velocity vectors of the receivers.\n\nThe output of this model consists of the path gains and delays. The path gains are returned for each batch example and each receiver, and in the form of a tensor. The path delays are also returned in a tensor for each batch example and each path. These outputs can then be used to compute the channel impulse response or the channel frequency response."
"The `Trellis` data structure from `sionna.fec.conv.utils` is a part of the convolutional code utilities within the Sionna Forward-Error Correction (FEC) library. It is used to define a trellis, which is a structure representing a state machine for an n-step convolutional encoder.\n\nTo create a `Trellis` object, the provided `gen_poly` parameter should be a tuple with elements that are strings of 0s and 1s. These strings define the connection polynomials for the convolutional encoder. If the `rsc` parameter is set to `True`, the first polynomial in the `gen_poly` tuple will be used as the feedback polynomial, making the encoder recursive-systematic.\n\nThe `Trellis` class is not implemented for all generator matrices of size 1/n, instead it is implemented for generator matrices that define convolutional codes which, when terminated, result in systematic encodings.\n\nEach `Trellis` object from `sionna.fec.conv.utils` also defines some constants:\n\n- `gen_poly` represents the generator polynomial(s) used to construct the trellis.\n- `n` which is the number of bits per codeword, \n- `k` which is the number of information bits per codeword,\n- `state_next` is an array that defines the next state for each current state and input,\n- `output` is an array that defines the output bits for each current state and input,\n- `terminate` is a boolean flag indicating if this is the final trellis for a recursive construction,\n- `initial_state` is used to indicate the initial state of the trellis if it is not the initial state of the encoder.\n\nWhen simulating this Trellis, you can apply settings through the `Trellis` object itself or the simulation parameters. The key parameter for simulation would be the binary input to be encoded, which can be passed during the creation of the `Trellis` object, or when calling the `Trellis` object for encoding.\n\nExample:\n```python\nfrom sionna.fec.conv.utils import Trellis\n\n# Create a Trellis object with constraint length 4 and in the rsc form\ntrellis = Trellis(gen_poly=(..., ...), rsc=True, terminate=True, initial_state=...)\n\n# To use this Trellis for encoding, assuming U is the numpy array of information bits \n# and c is the numpy array of codeword bits:\n# c = trellis(U)\n```"
"The properties of this class include `cyclic_prefix`, `cyclic_prefix_length`, `frame_duration`, `frame_number`, `kappa`, `mu`, `n_cell_id`, `n_size_grid`, `n_start_grid`, `num_slots_per_frame`, `num_slots_per_subframe`, `num_symbols_per_slot`, `slot_number`, `sub_frame_duration` and `subcarrier_spacing`. \n\nThe source code link is [CarrierConfig](https://nvlabs.github.io/sionna/_modules/sionna/nr/carrier_config.html#CarrierConfig)"
"Here is the definition of Receiver:  sionna.Receiver(enc_param=None, is_oba=None, channel_model=None, return_channel_samples=False, list_size=1, num_bits_per_symbol=2, hard_out=False, dtype=tf.complex64, **kwargs)  \n  \nThe link of the source code of Receiver is [Receiver](https://nvlabs.github.io/sionna/_modules/sionna/receiver.html#Receiver)  \n\nHere is an explanation:  \nThis class defines a layer implementing receiver models. It\u2019s used to recover the `K` information bits from a noisy received signal `y` given either a an AWGN channel or a 3GPP 38.901 model, if the channel_model argument is set, or a wireless channel in general.  \n  \n### Parameters\n\n- **enc_param** (`str` or `None`):  \n  If a valid 3GPP NR encoding parameter name is provided, the following parameters: `K, N, n_RH, n_RV, n_mod_vl, n_ant, n_lay, n_cod, n_cb, n_sc_id, n_dmrs`, `n_PRB`, `n_OFDM`, `f_min`, `dtype`, are inferred and overwritten by the 3GPP specifications. Defaults to `None`. In this case, the above parameters must be provided explicitly.\n\n- **is_oba** (`bool` or `None`):  \n  If `True`, it is assumed that the waveform was quadrature-ladder filtered, rather than receiving white filtered. This only matters when using the 3GPP specification. Defaults to `False`.\n\n- **channel_model** (str, instance of `ChannelModel`, or `None`):  \n  If a string is provided, it must be one of \"AWGN\", \"flat-fading\", \"perfect-csi\", \"rayleigh\", or \"xpr-balanced\". In this case, `return_channel_samples` is set to the value specified by the 3GPP channel model (True except for \"AWGN\"). If an instance of `ChannelModel` is provided, such as `Ldpc5g`, `Ldpc5gInferCsi`, or `Ldpc5gInferSims`, this instance is used and the value of `return_channel_samples` is used as given. If set to `None`, an AWGN channel model is assumed and the channel is generated using this model and then set to `perfectCSI` and `return_channel_samples` set to `False`. Defaults to `None`.\n\n- **return_channel_samples** (bool):  \n  If set to True, the channel samples are returned in addition to the logits or LLRs. Defaults to False.\n\n- **list_size** (int):  \n  Used by non-AWGN channel models. Indicates the number of paths to estimate and demap. Only relevant for `hard_out` = True.\n\n- **num_bits_per_symbol** (int):  \n  The number of bits per QAM symbol, only needed when `constellation_type` = \"qam\". Must be specified for \"qam\". Defaults to 2.\n\n- **hard_out** (bool):  \n  If set to True, the receiver will output hard decisions (i.e., estimates of the information bits). Defaults to False.\n\n- **dtype** (tf.Dtype):  \n  The dtype of `y`. Defaults to tf.complex64. The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n### Input\n\n- **(y, h)** \u2013 Tuple:\n  - **y** ([batch_size, n], tf.complex) \u2013 1D tensor containing the received signals.\n  - **h** ([batch_size, n, n], tf.complex) \u2013 2D tensor containing the channel matrices.\n\n### Output\n\n- **x** ([batch_size, k], tf.float) or ([batch_size, k, list_size], tf.float) \u2013 1D tensor of logits (i.e., unnormalized log-probabilities) or 2+D tensor of logits, for a given batch of received signals, corresponding channel matrices, and noise variance.\n- **b** ([batch_size, k], tf.float) or ([batch_size, k, list_size], tf.float) \u2013 1D tensor of hard-decisions (i.e., binary decisions) or 2+D tensor of hard-decisions, for a given batch of received signals, corresponding channel matrices, and noise variance.\n- **no** (tf.float) \u2013 Scalar or tensor (only if `return_channel_samples` is True) representing the noise variance estimate.\n- **c** ([batch_size, n, n], tf.float) \u2013 Tensor of logits (or log-likelihoods) for every possible symbol, for a given batch of received signals, corresponding channel matrices, and noise variance. Set to None if `return_channel_samples` is False.\n  \n**Note: **  \nAs of Sionna 0.15.0, the typical workflow when using this layer is to\n1. create a channel_model (e.g., with the help of 3GPPChannel),\n2. instantiate a Transmitter,\n3. and Receiver with return_channel_samples=False or True, depending on whether you want to access the channel symbols or not.\n  \nFor 3GPP-compliant channels, the use of the RadioEnvironment, AntennaArray, Transmitter, StreamManagement, and LdpcDecoder is recommended and shown in the [3GPP Tutorial](https://nvlabs.github.io/sionna/examples/3gpp_mac_pdcch_tap_detection.html)."
"The `ResourceGrid` in the Sionna Python package is used to define a grid or pattern for the elements in a multi-cell MIMO (Multiple-Input, Multiple-Output) system to share or reuse the same set of resources, like time-frequency resource units. \n\nThe core idea is to enable multiple transmitters with multiple antennas each and multiple receivers with multiple antennas each to communicate freely and concurrently, all while maintaining the defined resource grid to avoid any possible interference. This is particularly useful in scenarios with large numbers of such components, as efficiently managing the available resources is crucial for maintaining quality of service.\n\nThe `ResourceGrid` therefore serves as a key tool in effectively organizing and allocating these resources in complex multi-cell MIMO systems, ensuring that each element has its own slot on the resource grid for message transmission and reception."
"To generate a batch of frequency responses, you can use the utility function 'tf.while_loop' provided by TensorFlow. This function allows you to repeatedly execute a block of code with a condition, and therefore generate a batch of frequency responses.\n\nHere's a step by step guide on how to do it:\n\n1. Define a function that computes the frequency response for a single sample. In the given context, the function is named 'compute_ofdm_channel_frequency_response'.\n\n```python\ndef compute_ofdm_channel_frequency_response(frequencies, a, tau, normalize):\n    h_freq = cir_to_ofdm_channel(frequencies, a, tau, normalize)\n    return h_freq\n```\n\n2. Call this function in a loop with the batch size as the number of iterations. This will generate the frequency responses for each sample in the batch.\n\n```python\nbatch_size = 100\nfreq = tf.Variable(0.04, dtype=tf.float32, name=\"frequency\")\nh_freq = tf.while_loop(compute_ofdm_channel_frequency_response, \n                       # compute_ofdm_channel_frequency_response() callable\n                       cond,            # stop loop when this is True\n                       parallel_iterations=batch_size,  # number of iterations to run in parallel\n                       back_iter=batch_size,  # total number of iterations (batch size here)\n                       frequencies=freq,   # pass the same frequencies for all iterations\n                       a=activity_prob,    # parameters a, tau for the compute_ofdm_channel_frequency_response() callable\n                       tau=mean_active_time,\n                       normalize=True)     # normalize H, i.e., to ensure unit average power per resource element\n```\n\nIn this code, 'cond' is a function that returns True when the loop should stop, 'parallel_iterations' specifies how many instances to run in parallel, 'back_iter' is the total number of iterations the loop will run for, 'frequencies', 'a', 'tau' are the parameters passed to 'compute_ofdm_channel_frequency_response', and 'h_freq' is the output resulting from the loop. The 'cir_to_ofdm_channel' function is assumed to be one that computes the channel frequency response from the continuous-time channel impulse response. The 'normalize' parameter is set to True to ensure that the average power per resource element is one, as is typically done when working with OFDM systems. \n\n3. The frequency responses for the batch are now stored in 'h_freq', which can be passed to the ApplyOFDMChannel layer for the OFDM simulation. \n\nNote: Please be aware that the actual implementation might slightly vary based on the specific framework or tool you are using. The code provided is a general representation of how to generate a batch of frequency responses in TensorFlow."
"To configure transmitters and receivers for computing propagation paths in Sjsonna RT, you can follow these steps:\n\n1. **Define a Transmitter Array and Receiver Array**: You need to define a transmitter array and a receiver array. The configuration of these arrays includes the number of rows and columns in the array, the spacing between elements, the pattern of the elements, and the polarization of the elements. For example, \n\n```python\nscene.tx_array = PlanarArray(num_rows=1,\n                          num_cols=1,\n                          vertical_spacing=0.5,\n                          horizontal_spacing=0.5,\n                          pattern=\"iso\",\n                          polarization=\"VH\")\nscene.rx_array = PlanarArray(num_rows=1,\n                          num_cols=1,\n                          vertical_spacing=0.5,\n                          horizontal_spacing=0.5,\n                          pattern=\"dipole\",\n                          polarization=\"cross\")\n```\n\n2. **Create a Transmitter and a Receiver**: You need to create a transmitter and a receiver. The configuration of these includes a name, a position, and an orientation. For example,\n\n```python\ntx = Transmitter(name=\"tx\",\n              position=[30,60,1.5],\n              orientation=[0,0,0])\nrx = Receiver(name=\"rx\",\n           position=[200,200,1.5],\n           orientation=[0,0,0])\n```\n\n3. **Point the Transmitter and Receiver Towards Each Other**: You need to point the transmitter and receiver towards each other. For this, you can use the `look_at` function. For example,\n\n```python\ntx.look_at(rx)\n```\n\n4. **Add the Transmitter and Receiver to the Scene**: Once they are configured, you can add the transmitter and receiver to the scene.\n\n```python\nscene.add(tx)\nscene.add(rx)\n```\n\n5. **Compute Propagation Paths**: Finally, you can compute the propagation paths using the `compute_paths` function.\n\n```python\npaths = scene.compute_paths()\n```\n\nPlease note that the above code is just an example. You might need to adjust the parameters based on your specific requirements."
"The deprecated `SymbolDemapperWithPrior` class is defined as a part of the `sionna.mapping` module. It's functionality is implemented in the now deprecated class so as to compute normalized log probabilities (logits) or hard decisions on symbols for a given tensor of received symbols, presuming prior knowledge on the constellation points is available. The class computes the soft-symbols, i.e., the likelihood of each bit-transmitted symbol of the mapped variable $x$ given the received $y$, represented as $\\text{Pr}\\left(x \\lvert y, prior\\right)$. Additionally, it computes hard-decisions by assigning the symbol with the maximum likelihood (or the constellation point) for every $x$. The class is fully differentiable when computing soft-symbols.\n\nThe class takes the prior knowledge on the constellation points in the form of log-probabilities, further, the class assumes that the received symbols `y` and the prior information `prior` have datatypes `tf.complex64` or `tf.complex128`, and the dtype of the output is the real dtype (`tf.float32` or `tf.float64`).\n\nIt's important to note that the class has been deprecated in lieu of classes and functions that provide similar or improved functionality, while maintaining the performance. The package maintainers highly recommend using the `SymbolDemapper` class along with the `SoftToHardDecider` or their respective functionality, instead of using the deprecated class. \n\nThe details of the implementation and usage of the `SymbolDemapperWithPrior` class are documented in the context. However, it's crucial to refer to the latest package documentation or release notes when using deprecated classes, as the implementation details or the optimal usage of the class may have changed."
"To enable diffuse reflections and observe their impact on the coverage map, you need to modify the scene and set the `diffuse_reflection` property of the `radio_material` used by the scattering surfaces to `True`. Here are the steps to do this:\n\n1. Load the scene: Use the `load_scene` function from the `sionna.rt` module to load the scene you want to work with. For example, you can load a simple street canyon scene with the following code:\n\n```python\nscene = load_scene(sionna.rt.scene.simple_street_canyon)\n```\n\n2. Set up the transmitter and receiver: Use the `PlanarArray` class from the `sionna.rt` module to set up an antenna array for the transmitters and receivers. Then, create instances of the `Transmitter` and `Receiver` classes from the `sionna.rt` module and add them to the scene.\n\n```python\narray = PlanarArray(num_rows=1, num_cols=1, vertical_spacing=0.5, horizontal_spacing=0.5, pattern=\"tr38901\", polarization=\"V\")\ntx = Transmitter(name=\"tx\", position=[-33,11,32], orientation=[0,0,0], array=array)\nscene.add(tx)\n```\n\n3. Enable diffuse reflection: You need to access the scattering surfaces in your scene and set their `diffuse_reflection` property to `True`. This will enable diffuse reflection for these surfaces. For example, you can do this for the scattering surface named \"wall-itu\":\n\n```python\nscene.get(\"wall-itu\").radio_material.diffuse_reflection = True\n```\n\n4. Compute the coverage map: Use the `coverage_map` method of your scene to compute the coverage map. You can specify the cell size and the number of samples as arguments. For example:\n\n```python\ncm = scene.coverage_map(cm_cell_size=[5.,5.], num_samples=int(10e6))\n```\n\n5. Visualize the impact: You can visualize the impact of the diffuse reflections on the coverage map by rendering the scene and overlaying the coverage map. For example:\n\n```python\nscene.render(my_cam, coverage_map=cm)\n```\n\nPlease note that the code snippets provided above are based on the context provided and may need to be adjusted based on your specific use case."
"To compute the Mean Squared Error (MSE) between the transmitted and recovered symbols, you can follow these steps:\n\n1. First, you need to have the transmitted symbols `x` and the recovered symbols `x_hat`. These are the output of the equalizer in the given context.\n\n2. Then, subtract the transmitted symbols from the recovered symbols. This will give you the error or noise `x - x_hat`.\n\n3. Next, square the values of the errors to get the Mean Square Error (MSE). This is done to ensure all errors are treated as positive values.\n\n4. Finally, compute the mean of the squared errors. This will give you the MSE between the transmitted and recovered symbols. The lower the value, the better the recovery.\n\nThe provided code in the context does this computation with the following lines:\n\n```python\nx_ind = symbol_demapper([x, no])\nx_ind_hat = symbol_demapper([x_hat, no])\nprint(compute_mse(x, x_hat))\n```\n\nThe symbols are demapped using a `SymbolDemapper` function, and then the `compute_mse` function is called to compute the MSE. \n\nThe `compute_mse` function is defined in the context as a layer that computes the MSE between two sets of symbols. The function first takes the difference between the two symbol sets, then squares the difference to get the MSE for each example, and finally computes the mean MSE across all the examples. \n\nThis is how you compute the MSE between the transmitted and recovered symbols."
"The 'create_or_check_constellation' method is a part of the Constellation class. It is used to either create a new constellation or check the consistency of an existing one. This method is particularly useful because it allows users to specify their own settings for the constellation or use an already existing one, thus ensuring the integrity of the constellation.\n\nThe 'create_or_check_constellation' method requires two main parameters. The first one is 'num_bits_per_symbol', which is an integer that represents the number of bits per constellation symbol. The second parameter is 'constellation', which is an instance of the Constellation class and is set to None by default. If a value is explicitly provided for this parameter, the 'num_bits_per_symbol' parameter is ignored, and the method will return a handle to the matplot figure object of the constellation. This is particularly useful for ensuring that the same constellation is used across various processes or validations.\n\nIf the 'create_or_check_constellation' method is used to create a new constellation, the method will return a handle to a matplot figure object of the newly created constellation. If no handle on the output is needed, the method can simply be used to create a symbolic representation of a constellation in the context.\n\nIn summary, the 'create_or_check_constellation' method is a versatile way to work with constellations in a simulation, allowing either the creation of new ones or the validation of existence and properties of an old one. This can help in error handling, debugging, and ensuring the reusability and reliability of constellations in simulations."
"The `scat_keep_prob` argument plays a crucial role in the ray tracing process in the context of the 'Sionna RT - Ray Tracing Module' explained in the discussion. This argument is part of the process of computing scattered paths in the environment.\n\nScattering is a phenomenon that occurs when an electromagnetic wave or a light ray hits a surface. Part of the energy gets reflected (specular reflection) and part of it gets transmitted, but there is also a part that is redirected into the so-called diffuse field by reflection (diffuse reflection) or scattering. In the context of the `scat_keep_prob` argument, diffuse reflection is considered.\n\nThe `scat_keep_prob` argument is used when computing scattered paths to control the path selection process. In distributed ray tracing, a large number of scattered paths can be generated, which can significantly slow down the computational process. To manage this, the argument is used to specify a probability value which, in turn, determines the fraction of scattered paths that will be retained.\n\nFor instance, from the provided context, a  `scat_keep_prob` of `1.0` is used in the ray tracing process, which means that all scattered paths are kept. This can be useful for generating coverage maps where most of the points of interests have only a single (or very few) direct paths due to strong directive antenna patterns. \n\nOn the other hand, one could set `scat_keep_prob` to a smaller value to reduce the number of scattered paths and thus speed up the process, while still retaining a good estimation of the coverage map.\n\nIt's important to note that the `scat_keep_prob` argument should be used carefully, depending on the specific requirements of the ray tracing process in terms of accuracy and performance."
"Here is the detailed information of sionna.rt.r_hat: [sionna.rt.r_hat(p, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/rt/utils.html#r_hat)\n\nComputes the normalized squared distance vector.\n\nTransforms a point on the unit sphere $\\mathbf{u}\\in \\mathbb{S}^2$ and a point on a plane into a a normalized squared distance as defined in [(2)](https://sionna.rt.tr38901) and  [(3)](https://sionna.rt.tr38901).\n\n**Input**\n\n- `p` (..., 3), tf.float: Points on a plane.\n- `dtype` (, tf.complex): Data type to use for computations. Options are tf.complex64 or tf.complex128. Defaults to tf.complex64.\n\n**Output**\n\n- `r2` (...), tf.float: Normalized squared distance.\n\nsource code:\n```python\ndef r_hat(p, dtype=tf.complex64):\n    r\"\"\"\n    Computes the normalized squared distance vector.\n\n    Transforms a point on the unit sphere\n    :math:`\\mathbf{u}\\in \\mathbb{S}^2` and a point on a plane into a a\n    normalized squared distance as defined in (2) [WWTIMO]_ and  (3)\n    [WWTIMO]_\n\n    Input\n    -----\n    p : [...,3]\n        Points on a plane\n\n    dtype : , tf.complex\n        Datatype to use for computations.\n        Options are `tf.complex64` or `tf.complex128`.\n        Defaults to `tf.complex64`.\n\n    Output\n    ------\n    r2 : [...]\n        Normalized squared distance.\n    \"\"\"\n    if dtype not in (tf.complex64, tf.complex128):\n        raise ValueError(\"`dtype` must be tf.complex64 or tf.complex128`\")\n\n    # r_hat = [x_hat, y_hat, z_hat] dot [x, y, z]\n    #       =  [x_hat, y_hat,  z_hat]. [x, y, z]\n    # r_hat = x_hat * x + y_hat * y + z_hat * z\n    #       =  z_hat * z   (x_hat * x/x_z + y_hat * y/z_z)\n    # see 4.1.2.2 in 3GPP TR 38.901\n    one = tf.complex(tf.cast(1, dtype.real_dtype), 0)\n    x = tf.cast(p[...,0], dtype)\n    y = tf.cast(p[...,1], dtype)\n    z = tf.abs(p[...,2])\n    r2 = tf.math.real(\n        z*tf.math.add_no_nan(x/x, y/z)\n        )\n    return r2\n```"
"Here is the detailed information of OFDMDetectorWithPrior:   \n  \n[sionna.ofdm.OFDMDetectorWithPrior(detector, output, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#OFDMDetectorWithPrior)  \n\nWraps a MIMO detector that assumes prior knowledge of the transmitted signals for use with the OFDM waveform.\n\nThe parameter detector is a callable (e.g., a function) that implements a MIMO detection algorithm with prior for arbitrary batch dimensions. Either the existing detector MaximumLikelihoodDetectorWithPrior can be used, or a custom detector callable provided that has the same input/output specification.\n\nThis class preprocesses the received resource grid y, the channel estimate $\\hat{\\mathbf{H}}$ , and the prior information $\\mathbf{x}_{\\text{prior}}$ , and computes for each receiver the effective channel according to the OFDM and stream configuration provided by the resource_grid and stream_management. These quantities serve as input to the detection algorithm that is implemented by the callable detector. Both detection of symbols or bits with either soft- or hard-decisions are supported.\n\n**Note**\nThe callable detector must take as input a tuple ($\\mathbf{y}$, $\\mathbf{h}$, $\\mathbf{prior}$, $\\mathbf{s}$) such that:\n\n- y ([,num_rx], or [,num_rx,num_streams] tf.complex) \u2013 1+D tensor containing the received signals.\n\n- h ([,num_rx, num_streams_per_rx], or [,num_rx, num_streams_per_rx,num_lags] tf.complex) \u2013 2+D tensor containing the channel matrices.\n\n- prior ([,num_tx, num_streams_per_tx] or [,num_tx, num_streams_per_tx, num_bits_per_symbol] tf.float) \u2013 Prior of the transmitted signals. If output equals \"bit\", then LLRs for the transmitted signals are expected. If output equals \"symbol\", then logits for the transmitted constellation points are expected.\n\n- s ([,num_rx, num_rx], or [,num_rx, num_rx, num_lags] tf.complex) \u2013 2+D tensor containing the noise covariance matrices.\n\nIt must generate one of the following outputs depending on the value of output:\n\n- b_hat ([,num_streams, num_data_symbols*num_bits_per_symbol], tf.float) \u2013 LLRs or hard-decisions for every bit of every stream, if output equals \"bit\".\n\n- s_hat ([,num_streams, num_data_symbols, num_points], tf.float) or ([,num_streams, num_data_symbols], tf.int) \u2013 Logits or hard-decisions for constellation symbols for every stream, if output equals \"symbol\". Hard-decisions correspond to the symbol indices.\n\n**Parameters**\n\n- `detector` (Callable): Callable object (e.g., a function) that implements a MIMO detection algorithm with prior for arbitrary batch dimensions. The existing detector MaximumLikelihoodDetectorWithPrior can be used, or a custom detector callable provided that has the same input/output specification.\n- `output` (One of [\"bit\", \"symbol\"], str): Type of output, either bit or symbol.\n- `resource_grid` (ResourceGrid): Instance of ResourceGrid.\n- `stream_management` (StreamManagement): Instance of StreamManagement.\n- `constellation_type` (One of [\"qam\", \"pam\", \"custom\"], str): For custom, an instance of Constellation must be provided.\n- `num_bits_per_symbol` (int): Number of bits per constellation symbol, e.g., 4 for QAM16. Required for constellation types [\"qam\", \"pam\"].\n- `constellation` (Constellation): Instance of Constellation, or None. If None, both constellation_type and num_bits_per_symbol must be specified.\n- `dtype` (One of [tf.complex64, tf.complex128] tf.DType): The dtype of the input, used for both the input and output dtypes. Defaults to tf.complex64.\n\n**Input**\n\n- `x` ([batch_size, num_tx, num_data_symbols], tf.complex): The time-frequency representation of the transmitted signals.\n- `h` ([batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex): The channel matrices corresponding to all links from all transmitters to all receivers.\n- `prior` ([batch_size, num_tx, num_streams_per_tx, num_data_symbols x num_bits_per_symbol] or [batch_size, num_tx, num_streams_per_tx, num_data_symbols, num_points], tf.float): Prior of the transmitted signals. If output equals \"bit\", LLRs of the transmitted signals are expected. If output equals \"symbol\", Logits of the transmitted constellation points are expected.\n- `no` ([batch_size, num_rx, num_rx_ant] tf.float): The variance of the AWGN.\n\n**Output**\n\n- `x_hat` ([batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol] or [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float): The log-likelihood ratios (hard-decisions for symbols) or computed logit for constellation symbols for every stream, if output equals \"bit\". If output equals \"symbol\", the corresponding logits for the constellation points for every stream."
"Here is the detailed information of the class:   \n  \n[sionna.fec.utils.GaussianPriorSource(specified_by_mi=False, dtype=tf.float32, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#GaussianPriorSource)  \n\nGenerates fake LLRs as if the all-zero codeword was transmitted over an Bi-AWGN channel with noise variance no or mutual information (if specified_by_mi is True). If selected, the mutual information denotes the mutual information associated with a binary random variable observed at the output of a corresponding AWGN channel (cf. Gaussian approximation).\n\nThe generated LLRs are drawn from a Gaussian distribution with\n\n\u03c3llr2=4\u03c3ch2  \nand  \n\u03bcllr=\u03c3llr2/2  \nwhere \u03c3ch2 is the channel noise variance as defined by no.\n\nIf specified_by_mi is True, this class uses the of the so-called J-function (relates mutual information to Gaussian distributed LLRs) as proposed in Brannstrom.\n\nNote: The class inherits from the Keras layer class and can be used as layer in a Keras model.\n\n### Parameters\n\n- **specified_by_mi** (bool): Defaults to False. If True, the second input parameter `no` is interpreted as mutual information instead of noise variance.\n- **dtype** (tf.DType): Defaults to tf.float32. Defines the datatype for internal calculations and the output. Must be one of the following: (tf.float16, tf.bfloat16, tf.float32, tf.float64).\n\n### Input\n\n- **(output_shape, no)**: Tuple:\n  - **output_shape** (tf.int): Integer tensor or Python array defining the shape of the desired output tensor.\n  - **no** (tf.float32): Scalar. Defining the noise variance or mutual information (if `specified_by_mi` is True) of the corresponding (fake) AWGN channel.\n\n### Output\n\n- **Output**: tf.float. 1+D Tensor with shape as defined by `output_shape`.\n\n### Raises\n\n- **InvalidArgumentError**. If mutual information is not in (0,1).\n- **AssertionError**. If `inputs` is not a list with 2 elements.\n\n**Note: **  As the inverse Gaussian CDF is not implemented in Tensorflow, we use an approximation following . This approximation is implemented on top of the J-function, see also Brannstrom for details. The approximation becomes exact (for practical purposes) for very large input values.  \n  \nsource code:  \n```python\nclass GaussianPriorSource(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"GaussianPriorSource(specified_by_mi=False, dtype=tf.float32, **kwargs)\n\n    Generates fake LLRs as if the all-zero codeword was transmitted over an\n    Bi-AWGN channel with noise variance ``no`` or mutual information (if\n    ``specified_by_mi`` is True). If selected, the mutual information\n    denotes the mutual information associated with a binary random variable\n    observed at the output of a corresponding AWGN channel (cf. Gaussian\n    appx.).\n\n    The generated LLRs are drawn from a Gaussian distribution with\n\n    .. math::\n\n        \\sigma_{llr}^2=4\\sigma_{ch}^2\n\n    and\n\n    .. math::\n\n        \\mu_{llr} = \\frac{\\sigma_{llr}^2}{2}\n\n    where :math:`\\sigma_{ch}^2` is the channel noise variance as defined by\n    ``no``.\n\n    If ``specified_by_mi`` is True, this class uses the of the so-called\n    `J-function <https://en.wikipedia.org/wiki/Q-function>`_ (relates mutual\n    information to Gaussian distributed LLRs) as proposed in [Brannstrom]_.\n\n    Note\n    ----\n    The class inherits from the Keras `Layer` class and can be used as\n    layer in a Keras model.\n\n    Parameters\n    ----------\n    specified_by_mi : bool\n        Defaults to False. If True, the second input parameter ``no`` is\n        interpreted as mutual information instead of noise variance.\n\n    dtype : tf.DType\n        Defaults to `tf.float32`. Defines the datatype for internal\n        calculations and the output. Must be one of the following:\n        (`tf.float16`, `tf.bfloat16`, `tf.float32`, `tf.float64`).\n\n    Input\n    -----\n    (output_shape, no) :\n        Tuple:\n\n    output_shape : tf.int\n        Integer tensor or Python array defining the shape of the desired\n        output tensor.\n\n    no : tf.float32\n        Scalar. Defining the noise variance ``no`` of the corresponding\n        (fake) AWGN channel.\n\n    Output\n    ------\n        : ``dtype``. 1+D Tensor with shape as defined by ``output_shape``.\n\n    Raises\n    ------\n    InvalidArgumentError\n        If mutual information is not in (0,1).\n\n    AssertionError\n        If ``inputs`` is not a list with 2 elements.\n\n    Note\n    ----\n        As the inverse Gaussian CDF is not implemented in Tensorflow, we use\n        an approximation following :cite:`ijaz_inverse` . This approximation\n        is implemented on top of the J-function, see also :cite:`brannstrom`\n        for details. The approximation becomes exact (for practical\n        purposes) for very large input values.\n    \"\"\"\n\n    def __init__(self, specified_by_mi=False, dtype=tf.float32, **kwargs):\n\n        super().__init__(dtype=dtype, **kwargs)\n\n        assert isinstance(specified_by_mi, bool), \"\"\"`specified_by_mi` must be bool.\"\"\"\n        self._specified_by_mi = specified_by_mi\n\n        # c (see https://en.wikipedia.org/wiki/Box%E2%80%93Muller_transform)\n        r = tf.cast(tf.constant(2.), dtype)\n        u1 = tf.random.uniform((), minval=0, maxval=r, dtype=dtype)\n        u2 = tf.random.uniform((), minval=0, maxval=r, dtype=dtype)\n        self._c = tf.sqrt(-r*tf.math.log(u1))\n        self._u = tf.cos((2.0*PI)*u2)\n\n        if self._specified_by_mi:\n            # use inverse J-function to approximate Gaussian mutual information\n            # see Brannstrom\n            mi = tf.cast(1.0,dtype=dtype) - 2.*u1\n            sigma = tf.math.real(tf.sqrt(1. + 8.*mi)) / tf.cast(2.,dtype=dtype)\n            sigma = tf.minimum(sigma, tf.cast(7.62, dtype))\n        else:\n            sigma = self._c/tf.cast(tf.sqrt(tf.constant(3.), dtype=dtype),\n                                                            dtype=dtype)\n\n        # normalize to unit-variance\n        self._sigma = tf.cast(sigma / tf.sqrt(tf.constant(2., dtype=dtype)),\n                                                                dtype=dtype)\n\n    #########################################\n    # Public methods and properties\n    #########################################\n\n    def call(self, inputs):\n        # input is a tuple (shape, no)\n\n        if isinstance(inputs, (tuple, list)):\n            if len(inputs)==1:\n                # support keras automatically for expand_dims\n                no = inputs\n            elif len(inputs)==2:\n                no = inputs[1]\n            else:\n                raise AssertionError(\"The number of inputs must be 1 or 2.\")\n        else:\n            no = inputs\n\n        # as we only support decoding of (fake) channel output of all-zero codeword)\n        # we do not need the input mus.\n        # mus will calculated based on the all-zero codeword assumption.\n\n        # fake the channel output\n        x = tf.zeros(no, dtype = self.dtype)\n\n        # Use the Gaussian LLR approximation (all-zero codeword case))  as\n        # defined in (8) and (9)  https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6545109\n\n        if self._specified_by_mi:\n\n            # calculate mu as in (10)\n            mu = -tf.math.cosh(self._sigma**2 / 2. * (1. - 2.*x) / self._sigma) \\\n                 + tf.math.cosh(self._sigma**2 / 2. ) \\\n                 - tf.abs( tf.math.sinh(self._sigma**2 / 2. ) )\n            mu = tf.maximum(mu, tf.cast(1e-30, dtype=dtype)) # avoid 0\n        else:\n            mu = tf.maximum(tf.ones_like(x, dtype=dtype),\n                 tf.minimum( tf.maximum(self._sigma**2 / 2. * (1. - 2.*x) / self._sigma),\n                 tf.minimum( tf.maximum(self._sigma**2 / 2. - tf.abs(self._sigma**2 / 2. * (1. - 2.*x) / self._sigma) ),\n                 tf.maximum(self._sigma**2 / 2.) )))\n\n        # calculate llr as in (8)\n        llr = x * mu / tf.math.real(self._sigma**2) \\\n            +  0.5 * tf.math.log(mu / (1. - mu) )\n        llr= tf.cast(llr, self.dtype)\n\n        # permute llr such that the output shape is (n,); required by tf.Datasets\n        #llr = tf.squeeze(llr)\n        return llr\n\n    @property\n    def dtype(self):\n        \"\"\"Datatype `dtype` of the (output) expected internal dtype.\"\"\"\n        return super().dtype\n```  \n  "
"Here is the detailed information of source code:   \n  \n[sionna.mapping.QAM2PAM(num_bits_per_symbol)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#QAM2PAM)  \n  \nTransforms QAM symbol indices to PAM symbol indices.  \n\nFor indices in a QAM constellation, computes the corresponding indices for the two PAM constellations corresponding the real and imaginary components of the QAM constellation.\n\nParameters\n\n    num_bits_per_symbol (int) \u2013 The number of bits per QAM constellation symbol, e.g., 4 for QAM16.\n\nInput\n\n    ind_qam (Tensor, tf.int) \u2013 Indices in the QAM constellation\n\nOutput\n\n    ind_pam1 (Tensor, tf.int) \u2013 Indices for the first component of the corresponding PAM modulation\n    ind_pam2 (Tensor, tf.int) \u2013 Indices for the first component of the corresponding PAM modulation\n \n\n**Note:**\nThe transformation is performed according to Tables 5.1.3.2-1 and 5.1.3.2-2 in [3GPPTS38211](https://www.3gpp.org/specs/archive/38_series/38.211/38211-h00.zip) and Tables 5.1.3.2-1 and 5.1.3.2.-2 in [ETSI38.211](https://www.etsi.org/deliver/etsi_ts/138200/15005/16.00.00_60/ts_138200v15005.zip).  \n  \n**Properties**\n\n- `num_bits_per_symbol`: The number of bits per QAM constellation symbol, e.g., 4 for QAM16.\n  "
"To load the required Sionna components, follow these steps:\n\n1. First, you need to import the necessary components from the Sionna package. For example, in the given context, the following components are imported:\n\n```python\nfrom sionna.rt import load_scene\nfrom sionna.rt.scene import Scene\n```\n\n2. Next, you can load the desired scene by calling the `load_scene` function and passing the scene name as an argument. For example:\n\n```python\nscene = load_scene(etoile)\n```\n\n3. If you want to load a scene for preview in the notebook, you can call the `preview` method on the `scene` object. For example:\n\n```python\nscene.preview()\n```\n\nPlease note that the required Sionna components should be installed in your environment. If they are not installed, you can install them using pip."
"To import the necessary modules for Sionna's API and set up the GPU configuration, follow these steps:\n\n1. First, import the `os` module, which provides a way of using operating system-dependent functionality like reading or writing to the environment.\n\n```python\nimport os\n```\n\n2. Next, set the GPU number. If you want to use the CPU, set `gpu_num` to an empty string (\"\").\n\n```python\ngpu_num = 0  # Set to \"\" to use CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n```\n\n3. Import the `tensorflow` module. If the `gpu_num` is not an empty string, configure TensorFlow to use only a single GPU and allocate only as much memory as needed.\n\n```python\nimport tensorflow as tf\nif gpu_num is not \"\":\n    gpus = tf.config.list_physical_devices('GPU')\n    if gpus:\n        try:\n            tf.config.experimental.set_memory_growth(gpus[0], True)\n        except RuntimeError as e:\n            print(e)\n    tf.get_logger().setLevel('ERROR')\n```\n\n4. Set the global random seed for reproducibility.\n\n```python\ntf.random.set_seed(1)  # Set global random seed for reproducibility\n```\n\n5. To avoid warnings from TensorFlow, set the log level of the logger to 'ERROR'.\n\n```python\ntf.get_logger().setLevel('ERROR')\n```\n\n6. Finally, ensure the environment variables are set for the number of threads and type of TensorFlow logs.\n\n```python\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '3'\ntf.get_logger().setLevel('ERROR')\n```"
"An essential part of ray tracing in Sionna is the 'CoverageMap' component, which, as described in the given context, maps the power that is received at every point on a surface from a specific transmitter. This means that for a given transmitter, it is associated with every point on a surface with the power that a receiver with a specific orientation would observe at this point. \n\nSeveral key points and features about 'CoverageMap' can be derived from the provided context:\n\n1. Discreteness: It's important to note that a coverage map is not continuous but rather discrete. This refers to the quantization of the plane into small rectangular bins. The discretization or quantization would pave the way for effectively organizing and storing data about the surface.\n\n2. Access to Transmitter-Receiver Pairs: CoverageMap provides a way to access the entries of the coverage map for a specific transmitter-receiver pair. In this regard, the functions 'cm()' and 'cm_dB()' come into play. The former provides access to the complex-valued entries and the latter in decibel scale.\n\n3. Utility in Visualization and Analysis: CoverageMap has functionalities that make visualization and analysis of the coverage map possible. The 'render()' function can be utilized to render the map to a scene. If rendering to a file is preferred, 'render_to_file()' could be used. There's also a 'preview()' function that opens a preview in a separate window, providing a non-static, interactive visualization of the coverage map.\n\n4. Transmitter-Centric Capabilities: For all transmitters in the scene, one can determine their positions with respect to the global coordinate system, as well as create their individual coverage maps. The origin of the local coordinate system, which defines the position and orientation of the transmitters, can be set, and it moves along with the transmitter.\n\n5. Receiver-Oriented Features: For every transmitter, it's possible to compute the field-of-view (FoV) of any receiver. This FoV describes the set of rays that the transmitter would send into the world, which provides a measure of how focused the transmitter's energy is. \n\n6. Sample Positions for Channel Impulse Response (CIRs): One could sample a set of positions that have sufficient coverage from a specific transmitter using the 'sample_positions()' function. These sample positions can then be used to compute CIRs using the 'cir()' function.\n\n7. Accessibility: For ease of access and use in external codes, the coverage map can be serialized to a file or JSON string using the 'save()' or 'to_json()' methods, respectively. \n\nPlease note that the coverage map is computed after loading a scene, setting up the antenna arrays, and configuring the transmitters and receivers. The scene, antennas, and other components all interact to provide the data that the coverage map represents. For a transmitter, to which antennas are attached that have a defined radiation pattern, the coverage map is computed as soon as the 'position', 'orientation', or 'lookat' is changed."
"INPUT REQUIREMENTS:\n\nThe input for the TurboDecoder consists of log-likelihood ratio (LLR) values, denoted as `llr`, which is a tensor of shape `[n] + k]` containing LLR values, where `n` corresponds to the length of the codeword and `k` is the number of information bits per codeword. Additionally, the TurboDecoder is initialized with a list of generator matrices of shape `[k, n]` provided as `enc_mat`. Other parameters such as the number of iterations `num_iter`, the hard decision option `hard_out`, the puncturing option `punct_mode`, the termination option `term`, and the interleaver `intlv` need to be specified as well. The details of these parameters can be found in the decoder's documentation.\n\nOUTPUT FORMAT:\n\nThe output format of the TurboDecoder depends on whether a hard or soft decision is requested.\n\nFor hard decision (`hard_out=True`):\n- The output is a binary tensor of shape `[n] + [k]` containing the hard-decided codeword bits. \n- Each pair of square brackets indicates that the output tensor has two dimensions, which are the positions within the codeword and the two possible output values (in the case of hard decisions, these values correspond to 0 and 1).\n\nFor soft decision (`hard_out=False`):\n- The output is a float tensor of shape `[n, 2^k]` containing the log-likelihood ratio (LLR) values for each bit.\n- Here, the first dimension (`n`) still indicates the positions within the codeword, and the second dimension (`2^k`) indicates the different values that each bit can take (0 or 1).\n\nNote: the exact shape of the output is not explicitly described in the provided context. The descriptions provided above are based on typical output formats for decoding algorithms such as the TurboDecoder. The actual output format may vary depending on the specific implementation or the parameters used during initialization."
"Here is the detailed information of this function:\n\n[sionna.rt.antenna.iso_pattern(theta, phi, slant_angle=0.0, polarization_model=2, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/rt/antenna.html#iso_pattern)\n\nIsotropic antenna pattern with linear polarizarion\n\n**Input**\n\n- `theta` (*array_like*, float): Zenith angles wrapped within [0,\u03c0] [rad]\n- `phi` (*array_like*, float): Azimuth angles wrapped within [-\u03c0, \u03c0) [rad]\n- `slant_angle` (float): Slant angle of the linear polarization [rad]. A slant angle of zero means vertical polarization. Defaults to 0.\n- `polarization_model` (int, one of [1,2]): Polarization model to be used. Options 1 and 2 refer to [polarization_model_1()](https://nvlabs.github.io/sionna/_modules/sionna/rt/antenna.html#polarization_model_1) and [polarization_model_2()](https://nvlabs.github.io/sionna/_modules/sionna/rt/antenna.html#polarization_model_2), respectively. Defaults to 2.\n- `dtype` (tf.complex64 or tf.complex128): Datatype. Defaults to tf.complex64.\n\n**Output**\n\n- `c_theta` (*array_like*, complex): Zenith pattern\n- `c_phi` (*array_like*, complex): Azimuth pattern\n\nsource code:\n```python\ndef iso_pattern(theta, phi, slant_angle=0.0,\n                polarization_model=2, dtype=tf.complex64):\n    r\"\"\"\n    Isotropic antenna pattern with linear polarizarion\n\n    Input\n    -----\n    theta : *array_like*, float\n        Zenith angles wrapped within [0,pi] [rad]\n\n    phi : *array_like*, float\n        Azimuth angles wrapped within [-pi, pi) [rad]\n\n    slant_angle: float\n        Slant angle of the linear polarization [rad].\n        A slant angle of zero means vertical polarization.\n        Defaults to 0.\n\n    polarization_model: int, one of [1,2]\n        Polarization model to be used. Options `1` and `2`\n        refer to :func:`~sionna.rt.antenna.polarization_model_1`\n        and :func:`~sionna.rt.antenna.polarization_model_2`,\n        respectively. Defaults to 2.\n\n    dtype : tf.complex64 or tf.complex128\n        Datatype. Defaults to `tf.complex64`.\n\n    Output\n    ------\n    c_theta : *array_like*, complex\n        Zenith pattern\n\n    c_phi : *array_like*, complex\n        Azimuth pattern\n    \"\"\"\n    rdtype = dtype.real_dtype\n    k = tf.cast(1/np.sqrt(30), rdtype)\n    c = tf.cast(3.0, rdtype)\n    one = tf.cast(1.0, rdtype)\n\n    theta = tf.abs(clip(theta, 0, np.pi) - tf.cast(np.pi/2, rdtype))\n    theta_3db = tf.acos(1/k)\n    a = tf.square(tf.cos(theta))\n    b = tf.pow(c, a)\n    c = rdtype(b) # stop gradient is needed here\n    d = slant_angle_function(theta, phi, slant_angle, dtype=dtype)\n    e = rdtype(tf.complex(1,0)) + d\n    f = tf.pow(e, c)\n    g = 3*theta_3db\n    h = g*phi_function(theta, phi, dtype=dtype)\n    i = slant_angle_function(theta, phi, slant_angle, dtype=dtype)\n    j = rdtype(tf.complex(1,0)) + i\n    k = tf.math.real(j)\n    l = tf.math.imag(f)\n    m = tf.complex(k, l)\n    r_hat = f * m\n    r_hat = tf.cast(r_hat, dtype)\n    # The following stop_gradient is needed since the reflected field\n    #  should not be rotated into the local coordinate system.\n    return tf.math.real(r_hat), tf.math.imag(r_hat)\n```"
"To use the ApplyTimeChannel and ApplyOFDMChannel layers, you must first setup a wireless channel model, then create the relevant Keras layer. After that, you can create a channel input  and pass it to the model to get the output.\n\nHere's a quick example, demonstrating usage of these layers. First, you'll need to import the necessary classes:\n\n```python\nfrom sionna.channel import RayleighBlockFading, GenerateTimeChannel, ApplyTimeChannel\n```\n\nLet's say we have a `RayleighBlockFading` model, you would set it up like this:\n\n```python\nrayleigh = RayleighBlockFading(num_tx = 1, num_rx = 1, tx_ant = 32, rx_ant = 2)\n```\n\nThen, you would generate an instance of the `ApplyTimeChannel` Keras layer, providing the channel model operation as an argument:\n\n```python\napplytimechannel = ApplyTimeChannel(channel_model = rayleigh)\n```\n\nYou'd also need to create an instance of the `GenerateTimeChannel` class for the channel simulation.\n\n```python\ngen_time_channel = GenerateTimeChannel()\n```\n\nNow, let's assume you have a batch of channel inputs, consisting of a single random path index and a time step size. For demonstration, we'll create a placeholder `channel_input` of float32 type and shape `(*, 1, 1, 32, 1)`. The second dimension is for the number of transmit antennas, and the fourth is for the number of receive antennas.\n\nThe `ApplyTimeChannel` layer requires the channel inputs to be in a specific shape. Based on the `GenerateTimeChannel` source code documentation, it should have the shape `(*, num_time_steps + delay_l, num_tx_ant, num_rx_ant, num_paths)`, where `num_time_steps` is the number of time steps to process, `delay_l` is the (scalar) delay of the channel, `num_tx_ant` is the number of transmitting antennas, `num_rx_ant` is the number of receiving antennas, and `num_paths` is the number of paths (or channel taps).\n\nGiven this, you'll need to first generate a batch of channel responses. Let's assume the batch size is defined in a variable `batch_size`.\n\n```python\nchannel_input = tf.placeholder(dtype=tf.float32, shape=[batch_size, num_time_steps, 1, 32, 1])\nchannel_response = gen_time_channel(path_array, path_coeff, num_time_steps)\n```\nRemember to replace `path_array` and `path_coeff` with the actual propagation paths array and coefficients, as applicable. These depend on the specific channel model in use.\n\nThen, apply the channel on the input using the `ApplyTimeChannel` layer:\n\n```python\nchannel_output =  applytimechannel([channel_input, channel_response])\n```\n\nThe output, `channel_output`, will be the result of the channel transmission, showing the effects of the channel on the inputs. This can be used for further processing, such as in a receiver to compute the channel frequency response or to make channel-hardened predictions."
"To compute the log-likelihood ratios (LLRs) with the Demapper class in Sionna's mapping module, you would have first to create an instance of this class. The instantiation requires specifying the `demapping_method` (either \"app\" or \"maxlog\"), the `constellation_type`, the `num_bits_per_symbol` and optionally the `constellation` for custom constellation objects. After creating the instance, you can call it with a received signal vector `y`, a noise variance vector `no`, and optionally a vector of prior probabilities for each bit.\n\nHere is the general procedure in the form of steps:\n\n1. Instantiate the Demapper class:\n```python\ndemapper = Demapper(demapping_method=\"app\", constellation_type=\"qam\", num_bits_per_symbol=2, constellation=constellation_object)\n```\nReplace `\"app\"` with `\"maxlog\"` if you want to use that demapping method. Also, replace `\"qam\"` with your constellation type (like `\"pam\"`, or create a custom constellation object).\n\n2. Call the Demapper with the necessary arguments:\n```python\nllr = demapper([y, no, prior])\n```\nIn this call:\n   - `y` should be a 1D tensor containing the received symbols.\n   - `no` should be a 1D tensor containing the noise variance for each symbol.\n   - `prior` is an optional argument representing the a priori probability of each bit being a '1'. It should be provided as a 1D tensor. This argument is only needed if you want to use soft-decision demapping and have prior knowledge about the bits.\n\nThe method will return the computed LLRs (as a 1D tensor) according to the given Demapping method. Remember that the LLR sign indicates the candidate bit is a '0' or '1', and the value indicates the confidence level.\n\nIf hard decisions are desired (which consist of binary values instead of soft values), you can set the `hard_out=True` either during the Demapper instantiation or when calling the Demapper.\n\nCustomizing the Demapper's functionality, like error handling and adjusting configuration, can be implemented based on the requirements of your application and the data you are working with."
"The Channel Impulse Responses (CIRs) in the model can be obtained by two methods: \n\n1. **Direct Sampling**: The CIRs can be obtained by direct sampling in the time domain. This involves sampling the channel at a rate that is at least equal to the bandwidth of the channel model. The channel impulse response can then be obtained by computing the covariance of the channel and its Fourier transform. This method is utilized in the model when the `resource_grid` or `ofdm_symbol_indices` are given, as these parameters are used to compute the channel in the frequency domain.\n\nThis is seen in the following code snippet from the ApplyOFDMChannel layer where interpolation of the channel in the frequency domain is performed to compute the channel responses (reprs). \n\n```python\nx = cir(frequencies, time_cov, channel_cov)\nx = tf.expand_dims(x, axis=-1)\nh_freq = tf.experimental.numpy.fft(x, n)  # FFT\nh = tf.squeeze(h_freq, axis=-1)\nif interpolation is not None:\n    h = interpolation(h, time_indices)\nreturn h, reprs\n``` \n\n2. **CIRs Generation**: For models that support the generation of raw CIRs (baseband_channel parameter is set to True), the CIRs are computed using methods that are based on the channel model. The CIRs are then utilized to compute the channel frequency responses (i.e., Fourier transform of the CIRs) or the channel impulse responses in the time domain. The raw CIRs are expressed in the discrete time domain and are generated from the continuous power delay profiles.\n\nFor instance, in the RayleighBlockFading model, the raw CIRs are generated by combining the paths from the selected TDL (Tapped Delay Line) channel model with their respective delays and computing the channel responses at the time domain and/or frequency domain.\n\nIn the code below from the RayleighBlockFading model, `a` and `tau` represent the complex path amplitudes and path delays respectively.\n\n```python\na = tf.sqrt(0.5) * (tf.dtypes.complex(normal(0, 1), normal(0, 1)))\ntau = tf.abs(normal(0, 1))\n# Generate path\nh = tf.reduce_sum(a, axis=-1)\nh = tf.expand_dims(h, axis=-1)\ntau = tf.expand_dims(tau, axis=-1)\nh = tf.concat((h, tau), axis=-1)\n# Combine paths with channel delay spread\ntau = tf.expand_dims(self.channel_delay_spread, axis=-1)\nh = tf.add(h, tau)\n```\n\nIn both methods, the complex Gaussian path coefficients (a in the second method) are generated using the defined function `normal`. The delays (tau in the second method) are controlled using the defined variables such as `channel_delay_spread`.\n\nIt should be noted that the CIRs (both in the time and frequency domains) are generally not exposed as output by the channel models or the layers implementing these models. Instead, they are used internally to compute the channel responses. If access to the raw CIRs is needed, the `CIRDataset` class may be used to sample and store the CIRs in a dataset."
"{sionna.mimo.List2LLRSimple(num_bits_per_symbol, hard_out=False, dtype=tf.complex64)}  \nSource code: [List2LLRSimple](https://nvlabs.github.io/sionna/_modules/sionna/mimo/utils.html#List2LLRSimple)  \n\nComputes LLRs (or hard decisions) on all bits of all streams from a (possibly) larger list of candidate solutions, i.e., from `List2LLRSimple`. This class is fully differentiable by using the differentiability introduced by the soft decision function.\n\n#### Input\n- **y** ([...,n], tf.complex) \u2014 Channel output of a whitened channel. \n- **r** ([...,n,n], tf.complex) \u2014 Whitening channel matrix.\n- **x** ([...,n], tf.complex) \u2014 Channel inputs. \n- **x0** ([...,n,NumCand], tf.complex) \u2014 The whitened channel inputs.\n- **d** ([...n,NumCand], tf.complex) \u2014 Distance metric for each path (or candidate).\n- **p** ([...,n,NumCand], tf.complex) \u2014 Path symbols.\n- **llr_prior** ([...,n,NumCand], tf.complex) \u2014 Prior of LLRs.\n- **hard_out** (bool) \u2014 If true, the LLRs are computed by a hard-deciding all candidate solutions. Defaults to False.\n- **with_prior** (bool) \u2014 If true, the LLRs are computed assuming that prior knowledge on the bits is available. Defaults to False.\n- **state** (None) \u2014 Defaults to None.\n  \n#### Output\n- **[batch_size, num_streams * num_bits_per_symbol]** (tf.float) \u2013 LLRs or harddecisions for all bits of all streams.\n\n**Note: **\nAn implementation of this class does not need to make use of all of\nthe provided inputs which enable various different implementations."
"Here is the definition of MaximumLikelihoodDetector: sionna.ofdm.MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#MaximumLikelihoodDetector)  \n\n```python\nclass MaximumLikelihoodDetector(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    Maximum-likelihood (ML) detection for OFDM MIMO transmissions.\n\n    This layer implements ML detection for OFDM MIMO transmissions. Both ML\n    detection of symbols or bits with either soft- or hard-decisions are\n    supported. The OFDM and stream configuration are provided by a\n    :class:`~sionna.ofdm.ResourceGrid` and\n    :class:`~sionna.mimo.StreamManagement` instance, respectively. The\n    actual detection is carried out by an instance of\n    :class:`~sionna.mimo.MaximumLikelihoodDetector`.\n\n    Parameters\n    -----------\n    output : One of [\"bit\", \"symbol\"], str\n        Type of output, either bits or symbols. Whether soft- or\n        hard-decisions are returned can be configured with the\n        ``hard_out`` flag.\n\n    demapping_method : One of [\"app\", \"maxlog\"], str\n        Demapping method used\n\n    resource_grid : ResourceGrid\n        Instance of :class:`~sionna.ofdm.ResourceGrid`\n\n    stream_management : StreamManagement\n        Instance of :class:`~sionna.mimo.StreamManagement`\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n        Defaults to 4.\n\n    constellation : Constellation\n        Instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the detector returns hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of ``y``. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    ------\n    (y, h_hat, err_var, no) :\n        Tuple:\n\n    y : [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex\n        Received OFDM resource grid after cyclic prefix removal and\n        FFT\n\n    h_hat : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex\n        Channel estimates for all streams from all transmitters\n\n    err_var : [Broadcastable to shape of ``h_hat``], tf.float\n        Variance of the channel estimation error\n\n    no : [batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float\n        Variance of the AWGN noise\n\n    Output\n    ------\n    One of:\n\n    : [batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream, if ``output`` equals `\"bit\"`.\n\n    : [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int\n            Logits or hard-decisions for constellation symbols for every stream, if ``output`` equals `\"symbol\"`.\n            Hard-decisions correspond to the symbol indices.\n\n    Note\n    ----\n    If you want to use this layer in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sionna.Config.xla_compat=true``.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n    def __init__(self,\n                 output,\n                 demapping_method,\n                 resource_grid,\n                 stream_management,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        assert dtype in [tf.complex64, tf.complex128],\\\n            \"dtype must be tf.complex64 or tf.complex128.\"\n\n        # We cannot automatically set the output dtype to the dtype of the input.\n        # For some dtypes (e.g., tf.complex128), the memory is increased\n        # substantially.\n        self._output_dtype = tf.as_dtype(dtype).real_dtype\n\n        self._output = output\n        self._demapping_method = demapping_method\n        self._detector = MaximumLikelihoodDetector_(output,\n                                                    demapping_method,\n                                                    constellation_type,\n                                                    num_bits_per_symbol,\n                                                    constellation,\n                                                    hard_out,\n                                                    dtype=self.dtype)\n        self._resource_grid = resource_grid\n        self._stream_management = stream_management\n\n    def build(self, input_shape):\n        assert input_shape[-2] == self._resource_grid.num_ofdm_symbols, \\\n            \"Shape of `y` is not as expected.\"\n\n    def call(self, inputs):\n        y, h_hat, err_var, no = inputs\n\n        # Transpose resource grid to shape:\n        # [batch_size, num_rx, num_rx_ant, num_tx, num_streams, num_ofdm_symbols, fft_size]\n        y_t = tf.transpose(y, [0, 1, 2, 5, 6, 3, 4])\n        h_hat_t = tf.transpose(h_hat, [0, 1, 2, 3, 4, 5, 6])\n        err_var_t = tf.transpose(err_var, [0, 1, 2, 3, 4, 5, 6])\n\n        # Precompute LLRs for each stream of each receiver\n        llr = self._detector([y_t, h_hat_t, err_var_t, no])\n        llr = tf.transpose(llr, [0, 1, 2, 5, 6, 3, 4])\n        llr = flatten_last_dims(llr, 2)\n\n        # The call of the detector is equivalent to the following, but does\n        # not require the constellation object, which can be `None`.\n        # llr = self._detector([y, h_hat, err_var, no])\n        #\n        # llr = self._stream_management.p2s(llr)\n        # llr = flatten_last_dims(llr, 2)\n        if self._output == \"bit\":\n            return split_dim(llr,\n                            [self._stream_management.num_bits_per_symbol, -1],\n                            self._stream_management.num_streams,\n                            axis=1)\n        else:\n            return llr\n```"
"To get the details of the function generate_5g_ranking, we should be clear that nowhere in the provided context the complete source code of the function is given; just its utilization is shown. Thus, it is not feasible to entirely reconstruct the function's code, which would typically necess a knowledge of parameters and implementation details.\n\nGenerate_5g_ranking is not a native python or Sionna's function, at least, it is not documented within the given context. The context discusses various operations on (5G) LDPC codes, Polar codes, and convolutional code, but there is no detailed discussion about a 'generate_5g_ranking' function. Please, refer to the documentation or source code of the underlying 5g module (if available) for the specifics of this function. In any case, the usage of the function seems to return values related to the Block Error Rate (BLER) of a given code.\n\nFor context\u2019s integrity, here is the only potentially related piece regarding the use of 'generate_5g_ranking':\n\nThe function is utilized with a 5G specific code component, possibly an LDPC code component, and it appears in a BLER (Block Error Rate) simulation, where `model` is an instance of a `BLER_mi` class that appears to relate to LDPC codes.\n\n```python\nmodel(\"5g_ranking_ldpc-512_643\", snr)\n```\nIn this snippet, '5g_ranking_ldpc-512_643' would be replaced with the actual name of the LDPC code component to be evaluated.\n\nTo understand how this function works, including its parameters, input, output, errors, and any related properties, the complete source code of 'generate_5g_ranking' and the documentation of the underlying code module (if this is indeed a part of Sionna's 5G module) should be referenced. This is crucial because working with simulations and error rates usually requires a deep understanding of the specific modulation and coding schemes being used, as well as the details of the code component's implementation. The information provided in the context is not sufficient to provide a comprehensive understanding of this function."
"To run the channel modeling in Sionna, follow these steps:\n\n1. Instantiate a channel model using the appropriate class from the Sionna API. For example, you can use `RayleighBlockFading` for a simple wireless channel model with Rayleigh fading.\n\n2. Setup the configuration for the channel model. This includes parameters such as the number of transmit and receive antennas, the number of time samples, and the delay spread.\n\n3. Generate a batch of channel responses. The channel model instance can be called as a function, passing the batch size and the number of time samples as parameters.\n\nHere is a simplified example that demonstrates these steps:\n\n```python\nfrom sionna.channel import RayleighBlockFading\n\n# Instantiate the channel model\nrayleigh = RayleighBlockFading(num_rx=1, num_rx=1, num_time_samples=10, delay_spread=30e-9)\n\n# Generate a batch of channel responses\nbatch_size = 1\nnum_time_samples = 100\nh = rayleigh(batch_size, num_time_samples)\n```\n\nIn this example, `h` is a complex-valued tensor that represents the channel response. The tensor has the shape `[batch_size, num_rx, num_rx, num_time_samples, 1]`, where `num_time_samples` is the number of time samples and `batch_size` is the number of examples in the batch."
"Here is the detailed information of load_alist:\n\n[sionna.fec.utils.load_alist(path)](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#load_alist)\n\nRead alist-file and return nested list describing the parity-check matrix.\n\nMany code examples can be found in [MacKay](http://w.lyphard.com/HG21). For further details, see the source code of [load_alist](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#load_alist).\n  \nInput\n    path (str) \u2013 Path to file to be loaded.\n\nOutput\n    alist (list) \u2013 A nested list containing the imported alist data.\n      \n\n\nsource code:\n```python\ndef load_alist(path):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Read alist-file and return nested list describing the parity-check matrix.\n\n    Many code examples can be found in [MacKay](http://w.lyphard.com/HG21).\n    For further details, see the source code of load_alist.\n    \"\"\"\n    with open(path, 'r') as f_alist:\n        content = f_alist.readlines()\n\n    # remove comments in alist files\n    content = delelte_comments(content)\n\n    m = -1 # flag for empty lines\n    n = -1 # flag for 'None of the above' (which is not removed in alist files)\n    v = -1 # flag for 'verbose' (also not removed in alist files)\n    nn = -1 # flag for 'n' (column annotation)\n\n    alist = [] # nested list to store alist data\n\n    for idx, line in enumerate(content):\n        data = line.split()\n\n        # skip non-standardized (exotic) formats)\n        if data[0][0] in ['%','$']:\n            print(\"Warning: Unsupported format/code.\")\n            print(\"Returning imported data (nested) without parsing:\")\n\n            # alist is nested list\n            return content[::]\n\n        if (data[0][0] == 'n'): # we are in the row/col section now\n            if nn == -1: # only parse if not set to -1 (i.e., not in 'None of the above' section)\n                nn = idx # set index for (row/col) annotations\n\n            row = []\n            for entry in data[1:]:\n                if entry == '1':\n                    row.append(1)\n                else:\n                    row.append(0)\n            alist.append(row)\n\n        elif (data[0][0] == 'm'): # we are now in the the column section\n            if v == -1: # only parse if not set to -1 (i.e., not in verbose section)\n                if n != nn: # check if all columns have same length\n                    print(\"Error: Length of colums in row-section is not consistent.\")\n\n            col = []\n            for entry in data[1:]:\n                if entry == '1':\n                    col.append(1)\n                else:\n                    col.append(0)\n            alist.append(col)\n\n        elif data[0][0] == 'v': # we are now in the verbose section\n            v = idx # set index for verbose\n\n            # do not remove \"None of the above\" section in verbose mode\n            if n != -1:\n                print(\"Warning: Removing \\\"None of the above\\\" (all-zero column) section.\")\n                alist = alist[:n] + alist[n+1:]\n\n        elif data[0][0] == 'c': # we found the column/row annotation)\n            n = idx # set index for 'None of the above'\n\n        else:\n            m = idx # set index for number of cols in row/col section\n\n    # sanity check, code must have 0 in \"None of the above section\"\n    if n != -1:\n        if sum([a[n] for a in alist]) > 0:\n            print(\"Error: Malicious \\\"None of the above\\\" section! \\\"n\\\" section is not all-zero.\")\n\n    # move row/column section to end of list (as in MacKay format)\n    if v == -1: # only do this if not in verbose mode\n        rowcolsection = alist[m+1:]\n        alist = alist[:m+1]\n        alist = alist + rowcolsection\n\n    return alist\n```"
"Here is the useful link of it [5G NR PUSCH Tutorial](https://nvlabs.github.io/sionna/tutorials/5G_NR_PUSCH_tutorial.html)."
"The `cameras` property of the `Scene` in the Sionna RT module is a representation of all the available cameras within the current scene. These cameras are defined either by the loaded scene file or through explicit instantiation using the API. The `cameras` property allows listing and access to all the defined cameras, which can be beneficial for various tasks such as rendering or programmatic camera manipulation.\n\nUsing the `cameras` property, one can print the details of all available cameras in the scene with the following line of code:\n\n```python\nprint(scene.cameras)\n```\nWhere `scene` is an instance of the `Scene` class. \n\nThe cameras are displayed with their names and a preview image that shows the scene from their perspective. The functionality of the `cameras` property extends further to the ability to use these cameras for rendering. This can either be done by referring to a specific camera by name:\n\n```python\nscene.render(\"scene-cam-0\") # Using the first camera of the scene for rendering\n```\nOr by using the `Camera` instance directly:\n\n```python\ncam = Camera(\"mycam\", position=[200., 0.0, 50.])\nscene.add(cam)\ncam.look_at([0.0,0.0,0.0])\nscene.render(cam) # Render using the Camera instance\n```\nIn the above example, a new camera \"mycam\" is created with a particular configuration. The camera is then added to the scene. The `look_at` function is used to make the camera point towards a specific coordinate. Finally, the `render` method is called on the `Scene` instance, with either the name of the previously created camera or the `Camera` instance itself as an argument.\n\nThe `cameras` property is closely related to other classes and methods like `preview`, `remove()`, `position`, `orientation` and `look_at()`, which allow a wide range of operations like previewing the scene from a camera's perspective, changing a camera's position and orientation, or making a camera look at a specific point in the scene. It is also possible to remove a camera from the scene's camera list.\n\nPlease note that while the `cameras` property lists all cameras in the scene, it is recommended to have at most one inactive camera as multiple inactive cameras can significantly slow down the performance of the scene."
"Here is the detailed information of RaisedCosineFilter:   \n  \n[sionna.signal.RaisedCosineFilter(beta, span_in_symbols, samples_per_symbol, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/signal/filter.html#RaisedCosineFilter)  \n\nLayer for applying a raised-cosine filter of length K to an input x of length N.\n\nThe raised-cosine filter is defined by\n$\\begin{split}h_{\\text{RC}}(t;\\beta) = \\begin{cases}\n      \\frac{1}{2^\\beta}\\left(1+\\beta\\left(\\frac{4}{\\pi}-1\\right)\\right) & \\text{ , if }t = 0\\\\\n     \\frac{\\beta}{2^\\beta}\\left(\\cos\\left(\\frac{\\pi}{4\\beta}\\right) + \\frac{\\sin\\left(\\frac{\\pi}{4\\beta}\\right)}{4\\beta}\\right)  & \\text{ , if }t = \\pm\\frac{1}{4\\beta}\\\\\n     \\frac{1}{\\pi}\\left(\\sin\\left(\\frac{\\pi t}{2\\beta}\\right) + \\frac{t}{\\beta}\\cos\\left(\\frac{\\pi t}{2\\beta}\\right)\\right)  & \\text{ , otherwise}\n\\end{cases}\\end{split}$\nwhere $\\beta$ is the roll-off factor.\nThe filter length K is equal to the filter span in symbols ( span_in_symbols) multiplied by the oversampling factor (samples_per_symbol). If this product is even, the length is incremented by one (as in [lupf]). The filter is applied through discrete convolution.\n\nFor normalization, the filter is applied through the \u201csame\u201d padding, and a scalar factor equal to the filter energy per sample is optionally applied ( normalize).\n\nThe time-windowing parameter window can be used to apply additional complex-valued post-filtering, e.g., to counter the effect of quantization in an ADC. This is achieved by using element-wise multiplication of the filter and the window. window must have the same length as the filter.\n\nThe dtype of the output is tf.complex64 or tf.complex128 corresponding to the dtype of the filter.\n\n**Parameters**\n\n- `beta` (float): Roll-off factor. Must be in the range $[0,1]$.\n- `span_in_symbols` (int): Filter span as measured by the number of symbols.\n- `samples_per_symbol` (int): Number of samples per symbol, i.e., the oversampling factor.\n- `window` ([N], tf.complex): An optional instance of Window that is applied to the filter coefficients. Defaults to None.\n- `normalize` (bool): If True, the filter is energy-normalized. Defaults to True.\n- `trainable` (bool): If True, the filter coefficients are trainable. Defaults to False.\n- `dtype` (tf.DType): The dtype of the filter coefficients. Must be either tf.float32 or tf.float64. Defaults to tf.float32.\n\n**Input**\n\n- `x` ([\u2026, N], tf.complex): The input to which the filter is applied. The filter is applied along the last dimension.\n- `padding` (string): Padding mode for convolving x. Must be one of \"full\", \"same\", or \"valid\". Case insensitive. Defaults to \"same\".\n- `conjugate` (bool): If True, the filter is applied in its conjugate form. Defaults to False.\n\n**Output**\n\n- `y` ([..., M], tf.complex): Filtered input. It is tf.cast to the dtype of the filter.\n\n**Property**\n\n- `aclr`: The adjacent channel leakage ratio (ACLR) is 3.911344238954186 dB. This value is from [Google, \u201cEnabling Technologies for  Wireless Communication\u201d, 2019.](https://tf.nvlabs.com/_downloads/Enabling_Technologies_for_Wireless_Communication__ECC_WS_2019_.pdf#page=27).\n\n**Example**\nThe following code snippet shows how to use this class to filter some data x:\n\n```python\n# Create the (trainable) raised-cosine filter\nrc = RaisedCosineFilter(beta=0.35, span_in_symbols=8, samples_per_symbol=8, window=None, normalize=True, trainable=True, dtype=tf.complex64)\n\n# x: Usr data with shape [...,n], where n is the number of symbols\ny = rc(x)\n\n```"
"Here is the detailed information of Upsampling:   \n  \n[sionna.signal.Upsampling(samples_per_symbol, num_symbols, axis=- 1, fill_value=0, shape=Non, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/signal/utils.html#Upsampling)\n\nUpsamples an input by inserting zeros.\n\nThis layer performs multiple \u201cinsertions\u201d of zero samples into the the signal along a user-specified axis.\n\n### Parameters\n\n- `samples_per_symbol` (int): The upsampling factor. This is the number of zeros to insert between samples.\n- `num_symbols` (int): The number of symbols, i.e., elements, to upsample the signal to. This is useful when, e.g., you want to upsample a channel impulse response to the number of samples per symbol for subsequent symbol mapping and further data transmission, as it defines the \u201coversampling\u201d factor.\n- `axis` (int): The dimension to upsample on. Must not be the first dimension.\n- `fill_value` (float): The value to use for the zero-insertion. Must be either zero or tf.cast(zero, signal.dtype). Defaults to zero.\n- `shape` ([..., n], tf.float): Defines the shape of the upsampling filter. The number of elements in the last dimension must not be larger than n samples per symbol. If it has fewer elements, it will be zero-padded at the end. This means that one can also use pulse shaping filters of length much smaller than samples_per_symbol by properly setting this parameter. If shape is None, then a \u201cboxcar\u201d filter of length samples_per_symbol is used. Defaults to None.\n- `dtype` (tf.DType): The dtype of the filter coefficients. Defaults to tf.complex64.\n\n### Input\n\n- `x` ([..., n], tf.complex): The signal to upsample. `n` is the number of time-domain samples along the axis to be upsampled.\n\n### Output\n\n- `y` ([..., num_symbols * n], tf.complex): The upsampled signal. For each \u2018\u2026\u2019 up to the second to last dimension of x, the upsampled signal has `num_symbols` * n samples along the axis, where `num_symbols` is the `num_symbols` specified in the constructor."
" \n\n<polarization_model_1> is part of 3GPP 38.901 standard and it is one of the two possible polarization models used for transforming antenna patterns in radio propagation modelling.\n\nThe function takes the following inputs:\n\n- c_theta (*array_like, complex*): Zenith pattern\n- c_phi (*array_like, complex*): Azimuth pattern\n- slant_angle (*float*): Slant angle of linear polarization [radian]\n\nAnd gives the following output:\n\n- c(*array_like, complex*): Absolute value of the linear antenna pattern. This will have the same dimensions as the inputs c_theta and c_phi. It's not a separate output, rather it's a derived quantity from the inputs.\n\n'polarization_model_2' works in a similar fashion, but takes a different set of inputs. It is a model for polarized antennas in radio propagation modelling, like 'polarization_model_1'. The function takes the following inputs:\n\n- c (*array_like, complex*): Zenith pattern\n- slant_angle (*float*): Slant angle of the linear polarization [radian]\n\nAnd provides the same output as 'polarization_model_1':\n\n- c_theta (*array_like, complex*): Zenith pattern\n- c_phi (*array_like, complex*): Azimuth pattern\n\nWhile 'polarization_model_1' requires two input parameters corresponding to the zenith and azimuth patterns, 'polarization_model_2' requires only a single input parameter, which corresponds to the combined or resultant pattern of the antenna. \n\nThe choice between these two depends on how the antenna patterns are defined or measured, and also on the specific use case or model being implemented. \n\nIt is also worth mentioning that both of these functions can accept either 2D or N-dimensional arrays as inputs, which allows for some flexibility in how antenna patterns are represented for the purposes of polarization modelling."
"Here is the detailed information of Mapper:   \n  \n[sionna.mapping.Mapper(constellation=None, num_streams_per_cell=None, num_bits_per_symbol=None, constellation_type=None, gray=False, real_valued=False, trainable=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Mapper)  \n\nInitializes a mapper.\n\nThe mapper maps binary tensors of binary tensors of bits to points from a constellation.\n\nIf the mapper is configured to be trainable, the constellation can be trained using gradient-based optimization. Note that not all types of constellations are trainable. A trainable constellation can be also rotated to enable the learning of soft symbols.\n\n### Parameters\n\n- `constellation` (Constellation): An instance of Constellation or None. If None, num_bits_per_symbol and constellation_type must be provided.\n- `num_streams_per_cell` (int): Number of transmitted streams per cell. Only required for constellation_type=\"qam\" or constellation_type=\"pam\".\n- `num_bits_per_symbol` (int): Number of bits per constellation symbol, i.e., 1 for BPSK, 2 for QPSK, 3 for 8PSK, 4 for 16QAM, and 5 for 32QAM. Only required for constellation_type in [\"qam\", \"pam\"].\n- `constellation_type` (string): The type of the constellation, options are \"qam\", \"pam\", or \"custom\". For \"custom\", an instance of Constellation must be provided or an error is raised. Only required for constellation is None.\n- `gray` (bool): A boolean that indicates if the constellation is Gray-labelled. Only required for constellation_type in [\"qam\", \"pam\"]. Defaults to False.\n- `real_valued` (bool): A boolean, defaults to False. If True, the mapper outputs real-valued symbols instead of complex-valued symbols. Note that the two resulting streams correspond to the real and imaginary components of the constellation.\n- `trainable` (bool): A boolean to make the constellation trainable. Defaults to False.\n- `dtype` (tf.DType): The data type of the input and output, which must be either tf.complex64 or tf.complex128. Defaults to tf.complex64.\n\n### Input\n\n- `x` ([..., n], or [..., 2n], tf.float32): A tensor of binary values. If the constellation is real-valued, the dtype of x must be tf.float. The last dimension of x must be a multiple of 2 if real_valued is True. It is not required that the number of bits per symbol n is an integer.\n\n### Output\n\n- `[...,n/num_streams_per_cell]`, or `[...,num_streams_per_cell, n/num_streams_per_cell/num_bits_per_symbol]`, tf.float32: A tensor of real or complex values representing the mapped constellation symbols. If real_valued is True, the output is a tensor of real values.\n\n**Note: ** If num_bits_per_symbol is an integer that is a power of two (e.g., 1, 2, 4, 8, 16, ...), the symbols are mapped in a different (i.e., bit-reversed) order to ensure a sub-optimal but still very common ordering that is often utilized in system implementations. It can be observed that all QAM and PAM constellations are Gray-labelled when num_bits_per_symbol is an integer that is a power of two. This applies to the 2^n PAM constellations as they are defined here (see [J. H. Winters, \u201cHow good is two good? A new two-dimensional measure of constellations\u201d, IEEE Trans. Commun., vol. 54, no. 7, Jul. 2006.]).\n\n### Properties\n\n- `constellation`: The trainable constellation, or None.\n- `num_bits_per_symbol`: The number of bits per constellation symbol, (potentially) considering constellation_type and the gray flag.\n- `trainable`: Returns True if the constellation is trainable, False otherwise."
"The `LDPC5GEncoder` class is part of the Sionna library and is used to encode data using the 5G compliant Low-Density Parity-Check (LDPC) code as defined by the 3rd Generation Partnership Project (3GPP) specifications. Based on the context, the parameters and their types for the `LDPC5GEncoder` constructor are as follows:\n\n- `k` (int): This is the input parameter representing the number of information bits per codeword. It must be between 1 and 3824, inclusive.\n\n- `n` (int): Here, 'n' refers to the total number of codeword bits. It must be between 1 and 32768, inclusive.\n\n- `dtype` (tf.DType or None): Defines the datatype for internal calculations and the output datatype. This parameter is optional and defaults to `tf.float32`. \n\nThe function to create the `LDPC5GEncoder` instance and use these parameters is shown below for reference:\n\n```python\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\n\n# Create an LDPC5GEncoder instance with the required parameters\nencoder = LDPC5GEncoder(k=100, n=200)\n\n# Show that the encoder is created with the given parameters\nencoder.info()\n```\nThe `encoder.info()` method prints the details of the encoder including the values of the `k` and `n` that were passed during the instantiation."
"To explain the mentioned functions, it requires explaining some terminologies related to MIMO (Multi-Input Multi-Output) systems. For a quick overview, a MIMO system utilizes multiple antennas at both the transmitter and receiver ends. This allows multiple data streams to be transmitted and received simultaneously, which can significantly increase the data rate.\n\nNow, getting into the functions:\n\n1. `complex2real_vector()` - This function transforms a complex-valued vector into its real-valued equivalent. In the context of MIMO systems, this transformation is typically required when dealing with real and imaginary parts of complex signals separately.\n\n2. `real2complex_vector()` - This is the inverse operation of `complex2real_vector()`. It takes a real-valued vector as input and converts it into a complex-valued equivalent vector. In the context of MIMO systems, this transformation can be used to reintegrate separate real-valued signals into a complex-valued representation.\n\n3. `complex2real_matrix()` - This function transforms a complex-valued matrix into its real-valued equivalent. In the context of MIMO systems, this transformation could be applied to a channel matrix representing the paths of signal propagation from multiple transmitters to multiple receivers.\n\n4. `real2complex_matrix()` - This is the inverse operation of `complex2real_matrix()`. It converts a real-valued matrix into its complex-valued equivalent. In the MIMO context, this could be used to take a real-valued channel impulse response and reconstruct the complex-valued channel matrix for the propagation paths.\n\n5. `complex2real_covariance()` - This function computes the real-valued equivalent representation of a given complex-valued covariance matrix. In the MIMO context, this could be used to represent the covariance of the noise or interference in the propagation environment, which can have a complex correlation structure.\n\n6. `real2complex_covariance()` - This is the inverse operation of `complex2real_covariance()`. It converts a real-valued covariance matrix into its complex-valued equivalent. In the MIMO context, this could be used to convert the noise covariance matrix back to its original complex-valued representation.\n\n7. `complex2real_channel()` - This function computes the real-valued equivalent representation of a complex-valued MIMO channel. It returns the real-valued equivalent received signals, channel matrices, and noise covariance matrices. This function might be used in scenarios where complex-valued operations need to be converted into their real-valued equivalents for processing.\n\n8. `real2complex_channel()` - This is the inverse operation of `complex2real_channel()`. It returns the complex-valued equivalent representations of the signals, matrices, and covariances. It could be used to reverse a real-valued transformation for further complex-valued processing.\n\nSince the explanations provided are based on the context and understanding the functions in the Sionna module would require reviewing the entire codebase, these explanations should be verified in the actual Sionna documentation. The practical use cases and the exact behaviors of these functions in the context of MIMO systems should also be double-checked in the relevant documentation or literature. \n\nFor learning about MIMO systems, detailed and accurate descriptions as mentioned in the functions' documentation can be found in the standards like those from the IEEE or in signal processing textbooks. For a deeper understanding, one could study the \"evolution\" of such signals in domains like communication theory, signal processing, and electromagnetic wave propagation. \n\nAn important note is that the complex-to-real and real-to-complex transformations are common in many signal processing and communications applications to leverage mathematical and computational simplifications. However, the specific usage and validity of these functions in the Sionna module should be confirmed through the module's documentation and in the specific context in which the module is used."
"Here is the detailed information of FlatFadingChannel:   \n  \n[sionna.channel.FlatFadingChannel(num_tx_ant, num_rx_ant, spatial_corr=None, add_awgn=True, return_channel=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/channel/flat_fading_channel.html#FlatFadingChannel)  \nApply (time-invariant) channel matrices to an input vector.\n\nThis class applies a given channel matrix to an input tensor. Additionally, AWGN noise can be added and the channel realizations be returned. Mathematically, for a channel $\\\\mathbf{H} \\in \\mathbb{C}^{M \\\\times K}$, and an AWGN noise vector $\\\\mathbf{n}  \\sim \\mathcal{CN}(\\\\mathbf{0}, \\\\mathbf{I} N_0)$, the output is $\\\\mathbf{y} = \\\\mathbf{H}\\\\mathbf{x} + \\\\mathbf{n}$, where $\\\\mathbf{x} \\in \\mathbb{C}^{K}$ is the input.\n\nWhen called, this layer first generates a random channel realization. Then, the channel is applied to the input vector (optionally) and the AWGN noise is (optionally) added.\n\nFor the AWGN noise, different noise powers per dimension are supported through the noise power spectral density $N_0$. E.g., for a complex baseband system, $N_0$ could be a scalar, effectively scaling the noise power per complex dimension. For a system including a discrete Fourier transform, $N_0$ could be a tensor scaling the noise power differently frequency bin. In the general case, $N_0$ is a non-negative definite tensor that is  broadcastable to the shape of $\\\\mathbf{H}\\\\mathbf{x}$.\n\nFor the output of this layer, there are three options:\n\n-  (default) **y**: the output of the channel.\n-  **(y, h)**: tuple of the channel output and the channel realization. This is the default behavior.\n-  **h**: the channel realization. This is useful, e.g., for equalization.\n\n**Parameters**\n\n- `num_tx_ant` (int): Number of transmit antennas ($M$)\n- `num_rx_ant` (int): Number of receive antennas ($K$)\n- `spatial_corr` (SpatiaCorrelation, None): An optional SpatiaCorrelation object. If not None, the channel apply() function is expected to be passed `spatial_corr` as an additional argument.\n- `add_awgn` (bool): Indicates if AWGN should be added to the channel output. Defaults to True.\n- `return_channel` (bool): Indicates if the underlying channel realizations should be returned. Defaults to False. This is only effective if `add_awgn` is False.\n- `dtype` (tf.DType): Datatype for internal calculations and the output dtype. Defaults to tf.complex64.\n\n**Input**\n\n- `x` ([..., num_tx_ant], tf.complex): Input to the channel. The transmit signal.\n- `no` (float or [..., num_rx_ant, num_tx_ant], tf.complex): Scalar or tensor defining the noise power. In the general case, this is a tensor that is broadcastable to the shape of [..., num_rx_ant, num_tx_ant].\n\n**Output**\n\nOne of the following:\n\n-  `y` ([..., num_rx_ant], tf.complex): Output of the channel. The receive signal.\n-  `(y, h)` ([..., num_rx_ant], tf.complex): Tuple of the channel output and the channel realization. The channel realization is only returned if `return_channel` is True. Numpy arrays are replaced by tensors to simplify handling (e.g., addition of noise may introduce different dtypes).\n-  `h` ([..., num_rx_ant], tf.complex): Channel realization. The channel realization is only returned if `return_channel` is True. Numpy arrays are replaced by tensors to simplify handling (e.g., addition of noise may introduce different dtypes).\n\n**Note:** If you want to use this layer in Graph mode with XLA, i.e., within a function that is decorated with @tf.function(jit_compile=True), you must set sionna.Config.xla_compat=true. See xla_compat."
"Here is the definition of PilotPattern: sionna.ofdm.PilotPattern(mask, pilots, trainable=False, normalize_pilot=False, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/pilot_pattern.html#PilotPattern)  \n\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"Class defining a pilot pattern for an OFDM system\"\n\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.layers import Layer\n\nclass PilotPattern():\n    def __init__(self, mask, pilots, trainable=False,\n                 normalize_pilot=False, dtype=tf.complex64):\n        r\"\"\"\n        Creates a :class:`~sionna.ofdm.PilotPattern` instance.\n\n        Defines a pilot pattern over which an OFDM resource grid is\n        initialized. Every transmitter's  streams is supposed to sent a\n        distinct pilot sequence defined by ``pilots`` parameter.\n\n        Parameters\n        ----------\n        mask : [num_tx, num_tx_ant, num_ofdm_symbols, fft_size], tf.bool\n            A mask that indicates which resource elements are reserved\n            for pilot transmissions by each transmitter and its respective\n            streams. Note that ``num_streams_per_tx`` is either equal to\n            ``num_tx_ant`` or a  to a a subset of it. If\n            ``normalize_pilot`` is `True`, the  mean of ``pilots`` is\n            set to zero for every transmitter and stream.\n\n        pilots : [num_tx, num_tx_ant, num_pilot_symbols], tf.complex\n            The pilot symbols to be transmitted.\n\n        trainable : bool\n            If `True`, the pilots are trainable variables.\n            Defaults to `False`.\n\n        normalize_pilot : bool\n            If `True`, the pilots are normalized to have unit power.\n            Defaults to `False`.\n\n        dtype : tf.DType\n            The dtype of ``pilots``. Defaults to `tf.complex64`.\n\n        Output\n        ------\n        : :class:`~sionna.ofdm.PilotPattern`\n            A :class:`~sionna.ofdm.PilotPattern` instance.\n        \"\"\"\n        super().__init__()\n        self._mask = mask\n        self.pilots = pilots\n        self.trainable = trainable\n        self.normalize_pilot = normalize_pilot\n        self._dtype = dtype\n\n    @property\n    def mask(self):\n        return self._mask\n\n    @property\n    def normalize_pilot(self):\n        return self._normalize_pilot\n\n    @normalize_pilot.setter\n    def normalize_pilot(self, value):\n        self._normalize_pilot = bool(value)\n\n    @property\n    def trainable(self):\n        \"\"\"Indicates if the pilots are trainable.\"\"\"\n        return self._trainable\n\n    @trainable.setter\n    def trainable(self, value):\n        self._trainable = bool(value)\n\n    @property\n    def pilots(self):\n        \"\"\"The predefined set of pilot symbols.\"\"\"\n        return self._pilots\n\n    @pilots.setter\n    def pilots(self, value):\n        value = tf.cast(value, dtype=self._dtype)\n        if self._normalize_pilot:\n            # we need to broadcast the mean value to the last dimension of\n            # pilots. This is done automatically by tensorflow when adding\n            # tensors of different shapes.\n            value = value - tf.reduce_mean(value, axis=-1, keepdims=True)\n        self._pilots = value\n\n    def show(self, show_pilot_ind=False):\n        \"\"\"\n        Plots the pilot pattern.\n\n        The figure shows the pilot symbols indices in a [n,m] formatted\n        matrix where the resource grid for the ``m`` streams has been\n        collapsed to a single stream.\n\n        Input\n        -----\n        show_pilot_ind : bool\n            If `True`, the indices of the pilot symbols are shown.\n            Defaults to `False`.\n\n        Output\n        ------\n        : :class:`matplotlib.pyplot.Figure`\n            Figure object.\n        \"\"\"\n        num_tx = self._mask.shape[0]\n        num_streams_per_tx = self._mask.shape[1]\n        num_pilot_symbols = np.sum(self._mask)\n\n        # compute the number of columns for the figure\n        num_cols = 1 + num_streams_per_tx\n        tx_ind = list(range(num_tx))\n        fig = tf.zeros([num_pilot_symbols, num_cols], dtype=tf.int32)\n\n        # separate figure for pilot indices\n        if show_pilot_ind:\n            fig2 = tf.zeros([num_pilot_symbols, 1], dtype=tf.int32)\n\n        # fill in indices and pilot symbols\n        c = 0\n        for i in range(num_tx):\n            fig[c:\n                c+\n                self._mask[i].numpy().sum(), 0] = tx_ind[i]\n            c += self._mask[i].numpy().sum()\n            if show_pilot_ind:\n                cpi = np.where(self._mask[i].numpy().flatten())[0]\n                cpi = np.stack(cpi, 1)\n                cpi[range(c, c+self.pilots[i].shape[0]), 0] = i\n                cp = np.zeros([self._mask[i].numpy().sum(), 1],\n                    dtype=tf.int32)\n                cp[0:self._mask[i].numpy().sum()] = cpi\n                fig2[  c:\n                    c+\n                    self._mask[i].numpy().sum(), 0] = tx_ind[i]\n                fig2[ c:\n                    c+\n                    self._mask[i].numpy().sum(),\n                    0] = tx_ind[i]\n        pilotc = 0 # counter for pilots\n        for j in range(num_streams_per_tx):\n            fig[ 0:\n                self._mask[tx_ind[0]\n                    ].numpy().sum(), j+1] = tx_ind[0]\n            if show_pilot_ind:\n                fig2[0:\n                    self._mask[tx_ind[0]\n                        ].numpy().sum(), 0] = tx_ind[0]\n            c =  self._mask[tx_ind[j+1]].numpy().sum()\n            fig[0:c, j+1] = tx_ind[j+1]\n            if show_pilot_ind:\n                cp = np.concatenate(\n                        [cp,\n                        np.reshape(fig[0:c,0], (-1, 1)) + pilotc], axis=0)\n                pilotc += 1 # increment counter for pilots\n            else:\n                cp = np.zeros([c, 1], dtype=tf.int32)\n            cp[0:c] =  tx_ind[j+1]\n            cp[0:self._mask[tx_ind[j+1]].numpy().sum(), 0] = tx_ind[j+1]\n            cp[0:self._mask[tx_ind[j+1]].numpy().sum()] = tx_ind[j+1]\n            fig2[  c:\n                c+\n                self._mask[tx_ind[j+1]].numpy().sum(), 0] = tx_ind[j+1]\n            fig2[ c:\n                c+\n                self._mask[tx_ind[j+1]].numpy().sum(),\n                0] = tx_ind[j+1]\n            if self._trainable:\n                if j==0:\n                    ps = self._pilot_trainable[tx_ind[j],\n                                        tx_ind[j+1],\n                                        0:pilots[j].shape[0],\n                                        0]\n                else:\n                    ps = np.reshape(self._pilot_trainable[tx_ind[j],\n                                        tx_ind[j+1],\n                                        0:pilots[j].shape[0]\n                                        ,0], pilots[j].shape)\n            else:\n                ps = pilots[j]\n            fig[  c:\n                c+\n                self._mask[tx_ind[j+1]].numpy().sum(), j+1] = ps\n            if show_pilot_ind:\n                fig[ c:\n                    c+\n                    self._mask[tx_ind[j+1]].numpy().sum(), 0] = ps\n            if show_pilot_ind:\n                fig[ c:\n                    c+\n                    self._mask[tx_ind[j+1]].numpy().sum(),\n                    0] = ps\n            fig[ c:\n                c+\n                self._mask[tx_ind[j+1]].numpy().sum(), 0] = tx_ind[j+1]\n            fig[ c:\n                c+\n                self._mask[tx_ind[j+1]].numpy().sum(), 1] = tx_ind[j+1]\n\n        tx_ind = tx_ind[1:] + [tx_ind[0]] # round-robin for the the last tx\n\n        # add zero for guards\n        max_len = np.max(np.sum(self._mask, axis=-1))\n        fig = tf.pad(fig, [[0, 0], [0, 1]]) # for zero eol symbols\n        fig = tf.pad(fig, [[0, 0], [0, 1]]) # for guards\n        eols = np.mod(np.arange(max_len+2), 12)\n        eols[::2] = 7\n        for i in range(0, max_len+2, 14):\n            fig[i  +1, -2] = eols[i  +1]\n            fig[i+7, -1] = eols[i+7]\n\n        import matplotlib.pyplot as plt\n\n        fig = fig.numpy()\n\n        fig2 =  fig2.numpy()\n\n        c = 0 # counter for streams\n        max_tx = fig.shape[0]\n        for tx in range(max_tx):\n            fig[tx, 0] =  max_tx - c -1 # tx indicdes\n            c_ = 0 # used to cound the number of zero eol symbols\n            for stx in range(num_streams_per_tx):\n                fig[tx, stx+1] = max_tx - self._mask[tx, stx].numpy().sum() - c_ -1\n                c_ += fig2[tx, stx]\n            c += 1\n\n        # collapse tx 0 and tx 1 for visualization\n        fig = np.sum(fig, axis=0)\n        if show_pilot_ind:\n            fig2 = np.concatenate([fig2, np.zeros([1, 1])], axis=1)\n            # move last sybol to previous fig\n            fig2[-2:, :] = fig2[-1:, :]\n            fig2[-1, :] = 0\n            # add dummy to fig\n            fig_ = np.zeros([1,1])\n            fig2 = np.concatenate([fig2, fig_], axis=1)\n            fig2[-1, 0] = max_tx-1\n            # update max len\n            max_len += 1\n        else:\n            fig2 = np.zeros([1, 1])\n\n        fig = np.concatenate([fig[0:max_len+1],   fig2[0]],  axis=0)\n        fig[  max_len  ,0] = -1 # insert eol symbol\n\n        fig = tf.image.rot90(fig, k=1) # rotate the figure\n\n        fig = tf.cast(fig, dtype=tf.float32)\n        # add white space\n        fig_ = tf.image.resize_with_pad(\n                        tf.image.resize_with_pad(\n                            tf.zeros([1, 1, 1], tf.float32), [250, 250]),\n                        [max_len+1, 25])\n        fig = tf.image.rgb_to_grayscale(\n            tf.image.cast_to_float32(\n                tf.clip_by_value(\n                    tf.concat((fig, fig_), 2), 0, 255)))\n        fig_ = fig.numpy()\n        imax = np.max(fig_)\n        fig_ = fig_/imax # rescale\n\n        import matplotlib.pyplot as plt\n\n        plt.figure()\n        plt.imshow(fig_)\n        plt.title(\"Pilot Pattern\")\n        plt.axis(\"off\")\n        plt.show()\n        return plt\n```"
"To import the necessary packages for using Sionna, follow these steps:\n\n1. Import TensorFlow:\n```python\nimport tensorflow as tf\n```\n\n2. Set the TensorFlow log level to '3' to avoid warnings:\n```python\ntf.get_logger().setLevel('3')\n```\n\n3. Import NumPy:\n```python\nimport numpy as np\n```\n\n4. Import necessary Sionna modules:\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n5. Import required Sionna classes:\n```python\nfrom sionna.rt import Scene, PlanarArray, Transmitter, Receiver\nfrom sionna.rt.scene import load_scene\nfrom sionna.rt.utils import r_hat\nfrom sionna.constants import PI\n```\n\nPlease note that the 'try' block is used to first attempt the import of the Sionna package. If it's not successful, the code installs the package using pip and then imports it. \n\nAlso, the code assumes that you have already installed the Sionna package and its dependencies. If not, you may need to add an installation command before importing the package:\n\n```python\n# Install Sionna and its dependencies\nos.system(\"pip install sionna\")\n``` \n\nAfter installing the package, you can run the code again to import the necessary packages."
"LinearInterpolator is to be found in the sionna.ofdm.channel_estimation.\n\nGiven a channel estimate for the pilot-carrying resource elements and their error variances, this interpolates accross sub-carriers and OFDM symbols to provide channel estimates for the remaining resource elements.\nsource code: [LinearInterpolator](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/channel_estimation.html#LinearInterpolator)\n\nIn the context, the usage of LinearInterpolator is shown as follows:\n\n```python\nest = MIMOOFDMMPE(scratch)[...,num_pilot_symbols:]\n  # Select the nonzero elements of the channel matrix\n  h_hat = channel_estimates[:,:num_tx, :num_streams_per_tx, :num_pilot_symbols]\n  err_var = channel_est_error[..., :num_tx, :num_streams_per_tx, :num_pilot_symbols]\n  # Let's first build a Keras model with XLA, using default value for everything but the number of samples\n  if xla_supported:\n    keras.backend.set_floatx('tf.float32')\n    os.environ[\"TF_XLA_FLAGS\"] = \"--tf-xla-\"\n    # Insert the algorithm as first layer of a Keras model\n    mimoofdmmpe = MIMOOFDMMPE(scratch)\n    # Setting `trainable` to False avoid a warning when saving the model\n    mpe_layer = MIMOOFDMMPE(scratch, linear_pilots = True)\n    mpe_layer.trainable = False\n    interpolator = LinearInterpolator(pilot_pattern)\n    ofdm_estimator = OFDMChannelEstimator(pilot_pattern, interpolator, mimoofdmmpe, 'LS')\n    mimo_detector = MIMODetector(scratch, detector=detector, output=opt, mpe=mpe_layer)\n    end_to_end = KerasSymbolWrapper([cyclic_prefix_remover, mimo_detector, demapper, decoder],\n                                    forward_call=True)\n```\n\nThe parameters of LinearInterpolator are as following: \n- **pilot_pattern**: An instance of PilotPattern.\n- **time_avg**: If set to True, averages the channel over the time dimension. This is recommended for channels that do not vary substantially from an OFDM symbol to another. Defaults to False.\n  \nInput of the class\\_estimates (like `h_hat`): A tensor of channel estimates of shape `[num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols]`, tf.complex.\n\nerr_var (like `err_var`): A tensor of channel estimation error variances of shape `[num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols]`, tf.complex.\n\nOutput of the class: (h_hat, err_var)\n- **h_hat**: A tensor of channel estimates across the entire resource grid for all transmitters and streams, of shape `[num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size]`, tf.complex.\n- **err_var**: Channel estimation error variances across the entire resource grid for all transmitters and streams, of shape `[num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size]`, tf.float."
"{'source code': 'import tensorflow as tf\\nfrom collections import namedtuple\\n\\nConstellationConfig = namedtuple(\\'ConstellationConfig\\',\\n    [\\'constellation_type,\\' \\'num_bits_per_symbol\\', \\'constellation\\'])\\n\\#\\n# Note: The computation of the mean and var of the constellation points\\n#       is based on the assumption that the constellation points have been\\n#       generated independent and identically distributed (i.i.d.) . This\\n#       is not the case for custom constellations for which this assumpsion does\\n#       not hold. However, for custom constellations, one can provide precomputed\\n#       moments through the \\'constellation_moments\\' parameter of the LDPC5GDecoder.\\n#\\nclass SymbolLogits2Moments(tf.keras.layers.Layer):\\n    \"\"\"\\n    Computes the mean and variance of a constellation from logits\\n    (unnormalized log-probabilities) on the\\n    constellation points.\\n\\n    More precisely, given a constellation :math:`\\\\mathcal{C} = \\\\left[ c_0,\\\\dots,c_{N-1} \\\\\\n`    of size :math:`N`, this layer computes the mean and variance\\n    according to\\n\\n    .. math::\\n        \\\\begin{align}\\n        \\\\mu &= \\\\sum_{n = 0}^{N-1} c_n \\\\Pr \\\\left(c_n \\\\lvert \\\\mathbf{\\\\ell} \\\\right)\\\\\\\\\\n        \\\\nu &= \\\\sum_{n = 0}^{N-1} \\\\left( c_n - \\\\mu \\\\right)^2 \\\\Pr \\\\left(c_n \\\\lvert \\\\mathbf{\\\\ell} \\\\right)\\n    \\\\end{align}\\n\\n    where :math:`\\\\mathbf{\\\\ell} = \\\\left[ \\\\ell_0, \\\\dots, \\\\ell_{N-1} \\\\right]` are the logits, and\\n\\n    .. math::\\n        \\\\Pr \\\\left(c_n \\\\lvert \\\\mathbf{\\\\ell} \\\\right) = \\\\frac{\\\\exp \\\\left( \\\\ell_n \\\\right)}{\\\\sum_{i=0}^{N-1} \\\\exp \\\\left( \\\\ell_i \\\\right) }.\\n\\n    Parameters\\n    ----------\\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\\n        must be provided.\\n \\\\n        :mean:`constellation_type` is the dtype\\n\\n    num_bits_per_symbol : int\\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\\n        Only required for ``constellation_type`` in [\\'qam\\', \\'pam\\'].\\n\\n    constellation : Constellation\\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\\n        In the latter case, ``constellation_type`` and ``num_bits_per_symbol``\\n        must be provided.\\n\\n    dtype : One of [tf.float32, tf.float64] tf.DType (dtype)\\        The dtype for the input and output.\\n\\n    Input\\n    -----\\n    logits : [,n, num_points], tf.float\\n        Logits on constellation points.\\\\n    Output\\n    -----\\n    mean : [,n], tf.float\\n        The mean of the constellation.\\n\\n    var : [,n], tf.float\\n        The variance of the constellation.\\n    \"\"\"\\n\\n    def __init__(self, constellation_type=None, num_bits_per_symbol=None, constellation=None, dtype=tf.float32, **kwargs): #,l_min, l_max,  num_points, dtype=tf.float32):\\n\\n        if constellation is None:\\n            assert dtype is not None, \\\\\\n                \"dtype  must be provided if constellation is None\"\\n            assert constellation_type is not None, \\\\\\n                \"constellation_type must be provided if constellation is None\"\\n            assert num_bits_per_symbol is not None, \\\\\\n                \"num_bits_per_symbol must be provided if constellation is None\"\\\\n            constellation_config = ConstellationConfig(\\\\n                                            constellation_type,\\\\n                                            num_bits_per_symbol,\\\\n                                            dtype=dtype)\\\\n        else:\\n            assert dtype in [None, constellation.dtype], \\\\\\n                \"Invalid dtype for constellation\"\\n            constellation = constellation\\n            num_bits_per_symbol = constellation.num_bits_per_symbol\\n            dtype = constellation.dtype\\n            # Check that all parameters are set for the chosen constellation_type\\n            if constellation_type is not None:\\\\n                assert constellation_type==constellation.constellation_type, \\\\\\n                    \"constellation_type does not match for this constellation\"\\\\n                if num_bits_per_symbol is not None:\\\\n                \\tassert num_bits_per_symbol==constellation.num_bits_per_symbol, \\\\\\n                    \"num_bits_per_symbol does not match for this constellation\"\\\\n\\n        super().__init__(dtype=dtype, **kwargs)\\n\\n        self._c = constellation\\n        self._num_bits_per_symbol = num_bits_per_symbol\\n        self.p = tf.nn.softmax(logits, axis=-1)\\n\\n    def call(self, logits):\\n\\n        # Compute the constellation points\\n        points = self._c.compute_constellation_points(\\\\n                                    normalize=False, ensure_positive=True) #, l_min, l_max, num_points)\\\\n\\n        mean = tf.reduce_sum(self.p*points, axis=-1, keepdims=True)\\n        variance = tf.reduce_sum(self.p*(tf.square(points-mean)), axis=-1)\\\\n\\n        return tf.squeeze(mean, axis=-1), tf.squeeze(variance, axis=-1)    ', 'constellation_type': None, 'input': 'logits : [,n, num_points], tf.float', 'output': ' mean : [,n], tf.float  \\n var : [,n], tf.float  '}"
"The 'cir_to_ofdm_channel' function is a part of the radio propagation tutorial within the Sionna wireless propagation module. This function computes the frequency response of the radio channel at given frequencies, using the raw complex impulse responses (CIRs) of the channel which are generated by a channel impulse response function, such as 'cir_to_time_channel'.\n\nThe function's operation involves the computation of the channel frequency responses using the raw complex baseband channel impulse responses. It essentially calculates the effect of a wireless channel's characteristics on a signal's transmission by converting the raw CIRs to the frequency domain and then computing the channel frequency response for each relevant frequency.\n\nTaking a look at how this function is utilized within the given context, the relevant frequency was first computed using the 'subcarrier_frequencies' function. Then, the 'cir_to_ofdm_channel' function was called with parameters including the required number of guard subcarriers, number of fast fading filter taps, and normalization boolean. This resulted in the desired frequency responses being computed and normalized (if normalization was requested), and returned as output, ready to be used in further processing of the signal.\n\nTo summarize, 'cir_to_ofdm_channel' plays a key part in the radio propagation modelling by helping to compute the frequency responses from raw complex impulse responses of the wireless channel. These computations are essential in understanding and working with the effects wireless propagation may have on signals."
"The `EPDetector` class belongs to the module 'sionna.mimo' and is one of the Utilities classes used in implementing a MIMO (Multi-input Multi-output) system. The class stands for Expectation Propagation (EP) MIMO Detector and it relies on the concept of Expectation Propagation for handling MIMO detection.\n\nThe class is actually a layer used in defining a model for MIMO link simulations. It takes several input parameters such as the number of receive antennas, the number of transmitted streams, the binary flag for either decoding or demapping, the way Loglikelihood ratios (LLRs) are handled, the number of Iterative Detection and Decoding (IDD) to be performed, and whether IDD is to be performed alternately.\n\nThe EPDetector plays a significant role in the simulations as it implements the Expectation Propagation (EP) MIMO detection algorithm. This algorithm, unlike simple decoders, works well for systems with a large number of antennas and streams. It also has the advantage of being able to provide soft-output symbols, which can be advantageous for subsequent processing of the received data. The class is designed to work with the given parameters in the MIMO model, providing a vital part of the link's functionality. \n\nIt is important to note that the `EPDetector` parameter is not to be confused with another layer used for MIMO detection, the 'Detector' class, which implements an IDD detector, or the 'LD_MIMO_Detector' class, which implements Lattice Decoders for MIMO systems. The `EPDetector` works specifically with the concept of Expectation Propagation, making it a distinct part of MIMO simulations."
"To set up and run an instance of the `EDFA` class, which is part of the Sionna package, you will need to follow a series of steps. The `EDFA` class implements a model of an Erbium-Doped Fiber Amplifier. This model is implemented according to the given equation which combines both the lumped amplification and amplified spontaneous emission (ASE) noise. Running this class will simulate the operation of an Erbium-Doped Fiber Amplifier.\n\nHere's how you do it:\n\n1. First, ensure the Sionna package is installed in your environment. If it's not, you can install it using pip:\n\n```python\n   pip install sionna\n```\n\n2. Make sure to import the `EDFA` class in your python script before using it:\n\n```python\nfrom sionna.channel import EDFA\n```\n\n3. Initialize the `EDFA` class. You can either set specific parameters or use the default values. The Erbium-Doped Fiber Amplifier parameters include the gain `G` , the noise figure `F`, the signal input power `P_in` or `U_in`, and the noise bandwidth `f`. Here is an example of how you could initialize the `EDFA` class with specific values:\n\n```python\nnum_edfas = 10\ngain = 4.0\nnoise_fig = 5.0\nedfa = EDFA(gain=gain, noise_figure=noise_fig, num_edfas=num_edfas)\n```\n\n4. Now, run the instance by passing the input signal `x`:\n\n```python\n# x is the input signal\ny = edfa(x)\n```\n\nIn this example, `x` would be your signal input, and `y` would be the output signal.\n\nPlease note that, for both the input and output, the signal could be in either electrical or optical format. The note defaults to the use of the optical format, but you can set the format to 'electrical' if you prefer to use electrical signal values. The function supports both analog and digital signals, the latter being based on a bit or symbol mapping prior to the noise addition.\n\nAdditionally, the function can be operated either in a linear or in a per-channel (default) mode. The nonlinear model would be required if the system operates at close-to-saturated power levels. \n\nLast, note that when simulating the transmission over a single mode fiber, the fiber needs to be properly initialized, including the frequency of operation. This is not necessary in this example using lumped amplification. However, it is crucial when simulating the transmission over a (amplified) fiber optic link."
"The `render_to_file()` function in the `Scene` class of the Sionna package is used to render a scene to a file from a specific camera viewpoint. It's an alternative to the interactive rendering via `preview()` or the non-file rendering using `render()`.\n\nThe basic syntax to use the function is:\n\n```python\nscene.render_to_file(camera, filename, resolution=[650, 500],  fov=0.785398,  clip=(0.1, 1000.0), bg_color=[1.0, 1.0, 1.0], show_axis=False)\n```\nThe parameters are:\n- `camera`: The camera viewpoint from which the scene will be rendered. This should be either the name of a previously added camera or an instance of the `Camera` class.\n- `filename`: The name of the output file. The function will render the scene to this file.\n- `resolution`: An optional parameter to specify the image resolution in pixels. It should be a two-element list with integers. Defaults to `[650, 500]`.\n- `fov`: An optional parameter to specify the camera's field of view in radians. A default FoV of 45 degrees is used if this is set to 0. The value should be between 0 and pi. Defaults to 0, which gives a 45-degree FoV.\n- `clip`: An optional parameter to specify the near and far clipping planes. Defaults to `(0.1, 1000.0)`.\n- `bg_color`: An optional parameter to set the background color. This can be either a list of three floats or a string (\"white\" or \"black\"). Defaults to `[1.0, 1.0, 1.0]`, which is white.\n- `show_axis`: An optional boolean parameter to specify if the axis should be drawn to the final image. Defaults to `False`.\n\nThe function will return the path to the rendered file.\n\nIn case you do not want to render the scene to a file, the `render()` or `preview()` function can be used to render the scene to the screen."
"wrap_angle_0_360  means to wrap the given angle to (0,360). If the angle is positive, it will not change. If it's negative, it will be added to 360 to bring it to the [0,360] range.\n\nIn the case of Input, sionna.channel.wrap_angle_0_360(angle) requires angle which is a tensor.\n\nOutput will be angle wrapped to (0,360). This will be a tensor, having the same value as the input angle, but with adjustments that ensure it falls within the (0,360) range.\n\nFor example, in a scenario like -5 degrees, the function will return the output as 355 degrees, because 355 degrees when added by 5 gives us 360 degrees.\n\nTherefore, the function is a useful tool when you need to ensure that an angle value falls within the 0 to 360 range, which is a common requirement in trigonometry and related fields.\n\nTo use this in a programming scenario, you would first need to import the required module:\n```python\nfrom sionna.channel.utils import wrap_angle_0_360\n```\nAnd then you can use this function to wrap an angle to 360 degrees:\n```python\nresult = wrap_angle_0_360(input_angle)\n```\nHere, the `input_angle` should be replaced with the actual angle in degrees that you want to wrap. This input paramter should be a tensor. The `result` is the resulting wrapped angle, which will be a tensor as well. \n\nRemember, this function provides a computational tool ensuring that the returned angles are within the (0,360) range, which could be important for subsequent calculations or ensuring correct behavior in a defined range."
"Here is the definition of ChannelModel: sionna.channel.ChannelModel(source code: [ChannelModel](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel))  \n  \nThe default version is [Cir](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#Cir).  \n  \nA channel model generates channel impulse responses ($a$) and their associated path delays ($\\tau$) from which a channel output in the time domain or the frequency domain can be computed.\n\nChannel models operate in batches, the batch dimension is typically the first dimension and  different channel realization are usually used as different batch examples.  \n  \nTo implement a channel model, one has to subclass this abstract class [`ChannelModel`](https://nvlabs.github.io/sionna/api/channel.html#sionna.channel.ChannelModel) and implement the method [`call()`](https://nvlabs.github.io/sionna/api/channel.html#sionna.channel.ChannelModel.call), alternatively, the cir() method can be implemented instead cir() if only CIR information is available.  \n  "
"The 'sionna.rt.Scene.render_to_file' function in Sionna takes an argument for a class instance of 'camera' using which the function creates and saves a rendering of the scene to a file. \n\nThe input class instance should be of the 'sionna.rt.Camera' type. This 'Camera' instance is used for the viewpoint from which the scene will be rendered to the file.\n\nThe function also accepts an optional 'file_name' (type: string) argument which specifies the name of the file to save the render to. If no file name is provided, the name of the scene followed by '_render.png' is used.\n\nTo call this function, an instance of the 'sionna.rt.Scene' can be created using the 'sionna.rt.Scene' class method, and the necessary 'Camera' instance can be obtained, then the function can be called to render the scene.\n\nExample usage:\n```python\nscene = sionna.rt.Scene(sionna.rt.scene.etoile)\ncam = scene.get_cam(\"etoile-cam-1\") # Get camera instance\nscene.render_to_file(cam, \"etoile-cam-1-xyz-0-0-0\") # Render to file\n```"
"To configure DeepMIMO for use with Sionna, you need to specify the DeepMIMO dataset in the Sionna MIMO channel. This is done in the Sionna MIMO channel implementation, where you reference the DeepMIMO dataset. Here are the key steps:\n\n1. First, make sure you have the DeepMIMO dataset available. The dataset files are typically named `DeepMIMO_S<scenario>_G<user_array>_F<base_station_array>_W<antenna_selector>.h5`. The scenario is the name of the scenario you are using, for example, 'mmw_28'. The `user_array` parameter specifies the user side antenna array and the `base_station_array` parameter specifies the base station side antenna array. The `antenna_selector` parameter specifies which antennas are connected to each transmitter or receiver.\n\n2. In your Sionna MIMO channel implementation, specify the DeepMIMO dataset. This is typically done when creating an instance of the `DeepMIMO` class. For example:\n\n```python\nfrom sionna.channel import DeepMIMO\n\nDeepMIMO_dataset = DeepMIMO(  dataset_file, #e.g. 'DeepMIMO_San_Francisco/'\n                            scenario, #e.g. 'san_francisco_downtown'\n                            user_array, #e.g. 'ULA'\n                            base_station_array, #e.g. 'ULA'\n                            antenna_selector, #e.g. 'double'\n                            channel_sparsity = 1,\n                            ovd = 1,\n                            carrier_frequency = frequency,\n                            dtype = tf.complex64)\n```\n\nIn this example, `dataset_file` is the path to the DeepMIMO dataset files, `scenario` is the scenario name, `user_array` and `base_station_array` specify the antenna arrays on the user and base station side, `antenna_selector` specifies which antennas are connected to the transmitters or receivers, `channel_sparsity` specifies the channel sparsity, `ovd` specifies the channel overlap in the frequency direction, and `carrier_frequency` specifies the carrier frequency.\n\n3. Use the DeepMIMO dataset in your Sionna MIMO channel. For example, if you have a batch of user equipment (UE) and base stations, you can sample a Sionna MIMO channel using the `DeepMIMO` class, and then compute the MIMO frequency responses using the `cir_to_ofdm_channel` function. This can be used in the Keras model as a layer."
"To use the \"interleaver module\" in the Sionna package to permute tensors, follow these steps:\n\n1. Begin by setting up your system.\n\n2. Import the required functions and classes from the Sionna package. In this case, you will need to import `RandomInterleaver` and `Deinterleaver` from the `sionna.fec.interleaving` module.\n\n3. Configure the interleaver and deinterleaver. The interleaver is stateless, meaning its internal seed cannot be updated on runtime and does not change after initialization. However, an explicit random seed can be passed as an additional input to the interleaver/deinterleaver pair when calling the layer, if required. \n\n4. Use the `RandomInterleaver` class to create an instance of the interleaver. Configure the parameters as per your requirements. \n\n5. Create an instance of the `Deinterleaver` class, with your previously created interleaver instance as a parameter.\n\n6. The usage of these classes involves permuting a tensor (or a numpy array) `x` of rank at least two along the last (-1) axis by using the `interleaver` instance. \n\n7. To reconstruct the original order, call the `deinterleaver` instance with the interleaved tensor as a parameter. \n\nThe provided context mentions code snippets for both a simplified usage with a fixed seed and an advanced usage where an explicit seed is provided for each call. Make sure to understand both usage scenarios if you intend to fully comprehend how to use the interleaver module.\n\nPlease note that the actual code may involve parameters specific to your use case, and the explanation given here is based on the context provided for the \"interleaver module\" in the Sionna package. "
"The function `MMSEPICDetector` is a part of the 'sionna.ofdm' module's underlying code, it is used for implementing the receiver in an Orthogonal Frequency-Division Multiplexing (OFDM) system. This function is based on the use of the MIMO (Multiple Input, Multiple Output) MMSE-PIC (Minimum Mean Square Error - Parallel Interference Cancellation) algorithm. This function serves an important role as it is used for a key communication process in an OFDM system, that is, for detecting transmitted signals in a MIMO setup.\n\nFor a given OFDM and MIMO setup, the function is used to detect the transmitted signals and return the detected information. Specifically, the function takes in the received signals, channel estimates, and the noise covariance matrix as inputs and provides either bit-wise LLR (Log-Likelihood Ratios) or hard decided bit values for each of the streams, along with the estimated symbols for each stream.\n\nThe usage of this function comes in the context of OFDM systems, which are widely used in high data rate communication processes as they are able to mitigate the effects of multipath propagation, thus making the function crucial in such setups. The function effectively plays a role in detecting the transmitted signals, which is a key part of ensuring accurate data communication in an OFDM system.\n\nIn conclusion, the `MMSEPICDetector` function is of high importance in the functioning of OFDM systems, particularly in the process of signal detection in MIMO systems, which are widely used in high-performance communication channels. The usage of this function is essential in maintaining the integrity of data being transmitted in an OFDM system, thus its accurate usage is important for ensuring the reliability of data transmission. \n\nThe output of `MMSEPICDetector` function will be a sequence of either bit-wise LLRs or hard decided bits for every stream, as well as the corresponding estimated symbols. These outputs form the basis of the recovered data which can then be further processed for interpreting the transmitted information or making decisions on the bits that were transmitted."
"Here is the definition of RaisedCosineFilter: sionna.signal.RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/signal/filter.html#RaisedCosineFilter)\n\nsource code:\n```python\nclass RaisedCosineFilter(Filter):\n    # pylint: disable=line-too-long\n    r\"\"\"RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n\n    Layer for applying a raised-cosine filter of ``length``\n    ``samples_per_symbol`` to an input ``x`` of length\n    ``n``.\n\n    The raised-cosine filter is defined by\n\n    .. math::\n        h(t) = \\frac{1}{T} \\left( \\frac{1 + \\beta}\n        {2} \\right) + \\frac{\\sin\\left( \\frac{\\pi t}{T}\\right) }\n        {\\left( \\frac{\\pi t}{T} \\right) \\left( 1 - {\\beta}^2 \\right)}\n        \\qquad \\text{with} \\qquad 0 \\leq \\beta \\leq 1\n\n\n    The filter length ``samples_per_symbol`` is equal to the filter span\n    in symbols. For an odd filter length, the filter is applied through\n    sparse convolutions for efficiency.\n\n    An optional windowing function ``window`` can be applied to the filter.\n\n    The `dtype` of the output is `tf.float` if both ``x`` and the filter coefficients have dtype `tf.float`.\n    Otherwise, the dtype of the output is `tf.complex`.\n\n    Three padding modes are available for applying the filter:\n\n    * \"full\" (default): Returns the convolution at each point of overlap between ``x`` and the filter.\n    * \"same\": Returns an output of the same length as the input ``x``. The convolution is computed such that the coefficients of the input ``x`` are centered on the coefficient of the filter with index :math:`(K-1)/2` (assuming :math:`K`) filters have been applied, where :math:`K` is the filter length).\n    * \"valid\": Returns the convolution only at points where ``x`` and the filter completely overlap.\n\n    Parameters\n    ----------\n    span_in_symbols : int\n        Filter span as measured by the number of symbols.\n\n    samples_per_symbol : int\n        Number of samples per symbol, i.e., the oversampling factor.\n\n    beta : float\n        Roll-off factor.\n        Must be in the range :math:`[0,1]` inclusive.\n\n    window : Window or str ([\"hann\", \"hamming\", \"blackman\"])\n        Instance of :class:`~sionna.signal.Window` that is applied to the filter coefficients. Short-hand notations [\"hann\", \"hamming\", \"blackman\"] are allowed, in which case the respective window is instantiated with the default parameters.\n        No window is applied if `window` is None.\n        Default is None.\n\n    normalize : bool\n        If `True`, the filter is normalized to have unit power.\n        Defaults to `True`.\n\n    trainable : bool\n        If `True`, the filter coefficients are trainable variables.\n        Defaults to `False`.\n\n    dtype : tf.DType\n        The `dtype` of the filter coefficients.\n        Defaults to `tf.float32`.\n\n    Input\n    -----\n    x : [..., n], tf.complex or tf.float\n        The input to which the filter is applied.\n        The filter is applied along the last dimension.\n\n    padding : string ([\"full\", \"valid\", \"same\"])\n        Padding mode. Case insensitive.\n        Defaults to \"full\".\n\n    conjugate : bool\n        If `True`, the filter is conjugated before the convolution is computed.\n        In this case, the filter is applied in the frequency domain\n        (after the oversampling).\n        Defaults to `False`.\n\n    Output\n    ------\n    y : [...,m], tf.complex or tf.float\n        Filtered input.\n        The filter is applied such that the filter coefficients are\n        centered on the middle tap of the filter span.\n        The output length m depends on the ``padding``.\n    \"\"\"\n    def __init__(self,\n                 span_in_symbols,\n                 samples_per_symbol,\n                 beta,\n                 window=None,\n                 normalize=True,\n                 trainable=False,\n                 dtype=tf.float32,\n                 **kwargs):\n        super().__init__(span_in_symbols,\n                         samples_per_symbol,\n                         window=window,\n                         normalize=normalize,\n                         trainable=trainable,\n                         dtype=dtype,\n                         **kwargs)\n        self._beta = beta\n        if not 0. <= self._beta <= 1.:\n            raise ValueError(\"beta must be from the interval [0,1].\")\n        self.beta = beta\n\n    @property\n    def beta(self):\n        \"\"\"Roll-off factor\"\"\"\n        return self._beta\n\n    @beta.setter\n    def beta(self, value):\n        self._beta = tf.cast(value, self.dtype)\n\n    @property\n    def _coefficients_source(self):\n        h_rc = self._root_raised_cosine_tilde(self.samp_times,\n                                              1.0,\n                                              self.beta)\n        h_rc = tf.constant(h_rc, self.dtype)\n        return h_rc\n\ndef _root_raised_cosine_tilde(t, t_symbol, beta):\n    \"\"\"Compute the root-raised-cosine impulse response\n    without energy normalization\n    (cf. [J G Proakis, \"Digital Communications\", 4th. ed. ,McGraw-Hill, 2007.])\"\"\"\n    with tf.experimental.numpy.errstate(divide='ignore'):\n        t = tf.abs(t)\n        h = tf.cast((t/t_symbol) <= (1.0 - beta / 2.0), tf.float64)\n        a = tf.cast(1/4, h.dtype)\n        pi_inv = tf.cast(1/np.pi, h.dtype)\n        t_s = pi_inv * (1 + a) * beta\n        ts_inv = 1/t_symbol\n        h = tf.complex64(\n            tf.logical_or(tf.logical_and(h, t == 0),\n                          tf.logical_and(h, t == t_s)),\n            tf.logical_and(h, tf.abs(t - t_s) < ts_inv))\n        return tf.dtypes.cast(h, tf.as_dtype(t.dtype))\n```"
"The given context does not provide any details about `PAM2QAM` class and its functionality. The context only provides information related to `QAM2PAM` class. Based on the context, `QAM2PAM` class takes an input of indices in a QAM constellation and computes the corresponding indices for the two PAM constellations (real and imaginary components). The `PAM2QAM` class most likely does the opposite, transforming PAM symbol indices to QAM symbol indices. However, to provide a precise answer about the `PAM2QAM` class, the information from the source code or documentation related to the use of this class is needed."
"\n\nHere is how you can define the required variables and the RX-TX association matrix using Python code:\n\n```python\n# Number of transmitters (in this case, the base stations)\nnum_tx = 1\n\n# Number of receivers (the user terminals)\nnum_rx = 1\n\n# Number of streams per transmitter, as defined in the question\nnum_streams_per_tx = 1\n\n# The RX-TX association matrix. As there is only a single transmitter and receiver\n# and they are associated, the RX-TX association matrix is simply:\nrx_tx_association = np.array([[1]])\n```\n\nIn the given context, the provided Python code is encapsulated within a StreamManagement function. However, for the purpose of illustrating how to configure `StreamManagement` using the defined variables within the Python ecosystem, the provided code snippet can be directly used. \n\nPlease make sure that the necessary packages are imported and the StreamManagement function from the respective package (here, it's from `sn.mimo.StreamManagement`) is available in your environment before running the code."
"In the context of higher order modulation, constellations refer to the arrangement of possible symbols in the modulation scheme. A constellation is essentially a pattern of symbols, which are used to represent bits in the digital transmission process. Common types of constellations include QAM and PAM, which stand for Quadrature Amplitude Modulation and Pulse Amplitude Modulation, respectively.\n\nBit-channels, on the other hand, are the channels through which the individual bits of a binary number are transmitted. These channels can take binary values, i.e., 0 or 1. In the case of higher order modulation, each bit of a data symbol is mapped to a specific symbol on the constellation. This is performed by a mapper block in the first instance. After this mapping, the modulated waveform is transmitted over a 'channel', which could be a physical medium like a copper wire or a fiber optic cable, or a wireless medium. \n\nIn the wireless medium, there can be effects such as fading and noise, which can cause the received signal to be different from the transmitted signal. The received signal is then demapped to obtain an estimate of the transmitted bits. This estimate and the reliability of the estimate are represented using the concept of 'bit-channels', which is a key component in the analysis of higher order modulations over wireless channels."
"The given function [`pam` in sionna.mapping module](https://nvlabs.github.io/sionna/api/mapping.html#pam) is for generating a PAM (Pulse Amplitude Modulation) constellation for a given number of bits per symbol. This is typically used for modulation schemes like QAM (Quadrature Amplitude Modulation) to encode data into a higher-order digital format suitable for transmission over a communication channel.\n\nThe PAM constellation is a vector that represents the possible signal points in the constellation. For a modulation scheme like QAM, each constellation point represents a unique bit sequence. The function generates the PAM constellation, where each element is a constellation point. \n\nThe output of this function is a 1D tensor (TF array) that represents the generated PAM constellation. The output is in the numpy float32 format which is a standard 32-bit format for numerical data. \n\nTo use this function, one would call this with the desired number of bits per symbol (``num_bits_per_symbol``):\n```\nconstellation = pam(num_bits_per_symbol)\n```\nThe function will recursively determine the number of constellation points based on the input ``num_bits_per_symbol`` provided and return the constellation. \n\nIn the context of digital communication systems, this PAM constellation is used in the mapping (a process of converting bit sequences into symbols or a digital bit into an analog symbol) prior to modulation (conversion of the low-power baseband signal to a high-power passband signal). The corresponding demapping and decoding operations take place at the receiver to recover the transmitted data. \n\nIt's important to note that the function operates under the assumption that the normalize parameter (``normalize``) is set to True, which means the PAM constellation is normalized to have unit power. This is a standard practice in communication systems to prevent one constellation type having an unfair advantage over another. This recursive implementation is based on the 3GPP standards.\n\nWhile the recursive formula used by this function is not directly explained in the provided context, the function description mentions it as a recursive way to find the normalization factor for the PAM constellation, which is defined in the context. The recursion is not needed to understand the operation of the function in the given context."
"When using the \"List2LLR\" class in the Sionna package, the following assumptions should be fulfilled:\n\n1. It is assumed that `y` is a complex-valued read received signal of arbitrary length, `no` is a positive scalar or a tensor of the same shape as `y`, `codeword_sets` is a list of full-rank codewords, and `tb_crc_encoder` is an optional argument. If `tb_crc_encoder` is not set to `None`, it is further assumed that it is an instance of the `CRCEncoder` class.\n\n2. The \"List2LLR\" class implemented various algorithms for computing log-likelihood ratios (LLRs) or hard-decisions on bits from a list of candidate solutions. An optional cyclic redundancy check (CRC) can be used to verify the results.\n\n3. For the class to compute LLRs, it is assumed that a list of admissible length `\\\\bar{\\\\rho}` exists for each position describing which channel realizations are adapted to which codeword index. \n\n4. If the `CRCEncoder` is provided, it is assumed that the `tb_crc_encoder` argument is an instance of the `CRCEncoder` class and `length` and `position` match the TB CRC requirements. It is further assumed that the TB CRC adds parity bits to a (pre-) encoded bit stream and, thus, the for LLR computation expected interleaver for the CRC needs to be specified.\n\n5. It is assumed that the variable `algorithm` specifies which implementation should be used and can take one of the following values: \n    - `viterbi`: This refers to the Viterbi algorithm and requires a `Trellis` instance.\n    - `int`: This refers to the \"Pulse\" implementation of the BCJR algorithm.\n    - `j-log`: This refers to the \"Pulse\" implementation of the BCJR algorithm using the j-log domain.\n    - `box`: This refers to the BOX implementation of the BCJR algorithm.\n    - `map`: This refers to the MAP implementation of the BCJR algorithm.\n  \n6. The class assumes that `smoothing` argument can be either a non-negative number (then all LLRs are simply scaled by the same constant) or a tensor of the same shape as the input with an additional dimension (then smoothing can be applied on a per-bit basis).\n\nPlease refer to the Sionna documentation and the specific implementation details for the \"List2LLR\" class for additional and more detailed assumptions."
"The `MMSEPICDetector` class is a part of the signal processing module for Orthogonal Frequency-Division Multiplexing (OFDM) systems in the Sionna's package. This class implements the Expectation Propagation (EP) MIMO MMSE PIC (Parity-Iterative Decoding Detection) algorithm.\n\nUnder OFDM and stream configuration provided by a `StreamManagement` instance, this class computes soft-symbol/log-likelihood ratios (LLRs) or hard-decisions for the symbols of a (possibly) advanced ECC-aided data stream, given the received resource grid, channel estimates, and error variances.\n\nThe class takes the following parameters:\n\n- **output**: Type of output, accepted values are 'bit' or 'symbol'. Determines if soft- or hard-decisions are returned.\n\n- **resource_grid**: An instance of the `ResourceGrid` class.\n\n- **stream_management**: An instance of the `StreamManagement` class.\n\n- **ep_iter**: Number of EP iterations.\n\n- **llr_type**: The type of LLR (logarithm of base, default is 'maxlog', 'maxlog' is advised.)\n\n- **hard_out**: Switches the detector to compute hard-decided bit values or constellation point labels instead of soft-values.\n\n- **dtype**: The type of complex components, default is tf.complex64.\n\nThe conditions under which to use this class are when working on a MIMO MMSE PIC detector to be used within an OFDM-based system, and when the number of iterations for the EP process is a critical factor, as excessive number of iterations may lead to performance degradation. The `MMSEPICDetector` might be suitable for large communication systems where computational efficiency is paramount."
"The given Python class `QAM2PAM` is part of the `sionna.mapping` module and is intended to facilitate the transformation of Quadrature Amplitude Modulation (QAM) symbol indices to PAM (Pulse Amplitude Modulation) symbol indices. This class takes an instance of the `PAM2QAM` class as an input and is meant to be used in a pipeline where a QAM constellation is mapped to PAM symbols.\n\nThe `QAM2PAM` class takes the number of bits per constellation symbol during initialization and is used to compute the indices for two PAM constellations, corresponding to the real and imaginary components of the QAM constellation symbol. The transformation is based on the mathematical properties of QAM and PAM constellations.\n\nThe modulation techniques like PAM and QAM are used in digital communication systems to represent data as symbols in an efficient manner. These symbols can subsequently be transmitted over a communication channel.\n\nTo use the `QAM2PAM` class, one needs to create an instance of this class, and supply it with the number of bits per QAM constellation symbol, as shown in the provided context:\n\n```python\nqam2pam = QAM2PAM(num_bits_per_symbol=4)\n```\n\nIn the above line of code, `num_bits_per_symbol` is the number of bits per QAM constellation symbol. This value should be provided according to the QAM modulation scheme being used. For instance, for a standard 16-QAM constellation, this value would be equal to 4.\n\nIn summary, the `QAM2PAM` class is a utility class that provides a method for the arbitrary conversion of QAM symbol indices to PAM symbol indices. This supports the functionality and flexibility of modulation schemes and symbols in a digital communication system."
"To verify that the generator matrix (gm) and parity-check matrix (pcm) are orthogonal in GF(2) using the Sionna package, you can use the `verify_gm_pcm` function. This function checks the orthogonality relationship, which is a fundamental property of generator and parity-check matrices in linear block codes.\n\nHere is how you can use the `verify_gm_pcm` function:\n\n```python\nfrom sionna.fec.utils import verify_gm_pcm\n\n# Assume gm and pcm are already defined and computed\n# You should have your own code to generate gm and pcm\n\n# Verify that the matrices are orthogonal\nresult = verify_gm_pcm(gm, pcm)\n\n# The result will be a boolean indicating whether the matrices are orthogonal\nif result:\n    print(\"The generator matrix and parity-check matrix are orthogonal.\")\nelse:\n    print(\"The generator matrix and parity-check matrix are not orthogonal.\")\n```\n\nIn this code snippet, you first import the `verify_gm_pcm` function from the Sionna package. Then, you assume that the generator matrix (gm) and parity-check matrix (pcm) are already defined and computed (you should have your own code to generate these matrices). Finally, you call the `verify_gm_pcm` function with the generator and parity-check matrices as arguments. The function will return a boolean value. If this value is `True`, it means that the matrices are orthogonal in GF(2); if it's `False`, it means the matrices are not orthogonal.\n\nPlease make sure that the actual code to generate the matrices is present before using the `verify_gm_pcm` function. The code to generate the matrices is not provided in the given context, and it may vary depending on the specific application and the type of matrix (generator or parity-check) you are dealing with."
"The code to import the `LinearEncoder` class from the `sionna.fec.linear` module is:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n```\n\nThis statement allows you to use the `LinearEncoder` class in your code. It is specifically used to perform encoding of data using a given generator matrix."
"This class is part of the OFDM (Orthogonal Frequency-Division Multiplexing) module within the wireless simulation library. It's designed as a layer that wraps a MIMO (Multiple-Input, Multiple-Output) detector which assumes prior knowledge of the bits or constellation points is available. \n\nThe implementation process is designed to preprocess the received resource grid `y`, channel estimate `h_hat`, and the prior information `prior`, and then computes the symbol log-likelihood ratios (LLRs) or hard decisions for every symbol of every stream. This preprocessing includes managing the OFDM and stream configuration provided by the `resource_grid` and `stream_management`, as well as accounting for channel estimation error variance `err_var`. The actual detector used is an parameter of the class' instantiation, meaning it could be any callable object like a function or a method.\n\nThis class is suitable for scenarios where you have prior information about the transmitted signals, which could be, for example, soft-information of symbols or bits or a specific known input like pre- or demapping. By utilizing prior information, it accomplishes performing detection by considering this information along with the received signals, which can potentially enhance the detection accuracy or robustness under poor channel conditions. \n\nThis explanation assumes knowledge about MIMO, OFDM, detection algorithms, and related techniques. It's important to understand the context and content of the parameters and methods of this class to fully comprehend how it works. Additionally, the actual functionality of the class is dependent on the provided detector, which is part of the instantiation, and would vary based on whether it's meant for bit or symbol detection, and whether it's soft or hard decisions."
"The function `bin2int_tf` is a utility function from the Signalion Flat-Encode-Decode (sionna.fec.utils) library. It is used to convert a binary tensor into an integer tensor. The binary values in the input tensor `arr` are read from the last index, with the most significant binary value placed first.\n\nFor instance, given an input binary tensor like `arr` = [0, 1, 1], the `bin2int_tf` function will return 3 as a corresponding output, because this binary sequence translates to the integer value 3.\n\nThis function is particularly useful in scenarios where data is represented in binary form (consisting of 0s and 1s) but needs to be processed or analyzed as integer values. The conversion operation aligns with concepts in computer arithmetic and data processing where binary representations are used internally but the final output is typically in integer format.\n\nIt's important to ensure that the binary representation in `arr` is structured from the most significant bit to the least significant bit, as this function processes the binary values starting from the last index, which assumes the binary representation is in \"little-endian\" order.\n\nNote: Please make sure to use the actual binary tensor in your code where `arr` is mentioned, not the text \"<cite>[0, 1, 1]</cite>\". The content of `arr` should reflect the binary values you are trying to convert."
"This is how the usage of `TB5GScrambler` for enabling 5G NR compliant scrambling is demonstrated in the given context:\n\nFirstly, the appropriate `TB5GScrambler` needs to be imported:\n\n```python\nfrom sionna.fec.scrambling import TB5GScrambler\n```\n\nThen an instance of the scrambler is created. Here, the scrambler is set up to scramble binary data, as indicated by the `binary` parameter being set to `True`. The `n_rnti` parameter is the RNTI identifier and has been set to `1` for this example. This parameter is required to be provided to the `TB5GScrambler` and is specific to the 5G NR protocol.\n\n```python\ntb5g_scrambler = TB5GScrambler(binary=True, n_rnti=1)\n```\n\nAfter setting up the `TB5GScrambler`, binary data `c` of arbitrary shape is provided to the scrambler, which will apply the defined 5G NR compliant scrambling operation.\n\n```python\n# Arbitrary binary data, note that the data type should be as per the applicable.\nc_scr = tb5g_scrambler(c)\n```\n\nIn the above code, `c` is the binary data that is to be scrambled and has to be of type `tf.float32`. The result of the scrambling operation is stored in `c_scr`.\n\nTo enable the 5G NR compliant scrambling, the `TB5GScrambler` requires the RNTI parameter, which represents the Radio Network Temporary Identifier as per the 5G NR terminology. The RNTI parameter is used to compute the initial seed for the generation of pseudo-random sequences in the downlink direction of 5G NR and must be provided by the calling party. This parameter can be an integer or a binary string in any format, as the implementation will internally convert it as required. It is important to note that this parameter is specific to the 5G NR system and would be provided from the actual system configuration or simulation setup in a real-world usage scenario. Example values for the RNTI parameter could be in the range from 0 to 65335.\n\nPlease be aware that the actual usage of the `TB5GScrambler` should be in accordance with the specific data and requirements of the 5G NR system it is being used for."
"\nHere is the detailed information of int_mod_2:   \n[sionna.fec.utils.int_mod_2(x)[source]](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#int_mod_2)\n\nEfficient implementation of modulo 2 operation for integer inputs.\n\nThis function assumes integer inputs or implicitly casts to int.\n\nRemark: the function tf.math.mod(x, 2) is placed on the CPU and, thus, causes unnecessary memory copies.\n\n#### Parameters\n\n- **x** (*tf.Tensor*):  Tensor to which the modulo 2 operation is applied.\n\n\n#### Return\n\n- Return (*tf.int32*):  Tensor of same shape as the input filled with ones and zeros.\n\n\nsource code:\n```python\ndef int_mod_2(x):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Efficient implementation of modulo 2 operation for integer inputs.\n\n    This function assumes integer inputs or implicitly casts to int.\n\n    Remark: the function `tf.math.mod(x, 2)` is placed on the CPU and, thus,\n    causes unnecessary memory copies.\n\n    Parameters\n    ----------\n    x : tf.Tensor\n        Tensor to which the modulo 2 operation is applied.\n\n    Return\n    ------\n    : tf.int32\n        Tensor of same shape as the input filled with ones and zeros.\n    \"\"\"\n    # int_mod_2 = x%2  is equivalent to 1 if x is odd and 0 if x is even.\n    # We have to do two casts because the inputs is expected to be\n    # and integer tensor, and the remainder operation is performed as a float.\n    # The first cast is to (i)nt64 through bit operations on the (i)nt32\n    # tensor.\n    # The second cast is to bring int_mod_2 to the required, although redundant,\n    # int_mod_2 = x%2  is equivalent to 1 if x is odd and 0 if x is even.\n\n    x = tf.cast(x, tf.int64)\n    int_mod_2 = tf.cast( x%2, tf.int32)\n\n    return int_mod_2\n```   \n  "
"Here is the detailed information of sionna.utils.SymbolSource:   \n  \n[sionna.utils.SymbolSource(dtype=tf.complex64, add_awgn=True, return_indices=False, seed=None, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/utils/misc.html#SymbolSource)\n\nLayer to generate and transmit random complex-valued symbols and noise.\n\nThis layer generates a batch of random, complex-valued symbols and transmits them over an AWGN channel. The channel adds AWGN (Additive White Gaussian Noise) to the input with a certain variance. It can also return the symbol indices together with the transmitted symbols, e.g., for use with an ML detector.\n\n### Parameters\n\n- **dtype** (tf.complex64 or tf.complex128): The dtype.\n- **add_awgn** (bool): Indicates if AWGN noise should be added to the transmitted symbols or not. Defaults to True.\n- **return_indices** (bool): Indicates if the symbol indices should be returned along with the transmitted symbols. Defaults to False.\n- **seed** (int or None): Set the seed for the symbol generator to get a random set of symbols. Set to None for fully random symbols. Defaults to None.\n- **kwargs**: Additional parameters. \n### Input\n\n- **shape** (1D tensor/array/list, tf.int): The desired shape, i.e., the number of symbols to generate.\n\n### Output\n\n- **symbols** (Tensor, tf.complex):  Random complex symbols to be transmitted.\n- **indices** (Tensor, tf.int): Corresponding symbol indices. Returned only if `return_indices` is set to True.\n\n**Note: ** When using this class in Graph mode with XLA, i.e., within a function that is decorated with @tf.function(jit_compile=True), you must set sionna.Config.xla_compat=true. See xla_compat."
"Here is the detailed information of ChannelModel:   \n  \n[sionna.channel.ChannelModel](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel)  \n  \nAbstract class that defines an interface for channel models.\n\nAny channel model which generates channel impulse responses must implement this interface.\nAll the channel models available in Sionna, such as RayleighBlockFading or TDL, implement this interface.\n\n**Input**\n\n- `batch_size` (int): Batch size\n- `num_time_steps` (int): Number of time steps\n- `sampling_frequency` (float): Sampling frequency [Hz]\n\n**Output**\n\n- `a` ([batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex): Path coefficients\n- `tau` ([batch size, num_rx, num_tx, num_paths], tf.float): Path delays [s]\n\n**Properties**\n\n- `num_paths`: Number of paths $L$  \n- `num_time_steps`: Number of time steps $N_t$  \n- `sampling_frequency`: Sampling frequency $f_s$ [Hz]  \n- `delay_spread`: Delay spread $\\tau_\\text{DS}$ [s]. Assumed to be one for models that do not provide a delay spread.  \n- `mean_g`: Mean delay spread $(\\tau_\\text{m})$ in [s]. Equal to delay spread if a delay spread is not provided.  \n- `var_g`: Variance of the delay spread $(\\sigma_\\tau^2)$ in [s^2].  \n- `num_rx`: Number of received signals $M$  \n- `num_tx`: Number of transmitted signals $K$  \n- `num_rx_ant`: Number of antennas used for the  receive signals $M^{\\text{ant}}$  \n- `num_tx_ant`: Number of antennas used for the transmit signals $K^{\\text{ant}}$  \n    \n**Methods**\n\n- `__call__(batch_size, num_time_steps, sampling_frequency)`:  Abstract method that must be implemented by any class that provides access to channel impulse responses.   \nsource code:  \n```python\n    def __call__(self, batch_size, num_time_steps, sampling_frequency):\n        # pylint: disable=line-too-long\n        r\"\"\"Abstract method that must be implemented by any class that provides\n        access to channel impulse responses.\n        \n        This method is a callable, used to sample the channel. It should be\n        implemented by all concrete channel models that generate\n        channel impulse responses.\n\n        Input\n        ------\n        batch_size : int\n            Batch size\n\n        num_time_steps : int\n            Number of time steps\n\n        sampling_frequency : float\n            Sampling frequency [Hz]\n\n        Output\n        -------\n        a : [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex\n            Path coefficients\n\n        tau : [batch size, num_rx, num_tx, num_paths], tf.float\n            Path delays [s]\n        \"\"\"\n        raise NotImplementedError\n```"
"To build a custom `RadioMaterial` in the Sionna RT (Ray Tracing) module and attach it to a `SceneObject`, you'll need to define the material's parameters and create a callback function that computes the material properties (relative permittivity and conductivity) from the given frequency. After that, the custom material can be assigned to the `radio_material` attribute of the `SceneObject`.\n\nHere's a step-by-step guide:\n\n1. Define the material parameters. For example:\n\n```python\nrelative_permittivity = 2.1\nconductivity = 0.0\nscattering_coefficient = 0.3\nxpd_coefficient = 0.1\nscattering_pattern = LambertianPattern()\n```\n\n2. Create a callback function that computes the material properties from the frequency. The frequency callback function must always take as an input argument the frequency and must return the relative permittivity and conductivity.\n\n```python\ndef my_material_callback(f_hz):\n    relative_permittivity = compute_relative_permittivity(f_hz)\n    conductivity = compute_conductivity(f_hz)\n    return (relative_permittivity, conductivity)\n```\n\n3. Instantiate the custom `RadioMaterial`:\n\n```python\ncustom_material = RadioMaterial(\"my_material\",\n                                 relative_permittivity=relative_permittivity,\n                                 conductivity=conductivity,\n                                 scattering_coefficient=scattering_coefficient,\n                                 xpd_coefficient=xpd_coefficient,\n                                 scattering_pattern=scattering_pattern,\n                                 frequency_update_callback=my_material_callback)\n```\n\nIn the snippet above, `\"my_material\"` is the name for the custom material.\n\n4. Add the custom material to the scene:\n\n```python\nscene.add(custom_material)\n```\n\n4. Attach the material to a `SceneObject`. You can either use the material instance or refer to it by name:\n\n```python\n# Using the material instance\nobj = scene.get(\"my_object\")\nobj.radio_material = custom_material # \"my_object\" is made of the custom material\n\n# Using the material name\nobj = scene.get(\"my_object\")\nobj.radio_material = \"my_material\" # \"my_object\" is made of \"my_material\"\n```\n\nRemember to replace `\"my_object\"` with the name of your `SceneObject`.\n\nNote: The material parameters (like relative permittivity and conductivity) can be assigned to TensorFlow variables or tensors. This allows the material properties to be modified by assigning new values to them. This feature can be used to implement material training."
"In the context, the use of the `BCJRDecoder` with MAP (Maximum A Posteriori) decoding is described. This is relevant to the `sionna.fec.conv.BCJRDecoder` class, which is used to implement the BCJR algorithm for decoding convolutional codes in a differentiable manner when combined with a differentiable demapper.\n\nThe BCJR algorithm is a method for decoding convolutional codes, which is a channel-agnostic error correction code. It's a type of MAP (Maximum A Posteriori) decoder, which aims to find the mostly likely transmitted codeword given the received sequence of bits, taking into account the probability distribution of the input sequence. The algorithm is recursive and calculates forward and backward probabilities, which can be used to obtain an estimate of the original message sequence.\n\nThe `hard_out` parameter is mentioned in the context in the context of the `BCJRDecoder` class. This is a boolean parameter that, if set to `True`, causes the decoder to output hard decisions (bits values of 0 or 1) instead of soft values. The \"hard_out\" parameter essentially governs the type of output produced by the decoder: a hard decision directly provides the decoded output bits, whereas a soft output provides log likelihood ratios (LLRs) that represent the reliability of each bit.\n\nThe type of the output tensor from the `BCJRDecoder` has different types depending on the mode of operation:\n\n1. If the `hard_out` parameter is set to `True`, the output tensor will be of type `tf.int32` and of shape `[rate * \\hat{n}]`. This indicates that the decoded output bits are presented as integers, with the shape indicating the number of output bit elements and the value `\\\\hat{n}` representing the output sequence length of the decoder (which differs from the input sequence length due to termination of the convolutional code).\n\n2. If the `hard_out` parameter is `False` or if it's not provided (which seems to default to `False`), the type of the output tensor will be `tf.float32` (a soft output) and of shape `[\\\\hat{n}, 2]`. The shape indicates the number of output bit elements (again, the decoded bits are presented as LLR values) and the value `2` indicates that the tensor includes two values (representing the two different bit states).\n\nNow, regarding the possible inputs to the `BCJRDecoder`:\n\n- If the `BCJRDecoder` is instantiated with the `graph` parameter set to `True`, the input LLRs (`llr_ch`) would be a `tf.Tensor` of type `tf.float32` and of shape `[\\\\hat{n}, n]`. This represents the 2-dimensional tensor of LLR values corresponding to the (no, n) input bit sequence, where `\\\\hat{n}` again denotes the output sequence length (which is related to the termination of the convolutional code).\n\n- If the `BCJRDecoder` is not set to `graph` mode, the input would be a tuple of LLR values (`llr_ch`) and prior information on the input bits (`llr_a`). Specifically, `llr_ch` would still be a `tf.float32` tensor as described above, but `llr_a` would be a 1-dimensional `tf.float32` tensor of length `\\\\hat{n} * k`, where `k` is the number of bits per symbol mapped to the codeword symbols.\n\nThe understanding of the `hard_out` parameter and the decoding input is important as it informs the configuration of the BCJR decoder and the processing of the input LLRs (or LLRs and priors) to produce a decoded bit sequence as the output."
"To use the `sionna.utils.ebnodb2no` function, proceed as follows:\n\nInput:\n1. **ebno_db** (float): This is the desired Eb/No value in dB at which you want to evaluate. Eb/No is the signal energy per bit to the noise power spectral density ratio. A higher Eb/No value generally means better the quality of the received signal in relation to the introduced noise.\n2. **num_bits_per_symbol** (int): Specifies the number of bits per constellation symbol.\n3. **coderate** (float): The coderate used, which could be, for instance, a 1/2 for a rate-1/2 code.\n4. **resource_grid** (sionna.ofdm.ResourceGrid): An instance of the ResourceGrid class in Sionna, which is used to describe the grid on which your data symbols are mapped. This parameter is optional and only needed for OFDM transmissions.\n\nOutput:\n- **no** (float): This function will return the noise power spectral density No in linear scale. The noise power spectral density is a measure of the power that is introduced into a signal as a result of the noise introduced during the transmission.\n\nExample:\n```python\nno = ebnodb2no(ebno_db = 4.0, num_bits_per_symbol=2, coderate=1.0)\nprint(no)  # This will print the value of the noise power spectral density.\n```\n\nIn the example, you would replace the `ebno_db` value with your actual Eb/No value that you wish to use for the calculation. \n\nRemember that this function is generally used as a utility for signal simulations to help set simulation parameters. The actual use of the returned No at simulation stage would depend on the specific simulation setup and software in use."
"To evaluate the baseline and the two autoencoder-based communication systems, you can follow these steps:\n\n1. **Baseline Model**:\n   - Instantiate the baseline model. In the given context, the baseline model is `Baseline()`.\n   - Create an instance of the `TFBER` class with the model and the range of SNRs. This class is used for calculating the bit error rate (BER) of the model.\n   - Run the `compute_ber(ebno_dbs, model, batch_size, max_mc_iter)` function with the baseline model, the range of SNRs, the batch size, and the maximum number of Monte-Carlo iterations (`max_mc_iter`) as arguments. This function will calculate the BER for each SNR value.\n\n2. **Autoencoder-Based Model with Gaussian LLRs**:\n   - Instantiate the two autoencoder-based communication systems. In the given context, the two systems are named `ModelQAM()` and `ModelPAM()`. Both use QAM and PAM modulation schemes with bit labeling using gray code.\n   - For each model, create an instance of the `TFBER` class with the model and the range of SNRs. \n   - Run the `compute_ber(ebno_dbs, model, batch_size, max_mc_iter)` function with the autoencoder-based model, the range of SNRs, the batch size, and the maximum number of Monte-Carlo iterations (`max_mc_iter`) as arguments. This function will calculate the BER for each SNR value.\n\n3. **Autoencoder-Based Model with Bit-Channel Mappings**:\n   - Instantiate the two autoencoder-based communication systems with different bit-channel mappings. In the given context, the two systems are named `Model_QAM()` and `Model_PAM()`.\n   - For each model, create an instance of the `TFBER` class with the model and the range of SNRs. \n   - Run the `compute_ber(ebno_dbs, model, batch_size, max_mc_iter)` function with the autoencoder-based model, the range of SNRs, the batch size, and the maximum number of Monte-Carlo iterations (`max_mc_iter`) as arguments. This function will calculate the BER for each SNR value.\n\nRemember that the `compute_ber(ebno_dbs, model, batch_size, max_mc_iter)` function is provided by the `TFBER` class and is used to measure the performance of the models over a range of SNRs. The batch size determines how many examples are processed by the models in parallel. The maximum number of Monte-Carlo iterations (`max_mc_iter`) determines the number of Monte-Carlo simulations used to compute the BER for each SNR."
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can follow these steps:\n\n1. List the available GPUs and select the one you want to use. In the provided context, the code `gpus = tf.config.list_physical_devices('GPU')` is used to list the available GPUs. You can change the GPU index to use a different one if needed.\n\n2. Set the environment variables `CUDA_VISIBLE_DEVICES` and `TF_FORCE_GPU_ALLOW_GROWTH`. The `CUDA_VISIBLE_DEVICES` variable is used to specify which GPU the application can use. If you want to use the first GPU, you can set it to `0`. The `TF_FORCE_GPU_ALLOW_GROWTH` variable is used to avoid allocating the entire GPU memory up-front, which can lead to errors. It is set to `true` to allow the TensorFlow runtime to allocate only as much GPU memory as needed.\n\n3. Import the `os` module and set the GPU environment variables. You can do this using the `os.environ` dictionary-like object, setting the 'CUDA_VISIBLE_DEVICES' and 'TF_FORCE_GPU_ALLOW_GROWTH' keys to the desired values.\n\n4. Set the TensorFlow logger level to 'ERROR' to avoid warnings.\n\n5. Check the GPU memory usage before and after allocating memory using the `nvidia-smi` command line utility. You can do this in Python using the `subprocess` module to run the command and the `grep` and `sed` utilities to extract the GPU memory usage.\n\nPlease note that the exact commands and variables may vary depending on your specific GPU and TensorFlow setup. The provided context includes the specific commands and variables for a TensorFlow configuration with two available GPUs."
"To calculate the J-function in the Sionna package using the \"j_fun\" function, follow the steps below:\n\n1. First, ensure you have the Sionna package installed. If not, you can install it using pip with the following command:\n\n```python\npip install sionna\n```\n\n2. Next, import the required modules in your python script:\n\n```python\nfrom sionna.rt import load_scene, PlanarArray, Transmitter, Receiver, FarField\nfrom sionna.utils import speed_of_light\nfrom sionna.rt.utils import r_hat\nfrom sionna.rt.j_function import j_fun\n```\n\n3. Load the scene which you want to analyze. You can use the `load_scene` function from the `sionna.rt` module to achieve this. For example:\n\n```python\nscene = load_scene(sionna.rt.scene.simple_reflector)\n```\n\n4. Configure your transmitter and receiver arrays. You can use the `PlanarArray` class from the `sionna.rt` module to achieve this. For example:\n\n```python\nscene.tx_array = PlanarArray(num_rows=1,\n                             num_cols=1,\n                             vertical_spacing=0.5,\n                             horizontal_spacing=0.5,\n                             pattern=\"iso\", # or you can specify a pattern\n                             polarization=\"V\")  # you can also use \"V\" or \"H\"\nscene.rx_array = scene.tx_array  # you can also have different arrays\n```\n\n5. Create the transmitter and receiver at a specific position and add them to the scene:\n\n```python\ntx = Transmitter(name=\"my_transmitter\", position=[2,0,1.5], orientation=[0,0,0])\nscene.add(tx)\nrx = Receiver(name=\"my_receiver\", position=[8,0,1.5], orientation=[0,0,0])\nscene.add(rx)\n```\n\n6. Now, you need to specify the frequency at which you want to calculate the J-function. You can do this using the `frequency` attribute of the scene:\n\n```python\nscene.frequency = 1e9  # 1GHz\n```\n\n7. Next, you need to calculate the far field for the scene you have loaded. You can use the `far_field` function from the `sionna.rt` module for this:\n\n```python\nff = FarField(scene)\n```\n\n8. Finally, you can calculate the `J` function using the `j_fun` function. This function takes the required arguments such as the number of samples, the far field, transmitter, and receiver arrays, etc. For example:\n\n```python\nJ = j_fun(1e6, ff, scene.tx_array, scene.rx_array, real_hv_field())\n```\n\nPlease note that the above code snippets are based on the information provided in the given context. The actual implementation may vary based on the specific requirements of your project."
"Here is the definition of PUSCHTransmitter: sionna.nr.PUSCHTransmitter(pusch_configs, channel_estimator=None, interpolator=None, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/nr/pusch_transmitter.html#PUSCHTransmitter)\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"Transmitter for the physical uplink shared channel (PUSCH) of 5G NR\"\"\"\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Layer\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pusch_config import PUSCHConfig\nfrom turbo_encoder import TurboEncoder\nfrom polynomial import Polynomial\nimport logging\n\n# Constants definition\nSCATTERED_PILOTS = 0\nDEMOD_PRIMED_PILOTS = 1\nDEMOD_PRIMED_CCE = 2\nDATA_SYMBOLS = 3\nSYMBOLS = 4\n\nclass PUSCHTransmitter(Layer):\n    # pylint: disable=line-too-long\n    def __init__(self, pusch_configs, channel_estimator=None, interpolator=None, dtype=tf.complex64):\n        # Initialize from super class\n        super().__init__(dtype=dtype)\n        # Check configuration files and create pusch transmitter\n        self.pusch_configs = pusch_configs\n        self._check_config_files()\n        self._create_transmitter()\n        self._channel_estimator = channel_estimator\n        self._interpolator = interpolator\n        self._dtype = dtype\n\n    def _check_config_files(self):\n        \"\"\"The function checks that the psc and dmrs mask have correct length\n        \"\"\"\n\n        for pusch_config in self.pusch_configs:\n            if isinstance(pusch_config, str):\n                pusch_config = PUSCHConfig(pusch_config)\n            assert(pusch_config.psc.dmrs_mask.length == pusch_config.fft_size)\n            assert(pusch_config.psc.length == np.int32(pusch_config.bandwidth//15))\n            self._n_id = pusch_config.n_id\n            pusch_config.verify()\n        self._num_tx = len(self.pusch_configs)\n        self._k = self.pusch_configs[0].k\n        self._num_coded_bits = self.pusch_configs[0].turbo_config.constraint_length*\\\n                                self.pusch_configs[0].turbo_config.n_ra*\\\n                                self.pusch_configs[0].num_coderate\\\n                                *self.pusch_configs[0].num_coded_slots\n        self._num_bits_symbol = 2**self.pusch_configs[0].modulation_order\n\n    def _create_transmitter(self):\n        \"\"\"This method is used to instantiate a PUSCH Transmitter based on the\n        configuration parameters\"\"\"\n\n        # Number of transmitters\n        self._num_tx = len(self.pusch_configs)\n\n        # Number of info bits per TX depending on the coderate and CRC parity\n        # addition\n        tb = np.int32(self.pusch_configs[0].tb_size)\n        coderate = self.pusch_configs[0].coderate\n        if self.pusch_configs[0].turbo_config.crc_degree>0:\n            k_info = self._k - 12*self.pusch_configs[0].num_coded_slots\n            logging.debug(\"TB CRC parity bits are set => k_info = {0} \".format(k_info))\n        else:\n            if self.pusch_configs[0].remove_pcm5_n ==\"n240\":\n                # n240 only used for DMRS = \"double\"\n                k_info = self.pusch_configs[0].n-14\n                logging.debug(\"TB CRC parity bits are set and n240 active => \\\n                    k_info = {0} (n240)\".format(k_info))\n            else:\n                k_info = self.pusch_configs[0].n\n                logging.debug(\"TB CRC parity bits are set and n240 inactive => \\\nk_info = {0} (n240)\".format(k_info))\n\n        self._turbo_encoder = TurboEncoder(self.pusch_configs[0].turbo_config,\n                                            return_infobits=False,\n                                            terminate=True,\n                                            dtype=tf.float32)\n        # We deactivate the zero_padding of the encoder to simplify the\n        # PUSCH transmission, the actual turbo info bits position will be\n        # provided later explicitly deactivate zero padding\n        self._turbo_encoder.zero_pad = False\n        self._polynomial_selector = Polynomial(selector=\"CRC24A\",\n                                                degree=24,\n                                                trainable=False,\n                                                dtype=tf.float32)\n\n        # Scrambler is always deactivated as the scrambler state is\n        # configured in the 5G channel decoder\n        self._binary_source = BinarySource()\n        self._scrambler = Scrambler(seed=self._num_tx,\n                                    binary= True,\n                                    channel_type=\"uplink\")\n\n        # Number info bits including DMRS and additional CBC\n        # scrambler. This is independent of the actual number of\n        # TB/CB coded bits.\n        if self.pusch_configs[0].dmrs_config is not None:\n            cbc_last = True\n            if self.pusch_configs[0].dmrs_config.cbc_precoding == \"double\":\n                cbc_last = False\n            num_coded_bits_cbc = self._k + 12*self.pusch_configs[0].num_coded_slots\n        else:\n            cbc_last = self.pusch_configs[0].dmrs.cbc == DEMOD_PRIMED_CCE\n            num_coded_bits_cbc = self._k\n\n        # Due to the CB concatenation, the number of -1 insertions\n        # the scrambler is different\n        if cbc_last:\n            num_coded_bits_scrambler = 4*num_coded_bits_cbc\n        else:\n            num_coded_bits_scrambler = 3*num_coded_bits_cbc + 1\n\n        self._num_coded_bits_scrambler = tf.cast(num_coded_bits_scrambler,\n                                                  tf.int32)\n\n        num_coded_bits_tb  = self._num_bits_symbol*\\\n                            self.pusch_configs[0].num_prs_ports_per_tx*\\\n                            self.pusch_configs[0].num_coded_symbols\n\n        self._num_coded_bits_tb = tf.cast(num_coded_bits_tb, tf.int32)\n        num_c = 2**self.pusch_configs[0].modulation_order\n        self._num_bits_symbol = tf.cast(self._num_bits_symbol, tf.int32)\n        self._header_crc_size = 24\n        if self.pusch_configs[0].dmrs.dmrs_type == \"single\":\n            self._dmrs_length = self.pusch_configs[0].dmrs.length+1\n            self._num_cdm_groups_without_data = 1\n        elif self.pusch_configs[0].dmrs.dmrs_type == \"double\":\n            self._dmrs_length = self.pusch_configs[0].dmrs.length\n            self._num_cdm_groups_without_data = 2\n        self._num_cdm_groups = self._num_coded_bits_tb//self._dmrs_length\n        self._num_data_symbols = self.pusch_configs[0].num_coded_symbols -\\\n                                 self._num_cdm_groups*self._num_cdm_groups_without_data\n\n        # Number of allocated REs per DMRS additional PRB pilot\n        self._num_allocated_dmrs_re = self.pusch_configs[0].num_dmrs_ports\\\n                                    *self.pusch_configs[0].num_cdm_groups_without_data\\\n                                    *self.pusch_configs[0].num_coded_symbols\\\n                                    *self.pusch_configs[0].num_prs_symbols\n\n        # Number of nulled REs due to DMRS 2 additional nulled REs\n        self._num_nulleds_dmrs2 = 2*self.pusch_configs[0].num_dmrs_ports*\\\n                                 self.pusch_configs[0].num_cdm_groups_without_data\\\n                                 *self.pusch_configs[0].num_prs_symbols\n\n        self._tb_size = None\n        self._cw_size = None\n        self._num_packs = None\n        for config in self.pusch_configs:\n            if self._tb_size is not None:\n                assert config.tb_size==self._tb_size,\\\n                \"All PUSCHConfigs must have the same tb_size\"\n            self._tb_size = config.tb_size\n            if self._cw_size is not None:\n                assert config.transport_block.tb_size==self._cw_size,\\\n                \"All PUSCHConfigs must have the same cw_size\"\n            self._cw_size = config.transport_block.tb_size\n            if self._num_packs is not None:\n                assert config.n_packs==self._num_packs,\\\n                \"All PUSCHConfigs must have the same n_packs\"\n            self._num_packs = config.n_packs\n\n        # Number of TurboEncoder Conv0/Conv1 outputs per CW. The depencence\n        # on num_cdm_groups is asummed to be shared by all PUSCH configurations.\n        self._num_cdm_groups = self._num_cdm_groups\n        num_output = self._turbo_encoder.conv_trellis.num_output\n        self._num_cw_bits = num_output.numpy()//self._num_cdm_groups//self._num_tx\n        self._tb_crc_scrambler = Scrambler(seed = 69,\n                                            binary = False,\n                                            channel_type=\"c\",\n                                            trainable=False)\n        # CBC scrambling for TB. We can deactivate the zero_padding of the encoder\n        # c.f. 3GPP 38.212 Sec. 7.3.1\n        self._cb_crc_scrambler = Scrambler(seed = 7,\n                                            binary = False,\n                                            channel_type=\"c\",\n                                            trainable=False)\n        if self.pusch_configs[0].dmrs.dmrs_type is not None:\n            if self.pusch_configs[0].dmrs.dmrs_type == \"single\":\n                if self.pusch_configs[0].dmrs.config_type ==\"1\":\n                    # Init correct for config_type = \"2\"\n                    self._dmrs_mask = self.pusch_configs[0].dmrs.build_dmrs_mask()[:,1:]\n                else:\n                    self._dmrs_mask = self.pusch_configs[0].dmrs.build_dmrs_mask()\n                self._dmrs_type = self.pusch_configs[0].dmrs.dmrs_type\n                self._dmrs_length = self.pusch_configs[0].dmrs.length+1\n                self._num_cdm_groups_without_data = 1\n            elif self.pusch_configs[0].dmrs.dmrs_type == \"double\":\n                self._dmrs_type = self.pusch_configs[0].dmrs.dmrs_type\n                self._dmrs_mask, self._dmrs_mask_2  =\\\n                                    self.pusch_configs[0].dmrs.build_dmrs_mask_all()\n\n        # DMRS pilot generation for each trasmitter\n        ind = 0\n        for i, config in enumerate(self.pusch_configs):\n            if config.dmrs.dmrs_type is not None:\n                if config.precoding == \"non_codebook\":\n                    # For every transmitter, recover the  ind and length\n                    # of occupied DMRS symbols.\n                    num_time_steps = config.num_coded_symbols\n                    dmrs_length = config.dmrs.length\n                    time_ind = np.mod(np.arange(num_time_steps), int(num_time_steps/dmrs_length))\n                    occ_ind = np.where(time_ind==ind)[0]\n                    ind += len(occ_ind)\n                    setattr(config.dmrs, \"occ_ind\", occ_ind)\n                    setattr(config.dmrs, \"dmrs_length\", dmrs_length)\n                else:\n                    if config.precoding==\"single_stream\":\n                        ind = config.dmrs.dmrs_ports[0]\n                    elif config.precoding==\"codebook\":\n                    # ind refers to the four last layers\n                        ind = config.dmrs.c_ind[0,-4:].numpy()\n                    dmrs_length = config.dmrs.length\n                    setattr(config.dmrs, \"occ_ind\", ind)\n                    setattr(config.dmrs, \"dmrs_length\", dmrs_length)\n\n\n    def _info_bits_mapping_5g(self, u):\n        \"\"\"Maps the input tensor of info bits to the 5G format.\n        u[0]: The first contained info bit (TB or CB)\n        u[1]: The second contained info bit (TB only)\n        u[2]: The filler bits (TB only)\n\n        Returns\n\n        u_tb: Tensor, inputs mapped to the transport block\n        u_cb: Tensor, inputs mapped to the code block\n        n: int, the TB size or number of fillers for CB (only multiple of 8)\n\n        Remark: This is (w/o the CB concatenation) the inverse function of the\n        procedure defined in Sec 5.1.3 of 38.212.\n        \"\"\"\n        n_1 = int(self.pusch_configs[0].transport_block.tb_size-1)\n        n_2 = int(self.pusch_configs[0].transport_block.tb_size-2)\n        u = tf.concat([u, tf.zeros([3], u.dtype)], axis =-1)\n        state = 0\n        # distribute u[0] and u[1] to the output position per the spec\n        if u[n_1].numpy()%2==1: # if n is odd, last bit got to CB\n            u_cb = tf.concat([u[:n_1], [u[n_1]], tf.zeros([int(self.pusch_configs[0].tb_size-\\\n                         1-self.pusch_configs[0].cb_crc_encoder.crc_degree)], u.dtype)], axis =-1)\n        else:\n            u_cb = tf.concat([u[:n_2], u[n_2:], tf.zeros(\\\n                    [int(self.pusch_configs[0].cb_crc_encoder.crc_degree)], u.dtype)], axis =-1)\n        u_tb = u[0:self.pusch_configs[0].transport_block.tb_size]\n        c_init = self._polynomial_selector(u_tb)\n        # scramble info bits\n        c = self._binary_source([1,2]) * c_init\n        c = self._scrambler([c, tf.convert_to_tensor(0, tf.int32)])\n        c = tf.squeeze(c, axis=0)\n        # CRC scramble\n        c_crc = self._cb_crc_scrambler([u_cb, c, tf.convert_to_tensor(0, tf.int32)])\n        # CB concatenation\n        if self.pusch_configs[0].codeword_length==0: # only one cw\n            n = self.pusch_configs[0].transport_block.tb_size\n        else:\n            n =  self.pusch_configs[0].transport_block.tb_size- \\\n                     np.mod(self.pusch_configs[0].codeword_length, 8)\n            n = np.maximum(n, 8)\n        return u_tb, u_cb, tf.cast(n, tf.int32)\n\n\n    def _harq_info_bits_interleaving(self, u):\n        r\"\"\"Interleaved HARQ-related info bits as in Sec. 5.4.2.2.1\n        but without the filler bits.\n        Input: u as in Sec. 5.4.2.1  (only relevant for PDSCH)\n\n        Returns\n        -------\n        u_interleaved: Interleaved version of u\n            Tensor, the interleaved version of u\n\n        n: int\n            Number of filler bits, returned to be compatible with PUSCH\n        \"\"\"\n\n        # descramber\n        c = self._cb_crc_scrambler([u, tf.convert_to_tensor(0, tf.int32)])\n        # undo CB scrambling\n        c_init = self._polynomial_selector(c)\n        # re-interleaving\n        n_id = self.pusch_configs[0].harq_process_number\n        if self.pusch_configs[0].harq_preamble== \"short\":\n            n_rnti = self.pusch_configs[0].n_rnti[0]\n            mcs_index = 0 # no mcs index defined for the DMRS mcs\n        else:\n            n_rnti = self.pusch_configs[0].n_rnti[1]\n            mcs_index = self.pusch_configs[0].mcs_table[n]\n        c_init, _ = self.channel_internal puncturing(c_init, mcs_index, n_rnti)\n        u = tf.squeeze(c_init, axis =-1)\n        c_init = self._binary_source([1, 2]) * c_init\n        u = tf.squeeze(c_init, axis = -1)\n        u.set_shape(self.pusch_configs[0].transport_block.tb_size-1)\n        # reinterleaving\n\n        cbp = self.pusch_configs[0].cb_crc_encoder.crc_degree\n        u = self._binary_source([cbp, 2]) * u\n        u = tf.squeeze(u, axis=-1)\n\n        # CB scrambling\n        u_interleaved = self._scrambler([u, tf.convert_to_tensor(0, tf.int32)])\n\n        # n should be zero, however, we return it for compatibility with PUSCH\n        # (only relevant for the PDSCH)\n        return u_interleaved, tf.cast(0, u.dtype)\n\n\n    def call(self, inputs):\n        r\"\"\"PUSCH Transmitter: Takes as input a n dim tensor of\n        information bits, generates a frequency\n        or time domain representation of the transmitted signal and\n        returns  for each transmitter and layer\n\n        Inputs\n        ------\n        (x, n_id, output_domain, add_harq, input_domain, num_harq) where\n            x: 2+D tensor of information bits to be transmitted.\n                If `input_domain` equals \"frequency\",\n                the info bits are interleaved as per Sec 5.4.2.1 [3GPP38211]_ and\n                the `n_id` related to the current transmission is expected as\n                input.\n            n_id: Scalar or tensor of indices related to the specific\n                PUSCH transmitter, counted from 0. If provided, PUSCH\n                transmitter will use its internal parameter `n_id`.\n                Type must be `tf.int32`.\n            output_domain: Can be \"frequency\" or \"time\". Defaults to\n                \"frequency\". Type must be `tf.string`.\n            add_harq:  Only relevant if `output_domain` equals \"frequency\".\n                Can be `True` or `False`. Defaults to `True`.\n                Type must be `tf.bool`.\n            input_domain:  Can be \"bit\" or \"symbol\". Defaults to\n                \"bit\". Type must be `tf.string`.\n            num_harq: Number of input vectors provided related to the\n                current PUSCH transmitter. This is only required if\n                `add_harq` is set to `True`.\n                Type must be `tf.int32`.\n\n        Output\n        ------\n            : [batch_size, num_tx, num_layers, num_time_steps,  n] or\n                [batch_size, num_tx, num_layers, num_of"
"Here is the detailed information of verify_gm_pcm:   \n  \n[sionna.fec.utils.verify_gm_pcm(gm, pcm)](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#verify_gm_pcm)\n  \nVerify that generator matrix $\\mathbf{G}$ `gm` and parity-check matrix $\\mathbf{H}`pcm` are orthogonal in GF(2).\n\nFor an all-zero syndrome, it must hold that\n\n$$\n\\mathbf{H} \\mathbf{c}^t = \\mathbf{H} * (\\mathbf{u} * \\mathbf{G})^t = \\mathbf{H} * \\mathbf{G} ^t * \\mathbf{u}^t =: \\mathbf{0}\n$$\n\nwhere $\\mathbf{c}$ denotes an arbitrary codeword and\n$\\mathbf{u}$ the corresponding information bits.\n\nAs $\\mathbf{u}$ can be arbitrary it follows that\n\n$$\n\\mathbf{H} * \\mathbf{G} ^t =: \\mathbf{0}.\n$$\n\nInput\n    gm (ndarray) \u2013 Binary generator matrix of shape [k, n].\n    pcm (ndarray) \u2013 Binary parity-check matrix of shape [n-k, n].\n\nOutput\n    bool \u2013 True if gm and pcm define a valid pair of parity-check and generator matrices in GF(2).\n\nRaises\n    InvalidMatrixError \u2013 If the PCM is not full rank or if `gm` or `pcm` are not binary or `k` and `n` are not positive.\n\n**Note:**\nA generator matrix is valid for encoding, if it is full rank and binary. For any generator matrix $\\mathbf{G}$, a valid parity-check matrix $\\mathbf{H}$ can be computed, iff $\\mathbf{G}$ is full rank. The function verify_gm_pcm checks, by verifying that for a given generator matrix $\\mathbf{G}$, the corresponding parity-check matrix $\\mathbf{H}$ is orthogonal.\n  \n$\\mathbf{H} * \\mathbf{G} ^t =: \\mathbf{0}$\n  \n[Code:]  \n```python\ndef verify_gm_pcm(gm, pcm):\n    \"\"\"Verify that generator matrix ``gm`` and parity-check matrix ``pcm``\n    are orthogonal in GF(2).\n\n    For an all-zero  syndrome, it must hold that\n\n    .. math::\n\n        \\mathbf{H} \\mathbf{c}^t = \\mathbf{H} * (\\mathbf{u} * \\mathbf{G})^t =\n        \\mathbf{H} * \\mathbf{G} ^t * \\mathbf{u}^t =: \\mathbf{0}\n\n    where :math:`\\mathbf{c}` denotes an arbitrary codeword and\n    :math:`\\mathbf{u}` the corresponding information bits.\n\n    As :math:`\\mathbf{u}` can be arbitrary it follows that\n\n    .. math::\n\n        \\mathbf{H} * \\mathbf{G} ^t =: \\mathbf{0}.\n\n    Input\n    ------\n    gm : ndarray\n        Binary generator matrix of shape `[k, n]`.\n\n    pcm: ndarray\n        Binary parity-check matrix of shape `[n-k, n]`.\n\n    Output\n    -------\n    : bool\n        `True` if ``gm`` and ``pcm`` define a valid pair of parity-check and\n        generator matrices in GF(2).\n    \"\"\"\n    # GM is valid if PCM is full rank (Vandermonde) and has\n    # correct shape\n    k = np.shape(gm)[0]\n    n = np.shape(gm)[1]\n\n    if not np.all(np.isin(pcm, [0, 1])):\n        raise InvalidMatrixError(\"Parity check matrix must be binary.\")\n\n    if np.shape(pcm) != (n-k, n):\n        raise InvalidMatrixError(\"Shape of parity-check matrix is \\\n        [n-k, n], where k is the number of information bits and n \\\n        is the codeword length.\")\n\n    if not verify_vandermonde(pcm):\n        raise InvalidMatrixError(\"Parity-check matrix is not full rank.\")\n\n    # H * G must be the zero matrix (valid for all-zero syndrome)\n    if not np.array_equal(np.mod(np.matmul(pcm, gm), 2), np.zeros([n-k, k])):\n        return False\n\n    # G * H must be the zero matrix\n    if not np.array_equal(np.mod(np.matmul(gm, pcm), 2), np.zeros([k, n-k])):\n        return False\n\n    return True\n```  \n \nsource code:  \n    ```python\ndef verify_gm_pcm(gm, pcm):\n    \"\"\"Verify that generator matrix ``gm`` and parity-check matrix ``pcm``\n    are orthogonal in GF(2).\n\n    For an all-zero  syndrome, it must hold that\n\n    .. math::\n\n        \\mathbf{H} \\mathbf{c}^t = \\mathbf{H} * (\\mathbf{u} * \\mathbf{G})^t =\n        \\mathbf{H} * \\mathbf{G} ^t * \\mathbf{u}^t =: \\mathbf{0}\n\n    where :math:`\\mathbf{c}` denotes an arbitrary codeword and\n    :math:`\\mathbf{u}` the corresponding information bits.\n\n    As :math:`\\mathbf{u}` can be arbitrary it follows that\n\n    .. math::\n\n        \\mathbf{H} * \\mathbf{G} ^t =: \\mathbf{0}.\n\n    Input\n    ------\n    gm : ndarray\n        Binary generator matrix of shape `[k, n]`.\n\n    pcm: ndarray\n        Binary parity-check matrix of shape `[n-k, n]`.\n\n    Output\n    -------\n    : bool\n        `True` if ``gm`` and ``pcm`` define a valid pair of parity-check and\n        generator matrices in GF(2).\n    \"\"\"\n    # GM is valid if PCM is full rank (Vandermonde) and has correct shape\n    k = np.shape(gm)[0]\n    n = np.shape(gm)[1]\n\n    if not np.all(np.isin(pcm, [0, 1])):\n        raise InvalidMatrixError(\"Parity check matrix must be binary.\")\n\n    if np.shape(pcm) != (n-k, n):\n        raise InvalidMatrixError(\"Shape of parity-check matrix is \\\n        [n-k, n], where k is the number of information bits and n \\\n        is the codeword length.\")\n\n    if not verify_vandermonde(pcm):\n        raise InvalidMatrixError(\"Parity-check matrix is not full rank.\")\n\n    # H * G must be the zero matrix (valid for all-zero syndrome)\n    if not np.array_equal(np.mod(np.matmul(pcm, gm), 2), np.zeros([n-k, k])):\n        return False\n\n    # G * H must be the zero matrix\n    if not np.array_equal(np.mod(np.matmul(gm, pcm), 2), np.zeros([k, n-k])):\n        return False\n\n    return True\n```"
"In the given context, the definitions of permittivity and permeability are not explicitly mentioned. However, based on the context, we can infer that these terms are related to the behavior of electromagnetic waves in a medium.\n\n**Permittivity:** \nPermittivity is a measure of how an electric field affects an insulating medium. It is a property of the medium, and it describes the ability of the medium to store electrical energy in an electric field. In the context of electromagnetic waves, the permittivity of a medium affects the speed of light in that medium. \n\nFrom the context, the permittivity is denoted by the symbol \"\u03b5\" and is used in the context's equations to calculate the wave number, which is a measure of the spatial frequency of the wave.\n\nThe definition given in a general context can be applied here: Permittivity (\u03b5) is a measure of how an electric field affects an insulating medium. It is equal to the product of the dielectric constant and the vacuum permittivity.\n\n**Permeability:**\nPermeability is a measure of how a magnetic field affects a medium. Like permittivity, it is also a property of the medium. In the context of electromagnetic waves, the permeability affects the wave impedance, which is the ratio of the electric field to the magnetic field. \n\nFrom the context, the permeability is denoted by the symbol \"\u03bc\" and is used in the context's equations to calculate the wave number.\n\nThe definition given in a general context can be applied here: Permeability (\u03bc) is a measure of how a magnetic field affects a medium. It is equal to the permeability of the medium divided by the vacuum permeability.\n\n**Calculation:**\nThe exact methods for calculating permittivity and permeability are not explicitly provided in this context. The calculation of permittivity often involves the dielectric constant of the material and the vacuum permittivity. For example, in free space, the permittivity is the vacuum permittivity. The vacuum permittivity is a physical constant, and for free space, its value is about 8.854x10^-12 F/m. \n\nSimilarly, the calculation of permeability involves the permeability of the material and the vacuum permeability. In free space, the permeability is the vacuum permeability, which is also a physical constant. \n\nIt's important to note that the actual values of permittivity and permeability can vary for different materials. For example, in the context of radio waves, the permittivity and permeability of air are different from those of a solid object like a wall."
"Here is the detailed information of RemoveNulledSubcarriers:   \n  \n[sionna.ofdm.RemoveNulledSubcarriers(resource_grid](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/resource_grid.html#RemoveNulledSubcarriers)  \n\nRemoves nulled subcarriers from a ResourceGrid.\n\nGiven a resource grid, an instance of ResourceGrid, with the property that all its subcarriers are nulled (i.e., nulled OFDM symbol), this class will create a new ResourceGrid instance with the nulled subcarriers removed.\n\nThis class can be used as a layer in a Keras model.\n\n**Parameters**\n\n- `resource_grid` (ResourceGrid) \u2013 An instance of ResourceGrid.\n\n**Input**\n\n- `[batch_size, num_tx, tfl], remove_ind, tfl` \u2013 List of tensors\n  - `batch_size` (int) \u2013 Batch size\n  - `num_tx` (int) \u2013 Number of transmitters\n  - `remove_ind` (Optional)[batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers] \u2013  Tensor containing indices of subcarriers to be removed.\n  - `tfl` (Optional) \u2013  Tensor indicating if the output should be transposed. Transposition is useful when this operation is used after RemoveNulledOFDMSymbols.\n\n**Output**\n\n- `output` \u2013\n  `Output` (ResourceGrid) \u2013 An instance of ResourceGrid without nulled subcarriers.\n   - `output.dtype == tf.complex64`\n   - `output.shape == [batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers]`  \n   on.\n   - `output` (tf.complex64) \u2013 The resource grid with removed nulled subcarriers."
"Definition of LLRs2SymbolLogits: \n\nComputes logits or hard decisions on constellation points from a tensor of log-likelihood ratios (LLRs) on bits.\n\nSource code: sionna.mapping.LLRs2SymbolLogits(num_bits_per_symbol, hard_out=False, dtype=tf.float32, **kwargs)  \n  \n```python\nclass LLRs2SymbolLogits(Layer):\n    \"\"\"LLRs2SymbolLogits\n\n    Computes logits or hard decisions on constellation points from a\n    tensor of log-likelihood ratios (LLRs) on bits.\n\n    Parameters\n    ----------\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n\n    hard_out : bool\n        If `True`, the layer provides hard-decided constellation points\n        instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.float32, tf.float64] tf.DType (dtype)\n        The dtype for the input and output.\n        Defaults to `tf.float32`.\n\n    Input\n    -----\n    llrs : [,n, num_bits_per_symbol], tf.float\n        LLRs for every bit.\n\n    Output\n    ------\n    : [,n, num_points], tf.float or [,n], tf.int\n        Logits or hard-decisions on constellation points.\n\n    Note\n    ----\n    The logit for the constellation :math:`c` point\n    is computed according to\n\n    .. math::\n        \\begin{align}\n            \\log{\\left(\\Pr\\left(c\\lvert LLRs \\right)\\right)}\n                &= \\log{\\left(\\prod_{k=0}^{K-1} \\Pr\\left(b_k = \\ell(c)_k \\lvert LLRs \\right)\\right)}\\\\\n                &= \\sum_{k=0}^{K-1} \\log{\\left(\\text{sigmoid}\\left(LLR(k) \\ell(c)_k\\right)\\right)}\n        \\end{align}\n\n    where :math:`\\ell(c)_k` is the :math:`k^{th}` bit label of :math:`c`,\n    where 0 is\n    replaced by -1.\n    The definition of the LLR has been\n    chosen such that it is equivalent with that of logits. This is\n    different from many textbooks in communications, where the LLR is\n    defined as :math:`LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)`.\n\n    \"\"\"\n    def __init__(self,\n                 num_bits_per_symbol,\n                 hard_out=False,\n                 dtype=tf.float32,\n                 **kwargs):\n        super().__init__(trainable=False, dtype=dtype, **kwargs)\n        assert dtype in [tf.float16, tf.float32, tf.float64],\\\n            \"dtype must be (tf.float16, tf.float32, tf.float64).\"\n        self._input_dtype = dtype\n        self._output_dtype = tf.float32\n        self._check_bit_labels = CheckBitLabels(\n            num_bits_per_symbol, dtype=dtype)\n        self._k = num_bits_per_symbol\n        self._hard_out = hard_out\n        num_points = 2**num_bits_per_symbol\n        b = np.zeros([num_points, num_bits_per_symbol])\n        for i in range(num_points):\n            b[i,:]=aux.dec2bin(i, num_bits_per_symbol)\n        self._bit_labels = 2*b-1 # Bit labels -1 1\n        points = 2*tf.constant(b, dtype=self._output_dtype)-1\n        if self._hard_out:\n            self._points = points # Hard decide symbols\n        else:\n            self._points = tf.cast(points, dtype=dtype)\n        self._ones_vector = tf.ones(self._k, dtype=self._output_dtype)\n\n    def build(self, input_shape): #pylint: disable=unused-argument\n        self._check_bit_labels(tf.shape(input_shape)[1]) # input_shape[1]: number of bits per symbol\n\n    def call(self, inputs):\n        # inputs : [,n, num_bits_per_symbol]\n        llrs = tf.cast(inputs, dtype=self._output_dtype) # Change dtype of llrs\n\n        # Check inputs and bit labels\n        self._check_bit_labels(tf.shape(llrs)[1])\n        llrs = tf.expand_dims(llrs, axis=-1)\n        a = tf.concat([llrs, self._ones_vector], axis=1)\n        exponents = tf.reduce_sum(tf.cast(\n            tf.math.logical_xor(self._bit_labels, a), self._output_dtype) ,axis=-1)\n\n        if self._hard_out:\n            return exponents # Hard-decisions on symbols\n        else:\n            return tf.stack([exponents,\n                -exponents], axis=-1) # Logits on constellation points\n```  \n  "
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can follow these steps:\n\n1. Use the `tf.config.list_physical_devices('GPU')` function to get the list of all available GPU devices. If multiple GPUs are available, you can set which one to use by specifying the GPU index.\n\n2. Use the `tf.config.set_visible_devices([], 'GPU')` function to set the list of visible GPU devices. The first argument is the list of GPU devices, and the second argument is the type of the device (CPU or GPU). Setting this list to an empty string effectively tells TensorFlow to not use any GPU.\n\n3. Use the `tf.config.experimental.set_memory_growth` function to enable TensorFlow to allocate memory as needed. This operation must be performed after at least one GPU has been initialized. It attempts to allocate only as much GPU memory as needed for the runtime allocations.\n\nThe code snippet provided in the context can be used to implement these steps. It first sets the `gpu_options` for the TensorFlow session, specifying that it should use only a single GPU and allocate memory as needed. It then verifies that the `gpu_options` are set correctly.\n\nPlease note that the use of `tf.config.list_physical_devices` and `tf.config.set_visible_devices` may require the installation of the TensorFlow library (`pip install tensorflow`), and the import of the `tensorflow` module in the Python script (`import tensorflow as tf`)."
"Here's the code snippet from the LinearEncoder section that demonstrates how to compute codeword bits from information bits:\n\n```python\n# Generate random information bits\nk = 128 # Number of information bits\nu = tf.random.stateless_uniform(shape=[BATCH_SIZE, k],\n                                minval=tf.constant(0, tf.int32),\n                                maxval=tf.constant(2, tf.int32),\n                                dtype=tf.int32,\n                                seed=seed)\n\n# Initialize the encoder with a PCM or GM instance\nencoder = LinearEncoder(load_parity_check_examples(1, k, vbose))\n\n# Encode the bits\nc = encoder(u)\n\nprint(\"Input information bits (u): \", u)\nprint(\"Encoded codeword bits (c): \", c)\n```\n\nThe code first generates a batch of random information bits. Then, an instance of `LinearEncoder` is initialized using the `load_parity_check_examples` function with verbose mode `vbose=True`. The encoder is then used to encode the information bits to compute the codeword bits.\n\nThe function `load_parity_check_examples` is expected to return the values for `k` and `n`, which represent the number of information bits and codeword bits (i.e., the length of the codeword), respectively. Please ensure the proper implementation of this function to initialize the `LinearEncoder`.\n\nThe code finally prints the information bits (`u`) and the computed codeword bits (`c`). This demonstrates the process of encoding information bits into a codeword using the `LinearEncoder`."
"Here is the detailed information of sionna.utils.flatten_last_dims: \n\n[sionna.utils.flatten_last_dims(tensor, num_dims=2)](https://nvlabs.github.io/sionna/_modules/sionna/utils/tensors.html#flatten_last_dims)\n\nFlattens the last n dimensions of a tensor.\n\nThis operation flattens the last num_dims dimensions of a tensor.\n\nIt is a simplified version of the function flatten_dims.\n\n### Parameters\n\n- **tensor**  A tensor.\n\n- **num_dims** (int)  The number of dimensions to combine. Must be greater than or equal to two and less or equal than the rank of the tensor.\n\n### Returns\n\nA tensor of the same type as tensor with num_dims-1 lesser dimensions, but the same number of elements.\n\nsource code:\n```python\ndef flatten_last_dims(tensor, num_dims=2):\n    r\"\"\"\n    Flattens the last ``n`` dimensions of a ``tensor``.\n\n    This operation flattens the last ``num_dims`` dimensions of a ``tensor``.\n\n    It is a simplified version of the function `flatten_dims`.\n\n    Args:\n        tensor : A tensor.\n\n        num_dims (int) : The number of dimensions\n            to combine.  Must be greater than or equal to two and less or equal\n            than the rank of ``tensor``.\n\n    Returns:\n        A tensor of the same type as ``tensor`` with ``num_dims``-1 lesser\n        dimensions, but the same number of elements.\n    \"\"\"\n    rd = tf.rank(tensor)\n    s = tf.shape(tensor)\n    s = tf.cast(s, dtype=rd.dtype)\n    tf.assert_greater_equal(num_dims, 2, message=\"\")\n    tf.assert_less_equal(num_dims, rd, message=\"\")\n    tf.assert_less_equal(num_dims, s, message=\"\")\n    tf.assert_equal(tf.reduce_sum(s[-num_dims:]), tf.constant( tf.reduce_prod(s[-num_dims:], dtype=tf.int32)), message=\"\")\n    tf.assert_equal(tf.reduce_prod(s[:-num_dims], dtype=tf.int32), tf.constant( tf.reduce_prod(s, dtype=tf.int32)), message=\"\")\n    ind1 = tf.range(0, num_dims, 1)\n    ind2 = tf.range(num_dims, rd, 1)\n    s = tf.gather(s, ind1)  # (...)\n    t1 = tf.reduce_prod(s, axis=0)\n    t2 = tf.gather(s, ind2)\n    t3 = tf.reduce_prod(t2, axis=0)\n    t4 = tf.cast(tf.math.divide_no_nan(t3, t1), dtype=ind2.dtype)\n    t4 = tf.expand_dims(t4, axis=0)\n    t_idx = tf.roll(t4, -1, axis=tf.size(t4)-1)\n    t_idx = (tf.math.cumsum(t_idx, exclusive=True) + 1)*(tf.reduce_min(t2) + 1) - 1\n    t_idx = tf.math.minimum(t_idx, tf.reduce_prod(s, dtype=tf.int32)-1)\n    output = flatten_dims(tensor, num_dims, t_idx)\n\n    return output\n```"
"Here is the definition of Mapper: sionna.mapping.Mapper(constellation=None, nn_init=False, seed=None, disable_last_channel_corr=False, dtype=tf.complex64, **kwargs).\n  \nSource code:\n```python\nclass Mapper(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Mapper(constellation=None, nn_init=False, seed=None,  disable_last_channel_corr=False, dtype=tf.complex64, **kwargs)\n\n    Constellation that is trainable.\n\n    This class defines a constellation (of symbols or bits) that is\n    used by the ``Modulator`` and ``Demodulator``. The constellation\n    can be either binary or higher-order, and trainable. The\n    individual bits or symbols of the constellation can be\n    annotated with a (real-valued) signal-to-noise ratio (SNR)\n    such that higher-order modulation schemes can be trained\n    with the aid of soft-decision algorithms.\n\n    Parameters\n    ----------\n    constellation : :class:`~sionna.mapping.Constellation` or None\n        An existing instance of :class:`~sionna.mapping.Constellation`\n        or `None`. In the latter case, a trainable constellation\n        is created. Default is `None`.\n\n    nn_init : bool\n        If `True`, the initial weights of the constellation are\n        initialized with values commonly used by a neural network.\n        Those values are used to initialize the weights of the\n        of the ``tf.keras.Layer`` layer as defined in\n        :eq:`~sionna.mapping.nn_init`. Default is `False`.\n\n    seed : int or None\n        The seed is used for the initialization of the trainable\n        weights. If set to `None` a random seed is generated.\n        Default is `None`.\n\n    disable_last_channel_corr: bool\n        If `True`, the last dimension of the constellation is\n        interpreted as \"non-pilots\" and no channel estimation\n        with averaged least-squares is performed. Default is `False`.\n\n    dtype : tf.Dtype\n        The `tf.Dtype` of the constellation. Defaults to `tf.complex64`.\n        The dtype of `constellation` takes precedence over this parameter.\n\n    Output\n    ------\n    : [n, num_streams, ...], tf.complex\n        A tensor with the modulated data symbols.\n    \"\"\"\n    def __init__(self,\n                 constellation=None,\n                 nn_init=False,\n                 seed=None,\n                 disable_last_channel_corr=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n\n        if constellation is None:\n            constellation = Constellation(  # pylint: disable=too-many-function-args\n                                            trainable=True,\n                                            nn_init=nn_init,\n                                            seed=seed,\n                                            disable_last_channel_corr=disable_last_channel_corr,\n                                            dtype=dtype)\n        self._constellation = constellation\n\n    def call(self, inputs):\n        return self._constellation(inputs)\n```"
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, follow these steps:\n\n1. List all physical devices that are connected to the notebook using the `tf.config.list_physical_devices('GPU')` command. This will return a list of all connected GPUs.\n\n2. If multiple GPUs are available, you can restrict the notebook to use only a single GPU by specifying the index of the GPU you want to use. For example, if you want to use the first GPU, you can set `gpu_num = 0`.\n\n3. To allocate only as much memory as needed, you can set `tf.config.experimental.set_memory_growth(gpus[gpu_num], True)`. This will allow TensorFlow to allocate GPU memory as needed, and it will grow its memory incrementally as the program needs it. \n\n4. If you want to avoid warnings from TensorFlow, you can set the log level to 'ERROR' using `tf.get_logger().setLevel('ERROR')`.\n\n5. It is also good practice to set the environment variables \"TF_CPP_MIN_LOG_LEVEL\" to '3' to avoid logging all GPU messages, and \"CUDA_VISIBLE_DEVICES\" to the index of the GPU you want to use.\n\nPlease note that the exact index of the GPU you want to use and the amount of memory you want to allocate may vary depending on your specific requirements and the available resources."
"Here is the definition of BinaryErasureChannel: sionna.channel.BinaryErasureChannel(return_llrs=False, bipolar_input=False, llr_max=100.0, dtype=tf.float32, **kwargs)  \n  \n  The link of the source code of BinaryErasureChannel is [BinaryErasureChannel](https://nvlabs.github.io/sionna/_modules/sionna/channel/discrete_channel.html#BinaryErasureChannel)  \n  \n  The explanation:Discrete binary erasure channel that \"forgets\" bits with eprobility $p_\\text{b}$  \n \n  The binary erasure channel (BEC) is a discrete memoryless channel with two possible outcomes. In can be used for binary as well as bipolar inputs. Despite its name, the channel does not operate binary fashion, i.e., it does not transmit bits but rather the outcome is bits in the case of the BipolarInput modality.\n\nIn the BipolarInput modality, bit values 0 and 1 are mapped to -1 and 1, respectively.\n\nIn the BEC, bits are either correctly received or erased. Erasure in this context means that the receiver cannot be certain whether a bit was correctly received or not. This is a generalization to two possible erasure probabilities $p_\\text{b}=0$ and $p_\\text{e}=1$ in the following.\n\nThe channel can either return binary values or LLRs. In the binary case, the channel \"forgets\" bits, i.e., even if the input was binary, the output is ternary, where the extra -1 and 0 indicate an erased and a not erased bit, respectively. This is simply put the behavior of the BEC that only results in erasures, but does not generate binary values.\n\nIn the BipolarInput modality, an eprob of, e.g., 0 results in the channel output -1.\n\n  \n### Parameters\n\n- **return_llrs** (`bool`): If set to `True`, the layer returns log-likelihood ratios (LLRs) instead of binary values. Defaults to `False`.\n- **bipolar_input** (`bool`): If set to `True`, the expected input is given {-1, 1} instead of {0, 1}. Defaults to `False`.\n- **llr_max** (`tf.float`): Defines the clipping value of the LLRs. Defaults to 100.0.\n- **dtype** (`tf.DType`): Defines the datatype for internal calculations and the output dtype. Defaults to `tf.float32`.\n\n### Input\n\n- **x** (`[,n]`, `tf.float32`): Input sequence to the channel.\n- **pb** (`tf.float32`): Erasure probability. Can be a scalar or of any shape that can be broadcasted to the shape of `x`.\n\n### Output\n\n- **`[,n]`, `tf.float32`**: Output sequence of same length as the input `x`. If `return_llrs` is `False`, the output is ternary where each -1 and each 0 indicate an erased bit for the binary and bipolar input, respectively."
"To simulate the End-to-End Bit Error Rate (BER) performance of the PAM-4 transmission over a fiber link with zero and non-zero (i.e., FM) laser phase offset, you need the following components:\n\n1. **Binary Source** (provided in the context): This is used to generate the input sequence to the encoder.\n\n2. **5G NR LDPC Encoder**: The 5G NR LDPC codes are used to provide channel coding and are currently not optimized for PAM-4 transmissions. You can use an explicit LDPC (Low-Density Parity-Check) encoder by initializing it with the 5G parameters as shown in the context.\n\n3. **Gaussian LLR Source**: This component generates log-likelihood ratios (LLRs) that describe the received noisy communication.\n\n4. **AWGN Channel**: The Additive White Gaussian Noise (AWGN) channel is used to simulate the transmission over a noisy channel.\n\n5. **Fiber PAM-4 Channel**: This is a model for the fiber-optical channel. It utilizes the previously mentioned AWGN channel, optical amplifier, and CD (Chromatic Dispersion) compensation.\n\n6. **ZeroFM and NonZeroFM Estimators**: These are used to estimate and compensate the laser phase noise, which is essential in optical communications.\n\n7. **Hard Decision Decoder**: The decoder makes hard decisions (i.e., bit values `0` or `1`) based on the received LLRs. The decoder output is a `b_hat` which represents the estimated version of the transmitted `b`.\n\n8. **BER Analyzer**: This component is used to compute the BER, which is a performance measure of the communication system.\n\n9. **LDPC BP Decoder**: This is an implementation of the belief propagation (BP) algorithm for iterative decoding of LDPC codes. It is initialized with the 5G NR LDPC parity check matrix and set to use log-domain operations.\n\n10. **PAM-4 Mapper and Demapper**: These are used to map the coded bits to a PAM-4 symbol and mapped back to bits, respectively.\n\n11. **Scaler and MaxLog Metric**: These are used to implement hard-decision decoders by approximating the LLR metrics.\n\n12. **Binary Cross-Entropy Loss**: This is the loss function used for training the model.\n\n13. **Model and Weights**: The end-to-end communication system is modeled and trained using this set of components. The weights of the model can be loaded from a pre-trained model to evaluate the performance of the system or trained using the binary cross-entropy loss function and stochastic gradient descent (SGD) with a specified learning rate and momentum."
"Using the PUSCHDMRSConfig class and its properties in Sionna's API involves mainly the following steps:\n\n1. Import the PUSCHDMRSConfig class.\n   \n   ```python\n   from sionna.nr import PUSCHDMRSConfig\n   ```\n\n2. Create an instance of the PUSCHDMRSConfig class.\n\n   ```python\n   pusch_dmrs_config = PUSCHDMRSConfig()\n   ```\n   \n3. Use the instance to set configuration properties according to the requirements.\n   \n   ```python\n   pusch_dmrs_config.additional_position = 1\n   pusch_dmrs_config.dmrs_port_set = [0,1]\n   # Set other configurable properties\n   ```\n\nThe code snippet provided in the 'PUSCHDMRSConfig' under the 'API Reference' could be deconstructed to understand how the class and its properties are used:\n\n```python\ndmrs_config = PUSCHDMRSConfig(config_type=2)\ndmrs_config.additional_position = 1\n```\n\nAs seen from the snippet, the PUSCHDMRSConfig class is initiated with a configuration type. After the initiation, the instance is accessed to set the additional_position property. This updates the DMRS configuration to a type 2 configuration with an additional DMRS position. \n\nThe properties of the PUSCHDMRSConfig class are designed to represent the various parameters for DMRS configuration in a 5G New Radio (NR) setting, as mentioned in the decontextualized section:\n\n- additional_position: Maximum number of additional DMRS positions.\n- allowed_dmrs_ports: List of nominal antenna ports.\n- beta: Ratio of PUSCH energy per resource element (EPRE) to DMRS EPRE.\n- cdm_groups: List of CDM groups.\n- config_type: DMRS configuration type.\n- deltas: List of delta (frequency) shifts for all ports.\n- dmrs_port_set: List of used DMRS antenna ports.\n- length: Number of front-loaded DMRS symbols.\n- n_id: Scrambling identities.\n- n_scid: DMRS scrambling initialization.\n- num_cdm_groups_without_data: Number of CDM groups without data.\n- type_a_position: Position of the first DMRS OFDM symbol for type A.\n- w_f: Frequency weight vectors for all ports.\n- w_t: Time weight vectors for all ports.\n\nConfigurable properties like 'additional_position' can be set either during the initialization or later in the program, as shown in the example.\n\nIt's essential to ensure that the values set for these properties adhere to the valid ranges defined for each property within the Sionna API documentation to prevent errors and to provide correct parameter setting for the functioning of the 5G NR module.\n\nAlso, note that the properties can be assigned in a dict or keyword arguments during the initialization if the API supports that design pattern.\n\nAll in all, to use the PUSCHDMRSConfig class and its properties:\n\n1. Initialize the class with necessary parameters to create a DMRS configuration.\n2. Access the instance to set or change configuration properties as required.\n\nRemember, the actual parameters and property values should be set as per the valid ranges specified for the 5G NR module, which the code snippets using this class and its properties should be taken from the Sionna's API documentation. This explanation does not cover the complete set of properties that can be applied to the class, but it aims to guide through the essential ones based on the provided context."
"To demonstrate how to use the `ConvEncoder` to encode information bits, we must first set up an instance of the encoder and then pass our information bits to it. \n\nHere is a simplified version of the code provided in the context:\n\n```python\nfrom sionna.fec.conv import ConvEncoder\n\n# Define a rate 1/2 convolutional code with generator polynomials\ngen_poly = [[0, 7, 5], [0, 7, 6]]\nencoder = ConvEncoder(gen_poly, rsc=False) \n\n# If u is the tensor of information bits with the shape [...,k], then the encoded codewords can be obtained as follows:\nc = encoder(u)\n\n# c has the shape [...,n], which corresponds to the convolutional codeword.\n\n# To decode the received codeword and estimate the information bits, the following operations can be performed:\nu_hat = decoder(c) \n```\n\nLet's focus on demonstrating how to use the `ConvEncoder` to encode information bits.\n\nIn the provided context, an instance of `ConvEncoder` is already created for the rate 1/2 convolutional code with generator polynomials `gen_poly`. The encoder is then used to encode a tensor `u` containing the information bits to obtain the tensor `c` containing the convolutionally encoded codeword.\n\nTo depict the shapes and types of the input and output tensors, we will print the shape and type of `u` and `c`. \n\nPlease note that the actual code used to create the `gen_poly` as well as the import statements for the necessary components from the `sionna` package have been omitted from this answer, as the focus was just to demonstrate the usage of the `ConvEncoder`. The actual import statements and code to generate `gen_poly` would depend on the specific Sionna API components being used. \n\nHere is how you can print the shape and type of the input tensor `u` and the output tensor `c`:\n\n```python\nprint(\"Shape of u:\", u.shape, \"Type of u:\", type(u))\n```\n\nWhen you run the actual code, the output will depend on the shape and type of your information bits tensor `u`. The print statement will display the shape and type of the tensors `u` and `c`. \n\nRemember that the information bits tensor `u` should have the shape [...,k] and the output codewords tensor `c` will have the shape [...,n], where `k` and `n` are the kth and n corresponding to the rate of the convolutional code (if rate is 1/2, `n` is not twice the length of `u`). These shapes are indicated by the `shape` method of the `ConvEncoder` class documentation."
"The DMRS (demodulation reference signal) configuration for a 5G NR PUSCH (Physical Uplink Shared Channel) is shown in the provided code snippet. The DMRS is used for pilot symbol transmission in an OFDM-based system to aid channel estimation and MIMO (Multiple Input, Multiple Output) transmission.\n\nFrom the code, you can see that the DMRS configuration includes several parameters such as `additional_position`, `allowed_dmrs_ports`, `beta`, `cdm_groups`, `config_type`, `deltas`, `dmrs_port_set`, `length`, `n_id`, `n_scid`, `num_cdm_groups_without_data`, `type_a_position`, `w_f`, and `w_t`. \n\nTo visualize the pilot pattern, a method of the `PUSCHDMRSConfig` (PUSCH DMRS Configuration) instance named `show` is used. This method will generate a plot of the pilot pattern to display the DMRS configuration. \n\nHere is how you can do it:\n\n```python\npusch_config.dmrs.show()\n```\n\nThis will display a chart that represents the pilot pattern based on the current DMRS configuration. The pilot pattern shows, for each OFDM symbol and each antenna port, the indices of the resource elements that are mapped to these positions. \n\nKeep in mind that the DMRS configuration can be altered using the provided setters for the `PUSCHDMRSConfig` class, in case you would need to change the configuration for your specific needs."
"To visualize common scattering patterns using the Sionna package, you can follow these steps:\n\n1. Import the necessary modules from the Sionna package, including `LambertianPattern` and `DirectivePattern` from `sionna.rt.scattering`.\n\n2. To visualize a Lambertian scattering pattern, you can create an instance of the `LambertianPattern` class and then call the `visualize` method on it. This will generate a plot of the scattering pattern.\n\n    ```python\n    LambertianPattern().visualize()\n    ```\n\n3. To visualize a directive scattering pattern, you can create an instance of the `DirectivePattern` class with the desired sharpness parameter (or provide the desired shortcode), and then call the `visualize` method on it.\n\n    ```python\n    DirectivePattern(alpha_r=10).visualize()\n    ```\n\n4. The `visualize` method will generate a plot of the scattering pattern. The scattering pattern will be displayed as a surface, with the incoming direction (toward the surface) as the zenith and the surface normal as the azimuth.\n\n5. The scattering pattern can be visualized as either a 2D cut or a 3D surface. This can be controlled using the `type` parameter in the `visualize` method.\n\nPlease note that the specifics of creating and visualizing scattering patterns may vary depending on the exact features and options provided by the Sionna package, and this answer interprets the instructions given in the provided context within that context."
"To handle import errors for the Sionna package, the code first attempts to import the Sionna package using the `import sionna` statement within a `try/except` block. If the import is successful, the package is made available for use within the current environment. \n\nHowever, if the import statement raises an `ImportError`, the code then falls into the `except` block. Within the `except` block, the code first checks if the `sionna` module is not already installed by looking for an `ImportError` with the message \"No module named 'sionna'\". If this message is found, the code then goes on to install the Sionna package using the `pip install sionna` command. After the package is installed, the code then attempts to import the Sionna package again.\n\nHere is the relevant part of the code:\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    if \"No module named 'sionna'\" in str(e):\n        os.system(\"pip install sionna\")\n    import sionna\n```\n\nThis approach ensures that if the Sionna package is not initially available in the current environment, the code will attempt to install it and then import it again. If the installation fails for some reason (such as lack of internet connection or permissions), the code will raise an `ImportError` with an appropriate message."
"To import the necessary Sionna APIs, you would typically use the following code:\n\n```python\nfrom sionna.rt import load_scene, Paths\nfrom sionna.channel import cir_to_ofdm_channel, subcarrier_frequencies, cir_to_time_channel, cir_to_time_channel_lag\nfrom sionna.channel.tr38901 import UMa, Antenna, Panel\nfrom sionna.nr import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver\nfrom sionna.utils import compute_ber, ebnodb2no, remove_nones, insert_nones, split_n\nfrom sionna.ofdm import OFDMModulator, ResourceGrid, ResourceGridMapper, LSChannelEstimator, LMMSEEqualizer, LinearDetector, KBestDetector, EPDetector, MMSEPICDetector\nfrom sionna.mimo import StreamManagement, LayerDemapper, PUSCHDMRGMapper, CQIReporter, CQIComputer, ApplyOFDMChannel, OFDMChannel, CIRToOFDMChannel, OFDMDetector, KBestDetector, EPDetector, RemoveNulledSubcarriers, ReplaceNulledSubcarriers, RGToDMRS, DMRSGrid, DMRSMapper, ZFPrecoder, Equalizer, LinearDetector\nfrom sionna.mac import PUSCHMetrics\n```\n\nHowever, the exact APIs to import might vary depending on your specific use case and the Sionna components you need. If an API is not part of the core Sionna module, you might need to import it from the relevant sub-module or package. The Sionna documentation should provide guidance on which specific APIs you need and how to import them."
"The \"Descrambler\" class is mainly used to negate the operations performed by the associated \"Scrambler\" on a given sequence, effectively desrambling a scrambled sequence back to its original order. This is conducted by utilizing the seed for the pseudo-random generator in the scrambling process.\n\nHere are additional detailed information for this class:  \n- \n\n**Class \"Descrambler\" Parameters**:\n- `scrambler`: Associated Scrambler instance.\n- `seed`:  An integer defining the state of the random number generator. If explicitly given, the global internal seed is replaced by this seed. This can be used to realize random scrambler/descrambler pairs (i.e., they should call with the same random seed).\n- `binary`: Defaults to True. Indicates whether bit-sequence should be flipped (i.e., binary operations are performed) or the signs should be flipped (i.e., soft-value/LLR domain-based).\n\n**Input**:\nThis accepts either a list of sequences to be descrambled or a 2+D tensor. \nDepending on how the class is initialized, the `seed` parameter might be an input to the function.\n\n**Output**:\nThis would return a 2+D tensor of the same shape and datatype as the input. \n\n**Raised Errors**:\nIt will raise an `AssertionError` if the `scrambler` is not an instance of Scrambler.\nIt will raise a `TypeError` if the `seed` is not an integer.\n\n**Properties**:\nThis class has one property called 'scrambler' which returns the associated Scrambler instance. \n\n**Usage**:\nThis class is part of the `sionna.fec.scrambling` utility, used for processes like randomizing data to ensure the data has equal proportion of 0s and 1s, and to break any patterns within the sequences. \n\n*Can be used for*:\n-  Equalizing the distribution of 0s and 1s: By using a pseudo-random bit generator to produce an almost random sequence of 0s and 1s, if the original sequence had a long run of 0s or 1s, the scrambled sequence would break this pattern.\n-  For ensuring that sequences have equal proportion of 0s and 1s, which is important to ensure that parity-check codes can effectively verify the transmitted data and correct any bit errors, if the data was not properly distributed.\n-  For breaking patterns within a sequence, as certain patterns could affect the data when it's being transmitted.\n\nMake sure to have the Scrambler instance correctly associated when initializing the Descrambler, as this class relies on the Scrambler's parameters and methods. \n\nThis class is typically used after the `Scrambler`, making use of methods such as `descramble( )` to carry out the descrambling process and reconstruct the initial sequence. \n\n(Note: The sequences and tensors referred to in the explanation pertains to the data sequences that are provided as input to the Scrambler and Descrambler for the scrambling and descrambling operations.)"
"For decoding using an instance of `Polar5GDecoder` with log-likelihood ratios (LLRs) as inputs, you first need to create an encoder instance of `Polar5GEncoder`. The `Polar5GDecoder` instance is created by passing the associated encoder instance as a parameter. \n\nTaking the block of code provided in the context into consideration, here's how you would instantiate the necessary objects and demonstrate the process for Polar Decoding.\n\nYou have to make sure to import the correct classes from the `sionna.fec.polar.decoding` module. We will use the following classes:\n\n```python\nfrom sionna.fec.polar.encoding import Polar5GEncoder\nfrom sionna.fec.polar.decoding import Polar5GDecoder\n```\n\nFirst, you need to create an instance of the encoder:\n\n```python\nencoder = Polar5GEncoder(k=100, n=200)  # k is the number of information bits, n is the codeword length\n```\n\nThen, you create the `Polar5GDecoder` instance by passing the encoder instance:\n\n```python\ndecoder = Polar5GDecoder(encoder=encoder, dec_type=\"SCL\", list_size=8)  # \"SCL\" is one of \"SCL\", \"SC\", or \"BP\", list_size must match the list used for encoding\n```\n\nTo demonstrate the use of `Polar5GDecoder` with LLRs as inputs, assume you have an array `llr` of shape `[..., n]` that contains the Log-Likelihood Ratios from the demapper. \n\nIn the context of the provided code, this array `llr` would be generated as output of the `demapper` function. The `...` part means that `llr` should have the same shape as the original input LLR array. \n\nTo perform the decoding operation, you would call the `Polar5GDecoder` instance with the LLR array as the argument, and it would return the decoded output. This is independent of the use of LLRs and is the same whether you are working with LLRs or any other type of input.\n\nHere's how you would make that call, using the `u_hat` variable to capture the output (this contains the estimated information bits):\n\n```python\nu_hat = decoder(llr)\n```\n\nThis is the essential process for performing Polar decoding with an instance of `Polar5GDecoder` using log-likelihood ratios (LLRs) as inputs. The code provided in the context focuses on the setup for rate-matching and handling 5G-compliant Polar codes, but the actual demonstration of the Polar decoding process is somewhat abstracted.\n\nPlease note that the actual Log-Likelihood Ratios (`llr`) need to be available in your environment or simulated for the purpose of this demonstration. The provided context does not include the actual generation of LLRs. It's also important to ensure that the imports are correctly stated and that the necessary Sionna library modules are installed and available."
"To load a scene from a file using the `load_scene()` function from the `sionna.rt` module of the Sionna package, you have to follow these steps:\n\n1. Import the necessary function from the module.\n\n    In Python, you would do this by using an import statement like the following:\n    ```python\n    from sionna.rt import load_scene\n    ```\n\n2. Call the function with the `filename` as an argument.\n\n    You need to replace `'path_to_your_file/your_file_name'` with the actual path and name of your scene file. For example, if you have a scene file named `my_scene_name`, and it's located in the current working directory, you would call the function like this:\n    ```python\n    load_scene('my_scene_name')\n    ```\n\n    If the scene file is located in a different path, you would need to specify the path in the filename.\n\nPlease note that the function will return a `Scene` object representing the loaded scene. If you store this object in a variable, say `scene`, you can then use other methods and properties of the `Scene` class to work with the loaded scene data. For example, you can preview the scene by using the `preview()` method:\n```python\nscene = load_scene('my_scene_name')\nscene.preview()\n```\n\nAdditionally, make sure that the scene file you are trying to load is in a supported format (like the Mitsuba XML-based format) and is not corrupted. If the function fails to load the scene, it will return an error or `None`."
