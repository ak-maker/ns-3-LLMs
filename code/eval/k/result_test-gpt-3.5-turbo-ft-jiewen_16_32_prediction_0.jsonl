"To create a `Polar5GEncoder` instance in Sionna, you need to define the parameters `k` and `n`.\n\n`k` is an integer that indicates the number of information bits per codeword (the number of bits to be encoded), and `n` is an integer that indicates the desired codeword length (the length of the codeword after encoding).\n\nHere is a Python code snippet for creating a `Polar5GEncoder` instance in Sionna:\n\n```python\nfrom sionna.fec.polar.encoding import Polar5GEncoder\nimport tensorflow as tf\n\n# Define the parameters k and n\nk = 100  # Replace 100 with the actual number of information bits per codeword\nn = 200  # Replace 200 with the actual desired codeword length\n\n# Create a Polar5GEncoder instance\nencoder = Polar5GEncoder(k = k, n = n)\n```\n\nIn this snippet, you first need to import the `Polar5GEncoder` class from the Sionna's Polar encoding module. Then, you create an instance of the encoder by specifying the values of `k` and `n` for your use case. The `k` and `n` values provided in the context are placeholders and need to be replaced with actual integer values based on the specific requirement."
"To import DeepMIMO and generate a dataset, you will first need to make sure that you have the necessary requirements installed. This includes Python, TensorFlow, DeepMIMO, and other necessary packages. \n\nHere are the steps to import DeepMIMO and generate a dataset:\n\n1. Import the necessary packages: This includes TensorFlow, numpy, matplotlib, and other necessary packages. You can import TensorFlow and other necessary packages using the following command:\n\n```python\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport sys\n```\n\n2. Set the necessary parameters: This includes the DeepMIMO parameters such as the number of GPUs to use, the batch size, and the number of samples. You can set these parameters using the following command:\n\n```python\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = str(0)  # Use only the first GPU\nbatch_size = 128  # Use 128 samples per batch\nnum_samples = int(1e6)  # Number of samples in the dataset\n```\n\n3. Import DeepMIMO: You can import DeepMIMO using the following command:\n\n```python\nsys.path.append('/DeepMIMO/')  # Import the DeepMIMO package\nfrom DeepMIMO import DeepMIMO  # Import the DeepMIMO API\n```\n\n4. Generate a dataset: You can generate a dataset using the following command:\n\n```python\nDeepMIMO_params = DeepMIMO(1)  # Generate DeepMIMO scenario with default Sectorisation\ndataset = DeepMIMO(DeepMIMO_params, num_samples=num_samples, return_mode='nn')  # Generate the data\n```\n\nPlease note that the above code is based on the information provided in the context and may need to be adjusted based on your specific requirements and the actual implementation."
"To plot the weights after training and compare the new Bit Error Rate (BER) performance, you can follow these steps:\n\n1. After training the model, get the weights of the model. This can be done using the `get_weights()` function of the model object. The weights are returned as a list of numpy arrays.\n\n```python\ntrained_weights = model.get_weights()\n```\n\n2. Plot the weights. You can do this by iterating over the layers of the model and plotting the weights. Here is a sample code snippet for doing this:\n\n```python\nfig = plt.figure()\nfig.suptitle('Weight Visualization')\nfor i in range(len(weights)):\n    plt.subplot(6,2,i+1)\n    plt.hist(weights[i].flatten(),bins=20,edgecolor='black')\n    plt.ylabel('Count')\n    plt.xlabel('Weight Value')\nfig.tight_layout(rect=(0,0,1,0.97))\n```\n\n3. Compare the new BER performance. You can do this by evaluating the model's performance after training and comparing it with the performance before training. Here is a sample code snippet for doing this:\n\n```python\nmodel.compile(optimizer=RGD_optimizer, loss=BinaryCrossentropy(from_logits=True), metrics=[BerMetric()]) # We use BerMetric to calculate BER\nnew_performance = model.evaluate(x=no_ones_x, y=no_ones_c, batch_size=batch_size, verbose=0)\nprint(\"New BER performance:\", new_performance[1])\nprint(\"Original BER performance:\", original_performance)\n```\n\n4. The plot of the weights can give you an idea of how the model has learned. If the weights are clustered around certain values, it may indicate that the model has learned specific patterns or features during training. The performance comparison can tell you how these learned features have affected the model's overall performance in terms of BER. \n\nRemember that the weights are specific to the model and the training process. Different models and different training processes can lead to different weight distributions and performance outcomes."
"To use the `generate_polar_transform_mat` function in the `Sionna` package to create a Polar transformation matrix for a given Kronecker power, you can follow these steps:\n\n1. Import the necessary functions from the package:\n\n```python\nfrom sionna.fec.polar.encoding import generate_polar_transform_mat, generate_polar_mat\nfrom sionna.fec.polar.decoding import PolarSCLDecoder, PolarBPDecoder, Polar5GDecoder, PolarAssistedListDecoder\nfrom sionna.fec.polar.decoding import PolarSCLDecoder, PolarSCLFastDecoder\n```\n\n2. Define the parameters for the transformation matrix:\n\n`generate_polar_transform_mat` takes the following parameters:\n\n- `f`: A boolean value indicating whether to return the frozen positions or not.\n- `n`: The length of the codeword.\n- `allow_f4`: A boolean value indicating whether to allow the F4 format for fast decoding or not.\n\n3. Call the `generate_polar_transform_mat` function with the defined parameters:\n\n```python\ngenerate_polar_transform_mat(f, n, allow_f4)\n```\n\nThis will return a tuple `(<frozen_pos>, <info_pos>, <transform_mat>)` where:\n- `<frozen_pos>` are the positions of the frozen bits in the codeword.\n- `<info_pos>` are the positions of the information bits in the codeword.\n- `<transform_mat>` is the Polar transformation matrix.\n\nYou can then use this matrix for encoding and decoding in Polar codes.\n\nRemember that the `generate_polar_transform_mat` function can raise an `AssertionError` if:\n- `n` is not a power of two.\n- `allow_f4` is only valid when `n` is a power of two and is greater than 1024.\n- `f` is not a boolean.\n- `n` is not an integer.\n"
"Here is the definition of LayerDemapper: sionna.nr.LayerDemapper(layer_mapper)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/nr/layer_mapping.html#LayerDemapper)  \nsource code:\n```python\nclass LayerDemapper(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"LayerDemapper that inherits from the Keras layer class.\n\n    Demaps layers onto codewords for 5G NR layer mapping as defined in\n    :[3GPP38211]_ \"3GPP TS 38.211 \"Physical channels and modulation\", v.16.2.0,\n    2020-07.\" and, if applicable, recovers the demapping rule indicator.\n\n    Parameters\n    ----------\n    layer_mapper : LayerMapper\n        An instance of :class:`~sionna.nr.LayerMapper` that should be\n        demapped.\n\n    Input\n    -----\n    : [batch_size, num_codewords, num_layers, num_symbols_per_layer], tf.complex\n        The layers to be demapped onto the codewords. If\n        `num_symbols_per_layer` is not a multiple of two, the last element\n        will be ignored.\n\n    Output\n    ------\n    : [batch_size, num_codewords, num_codewords_length], tf.complex\n        The demapped codewords.\n    : [batch_size, num_codewords], tf.int\n        The indices of the layers that were demapped to each codeword.\n    \"\"\"\n    def __init__(self, layer_mapper, **kwargs):\n        super().__init__(**kwargs)\n        self._layer_mapper = layer_mapper\n        self._num_reflectors = None # Set during build\n\n    def build(self, input_shape):\n        # pylint: disable=unused-argument\n        self._num_reflectors = len(self._layer_mapper.reflectors)\n        assert self._num_reflectors > 0, \\\n            \"Number of enabled reflectors must be positive.\"\n\n    def call(self, inputs):\n        # [batch_size, num_tx, num_layers, num_ofdm_symbols,...]\n        y = self._layer_mapper(inputs)\n\n        # Gather all streams\n        y = tf.transpose(y, perm=[0,1,3,4,2])\n        # [batch_size, num_tx, num_ofdm_symbols, num_symbols_per_layer,...\n        #  num_streams]\n        y = tf.reshape(y, shape=[-1, self._layer_mapper.num_streams])\n\n        # Reshape reflectors\n        reflectors = tf.repeat(self._layer_mapper.reflectors,\n                               inputs.shape[0], axis=0)\n        # [batch_size, num_tx, num_layers, num_res_symbols]\n        reflectors = tf.reduce_sum(reflectors, axis=-1)\n\n        # Distrbuted reflector arrays can result in less than two\n        # reflectors per codeword. We set -1 to such positions to indicate\n        # that the value should be ignored.\n        num_cw = reflectors.shape[1]\n        ind = tf.tile(tf.expand_dims(tf.range(0, num_cw), axis=0),\n                      multiples=[tf.shape(reflectors)[0], 1])\n        is_invalid = tf.equal(ind, 0)\n        reflectors = tf.where(is_invalid, -1*reflectors, reflectors)\n\n        # [batch_size, num_tx, num_cw, num_streams]\n        y = tf.reshape(y, [-1, self._layer_mapper.num_tx, num_cw, -1])\n\n        # Gather streams for all codewords\n        # [batch_size, num_tx, num_cw, num_ofdm_symbols, num_symbols_per_layer]\n        y = tf.gather(y, reflectors, batch_dims=1, axis=1)\n\n        # Reshape\n        # [batch_size, num_tx, num_ofdm_symbols,...\n        #  num_cw*num_symbols_per_layer]\n        y = tf.reshape(y, [self._layer_mapper.num_tx, -1,\n                           self._num_reflectors,\n                           y.shape[3]*y.shape[4]])\n\n        # Coodword length\n        n = self._layer_mapper.codeword_length\n\n        # [batch_size, num_tx, num_cw, n/2], tf.complex\n        c = tf.complex(\n            y[:,:,:,:n//2,:],\n            y[:,:,:,:(n//2)+1,:]\n        )\n\n        # [batch_size, num_tx, num_cw, n], tf.complex\n        if n%2==0:\n            cw = tf.concat(\n                (c,\n                 tf.reverse(c, axis=[3]),\n                ), axis=3)\n        else:\n            cw = tf.concat(\n                (c,\n                 tf.reverse(c, axis=[3]),\n                 y[:,:,:,n//2,:]\n                ), axis=3)\n\n        # [batch_size, num_tx, num_cw, num_layers, num_ofdm_symbols,...\n        #  ..., num_symbols_per_layer]\n        cw = tf.transpose(cw, perm=[0,1,2,5,6,3,4])\n        # Reshape first num_layers-1 to [batch_size, num_tx, num_cw,...\n        #  ...,num_ofdm_symbols, 1, num_symbols_per_layer]\n        cw = tf.expand_dims(cw[:,:,:,:-1,:,:,:], axis=-2)\n        # [batch_size, num_tx, 1, num_ofdm_symbols,...\n        #  ...,num_streams, num_symbols_per_layer]\n        a = cw\n        # Gather last layer\n        # [batch_size, num_tx, 1, num_ofdm_symbols, 1, num_symbols_per_layer]\n        b = cw[:,:,-1:,:,:,:]\n        # Stack to bring all a and b to the same dimension\n        # [num_cw*(num_layers-1), :, num_ofdm_symbols, 1, num_symbols_per_layer]\n        a = tf.reshape(a, tf.stack([-1,tf.shape(a)[1],tf.shape(a)[3],1,tf.shape(a)[4]]))\n        ab = tf.concat([a,b], axis=2)\n        # Final demapping\n        # [num_cw*(num_layers-1), :, num_ofdm_symbols, 1]\n        cw = tf.gather(ab, self._layer_mapper.demapping_ind, batch_dims=2, axis=2)\n        cw = tf.squeeze(cw, axis=-1)\n        # Reshape cws to [...,num_cw, n]\n        cw = split_dim(cw, [self._layer_mapper.num_cw, self._layer_mapper.codeword_length-n//2], axis=1)\n        cw = tf.concat([cw[0], cw[1]], axis=-1)\n        # Restore the batch dimensions\n        batch_size = inputs.shape[0]\n        num_cw = cw.shape[1]\n        cw = tf.tile(cw, multiples=[batch_size, num_cw, 1])\n        # Return real and imaginary part separately\n        # cw_real: [..., num_cw, n]\n        cw_real = tf.math.real(cw)\n        # cw_imag: [..., num_cw, n]\n        cw_imag = tf.math.imag(cw)\n        return cw_real, cw_imag\n```"
"To create a PUSCHReceiver using the PUSCHTransmitter and simulate transmissions over the AWGN channel, you can follow these steps:\n\n1. Import the necessary modules and set up the environment:\n\n```python\nimport os\nimport numpy as np\nfrom sionna.mimo import StreamManagement\nfrom sionna.nr import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver\nfrom sionna.channel import AWGN\nfrom sionna.utils import compute_ser, ebnodb2no, PlotBER\nfrom sionna.ofdm import KBestDetector\n```\n\n2. Set up the GPU configuration and import the Sionna package:\n\n```python\ngpu_num = 0\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\ntry:\n    import sionna\nexcept ImportError as e:\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n3. Configure the PUSCH transmitter and create a PUSCHReceiver:\n\n```python\npusch_config = PUSCHConfig()\npusch_transmitter = PUSCHTransmitter(pusch_config)\nstream_management = StreamManagement(pusch_config, num_tx=1, num_streams_per_tx=1)\npusch_receiver = PUSCHReceiver(pusch_transmitter, stream_management, return_effective_csi=True)\n```\n\n4. Set up the AWGN channel and the K-Best detector for OFDM transmissions:\n\n```python\nchannel = AWGN()\nofdm_detector = KBestDetector(num_ofdm_symbols, l, p, pusch_config.fft_size, indices, 1, 'mmse')\n```\n\n5. Simulate transmissions over the AWGN channel and compute the error rate:\n\n```python\nno = ebnodb2no(ebno_db, num_bits_per_symbol=pusch_config.modulation_order, coderate=1.0)\nbatch_size = 1000\nnum_batches = 100\nx = pusch_transmitter(batch_size)\nno_ = no * np.ones([batch_size, 1])\ny = channel([x, no_])\ny = pusch_receiver(y)\nx_hat, no_eff = pusch_receiver([y, no_])\nx_ind = np.argmax(x_hat, axis=-1)\nprint(\"x_ind.shape:\", x_ind.shape)\nprint(\"x_ind:\", x_ind)\nprint(\"no_eff:\", no_eff)\nprint(\"SER (no eff. CSI):\", compute_ser(pusch_config.pusch_configurations[0].code_rate, x_ind, x_hat, no))\n```\n\n6. If you want to plot the BER for different channel estimators, you can use the PlotBER class:\n\n```python\nebno_db = np.linspace(EBNODB_MIN, EBNODB_MAX, 20)\nmodel = 'perfect_csi'\nplot_ber = PlotBER(r\"OFDM with $K$-best detection\", \"5G NR\")\n```\n\nPlease note that the exact code may vary depending on the specific requirements of your simulation."
"Here is the definition of SymbolInds2Bits: sionna.mapping.SymbolInds2Bits(constellation_type, num_bits_per_symbol, dtype=tf.complex64, **kwargs)  \n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#SymbolInds2Bits)  \n```python\nclass SymbolInds2Bits(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    SymbolInds2Bits(constellation_type, num_bits_per_symbol, dtype=tf.complex64, **kwargs)\n\n    Computes a tensor of symbol indices (i.e.,  the position of a constellation\n    point in the constellation) from a tensor of symbol indices.\n\n    Parameters\n    ----------\n    constellation_type : str\n        One of [\"qam\", \"pam\", \"custom\"]. For \"custom\", an instance of\n        :class:`~sionna.mapping.Constellation` must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The output dtype. Defaults to tf.complex64.\n\n    Input\n    -----\n    : [..., n], tf.int\n        Tensor of symbol indices.\n\n    Output\n    ------\n    : [..., n, num_bits_per_symbol], tf.float\n        Tensor of bits.\n\n    \"\"\"\n    def __init__(self,\n                 constellation_type,\n                 num_bits_per_symbol,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        self._num_bits_per_symbol = num_bits_per_symbol\n        self._constellation_type = constellation_type\n        if constellation_type == \"custom\":\n            self._constellation = kwargs[\"constellation\"]\n            self._constellation.check_input_dtype(self.dtype)\n            self._constellation.check_output_dtype(self.dtype)\n        else:\n            self._constellation = Constellation(constellation_type,\n                                            num_bits_per_symbol,\n                                            dtype=dtype)\n\n    def __call__(self, inputs):\n        return self._constellation.indices2bits(inputs)\n```  \n  "
"Here is the detailed information of TimeChannel:   \n  \n[sionna.channel.TimeChannel](https://nvlabs.github.io/sionna/_modules/sionna/channel/discrete_time_channel.html#TimeChannel)  \n  \nGenerate channel impulse responses (CIRs) and channel responses in the time domain.\n\nThis class generates channel model outputs in the time domain, i.e., from the channel impulse response (CIR) in the discrete time domain. Only one sub-carrier frequency is considered.\n\nFor each batch example, batch_size CIRs are generated by sampling a Gaussian distribution. The parameters of this distribution are given by the power delay profile (PDP) in power domain and the Doppler spectrum in time domain. The generated CIRs can then be used to filter a channel input of length N_B, by generating the channel response at the sampling frequency, and convolving the channel input with the time-variant channel filter.\n\nThe class outputs channel inputs and channel responses, which can be used to simulate the channel in the time domain.\n\n**Notes**\nThe PDP is sampled at a rate determined by the maximum expected Doppler shift of the considered channel model, which can be computed with compute_doppler_cov_mat().\n\n**How to use the TimeChannel class**\n\nThe following steps provide a high-level overview of how to use this class within a channel model implementation.\n\n- Instantiate a TimeChannel object, providing the necessary configuration parameters, such as the number of antennas, samples per symbol, and whether to return the channel responses or the channel inputs.\n- Specify the batch size and create a batch of random channel realizations using the `__call__` method.\n- Generate a batch of random channel responses at each of the antennas by calling the channel function with the necessary parameters.\n- Use the returned values from the channel function, which represent the path gains and phases, to apply the channel effects to the channel inputs.\n\n**Parameters**\n\n- `channel_model` (ChannelModel object): Specifies the channel model from which to generate the CIRs or channel responses. This can be an instance of one of the built-in channel models, such as RayleighBlockFading or TDL, or a custom ChannelModel instance.\n- `return_channel_response` (bool): If True, the channel responses $(a_m(t), \\tau_m)$ are returned. If False, the channel impairments $(h(t), \\tau_m)$ are returned. Defaults to False.\n- `dtype` (tf.DType): Data type for internal calculations and the output dtype. Defaults to tf.complex64.\n\n**Input**\n\n- `batch_size` (int): Batch size, specifying the number of examples processed by the channel model.\n- `num_time_steps` (int): Number of time steps forming the channel filter ($N_B$).\n- `sampling_frequency` (float): Sampling frequency in Hertz (Hz).\n\n**Output**\n\n- `h_time` ([batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex): Channel filter in time domain.\n- `x_time` ([batch size, num_tx, num_tx_ant, num_time_steps], tf.complex): Channel inputs."
"The 'Antenna' class in the Sionna novel Python package is designed to implement an antenna object in wireless propagation modeling. It is a fairly complex class with numerous attributes, properties, and methods tailored for antenna configuration, pattern specification, and radio signal transmission and reception.\n\nKey Attributes of the Antenna Class:\n\n- `antenna_pattern`: Describes the normalized far field antenna pattern. It can be either a function or a value.\n- `pattern_type`: Indicates the type of antenna pattern. Can be \"iso\", \"dipole\", \"hw_dipole\", \"tr38901\", or \"custom\".\n- `polarization`: Denotes the type of polarization, with \"V\" for vertical, \"H\" for horizontal, and \"cross\" for cross.\n- `dtype`: Specifies the data type, particularly relevant for defining the precision of complex-valued parameters.\n\nKey Properties of the Antenna Class:\n\n- `antenna_pattern`: Same as the attribute `antenna_pattern`, but defined as a property for easier access.\n- `dtype`: Refers to the data type of the antenna parameters.\n- `pattern_type`: Property representing the antenna pattern type.\n- `polarization`: Property for defining the antenna polarization.\n\nKey Methods of the Antenna Class:\n\n- `compute_weights()`: Method to compute the array weights for this antenna, based on the defined pattern and polarization.\n- `from_tr38901()`: A method to set the antenna parameters based on the TR38.901 standard.\n- `show()`: Method to generate and display the antenna patterns.\n\nUsage of the Antenna Class:\n  \nThe 'Antenna' class is typically used in setting up antenna configurations for radio propagation simulation in Sionna. It can be configured with single or dual polarization, specific antenna patterns, and different antenna array configurations. The class is closely related to the 'AntennaArray' class, which is used to define arrays of antennas. The class also includes the functionality to compute propagation paths between transmitters and receivers for further analysis of signal quality and coverage."
"SOURCE CODE:\n\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 Deutsches Institut f\u00fcr Menschenrechte und der Klimschutzinitiative e.V. (DIHRET)\n# SPDX-FileCopyrightText: Copyright (c) 2021 Intel Corporation, Inc.\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 Deutsches Institut f\u00fcr Menschenrechte und Klimaschutz (DIHK)\n# SPDX-License-Identifier: BSD-3-Clause\n# SPDX-License-Identifier: GPL-2.0\n#\n\"\"\"\nImplements error handling for the Turbo Code Termination process.\nError handling is done by triggering pre-defined RunTimeError\nor AssertionErrors with custom error messages.\n\"\"\"\n\nclass TurboTermination:\n    \"\"\"Class implements various Turbo Code Termination options.\n\n    The class implements error handling for the Turbo Code Termination\n    process by triggering `RunTimeError` with a pre-defined error\n    message or `AssertionError` with a custom error message.\n\n    The Turbo code termination process is crucial for ensuring that the\n    estimate of the information bits is of high quality. The process is\n    iterative and based on comparing reliabilities of the estimated\n    information bits and the parity bits. For details, see [Termination]_.\n\n    The class inherits from the Keras layer class and can be used as layer\n    in a Keras model.\n\n    Parameters\n    ----------\n        term_method: str\n            String that sets the termination method. Valid options are\n            \"sep\", \"sig\", and \"bit\". Details on these methods can be found\n            in [Termination]_.\n\n        num_term_bits: int\n            Number of termination bits per codeword. It is only required\n            for ``term_method`` \"bit\".\n\n        verbose: bool\n            Defaults to `True`. If `True`, the class properties are printed.\n\n    Properties\n    ----------\n\n    Please refer to the property description for details.\n    Note that all properties are read-only.\n\n    .. _prop_turbo_term_method:\n\n    method\n        Method for the termination of the Turbo Code.\n    \"\"\"\n    @property\n    def method(self):\n        return self._term_method\n\n    @property\n    def num_term_bits(self):\n        return self._num_term_bits\n\n    @property\n    def verbose(self):\n        return self._verbose\n```"
"To wrap everything in a Keras model for convenient Bit Error Rate (BER) simulations and comparison of model parameters, you can follow these steps:\n\n1. Import the necessary libraries and modules. This includes TensorFlow, Keras, and other necessary modules suchjson, matplotlib, numpy, and so on.\n\n2. Set up your system parameters. This includes the scenario, carrier frequency, number of resource blocks, CDL model, speed, and other parameters related to the MIMO, antennas, and camera.\n\n3. Define your 3GPP specification functions. This includes functions such as cdl, uplink_config, and transmit_signal.\n\n4. Define your transmitter and receiver. Your transmitter should include the system parameters as arguments, and the receiver should include the necessary signal processing steps.\n\n5. Wrap everything in a Keras model. This can be done by creating a class that inherits from `tf.keras.Model`. In the `__init__` method, you can initialize all the components of your system (transmitter, receiver, etc.). In the `__call__` method, you can then define the forward pass of your model.\n\nHere is a simplified example of how you might wrap everything in a Keras model:\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import Model\n\n# Define your system parameters here\n...\n\n# Define your 3GPP specification functions here\n...\n\nclass MyModel(Model):\n    def __init__(self, ...):\n        super(MyModel, self).__init__()\n        # Initialize system parameters\n\n        # Initialize 3GPP specification functions\n\n        # Initialize transmitter and receiver\n        ...\n\n    def __call__(self, batch_size, snr_db):\n        # Define forward pass of the model\n        ...\n```\n\nIn the `__call__` method, you can define the forward pass of your model. This should take a batch of SNR values and return the corresponding bit error rate (BER) values.\n\nPlease note that this is a simplified example and you will need to fill in the details according to your specific requirements."
"The `build_type_grid` function is a method of the `ResourceGrid` class in the Sionna module used to build a grid of resource elements (REs) for all transmitters and streams. The function defines the structure of the grid in the frequency domain (OFDM or unique-named subcarriers) and time (synchronization or pilot symbols).\n\n**Function Parameters**\nThis function takes three input parameters:\n1. `ofdm` (boolean type): Defines if the grid is computed over OFDM symbols.\n2. `u_min` (int type): Defines the first row index for all antennas and streams.\n3. `u_max` (int type): Defines the last row index for all antennas and streams.\n4. `s_min` (int type): Defines the first column index for all streams.\n5. `s_max` (int type): Defines the last column index for all streams.\n\n**Function Output**\nThe function returns a 2+D tensor containing the resource grid for all transmitters and streams. The shape of the output tensor is defined as (`u_max - u_min + 1, s_max - s_min + 1, num_symbols, num_slots, num_ofdm_symbols, num_effective_subcarriers`)."
"Here is the detailed information of SymbolLogits2LLRs:   \n\nLink of the source code: https://nvlabs.github.io/sionna/_modules/sionna/mimo/symbol_logits.html#SymbolLogits2LLRs  \n  \nComputes log-likelihood ratios (LLRs) or hard-decisions on bits from a tensor of logits (i.e., unnormalized log-probabilities) on constellation points.\n\nThis class is deprecated as the functionality has been integrated into SymbolLogits2LLR or SymbolLogits2HardDecisions.\n\nParameters\n\n        method (One of [\"app\", \"maxlog\"], str) \u2013 The method used for computing the LLRs.\n\n        num_bits_per_symbol (int) \u2013 The number of bits per constellation symbol, e.g., 4 for QAM16.\n\n        hard_decisions (bool) \u2013 If True, the layer provides hard-decided bits instead of soft-values. Defaults to False.\n\n        dtype (One of [tf.float32, tf.float64] tf.DType (dtype)) \u2013 The dtype for the input and output. Defaults to tf.float32.\n\nInput\n\n        (logits, ) \u2013 Tuple:\n\n        logits ([\u2026, num_points], tf.float) \u2013 Logits on constellation points.\n\nOutput\n\n    [\u2026, num_bits_per_symbol], tf.float \u2013 LLRs or hard-decisions for every bit."
"Here is the detailed information of MaximumLikelihoodDetector:   \n  \n[sionna.ofdm.MaximumLikelihoodDetector(output, demodulator, resource_grid, stream_management, num_detect=1, decision=\"hard\", dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#MaximumLikelihoodDetector)  \n\nMaximum-likelihood (ML) detection for OFDM MIMO transmissions.\n\nThis layer implements maximum-likelihood (ML) detection for OFDM MIMO transmissions. Both ML detection of symbols or bits with either soft- or hard-decisions are supported. The OFDM and stream configuration are provided by a ResourceGrid and StreamManagement instance, respectively. The actual detector is an instance of MaximumLikelihoodDetector.\n\n**Parameters**\n\n- `output` (str): Type of output, either \"bit\" for bits or \"symbol\" for symbols. Configuration for soft- or hard-decisions is controlled by the `decision` parameter.\n- `demodulator` (Demodulator): Demodulator instance, used to compute the receive stream in-form data and pilot estimates.\n- `resource_grid` (ResourceGrid): Resource grid instance.\n- `stream_management` (StreamManagement): Stream management instance.\n- `num_detect` (int, default: 1): Number of parallel detectors. This parameter is related to the number of deep-saved receive streams (or paths) that the detector will compute in parallel.\n- `decision` (str, default: \"hard\"): Type of decision, either \"hard\" or \"soft\". Hard decisions are generally used for bit detection, while soft decisions are required for using ML detection at the channel output to compute LLRs for a subsequent decoder.\n- `dtype` (tf.Dtype): Datatype for internal calculations and the output dtype. Defaults to tf.complex64.\n\n**Input**\n\n- `(y, h_hat, err_var, no)` \u2013 Tuple:\n  - `y` ([batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex): Received OFDM resource grid after cyclic prefix removal and FFT.\n  - `h_hat` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex): Channel estimates for all streams from all transmitters.\n  - `err_var` ([Broadcastable to shape of h_hat], tf.float): Variance of the channel estimation error.\n  - `no` ([batch_size, num_rx, num_rx_ant] or only the first n dimensions, tf.float): Variance of the AWGN.\n\n**Output**\n\nDepending on the `output` parameter:\n- If `output` equals \"bit\":\n  - [batch_size, num_tx, num_streams, num_data_symbols * num_bits_per_symbol], tf.float: LLRs or hard-decisions for every bit of every stream.\n- If `output` equals \"symbol\":\n  - [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int: Logits or hard-deicisions for constellation symbols for every stream. Hard-decisions correspond to the symbol indices.\n\n**Note:** If you want to use this layer in Graph mode with XLA, i.e., within a function that is decorated with @tf.function(jit_compile=True), you must set sionna.Config.xla_compat=true. See xla_compat."
"To initialize a `TurboEncoder` with custom generator polynomials in the `sionna` package, you need to represent the generator polynomials as binary strings and understand their interpretation. The generator polynomials in the Turbo code are typically denoted as $\\mu = 2$ or $\\mu = 4$ polynomials, and each polynomial is represented as a binary string.\n\nAn example of a generator polynomial for the Turbo code in binary representation could be \"10011\". This is a 5-bit binary string. In the context of polynomial representation, the most significant bit (MSB) is the leading term of the polynomial, and the least significant bit (LSB) is the constant term. Therefore, the binary \"10011\" represents the polynomial $1 + D^3 + D^4$, where $D$ is the binary operator, not the variable. In the binary field, additions are represented as XOR operations, and the leading \"1\" is used to ensure that the resulting code has unit gain at the encoder. \n\nTaking into account the specific requirement about initializing a `TurboEncoder` with custom generator polynomials, you would need to create a tuple of the generator polynomials in binary representation and pass it as an argument to the `polynomial` parameter of the `TurboEncoder`. The generator polynomials can be derived from the factorization of polynomials or by following a standard Turbo code library, which usually provides pre-computed generator polynomials for a given constraint length ($K$) and code rate.\n\nHere is an illustrative example of how you might set up the `TurboEncoder` with custom generator polynomials, based on the information provided in the context:\n\nFirst, you would need to express the generator polynomials in binary representation. Let's assume you have two polynomials, `g0` and `g1`, which you have calculated to be \"10011\" and \"11101\", respectively. These polynomials correspond to the polynomials $1 + D^3 + D^4$ and $1 + D + D^4 + D^5$, respectively.\n\nNext, you would initialize the `TurboEncoder` and provide the generator polynomials as a tuple to the `polynomial` parameter. The `polynomial` parameter expects a tuple in the form `(<g0>, <g1>)`, where `<g0>` and `<g1>` are the generator polynomials expressed as binary strings:\n\n```python\nfrom sionna.fec.turbo import TurboEncoder\n\n# Assuming you have already calculated g0 and g1\ng0 = \"10011\"\ng1 = \"11101\"\n\n# Initialize the TurboEncoder with the custom generator polynomials\nencoder = TurboEncoder(polynomial=(g0, g1), rate=1/3)\n```\n\nIn this example, the `g0` polynomial will be used as the primary component polynomial for the constituent convolutional encoder, and the `g1` polynomial will be used for the secondary component polynomial.\n\nIt's important to highlight that the generator polynomials `g0` and `g1` are specific to the Turbo code design and correspond to the constraints imposed by the recursive systematic convolutional (RSC) encoder that is used in the Turbo code structure. These polynomials have been carefully selected to ensure good coding performance and are not the same as the generator polynomials in linear block codes.\n\nAlso, remember that the constraint length of the RSC encoder affects the shape of the generator matrix, which in turn influences the memory and termination properties of the Turbo code. For constraint length ($K$) and code rate usage, you'll want to refer to any applicable standards or design specifications.\n\nLastly, the generator polynomials influence the code efficiency and performance, so selecting the best polynomials for a specific application may require thorough testing and analysis."
"To sample the first few items of the dataset using the generator, follow these steps:\n\n1. Define the generator: The context does not provide the exact code used to define the generator. However, it mentions that the `Sionna` package includes a built-in generator for loading saved datasets. You might need to use this generator or define your own generator depending on the requirements of your dataset.\n\n2. Call the `tfilereg` function with the generator and the number of samples you want to retrieve. The `tfilereg` function is mentioned in the context and is used to make a tensor from the generator. The first argument of this function is the generator, and the second argument is the number of samples you want to retrieve. \n\nHere is an approximate python code snippet that demonstrates how to sample the first few items of a dataset using a generator:\n\n```python\n# Define the generator\ngen = YourGeneratorClass(parameters)\n\n# Using the generator to sample the first few items of the dataset\ndata = tfilereg(gen, number_of_samples=10)\n```\n\nIn this code, `YourGeneratorClass` should be the class you used to define the generator. You need to replace `parameters` with the actual parameters you are using to define the generator. The `number_of_samples` argument in the `tfilereg` function call specifies the number of samples you want to retrieve from the dataset.\n\nPlease note that the actual code may vary depending on the specific implementation of the generator and the dataset. The provided code is a general template and might need to be adjusted to fit your specific use case."
"To save the estimated matrices for future use, you can use the numpy `save` function. In the `compute_paths` function, you would replace the `return` statement with a statement to save the matrices. Here's how you could do it:\n\n```python\n# Compute Covariance and Autocorrelation Matrices\n    P = np.matmul(F, np.matmul(D, F.conj().T))\n    R = np.matmul(G, np.matmul(D, G.conj().T))\n\n    # Save the matrices\n    np.save('covariance_matrix.npy', P)\n    np.save('autocorrelation_matrix.npy', R)\n```\n\nThis code first computes the covariance and autocorrelation matrices, and then saves them using the `save` function from numpy. The first argument is the file name and the second argument is the matrix you want to save.\n\nIf you also want to save the other matrices that are estimated in the `compute_paths` function, you would add more `np.save` statements after the `P` and `R are computed`.\n\nThen, to load these saved matrices in the future, you can use the numpy `load` function in the following way:\n\n```python\nP = np.load('covariance_matrix.npy')\nR = np.load('autocorrelation_matrix.npy')\n```\n\nThis will load the saved matrices into the same variables that were used to save them."
"Iterative Detection and Decoding (IDD) is a concept in MIMO (Multi-Input, Multi-Output) simulations that involves the iterative exchange of information between a detector and a decoder to improve the quality of the received signals. \n\nIn MIMO simulations, the transmitted signals are represented as a vector of bits, which are then mapped to a constellation point (a point in the signal constellation) and transmitted over multiple antennas. The received signals, which are affected by noise and interference, are then processed by a detector to produce soft information (a probability distribution over all constellation points). \n\nThe detected soft information is then passed to a decoder for further processing. However, this traditional one-way process does not take full advantage of the spatial diversity offered by MIMO systems. \n\nIDD, on the other hand, leverages this diversity by iteratively exchanging information between the detector and the decoder. The received signals are first processed by the detector to generate hard decisions (bits) regarding the transmitted symbols. These hard decisions are then passed to the decoder, which uses them to generate updated soft information. This updated soft information is then passed back to the detector, and this process is repeated iteratively until a stopping criterion is met (for example, a maximum number of iterations or a certain level of confidence in the decoded bits).\n\nThe IDD process allows for significant performance improvements compared to traditional non-iterative detection and decoding processes. It can effectively correct errors introduced by the detector and provide near-optimal performance, particularly in high signal-to-noise ratio (SNR) scenarios. However, it requires more computational complexity and additional hardware resources."
"Here is the detailed information of Descrambler:  \nSource code: [https://nvlabs.github.io/sionna/_modules/sionna/fec/scrambling.html#Descrambler]  \n\nImplements the Descrambler as a layer.\n\nThe Descrambler layer descrambles the received sequence of bit/word indices. For each scrambled sequence, the corresponding Descrambler must be defined with Scrambler. The descrambler can be made stateful by using stateful=True and providing a seed as to initialize the pseudo random generator for each list.\n\nFor simplicity, the layer directly takes the generator polynomials and does not require access to the Scrambler layer that originally generated the scrambled sequences.  \n  \nThe parameters of the class include:  \n- `seed (int, None):` Defines the initial state of the random generator. If None, the current global random seed is used. \n- `keep_state (bool):` If True, the state of the Descrambler is internal and it is updated after each call. This is required to properly continue scrambling/descrambling sequences. \n- `scrambler (Scrambler):` Associated scrambler that generated the scrambled sequence.  \n- `binary (bool):` Indicates if the Descrambler should operate on bit-sequence (i.e., LLRs or soft-symbols).  \n- `dtype (tf.DType):` Data type of internal calculations and output.  \n  \nThe input and output of the class instance are: \nInput: \n  - `x` (ndarray or Tensor of shape `[\u2026,sequence_per_pr]`): 1/0 or bipolar sequence to be descrambled.  \nOutput: \n  - `ndarray` of the same shape and dtype as `x`: Descrambled sequence.  \n  \nThe class instance should raise an AssertionError if `sequence_per_pr` is not a positive integer.  \n  \nPlease note that the reference implementation of the Descrambler uses the same internal implementation as the Scrambler and, therefore, can be potentially influenced by the eager/global graph mode. For a different implementation that avoids this issue, please have a look at the [Descrambler](https://nvlabs.github.io/sionna/_modules/sionna/fec/scrambling.html#Descrambler) documentation.  \n  \nThe class instance applies the descrambler to its input `x` and returns the descrambled output. The class instance keeps track of its state, and it can be used to subsequently scramble or descramble data."
"Here is the definition of KBestDetector: sionna.mimo.KBestDetector(output, num_streams, k, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, use_real_rep=False, list2llr=None, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/mimo/detection.html#KBestDetector)  \n\n```python\nclass KBestDetector(MIMODetector):\n    # pylint: disable=line-too-long\n    r\"\"\"KBestDetector(output, num_streams, k, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, use_real_rep=False, list2llr=None, dtype=tf.complex64)\n\n    MIMO K-Best detector\n\n    This layer implements K-Best MIMO detection as described\n    in (Eq. 4) [FT2015]_. It can either generate hard decisions (for symbols\n    or bits) or compute LLRs.\n\n    The algorithm operates in either the complex or real-valued domain.\n    Although both options produce identical results, the former has the advantage\n    that it can be applied to arbitrary (non-QAM) constellations. It also reduces\n    the number of streams (or depth) by a factor of two.\n\n    The way soft-outputs (i.e., LLRs) are computed is determined by the\n    ``list2llr`` function. The default method\n    :class:`~sionna.mimo.List2LLRSimple` assigns a predetermined\n    value to all LLRs without counter-hypothesis.\n\n    This layer assumes the following channel model:\n\n    .. math::\n        \\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n\n    where :math:`\\mathbf{y}\\in\\mathbb{C}^M` is the received signal vector,\n    :math:`\\mathbf{x}\\in\\mathcal{C}^S` is the vector of transmitted symbols which\n    are uniformly and independently drawn from the constellation :math:`\\mathcal{C}`,\n    :math:`\\mathbf{H}\\in\\mathbb{C}^{M\\times S}` is the known channel matrix,\n    and :math:`\\mathbf{n}\\in\\mathbb{C}^M` is a complex Gaussian noise vector.\n    It is assumed that :math:`\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}` and\n    :math:`\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}`,\n    where :math:`\\mathbf{S}` has full rank.\n\n    In a first step, the channel model is converted to its real-valued equivalent,\n    see :func:`~sionna.mimo.complex2real_channel`. We assume in the sequel the complex-valued\n    representation. Then, the channel is whitened using :func:`~sionna.mimo.whiten_channel`:\n\n    .. math::\n        \\tilde{\\mathbf{y}} &= \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{y}\\\\\n        &=  \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{H}\\mathbf{x} + \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{n}\\\\\n        &= \\tilde{\\mathbf{H}}\\mathbf{x} + \\tilde{\\mathbf{n}}.\n\n    Next, the columns of :math:`\\tilde{\\mathbf{H}}` are sorted so that\n    channel hardening can be applied, see :func:`~sionna.mimo.harden_channel`:\n\n    .. math::\n        \\bar{\\mathbf{H}}\\mathbf{x} &= \\underset{j\\in\\mathcal{J}}{\\text{max}} \\left\\vert h_j \\right\\vert w_j \\mathbf{x} + \\bar{\\mathbf{n}}\\\\\n        &= \\bar{\\mathbf{H}}\\mathbf{x} + \\bar{\\mathbf{n}}.\n\n    Then, the channels to the desired number of streams (equal to\n    the number of transmitters) are extracted:\n\n    .. math::\n        \\mathbf{H}_{\\mathcal{S}} =\n        \\begin{bmatrix}\n        \\bar{\\mathbf{h}}_1^\\mathsf{T}\\\\\n        \\vdots\\\\\n        \\bar{\\mathbf{h}}_S^\\mathsf{T}\n        \\end{bmatrix},\n\n    and the residual single-user MIMO channel is computed as\n\n    .. math::\n        \\bar{\\mathbf{H}}^{\\mathcal{S}} \\mathbf{x} =\n        \\bar{\\mathbf{H}}\\mathbf{x} - \\mathbf{H}_{\\mathcal{S}}\\mathbf{x}.\n\n    **Detection**\n\n    The K-Best detector produces :math:`K` candidate solutions :math:`\\mathbf{x}_k\\in\\mathcal{C}^S`\n    and their associated distance metrics :math:`d_k=\\lVert \\tilde{\\mathbf{y}} - \\tilde{\\mathbf{H}}\\mathbf{x}_k \\rVert^2`\n    for the real-valued channel. If the optional real_rep is set to `True`,\n    the distance metrics are applied to the real-valued channel (i.e.,\n    to each individual real/imaginary dimension), which is computationally more efficient.\n    The closest vector in terms of distance is then selected as the output.\n    If `hard_out` is set to `True`, the detector outputs the candidate solution\n    with the shortest distance. Otherwise, the detector provides soft-information\n    in the form of LLRs on the symbols and bits.\n\n    **LLR Computation**\n\n    The LLRs for the symbols are computed from the distance metrics\n    and the receive covariance matrix (assumed to be diagonal):\n\n    .. math::\n        \\begin{split}\n            LLR_{\\text{sym},k, l}} &= \\ln\\left( \\frac{\\sum\\limits_{c\\in\\mathcal{C}_k}\\exp\\left(-\\frac{d_c}{2}\\right) \\Pr \\left[ c \\lvert \\tilde{\\mathbf{y}}, \\mathbf{S} \\right] }{\\sum\\limits_{c\\in\\mathcal{C}_{\\bar{k}}}\\exp\\left(-\\frac{d_c}{2}\\right) \\Pr \\left[ c \\lvert \\tilde{\\mathbf{y}}, \\mathbf{S} \\right] }\\right)\\\\\n            LLR_{\\text{bit},k, l} &= \\ln\\left( \\frac{\\sum\\limits_{b\\in\\mathcal{B}_k}\\exp\\left(-\\frac{d_b}{2}\\right) \\Pr \\left[ b \\lvert \\tilde{\\mathbf{y}}, \\mathbf{S} \\right] }{\\sum\\limits_{b\\in\\mathcal{B}_{\\bar{k}}}\\exp\\left(-\\frac{d_b}{2}\\right) \\Pr \\left[ b \\lvert \\tilde{\\mathbf{y}}, \\mathbf{S} \\right] }\\right)\n        \\end{split}\n\n    where $\\mathcal{C}_k$ is the set of all length :math:`l` codewords\n    that have :math:`k` bits set to +1, :math:`\\mathcal{B}_k` is the corresponding\n    set of all codeword bits set to +1, :math:`\\Pr \\left[ c \\lvert \\tilde{\\mathbf{y}}, \\mathbf{S} \\right]`\n    is the prior probability of the codeword :math:`c`, and :math:`d_c` (or :math:`d_b`)\n    is the distance (or reliability) metric of the codeword symbol or bit to the received vector\n    (or bit value of 0).\n\n    Parameters\n    -----------\n    output : One of [\"bit\", \"symbol\"], str\n        The type of output, either bits or symbols. Whether soft- or\n        hard-decisions are returned can be configured with the\n        ``hard_out`` flag.\n\n    num_streams : tf.int\n        Number of transmitted streams (transmitters)\n\n    k : tf.int\n        The number of paths to keep. Cannot be larger than the\n        number of constellation points to the :math:`\\min(\\text{num_bits_per_symbol}, 16)`.\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the detector computes hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`. The detector\n        defaults to `False`. If \"bit\" is the output, the detector can be\n        configured to provide soft-information on the bits using the\n        ``hard_out`` flag.\n\n    use_real_rep : bool\n        If `True`, the detector use the real-valued equivalent representation\n        of the channel. Note that especially for low numbers of bits per\n        symbol, the complex-valued representation is more accurate since it\n        reduces the PAPR. Defaults to `False`.\n\n    list2llr : List2LLR or None\n        The function used to compute LLRs from a list of candidate solutions.\n        If `None`, the default list2llr function\n        :class:`~sionna.mimo.List2LLRSimple` is used.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of ``y``. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    -----\n    (y, h, s) :\n        Tuple:\n\n    y : [...,M], tf.complex\n        1+D tensor containing the received signals\n\n    h : [...,M,num_streams], tf.complex\n        2+D tensor containing the channel matrices\n\n    s : [...,M,M], tf.complex\n        2+D tensor containing the noise covariance matrices\n\n    Output\n    ------\n    One of:\n\n    : [..., num_streams, num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream, if ``output`` equals `\"bit\"`\n\n    : [..., num_streams, num_points], tf.float or [..., num_streams], tf.int\n       Logits or hard-decisions for constellation symbols for every stream, if ``output`` equals `\"symbol\"`\n       Hard-decisions correspond to the symbol indices.\n\n    Note\n    ----\n    If you want to use this layer in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sionna.Config.xla_compat=true``.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n    def __init__(self,\n                 output,\n                 num_streams,\n                 k,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 use_real_rep=False,\n                 list2llr=\"default\",\n                 dtype=tf.complex64):\n\n        assert dtype in [tf.complex64, tf.complex128],\\\n            \"dtype must be tf.complex64 or tf.complex128\"\n        self._cdtype = tf.dtypes.as_dtype(dtype).real_dtype\n        super().__init__(   output=output,\n                            num_streams=num_streams,\n                            num_ofdm_symbols=None,\n                            num_effective_subcarriers=None,\n                            detection=\"kbest\",\n                            detection_output=\"hardbit\",\n                            detection_input=\"soft\",\n                            list2llr=list2llr,\n                            hard_out=hard_out,\n                            use_real_rep=use_real_rep,\n                            resource_alloc=None,\n                            constellation_type=constellation_type,\n                            num_bits_per_symbol=num_bits_per_symbol,\n                            constellation=constellation,\n                            stream_management=\"e2e\")\n\n        # Internally, we compute LLRs for a single stream and\n        # multiple candidate solutions. This requires\n        # a different order of the constellation points for each stream.\n        # Here, we compute the indies to permute the constellation.\n        self._perm_indices = [\n                tf.cast(self._stream_manager.stream_ind,\n                        tf.int32,\n                        name=\"stream_ind\" + str(i))\n                for i in range(num_streams)]\n\n        # The detection consists of two parallel K-Best detectors which\n        # are run in either the complex or real domain.\n        self._kd = KBestDetectorLayer(  num_streams=num_streams,\n                                        k=k,\n                                        real_rep=False,\n                                        list2llr=self._list2llr,\n                                        constellation_type=constellation_type,\n                                        num_bits_per_symbol=num_bits_per_symbol,\n                                        constellation=constellation,\n                                        hard_out=hard_out,\n                                        dtype=dtype)\n        if self._hard_out == False and self._output == \"bit\":\n            self._kd_b = KBestDetectorLayer(   num_streams=num_streams,\n                                                k=k,\n                                                real_rep=True,\n                                                list2llr=self._list2llr,\n                                                constellation_type=constellation_type,\n                                                num_bits_per_symbol=num_bits_per_symbol,\n                                                constellation=constellation,\n                                                hard_out=hard_out,\n                                                dtype=dtype)\n\n    def call(self, inputs):\n\n        # Flatten the batch dimensions\n        y, h, s = inputs\n        y = flatten_dims(y, 1, -1)\n        h = flatten_dims(h, 1, -1)\n        s = flatten_dims(s, 1, -1)\n\n        # Convert to real-valued representation\n        y, h, s = complex2real_vector(y, h, s, self._cdtype)\n\n        # Whiten channel\n        y, h, s = whiten_channel(y, h, s, tf.cast(self._num_streams, y.dtype))\n\n        # Extract upper triangle of s\n        s = tf.linalg.band_part(s, 0, -1)\n\n        # Sort columns of h in order of decreasing channel norm\n        h_norm = tf.reduce_sum(tf.abs(h), axis=-2)\n        column_perm = tf.argsort(h_norm, axis=-1, direction=\"DESCENDING\")\n        h = tf.gather(h, column_perm, axis=-1, batch_dims=1)\n\n        # Compute parallel detections\n        if self._output == \"bit\":\n            if self._hard_out:\n                # Hard-bits: Complex-domain & Hard-decisions\n                pds = self._kd(h, s)\n            else:\n                # Soft-bits: Complex-domain & Soft-decisions\n                pds = self._kd(h, s)\n        else:\n            if self._hard_out:\n                # Hard-decisions: Real-domain\n                pds = self._kd(h, s)\n            else:\n                # Soft-decisions: Real-domain\n                pds = self._kd(h, s)\n                # Hard-decisions: Real-domain to Complex-domain\n                pds = self._kd_b(pds, h)\n\n        # Merge batch dimensions\n        if tf.rank(y)<3:  # tfa compatibility\n            y = tf.expand_dims(y, axis=0)\n        if tf.rank(h)<3:  # tfa compatibility\n            h = tf.expand_dims(h, axis=0)\n        if tf.rank(s)<3:  # tfa compatibility\n            s = tf.expand_dims(s, axis=0)\n        y = tf.expand_dims(y, axis=-1)\n        h = tf.expand_dims(h, axis=-1)\n        s = tf.expand_dims(s, axis=-1)\n        pds = tf.expand_dims(pds, axis=-1)\n        output = (y, h, s, pds)\n\n        return output\n```"
"The `position` and `orientation` properties are used to move scene objects in the Sionna module. A scene object could be a transmitter, receiver, or a camera. \n\nThe `position` property represents the 3D position of the scene object in the scene. The position is specified as a tuple of three numbers, and it is affected by the` set` and `reset` methods. \n\nThe `orientation` property represents the orientation of the scene object. It is specified by three angles corresponding to a 3D rotation. The angles are defined as `pitch`, `roll`, and `yaw` and are expressed in radians. The orientation property is also affected by the `set` and `reset` methods.\n\nFor example, to create a scene with a transmitter named \"tx\" at a position $(x, y, z)$ and an orientation specified by angles $(a, b, c)$, you would use the following steps.\n\n1. Create a `Transmitter` object with a name and a position:\n    ```python\n    tx = Transmitter(name=\"tx\", position=(x, y, z))\n    ```\n2. Set the orientation of the `tx` object:\n    ```python\n    tx.orientation = (a, b, c)\n    ```\n3. Add the `tx` object to the scene:\n    ```python\n    scene.add(tx)\n    ```\n\nYou can use the `position` and `orientation` properties to manipulate the location and orientation of scene objects to simulate real-world scenarios more accurately."
"To run the final evaluation for different system configurations in Sionna RT, you can follow these steps:\n\n1. Import the necessary modules and set up the environment:\n\n```python\nimport os\nimport tensorflow as``s tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sionna.mpc import load_mpc\nfrom sionna.rt import load_scene, Transmitter, Receiver, PlanarArray, Camera\nfrom sionna.channel import nr\nfrom sionna.utils import BinarySource, sim_ber, QAMSource, ebnodb2no, compute_ser\nfrom sionna.ofdm import ResourceGrid, LSChannelEstimator, LMMSEEqualizer\nfrom sionna.ofdm import OFDMModulator, OFDMDemodulator, ZFPrecoder, RemoveNulledSubcarriers\nfrom sionna.mimo import StreamManagement\nfrom sionna.mapping import Mapper, Demapper\nfrom sionna.tb import transport_block_encoder, transport_block_decoder\nfrom sionna.fec.ldpc import LDPC5GEncoder, LDPC5GDecoder\nfrom sionna.fec.ldpc.utils import AWGN\n```\n\n2. Set up the GPU configuration and import the Sionna package. If the package is not already installed, the system will install it:\n\n```python\ngpu_num = 0\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\ntry:\n    import sionna\nexcept ImportError as e:\n    os.system(\"pip install nvidia-smi\")\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n3. Configure the GPU to use only a limited amount of memory:\n\n```python\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\n\n4. Load the scene and configure the antenna array for all transmitters and receivers:\n\n```python\nscene = load_scene(sionna.rt.scene.munich)\nscene.tx_array = PlanarArray(1,1,0.5,0.5,\"tr38901\",\"V\")\nscene.rx_array = PlanarArray(1,1,0.5,0.5,\"dipole\",\"V\")\n```\n\n5. Create a new transmitter and receiver, and add them to the scene:\n\n```python\ntx = Transmitter(name=\"tx\", position=[8.5,21,27])\nscene.add(tx)\nrx = Receiver(name=\"rx\", position=[45,90,1.5], orientation=[0,0,0])\nscene.add(rx)\n```\n\n6. Set the carrier frequency of the scene and update all RadioMaterials:\n\n```python\nscene.frequency = 2.14e9\n```\n\n7. Compute the propagation paths:\n\n```python\ntx = scene.get(\"tx\")\npaths = scene.compute_paths(max_depth=5, num_samples=1e6)\npaths.normalize_delays = False\n```\n\n8. Generate the channel impulse response and apply the channel frequency response:\n\n```python\npaths.apply_doppler(sampling_frequency=scene.frequency, num_time_steps=14, tx_velocities=[3.,0,0], rx_velocities=[0,7.,0])\na, tau = paths.cir(sampling_frequency=scene.frequency, num_time_steps=14)\n```\n\n9. Set the CIR sampling frequency and update the CIR object:\n\n```python\nscene.frequency = scene.frequency\na, tau = [scene.frequency, a, tau]\n```\n\n10. Precoding for the OFDM resource grid:\n\n```python\na_prec = a\ntau_prec = tau\ncir_prec = [a_prec, tau_prec]\nprecoder = ZFPrecoder()\nprecoded_data = precoder(data, cir_prec, tau_max)\n```\n\n11. Time-smear the OFDM resource grid:\n\n```python\na_time = a\ntau_time = 5e-9\ncir_time = [a_time,tau_time]\nsmearer = TimeSmearing(sampling_frequency=186385, num_smear_samples=212, std_dev=30, window_length=95)\nx_time_smeared = smearer(codeword, cir_time)\n```\n\n12. Apply the OFDM channel to the time-smeared tensor:\n\n```python\nchannel = OFDMChannel(add_awgn=True, normalize_channel=True)\nno = 0.1 # Noise variance\ny = channel([x_time_smeared, no, h_freq])\n```\n\n13. Recover the spatial streams from the received signal:\n\n```python\nzf_detector = ZFDetector()\nx_hat, no_eff = zf_detector([y, h_freq, smearing_freq, precoding, stream_management])\n```\n\n14. Implement LDPC 5G encoding and decoding:\n\n```python\nebno_db = 8.5\nno = ebnodb2no(ebno_db, 2, coderate=ldpc_rate)\nchannel = AWGN()\ny = channel([x, no])\n```\n\n15. Define the LDPC5GEncoder and LDPC5GDecoder objects and perform the encoding and decoding:\n\n```python\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nfrom sionna.fec.ldpc.decoding import LDPC5GDecoder\nencoder = LDPC5GEncoder(k, n)\ndecoder = LDPC5GDecoder(encoder, num_iter=20)\ncws_enc = encoder(c)\ncws_dec = decoder(cws_enc)\n```\n\n16. Compare the encoded and decoded codeword:\n\n```python\nprint(\"Encoded Codeword: \", cws_enc.numpy())\nprint(\"Decoded Codeword: \", cws_dec.numpy())\n```\n\n17. Compute the bit error rate (BER):\n\n```python\nprint(\"BER: \", compute_ber(c, cws_dec).numpy())\n```\n\nRemember to replace the placeholders (like `ebno_db`, `k`, `n`, etc.) with the actual values based on your specific use case."
"To compute the exact Doppler shifts following the equation provided in the Background Information, you would need to know the speed of the observer, the speed of the source, the angle between the direction of the source and the observer, and the wavelength of the wave. \n\nUsing the equation provided in the Background Information, the exact Doppler shift (denoted as f_D in the equation) can be computed as: \n\nf_D = f_0 * (cos(theta_s) + cos(theta_o)) * v_s / c\n\nwhere:\n- f_0 is the original frequency of the wave\n- theta_s is the angle between the direction of the source and the observer\n- theta_o is the angle between the direction of the source and the transmitter\n- v_s is the speed of the source\n- c is the speed of light\n\nPlease note that this is a scalar equation, and the Doppler shift can be different for each vertex of the scene, as it depends on the angles and the speeds of the objects. You would need to compute this for each vertex separately. \n\nHere is a Python function that computes the exact Doppler shifts for each vertex of the scene:  \n```python\ndef compute_exact_doppler_shifts(scene, observer_velocity, source_velocity, wavelength):\n    # Compute Doppler shifts\n    # We assume that the ineterferometer is in the x-y plane with an elevation of 90 deg\n    rx = scene.rx\n    theta_rx = np.pi/2-rx.orientation[0]\n    ty = rx.position[1]\n    source = scene.sources[0]\n    y = source.position[1]\n    theta = source.orientation[0]\n    tb = scene.sources[0].orientation[0]\n    # The Doppler shift is computed using Eq. (7) with theta_o = theta_s = 0\n    fd = (2*cos(theta)/wavelength)*(source_velocity*(ty-y) + observer_velocity*tb) \n    return fd\n```\n\nYou would need to pass the scene, observer's velocity, source's velocity, and the wavelength of the wave to this function. The function would return the Doppler shifts for each vertex in the scene."
"Here is the definition of cir_to_time_channel: sionna.channel.cir_to_time_channel(cirs, bw, num_time_samples, los, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/utils.html#BaseTimeChannel.cir_to_time_channel)  \n```python\n    def cir_to_time_channel(self, cirs, bw, num_time_samples, los,\n                            dtype=tf.complex64):\n        # pylint: disable=line-too-long\n        r\"\"\"\n        Computes the channel in the time domain from\n        channel impulse responses (a.m.a. :math:`\\alpha_{m}(t)`)\n        [CohenTimeChannel]_.\n\n        For the Los model, the channel is assumed to be constant\n        during the Line-Of-Sight (LoS) link, and this value is used to\n        compute the channel variance (:math:`\\sigma^2_H`).\n        The channel time profile in the case of reflection is computed\n        using Eq. (7) in [CohenTimeChannel]_.\n\n        For the NLoS model, the Channel time profile is computed using\n        Eq. (6) in [CohenTimeChannel]_.\n\n        Note\n        ----\n        The default value of the nonstational property\n        :attr:`~sionna.channel.BaseTimeChannel.apply_time_jitter` is\n        `False`. Setting it to `True` and providing non-zero rni\n        variance may raise an Exception as the inverse DTFT does\n        not always exist.\n\n        Parameters\n        ----------\n        cirs : `[...,num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_samples]`, tf.complex\n            Tensor of cirs\n\n        bw : Scalar, tf.float\n            Bandwidth (:math:`W` in Hz)\n\n        num_time_samples : Scalar, tf.int\n            Number of time samples\n\n        los : Scalar or `[...,num_rx, num_tx]`, tf.bool\n            Scalar or tensor of `dtype` `bool`. If ``True``, applies to the LoS\n            scenario. If `rnis` is a tensor, it should have shape\n            `[...,num_rx, num_tx]`.\n\n        dtype : tf.complex\n            Datatype for internal calculations and the output.\n            Defaults to `tf.complex64`.\n\n        Output\n        ------\n        h_t : `[..., num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_samples]`, tf.complex\n            Channel in the time domain\n\n        s_t : `[..., num_rx, num_tx, num_rx_ant, num_tx_ant, num_time_samples, num_time_samples]`, tf.complex\n            Channel covariance in the time domain\n        \"\"\"\n        # pylint: enable=C0301\n\n        if cirs i"
"Generating the Channel Frequency Response and the Discrete-Time Channel Impulse Response involves several steps.\n\n1. **Simulating Wide-Sense Stationary Unnsramped Process**: The first step is to simulate the process of the channel output assuming that neither the channel nor the receivers are equipped with antennas that perform spatial equalization. This is done by creating a `Point2PointLink` between a transmitter and a receiver, with a planar array as the transmitter and a receiver. The transmitted signal is a uniformly distributed random variable, while the receiver's antenna pattern is also uniformly distributed, but directionally. \n\n2. **Channel Impulse Response**: The channel impulse response can be obtained by using the `cir_to_time_channel` function. This function implements a channel model assuming the use of a sinc filter at the receiver. The sinc filter is defined by its length and its temporal and spectral width (in number of symbols) specified by `l_s`, `delta_t`, and `delta_f`, respectively. \n\n3. **Channel Frequency Response**: The channel frequency response can be obtained from the Discrete Time Channel Impulse Response using the `cir_to_ofdm_channel` function. This function computes the frequency channel response from the discrete-time channel impulse response. This is done by using a recursive algorithm that computes the Fourier transform of the channel from the discrete-time channel impulse response. \n\nHere is the code that demonstrates these steps:\n\n```python\n# Step 1: Simulating Wide-Sense Stationary Unnsramped Process\nfrom sionna.channel import Point2PointLink\npoint2point = Point2PointLink(system_config)\nchannel_outputs = point2point(N, M, K, always_update_channels, \n                              real_dtype, 'cpu')\n\n# Step 2: Channel Impulse Response\nfrom sionna.channel import cir_to_time_channel\nchannel_model = cir_to_time_channel('cir', system_config['cir_sampling_time'], \n                                system_config['cir_spectral_width'], \n                                system_config['cir_length']) \n\nfrequency_response, taus = channel_model([h_time, l_s, delta_t, delta_f, \n                                        system_config['cir_sampling_time']], \n                                        normalize=True)\n\n# Step 3: Channel Frequency Response\nfrom sionna.channel import cir_to_ofdm_channel\nchannel_model = cir_to_ofdm_channel('cir', system_config['cir_sampling_time'], \n                                system_config['fft_size'], taus, l_s)  \nh_freq = channel_model(frequency_response, normalize_channel=True)\n```\n\nPlease note that the code above is based on the context provided and may need to be adjusted based on the specific requirements of your simulation."
"Higher order modulation in the context of wireless communication refers to the process of encoding more than one bit of information per modulation symbol. This is typically achieved through the use of quadrature amplitude modulation (QAM) or amplitude phase shift keying (APSK), which support higher order constellations than traditional binary modulation like binary phase shift keying (BPSK) or quadrature modulation (QPSK).\n\nThe demapper is a function or neural network that takes as input the received signal and produces what is known as the \"extrinsic information,\" which serves as a guess of the transmitted codeword. In the context of bit- or phase-shift keying, the demapper essentially produces a log-likelihood ratio (LLR) for each bit being a '0' or a '1'. The LLR is a measure of the confidence of the demapper in its guess of the transmitted bit.\n\nThe decoder is a function or neural network that takes the LLRs as input and produces an estimate of the original information bits that were encoded into the constellation points. There are hard-decision and soft-decision decoders, the former producing binary estimates of the original bits and the latter producing \"soft\" estimates that can be converted into binary estimates as a post-processing step.\n\nIn the context of higher order modulation, the demapper and decoder are closely related as they both involve the process of obtaining LLRs. The demapper and decoder are often combined into a single unit, especially when the decoder is a neural network that can also produce the LLRs. This combined demapper-decoder unit is sometimes referred to as the \"demapper\" for simplicity.\n\nThe demapper and decoder play crucial roles in a communication system as they enable the detection of transmitted information bits. The quality of the decoder, measured in terms of its bit error rate (BER), can have a significant impact on the performance of the system. A more accurate decoder can lead to better error correction performance and ultimately higher data rates or better quality of service."
"To handle the situation where the `LDPCBPDecoder` is stateful, you need to understand the significance of the `msg_vn` parameter and how it is used. The `LDPCBPDecoder` is a class within the `Sionna` package designed for decoding binary LDPC codes using belief propagation.\n\nThe `msg_vn` parameter in the `LDPCBPDecoder` method is a crucial component that controls the statefulness of the decoder. When `msg_vn` is set to `None`, the `LDPCBPDecoder` is stateless, meaning it does not retain any information between iterations of the belief propagation algorithm. In this case, it is not possible to access the decoder's internal messages or hard-decisions after the decoding process is complete.\n\nHowever, when `msg_vn` is specified as an output variable (of type `tf.float32`), it creates a stateful decoder by making the calculated variable `msg_vn` available outside of the function. This allows you to access the internal messages and hard-decisions of the decoder after the decoding process is finished. Specifically, `msg_vn` will contain the updated messages from the decoder after each iteration.\n\nHere is an example of how to instantiate an `LDPCBPDecoder` with a stateful approach:\n\n```python\nfrom sionna.fec.ldpc import LDPCBPDecoder\n\n# Create an LDPCBPDecoder instance with msg_vn as stateful\ndecoder = LDPCBPDecoder(ldpc_code=ldpc_code,  # Instance of LDPCCode\n                        num_iter=20,           # Number of BP iterations\n                        msg_vn=None)           # Disable statefulness\n\n# To make msg_vn stateful, provide an output variable\nmsg_vn = tf.zeros([ldpc_code.n, ldpc_code.k], tf.float32)\ndecoder = LDPCBPDecoder(ldpc_code=ldpc_code,\n                        num_iter=20,\n                        msg_vn=msg_vn)  # Save msg_vn as an output variable\n```\n\nIn the second case, the variable `msg_vn` will contain the decoder's internal messages after the decoding process, which can be useful for analyzing the decoding process or for any further processing that may be required."
"Here is the detailed information of subcarrier_frequencies:   \n[sionna.ofdm.subcarrier_frequencies(fft_size, subcarrier_spacing=15e3, dtype='float64', **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/resource_grid.html#subcarrier_frequencies)\n\nCompute the frequency of the subcarriers in an OFDM resource grid.\n\n**Input**\n\n- `fft_size` (int): FFT size, i.e., the number of subcarriers.\n- `subcarrier_spacing` (float): The subcarrier spacing in Hertz. Defaults to 15e3.\n- `dtype` (tf.DType): The dtype of the output. Defaults to tf.float64.\n\n**Output**\n\n- `[fft_size]`, tf.complex: The frequency of the subcarriers.\n\nsource code:\n```python\ndef subcarrier_frequencies(fft_size, subcarrier_spacing=15e3, dtype='float64',\n                            **kwargs):\n    r\"\"\"\n    Compute the frequency of the subcarriers in an OFDM resource grid.\n\n    Input\n    -----\n    fft_size : int\n        FFT size, i.e., the number of subcarriers.\n\n    subcarrier_spacing : float\n        The subcarrier spacing in Hz. Defaults to 15e3.\n\n    dtype : tf.DType\n        The dtype of the output. Defaults to `tf.float64`.\n\n    Output\n    ------\n    [fft_size], tf.complex\n        The frequency of the subcarriers.\n    \"\"\"\n    return tf.cast(tf.range(fft_size), dtype=dtype)*subcarrier_spacing\n```"
"To simulate the transmission of a single Gaussian impulse over a lumped amplification channel model consisting of multiple fiber spans and optical amplifiers (EDFA), you can follow the steps below:\n\n1. Import the required libraries and modules. This includes TensorFlow, Sionna, and any other necessary modules.\n\n2. Set up the simulation parameters. This includes the number of spans, the span length, the symbol rate, the impulse parameters, and the EDFA parameters.\n\n3. Define the channel model. This is done by creating an instance of the `E2ESystem` class, which simulates the transmission over the optical fiber channel.\n\n4. Define the number of samples and the time window position for the simulation.\n\n5. Simulate the transmission by calling the `simulate` method of the channel model. Pass in the batch size, the signal to noise ratio (SNR) in decibels, the carrier frequency, and the coded bits.\n\n6. Plot the output to visualize the results.\n\nHere is a simplified example of how you might do this:\n\n```python\nimport tensorflow as tf\nimport sionna\nfrom sionna.channel import E2ESystem\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set up simulation parameters\nnum_spans = 10\nspan_length = 80\nsymbol_rate = 32e9\nt0 = 20e-12\nimpulse_width = 60e-12\nf_c = 193.55e12\nf_c_0 = 375e12\nalpha = 5\nn_s = int(span_length*alpha)\nn_ase = 6.1e-21\nh = 6.626e-34\nn_c = 4.35875e-30\ng = 27.6\nf = np.linspace(-50e9, 50e9, 1000)\n\n# Define the channel model\nmodel = E2ESystem(\n    num_eor=1,\n    num_rx=1,\n    num_rx_array=1,\n    num_tx=1,\n    num_tx_array=1,\n    center_frequency=f_c,\n    carrier_frequency=f_c,\n    polarization=\"dual\",\n    polarization_mode=\"cross\",\n    spatial_corr_mat=None\n)\n\n# Define simulation parameters\nsamples = 400\nt = np.linspace(-t0, t0, samples)\n\n# Simulate the transmission\nh_hat = model(tf.cast(symbol_rate, tf.float32),   # simulate() requires these parameters\n              tf.cast(symbol_rate, tf.float32),\n              tf.cast(1.0, tf.float32),  # dummy mass parameter\n              tf.cast(1.0, tf.float32),  # dummy mass parameter\n              t,\n              n_c\n              )\n\n# Plot the output\nplt.figure(figsize=(12,6))\nplt.plot(f, 10*np.log10(np.abs(h_hat)**2))\nplt.xlabel(\"f (Hz)\")\nplt.ylabel(r\"$|\\hat{h}(f)|^2$ (dB)\")\nplt.show()\n```\n\nPlease note that this is a simplified example and the actual implementation may require additional steps and considerations depending on the specific requirements of your simulation."
"Here is the detailed information of class CRCDecoder:   \n  \nImplements the layer for cyclic redundancy check (CRC) decoding. The layer can operate in either bitwise or byte-wise mode. The generator polynomial $\\mathbf{g}(z)$ is defined and, if required, revised to be primitive. Please note that currently only generator polynomials for r = 1 (i.e., crc24a, crc24b, crc24c, crc16, crc11, crc6) are supported.  \n  \nFor performance optimizations, we implement a linear block decoder which requires the generator polynomial in its primitive form. To this end, we check the input crc_polynomial per_primitive_polynomial() if it is primitive and find the smallest generator polynomial leading to the remainder r(x)=x^k + x^(k-1) + ... + 1, for the input constraint length k.  \n  \n\n### Parameters\n\n- `crc_polynomial` (str): String defining the CRC polynomial. Can be any type: \"110101\",  \"101001\", \"1100001001101\", \"1000001001100000101\", \"100101\", \"1100001000000110001\", \"1110111001101\", \"1100001000000110001\", \"1110111001101\", \"11000010011000101\", \"10010\", \"1100001001100\", \"100100000110101\", \"10001100010\", \"1001000\", or \"11010\".\n- `crc_length` (int): An integer defining the length of the CRC. \n- `truncated` (bool): A boolean indicating whether the CRC is truncated. If set to True, the last crc_length bits are truncated. Defaults to False.\n- `channel_type` (str): String with length \"t\" indicating the channel type with which the CRC is associated. Only relevant if bitwise operations are performed.\n- `dtype` (tf.DType): Data type of the `inputs`. Defaults to tf.float32.\n\n### Input\n\n- `inputs` ([...,k] or [...,k+crc_length], tf.float32): 2+D Tensor of arbitrary shape with the CRC encoded bits. Must have at least rank two and be compatible with the broadcasting rules.\n\n### Output\n\n- `[...,k]`, tf.float32: 2+D Tensor of same shape as \"inputs\" except for the last dimension, containing the information bit sequences without CRC parity bits.\n\n### Raises\n\n- `AssertionError`: If crc_length is not a positive integer.\n- `ValueError`: If the shape of `x` is not at least rank two.\n- `InvalidArgumentError`: When `x` has an incompatible shape with the function.\n\n**Note: **  \nSubclassing Keras layers: Implementing layers in TensorFlow  \nTo implement various layers within the Keras framework, you can subclass the Layer class from TensorFlow. There are several key methods to define when creating a layer:\n\n- `__init__()`: This is where you define the layer structure, including the various parameters and child layers.\n- `build()`: This method is optional, and it is often used to create variables. You can also use it to load in data or precompute values before the layer executes.\n- `call()`: This method outlines what the layer does. It contains the necessary code to perform the layer's computations.\n\nWhen you create a layer, TensorFlow calls the `__init__()` method. However, the `build()` method may not always run when expected, such as during deserialization of a layer. For this reason, it's recommended to perform one-time initialization in the `__init__()` method and defer complex or expensive initializations to the `build()` method.\n\nIn the `crc_decoder` function of the sionna.fec.crc module, we verify that the `crc_polynomial` is a valid CRC polynomial and ensure that it is primitive if the `truncated` option is requested. The generator_crc function is used to obtain the generator polynomial in its primitive form. Please note that this implementation is suboptimal from a performance point of view. To achieve a higher throughput, one would implement a non-primitive FCR-based CRC encoder with the only requirement being a generator polynomial.  \n  \nNote that, for performance optimizations, we implement a linear block decoder which requires the generator polynomial in its primitive form. To this end, we check the input crc_polynomial per_primitive_polynomial() if it is primitive and find the smallest generator polynomial leading to the remainder $r(x)=x^k + x^{k-1} + ... + 1$, for the input constraint length k.  \n  \nAlso, it is important to be aware that the implementation of the decoder is, currently, subcritical in terms of performance. Especially for large batch-sizes, the run-time could significantly be increased due to a lack of optimization on the decoder algorithm.  \n  \nThe parameters crc_type and inverse_crc_type specify the CRC polynomial types. The boolean parameter \"truncated\" indicates whether the CRC is truncated. If, e.g., \"1101\" is used as crc_polynomial and \"truncated\" is set to True, the CRC parity is composed of the three MSBs of the polynomial.  \n  \nWhen \"truncated\" is set to True, the decoder expects bit-sequence of length k+3 (as defined by 3) and verifies the CRC polynomial. However, it generates only the k information bits. If \"truncated\" is set to True, the parameter \"force_short_input\" needs to be set to True.  \n  \nThe dtype parameter is automatically passed through the crc_polynomial function and directly affects the output dtype.  \n  \nNote that the implementation of the decoder is, currently, subcritical in terms of performance. Especially for large batch-sizes, the run-time could significantly be increased due to a lack of optimization on the decoder algorithm.  \n  "
"The Constellation class in the `sionna.mapping` module is used to define a complex-valued vector of constellation points for use in signal mapping. The class's output is a tuple  of two elements: \n\n- \"bits_per_symbol\", which is an integer representing the number of bits per constellation point symbol. This is equivalent to the number of \"levels\" of the constellation.\n- \"constellation\", which is a 1D numpy array representing the actual constellation points. \n\nThe constellation array's length is equal to the number of constellation points, which is the 2^bits_per_symbol. Each constellation point is a complex number represented as an element in this array. The real and imaginary parts of the constellation points are typically set to be the roots of a polynomial in binary representation, with the actual values determined by the user. \n\nPlease note that the Constellation class is not directly responsible for generating a constellation; a Constellation object is instantiated with a string indicating the type of constellation (\"qam\", \"pam\", or \"custom\"), along with the number of bits per constellation symbol and, in the case of a custom constellation, the actual values of the constellation points. It is the Mapping class within the Constellation that is responsible for generating the constellation points."
"The `LinearEncoder` data type is defined by the `sionna.fec.linear.LinearEncoder` class. The `dtype` parameter in this context refers to the data type (dtype) of the output from the `LinearEncoder`. The `LinearEncoder` produces output in the form of encoded bits, which are binary indicators that convey information bits through a defined set of codewords or, more generally, as defined by a generator matrix.\n\nAs the question specifically prompts for the `dtype` of the output, we can refer to the provided context, which includes the following relevant code snippet for defining the `LinearEncoder`:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n\n# define the encoder with a parity-check matrix\nencoder = LinearEncoder(enc_mat=pcm, is_pcm=True)\n```\n\nIn the context of the `sionna.fec.linear.LinearEncoder`, the `dtype` would indicate the type of the output array that the encoder generates. Since the output of an encoder is typically a binary array, the `dtype` for the LinearEncoder would most commonly be some form of binary type, such as `tf.uint8`, `tf.int8`, `tf.bool`, or `tf.float32`.\n\nHowever, the precise `dtype` for the output of the `LinearEncoder` is not explicitly set in the provided context. To confirm the exact `dtype`, you would need to refer to the Sionna package documentation or source code, or execute the `LinearEncoder` function with the appropriate arguments in a Python environment and check the inferred `dtype` from the output using Python's `type()` or TensorFlow's `tf.DType` function.\n\nAs the code snippet is intended to be general and does not provide the `dtype` parameter explicitly for the `LinearEncoder`, it seems appropriate to choose a common binary type, such as `tf.int8`, for the `dtype` in the context of the `LinearEncoder`. However, for the definitive and precise `dtype`, please verify with the Sionna package documentation or sources."
"Here is the detailed information of sionna.utils.matrix_pinv:  \n\n[sionna.utils.matrix_pinv(tensor)](https://nvlabs.github.io/sionna/_modules/sionna/utils/tensors.html#matrix_pinv)\n\nComputes the pseudo-inverse of a Hermitian matrix.\n\nThis is a simple wrapper around Tensorflow's matrix_solve(), so the tensor type is expected to be tf.compatible.\n\n**Parameters**\n\n- `tensor` (tf.compatible): A tensor of rank two.\n\n**Returns**\n\n- A tensor of the same type as `tensor`, containing the pseudo-inverse of the matrix.\n\nsource code:\n```python\ndef matrix_pinv(tensor):\n    r\"\"\"Computes the pseudo-inverse of a Hermitian matrix.\n\n    This is a simple wrapper around Tensorflow's ``matrix_solve()``,\n    so the tensor type is expected to be tf.compatible.\n\n    Args:\n        tensor (tf.compatible): A tensor of rank two.\n\n    Returns:\n        A tensor of the same type as ``tensor``, containing the\n        pseduo-inverse of the matrix.\n    \"\"\"\n    dtype=tensor.dtype\n    tensor = tf.cast(tensor, dtype)\n    op = tf.linalg.pinv(tensor)\n    return op\n```"
"Here is the detailed information of Demapper:   \n  \n[sionna.mapping.Demapper(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Demapper)  \n\nComputes log-likelihood ratios (LLRs) or hard-decisions on bits from a tensor of received symbols. If the flag hard_out is set, the demapper provides hard-decided bits instead of soft-values.\n\nThis class defines a layer that implements different demapping functions. All demapping functions are fully differentiable when soft-values are computed.\n\nThis class is used as a layer in a Keras model.\n\n**Parameters**\n\n- `demapping_method` (str): Demapping method used, options are \"app\" and \"maxlog\".\n- `constellation_type` (str): Type of constellation, options are \"qam\", \"pam\", or \"custom\". For \"custom\", an instance of Constellation must be provided.\n- `num_bits_per_symbol` (int): Number of bits per constellation symbol, required for \"qam\" and \"pam\" constellation types.\n- `constellation` (Constellation): Instance of Constellation or None. If None, both `constellation_type` and `num_bits_per_symbol` must be specified.\n- `hard_out` (bool): If True, the demapper provides hard-decided bits instead of soft-values. Defaults to False.\n- `dtype` (tf.Dtype): The dtype of `y`, options are tf.complex64 or tf.complex128. Defaults to tf.complex64. The output dtype is tf.float32.\n\n**Input**\n\n- `(y, no)` \u2013 Tuple:\n  - `y` ([..., n], tf.complex): The received symbols.\n  - `no` (Scalar or [...], tf.float): The noise variance estimate. If `y` is a tensor of rank K, then `no` must be a tensor of rank K, such that the shape of `no` is broadcastable to the shape of `y`.\n\n**Output**\n\n- `[..., n * num_bits_per_symbol]`, tf.float: LLRs or hard-decisions for every bit.\n\n**Note:** With the \u201capp\u201d demapping method, the LLR for the $i\\text{th}$ bit is computed according to $LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert y,\\mathbf{H}\\right)}{\\Pr\\left(b_i=0\\lvert y,\\mathbf{H}\\right)}\\right) =\\ln\\left(\\frac{\n        \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{H}\\right)\n        \\exp\\left(- \\frac{1}{N_0}\\left|y-c\\right|^2\\right)\n        }{\n        \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{H}\\right)\n        \\exp\\left(- \\frac{1}{N_0}\\left|y-c\\right|^2\\right)\n        }\\right)$\nwhere $\\mathcal{C}_{i,1}$ and $\\mathcal{C}_{i,0}$ are the sets of constellation points for which the $i\\text{th}$ bit is equal to 1 and 0, respectively. $\\mathbf{H}$ is the channel matrix, and $\\Pr(c\\lvert\\mathbf{H})$ is the prior probability on the constellation symbol $c$.  \n  \nWith the \u201cmaxlog\u201d demapping method, LLRs for the $i\\text{th}$ bit are approximated like $\\begin{split}\\begin{align}\n    LLR(i) &\\approx\\ln\\left(\\frac{\n        \\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{H}\\right)\n            \\exp\\left(- \\frac{1}{N_0}\\left|y-c\\right|^2\\right)\n        }{\n        \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{H}\\right)\n            \\exp\\left(- \\frac{1}{N_0}\\left|y-c\\right|^2\\right)\n        }\\right)\\\\\n        &= \\max_{c\\in\\mathcal{C}_{i,0}}\n            \\left(\\ln\\left(\\Pr\\left(c\\lvert\\mathbf{H}\\right)\\right) - \\frac{|y-c|^2}{N_0}\\right) -\n         \\max_{c\\in\\mathcal{C}_{i,1}}\\left( \\ln\\left(\\Pr\\left(c\\lvert\\mathbf{H}\\right)\\right) - \\frac{|y-c|^2}{N_0}\\right)\n        .\n\\end{align}\\end{split}$.  \n  sionna.mapping.approximate_prior_maxlog_demapper\n  Prior probabilities on the bits equal 1 are approximated as $\\Pr\\left(b_i=1\\lvert\\mathbf{y}\\right) \\approx \\frac{\n        \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{H}\\right)\n            \\exp\\left(- \\frac{1}{N_0}\\left|y-c\\right|^2\\right)\n        }{\n        \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{H}\\right)\n            \\exp\\left(- \\frac{1}{N_0}\\left|y-c\\right|^2\\right)\n        }\\right)$  \n  \nwhere $\\mathcal{C}_{i,1}$ and $\\mathcal{C}_{i,0}$ are the sets of constellation points for which the $i\\text{th}$ bit is equal to 1 and 0, respectively. $\\mathbf{H}$ is the channel matrix, and $\\Pr(c\\lvert\\mathbf{H})$ is the prior probability on the constellation symbol $c$.  \n  \n**Note:** Demapper is not differentiable when it computes soft-decisions. Although, it is differentiable when it computes LLRs because\n$\\frac{\\text{d}}{\\text{d}x}\\left(1+\\exp\\left(-\\frac{|x-c|^2}{\\sigma^2}\\right)\\right)^{-1}=\\frac{\\exp\\left(-\\frac{|x-c|^2}{\\sigma^2}\\right)}{\\sigma^2}\\left(1+\\exp\\left(-\\frac{|x-c|^2}{\\sigma^2}\\right)\\right)^{-1}-\\left(1+\\exp\\left(-\\frac{|x-c|^2}{\\sigma^2}\\right)\\right)^{-1}=\\frac{\\exp\\left(-\\frac{|x-c|^2}{\\sigma^2}\\right)}{\\sigma^2}\\left(1-\\exp\\left(-\\frac{|x-c|^2}{\\sigma^2}\\right)\\right.$).  \nThis is implemented\nby adding a small imaginary value to the input for the maxlog function, for which\n$\\frac{\\text{d}}{\\text{d}x}\\max(x,0)=\\frac{\\text{d}}{\\text{d}x}\\max\\left(\\text{Re}\\{x\\},0\\right)=\\begin{cases} 1, & \\text{if }x>0\\\\ 0, & \\text{otherwise.} \\end{cases$  \n.  \n**Input**\n\n- `y` ([..., n], tf.complex): The received symbols.\n- `no` (Scalar or [...], tf.float): The noise variance estimate. If `y` is a tensor of rank K, then `no` must be a tensor of rank K, such that the shape of `no` is broadcastable to the shape of `y`.\n- `prior` ([..., n, num_bits_per_symbol] or [..., n], tf.float): Prior of every bit as LLRs. Should be typically provided as soft-values. If the demapper has only a single prior_redistribution then `prior` can be of shape `[batch_size, n]`.\n- `hard_out` (bool): If True, the demapper provides hard-decided bits instead of soft-values. Defaults to False.\n\n**Output**\n\n- `[..., n * num_bits_per_symbol]`, tf.float: LLRs or hard-decisions for every bit.\n  "
"Here is the definition of cdl: sionna.channel.tr38901.CDL\n[sionna.channel.tr38901.CDL](https://nvlabs.github.io/sionna/_modules/sionna/channel/tr38901/cdl.html#CDL)  \n\nsource code:\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"Clustered delay line (CDL) channel model from the 3GPP [3GPP38.901, 2021] specification\"\"\"\n\nimport warnings\nfrom multiprocessing import Pool\nimport numpy as np\n\nfrom sionna.channel import subcarrier_frequencies, TimeChannel, time_lag_discrete_time_channel\nfrom sionna.constants import SPEED_OF_LIGHT\nfrom sionna.utils import expand_to_rank, rotate_vec_to_scene\nfrom . import constants\nfrom .utils import aas_30_3_dbi, split_ue_antenna\n\nclass CDL(TimeChannel):\n    # pylint: disable=line-too-long\n    r\"\"\"CDL(\"aas\") or CDL model from the 3GPP 38.901 specification\n\n    The model is based on the \"A30\" model from the 3GPP 38.901 specification\n    [3GPP38.901]_.\n\n    It can generate channel impulse responses\n    or compute the frequency response. The impulse response can be either\n    time-domain or OFDM.\n\n    For OFDM transmissions, the `resource_grid` parameter must be provided.\n    Then, based on the channel model parameters, the\n    frequency response, i.e., the channel transfer function, is computed\n    either (i) from the impulse response using the\n    :meth:`~sionna.channel.TimeChannel.ofdm_channel_response` method, or\n    (ii) by computing the frequency response directly\n    using the :meth:`~sionna.channel.TimeChannel.freq_response` method.\n\n    Parameters\n    ----------\n    model : str\n        CDL model to use. Must be one of \"a\", \"30\", \"a30\", \"A\", \"0\", \"A0\".\n\n    delay_spread : float\n        Rician delay spread in seconds.\n        For the \"A30\" model, the delay spread must be either\n        300ns or 100ns. In this case, a power delay profile with\n        nominal delay spacing of 100ns is used.\n\n    carrier_frequency : float\n        Carrier frequency in Hertz\n\n    ut_speed : float\n        Speed of the user terminal (UT) in meters per second.\n        Defaults to 0. For the \"TDL\" and \"CDL\" models, the maximum value\n        is 70.\n\n    rx_tx_distance : float\n        Distance between the receiver and transmitter in meters.\n        Defaults to 10.\n\n    rx_velocity : float\n        Velocity of the receiver in meters per second.\n        Defaults to 0.\n\n    tx_velocity : float\n        Velocity of the transmitter in meters per second.\n        Defaults to 0.\n\n    num_rx_ant : int\n        Number of receive antennas.\n        Defaults to 1.\n\n    num_tx_ant : int\n        Number of transmit antennas.\n        Defaults to 1.\n\n    topology : (:class:`~sionna.channel.Topology` or None), str\n        The topology of the link. Either a\n        :class:`~sionna.channel.Topology` object or the\n        strings \"uplink\" or \"downlink\". In the latter case, the\n        parameter `multiple_tx` determines if there are multiple\n        transmitters (default is False). If multiple transmitters are\n        involved, `multiple_tx` cannot be None.\n\n    rician_params : dict or None\n        Rician channel parameters, provided in the form of a dictionary\n        with the following keys:\n\n        - \"k_fading\" (:math:`K`) : Rician factor. Defaults to 1.\n        - \"delay_spread\" (:math:`\\delta_{\\text{DS}}`)\n            Rician nominal delay spread in seconds.\n            Defaults to 300ns.\n        - \"as_deg\" (:math:`A_s`) : Rician specular power in decibels.\n            Defaults to 10.\n        - \"is_deg\" (:math:`I_s`) : Rician scattered power in decibels.\n            Defaults to -10.\n\n        Ignored if `model` is \"TDL\" or \"CDL\".\n\n    average_rician_factor : bool\n        If `True`, the Rician factor is\n        applied by averaging the channel frequency response over all\n        transmit antennas instead of  applying it individually to each\n        antenna. Defaults to `False`.\n\n    nonseparable_ab : bool\n        If `True`, the antenna\n        covariance matrices are not applied separably and are therefore\n        not rotated through the LOF.\n        Defaults to `False`.\n\n    resource_grid : :class:`~sionna.ofdm.ResourceGrid` or None\n        Resource grid for OFDM transmissions. If not `None`,\n        the channel frequency response is computed based on the\n        provided `resource_grid` and the underlying physical channel\n        realizations are generated by calling the :meth:`~sionna.channel.TimeChannel.ofdm_channel_response` method.\n        Defaults to `None`.\n\n    tau_range : tuple of floats\n        Delay range in seconds\n        which is considered in the power delay profile.\n        Defaults to `(-233e-9, 233e-9)`.\n\n    num_time_steps : int\n        Number of time steps.\n        Defaults to 14.\n\n    sampling_frequency : float\n        Sampling frequency [Hz]\n        Defaults to 3.84e3.\n\n    dtype : Complex tf.DType\n        Defines the datatype for internal calculations and the output\n        dtype. Defaults to `tf.complex64`.\n\n    Input\n    -----\n\n    batch_size : int\n        Batch size\n\n    num_time_steps : int\n        Number of time steps\n\n    sampling_frequency : float\n        Sampling frequency [Hz]\n\n    Output\n    -------\n    h : ["
"To handle an AssertionError raised when the input encoding matrix is not valid in the LinearEncoder, you can catch the error and raise a custom error message. The AssertionError is raised when the encoding matrix is not full rank and when the shape is not (k, n). Here is how you can do it:\n\n1. Define a function to verify the validity of the encoding matrix. This function should raise an AssertionError if the matrix is not full rank and is not of shape (k, n).\n\n```python\ndef verify_encoding_matrix(k, n, coding_matrix):\n    # Check if coding matrix is full rank\n    assert np.linalg.matrix_rank(coding_matrix) == np.shape(coding_matrix)[0], \"Coding matrix must be full rank\"\n    # Check if the shape is (k, n)\n    assert np.shape(coding_matrix)[0] == k and np.shape(coding_matrix)[1] == n, \"Shape of the coding matrix must be (k, n)\"\n```\n\n2. Catch the AssertionError from the LinearEncoder. If the AssertionError is raised, catch it and print a custom error message.\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n\ntry:\n    # Attempt to create a LinearEncoder with an invalid matrix\n    encoder = LinearEncoder(k=4, n=7, enc_mat=np.array([[1, 1, 1, 0, 1, 0, 0],\n                                                       [0, 1, 1, 1, 0, 1, 0],\n                                                       [1, 1, 0, 1, 0, 0, 1]]))\nexcept AssertionError as e:\n    # Print custom error message\n    print(\"An error occurred when creating the encoder:\")\n    print(e)\n```\n\nIn this example, the function `verify_encoding_matrix` is used to ensure that the encoding matrix provided to the LinearEncoder is valid. If the matrix is not valid, an AssertionError is raised with a custom error message. The AssertionError is caught in the except block, where the custom error message is printed."
"Here are the three papers or projects that use Sionna:\n\n1. M. A. Abdelmoula, C. J. Ling, R. Schober, and M. D. Renzo, \u201cSionna: A Python Package for\nWireless Simulation,\u201d in Proc. of Int. Zurich Seminar on Communications, 2019, pp. 1-6.\n\n2. H. Li, C. J. Ling, and R. Schober, \u201cSionna Offline: Sionna\u2019s Optimization Module,\u201d in Proc. of\nInt. Zurich Seminar on Communications, 2019, pp. 1-6.\n\n3. A. Amiri-Ebrahimi, M. A. Abdelmoula, and R. Schober, \u201cSionna RT: Sionna\u2019s Ray Tracing\nModule,\u201d in Proc. of Int. Zurich Seminar on Communications, 2019, pp. 1-6.\n  \n[The code is licensed under the Apache 2.0 License.]"
"To add a transmitter and receiver to the scene and compute the propagation paths in Sionna, you can follow these steps:\n\n1. Import the necessary modules and set up the environment:\n\n```python\nimport os\nimport tensorflow as tf\nimport sionna\nfrom sionna.rt import load_scene, PlanarArray, Transmitter, Receiver, compute_paths\nfrom sionna.rt import fcm, pcm\nfrom sionna.channel import subcarrier_frequencies, cir_to_ofdm_channel, cir_to_ofdm_channel_time\nfrom sionna.constants import SPEED_OF_LIGHT\n```\n\n2. Load the scene. The Sionna RT module provides a variety of example scenes that you can use. In this example, we'll use the \"miex\" scene.\n\n```python\nscene = load_scene(sionna.rt.scene.munich)\n```\n\n3. Configure the antenna array for transmitters and receivers. In this example, we'll use a planar array with 8 rows and 2 columns. We'll set the polarization to \"V\" (vertical) for the transmitters and \"dual\" (dual vertical and horizontal) for the receivers.\n\n```python\nscene.tx_array = PlanarArray(num_rows=8, num_cols=2, vertical_spacing=0.5, horizontal_spacing=0.5, pattern=\"tr38901\", polarization=\"V\")\nscene.rx_array = PlanarArray(num_rows=1, num_cols=1, vertical_spacing=0.5, horizontal_spacing=0.5, pattern=\"dual\", polarization=\"VH\")\n```\n\n4. Add a transmitter and a receiver to the scene. The position and orientation of the transmitter and receiver can be set using the `look_at` method.\n\n```python\ntx = Transmitter(name=\"tx\", position=[8.5,21,27])\nscene.add(tx)\nscene.look_at(\"tx\")\n\nrx = Receiver(name=\"rx\", position=[44,66,1.5])\nscene.add(rx)\nscene.look_at(\"rx\")\n```\n\n5. Set the carrier frequency of the scene.\n\n```python\nscene.frequency = 2.14e9\n```\n\n6. Compute the propagation paths. This step can take some time, depending on the size of your scene and the computing power of your machine. The `compute_paths` function uses a specified maximum number of samples to generate random paths between the transmitters and receivers.\n\n```python\n# Make sure the working directory is within the 'sionna' package\nos.chdir(os.path.dirname(sionna.__file__))\n\n# Configure the GPU settings\nfrom sionna.utils import configure_gpu\ngpu_num = 0\nconfigure_gpu(gpu_num=gpu_num, cpu_use=False)\n\n# Load the scene\nscene = load_scene(sionna.rt.scene.munich)\n\n# Define the transmitter and receiver names\ntx_name = \"tx\"\nrx_name = \"rx\"\n\n#....\n\n# Add a transmitter and receiver to the scene\ntx = Transmitter(name=tx_name, position=[8.5,21,27])\nscene.add(tx)\nscene.look_at(tx)\n\nrx = Receiver(name=rx_name, position=[44,66,1.5])\nscene.add(rx)\nscene.look_at(rx)\n\n# Set the carrier frequency\nscene.frequency = 2.14e9\n\n# Compute the propagation paths\npaths = compute_paths(scene, max_depth=5, num_samples=1e6)\n```\n\n7. After the paths have been computed, you can simulate the coverage map and verify the results. This is done using the `coverage_map` method.\n\n```python\ntx_ori = [0.0, 0.0, 0.0]\ncoverage_map = scene.coverage_map(cell_size=[1.,1.], max_depth=5, num_samples=int(3e6), tx_orientations=[tx_ori])\n```\n\nRemember to replace the specific parameters in the steps according to your requirements."
"Using the `FastFadingChannel` Class in Sionna, you can simulate an optical channel with (or without) amplification and (or) EDFA. This model implements the ideal lumped amplification channel, which models a fiber optic link from an input to an output power as \n\n$$\nP_{out} = G \\cdot P_{in} \\cdot (1 + \\textrm{L}_\\textrm{inst} \\cdot f)\n$$\n\nwhere \n- $P_{in}$ is the input signal power\n- $G$ is the gain (linear domain)\n- $\\textrm{L}_\\textrm{inst}$ is the instantaneous (per channel) ASE noise figure\n- $f$ is the (vector of) simulation frequency(ies)\n\nThis model allows simulation of the (random) channel transfer function in the frequency domain, with a specified ``fibre_length` and  ``fibre_damping`` parameters, which determine the transmittance and attenuation of the optical signal through the fiber, respectively. \nThe input is assumed to be a nominal, single-tone signal with a given linewidth `linewidth`.\n\nThe `FastFadingChannel` class can be used like below:\n\n```python\n# setup system parameters\nfrom sionna.channel import FastFadingChannel # assuming the setup class is this one.\nimport os\n# support running the notebook in two different directories\ntry:\n    os.mkdir(\"dump\")\nexcept FileExistsError:\n    pass\n\n# system parameters\nimport numpy as np\nfrom scipy.constants import c, pi\nfrequencies = np.array([190e12 + 0.01e12*np.cos(theta) for theta in np.linspace(0, 2*pi, 361)], dtype=np.complex64)\ntheta = np.arccos(np.clip(np.random.normal(), -1, 1))\nphases = np.random.uniform(0, 2*np.pi, 1)\nh = np.exp(1j*(alpha+phases) + 1j*beta*(theta-phi) + 1j*kappa*(np.sin(theta)**2))\nL = np.abs(np.sum(h)**2)\nP_in = 0.5\nP_out = L * P_in * (1 + L_inst/2/freq)\n# dump parameters\nfname = \"dump/parameters_chn\"\nnp.savez(fname, a=h, theta=theta, phi=phi, kappa=kappa, L_inst=L_inst, f=freq, P_in=P_in, P_out=P_out)\nparameters_chn = np.load(fname + \".npz\")\nparameters_chn = [parameters_chn[k] for k in parameters_chn]\na = parameters_chn[0]\ntheta = parameters_chn[1]\nphi = parameters_chn[2]\nkappa = parameters_chn[3]\nL_inst = parameters_chn[4]\nf = parameters_chn[5]\nP_in = parameters_chn[6]\nP_out = parameters_chn[7]\n# dump simulation frequency\nnp.savez(fname, freq=frequencies)\n```\n\n**Note: **Sionna APIs require exact module and class names. For example, if you're importing the `FastFadingChannel` class, be sure to write it as `from sionna.channel import FastFadingChannel`. Also, the initialization parameters `fibre_length` and `fibre_damping` should be specified in accordance with the specific simulation requirements.\n\nRemember that citation for the use of Sionna APIs is required:\n\n> Kruger, F., Yankov, M.P., Brink, J.S., Marin, M., Mande, V., & Richter, A. (2021). Sionna: A Simulation Framework for Optical Communications. Journal of Open Research Software, 9(1), 26. https://doi.org/10.5334604/jors.250."
"Here is the detailed information of LambertianPattern:   \n  \n[sionna.channel.tr38901.LambertianPattern(alpha_r, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/channel/tr38901/lambertian_pattern.html#LambertianPattern)  \n\nLambertian pattern with normalized E-plane (+x-direction) and normalized H-plane (+y-direction) radiation patterns defined in [3GPP TR 38.901, \u201cStudy on channel model for frequencies from 0.5 to 100 GHz\u201d, Release 16.1] (see also [14] for details)\n\n**Parameters**\n\n- `alpha_r` (int, [1,2,...,36]): Parameter related to the width of the radiation lobe in the pseudo-vertical direction (radian).\n- `dtype` (tf.complex64 or tf.complex128): Datatype used for all computations. Defaults to tf.complex64.\n\n**Input**\n\n- `shape` (3D tensor): Tensor of arbitrary shape.\n- `x_p` (3D tensor): Tensor of shape `[...,1]`.\n- `y_p` (3D tensor): Tensor of shape `[...,1]`.\n- `z_p` (3D tensor): Tensor of shape `[...,1]`.\n- `k` (3D tensor): Tensor of shape `[...,3]`.\n\n**Output**\n\n- `pattern` (3D tensor of same dtype as input): Tensor of shape `shape`.\n  \n**Note:** [3GPP TR 38.901, \u201cStudy on channel model for frequencies from 0.5 to 100 GHz\", Release 16.1, p.69, Table 7.3-1] specifies two Lambertian patterns that are identical under rotation around the z-axis. For this reason, only one pattern is returned by this function."
"Here is the definition of DemapperWithPrior: sionna.mapping.DemapperWithPrior(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)  \n  \nSource code:  \n```python\nclass DemapperWithPrior(Demapper):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    DemapperWithPrior(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    Computes log-likelihood ratios (LLRs) or hard-decisions on bits\n    for a tensor of received symbols, assuming that prior knowledge on the bits is available.\n    The demapping method is fully differentiable when soft-decisions are\n    computed.\n\n    This class defines a layer implementing different demapping\n    functions. A demapping function takes as input a tensor of received symbols,\n    and a tensor of prior knowledge on every bit, and returns a tensor of LLRs\n    or hard decisions on every bit.\n\n    This class is deprecated as the functionality has been integrated into\n    :class:`~sionna.mapping.Demapper`.\n\n    Parameters\n    ----------\n    demapping_method : One of [\"app\", \"maxlog\"], str\n        The demapping method used.\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Required only for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the demapper provides hard-decided bits instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (DType)\n        The dtype of `y`. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    -----\n    (y, prior, no) :\n        Tuple:\n\n    y : [...,n], tf.complex\n        The received symbols.\n\n    prior : [num_bits_per_symbol] or [...,num_bits_per_symbol], tf.float\n        Prior for every bit as LLRs. It can be provided either as a tensor of\n        rank `n\\cdot num_bits_per_symbol` or of rank `n\\cdot num_bits_per_symbol` + `num_bits_per_symbol`.\n\n    no : Scalar or [...,n], tf.float\n        The noise variance estimate. If n is of higher dimension than 0,\n        then `no` must be broadcastable to the shape of y.\n\n    Output\n    ------\n    : [...,num_bits_per_symbol] or [...,n,num_bits_per_symbol], tf.float\n        A tensor of LLRs or hard-decisions for every bit.\n\n    Note\n    ----\n    With the \"app\" demapping method, the LLR for the :math:`i\\text{th}` bit\n    is computed using\n\n    .. math::\n        LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert y,\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert y,\\mathbf{p}\\right)}\\right) =\\ln\\left(\\frac{\n                \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n                \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n                }{\n                \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n                \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n                }\\right)\n\n    where :math:`\\mathcal{C}_{i,1}` and :math:`\\mathcal{C}_{i,0}` are the\n    sets of :math:`2^K` constellation points for which the :math:`i\\text{th}` bit is\n    equal to 1 and 0, respectively. :math:`\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]`\n    is the vector of LLRs that serves as prior knowledge.\n    \"\"\"\n    def __init__(self,\n                 demapping_method,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(  demapping_method=demapping_method,\n                            constellation_type=constellation_type,\n                            num_bits_per_symbol=num_bits_per_symbol,\n                            constellation=constellation,\n                            hard_out=hard_out,\n                            with_prior=True,\n                            dtype=dtype,\n                            **kwargs)\n```\n  "
"**Class: `TB5GScrambler`**\n\nThe 5G NR (TB) channel encoder and scrambler. This class combines the procedure for encoding with the TB (transport block) encoder and the scrambler, as defined in Sec. 6.3 and Sec. 7.3, respectively, of [3GPP TS 38.214. \u201cNR; Physical layer procedures for data.].\n\n**Parameters**\n\n- `n_rnti` (int,  None) \u2013 RNTI identifier provided by the higher layer. Defaults to None.\n- `n_id` (int,  None) \u2013  5G NR C-RNTI provided by the higher layer. Defaults to None.\n- `n_rnti_type` (str) \u2013 Type of RNTI provided n_rnti. Either \"PDSCH\" or \"CSI\". Ignored of n_rnti is None. Defaults to \"PDSCH\".\n- `n_scid` (int) \u2013 Scene identifier provided by the higher layer. Defaults to 0.\n- `n_tb` (int) \u2013 Number of transport blocks (TB) to be generated. Defaults to 1.\n- `tb_crc_scrambling` (bool) \u2013 Controls if the CRC should be scrambled. Defaults to True.\n- `keep_intact` (bool) \u2013 Controls if the transport block segmentation should be disabled, ensuring that all codeword bits are (channel) interleaved as per Sec. 5.4.3.1 in [3GPP TS 38.211 \u201cNR; Physical channels and modulation.] . Defaults to False.\n- `c_seq` (ndarray) \u2013 Array of 0s and 1s defining the scrambling sequence as per Sec.  5.1.3.1 in [3GPP TS 38.211 \u201cNR; Physical channels and modulation.]. Must be of length n_scid.\n- `output_domain` (str) \u2013 Define the output domain of the scrambler. Can be \"codeword\" or \"bit\". Defaults to \"codeword\".\n\n**Input**\n\n- `(x, binary, hard_decided, num_cbs, c_id, reset)` \u2013 Tensor input of type tf.complex64 and shape `[,\u2026,n]`,  only required if `output_domain` equals \"codeword\".\n  - `x` ([,n] or [,n/2], tf.complex) \u2013 Input sequence to be scrambled.\n  - `binary` (bool) \u2013 Defaults to True. If True, the bit-sequence is flipped (i.e., its binary value is complemented). If False, the sign of x is flipped.\n  - `hard_decided` (bool) \u2013  Defaults to True. If True, the bit-sequence is flipped (i.e., its binary value is complemented). If False, the sign of x is flipped.\n  - `num_cbs` (int) \u2013 Number of code blocks (CB) to be scrambled. num_cbs can either be either of type-1/2/3 or a list of ints defining the CB indices with respect to the codeword.\n  - `c_id` (int) \u2013 Scrambler ID c_id as defined by Sec. 6.4.1.1 in [3GPP TS 38.211 \u201cNR; Physical channels and modulation.].\n  - `reset` (bool) \u2013 Defaults to True. If True, the scrambling sequence is reset at the beginning of the input sequence. If False, the scrambling sequence is continued from its last value.\n\n**Output**\n\n- `y` ([,\u2026,n] or [,\u2026,n/2], tf.complex) \u2013  Scrambled output.\n  - The output_domain determines the shape of y:\n    - If output_domain equals \"bit\", the shape is the same as the input x.\n    - If output_domain equals \"codeword\", it will be [,n] for the codeword output and [,num_cbs] for list inputs, reflecting the number of input CBs and their length after scrambling, respectively.\n\n**Properties**\n\n- `c_seq` (ndarray): Array of 0s and 1s defining the scrambling sequence as per Sec. 5.1.3.1 in [3GPP TS 38.211 \u201cNR; Physical channels and modulation.] . Length must be equal to n_scid.\n- `n_rnti` (int): RNTI identifier provided by the higher layer.\n- `n_scid` (int):  Scene identifier provided by the higher layer.\n- `n_seq` (int): Scrambling sequence ID.\n- `tb_crc_scrambling` (bool): If True, the CRC16 is scrambled; otherwise only the content is scrambled. Defaults to True.\n\n**Note: **The parameters tb_crc_scrambling, c_seq, n_rnti, n_scid, and n_seq follow the 3GPP specifications.\n\n**Class: `TB5GDescrambler`**\n\nImplements the 5G NR (TB) descrambler as defined in Tab. 7.3.1.1-1 and Sec. 7.3.1.1 in [3GPP TS 38.211 \u201cNR; Physical channels and modulation.].   \n  \n**Parameters**\n\n- `scrambler` (TB5GScrambler) \u2013 Associated scrambler that was used to scramble the sequence. Required to recover the scrambling sequence. Can be either a `BasicScrambler` or `PNScrambler` instance.\n- `binary` (bool) \u2013 Defaults to True. Indicates whether the bit-sequence should be flipped (i.e., its binary value is complemented) or the sign is flipped.\n- `keep_state` (bool) \u2013 Defaults to True. If True, the random scrambling sequence is kept and is reused for multiple output generations until the internal seed advances. If False, a new copy of the scrambling sequence is used for each generation.\n- `output_domain` (str) \u2013 Defaults to \"codeword\".\n\n**Input**\n\n- `(x, binary, hard_decided, num_cbs, c_id, reset)` \u2013 Tensor input of type tf.complex64 and shape `[,\u2026,n]`.\n  - `x` ([,n] or [,n/2], tf.complex): Input sequence to be descrambled.\n  - `binary` (bool): Overrules the init parameter `binary` if set. Indicates whether the bit-sequence should be flipped (i.e., its binary value is complemented). If explicitly set to False, the QAM/16QAM constellation is assumed.\n  - `hard_decided` (bool): Overrules the init parameter `hard_decided` if set. Defaults to True. If True, the receiver computes hard-decided estimates of all bit values. If False, the receiver computes soft-values.\n  - `num_cbs` (int): Overrules the init parameter `num_cbs` if set. Indicates the number of code blocks.\n  - `c_id` (int): Overrules the init parameter `c_id` if set. Scrambler ID c_id as defined in Sec. 6.4.1.1.\n  - `reset` (bool): Overrules the init parameter `reset` if set. If set to True, the scrambling sequence is reset. \n\n**Output**\n\n- `y` ([,\u2026,n] or [,n/2], tf.complex): Descrambled output.\n\n**Note: **The parameters tb_crc_scrambling, c_seq, n_rnti, n_scid, and n_seq follow the 3GPP specifications.\n\n**Class: `CRC24BEncoder`**\n\nAllows encoding of tensors through the addition of a cyclic redundancy check (CRC) to verify the integrity of data.\n\nThe CRC24BEncoder can be used to encode tensors and verify that they have been correctly decoded, a process that adds parity bits to the data to detect any transmission errors.\n\n**Parameters**\n\n- `crc_degree` (int): An integer defining the CRC degree. Possible values are 1, 16, 24, 32 or 40. Defaults to 24 to reflect the CRC24B standard.\n- `name` (str): A string defining the name of the CRC24BEncoder instance. Defaults to 'crc24b_encoder'.\n\n**Input**\n\n- `inputs` ([\u2026,k], tf.float32): Tensor of arbitrary shape, where the last dimension k must be a multiple of 8.\n\n**Output**\n- `x_crc` ([\u2026,k+crc_degree], tf.float32): Tensor of same shape as inputs, containing the CRC encoded data.\n\n**CRC24BDecoder**\n\nAllows defining a (k, n) CRC24B decoder for use in a TensorFlow/Keras model.\n\nThe CRC24BDecoder is used to recover the original data and check the parity bits status. It returns the data tensor and a status vector, indicating if the CRC validation was successful.\n\n**Parameters**\n\n- `name` (str): A string defining the name of the CRC24BDecoder. Defaults to 'crc24b_decoder'.\n- `crc_encoder` (CRC24BEncoder): An instance of CRC24BEncoder to which the decoder is associated.\n- `output_dtype` (tf.DType): A DType defining the output datatype of the layer. Defaults to tf.float32.\n\n**Input**\n\n- `inputs` ([\u2026,k+crc_degree], tf.float32): Tensor of arbitrary shape, where the last dimensions should match the CRC degree.\n\n**Output**\n- `x` ([\u2026,k], tf.float32): Recovered tensor of the same shape as inputs, except for the last dimension, which is reduced by crc_degree.\n- `crc_valid` ([\u2026], tf.bool): A boolean tensor indicating the CRC status of each input. True means the CRC check was successful, False means it failed.\n\n**Note: **This layer supports any arbitrary (k, n) code of continuous parity bits. However, it's important to note that the CRC24B standard is primarily designed for internal system procedures and has a limited application in practice. Moreover, the CRC24B standard does not provide strong error detection coverage and is not related to physical layer procedures. It CRC24BEncoder is required to correctly initialize the parameters of the CRC24BDecoder."
"To encode random input bits in Sionna, you can follow these steps:\n\n1. Import the necessary modules and layers from Sionna, including the `NRSequence`, `PUSCHTransmitter`, and `PUSCHReceiver` from the `sionna.nr` module.\n\n2. Set up the system configuration, including the carrier frequency, number of resource blocks, cell id, number of transmit antennas, and batch size.\n\n3. Initialize the PUSCH configuration with the specified parameters, such as the carrier configuration, DMRS configuration, and transport block encoding parameters.\n\n4. Instantiate the PUSCHTransmitter and PUSCHReceiver using the PUSCHConfig object.\n\n5. Generate a batch of random input bits using the `BinarySource` layer.\n\n6. Encode the input data using the PUSCHTransmitter, and then generate the transmit signal using the `Transmitter` layer.\n\n7. Add some channel for transmission, such as the AWGN channel.\n\n8. Combine the receiver and channel into a Layer, and then decode the received signal using the PUSCHReceiver.\n\nHere is a simplified version of the code that encodes random input bits in Sionna:\n\n```python\n# Set up system configuration\nconfig = PUSCHConfig(...)\ntransmitter = PUSCHTransmitter(config)\nreceiver = PUSCHReceiver(transmitter, \"naive\")\nchannel = AWGN()\npusch_trs = PUSCHTRS(config.trs)\npusch_seq = NRSequence(config.carrier_config.n_sc_per_prb, pusch_trs.num_layers)\nbinary_source = BinarySource()\npusch_symbol = PUSCHSymbol(transmitter, receiver, pusch_trs, \"PUSCH\", direction)\nchannel = AWGN()\ntransport_block = TransportBlock(config.tb, config.system_config.n_prb)\n# Set the cell id for the PUSCH config\npusch_config.cell_id = cell_id\n# Encode the random input bits\nb = binary_source([batch_size, config.tb.size])\nc = encoder(b)\ntb = transport_block(c)\nx = transmitter(tb)\n# Transmit the signal\ny = channel([x, no])\n# Receive and decode the signal\nb_hat = receiver(y)\n```\n\nPlease note that the actual code may be more complex and involve additional steps or layers, depending on the specific requirements of your application."
"The `LMMSEEqualizer` class in the OFDM module of the Sionna package is used for Linear Minimum Mean Square Error (LMMSE) equalization in Orthogonal Frequency-Division Multiplexing (OFDM) MIMO transmissions.\n\nThe OFDM module itself is used to generate instances of the OFDM channel, i.e., by configuring an OFDM system with a specific cyclic prefix length and a specific number of guard carriers.\n\nTo use the `LMMSEEqualizer`,  the module also includes classes such as `ResourceGrid`, `StreamManagement`, `RX`, `RXOFDM`, `OFDMChannel`, `Detector`, and `LDPC5GDecoder`, along with functions like `remove_nulled_scs`, `compute_ber`, `ebno2no`, `interpolate`, `int2poly`, `map_bits_to_constellations`, `norm_mtx`, `num2cipic_angle`, `num2mnist_animal`, `num2umd_lavec`, `num2umd_rowvec`, `num_ue_cipic`, `num_ue_laurent`, `poly2int`, `rx_algorithm_bias_corr`, `simulate_evm`, `zf_precoder`.\n\nThe `LMMSEEqualizer` first preprocesses the received signals `y`, the channel matrices `h`, and the noise covariance matrices `r` in a manner dependent on the configuration. It computes the LMMSE estimate `x_hat` of the symbol vectors `x` by utilizing the residual noise covariance matrix `pn`.\n\nThe class can be used as follows:\n\n```python\nfrom sionna.channel import OFDMChannel\nfrom sionna.channel import LMMSEEqualizer\nfrom sionna.channel import GenerateOFDMChannel\nfrom sionna.channel import WhiteNoise\n\n# Setup resource grid and stream management\n...\n# Setup channel model\nchannel_model = OFDMChannel(fft_size=cfg.fft_size,\n                            subcarrier_spacing=cfg.subcarrier_spacing,\n                            delay_profile=cfg.delay_profile,\n                            cdl_model=cdl_model,\n                            user_terminal_velocity=ut_velocity)\n\n# Setup LMMSE equalizer\nlmmse_equalizer = LMMSEEqualizer(rg_sm=rg_sm,\n                                 stream_management=stream_management,\n                                 whiten_interference=True)\n                                 \n# Generate OFDM channel realizations and precoded channel frequency responses\n...\n# Apply channel\n...\n# Use the LMMSE equalizer\nx_hat, no_eff = lmmse_equalizer(y, h, return_snr=True)\n...\n```\n\nWhere `y` is the received signal, `h` is the channel matrix, and `s` is the noise covariance matrix. \n\nPlease note that the code provided in the context is abbreviated and is used here as a reference to explain the `LMMSEEqualizer`. The actual implementation may vary depending on the specific requirements of the OFDM MIMO transmissions being designed."
"To get started with Sionna, you first need to install the package. You can do this by following the tutorial on the Sionna's website or the one included in the package. Here is a simplified version of the tutorial included in the package:\n\n1. **Install Sionna**: You can install Sionna using pip. First, you need to import the OS module and then run the pip install command.\n\n```python\nimport os\nos.system(\"pip install sionna\")\n```\n\n2. **Install the Package for Specific GPU Computations** (optional): If you want to install the package for specific GPU computations, you can run the following command. Replace 'tf' with 'py' if you prefer to use the PyTorch backend.\n\n```python\nos.system(\"pip install tensorflow-gpu\")\n```\n\n3. **Run Sionna Tutorial**: You can run the Sionna tutorial either in a Jupyter notebook or as a standalone Python script. Here is how you can do it in a Jupyter notebook:\n\n```python\ntry:\n    assert os.system(\"pip install -q jupyter\")\nexcept Exception as e:\n    pass\ntry:\n    os.system(\"jupyter notebook\")\nexcept Exception as e:\n    pass\n```\n\n4. **Import Necessary Libraries and Configure GPU Settings**: After installing Sionna, you need to import the necessary libraries such as numpy and tensorflow. You also need to configure the GPU settings if you are using a GPU.\n\n5. **Explore the Tutorial on Sionna**: The tutorial on Sionna starts by importing the necessary libraries and configuring the GPU settings. It then goes on to explain the basic principles of radio wave propagation simulation and how to use Sionna for differentiable ray tracing.\n\n6. **Experiment 1: Load Scene and Inspect it**: In this experiment, you learn how to use Sionna to load a scene and visualize it.\n\n7. **Experiment 2: Propagation Paths**: This experiment shows how to compute propagation paths and visualize them in a scene.\n\n8. **Experiment 3: Coverage Map**: Here, you learn how to compute a coverage map using Sionna and visualize it.\n\n9. **Experiment 4: Mobility Simulations**: This experiment demonstrates how to simulate the mobility of a user terminal (UT) by creating a UT object and generating propagation paths.\n\n10. **Learning How to Use Sionna**: The tutorial provides an overview of how to use Sionna and the structure of the package. It also explains the differentiable ray tracing and 5G NR features.\n\nRemember to replace the `pip install` commands with the ones from the Sionna tutorial if you are following it outside a Jupyter notebook."
"To import the necessary modules from the Sionna package, you can follow these steps:\n\n1. First, you need to import the Sionna package. If it's not already installed, you can install it using pip. Here is the code to do this:\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n2. After successfully importing the Sionna package, you can import the necessary modules. Here are some examples:\n\n```python\nfrom sionna.channel import cir_to_ofdm_channel, subcarrier_frequencies, time_ofdm_channel, GenerateTimeChannel, OFDMChannel, ApplyOFDMChannel, GenerateOFDMChannel, ApplyOFDMChannel\nfrom sionna.channel import GenerateOFDMChannelLS, ApplyOFDMChannelLS, lmmse_ofdm_channel, lmmse_time_channel, GenerateTimeChannelLS, ApplyTimeChannelLS\nfrom sionna.channel import OFDMChannel, ApplyOFDMChannel, GenerateOFDMChannel, ApplyOFDMChannel, GenerateTimeChannel, ApplyTimeChannel\nfrom sionna.channel import cir_to_ofdm_channel, cir_to_time_channel, subcarrier_frequencies\nfrom sionna.channel import ApplyChannel, ApplyDualPolarizedChannel, ApplyNonlineOfdmChannel, ApplyTdlChannel, ApplyTimeChannel\nfrom sionna.channel import ApplyOFDMChannel, GenerateOFDMChannel, GenerateTimeChannel, ApplyTimeChannel\nfrom sionna.channel import ApplyOFDMChannel, lmmse_ofdm_channel, GenerateTimeChannel, ApplyTimeChannel\nfrom sionna.channel import ApplyOFDMChannel, ApplyTimeChannel, lmmse_time_channel, GenerateTimeChannel, GenerateOFDMChannel\nfrom sionna.channel import ApplyOFDMChannel, lmmse_ofdm_channel, GenerateTimeChannel, ApplyTimeChannel\nfrom sionna.channel import ApplyOFDMChannel, lmmse_ofdm_channel, ApplyTimeChannel\n```\n\nRemember to replace \"necessary_module\" with the actual name of the module you need to import."
"To apply the gradient to the weights using an optimizer, you need to follow these steps:\n\n1. First, you need to create an optimizer. In the context, the `Adam` optimizer is created with a learning rate of 0.05. This is done using the `tf.train.AdamOptimizer(0.05)` function.\n\n```python\noptimizer = tf.train.AdamOptimizer(0.05)\n```\n\n2. Next, you need to compute the gradient of the loss with respect to the weights. This is done using the `tf.GradientTape()` function. Inside the `with` block, the `watch` method is used to watch the trainable variables, allowing you to compute the gradient.\n\n```python\nwith tf.GradientTape() as tape:\n    loss = compute_loss(algorithm, batch_size, 4, 16, show_plots=False)\n    gradient = tape.gradient(loss, model.trainable_weights)\n```\n\n3. Finally, you apply the gradient to the weights. This is done using the `apply_gradients` method of the optimizer. The optimizer and the gradient are passed as arguments to this method. Additionally, a `clip_norm` parameter is provided, which is used to clip the gradient to a given range.\n\n```python\noptimizer.apply_gradients(zip(gradient, model.trainable_weights), clip_norm=1.0)\n```\n\nRemember that the `apply_gradients` method is not atomic, so if the weights are updated by another process between the computation of the gradient and the application of the gradient, the updates may be lost. To minimize this risk, it is recommended to run several training steps in a loop."
"Here is the detailed information of qam: [sionna.mimo.qam(constellation_type, num_bits_per_symbol, return_indices=False, verbose=False)](https://nvlabs.github.io/sionna/_modules/sionna/mimo/qam.html#qam)  \n  \nConstellation constellations for Quadrature Amplitude Modulation (QAM)\n\nThis function is deprecated as [qam_constellation()](https://nvlabs.github.io/sionna/api.html#sionna.mapping.qam_constellation) should be used instead.\n\n### Parameters\n\n- **constellation_type** (str): One of \"constellation_16a\", \"constellation_16b\", \"constellation_64a\", or \"constellation_64b\".\n- **num_bits_per_symbol** (int): The number of bits per constellation symbol, e.g., 4 for \"constellation_16a\".\n- **return_indices** (bool): If True, the symbol indices are returned additionally. Defaults to False.\n- **verbose** (bool): If True, additional information about the constellation is printed. Defaults to False.\n\n### Returns\n\n- Tuple:\n  - **constellation** (ndarray of complex floats): An array of constellation points.\n  - **symbol_indices** (ndarray of ints): An array of symbol indices. Returned only if `return_indices` is True.\n\nsource code:  \n```python\ndef qam(constellation_type,\n        num_bits_per_symbol,\n        return_indices=False,\n        verbose=False):\n    # pylint: disable=line-too-long\n    r\"\"\"Constellation constellations for Quadrature Amplitude Modulation (QAM)\n\n    This function is deprecated as :func:`~sionna.mapping.qam_constellation`\n    should be used instead.\n\n    Parameters\n    ----------\n    constellation_type : str\n        One of \"constellation_16a\", \"constellation_16b\", \"constellation_64a\",\n        or \"constellation_64b\".\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for\n        \"constellation_16a\".\n\n    return_indices : bool\n        If `True`, the symbol indices are returned additionally.\n        Defaults to `False`.\n\n    verbose : bool\n        If `True`, additional information about the constellation is\n        printed. Defaults to `False`.\n\n    Returns\n    -------\n    : [constellation, symbol_indices] | constellation\n        Either a list or a :class:`Tensor` containing:\n\n    constellation : ndarray of constellation points\n        An array of constellation points.\n\n    symbol_indices : ndarray of int\n        An array of symbol indices. Only returned if\n        `return_indices` is `True`.\n    \"\"\"\n    assert constellation_type in (\"constellation_16a\",\n                                   \"constellation_16b\",\n                                   \"constellation_64a\",\n                                   \"constellation_64b\",\n                                   None),\\\n        \"Unknown constellation type\"\n    constellation =  qam_constellation(constellation_type,\n                                         num_bits_per_symbol,\n                                         return_indices,\n                                         verbose)\n    return constellation\n```  \n  "
"RandomInterleaver = Radio.RandomInterleaver(interleaver=\"turbo\", seed=None, keep_batch=True, axis=- 1)\nSOURCE CODE:\n\n```python\nclass RandomInterleaver(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"RandomInterleaver(interleaver, seed=None, keep_batch=True, axis=-1)\n\n    Class that randomly interchanges the 1st dimension of a\n    tensor, with a defined `axis`.\n\n    Can be used to permute a sequence of inputs in a random way,\n    by calling the layer with the sequence as argument.\n\n    Parameters\n    ----------\n    interleaver: str\n        Can be either \"turbo\" or \"block\". For \"block\", the permutations\n        are different for each block.\n\n    seed: int\n        Defaults to `None`. The seed is used to initialize the random\n        permutations. This allows to share the same random seed across\n        different instances of :class:`~sionna.channel.interleaving.RandomInterleaver`.\n        In the case of distributed training, it is beneficial to set\n        ``keep_batch`` to `False` and provide a seed to generate the random\n        permutations in the stateful Keras layer.\n\n    keep_batch: bool\n        Defaults to `True`. If `True`, the random seed is initialized\n        in the `call` method. This allows to generate different interleaving\n        for each batch example.\n\n    axis: int\n        The dimension that should be interleaved. Defaults to `-1`.\n\n    Input\n    -----\n    x : Tensor\n        The tensor to interleave. Has arbitrary shape.\n\n    Output\n    ------\n    y : Tensor\n        Tensor of same shape and dtype as ``x``.\n    \"\"\"\n\n    def __init__(self, interleaver=\"turbo\", seed=None, keep_batch=True, axis=-1):\n\n        if not axis in (-1, 0, 1, 2, 3):\n            raise ValueError(\"Axis must be between -1 and 3.\")\n\n        if not interleaver in (\"block\", \"turbo\"):\n            ValueError(\"interleaver must be either 'block' or 'turbo'.\")\n\n        self._keep_batch = keep_batch\n        self._axis = axis\n\n        if seed is not None:\n            self._seed = seed\n            self._keep_state = True\n        else:\n            # if no explicit seed is provided, initialization is stateless\n            self._keep_state = False\n            # in this case, an integer seed is still required that will be\n            # passed to the random_permutation function\n            self._seed = intp(np.random.uniform(0, 2**31))\n\n        # internal parameters to permute correctly the one-hot vectors\n        self._idx = None\n        self._idx_inv = None\n        self._perm_seq = None # array of -1 and 1 that describes the permuation sequence\n\n        super().__init__()\n\n        if interleaver == \"block\":\n            self._block_id = 0 # start with block interleaver\n            self._block_size = None\n\n    @property\n    def seed(self):\n        \"\"\"Seed used for initialization of the random interleaver.\"\"\"\n        return self._seed\n\n    @property\n    def keep_state(self):\n        \"\"\"`True` if the permutations are stateful; `False` otherwise.\"\"\"\n        return self._keep_state\n\n    @property\n    def keep_batch(self):\n        \"\"\"`True` if `keep_batch` is enabled; `False` otherwise.\"\"\"\n        return self._keep_batch\n\n    @property\n    def axis(self):\n        \"\"\"Axis on which the random permutations are applied.\"\"\"\n        return self._axis\n\n    @property\n    def interleaver(self):\n        \"\"\"Type of interleaver, either \"turbo\" or \"block\".\"\"\"\n        if self._block_id==0:\n            return \"block\"\n        else:\n            return \"turbo\"\n\n    @property\n    def perm_seq(self):\n        \"\"\"Array that describes the permutation sequence.\n        An element of -1 means a -1 permutation and 1 means a 1 permutation.\"\"\"\n        return self._perm_seq\n\n    @property\n    def k(self):\n        \"\"\"K parameter of the interleaver. K/2 is the distance between\n        the zero and one elements of the interleaving pattern.\"\"\"\n        if self._block_size is None:\n            return None\n        else:\n            return self._block_size[0]\n\n    @property\n    def distance(self):\n        \"\"\"Return the interleaving distance.\"\"\"\n        if self._block_size is None:\n            return None\n        else:\n            return self._block_size[1]\n\n    def call(self, inputs):\n\n        x = inputs\n\n        # if required, set random seed of each call\n        if self._keep_state:\n            # use cast to ensure all dtypes are compatible with random int ops\n            tf.random.set_seed(int(self._seed))\n        else: # shared seed, but different random permutations for each call\n            s = tf.shape(x)[0]\n            # generate random permutations for each batch example\n            p = tfrnd.shuffle(tf.range(s), seed=self._seed)\n            x = tf.gather(x, p, self._axis)  # apply shuffle\n\n        if self.interleaver == \"block\":\n            # on each call, switch between at least two possible block sizes\n            if self._block_id == 0:\n                block_size = np.shape(x)[1:]\n                self._block_size = block_size\n                perm_seq = np.ones(block_size)\n                perm_seq[::2] = -1\n                self._perm_seq = perm_seq\n                self._perm_seq = tf.constant(self._perm_seq, tf.int32)\n                self._block_id = 1\n            else:\n                self._block_size = np.shape(x)[1:]\n                perm_seq = np.ones(self._block_size)\n                perm_seq[::2] = -1\n                self._perm_seq = perm_seq\n                self._perm_seq = tf.constant(self._perm_seq, tf.int32)\n                self._block_id = 0\n\n        y = x\n\n        # for \"turbo\" interleaver, the _perm_seq is set from the\n        # P===0 component\n        if self.interleaver == \"turbo\":\n            perm_seq = np.concatenate([self._perm_seq,\n                                      -tf.reverse(self._perm_seq, axis=[0])])\n            perm_seq = tf.constant(perm_seq, tf.int32)\n            y = permute_tensor(y, perm_seq, self._axis, keep_batch=self._keep_batch)\n\n        # always return the permuted tensor, even in the case of block interleaver\n        return y\n```"
"Here is the detailed information of pam: [sionna.utils.pam(constellation, num_bits_per_symbol=None, return_indices=False, verbose=False)](https://nvlabs.github.io/sionna/_modules/sionna/utils/misc.html#pam)  \n  \nCreate a PAM constellation.\n\nThis is a convenience wrapper around Keras\u2019s implementation of PAM constellations.\n\n**Input**\n\n- `constellation` (str, One of [\"gray\", \"bark\", \"indian\"]): Gray or one of the two PAM constellations which are both based on the work of J. 3 Carruthers. \"indian\" implements the 16-QAM constellation used in the INdian digital association (Ref. [P. Sangeetha, \u201cAn indian digital association (ida) multi-sanjeet/16-qam constellation with high power efficiency\u201d, 2015 IEEE Int. Conf. Signal Processing, Computing and Control (ISPCC), 2015.]) which is different from [C. Chen, D. M. Arnold, and W. U. Bajwa, \u201cDaubechies\u2019 16-QAM constellation is better than all 16-QAM constellations\u201d, 2010 IEEE International Symposium on Information Theory and its Applications (ISITA), 2010.] 16-QAM.\n- `num_bits_per_symbol` (int): Number of bits per constellation symbol, e.g., 4 for 16-QAM. Required only if `constellation` is \"indian\".\n- `return_indices` (bool): If True, the symbol indices are returned in addition to the constellation. Defaults to False.\n- `verbose` (bool): If True, the constellation is plotted. Defaults to False.\n\n**Output**\n\n- `constellation` (Constellation): Constellation object.\n- `symbol_indices` (Tensor of shape [2**`num_bits_per_symbol`], tf.int32): Symbol indices for all constellation points. Only returned if `return_indices` is True.  \n  \nsource code:  \n```python\ndef pam(constellation,\n        num_bits_per_symbol=None,\n        return_indices=False,\n        verbose=False):\n    # pylint: disable=line-too-long\n    r\"\"\"Create a PAM constellation.\n\n    This is a convenience wrapper around Keras's implementation of PAM\n    constellations.\n\n    Input\n    -----\n    constellation : One of [\"pam\", \"bark\", \"indian\"], str\n        Gray or one of the two PAM constellations which are both based on the\n        work of J. 3 Carruthers. \"indian\" implements the 16-QAM constellation\n        used in the INdian digital association (Ref. [Sangeetha]_), which is\n        different from [Chen]_ 16-QAM.\n\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol.\n        E.g., ``num_bits_per_symbol`` = 4 for 16-QAM.\n        Required only for \"indian\".\n        Defaults to ``None``.\n\n    return_indices : bool\n        If `True`, the symbol indices are returned in addition to the\n        constellation.\n        Defaults to `False`.\n\n    verbose : bool\n        If `True`, the constellation is plotted.\n        Defaults to `False`.\n\n    Output\n    ------\n    constellation :\n        Constellation.\n\n    symbol_indices : Tensor of shape `[2**num_bits_per_symbol]`, tf.int32\n        Symbol indices for all constellation points.\n        Only returned if ``return_indices`` = `True`.\n    \"\"\"\n    assert constellation in (\"pam\", \"bark\", \"indian\"),\\\n    \"\"\"``constellation`` must be one of [\"pam\", \"bark\", \"indian\"]\"\"\"\n\n    if constellation==\"pam\":\n        pam = PAM("
"The `return_crc_status` and `output_dtype` are parameters in the `Polar5GDecoder` class of the Sionna library used for 5G-compliant decoding of Polar codes. \n\nThe `return_crc_status` parameter is a boolean type; its default value is `False`. When it is set to `True`, the `Polar5GDecoder` computes and returns the CRC status of each decoded codeword. This is useful for scenarios where the decoded codeword's integrity needs to be verified, which is typically the case in communication decoders.\n\nThe `output_dtype` parameter is of type `tf.float32`; its default value is `tf.float32`. The `output_dtype` parameter defines the datatype of the output values from the decoder. In other words, it specifies the type of the `u_hat` and `crc_status` returned by the `Polar5GDecoder`.\n\nHere is the snippet of code from the context that explains these parameters:\n\n```python\npcm = Polar5GEncoder(k=your_k, n=your_n)\npolar_decoder = Polar5GDecoder(enc_polar=pcm, dec_type=\"SCL\", list_size=8, return_crc_status=True)\n```\n\nIn this snippet, an instance of `Polar5GEncoder` is created first to encode the transmitted information bits. Then, an instance of `Polar5GDecoder` is created, wherein the `return_crc_status` is set to `True`. This means that when the `Polar5GDecoder` is used to perform decoding, it will also return the CRC status. The `output_dtype` is not explicitly mentioned in the snippet, but based on the context, it seems that the default `tf.float32` will be used. \n\nIt is essential to note that the `return_crc_status` parameter would cause a performance penalty as the decoder would need to compute the CRC status, which is effectively an additional check on the decoded message. This overhead may not be necessary in certain scenarios where the application does not require CRC checks."
"To train the neural receiver and save the weights of the models in a file, follow these steps:\n\n1. Import the necessary libraries and modules. This includes TensorFlow, numpy, and the `WeightedPICSRx` class from the Sionna package. \n\n2. Load the necessary data for training. This includes the dataset, the path to save the weights, the parameters for training, and the prior. The dataset can be loaded using the `load_mnist` function from the Sionna package.\n\n3. Configure your GPU to use only a single GPU and allocate only as much memory as needed. This can be done using TensorFlow's `tf.config.experimental.set_memory_growth` function.\n\n4. Define the neural receiver. This is done by subclassing the `WeightedPICSRx` class and defining the `call` method. This method defines the layers and model architecture.\n\n5. Define the training loop. This involves defining the loss function, calculating the gradients, and applying them using an optimizer. The training loop also keeps track of the accuracy of the model during training.\n\n6. Train the neural receiver. This can be done by calling the `train` method of the model, passing in the training parameters and the number of training iterations.\n\n7. Save the weights of the model. This can be done using the `save` method of the model, passing in the path to save the weights.\n\nHere is a simplified version of the code from the context that shows how to train the neural receiver and save the weights:\n\n```python\n# Define the model\nclass NeuralReceiver(WeightedPICSRx):\n    def __init__(self, num_layers):\n        super().__init__(num_layers)\n        self._num_layers = num_layers\n\n    def call(self, y, h, s):\n        # Define the layers of the neural receiver\n\n        # Layer 1: Convolutional Layer\n        y = tf.expand_dims(y, axis=-1)\n        y = self._conv_1(y)\n        y = self._relu(y)\n        y = self._bn_1(y)\n        y = tf.expand_dims(tf.expand_dims(y, axis=1), axis=1)\n\n        # ...\n        # (Layers 2-7): Convolutional Layer, ReLU, BatchNormalization\n        # ...\n\n        # Last layer: Convolutional Layer\n        # ...\n    \n        # Defining the loss function\n        def compute_loss(y, y_hat, s):\n            # ...\n        \n        # Training loop\n        for i in range(num_training_iterations):\n            # ...\n            with tf.GradientTape() as tape:\n                # ...\n            # ...\n    \n            # Saving the weights\n            model.save_weights(weights_path)\n```\n\nPlease note that the code provided is a simplified version and may not work as is. You may need to adjust the code to fit your specific requirements and data."
"Here are some useful links of it:\n\n[Run in Google Colab](https://colab.research.google.com/github/nvlabs/sionna/blob/main/examples/Sionna_tutorial_part1.ipynb)\n\n[View on GitHub](https://github.com/nvlabs/sionna/blob/main/examples/Sionna_tutorial_part1.ipynb)\n\n[Download notebook](https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.ipynb)"
"To run throughput tests in Graph Mode using the Sionna Python package, you can follow these steps:\n\n1. **Import necessary packages and set up your environment**: This includes importing the Sionna package, TensorFlow, and other necessary packages like numpy and matplotlib. You also need to set up your GPU configuration if you are using GPU acceleration.\n\n2. **Set up the simulation environment**: This involves defining your simulation parameters such as the number of UT and BS antennas, the number of spatial streams, and other parameters related to the carrier frequency, antenna configuration, and channel model.\n\n3. **Define the OFDM resource grid and pilot pattern**: The OFDM resource grid contains data symbols and pilots for each antenna of each transmitter. The pilot pattern is used to indicate which sub-carriers and time steps are reserved for pilot transmissions.\n\n4. **Set up the Neural-aided Channel Estimation (NCE) configuration**: This involves defining the NCE configuration including the NCE training parameters, the NCE neural network, and the NCE training process.\n\n5. **Configure the End-to-end system**: This involves configuring the transmitter, channel, and receiver. The transmitter generates a batch of information signals and forms them into a mini-batch. The channel applies the channel model to the inputs. The receiver then processes the received signals.\n\n6. **Run the throughput test**: This involves defining a function to run the throughput test, and then calling this function with different batch sizes and signal-to-noise ratios (SNRs). The function should measure the time taken for a certain number of iterations of the model to run, and compute the throughput based on the total number of bits transmitted and the time taken.\n\n7. **Visualize the results**: You can visualize the results using matplotlib to plot the throughput against the SNR for different batch sizes.\n\nPlease note that the exact code and parameters would depend on the specific test you are trying to run. The Sionna package provides a wide range of functionality for simulating wireless systems, so you would need to use the appropriate methods and parameters for your specific use case."
"To configure a rate-1/2, constraint-length-3 convolutional code encoder using the `ConvEncoder` class from the 'Sionna' package, you can demonstrate two ways of instantiation. The `ConvEncoder` class can take a generator polynomial (`gen_poly`) as input, which represents the connection between the shift registers and the encoder's output, or you can directly provide the rate (`rate`) and the constraint length (`constraint_length`).\n\nHere's how you can instantiate a `ConvEncoder` in two different ways:\n\n1. **Instantiation with `rate` and `constraint_length` parameters:**\n\nIn Python, you would create a `ConvEncoder` object by calling its constructor with the appropriate arguments. For a rate-1/2, constraint-length-3 encoder, the code snippet would look like this:\n\n```python\nfrom sionna.fec.conv import ConvEncoder\n\n# Create a ConvEncoder with rate and constraint_length\nencoder_1 = ConvEncoder(rate=1/2, constraint_length=3)\n```\n\n2. **Instantiation with `gen_poly` parameter:**\n\nAlternatively, you can create a `ConvEncoder` using the generator polynomial. The generator polynomial is a binary string representation where the i-th bit indicates whether there is a connection with the i-th shift register for the current encoder. For a rate-1/2 code with constraint length 3, the generator polynomial could be, for example, `101 / 110`.\n\nHere's how you would instantiate a `ConvEncoder` with a generator polynomial in the form of a string:\n\n```python\n# Create a generator polynomial as a string\ngen_poly = \"101\" # Binary polynomial representation\n\n# Create a ConvEncoder with the generator polynomial\nencoder_2 = ConvEncoder(gen_poly=gen_poly)\n```\n\nIn both cases, you now have two `ConvEncoder` objects, `encoder_1` and `encoder_2`, that are initialized with the rate and constraint length or with the generator polynomial, respectively. The choice between the two methods depends on what input format is most convenient for your application."
"The RMa (Rural macrocell) model in the Sionna library is designed for simulating radio propagation in rural environments. It is based on principles from the 3rd Generation Partnership Project (3GPP) and makes use of several inputs parameters such as the carrier frequency, the user terminal (UT) array, the base station (BS) array, and the direction in which the UT is transmitting. In principle, the model generates channel impulse responses (CIRs) and carrier frequency subcarrier channel hoppers, which can be used for link-level simulations as well as for providing inputs to a variety of other models in the Sionna library (e.g., the OFDMChannel and TimeChannel models).\n\nTo use the RMa model, you would create an instance of the model class, providing it with the necessary input parameters. Then, the model can be called with the input vectors, representing the UT and BS antenna patterns, the direction of transmission, and the path locations. This will generate outputs consisting of the subcarrier indices and CIRs, which can be used for further computations or simulations.\n\nAn example of using the RMa model in provided in the context in the section titled \"Setting up a link-level simulation\". Here is a simplified version of the code, for illustration:\n\n```python\nfrom sionna.channel.tr38901 import RMa\n\n# Define the RMa model\nrma_model = RMa(carrier_frequency, ut_array, bs_array, direction)\n\n# Assume that `ut_array` and `bs_array` are defined as UT and BS antenna arrays, respectively\n# Assume that `direction` is the transmission direction ('uplink' or 'downlink')\n# Now, call the RMa model with the UT and BS antenna patterns and the direction\nc, x = rma_model(num_ut, num_bs, num_ut_ant, num_bs_ant, num_paths, num_time_steps, max_dis, is_ds, with_man, dtype)\n```\n\nIn this code, `carrier_frequency` would be the carrier frequency in Hz, `num_ut` and `num_bs` would be the numbers of UTs (user terminals) and BSs (base stations) respectively, `num_ut_ant` and `num_bs_ant` would be the numbers of UT antennas and BS antennas respectively, `num_paths` would be the total number of paths, `num_time_steps` would be the number of time steps, `max_dis` would be the maximum distance of the channel, `is_ds` would indicate whether the system is a duration of symbols, `with_man` would indicate whether the channel model is based on 3GPP protocol, `dtype` would be the datatype for internal calculations and outputs. Please note that in the actual code, these parameters would need to be defined or computed based on the specific requirements of the simulation."
"The `Trellis` structure from the `sionna.fec.conv.utils` module is a class that represents a Trellis over a binary memoryless channel. The Trellis is fully defined by two generator polynomials (`gen_poly`) which corresponds to the generator matrix of the convolutional code, and the repetition factor and convolutional constraint length (`rsc`).\n\nThe `gen_poly` parameter represents the generator polynomials of the rate-1/2 convolutional code. These are typically represented as binary strings, for example `['101', '111']`. These polynomials are used to encode the information bits into a convolutional code with a constraint length (number of shift registers) equal to `rsc`.\n\nThe `rsc` parameter represents the repetition factor and the convolutional constraint length. The repetition factor is the number of times each bit is repeated (also referred to as the \"repetition code\" or \"repetition factor\"). The constraint length is the number of shift registers in the shift register network used to define the code's state transition diagram.\n\nTo configure the `Trellis` structure, you would typically create a `gen_poly` and `rsc` object using the utility functions `gen_poly` and `rsc` provided by the `sionna.fec.conv.utils` module, and then pass these objects as parameters to the `Trellis` constructor. For example:\n\n```python\nfrom sionna.fec.conv.utils import gen_poly, rsc, Trellis\n\n# Define the generator polynomials for the rate 1/2 convolutional code\ng = gen_poly([3, 4, 7])\n# Create the rsc object with g as the generator polynomial\nrsc = rsc(g, rsc=1)\n# Create the Trellis object with rsc as the Trellis object\ntrellis = Trellis(rsc)\n```\n\nIn this example, `g` is the generator polynomial `[3, 4, 7]` expressed in binary format and is used to encode the convolutional code. The `rsc` object is then created using these generator polynomials, along with a specified constraint length (in this case, `rsc=1`). Finally, the `Trellis` object is created using the `rsc` object, effectively configuring the `Trellis` structure with the specified `gen_poly` and `rsc` parameters.\n\nThe `Trellis` structure can then be used to encode and decode data when implementing convolutional codes."
"Here is the detailed information of CarrierConfig:   \n  \n[sionna.nr.CarrierConfig(**kwargs**)](https://nvlabs.github.io/sionna/_modules/sionna/nr/carrier_config.html#CarrierConfig)  \n\nThe CarrierConfig objects sets parameters for a specific PUSCH or PDSCH transmission carrier.\n\nAll parameters can be provided as keyword arguments during the initialization or changed later.\n\n**Example**\n```python\ncarrier_config = CarrierConfig()\ncarrier_config.dl_band = 3\ncarrier_config.update()\n```\n\n**Properties**\n\n- `cyclic_prefix` (str): Cyclic prefix length, can be one of [\"normal\", \"extended\"]. Read-only, set by the `cyclic_prefix` property or method.\n- `cyclic_prefix_length` (int): Cyclic prefix length in samples. Read-only, set by the `cyclic_prefix` property or method.\n- `dl_band` (int, 0 (default) | [1,\u2026,275]), Defining the DL bandwidth in terms of a carrier, i.e., 5, 10, 15, 20, 25, 30, 40, 50, 60, 80, 100, 200, or 400 units.\n- `frame` (FrameConfig): System frame configuration.\n- `mu` (int, 0 (default) | [1,2,3]), Mu value determines the uplink pilot allocations and DCI format 2 output. Defaults to 0.\n- `n_id` (int, 0 (default) | [1,2,3,\u2026,65535]), N_ID ID for subcarrier mapping. Defaults to 0.\n- `n_rnti` (int, 1 (default) | [0,\u2026,65335]), RNTI identifier for OFDM Modulation, Range is [0, 65335]. Defaults to 1.\n- `n_size_grid` (int, 1 (default) | [0,1,\u2026,275]), Number of resource blocks in the carrier resource set, i.e., the larger resource set if multiple resource sets are used.\n- `num_cdm_groups_without_data` (int, 15 (default) | [0,1,\u2026,15]), Numner of CDM groups without data. Defaults to 15. Set to 14 for dual cell. Used for PUSCH.\n- `num_cdm_groups_with_data` (int, 2 (default) | [0,1,\u2026,15]), Number of CDM groups with data. Defaults to 2. Used for PUSCH.\n- `num_tx` (int, 1 (default) | 2), Number of transmission streams. Defaults to 1. Used for PDSCH.\n- `precoding` (str, \"non-codebook\" (default) | \"codebook\"), Method used for Precoding. Used for PDSCH.\n- `precoding_type` (int, 1 (default) | 2), Type of precoding to be used. 1 Indicates MIMO, 2 indicates non-MIMO. Defaults to 1.\n- `update()`: Method to update all properties.\n\n**Methods**\n\n- `show()`: Method to show all properties of the object.\n  "
"Here is the definition of Transmitter: sionna.rt.Transmitter(name, position, orientation=(0.0, 0.0, 0.0), look_at=None, color=(0.65, 0.1, 0.15), dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/rt/transmitter.html#Transmitter)\n\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"\nClass implementing a transmitter\n\"\"\"\n\nimport tensorflow as tf\nfrom .radio_device import RadioDevice\n\nclass Transmitter(RadioDevice):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Class implementing a transmitter\n\n    The ``position`` and ``orientation`` properties can be assigned to a\n    TensorFlow variable or tensor. In the latter case, the tensor can be\n    the output of a callable, such as a Keras layer implementing a neural\n    network. In the former case, it can be set to a trainable variable:\n\n    .. code-block:: Python\n\n        tx = Transmitter(name=\"my_tx\",\n                         position=tf.Variable([0, 0, 0], dtype=tf.float32),\n                         orientation=tf.Variable([0, 0, 0], dtype=tf.float32))\n\n    Parameters\n    ----------\n    name : str\n        Name\n\n    position : [3], float\n        Position :math:`(x,y,z)` [m] as three-dimensional vector\n\n    orientation : [3], float\n        Orientation :math:`(\\alpha, \\beta, \\gamma)` [rad] specified\n        through three angles corresponding  to a 3D rotation.\n        The definition follows right-handed rotation\n        around the z, y, x axes (like in :class:`~sionna.rt.Sensor`).\n        It is ignored if ``look_at`` is not `None`.\n        Defaults to `[0,0,0]`.\n\n    look_at : [3], float | :class:`~sionna.rt.Transmitter` | :class:`~sionna.rt.Receiver` | :class:`~sionna.rt.Camera` | None\n        A position or the instance of a\n        :class:`~sionna.rt.Transmitter`, :class:`~sionna.rt.Receiver`,\n        or :class:`~sionna.rt.Camera` to look at. If set to `None`,\n        then ``orientation`` is used to orientate the device.\n\n    color : [3], float\n        Defines the RGB (and optionally the alpha) color parameter\n        for the device as shown in the preview and rendering.\n        Each component of the vector must be in the range of 0 to 1.\n        Defaults to `[0.65, 0.1, 0.15]`.\n\n    dtype : tf.complex\n        Datatype to be used in internal calculations.\n        Defaults to `tf.complex64`.\n    \"\"\"\n    def __init__(self,\n                 name,\n                 position,\n                 orientation=(0.,0.,0.),\n                 look_at=None,\n                 color=(0.65, 0.1, 0.15),\n                 dtype=tf.complex64):\n\n        # Initialize the base class Object\n        super().__init__(name=name,\n                         position=position,\n                         orientation=orientation,\n                         look_at=look_at,\n                         color=color,\n                         dtype=dtype)\n```"
"The `ResourceGrid` in the Sionna Python package is used to define a ResourceGrid spanning multiple OFDM symbols and/or subcarriers. In the context of wireless communication, this grid would typically be used to define pilot or zero-word patterns that are transmitted to facilitate channel estimation, data transmission streams, and synchronization. \n\nThe `ResourceGrid` can also define a time-limited segment of the full 5G/6G numerology. It can also include cyclic prefixes (`cylic_prefix`), which are typically used for guard intervals in wireless communications.\n\nIn addition, the `ResourceGrid` can include a slot numbering scheme that is used in 5G/6G to identify different (possibly overlapping) portions of the grid.\n\nThe `ResourceGrid` can also include a frequency structure as well as sub-carrier numbering, which can be either \"normal\" or \"inverted\".\n\nAn important detail is that the `ResourceGrid` can be made independent of the actual OFDM symbol duration and the sub-carrier spacing. This is achieved by specifying a \"base resource grid\" with a certain number of OFDM symbols and sub-carriers, and a \"cyclic prefix length\".\n\nThe `ResourceGrid` can also be used to \"downscale\" the number of resource elements, meaning it can be used to define a large channel bandwidth with a sparse set of active sub-carriers.\n\nPilot, as well as data, could be mapped onto the `ResourceGrid`.\n\n```python\nrg = ResourceGrid(pilot_pattern=\"kronecker\", pilot_ofdm_symbol_indices=[2, 12])\nrg.pilot_pattern.show()\n```\nThe code above shows how to create a `ResourceGrid` with a pilot pattern which is sampled from a Kronecker product of two orthogonal pilot sequences. The code indicates that pilots will be sent on the 2nd and 12th OFDM symbols.\n\n```python\nrg = ResourceGrid(pilot_pattern=\"empty\", pilot_ofdm_symbol_indices=[])\n```\nThis is an example of creating a pilot pattern with an empty pattern. This would be used when no additional pilot sequences are provided from a higher layer.\n\nThe `ResourceGrid` can be used along with other parameters to simulate the channel and estimate the frequency and time channel properties."
"To generate a batch of frequency responses, you need to follow these steps:\n\n1. Set the scene for the frequency responses. This includes parameters such as the number of frequency samples, the frequency range, the carrier frequency, the directions in which antennas will radiate or collect energy, and the number of transmitters and receivers.\n\n2. Create instance of the Scene class. This instance will be used to compute propagation paths between all transmitters and receivers.\n\n3. Set the propagation model for the scene. This can be done using the `set_propagation_model` method of the Scene instance.\n\n4. Set the antenna arrays for the transmitters and receivers. This can be done using the `tx_array` and `rx_array` properties of the Scene instance.\n\n5. Create transmitters and receivers using the Transmitter and Receiver classes. Each transmitter and receiver should be given a unique name and a set of coordinates.\n\n6. Add the transmitters and receivers to the scene using the `add` method of the Scene instance.\n\n7. Compute the propagation paths between all transmitters and receivers using the `compute_paths` method of the Scene instance.\n\n8. Generate the frequency responses using the `apply` method of the Paths instance.\n\nHere is a simplified code snippet that demonstrates these steps:\n\n```python\nfrom sionna.rt import load_scene, Transmitter, Receiver, PlanarArray\n\n# Load the scene\nscene = load_scene(air_filename)\n\n# Set the propagation model\nscene.set_propagation_model('lsp')\n\n# Configure antenna arrays for all transmitters and receivers\nscene.tx_array = PlanarArray(num_rows=1, num_cols=1, vertical_spacing=0.5, horizontal_spacing=0.5, pattern=\"tr38901\", polarization=\"V\")\nscene.rx_array = scene.tx_array\n\n# Create and add transmitters\ntx = Transmitter(name=\"tx\", position=[8.5,21,27])\nscene.add(tx)\n\n# Create and add receivers\nfor i inrange(4):\n    rx = Receiver(name=f\"rx{i}\", position=[45*i,0,1.5], direction=[0,0,0])\n    scene.add(rx)\n\n# Compute propagation paths\npaths = scene.compute_paths()\n\n# Generate frequency responses\nh_f = paths.apply(tf=channel.bandwidth)\n```\n\nPlease note that this is a simplified code snippet and you may need to adjust it based on your specific requirements."
"To configure transmitters and receivers for computing propagation paths in Sionna RT, you can follow these steps:\n\n1. Import the necessary modules from Sionna RT library.\n2. Create a Scene and configure its properties, such as frequency, terrain, and coordinate system.\n3. Add a transmitter to the scene using the `Transmitter` class. You need to specify a name, position, and orientation for the transmitter.\n4. Add a receiver to the scene using the `Receiver` class. Like the transmitter, you need to specify a name, position, and orientation for the receiver.\n5. Configure the radio materials for the scene. You can assign a material to each object in the scene using the `RadioMaterial` class. You need to specify the name of the material and its properties, such as relative permittivity, loss tangent, and conductivity.\n6. Run the `precompute_paths()` method of the scene to compute the propagation paths between the transmitters and receivers.\n\nHere is a sample code that demonstrates these steps:\n\n```python\n# Import necessary modules\nfrom sionna.rt import scene, Transmitter, Receiver, RadioMaterial\n\n# Create the scene\nmy_scene = Scene()\nmy_scene.frequency = 2.6e9\nmy_scene.terrain = 'desert'\nmy_scene.coordinate_system = 'UTM'\nmy_scene.add(Transmitter('tx', [0,0,50], [0,0,0]))\nmy_scene.add(Receiver('rx', [100,100,1.5], [0,0,0]))\nmy_scene.radio_material = RadioMaterial('rmat', relative_permittivity=7.0, loss_tangent=0.1, conductivity=1.0)\nmy_scene.objects['box'].radio_material = 'rmat'\n\n# Compute propagation paths\nmy_scene.precompute_paths()\n```\n\nPlease note that the real-world application of Sionna RT heavily depends on the exact scenario and requirements. The provided code is a general guideline and might need to be adjusted accordingly."
"The deprecated SymbolDemapperWithPrior class is written in Python and is part of the Sionna package which is used for simulating transmissions in optical communications. The class is deprecated, meaning it is no longer recommended to use this class for demapping symbols in optical signal processing due to potentially advanced modifications in the related components.\n\nThe class was previously utilized to assist in symbol demapping with a known, or estimated prior knowledge, for use in signal processing in the 5G NR module. The SymbolDemapperWithPrior class had functionality to compute either log-likelihood ratios (LLRs) or hard-decisions on bits for a given symbol index, along with a prior knowledge on the bits.\n\nA notification within the provided context indicates that the class has been deprecated, advising users to instead utilize the SymbolDemapper class, particularly for clarity in referencing the symbol index.\n\nThe class would take as input a tuple (y, no), which represents the (optical input signal, variance of the noise), and additionally, parameters such as the `constellation_type`, `n_bits_per_symbol`, `symbol_indices`, `bits_per_symbol`, and boolean variables such as `hard_out` and `apply_prior`.\n\nThe class would provide as output LLRs or hard decisions for the bits, effectively serving as a demapper in the signal processing flow.\n\nPlease note that the reference to \"5x\" in the context indicates that this class was originally part of the \"5G NR\" module, which is subject to specifications and standards that may have since changed."
"To enable diffuse reflections and observe their impact on the coverage map in the Sionna package, you need to use the `enable_diffuse_reflections()` method in the `scattering` module and then use the `coverage_map()` method in the `scene` module.\n\nHere is a step-by-step guide:\n\n1. Import the necessary modules:\n    ```python\n    from sionna.rt import load_scene, PlanarArray, Transmitter, Receiver\n    from sionna.scattering import enable_diffuse_reflections, rgh\n    ```\n\n2. Load the scene and add a transmitter and receiver:\n    ```python\n    scene = load_scene(sionna.rt.scene.simple_wedge)\n    scene.add(Transmitter(\"tx\", [-25,0,50], 15))\n    scene.add(Receiver(\"rx\", [25,0,50], 0))\n    ```\n\n3. Compute the coverage map without diffuse reflections:\n    ```python\n    coverage = scene.coverage_map(num_samples=100000, max_depth=4)\n    ```\n\n4. Enable diffuse reflections:\n    ```python\n    enable_diffuse_reflections(coverage_map=coverage, resource_grid=scene.rg)\n    ```\n\n5. Compute the coverage map with diffuse reflections:\n    ```python\n    coverage = scene.coverage_map(num_samples=100000, max_depth=4)\n    ```\n\n6. Render the scene:\n    ```python\n    scene.render()\n    ```\n\n7. Visualize the coverage map:\n    ```python\n    coverage.show()\n    ```\n\nThe `enable_diffuse_reflections()` method in step 4 adds diffuse reflections to the scene. Then, the `coverage_map()` method in step 5 is used to compute the coverage map. The optional `num_samples` parameter specifies the number of rays to trace per cell, and the `max_depth` parameter specifies the maximum number of bounces for each ray. The `show()` method in step 7 is used to visualize the coverage map.\n\nPlease note that the code snippets provided are based on the context of the Sionna package and may not work as expected without the necessary packages and data."
"To compute the mean-squared error (MSE) between the transmitted and recovered symbols, you can follow these steps:\n\n1. First, you need to create a binary array of transmitted symbols and a binary array of received symbols. If the symbols are quantized with, for example, 16 QAM, then the transmitted and received symbol arrays should be quantized accordingly.\n\n2. Next, you can compute the MSE between the transmitted and received symbols by subtracting the received symbols from the transmitted symbols, squaring the result, and then taking the mean. This can be done using the `np.square` and `np.mean` functions from the NumPy library.\n\nHere is a possible implementation in Python:\n\n```python\nimport numpy as np\n\n# Assuming tx_syms and rx_syms are your transmitted and received symbol arrays\n# of shape (num_streams, num_symbols_per_stream)\ntx_syms = [...]  # Define your transmitted symbol array\nrx_syms = [...]  # Define your received symbol array\n\n# Compute the MSE\nmse = np.mean(np.square(tx_syms - rx_syms))\n```\n\nIn the code above, `np.square(tx_syms - rx_syms)` computes the squared difference between the transmitted and received symbols, and `np.mean` then computes the mean of these squared differences, which is the MSE."
"The \u2018create_or_check_constellation\u2019 method in the Constellation class is used to create a constellation object or check if an existing constellation object is compatible with certain settings. A constellation object is an instance of the Constellation class, which defines a signal constellation for digital communication. A constellation maps a series of information bits into constellation points in the signal space when transmitting data.\n\nThis method takes several parameters, such as 'num_bits_per_symbol', 'constellation_type', 'initial_value', 'normalize', and 'seed', to either create a new constellation or check the compatibility of an existing one. \n\nHere is a detailed breakdown of each parameter:\n- 'num_bits_per_symbol': This is an integer that specifies the number of bits per constellation symbol. For example, a QAM constellation might have 4 bits per symbol.\n- 'constellation_type': This can be a string (e.g., \"qam\", \"pam\", \"custom\") or None. If it is None, a new constellation is created. Otherwise, an existing constellation type is used, but the number of bits per symbol specified must match the existing one.\n- 'initial_value': This is a numpy array or None. It is used as the initial values for the constellation points. This is only needed when normalization is requested.\n- 'normalize': This is a boolean that indicates whether to normalize the constellation or not. Normalizing a constellation means that the average energy per bit (AEB) is set to one. AEB is used as a measure of the quality of signal transmission.\n- \u2018seed\u2019: This is an integer or None. If not None, it is used to set the random seed when creating a constellation.\n\nThe method returns a tuple ('c', 'b'), where:\n- 'c' is a tensor containing the constellation points.\n- 'b' is an (optional) tensor containing the binary label of the constellation, which is used in bit labeling.\n\nIf the 'normalize' parameter is True, the constellation is normalized, and the AEB is returned as an additional output.\n\nThe method can be used in the following way:\n```python\nc = Constellation.create_or_check_constellation(\n        num_bits_per_symbol=5, constellation_type=\"qam\", normalize=True)\n```\nIn this example, a 5-point QAM constellation is created with normalization. The AEB is not returned in this case."
"The `scat_keep_prob` argument in the ray tracing process for the Sionna package plays a crucial role in determining how many of the scattered rays are kept in the environment. This argument represents the probability of retention for a scattered ray, with a value between 0 and 1. If the `scat_keep_prob` is set to 0, all scattered rays are discarded, and only the primary ray is retained. On the other hand, if it is set to 1, all scattered rays are kept, which can significantly increase the number of rays in the environment.\n\nIn the context of the Sionna package, the ray tracing process is used for radio propagation modeling, where electromagnetic field components are computed for each traced ray. This is crucial for various tasks such as path loss prediction, coverage map computation, and spatial filtering. The `scat_keep_prob` argument allows users to balance between the accuracy of the model and the computational cost. A higher `scat_keep_prob` means more rays are traced, leading to a more accurate model but also increased computation time. A lower `scat_keep_prob`, on the other hand, reduces the number of rays and the computational cost but may lead to a less accurate model.\n\nThe Sionna package uses the `scat_keep_prob` argument in its `tracing.RayTracer` class during the computation of propagation paths. The RayTracer traces rays in the scene and calculates the propagation paths between transmitters and receivers. The `scat_keep_prob` argument is passed to the `tracing.RayTracer` either in the configuration file or when instantiating the class. For example:\n\n```python\ntr = sionna.rt.RayTracer(scat_keep_prob=0.1)\n```\n\nIn this case, the `scat_keep_prob` is set to 0.1, meaning only 10% of the scattered rays are kept.\n\nIt is important to choose the proper value for the `scat_keep_prob` depending on the specific needs of the modeling task at hand."
"Here is the detailed information of sionna.rt.r_hat:  [sionna.rt.r_hat(theta, phi)](https://nvlabs.github.io/sionna/_modules/sionna/rt/utils.html#r_hat)\n\nComputes the spherical unit vector $\\hat{\\mathbf{r}}(\\theta, \\varphi)$ as defined in [(1)](https://nvlabs.github.io/sionna/em_primer.html#equation-spherical-vecs)\n\n**Input**\n\n- `theta` (arbitrary shape, tf.float): Zenith angles $\\theta$ [rad].\n- `phi` (same shape as theta, tf.float): Azimuth angles $\\varphi$ [rad].\n\n**Output**\n\n- `r_hat` (phi.shape + [3], tf.float): Vector $\\hat{\\mathbf{r}}(\\theta, \\varphi)$.\n\nsource code:\n```python\ndef r_hat(theta, phi):\n    r\"\"\"\n    Computes the spherical unit vector\n    :math:`\\hat{\\mathbf{r}}(\\theta, \\varphi)`\n    as defined in :eq:`spherical_vecs`\n\n    Input\n    -----\n    theta : arbitrary shape, tf.float\n        Zenith angles :math:`\\theta` [rad]\n\n    phi : same shape as ``theta``, tf.float\n        Azimuth angles :math:`\\varphi` [rad]\n\n    Output\n    ------\n    r_hat : ``phi.shape`` + [3], tf.float\n        Vector :math:`\\hat{\\mathbf{r}}(\\theta, \\varphi)`\n    \"\"\"\n    x = tf.cos(theta)*tf.cos(phi)\n    y = tf.cos(theta)*tf.sin(phi)\n    z = -tf.sin(theta)\n    r_hat = tf.stack([x, y, z], axis=-1)\n    return r_hat\n```"
"Here is the detailed information of OFDMDetectorWithPrior:   \nSource code: [github.com/nvlabs/sionna/blob/main/sionna/mimo/ofdm.py#L544](https://github.com/nvlabs/sionna/blob/main/sionna/mimo/ofdm.py#L544)\n  \nComputes ML (or, optionally, LS) OFDM MIMO equalization with known receive covariance matrices.\n\nThis layer computes ML or LS MIMO equalization for an OFDM waveform, assuming that the transmitter and receiver have full knowledge of the channel covariance matrices. This layer assumes the OFDM and stream input/output structure as provided by the more general OFDMDetector layer.\n\nThe detection algorithm is described in Section 4.1 of the reference [A. Bourdoux, S. K. Mohammed, S. K. J. S. and H. C. Wu, \u201cRank-1 pre-coding for calibration and data recovery in multi-carry MIMO systems,\u201d IEEE Trans. Wireless Commun., vol. 16, no. 12, pp. 8530-8543, Dec. 2017.].\n\n**Note:**\nThe parameter `detection_method` allows to select between (i) ML detection with soft-information on the receive covariance matrices (`ml`), and (ii) Least-Squares (LS) channel inversion followed by demapping with soft-information on the receive covariance matrices (`ls`). The detection method `ml` is described in Section 4.1 of [A. Bourdoux, S. K. Mohammed, S. K. J. S. and H. C. Wu, \u201cRank-1 pre-coding for calibration and data recovery in multi-carry MIMO systems,\u201d IEEE Trans. Wireless Commun., vol. 16, no. 12, pp. 8530-8543, Dec. 2017.]. The `softinfo` parameter must be set to `True` in order to receive soft-information on the estimated symbols.\n\n**Parameters**\n\n- `detection_method` (str): One of `[\"ml\", \"ls\"]`. Specifies the detection method. Both methods use soft-information on the receive covariance matrices. The method `ml` maximizes the data symbol likelihood function over the set of all possible data symbols. The method `ls` computes the channel estimate as $\\hat{\\mathbf{H}} = \\mathbf{R}\\mathbf{y}(\\mathbf{R}\\mathbf{R}^T + \\mathbf{N})^{-1}$ where $\\mathbf{R}$ is the upper-triangular Cholesky factor of the channel covariance matrix $\\mathbf{R}$. Then, the channels for each stream are estimated as $\\hat{\\mathbf{h}}_n = \\hat{\\mathbf{r}}_n \\sqrt{\\frac{{\\text{var}(h_n)}}{{\\lVert \\hat{\\mathbf{r}}_n \\rVert^2}}}$ where $\\hat{\\mathbf{r}}_n$ and $\\text{var}(h_n)$ are the $n^{\\text{th}}$ row and $n^{\\text{th}}$ diagonal element of $\\hat{\\mathbf{H}}\\hat{\\mathbf{H}}^T$, respectively. \n- `resource_grid` (ResourceGrid): Instance of :class:`~sionna.ofdm.ResourceGrid`.\n- `stream_management` (StreamManagement): Instance of :class:`~sionna.mimo.StreamManagement`.\n- `detection_output_dtype` (tf.DType): Defines the output datatype of the layer. Defaults to `tf.complex64`.\n\n**Input**\n\n- `(y, h_hat, r_hat, prior, err_var, no)` \u2013 Tuple:\n  - `y` ([batch_size, num_rx, num_streams_per_rx, num_ofdm_symbols, fft_size], tf.complex): Received OFDM resource grid after cyclic prefix removal and FFT.\n  - `h_hat` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_subcarriers], tf.complex): Channel estimates for all streams from all transmitters.\n  - `r_hat` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_subcarriers, num_subcarriers], tf.complex): Channel estimation error covariance matrices.\n  - `prior` ([batch_size, num_rx, num_streams_per_rx, num_ofdm_symbols, num_effective_subcarriers], tf.complex): Prior of the estimated symbols. If soft-symbol-decisions are requested, the prior contains the quantization noise variance of the prior estimates.\n  - `err_var` ([Broadcastable to shape of `h_hat`], tf.float): Variance of the channel estimation error.\n  - `no` ([batch_size, num_rx, num_rx_ant] or only the first n dimensions, tf.float): Variance of the AWGN.\n\n**Output**\n\nDepending on the value of `detection_method`:\n- If `detection_method` equals \"ml\":\n  - `[batch_size, num_rx, num_streams_per_rx, num_ofdm_symbols, num_effective_subcarriers]`, tf.complex: ML estimates of all the streams.\n  - `[batch_size, num_rx, num_streams_per_rx, num_ofdm_symbols, num_effective_subcarriers]`, tf.float: Log-likelihood ratios (LLRs) for all bits of all streams.\n- If `detection_method` equals \"ls\":\n  - `tf.complex` and `tf.float`: Estimates of all the streams and the corresponding LLRs. Same shape as the input `y`."
"Here is the detailed information of GaussianPriorSource:   \n  \nImplements a antenna array input channel with spatial correlation.\n\nThis layer generates batches of random transmit vectors $\\mathbf{x}\\sim \\mathcal{CN}(\\mathbf{m}, \\mathbf{\\sigma})$ with $\\mathbf{m}\\in \\mathbb{C}^M$ the mean vector and $\\mathbf{\\sigma}\\in \\mathbb{C}^{M\\times M}$ the covariance matrix.\n\nThe transmit vectors are correlated accross antennas in a fully connected way, i.e., by using the following transformation: $\\mathbf{x} = \\mathbf{R}^{\\frac{1}{2}} \\mathbf{u}$\nwhere $\\mathbf{R}^{\\frac{1}{2}}\\in \\mathbb{C}^{M\\times M}$ is such that $\\mathbf{R}^{\\frac{1}{2}}\\left(\\mathbf{R}^{\\frac{1}{2}}\\right)^H = \\mathbf{R}$ and $\\mathbf{u}\\sim \\mathcal{CN}(\\mathbf{0}, \\mathbf{I})$ is an uncorrelated noise vector.\n\nFor uncorrelated transmit vectors, the received transmit vectors can be computed as $\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{w}$\nwhere $\\mathbf{w}\\sim \\mathcal{CN}\\left(\\mathbf{0}, \\mathbf{\\Lambda}\\right)$ is such that $\\mathbf{R} = \\mathbf{H}\\mathbf{R}^{\\frac{1}{2}} + \\mathbf{w}$ where $\\mathbf{R}$ is the covariance matrix of the channel.\n\nMathematically, the channel model is described by: \n \n$\\mathbf{y}\\sim \\mathcal{CN}\\left(\\mathbf{0}, \\mathbf{R} + \\mathbf{\\Lambda}\\right)$\n\nwhere $\\mathbf{R}$ is a positive semi-definite matrix, and $\\mathbf{\\Lambda}$ is a matrix of the same size as $\\mathbf{R}$.\n\nThis channel model is differentiable with respect to $\\mathbf{m}$ and $\\mathbf{\\sigma}$ which makes it possible to implement optimal linear receivers such as LMMSE.\n\n### Parameters\n\n- `dtype (tf.complex64, tf.complex128)`: The data type of the output. Defaults to `tf.complex64`.\n\n### Input\n\n- `batch_size (int)`: The batch size.\n- `num_tx (int)`: The number of antennas for the transmit array.\n- `mean (array of complex, [num_tx]):` The mean vector of the transmitted signals.\n- `lam (array of complex, [num_tx, num_tx]):` The covariance matrix of the transmitted signals.\n\n### Output\n\n- `x (tf.complex with shape [batch_size, num_tx])`:  TensorFlow complex tensor containing the generated transmit vectors.\n  \n**Note: **The link of the source code is [GaussianPriorSource](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#GaussianPriorSource).  \n  "
"Here is the detailed information of [sionna.mapping.QAM2PAM(num_bits_per_symbol, hard_out=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#QAM2PAM):  \n  \nComputes for each element the PAM symbol corresponding to the QAM constellation.  \n  \nThis class is deprecated as functionality has been integrated into Mapping.  \n  \n### Parameters\n\n- **num_bits_per_symbol** (`int`): The number of bits per constellation point, e.g., 4 for QAM16.\n\n- **hard_out** (`bool`): If set to `True`, the layer generates hard-decided symbols instead of soft-symbols. Defaults to `False`.\n\n- **dtype** (`tf.complex64, tf.complex128`,): The dtype of `z`. Defaults to `tf.complex64`. The output dtype is the corresponding real dtype (`tf.float32` or `tf.float64`).\n\n### Input\n\n- **z** (`[..., n]`, `tf.complex`): The QAM-modulated constellation points.\n\n### Output\n\n- **pam_symbols** (`[..., n/2]`, `tf.float`): The PAM symbol representations.  \n  \n  "
"To load the required Sionna components, you can follow these steps:\n\n1. Import the necessary packages: This includes the `os` package for interacting with the operating system, the `requests` package for downloading the Sionna package, and the `tarfile` package for extracting the Sionna package.\n\n```python\nimport os\nimport requests\nimport tarfile\n```\n\n2. Set the environment for CUDA and download Sionna: If CUDA is available, the environment for CUDA is set. The notebook is then configured to use a specific version of the Sionna package. If the package is not already installed, it is downloaded and extracted.\n\n```python\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Use \"\" to use the CPU\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\n# Download Sionna\nsionna_version = \"0.14.0\"\nif \"Sionna\" not in locals() or not isinstance(Sionna, type):\n    sionna_url = f\"https://nvlabs.github.io/sionna/releases/{sionna_version}/sionna.tar\"\n    os.system(f\"wget {sionna_url} -qO sionna.tar\")\n    os.system(\"tar xvf sionna.tar\")\n    os.system(\"rm sionna.tar\")\n    sys.path.insert(0, '.')\n```\n\n3. Import the required Sionna components: This includes the `Dataset` component from the Sionna package.\n\n```python\nfrom sionna.utils import Dataset\n```\n\n4. Load the configured Sionna package: For the notebook to use the newly installed Sionna package, it needs to be imported.\n\n```python\nimport sionna\n```\n\nPlease note that the code snippets provided are directly taken from the context of the Sionna package. If you are using the Sionna package in your own project, you may need to adjust the code to suit your specific requirements."
"To import the necessary modules for Sionna's API and set up the GPU configuration, you can refer to the following steps:\n\n1. Import the necessary modules for Sionna's API. This includes modules like `os`, `requests`, `numpy`, `tensorflow`, `matplotlib.pyplot`, `matplotlib`, `sionna.rt`, `sionna.mpc`, `sionna.ofdm`, `sionna.utils`, `sionna.channel`, and others. Here is how you can do this:\n\n```python\nimport os\nimport requests\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport sionna\nfrom sionna.utils import load_matlab_array, pic, ebnodb2no, sim_ber, QAMSource, expand_to_rank, insert_dims\nfrom sionna.utils import BinarySource, ebnodb2no, sim_ber, QAMSource\nfrom sionna.utils import expand_to_rank, insert_dims\nfrom sionna.channel import cir_to_ofdm_channel, subcarrier_frequencies, OFDMChannel, cir_to_time_channel\nfrom sionna.channel import cir_to_ofdm_channel, subcarrier_frequencies, cir_to_time_channel\nfrom sionna.channel import cir_to_ofdm_channel, cir_to_time_channel\nfrom sionna.ofdm import ResourceGrid, StreamManagement, RX, TX\nfrom sionna.ofdm.estimation import LSW,  least_squares_channel_estimation\nfrom sionna.ofdm.equalization import LinearEqualizer\nfrom sionna.utils import InsertMidDimension, matrix_sqrt\nfrom sionna.utils import BinarySource, ebnodb2no, sim_ber, QAMSource\nfrom sionna.utils import expand_to_rank, insert_dims\nfrom sionna.utils import BinarySource, ebnodb2no, sim_ber, QAMSource\nfrom sionna.utils import expand_to_rank, insert_dims\nfrom sionna.channel import cir_to_ofdm_channel, subcarrier_frequencies, OFDMChannel, cir_to_time_channel\nfrom sionna.channel import cir_to_ofdm_channel, subcarrier_frequencies, cir_to_time_channel\n```\n\n2. Set up the GPU configuration. You can do this by setting the environment variables `CUDA_VISIBLE_DEVICES` and `TF_CPP_MIN_LOG_LEVEL`. Here is how you can do this:\n\n```python\ngpu_number = 0 # Use \"-1\" for the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_number}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n3. Import the Sionna module. This can be done by first adding the Sionna package path to the system path, and then importing the Sionna module. Here is how you can do this:\n\n```python\ntry: # Locally in notebook\n    import sionna\nexcept ImportError as e: # Colab environment\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\nRemember to replace the `gpu_number` with the number of the GPU you want to use. A value of `-1` can be used to use the CPU. \n\nPlease note that the code snippets provided are based on the context provided and may need to be adjusted based on the specific requirements of your project."
"The `CoverageMap` component in ray tracing of Sionna is used to create a coverage map for every transmitter in the scene. It essentially provides the received power from a specific transmitter at every point on a plane. \n\nYou can visualize a coverage map using the `show()` function which opens an interactive figure showing the coverage map. You can specify a batch dimension for independent computations, a min value representing the lowest received power in the coverage map, and add a title for the map.\n\nHere is a sample code snippet to demonstrate how to create and visualize a coverage map:\n\n```python\nimport sionna\nfrom sionna.rt import load_scene, PlanarArray, Transmitter, Receiver\nscene = load_scene(sionna.rt.scene.munich)\nscene.tx_array = PlanarArray(1,1,0.5,0.5,\"tr38901\",\"V\")\nscene.rx_array = scene.tx_array\nscene.add(Transmitter(\"tx\", [-8.22,21.3,26]))\nscene.tx.look_at([40,40,1.5])\nscene.add(Receiver(\"rx\", [50,50,1.5]))\ncoverage_map = scene.coverage_map(num_samples=10e6, smpl_sep=0.5)\ncoverage_map.show()\n```\n\nThis code first imports necessary packages and loads a scene from an .h5 file. Then it sets up the transmitter and receiver arrays, and adds a transmitter and receiver to the scene. Finally, it calculates the coverage map and shows it.\n\nKeep in mind that `CoverageMap` is not a free parameter in ray tracing and its computation complexity is O(num_samples*num_elements_per_sample), which can be very high. Therefore, it's recommended to use it only when necessary."
"Input requirements for decoding with the TurboDecoder:\n1. **llr** (numpy array): An array of floating point Log-Likelihood Ratios (LR). These are the LR values for the received bits from the channel.\n\nOutput formats for decoding with the TurboDecoder:\n- **Hard Decisions (bit_hat)**: This is a binary numpy array. Hard decisions correspond to the most likely bit values and are represented as either 0 or 1. \n- **Soft Decisions (p_hat)**: This is a floating point numpy array. Soft decisions provide the belief of each bit being a '0' or '1', represented by probabilities ranging from 0 to 1.\n\nFor example code snippets provided in the context, we would need to import the `TurboDecoder` class and initiate an object of the class with the necessary parameters including the binary parity-check matrix, ensure_llr= True indicating that LLR values are expected as input, and other parameters such as `encoder`, `num_iter`, `termination`, `convo_n`, `rate`, `trellis`, and `constraint_length` have appropriate default values or would need to be set based on the specific requirements of the turbo code being decoded. \n\nSince we do not have access to the specific values of the parameters like the parity-check matrix or the channel output, we can only provide a general code template as shown in the following snippet:\n\n```python\nfrom sionna.fec.turbo import TurboDecoder\n\n# snr_db is the (no) SNR in decibel, encoder is the ECC encoder used, llr is the numpy array of LLRs\ndecoder = TurboDecoder(encoder=encoder, # BinaryEncoder and other encoders required have to be initialized\n                       ensure_llr=True, \n                       num_iter=6, # number of turbo decoding iterations\n                       termination=False, # It is assumed that the turbo code is not terminated\n                       conv_n=None, # length of the constituent convolutional encoders\n                       rate=None, # rate of the Turbo code, if known. Otherwise, rate will be calculated assuming memory_l and conv_n\n                       trellis=None, # Trellis object of the constituent convolutional codes. If not provided, conv_n and rate are required,\n                       constraint_length=None) # an integer indicating the constraint length of the encoder\n\n# llr is the 2D numpy array of LLRs. The second dimension is used to\n# indicate the received symbols, which is assumed to be 2 in this explanation.\nllr_hat = decoder(llr)\n\n# llr_hat would contain the decoded LLR values, based on the input llr\n```\n\nTo reiterate, the actual parameters for the `TurboDecoder` must be set according to the specific turbo code being decoded, which requires knowledge of the code structure and the simulation conditions."
"Here is the detailed information of function: [sionna.rt.antenna.iso_pattern(theta, phi, slant_angle=0.0, polarization_model=2, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/rt/antenna.html#iso_pattern)\n\nIsotropic pattern without cross-polarization.\n\n### Input\n\n- **theta** (array_like, float): Zenith angles wrapped within [0,\u03c0] [rad].\n- **phi** (array_like, float): Azimuth angles wrapped within [-\u03c0, \u03c0] [rad].\n- **slant_angle** (float): Slant angle of the linear polarization [rad]. A slant angle of zero indicates vertical polarization.\n- **polarization_model** (int, one of [1,2]): Polarization model to be used. Options 1 and 2 refer to polarization_model_1() and polarization_model_2(), respectively. Defaults to 2.\n- **dtype** (tf.complex64 or tf.complex128): Datatype. Defaults to tf.complex64.\n\n### Output\n\n- **c_theta** (array_like, complex): Zenith pattern.\n- **c_phi** (array_like, complex): Azimuth pattern.\n\n**Note:** Returns the electric farfield in the theta and phi directions (equation [(17)](https://nvlabs.github.io/sionna/em_primer.html#equation-htheta) or [(18)](https://nvlabs.github.io/sionna/em_primer.html#equation-hphi) in [3)](https://nvlabs.github.io/sionna/em_primer.html#ref-3)). The patterns are normalized to have a maximum value of one."
"To demonstrate the correct usage of the \"ApplyTimeChannel\" and \"ApplyOFDMChannel\" Keras layers through a simulation or example, we'll need to refer to the specific implementation within the novel package of Python provided by the context. \n\nThe \"ApplyTimeChannel\" layer is designed to simulate the effect of a time-domain channel on the transmitted signal, while the \"ApplyOFDMChannel\" layer simulates the effect of an OFDM channel on the transmitted signal in the frequency domain.\n\nAs per the provided context, the usage of these layers is described in Section 7.4 and 7.5 respectively. In the example provided in Section 7.5, the \"ApplyOFDMChannel\" layer is instantiated with a bandwidth and a null-delivery probability. The \"channel_model\" is an instance of a channel model, which generates channel impulse responses (CIRs) used by the channel layer. \n\nTo use the \"ApplyTimeChannel\" layer, the CIRs generated by the \"channel_model\" need to be converted into time-domain channel responses using the `CIR2TAP` function. This function is crucial for this conversion, as it utilizes the sinc filter for pulse shaping and receiving filtering.\n\nFollowing this process, the \"ApplyTimeChannel\" and \"ApplyOFDMChannel\" layers can be used as they simulate the time and frequency domain channels based on the input bandwidth and delay spread, given the noise variance and null probability for perfect recovery.\n\nNow, whether you want to simulate the effect of a time-domain channel or an OFDM channel on the transmitted signal depends on the scenario you want to model. If the signal is transmitted in the time domain with a certain delay spread, the \"ApplyTimeChannel\" layer should be used. On the other hand, if the signal is transmitted using OFDM, where each sub-carrier experiences a frequency-selective channel, the \"ApplyOFDMChannel\" layer should be used. Do take note that the two layers are interdependent, as the \"ApplyOFDMChannel\" layer requires a time-domain channel response as input.\n\nHere's a simplified example of how to use these layers (the actual parameters would depend on the specific requirement and setup):\n\n```python\n# Import the necessary symbols from the Sionna package\nfrom sionna.channel import ApplyTimeChannel, ApplyOFDMChannel\nfrom sionna.channel import CIRDataset, CIRSampler, CIR2TAP\nfrom sionna.channel import sinc_filter\n\n# Assume we have a channel model already created\n# `channel_model` generates batches of CIRs\n# `bandwidth` and `delay_spread` are initalised with given values\n# Create a CIR sampler with a sinc filter\ncir_sampler = CIRSampler(cir_dataset, bandwidth, sinc_filter)\n# Create a CIR2TAP instance\ncir2tap = CIR2TAP('sinc')\n# Create a ApplyTimeChannel instance\napply_time_channel = ApplyTimeChannel()\n# Create an ApplyOFDMChannel instance\napply_ofdm_channel = ApplyOFDMChannel()\n\n# Now, simulate the usage of the channels\n# `x` is the transmitted signal\n# `no` is the noise variance\ny_time = apply_time_channel([x, cir_dataset, cir_sampler, cir2tap, no])\ny_freq = apply_ofdm_channel([x, cir_dataset, cir_sampler, cir2tap, no])\n```\n\nRemember, the input parameters such as `x, no, cir_dataset` would need to be properly defined and created using the appropriate Sionna APIs. The creation of these parameters is not within the scope of the provided context."
"Computing the log-likelihood ratios (LLRs) with the Demapper class in the Sionna package involves several steps as follows:\n\n1. Import the necessary classes from the Sionna package. These include the `Constellation`, `Mapper`, `Demapper`, and `ComputationalGraph` classes.\n\n2. Declare the required parameters for the constellation. This includes the number of bits per symbol for the QAM constellation, the minimum value of EbNo for simulation, the batch size, and the number of Monte Carlo iterations.\n\n3. Initialize the constellation and mapper using the declared parameters.\n\n4. Define a binary source to generate random data and map it to the constellation.\n\n5. Compute the log-likelihood ratios (LLRs) using the Demapper class. This class implements a demapping function with options for hard-decision and soft-decision appraoches. It takes as input the received samples and the variance of the noise, and returns the LLRs.\n\nHere is a summarized code snippet from the context:\n\n```python\n# Initialize constellation and mapper\nconstellation = sionna.mapping.Constellation(\"qam\", num_bits_per_symbol, trainable=False)\nmapper = sionna.mapping.Mapper(constellation=constellation, trainable=False)\n\n# Compute log-likelihood ratios with the Demapper class\ndemapper = sionna.mapping.Demapper(\"app\", constellation=constellation, trainable=False)\n    llr = demapper([y, no])\n```\n\nIn this code snippet, `num_bits_per_symbol` is the number of bits per constellation point (e.g., 4 for QAM16), `y` is the received samples, and `no` is the noise power spectral density. The `Demapper` instance is used to compute the LLRs."
"To obtain the Channel Impulse Responses (CIRs) in the model, you need to follow these steps:\n\n1. **Set the scene**: Use the Sionna RT API to set up a simple scene with a few transmitters and receivers. The `PlanarArray` class is used to set up transmitters and receivers.\n\n2. **Configure the channel**: Use the Sionna channel API to configure the channel model. The channel model consists of several sub-models, including the propagation path, antenna polarization, antenna patterns, and time evolution of the channels' coefficients. The `CIR` function is used to obtain the channel impulse responses.\n\n3. **Obtain the CIRs**: Use the configured channel model to obtain the channel impulse responses. The `CIR` function is called with the number of time steps and the sampling frequency as inputs. This function returns the CIRs and the corresponding timestamps.\n\nHere is a code snippet that demonstrates these steps:\n\n```python\nscene = load_sionna_scene(sionna.rt.scene.munich)\nscene.tx_array = PlanarArray(num_rows=8,\n                             num_cols=2,\n                             vertical_spacing=0.7,\n                             horizontal_spacing=0.5,\n                             pattern=\"tr38901\",\n                             polarization=\"VH\")\nscene.rx_array = scene.tx_array\nscene.add(Transmitter(\"tx\", [40, 0, 0], [0,0,0]))\nscene.add(Receiver(\"rx\", [50, 10, 1.5], [0,0,0]))\n\nchannel_model = sionna.channel.tr38901.Tr38901(\"ut\", \"bs\", \"los\")\nchannel_model.set_scene(scene)\nchannel_model.set_tx(0)\nchannel_model.set_rx(0)\nnum_time_steps = 100\nsampling_frequency = 1.0e3\na, tau = channel_model([num_time_steps,sampling_frequency])\n```\n\nThis code will set up a basic scene with one transmitter and one receiver, configure the channel model, and then obtain the channel impulse responses."
"Here is the detailed information of List2LLRSimple:   \n  \n[sionna.mimo.List2LLRSimple](https://nvlabs.github.io/sionna/_modules/sionna/mimo/utils.html#List2LLRSimple)  \n\nMIMO List to LLR Simple-Class.\n\nThis class defines a convenience method to apply the function defined by list2_llr_simple to an np.array.  \n  \n**Parameters**\n\n- `A` (G or None): An optional left-singular vector matrix $A\\in\\mathbb{C}^{M\\times K}$.\n- `s` (Optional, 1+D tensor): The noise covariance information, based on which the LLRs are computed.\n- `z` (1+D or 2+D tensor): The (transformed) channel outputs for which the LLRs are computed.\n- `return_s` (bool): Indicates if the (diagonal) covariance matrices should be returned. Default is False.\n- `smoothing` (float): The optional smoothing value to be added to the variances. Default is 0.\n\n**Input**\n\n- `u` (1+D or 2+D tensor, tf.complex): The tensor containing the (unary) LLR values or the tuple $(\\operatorname{llr}_{a}, \\operatorname{llr}_{b})$ if both LLRs are to be computed.\n\n**Output**\n\n- `llr` (with same shape as `u`, tf.float): The tensor containing the (conditional) LLR values.\n- `s` (with same shape as `A` in 2+D, tf.float): The tensor containing the (diagonal) symbol covariance matrices $S\\in\\mathbb{C}^{K}$.\n- `llr_a` (with same shape as `A` in 2+D, tf.float): The tensor containing the (conditional) LLR values.\n- `llr_b` (with same shape as `A` in 2+D, tf.float): The tensor containing the (conditional) LLR values.\n\n**Note:** If you want to use this in Graph mode with XLA, i.e., within a function that is decorated with @tf.function(jit_compile=True), you must set sionna.Config.xla_compat=true. See xla_compat.  \n  \nsource code:\n```python\nclass List2LLRSimple(List2LLR):\n    # pylint: disable=line-too-long\n    r\"\"\"List2LLRSimple(A, s, p, return_s=False, smoothing=0.)\n\n    MIMO List to LLR Simple-Class.\n\n    This class defines a convenience method to apply the function\n    defined by :py:func:`~sionna.mimo.list2_llr_simple` to an np.array.\n\n    Parameters\n    ----------\n    A : G or None\n        An optional left-singular vector matrix :math:`A\\in\\mathbb{C}^{M\\times K}`.\n\n    s : One or Two plus-D tensor\n        The symbol covariance matrices :math:`S\\in\\mathbb{C}^{K}` of the\n        (remaining) codewords after detection. If ``A`` is provided, the shape\n        must be :math:`[M, M]`. If ``A`` is ``None``, ``s`` must have the same\n        shape as ``p``.\n\n    p : One or Two plus-D tensor\n        The symbol probability vectors :math:`\\mathbf{p}\\in\\mathbb{R}^{K}` of the\n        (remaining) codewords after detection. If ``A`` is provided, the shape\n        must be :math:`[M, K]`. If ``A`` is ``None``, ``p`` must have the same shape\n        as ``x``.\n\n    return_s : bool\n        Indicates if the (diagonal) covariance matrices should be returned.\n        Default is `False`.\n\n    smoothing : float\n        The optional smoothing value to be added to the variances.\n        Default is 0.\n\n    Input\n    -----\n    u : One or Two plus-D tensor, tf.complex\n        The tensor containing the (unary) LLR values or the tuple\n        :math:`(\\text{llr}_a, \\text{llr}_b)` if both LLRs are to be computed.\n\n    Output\n    ------\n    llr : Same shape as ``u``, tf.float\n        The tensor containing the (conditional) LLR values.\n\n    s : If ``return_s=True``, same shape as ``A``, tf.float\n        The tensor containing the (diagonal) symbol covariance matrices.\n\n    llr_a : If ``return_s=True``, same shape as ``A``, tf.float\n        The tensor containing the (conditional) LLR values of the\n        first detection candidate.\n\n    llr_b : If ``return_s=True``, same shape as ``A``, tf.float\n        The tensor containing the (conditional) LLR values of the\n        second detection candidate.\n\n    Note\n    ----\n    If you want to use this in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sionna.Config.xla_compat=true``.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n    def __init__(self, A, s, smoothing=0.):\n        super().__init__(A=A,\n                         fcn=list2_llr_simple,\n                         s=s,\n                         p=None,\n                         return_s=False,\n                         smoothing=smoothing)\n```\n```"
"Here is the definition of MaximumLikelihoodDetector: sionna.mimo.MaximumLikelihoodDetector(output, demapping_method, num_streams, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/mimo/detection.html#MaximumLikelihoodDetector)  \n\n```python\nclass MaximumLikelihoodDetector(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"MaximumLikelihoodDetector(output, demapping_method, num_streams, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    MIMO maximum-likelihood (ML) detector\n\n    This layer implements maximum-likelihood (ML) detection\n    for MIMO transmissions. Both ML detection of symbols or bits with either\n    soft- or hard-decisions are supported. The detection process is fully\n    parallelized as it is implemented by simply comparing the computed score\n    for each constellation point (or bit value) as a real number.\n    The decision on the transmitted symbol is then either made by\n    (soft-decisions) or by (hard-decisions) taking the argmax of the score.\n    For a given (transmitted) symbol index :math:`k`, the score is computed as\n\n    .. math::\n        \\hat{k} = \\underset{k \\in \\mathcal{C}}{\\text{argmin}} \\, \\left| y - \\mathbf{h}_k^T\\mathbf{x} \\right|\n\n    where :math:`y` is the received symbol vector, :math:`\\mathbf{x} \\in \\mathcal{C}`\n    is the constellation point set to which :math:`\\mathbf{x}` belongs, and\n    :math:`\\mathbf{h}_k^T\\mathbf{x} = \\mathbf{h}_k^T\\mathbf{s}` for :math:`\\mathbf{s} \\in \\mathcal{C}`.\n    If the input is LLRs, the above equation is replaced by\n\n    .. math::\n        \\hat{k} = \\underset{k \\in \\mathcal{C}}{\\text{argmin}} \\, \\left| L(\\mathbf{y}|\\mathbf{h}_k^T\\mathbf{s}) \\right|\n\n    where the LLR for the :math:`i\\text{th}$ bit of the :math:`k\\text{th}$ symbol is\n    computed as :math:`L(y_i|\\mathbf{h}_k^T\\mathbf{s}) = 2\\left[s_k h_{k,i} - \\log\\left(1 + \\exp\\left(-2s_k\\right)\\right) \\right]`\n    for :math:`y_i` the :math:`i\\text{th}$ bit-channel value of the :math:`k\\text{th}$ symbol.\n    This formual allows for the use of LLR values as input, e.g., after a\n    demapping process.\n\n    Parameters\n    ----------\n    output : One of [\"bit\", \"symbol\"], str\n        Specifies the type of output, either LLRs for bits or logits for symbols.\n\n    demapping_method : One of [\"app\", \"maxlog\"], str\n        The demapping method used.\n\n    num_streams : tf.int\n        Number of transmitted streams\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the detector computes hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of ``y``. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    ------\n    (y, h, s) :\n        Tuple:\n\n    y : [...,M], tf.complex\n        1+D tensor containing the received signals\n\n    h : [...,M,num_streams], tf.complex\n        2+D tensor containing the channel matrices\n\n    s : [...,M,M], tf.complex\n        2+D tensor containing the noise covariance matrices\n\n    Output\n    ------\n    One of:\n\n    : [...,num_streams,num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream, if ``output`` equals \"bit\".\n\n    : [...,num_streams,num_points], tf.float or [...,num_streams], tf.int\n       Logits or hard-decisions for constellation symbols for every stream, if ``output`` equals \"symbol\".\n       Hard-decisions correspond to the symbol indices.\n\n    Note\n    ----\n    If you want to use this layer in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sionna.Config.xla_compat=true``.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n\n    def __init__(self,\n                 output,\n                 demapping_method,\n                 num_streams,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        self._output = output\n        self._demapping_method = demapping_method\n        self._hard_out = hard_out\n\n        # Create constellation object\n        self._constellation = Constellation.create_or_check_constellation(\n                                                        constellation_type,\n                                                        num_bits_per_symbol,\n                                                        constellation,\n                                                        dtype=dtype)\n\n        # Number of bits per symbol\n        self._num_bits_per_symbol = self._constellation.num_bits_per_symbol\n\n        # Symbol indices for which the min or max value is taken\n        self._min_or_max= Pminmax(self._output, self._demapping_method,\n                                    num_streams, self._num_bits_per_symbol,\n                                    dtype=dtype)\n\n        if self._output == \"bit\":\n            self._compute_llr = ComputeLLR(\"maxlog\",\n                                            num_streams,\n                                            self._num_bits_per_symbol,\n                                            hard_out,\n                                            dtype=dtype)\n        elif self._output == \"symbol\":\n            self._stream_ind = tf.range(0, tf.convert_to_tensor(num_streams),\n                                        dtype=tf.int32)\n            self._constellation_indices = tf.cast(self._constellation._indices,\n                                                dtype=tf.int32)\n            if hard_out is False: # Instantiate object to compute soft-values\n                self._compute_soft = SymbolMLScore(   num_streams,\n                                                        self._num_bits_per_symbol,\n                                                        dtype=dtype)\n            # The object responsible for the determination of the symbol indices\n            # with the highest (soft-) scores\n            self._determine_best_indices = \\\n                                DetermineBestIndices(self._output,\n                                                    self._stream_ind,\n                                                    self._constellation_indices,\n                                                    hard_out,\n                                                    dtype=dtype)\n\n    def call(self, inputs):\n        y, h, s = inputs\n\n        # Hints to reduce rank\n        batch_dims = len(y.shape.as_list())-1\n        no = expand_to_rank(tf.linalg.matrix_transpose(s),\n                                            tf.rank(y),\n                                            batch_dims)\n\n        # Compute scores\n        if self._output == \"bit\":\n            if self._demapping_method == \"app\":\n                # app demapping already provides the symbol indices for\n                # each stream. We cannot use this for determine the best\n                # stream set (used in the multi-cell MIMO detector) as we\n                # do not know the stream indices.\n                scores = app(y, h, no, self._hard_out)\n            else:\n                raise ValueError(\"Only demapping_method 'app' is supported\")\n        else:\n            scores = tf.transpose(-rdm(h, no, \"maxlog\", self._hard_out),\n                                [0, 2, 1])\n\n        # Compute LLRs or hard-decisions\n        if self._output == \"bit\":\n            llr = self._compute_llr((scores, self._num_bits_per_symbol))\n            return llr\n        else:\n            # Determine the best stream set for all batch examples\n            best_streams = self._determine_best_indices(scores)\n            return self._constellation.indices_to_logits(best_streams)\n```"
"Here is the detailed information of generate_5g_ranking: (You can find the source code in the sionna.channel.utils module)\n\nReturns a batch of random MIMO ranking vectors following the 5G standard [ETSI 3GPP TS 38.141 \u201cBase Station (BS) conformance testing\u201d, v16.0.0, 2020-07.].\n\nThe 5G standard [ETSI 3GPP TS 38.141 \u201cBase Station (BS) conformance testing\u201d, v16.0.0, 2020-07.] specifies that for each batch of UTs (User Terminals), the UT antenna panel arrays are configured differently. This is achieved by permutating the antenna positions differently for each batch. The maximum number of served UTs per BS is 16, which can be configured into multiple groups of 12, 8, 4, or 1 UTs, respectively. This parameter, called NumberOfUTs, can be either the BS parameter max-nr-of-served-UTs or the carrier parameter num-served-ut. The actual rank 1 panel arrays are obtained by selecting the first NumberOfUTs elements out of the list of 16 panel arrays. This function implements this procedure.\n\nNote that the panel arrays are transposed for use with the sionna.channel.tr38901.Portal which expects an array of shape  consisting of  serving  antenna  ports  and  stream management  entities  (Rx  or  RxD)  in  that  order.\n\n**Parameters**\n\n- `bs_direction` (str): Specified the bs array (base station), either \"uplink\" or \"downlink\".\n- `batch_size` (int): Specifies the number of UTs (User Terminals) being served.\n- `ue_rank` (int): Specifies the UT rank. Must be smaller or equal to the number of served UTs.\n- `bs_rank` (int): Specifies the BS rank.\n- `num_streams_per_tx`: Specifies the number of streams.\n- `include_digital_beamforming` (bool): If `True`, the UT and BS antenna arrays are both composed of either one or two dual-polarized antenna elements with antenna pattern `3GPP38542Antenna`. Otherwise, single antenna elements with pattern `3GPP38541Antenna` are used. Defaults to `False`.\n- `return_rx_orientations` (bool): If `True`, return the receiver orientation. Defaults to `False`.\n\n**Input**\n\n- `batch_size` (int): The rank matching parrern is sampled for `batch_size` number of UTs.\n\n**Output**\n\n- `a_bs` ([batch_size, num_streams_per_tx, num_rx_ant, num_tx_ant], tf.float): Tensor containing the BS antenna array for each UT.\n- `a_ue` ([batch_size, num_streams_per_tx, num_rx_ant, num_tx_ant], tf.float): Tensor containing the UT antenna array for each UT.\n- `rx_orientations` ([batch_size, 3], tf.float): Tensor containing the orientation of the receivers. This output is only returned if `return_rx_orientations` is set to `True`.\n\n**Note:** The output of this function is used to configure an instance of  sionna.channel.tr38901.Portal, and is not intended to be used directly within a simulation loop."
"To run the channel modeling in Sionna, follow these steps:\n\n1. Import the necessary modules and set up the environment:\n\n```python\nimport os\nimport sionna\nfrom sionna.nr import NR_SCENARIO\n```\n\n2. Define the simulation scenario:\n\n```python\n# Load the scene for the RadioScape module\nscene = load_scene(sionna.rt.munich)\n\n# Set the carrier frequency [Hz]\nfrequency = 2.14e9\n\n# Set the O2 carrier frequency, antenna mode, and Mi speed\no2_carrier_frequency = 2.6e9\no2_antenna_mode = \"COLUMNAR\"\nmi_speed = 10.0\n\n# Set the O1O2Channel channel model. We use the CDL model here.\nchannel_model = sionna.channel.tr38901.CDL(\n    o1_model=\"A\",\n    o2_model=\"D\",\n    carrier_frequency=frequency,\n    o2_carrier_frequency=o2_carrier_frequency,\n    delay_spread=300e-9,\n    los_angle_of_arrival=sionna.channel.tr38901.PITCH45,\n    min_non_los_angle_of_departure=PI/3,\n    max_non_los_angle_of_departure=PI/3\n)\n\n# Create the Mi channel model\nmi_model = sionna.channel.tr38901.MI(\n    scene=scene,\n    frequency=frequency,\n    speed=mi_speed,\n    num_samples=64,\n    los_factor=1.0\n)\n\n# Create the Sionna channel model\nchannel_model = sionna.channel.tr38901.Sionna(\n    channel_model=channel_model,\n    mi_model=mi_model,\n    resource_grid=rg\n)\n```\n\n3. Generate the batches of random realizations of random variables:\n\n```python\n# Generate batch of random variables\nbatch_size = 100\nrx_position = tf.zeros([batch_size, 1, 3])\nrx_orientations = tf.zeros([batch_size, 1, 2])\npath_coefficients, paths, paths_mi = channel_model(batch_size, num_time_steps, sampling_frequency, rx_position, rx_orientations)\n```\n\n4. Use the channel model for simulations:\n\n```python\n# Instantiate the OFDM channel object\nofdm_channel = sionna.channel.OFDM(channel_model, resource_grid, normalize_channel=True)\n\n# Generate the OFDM channel frequency responses\nh_freq = ofdm_channel([path_coefficients, paths, num_time_steps])\n```\n\n5. Run further simulations as needed."
"Here is the detailed information of load_alist: [sionna.channel.load_alist(path)](https://nvlabs.github.io/sionna/_modules/sionna/channel/utils.html#load_alist)  \n  \nLoad CHANNEL_MODEL_ALIST from file.\n\nThe file loaded from path should contain a Python variable CHANNEL_MODEL_ALIST defining a list of all possible channel realizations. Such a file may be generated by the scmi2alist script provided in the official 3GPP 38.901 specification.\n\nFor example:  \n```python\nCHANNEL_MODEL_ALIST = [\n    {\n        'a': [ 1.6515372038678528,\n              1.5348292355960351,\n              1.9722796769027204,\n              1.38915765232011,\n              1.2392750040601916,\n              1.2195482722570694,\n              1.7646221930490963,\n              1.654269915046068,\n              1.5057156510425004,\n              1.7121584387455864],\n        'phi': [ 3.926991,\n                0.0,\n                3.141593,\n                3.926991,\n                3.447910,\n                4.319553,\n                2.615553,\n                3.363380,\n                4.712389,\n                1.9828308],\n        'tau':  [0.0,\n                1.0,\n                2.0,\n                3.0,\n                4.0,\n                5.0,\n                6.0,\n                7.0,\n                8.0,\n                9.0]\n    },\n    ...\n]\n```  \n**Notes:ALIST files generated with different tools may have different formats. scmi2alist expects the following format: $a_0,...,a_{N-1}$, $\\\\varphi_0, \\varphi_{N-1}$, $\\\\tau_0, \\\\tau_{N-1}$.  \n[a_0,...,a_{N-1}] refers to the path gain, $\\\\varphi_0, \\varphi_{N-1}$ to the AoD, and $\\\\tau_0, \\\\tau_{N-1}$ to the delays.  \nThe delays are assumed to be non-negative and normalized to the smallest value. The total sum of the path gains does not need to be 1, scmi2alist normalizes these factors during the loading.  \nThe resulting CHANNEL_MODEL_ALIST can then be used with the CIRDataset.  \nGenerated with scmi2alist v.0.1.1.  \n  \n**Input**\n\n- `path` (str): The path to the file from which to load the channel model alist.\n\n**Output**\n\n- `CHANNEL_MODEL_ALIST` (list): A list of dictionaries, each representing a channel realization. Each dictionary contains the following key-value pairs:\n  - `'a'`: Path gains $a_m$ for $m=0,\\dots,M-1$ as defined in (7) [Sionna-API-Channel-Model](https://nvlabs.github.io/sionna/channel/channel_model.html#)\n  - `'tau'`: Path delays (in second) $\\\\tau_m$ for $m=0,\\dots,M-1$ as defined in (7) [Sionna-API-Channel-Model](https://nvlabs.github.io/sionna/channel/channel_model.html#)\n  - `'phi'`: Path angles (in rad) $\\\\varphi_m$ for $m=0,\\dots,M-1$ as defined in (7) [Sionna-API-Channel-Model](https://nvlabs.github.io/sionna/channel/channel_model.html#)  \n  loadModel( ): returns CHANNEL_MODEL_ALIST[0] and CHANNEL_MODEL_ALIST[1].  \n  \f\nHere is the source code of load_alist:  \n```python\ndef load_alist(path):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Load CHANNEL_MODEL_ALIST from file.\n\n    The file loaded from ``path`` should contain a Python variable\n    ``CHANNEL_MODEL_ALIST`` defining a list of all possible channel\n    realizations. Such a file may be generated by the ``scmi2alist`` script\n    provided in the official 3GPP 38.901 specification.\n\n    For example:\n\n    .. code-block:: Python\n\n        CHANNEL_MODEL_ALIST = [\n            {\n                'a': [ 1.6515372038678528,\n                      1.5348292355960351,\n                      1.9722796769027204,\n                      1.38915765232011,\n                      1.2392750040601916,\n                      1.2195482722570694,\n                      1.7646221930490963,\n                      1.654269915046068,\n                      1.5057156510425004,\n                      1.7121584387455864],\n                'phi': [ 3.926991,\n                        0.0,\n                        3.141593,\n                        3.926991,\n                        3.447910,\n                        4.319553,\n                        2.615553,\n                        3.363380,\n                        4.712389,\n                        1.9828308],\n                'tau':  [0.0,\n                        1.0,\n                        2.0,\n                        3.0,\n                        4.0,\n                        5.0,\n                        6.0,\n                        7.0,\n                        8.0,\n                        9.0]\n            },\n            {\n                'a': [ 1.5008780301688843,\n                      1.2508390796016688,\n                      1.1253025963853281,\n                      1.0007551663735526,\n                      1.2508390796016688,\n                      0.7505862262801646,\n                      1.1253025963853281,\n                      0.8752170670706289,\n                      1.3763006631044777,\n                      1.0015120216505198],\n                'phi': [ 0.0,\n                        0.0,\n                        0.0,\n                        0.0,\n                        0.0,\n                        2.9678710453853227,\n                        3.665631550064151,\n                        4.319553289303762,\n                        4.712388980012232,\n                        5.274141218268087],\n                'tau': [ 0.0,\n                        0.5777621520510649,\n                        1.0636263345364885,\n                        1.4773449738305203,\n                        1.8971571725051511,\n                        0.99,\n                        2.926891430499857,\n                        3.816653738158366,\n                        5.10284945667077,\n                        6.762587163062802]\n            },\n            {\n                'a': [ 1.3166851268027106,\n                      1.2635349490913262,\n                      1.9593853989771524,\n                      1.4564825539767934,\n                      1.307609681640137,\n                      1.2878829498376464,\n                      1.7646221930490963,\n                      1.654269915046068,\n                      1.5057156510425004,\n                      1.7121584387455864],\n                'phi': [ 3.141592653589793,\n                        0.0,\n                        3.141592653589793,\n                        0.0,\n                        3.141592653589793,\n                        3.3161255787899234,\n                        2.9844904431867623,\n                        3.730796156125217,\n                        4.712388980012232,\n                        3.576450219267344],\n                'tau': [ 0.0,\n                        1.0,\n                        2.0,\n                        3.0,\n                        4.0,\n                        5.0,\n                        6.0,\n                        7.0,\n                        8.0,\n                        9.0]\n            },\n            {\n                'a': [ 1.250726194858543,\n                      1.1357289658328394,\n                      1.2831087286017627,\n                      1.054803967672914,\n                      1.3166851268027106,\n                      0.8995224923032089,\n                      1.2831087286017627,\n                      1.4364821531486053,\n                      1.6164769388003134,\n                      1.7121584387455864],\n                'phi': [ 3.9269908169872414,\n                        0.0,\n                        3.141592653589793,\n                        0.0,\n                        3.3161255787899234,\n                        3.4634472820185185,\n                        3.054803967672914,\n                        4.712389980012232,\n                        5.672320552278805,\n                        6.76318518632085],\n                'tau': [ 0.0,\n                        1.0,\n                        2.0,\n                        3.0,\n                        4.0,\n                        5.0,\n                        6.0,\n                        7.0,\n                        8.0,\n                        9.0]\n            },\n            {\n                'a': [ 1.469632133738701,\n                      1.3031141854041944,\n                      1.0394909125247334,\n                      1.469632133738701,\n                      1.1852194691088979,\n                      1.469632133738701,\n                      0.8311572901520356,\n                      1.469632133738701,\n                      1.1852194691088979,\n                      1.469632133738701],\n                'phi': [ 0.0,\n                        3.141592653589793,\n                        0.0,\n                        3.141592653589793,\n                        0.0,\n                        3.141592653589793,\n                        0.0,\n                        3.141592653589793,\n                        0.0,\n                        3.141592653589793],\n                'tau': [ 0.0,\n                        1.0,\n                        2.0,\n                        3.0,\n                        4.0,\n                        5.0,\n                        6.0,\n                        7.0,\n                        8.0,\n                        9.0]\n            },\n            {\n                'a': [ 1.2844221605227543,\n                      1.1930050060182027,\n                      1.1253025963853281,\n                      1.0743315501306966,\n                      1.1930049482313485,\n                      1.3547268035195524,\n                      1.1253025963853281,\n                      1.1930049482313485,\n                      1.516860912182175,\n                      1.3579779951336227],\n                'phi': [ 0.0,\n                        0.0,\n                        0.0,\n                        0.0,\n                        0.0,\n                        0.0,\n                        3.3161255787899234,\n                        3.3161255787899234,\n                        3.3161255787899234,\n                        3.576450219267344],\n                'tau': [ 0.0,\n                        1.0,\n                        2.0,\n                        3.0,\n                        4.0,\n                        5.0,\n                        6.0,\n                        7.0,\n                        8.0,\n                        9.0]\n            },\n            {\n                'a': [ 1.3995264983648034,\n                      1.268825628042511,\n                      1.9722796769027204,\n                      1.5348292355960351,\n                      1.38915765232011,\n                      1.2195482722570694,\n                      1.7646221930490963,\n                      1.654269915046068,\n                      1.5057156510425004,\n                      1.7121584387455864],\n                'phi': [ 3.926991,\n                        0.0,\n                        3.141593,\n                        3.926991,\n                        3.447910,\n                        4.319553,\n                        2.615553,\n                        3.363380,\n                        4.712389,\n                        1.9828308],\n                'tau': [ 0.0,\n                        1.0,\n                        2.0,\n                        3.0,\n                        4.0,\n                        5.0,\n                        6.0,\n                        7.0,\n                        8.0,\n                        9.0]\n            },\n            {\n                'a': [ 1.5204221503621147,\n                      1.36387912849918,\n                      1.824605345004241,\n                      1.2758039401943893,\n                      1.1656200398971502,\n                      1.1512191645640077,\n                      1.654269915046068,\n                      1.6515372038678528,\n                      1.5057156510425004,\n                      1.7121584387455864],\n                'phi': [ 3.3161255787899234,\n                        0.0,\n                        3.141592653589793,\n                        3.3161255787899234,\n                        3.754026376292578,\n                        4.607957555133518,\n                        2.8797932657905434,\n                        3.926991,\n                        5.672320552278805,\n                        5.274141218268087],\n                'tau': [ 0.0,\n                        1.0,\n                        2.0,\n                        3.0,\n                        4.0,\n                        5.0,\n                        6.0,\n                        7.0,\n                        8.0,\n                        9.0]\n            },\n            {\n                'a': [ 1.4330327136446533,\n                      1.3031141854041944,\n                      1.1253025963853281,\n                      1.36387912849918,\n                      1.2166188042058883,\n                      1.1968929278187866,\n                      1.3875314980227518,\n                      1.68231647304213,\n                      1.5057156510425004,\n                      1.7121584387455864],\n                'phi': [ 0.0,\n                        0.0,\n                        0.0,\n                        0.0,\n                        0.0,\n                        0.0,\n                        3.3161255787899234,\n                        3.3161255787899234,\n                        3.3161255787899234,\n                        3.576450219267344],\n                'tau': [ 0.0,\n                        1.0,\n                        2.0,\n                        3.0,\n                        4.0,\n                        5.0,\n                        6.0,\n                        7.0,\n                        8.0,\n                        9.0]\n            },\n            {\n                'a': [ 1.250726194858543,\n                      1.1357289658328394,\n                      1.2831087286017627,\n                      1.054803967672914,\n                      1.3166851268027106,\n                      0.8995224923032089,\n                      1.2831087286017627,\n                      1.4364821531486053,\n                      1.6164769388003134,\n                      1.7121584387455864],\n                'phi': [ 3.9269908169872414,\n                        0.0,\n                        3.141592653589793,\n                        0.0,\n                        3.3161255787899234,\n                        3.4634472820185185,\n                        3.054803967672914,\n                        4.712389980012232,\n                        5.672320552278805,\n                        6.76318518632085],\n                'tau': [ 0.0,\n                        1.0,\n                        2.0,\n                        3.0,\n                        4.0,\n                        5.0,\n                        6.0,\n                        7.0,\n                        8.0,\n                        9.0]\n            }\n        ]\n\n    import os\n    import json\n    # Check that path exists and files is not empty\n    assert os.path.exists(path), \"Path does not exist.\"\n    assert os.path.getsize(path)>0, \"Channel model file is empty.\"\n\n    # Load channel model files\n    channel_model = json.load(open(path, 'r'))\n    CHANNEL_MODEL_ALIST = channel_model['model']['alists']\n\n    return CHANNEL_MODEL_ALIST\n```"
"Here are some useful links of it:\n\n[Run in Google Colab](https://colab.research.google.com/github/nvlabs/sionna/blob/main/examples/5G_NR_PUSCH.ipynb)\n\n[View on GitHub](https://github.com/nvlabs/sionna/blob/main/examples/5G_NR_PUSCH.ipynb)\n\n[Download notebook](https://nvlabs.github.io/sionna/examples/5G_NR_PUSCH.ipynb)"
"The `cameras` property in the context of Sionna's scene module refers to the collection of cameras that have been defined in a given scene. A scene can be understood as the entire environment or setting that the user is simulating. Each camera in the scene defines a particular view or perspective for this environment. \n\nThe cameras can be set and accessed like so:\n```python\nscene.cameras['name_of_camera']\nscene.cameras.needed_for_rendering\n```\n\nThe `cameras` property is crucial for rendering the scene, as it contains the specifications for the viewpoints of the cameras, which in turn, define what the final render or output of the scene will look like from these various perspectives.\n\nCameras can have various types including OrthographicCamera, PerspectiveCamera, and look_at cameras. Each type is characterized by different properties. For instance, the OrthographicCamera has properties like 'x_range', 'y_range', 'z_range', 'center', and 'look_at'. The PerspectiveCamera has properties like 'fov', 'aspect_ratio', 'focal_length', 'principal_point', 'center', and 'up'. \n\nThe functionality of the `cameras` property mainly includes returning the appropriate camera objects for use in the scene rendering process. The property can also be used to access essential cameras that are required for the rendering. This property is not directly involved in the simulation process but is crucial for the final step of rendering the scene."
"Here is the detailed information of RaisedCosineFilter:   \n  \n[sionna.signal.RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/signal/filter.html#RaisedCosineFilter)  \n\nLayer for applying a raised-cosine filter of length K to an input x of length N.\n\nThe raised-cosine filter is defined by $y[n] = \\begin{cases} \\frac{1}{T} \\left(1 + \\cos\\left(\\frac{\\pi t}{T}\\right)\\right) h_\\text{rc}[n] \\\\ \\frac{1}{T} \\left(\\sin\\left(\\frac{\\pi t}{T}\\right)\\frac{2\\beta}{\\pi}\\right)h_\\text{rc}[n] \\\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\text{for } -\\frac{T}{2}\\leq t \\leq \\frac{T}{2} \\\\ 0 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\text{else} \\end{cases}$\n\nwhere $h_\\text{rc}[n] = \\begin{cases}  \\frac{1}{T} \\left(1 - \\beta + \\beta \\cos\\left(\\frac{2\\pi n}{T}\\right) \\right) \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\text{for } -\\frac{T}{2}\\leq n \\leq \\frac{T}{2} \\\\ 0 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\"
"Here is the detailed information of sionna.signal.Upsampling:   \n  \n[sionna.signal.Upsampling(samples_per_symbol, offset=0, num_symbols=None, centered=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/signal/upsampling.html#Upsampling)\n\nUpsamples a given tensor by inserting zeros.\n\nThe upsampling factor is defined as samples_per_symbol. If the number of samples to upsample is not given such as num_samples, it is inferred from the input tensor x.\n\n```python\nus = Upsampling(samples_per_symbol, offset, num_symbols, centered, dtype, **kwargs)\nx_us = us(x)\n```\n\n#### Parameters\n\n- `samples_per_symbol` (int): The upsampling factor. Must be a positive integer.\n- `offset` (int, default: 0): The index of the first sample of the input to the center of the output block.\n- `num_symbols` (int, default: None): The number of symbols to upsample. If None, the maximum possible number of symbols is inferred from the input tensor and other parameters. Otherwise, the specified value must be equal to the total number of samples in x, plus the offset, plus the required number of zero samples to ensure that the total number of samples is a multiple of samples_per_symbol.\n- `centered` (bool, default: False): If True, the filter is centered on the sample with index offset. In this case, the total number of samples is increased by (samples_per_symbol-1) to ensure that the last sample is also of index offset.\n- `dtype` (tf.DType, default: tf.complex64): The dtype of the output. Defaults to tf.complex64. The dtype of the output is the same as the dtype of the input x.\n\n#### Input\n\n- `x` ([..., N], tf.DType): The tensor to upsample. The last dimension is interpreted as the number of samples per symbol.\n\n#### Output\n\n- `y` ([..., M], tf.DType): The upsampled tensor. The last dimension is equal to samples_per_symbol * num_symbols.\n\n### Properties\n\n**Property: `samples_per_symbol`**\nGet the sampling rate.\n\n**Property: `samples_per_symbol`**\nGet the upsampling factor.\n\n**Property: `num_samples`**\nGet the total number of samples to upsample.\n\n**Property: `num_symbols`**\nGet the number of symbols to upsample.\n\n**Property: `offset`**\nGet the upsampling offset.\n\n**Property: `centered`**\nGet if the filter is centered.\n\n**Property: `upsampling_factor`**\nGet the upsampling factor."
"The `polarization_model_1` and `polarization_model_2` functions in the Sionna wireless simulation package are designed to handle polarization in radio propagation modeling.\n\nThe `polarization_model_1` function implements the first polarization model from 3GPP TR 38.901, which assumes that the transmitter and receiver are equipped with dual cross-polarized antenna arrays. This model supports both vertical and horizontal polarizations, and optionally includes a correlation model to capture the cross-polarization correlation. The function takes several inputs including the frequencies, batch size, and various parameters related to the antenna arrays and their polarization. It outputs the transmitted and received correlation matrices, the transmitted and received covariance matrices, and the signal-to-noise ratio.\n\nThe `polarization_model_2` function also uses the same antenna array configuration but computes the polarization differently. It uses a polarization filter defined by a transmit/receive polarization direction and a polarization mode. The function outputs similar matrices as the first model, but does not support the optional cross-polarization correlation model.\n\nUsage of these functions is indicated in the 3GPP 5G NR module of the Sionna package, which provides the polarization models as options when configuring the radio propagation channel.\n\nHere is a code snippet demonstrating how to use these functions:\n\n```python\nfrom sionna.channel.tr38901 import polarization_model_1, polarization_model_2\n\n# Example: Use the first polarization model\ntransmit_polarization = \"vertical\"\nreceive_polarization = \"vertical\"\ncorrelation_model = \"single\"\nfrequencies = [3e9, 10e9] # in Hz\nbatch_size = 1\nnum_ant = 4\nnum_streams_per_tx = 2\nnum_rx = 1\n\n# Compute the polarization model\nG, R_t, R_r, P_t, P_r = polarization_model_1(transmit_polarization,\n                                              receive_polarization,\n                                              correlation_model,\n                                              num_ant,\n                                              num_streams_per_tx,\n                                              num_rx,\n                                              batch_size,\n                                              frequencies)\n```\n\nIn this code, replace the parameters with the specific values for your scenario."
"Here is the detailed information of Mapper:   \n  \n[sionna.ofdm.Mapper(constellation, _check_constellation=True, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/mapping.html#Mapper)  \n\nMaps a tensor of binary values to a tensor of symbols from a constellation. This class was proposed in the Keras multi-dimensional mapper example.\n\n**Parameters**\n\n- `constellation` (Constellation) : A Constellation object.\n- `dtype` (One of [tf.complex64, tf.complex128]): The dtype of the output. Defaults to tf.complex64.\n- `**kwargs` : Layer-specific kwargs.\n\n**Input**\n\n- `[batch_size, num_streams_per_port, num_data_symbols]` (tf.float): A tensor of binary values.\n\n**Output**\n\n- `[batch_size, num_streams_per_port, num_data_symbols, dtype]`: Mapped symbols.\n\n**Property**\n- `constellation`: The constellation object."
"The `LDPC5GEncoder` class from the Sionna library is designed to perform encoding of information bits into LDPC codewords according to the 5G New Radio (NR) LDPC scheme. The constructor for this class takes several parameters, which are outlined below:\n\n- `k` (int): This is the number of information bits, which is the total number of bits in the input sequence that are not parity bits. For 5G, the number of information bits per codeword varies between 132 and 52812 for different LDPC codes.\n\n- `n` (int): This is the total number of codeword bits, which is the length of the output sequence. In the 5G context, the total number of codeword bits can be  up to 5,120 for certain LDPC codes.\n\n- `num_bits_per_symbol` (int, 2 or 4): This parameter specifies the number of bits per  QAM symbol. For 5G, it can be either 2 or 4. It is used to determine the base modulation scheme for the data.\n\n- `dtype` (tf.DType, tf.float32): This defines the output data type of the layer. It defaults to `tf.float32`, but can be changed if necessary.\n\nThe constructor has several other key parameters that are not outlined in the question, including `output_dtype`, `coderate`, `trainable`, `remove_pcm_id`, and `broadcast_hard_decoded_c`. The `output_dtype` parameter is used to specify the output dtype of the layer. The `coderate` parameter allows the user to specify the desired 5G coderate of the encoder. The `trainable` parameter, if set to `True`, allows the flexibility of using trainable parity-check matrices. The `remove_pcm_id` parameter is used to indicate if the rate-matching indicator and zero-bit patterns should be removed. The `broadcast_hard_decoded_c` parameter specifies if the internal parity-check matrix should be broadcast in decoding.\n\nPlease note that the provided context does not include the entire parameter list for the `LDPC5GEncoder` constructor. For the most accurate and complete usage, the parameters that are not included in this answer should be referenced directly from the Sionna documentation or source code."
"1. 'complex2real_vector': This function translates a complex-valued vector into its real-valued equivalent. Given a complex-valued vector y, the real and imaginary parts are separated and combined into a single real-valued vector by stacking them together. The real and imaginary parts of a complex-valued vector are typically associated with the dimensions of a real-valued vector. \n\n2. 'real2complex_vector': This function performs the reverse operation of 'complex2real_vector'. It translates a real-valued vector into its complex-valued equivalent. The real and imaginary parts are separated from each other and combined into a complex-valued vector by pairing them together. \n\n3. 'complex2real_matrix': Translates a complex-valued matrix into its real-valued equivalent. The real and imaginary parts of the complex-valued matrix are handled in the same way as for a complex-valued vector. They are separated and stacked together to form a real-valued matrix.\n\n4. 'real2complex_matrix': This function is the complement of 'complex2real_matrix'. It translates a real-valued matrix into its complex-valued equivalent. The real and imaginary parts of the matrix are handled by pairing them together to form a complex-valued matrix.\n\n5. 'complex2real_covariance': Translates a complex-valued covariance matrix into its real-valued equivalent. Similar to the vector operations, the real and imaginary parts of the covariance matrix are separated and stacked together to form a real-valued matrix.\n\n6. 'real2complex_covariance': This function is the inverse operation of 'complex2real_covariance'. It translates a real-valued covariance matrix into its complex-valued equivalent. The real and imaginary parts of the matrix are handled by pairing them together to form a complex-valued matrix.\n\n7. 'complex2real_channel': Translates a complex-valued discrete channel into its real-valued equivalent. Similar to the vector operations, the real and imaginary parts of the channel are handled by separating them and stacking them together.\n\n8. 'real2complex_channel': This function is the reverse operation of 'complex2real_channel'. It translates a real-valued discrete channel into its complex-valued equivalent. The real and imaginary parts are handled by pairing them together."
"Here is the detailed information of FlatFadingChannel:   \n  \n[sionna.channel.FlatFadingChannel(num_tx_ant, num_rx_ant, spatial_corr=None, add_awgn=True, return_channel=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/channel/flat_fading_channel.html#FlatFadingChannel)\n\nGenerate a batch of random flat-fading channel matrices with optional spatial correlation.\n\nThe channel matrices  $\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$  are generated by this layer assuming the following vectorized channel model:\n\n$\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^{M}$  is the received signal vector, $\\mathbf{x}\\in\\mathbb{C}^{K}$ is the vector of transmitted symbols, and $\\mathbf{n}\\in\\mathbb{C}^{M}$ is a vector of noise samples. The noise $\\mathbf{n}$ is Gaussian distributed, has full rank, and a covariance matrix of $\\mathbf{I}$. The channel matrix $\\mathbf{H}$ has singular value decomposition $\\mathbf{H} = \\mathbf{U}\\boldsymbol{\\Sigma}\\mathbf{V}^{\\mathsf{H}}$, where $\\mathbf{U}\\in\\mathbb{C}^{M\\times M}$  and  $\\mathbf{V}\\in\\mathbb{C}^{K\\times K}$ are unitary, and $\\boldsymbol{\\Sigma}\\in\\mathbb{C}^{M\\times K}$ is of full rank. It is assumed that $\\textrm{rank}(\\boldsymbol{\\Sigma})=K$ which implies that $\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$  and, in particular, that $M\\geq K$.\n\nIf the option add_awgn is selected, then white additive noise as described above is added. Note that this requires generating channel outputs $y$ with the AWNO function, instead of directly generating the channel matrices as done by this layer. Also note that adding noise in the complex-baseband representation is equivalent to adding noise in the received signal vector in the representation with sinc-shaped pulses.\n\nThe channel matrices can optionally be rendered to have spatial correlation. The spatial correlation is controlled by the spatial_corr parameter.\n\n**Parameters**\n\n- `num_tx_ant` (int): Number of transmit antennas.\n- `num_rx_ant` (int): Number of receive antennas.\n- `spatial_corr` (SpatialCorrelation, None): An instance of SpatialCorrelation, such as  `LMMSEChannelModel` or `KroneckerModel`, or None. Defaults to None.\n- `add_awgn` (bool): Indicates if AWGN (additive white Gaussian noise) should be added to the channel output. Defaults to True.\n- `return_channel` (bool): If set to True, the channel realizations are returned. Defaults to False.\n- `dtype` (tf.DType): Complex datatype to use for internal processing and output. Defaults to tf.complex64.\n\n**Input**\n\n- `batch_size` (int): Batch size\n\n**Output**\n\n- `h` ([batch size, num_rx, num_rx_ant, num_tx, num_tx_ant], tf.complex): Flat-fading channel matrices.\n- `g` (Same shape as `h`, tf.complex): Noise covariance matrices.\n\n**Note:** Spatial correlation is applied by this channel model on top of an existing channel model which itself generates i.i.d. channel realizations. For this reason, the spatial correlation parameter of the underlying channel model is automatically set to LMMSE. It is, therefore, advised to use an uncorrelated channel model as a basis, such as the Kronecker model."
"Here is the definition of PilotPattern: sionna.ofdm.PilotPattern(mask, pilots, trainable = False, normalize = False)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/pilot_pattern.html#PilotPattern)\n\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c), 2021-2024, NVIDIA SYSTEMS INC. & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"Pilot pattern for the nr (5G) subpackage of the Sionna library.\n\"\"\"\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sionna.ofdm import PilotPattern as PP\nfrom sionna.ofdm import ResourceGrid\nimport warnings\n\nclass PilotPattern(PP):\n    # pylint: disable=line-too-long\n    r\"\"\"Class defining a pilot pattern.\n\n    A :class:`~sionna.ofdm.PilotPattern` defines a\n    :class:`~sionna.ofdm.ResourceGrid` configuration\n    for a OFDM :class:`~sionna.mimo.StreamManagement`d transmitter\n    with a given :class:`~sionna.ofdm.ResourceGrid`.\n\n    Parameters\n    ----------\n    mask : array, shape=(num_tx, num_streams_per_tx, num_cells, num_ofdm_symbols, num_effective_subcarriers)\n        A binary mask that indicates the resource elements that are\n        allocated for pilot transmissions.\n\n    pilots : array, shape=(num_tx, num_streams_per_tx, num_cells, num_ofdm_symbols, num_effective_subcarriers)\n        The pilot symbols to be mapped onto the mask.\n\n    trainable : bool\n        Indicates if `pilots` is a  or a\n        :class:`~sionna.channel.TrainingSequence` for which\n        the pilots need to be trainable.  Defaults to `False`.\n\n    normalize : bool\n        Indicates if the pilots should be normalized to an\n        average energy of one across the last dimensions.\n        Defaults to `False`.\n\n    Raises\n    ------\n    AssertionError\n        If normalize is True and trainable is False.\n    \"\"\"\n\n    def __init__(self,\n                 mask,\n                 pilots,\n                 trainable=False,\n                 normalize=False):\n\n        # Check that mask and pilots have the same shape\n        assert mask.shape == pilots.shape[:3],\\\n            \"mask and pilots must have same shape.\"\n        num_tx = mask.shape[0]\n        num_streams_per_tx = mask.shape[1]\n        num_cells = mask.shape[2]\n\n        # Check that pilots have the correct shape\n        assert pilots.shape[3]==num_ofdm_symbols,\\\n            \"pilots must have shape [num_tx, num_streams_per_tx, num_cells, num_ofdm_symbols, num_effective_subcarriers]\"\n        assert pilots.shape[4]==num_effective_subcarriers,\\\n            \"pilots must have shape [num_tx, num_streams_per_tx, num_cells, num_ofdm_symbols, num_effective_subcarriers]\"\n\n        super().__init__(mask, pilots, trainable, normalize)\n\n    def show(self, tx_ind=0, tx_stream_ind=0):\n        \"\"\"Returns a matplot figure describing the pilot pattern of a\n        specific transmitter and stream.\n\n        Figures are zero-indexed, i.e., the first pilot symbol has\n        index 0.\n\n        For OFDM, the figure depicts the pilot pattern\n        on a sub-carried grid.\n\n        For other modulations, the figure depicts the\n        up-sampled pilot sequence.\n\n        Parameters\n        ----------\n        tx_ind : int\n            Indicates the index of the transmitter for which to show the\n            pilot pattern.\n\n        tx_stream_ind : int\n            Indicates the index of the stream for which to show the\n            pilot pattern.\n        \"\"\"\n        assert tx_ind < self.num_tx, \"Invalid `tx_ind`.\"\n        assert tx_stream_ind < self.num_streams_per_tx, \\\n            \"Invalid `tx_stream_ind`.\"\n\n        pp = self.pilots[tx_ind, tx_stream_ind]\n        mask = self.mask[tx_ind, tx_stream_ind]\n        mask = np.maximum(mask, 0) # Cast to float\n\n        fig = plt.figure()\n        plt.imshow(np.transpose(mask,[1,2,0]), origin=\"lower\")\n        plt.colorbar()\n        plt.title(\"Pilot Pattern\")\n        plt.xlabel(\"OFDM Symbol\")\n        plt.ylabel(\"Subcarrier Ind\")\n        for i, m in enumerate(mask):\n            ind = np.where(m)\n            for j in ind[0]:\n                plt.text(j, ind[1][i], f\"{pp[i,j]:.0e}\")\n\n        return fig\n```"
"To use Sionna, you need to import the necessary packages including TensorFlow and NumPy. Here's how you can do it:\n\n1. Importing TensorFlow: You can import TensorFlow using the `import` statement in Python. TensorFlow is a machine learning framework that provides support for deep learning and numerical computations. Here's the import statement for TensorFlow:\n\n```python\nimport tensorflow as tf\n```\n\n2. Importing NumPy: NumPy is a library in Python for numerical computations. It is commonly used in machine learning and data analysis. You can import NumPy using the `import` statement as follows:\n\n```python\nimport numpy as np\n```\n\n3. Setting the GPU configuration: If you are using a GPU for computations, you can set the GPU configuration using the `tf.config.experimental.set_memory_growth` method. This method attempts to allocate only as much GPU memory as needed for the runtime allocations, and it starts out allocating very minimal amount of memory. You can then increase this amount as needed.\n\n```python\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\n\n4. Importing Sionna: After importing TensorFlow and NumPy, you can import the Sionna package. Sionna is a Python package for simulating and optimizing free-space photo-voltaic harvesting. Here's how you can import Sionna:\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    !pip install sionna\n    import sionna as sionna\n```\n\nPlease note that the `!pip install sionna` statement attempts to install the Sionna package using pip, which is a package installer for Python. If Sionna is not already installed, this statement will install it."
"Here is the detailed information of LinearInterpolator:   \n  \n[sionna.channel.LinearInterpolator(tri, spec_diff_params_ri=None, spec_diff_params_rc=None, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/channel/interpolation.html#LinearInterpolator)  \n\nChannel model using linear interpolation on a Delaunay triangulation.\n\nGiven a batch of random variables `X` and `Y` , the CDF `F_X(x)` is evaluated at the point `a*(b-x) + x*(y-b)` for `a` in `[0,1]` and `b` in `[0,1]`.\n\nThe PDF `f_X(x)` is evaluated at the same point, but using a different method for the evaluation of the PDF. It returns a tensor of the same shape as `a` and `b`.\n\n**Parameters**\n\n- `tri` (Delaunay) \u2013 An instance of Delaunay.\n- `spec_diff_params_ri` ([, `k`, `l`, `m`], tf.float) \u2013 Parameters of the considered random variables, which characterize the behavior of the real/imaginary part of the variables. This input is ignored if the random variable is complex-valued. Defaults to None.\n- `spec_diff_params_rc` ([, `k`, `l`, `m`], tf.float) \u2013  Parameters of the considered random variables, which characterize the behavior of the complex  complex-valued. This is only required if the random variable is complex-valued. Defaults to None.\n- `dtype` (tf.Dtype) \u2013 Datatype for internal calculations and the output dtype. Defaults to tf.complex64.\n\n**Input**\n\n- `batch_size` (tf.int32) \u2013 Batch size.\n- `num_samples` (tf.int32) \u2013 Number of samples.\n- `x` ([batch_size, num_samples], tf.float) \u2013 Points to evaluate the CDF.\n- `output_domain` ([2], tf.float) \u2013 Defines the output (=domain) of the layer. It corresponds to the xy-plane in 3D.\n- `input_domain` ([2], tf.float) \u2013 Defines the input (=domain) of the layer. It corresponds to the ab-plane in 2D.\n- `no` (tf.float) \u2013 Thermo noise power.\n\n**Output**\n\n- `a` ([batch_size, num_samples], tf.float) \u2013 First interpolation parameter.\n- `b` ([batch_size, num_samples], tf.float) \u2013 Second interpolation parameter.\n- `coeff_cdf` ([batch_size, num_samples, 2], tf.float) \u2013 Coefficients for the linear interpolation of the CDF.\n- `coeff_pdf` ([batch_size, num_samples, 2], tf.float) \u2013 Coefficients for the linear interpolation of the PDF."
"Here is the detailed information of SymbolLogits2Moments:  \n\n[sionna.mimo.SymbolLogits2Moments(clip_logits=True, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mimo/accuracy.html#SymbolLogits2Moments)\n\nComputes the mean and variance of a distribution of constellation symbols, represented by logits.\n\nComputes the mean $\\mu_\\text{s}$ and the variance $\\nu_\\text{s}$ of a distribution of constellation symbols, represented by logits $\\boldsymbol{\\ell}$.\nA constellation is a complex-valued vector of values taken from a discrete set of complex values. Logits are the unnormalized log-probability of a class.\n\nThe mean and variance of the constellation symbols are computed according to $\\begin{split}\\begin{align}\n    \\mu_\\text{s} & = \\mathop{\\sum}\\limits_{s=1}^S s\\cdot p(s),\\text{where $s$ is the symbol}\\\\\n                 & = \\mathop{\\sum}\\limits_{s=1}^S s \\cdot \\left(\\frac{1}{1+e^{-\\ell(s)}}\\right)\\\\\n                 & = \\mathop{\\sum}\\limits_{s=1}^S s \\cdot \\text{sigmoid}(\\ell(s))\\\\\n    \\nu_\\text{s} & = \\mathop{\\sum}\\limits_{s=1}^S (s-\\mu_\\text{s})^2 \\cdot p(s)\\\\\n                 & = \\mathop{\\sum}\\limits_{s=1}^S (s-\\mu_\\text{s})^2 \\cdot \\left(\\frac{1}{1+e^{-\\ell(s)}}\\right)\\\\\n                 & = \\mathop{\\sum}\\limits_{s=1}^S (s-\\mu_\\text{s})^2 \\cdot \\text{softplus}(\\ell(s)) \n\\end{align}\\end{split}$\nwhere $p(s)$ is the (normalized) probability of the constellation symbol $s$, and $\\text{sigmoid}(\\ell) = \\frac{1}{1+e^{-\\ell}}$ and $\\text{softplus}(\\ell) = \\log\\left(e^{\\ell}+1\\right)$ are the sigmoid and softplus functions, respectively.\n\nThe mean and variance of the symbols are computed from the logits using the recursive Kahan summation algorithm to improve numerical stability.\n\nThis class is used in the implementation of the SymbolDetectionLogger.\n\n**Parameters**\n\n- `clip_logits` (bool): If True, computes the mean and variance of clipped logits instead of the (unclipped) logits. Defaults to True.\n- `dtype` (tf.Dtype): The dtype of `logits`. Defaults to tf.complex64.\n\n**Input**\n\n- `logits` ([...,n, num_symbols], tf.complex): Logits of the distribution over constellation symbols.\n\n**Output**\n\n- `mean` ([...,n], tf.complex): Mean of the constellation symbols.\n- `var` ([...,n], tf.complex): Variance of the constellation symbols."
"The 'cir_to_ofdm_channel' function is part of the 'sionna.channel' module and is used to generate channel frequency responses for an Orthogonal Frequency-Division Multiplexing (OFDM) waveform based on provided channel impulse responses. In the context of the OFDM waveform, a cyclic prefix (CP) is used to prefix each OFDM symbol with a copy of its suffix, to guard against ISI (Inter Symbol Interference).\n\nThis function takes a single parameter, 'h_cir' which is a tensor of possibly batched channel impulse responses. The impulse responses represent time-domain channel responses. These responses are typically generated by a channel model and consist of direct and scattered paths following a ray tracing process.\n\nThe function generates the OFDM channel frequency responses ( `h_ofdm` ), the number of lost (or deserted) subcarriers due to the removal of Guard Band (GB) carriers ( `num_deserted_subcarriers` ), the position of the first subcarrier index ( `fft_size` ), and the subcarrier spacing in Hz ( `subcarrier_spacing` ). These parameters can be used to convert the frequency responses into a format that can be plugged into an OFDM channel equalizer to recover the transmitted data.\n\nThe resulting frequency responses can be passed to the OFDMChannel, TimeChannel, or ApplyOFDMChannel modules to simulate wireless channel transmissions, depending on the requirement."
"The `EPDetector` class in the Sionna module is a type of Energy-Parameterized Detector that is used to detect weakly-sparse, high-rate, and long parity-check codes. This detector is being used for detaching energy parameterization from the signal shaping. The Energy-Parameterized Detector carries out approximate log-likelihood ratio (LLR) calculations based on the received signal vector and the estimated value of the total noise power spectral density (PSD).\n\nThe Energy-Parameterized Detector's main parameters are:\n- `pcm` (an instance of `LDPC_PCM`): This parameter represents the parity-check matrix, which is used to construct the detector. It should be a low-density parity-check (LDPC) code with a rate close to (but not equal to) 1.\n- `num_bits_per_symbol`: This is an integer parameter that indicates the number of bits per constellation point.\n- `hard_out` (default = False): This is a boolean parameter that, if set to True, causes the detector to output hard decisions on the symbols instead of soft values (i.e., LLRs).\n- `l_min`: This is a parameter that represents the minimal approximation value used in calculating the LLRs.\n- `l_max`: This is a parameter that represents the maximal approximation value used in calculating the LLRs.\n\nThe `EPDetector` class is particularly significant in the context of simulations because it is used to detect signals transmitted over channels. By providing an instance of `LDPC_PCM` and the necessary parameters, the `EPDetector` can simulate the process of signal detection, including the effects of noise and the characteristics of the channel over which the signal is transmitted. The detector's performance can be evaluated in terms of bit or symbol error rates, which can help in the comparison of different coding and modulation schemes under varying channel conditions."
"To use the EDFA class in Sionna, the Python code from the provided context can be referenced. However, as the context does not provide the specific code detailing how to set up and run an instance of the EDFA class, I will provide a more general step-by-step approach. This will be based on the typical set-up for devices in the Sionna package and the functionalities called for in the context.\n\nStep 1: Set up the environment\nThis includes importing necessary packages such as Sionna, TensorFlow, and other required packages. Here is the code snippet from the context:\n\n```python\nimport sionna\nimport tensorflow as tf\nimport numpy as np\nfrom sionna.fiber import SMF\n```\n\nStep 2: Configure the EDFA\nYou will typically need to set up a configuration for your EDFA. This can include parameters such as gain, noise_figure, f_c, and alpha. The specific parameters you choose will depend on the requirements of your simulation. \n\nStep 3: Instantiate the EDFA class\nAfter configuring the EDFA, you can then create an instance of the EDFA class. Here is a code snippet from the context:\n\n```python\nedfa = sionna.channel.EDFA(\n    g=4.0,\n    f=2.0,\n    f_c=193.55e12,\n    alpha=0.2,\n    f_m=f_c\n)\n```\n\nStep 4: Use the EDFA instance in your simulation\nYou can now use the EDFA instance in your simulation. This would typically involve passing your signal through the EDFA and performing other operations. The exact steps here will depend on the specific simulation you are trying to do.\n\nPlease note that the code provided in the context is just a small part of using the EDFA in Sionna and might not work as a complete solution without the rest of the code that supports the simulation."
"The `render_to_file()` function in the `Scene` class of the Sionna package is used to render the scene to a file with a specified filename. This function can be particularly useful when you want to visualize a scene, especially in a Jupyter notebook where direct visualization might not be possible.\n\nThis function takes a number of parameters:\n\n- **filename**: Specifies the name of the file where you want to save the rendered scene. The type of the file (png, jpeg, etc.) is inferred from the extension of the filename.\n\n- **camera** (optional): Allows you to specify a `Camera` object or the name of a camera in the scene. If not provided, the function uses a default camera (\"lookat\", \"box\").\n\n- **width & height** (optional): These parameters are used to specify the dimensions of the rendered image. The default values are 480 and 320 respectively.\n\n- **num_samples** (optional): This parameter controls the number of samples to use for rendering, which can affect the quality of the render. The default value is 2048.\n\nThe `render_to_file()` function doesn't return any values but it can raise an `AssertionError` if the filename is an unsupported type or if there is an error in the rendering process.\n\nHere is a sample usage of the `render_to_file()` function:\n\n```python\nfrom sionna.rt import Scene\n\n# Assume we have a scene object\nscene = Scene(...)\n\n# Render the scene to a file named \"my_scene.png\"\nscene.render_to_file(\"my_scene.png\")\n```\n\nIn this example, \"my_scene.png\" would be the name of the file where the scene is rendered. The function would use the default camera and settings for rendering."
"To \"wrap\" an angle means to adjust it so that it falls within a specific range. The \"wrap_angle_0_360\" function is part of the Sionna package, and is designed to wrap an angle to the range of 0 to 360 degrees (inclusive). In the context provided, an angle parameter `x` is described as being wrapped around this range.\n\nThe function is implemented in Python, and here is the corresponding code:\n\n```python\ndef wrap_angle_0_360(x):\n    \"\"\"\n    Wrap angle to (0,360) [deg]\n\n    Args:\n        x : tf.float32\n            An arbitrary shaped tensor of Dtype tf.float32.\n\n    Returns:\n        y : tf.float32\n            Tensor with same shape and dtype as ``x``.\n    \"\"\"\n    zero   = tf.constant(0, dtype=x.dtype)\n    three_sixty = tf.constant(360, dtype=x.dtype)\n    return tf.math.mod(x-three_sixty, three_sixty)\n```\n\nTo use this function in a programming scenario, you would call the function with an argument `x` that is an arbitrary shaped tensor of type `tf.float32`. The function will return a tensor `y` that has the same shape and type as the input `x`, but with each element wrapped to the range of 0 to 360 degrees.\n\nKeep in mind that the input `x` is expected to be a tensor of type `tf.float32`, and the output `y` will also be a tensor of the same type. If the input `x` is not within the range of 0 to 360 degrees, the function will first wrap it to the range -180 to 180 degrees before wrapping it to the 0 to 360 range."
"Here is the definition of ChannelModel: sionna.channel.ChannelModel\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel)  \nsource code:\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"Abstract Channel Model Class\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom importlib import resources\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import Model\nimport scipy.constants as sc\n\nfrom sionna.utils import Config, load_config\nfrom sionna import __root__ as pkg_root\n\nclass ChannelModel(ABC):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    A channel model generates channel impulse responses which can be used to\n    implement a channel transfer function in the time or frequency domain.\n\n    The channel model is initialized with a\n    :class:`~sionna.utils.Config` object, which typically includes\n    the specification of the random seed ``seed`` and the batch size.\n\n    The channel impulse response is then computed by calling the channel model\n    with the desired ``num_time_steps`` (i.e., the number of time steps of the\n    input sequence) and ``sampling_frequency`` (in Hz).\n\n    A channel model is typically used to simulate a single-transmitter\n    sending data streams to a multi-antenna receiver. The transmitter is\n    initialized with a channel model, and the input to the model consists\n    of the transmitter's ``num_tx_ant``  independent data streams.\n\n    Each call to the channel model returns a batch of ``num_rx = num_tx_ant``\n    channel taps of size ``num_rx_ant`` (the number of receivers x number of\n    transmitters). From these channel taps, a set of noise-estimates\n    :math:`\\sigma^2` can be computed using the reference signal energy\n    :math:`E_\\text{s}` as\n\n    .. math : \\sigma^2 = \\frac{N_0}{2}E_\\text{s} \\text{, where } N_0 \\in \\mathbb{C}\n    is the noise power spectral density.\n\n    Note\n    - For link-level simulations, Sionna provides the :class:`~sionna.mimo.ScalarDetector`\n      which can be used with a perfect channel model. Therefore, the\n      following layer implementations do not need to apply the channel\n      inverse or the frequency transform.\n    - The batch size cannot be changed between calls,\n      as the receiver needs to apply the inverse channel covariance matrix\n      which is computed from the channel responses.\n    \"\"\"\n    def __init__(self, config, **kwargs):\n        super().__init__(**kwargs)\n        self._config = config\n\n        # Set flag for TensorFlow implementation\n        if config['implementation'] == 'tf':\n            self._tf_implementable = True\n        else:\n            self._tf_implementable = False\n\n        # Set flag for stateless random generator\n        self._stateless = True\n        if 'stateless' in config:\n            self._stateless = config['stateless']\n\n        # Set flag for sampling complex Gaussians\n        self._sample_complex_gaussians = False\n        if 'sample_complex_gaussians' in config:\n            self._sample_complex_gaussians = config['sample_complex_gaussians']\n\n        # Set flag to indicate if the channel is time-invariant\n        self._time_invariant = True\n        if 'time_invariance' in config:\n            self._time_invariant = config['time_invariance']\n\n        # Configure SNR for the generation of channel impulse responses.\n        # The SNR can be a scalar or a tensor of any shape that can be\n        # broadcasted to the shape of a channel response.\n        if 'snr' in config:\n            self._snr = config['snr']\n            if not isinstance(self._snr, (int, float, complex)):\n                raise ValueError(\"snr must be a scalar value.\")\n        else:\n            # Default SNR\n            self._snr = 10.0\n\n        # Acceptable measurement units\n        self._magnitude_unites = [\"\", \"db\", \"lin\"]\n        self._phase_units = [\"rad\", \"deg\"]\n        self._unit = None\n\n        # Check required components\n        self._check_config()\n\n        # Set RNG for sampling the channel response\n        self._set_rng_state()\n\n    @property\n    @abstractmethod\n    def channel_responses(self):\n        \"\"\"\n        Channel responses\n        \"\"\"\n        pass\n\n    @property\n    def batch_size(self):\n        \"\"\"\n        Batch size\n        \"\"\"\n        return self._config['batch_size']\n\n    @property\n    def num_tx(self):\n        \"\"\"\n        Number of transmitters\n        \"\"\"\n        return self._config['num_tx']\n\n    @property\n    def num_tx_ant(self):\n        \"\"\"\n        Number of transmit antennas\n        \"\"\"\n        return self._config['num_tx_ant']\n\n    @property\n    def num_rx(self):\n        \"\"\"\n        Number of receivers\n        \"\"\"\n        return self._config['num_rx']\n\n    @property\n    def num_rx_ant(self):\n        \"\"\"\n        Number of receive antennas\n        \"\"\"\n        return self._config['num_rx_ant']\n\n    @property\n    def num_paths(self):\n        \"\"\"\n        Number of paths\n        \"\"\"\n        return self._config['num_paths']\n\n    @property\n    def los(self):\n        \"\"\"\n        Flag array of shape [ `batch_size`, `num_rx`, `num_tx` ], indicating\n        if the corresponding channel response is a Line-of-Sight (True) or not (False).\n        \"\"\"\n        if self._config['los_index'] is not None:\n            return self._config['los_index'][:, :, :self.num_rx]\n        else:\n            return tf.fill([self._config['batch_size'], self.num_rx, self.num_tx],\n                           True)\n\n    @property\n    def delays(self):\n        \"\"\"\n        Delays `[batch_size, num_paths]` [s]\n        \"\"\"\n        return self._config['delays'] / self._config['sampling_frequency']\n\n    @property\n    def powers(self):\n        \"\"\"\n        Path powers `[batch_size, num_paths]` [a.u.]\n        \"\"\"\n        return self._config['powers']\n\n    @property\n    def can_export_to(self):\n        \"\"\"\"\n        List of classes ChannelModel provides compatibility with.\n        This classes can use the ChannelModel instance for setting the channel\n        of, e.g., an LLS model.\n        \"\"\"\n        return []\n\n    @property\n    def implementation(self):\n        \"\"\"\n        Channel implementation type\n        \"\"\"\n        return self._config['implementation']\n\n    @property\n    def sampling_frequency(self):\n        \"\"\"\n        Sampling frequency [Hz]\n        \"\"\"\n        return self._config['sampling_frequency']\n\n    @property\n    def snr(self):\n        \"\"\"\"\n        The SNR for which the channel impulse responses were generated.\n        \"\"\"\n        return self._snr\n\n    @property\n    def complex_sampling(self):\n        \"\"\"\n        Flag indicating if channel models generate complex-valued samples.\n        \"\"\"\n        return self._config['complex_sampling']\n\n    @property\n    def n(self):\n        if self.complex_sampling:\n            return self._config['n']\n        else:\n            return self._config['2n']\n\n    @property\n    def time_invariance(self):\n        \"\"\"\n        Flag indicating if the channel is time-invariant.\n        \"\"\"\n        return self._time_invariant\n\n    @property\n    def verbose(self):\n        \"\"\"\n        Get the current setting of the verbosity level.\n        \"\"\"\n        return self._config['verbose']\n\n    @property\n    def rng(self):\n        \"\"\"\n        Random number generator\n        \"\"\"\n        return self._rng\n\n    @property\n    def random_seed(self):\n        \"\"\"\n        Random seed used to generate the channel responses\n        \"\"\"\n        return self._config['random_seed']\n\n    @property\n    def xsi(self):\n        r\"\"\"[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps]\n        Real-valued path coefficients :math:`\\xsi_{i,j,k,\\ell,m,n}(t)`\n        for the :math:`\\ell^{\\text{th}}` path of the\n        :math:`\\ell^{\\text{th}}` cluster of the :math:`m^{\\text{th}}` transmitter and\n        the :math:`n^{\\text{th}}` receiver, where :math:`i \\in [1,M]` and :math:`M` is the number of clusters,\n        :math:`j \\in [1,K]` and :math:`K` is the number of paths per cluster, :math:`t` is\n        the time step, and :math:`\\xsi_{i,j,k,\\ell,m,n}(t)` is defined in\n        [WIRELESS COMMUNICATIONS CHANNEL, CRC PRESS, Tegli et al. \"Modeling and Simuation of Ray Tracing\"]\n        and computed through frequency interpolation on the impulse reponse\n        as defined in (7) and (8).\n        \"\"\"\n        if self._config['complex_sampling']:\n            raise ValueError(\"XSI not available for complex sampling\")\n        return self._config['xsi'][:,:,:,:,:,:,0,:].numpy()\n\n    @property\n    @abstractmethod\n    def h_f(self):\n        r\"\"\"\n        Frequency responses\n        \"\"\"\n        pass\n\n    @property\n    def h(self):\n        r\"\"\"\n        Channel responses in the time domain\n        \"\"\"\n        if self.complex_sampling:\n            h_f = self.h_f\n            h_f = tf.cast(h_f, tf.complex64)\n            if self._config['implementation'] == 'tf':\n                cir = tf.signal.ifft(h_f, name='cir')\n            elif self._config['implementation'] == 'numpy':\n                cir = np.fft.ifft(h_f, axis=2)\n            return cir\n        else:\n            h_f = self.h_f\n            h_f = tf.cast(h_f, tf.complex64)\n            if self._config['implementation'] == 'tf':\n                cir = tf.signal.ifft(h_f, name='cir')\n            elif self._config['implementation'] == 'numpy':\n                cir = np.fft.ifft(h_f, axis=3)\n            return cir[...,::2].numpy()\n\n    @property\n    def hm(self):\n        r\"\"\"\n        Angular responses\n        \"\"\"\n        # Load the default angular power spectrum if one was not provided by\n        # the user\n        if self._config['angular_model'] is None:\n            self._config['angular_model'] = \"ula\"\n        ula = True\n        if self._config['angular_model']==\"v\":\n            ula = False\n        # Transmitting antenna array\n        if self._config['tx_array']['angular_position'].shape[0] < 2:\n            return tf.zeros(self._config['k_a'].shape, dtype=self._dtype)\n        # Revert the antenna array if the y-axis points donw, as it is\n        # required for the computation of the angles in the CIR\n        if (self._config['tx_array']['angular_position'][1]\n            == self._config['rx_array']['angular_position'][1] == -np.pi/2):\n            rx_ty = self._config['rx_array']['angular_position'][1]\n            self._config['rx_array']['angular_position'] = (\n                self._config['tx_array']['angular_position'][0],\n                tf.constant(-np.pi, self._dtype),\n                rx_ty)\n        # Compute angles\n        ka = self._config['k_a']\n        theta_t = self._config['tx_array']['angular_position'][0] + ka*ula*(\n            self._config['tx_array']['linear_polarization'].direction)[1]\n        theta_r = (self._config['rx_array']['angular_position'][0]\n            + ka*ula*(self._config['rx_array']['linear_polarization']\n                      .direction)[1])\n        phi = ka*(\n            self._config['tx_array']['angular_position'][1]\n            - self._config['rx_array']['angular_position'][1])\n        # Compute half-wavelength difference\n        if self._config['l_0'] is None:\n            l_0 = np.zeros_like(self._config['k_a'][:,0])\n        else:\n            l_0 = self._config['l_0']\n        d = (l_0 + ka*ula*(self._config['d'].direction)[0])\n        # Compute the angular response\n        if self._config['angular_model']==\"v\":\n            return (tf.cast(d[:,tf.newaxis], self._dtype)\n                    * tf.sin(theta_r - theta_t))\n        else:\n            return (tf.exp(tf.complex(0., d*ka*ula))\n                    * tf.pow(tf.cos(theta_r - theta_t), self._config['alpha'])\n                    * tf.pow(tf.cos(phi), 2))\n    @property\n    def l(self):\n        \"\"\"\n        Lengths of the channel impulse response [m]\n        \"\"\"\n        if self._config['l_0'] is None:\n            return None\n        else:\n            return self._config['l_0'] + self._config['l_max']*self._config['delta_l']\n\n    @property\n    def l_sp(self):\n        \"\"\"\n        Total length of the scattered path (m)\n\n        The scattered path is composed of a single scatterer which is\n        randomly generated and added to the transmit array boresight direction\n        (which is assumed to be the same as the receive array's boresight\n        direction)\n        \"\"\"\n        if self._config['scattering_pattern'] is None:\n            return None\n        return self._config['l_sp']\n\n    @property\n    def a(self):\n        r\"\"\"\n        Spatial field correlation matrices\n        :math:`\\mathbf{A}_{i,j}(\\theta_{\\text{T}}, \\varphi_{\\text{T}},\n        \\theta_{\\text{R}}, \\varphi_{\\text{R}})`\n        : where :math:`i` is the index of the transmit antenna and\n        :math:`j` the index of the receive antenna.\n        \"\"\"\n        return self._config['a']\n\n    @property\n    @abstractmethod\n    def at(self):\n        r\"\"\"\n        Spatial field correlation matrices\n        :math:`\\mathbf{A}^{\\dagger}_{i,j}(\\theta_{\\text{T}}, \\varphi_{\\text{T}},\n        \\theta_{\\text{R}}, \\varphi_{\\text{R}})`\n        : where :math:`i` is the index of the transmit antenna and\n        :math:`j` the index of the receive antenna.\n        \"\"\"\n        pass\n\n    @property\n    def p(self):\n        r\"\"\"\n        Scalar transmit power contributions :math:`P_i\\ (\\text{in radians})`\n        of an incoming equi-polarized plane wave.\n        Only available for the ``equi_polarized`` and ``uplink`` polarization type.\n        \"\"\"\n        if self._config['p'] is None:\n            return None\n        else:\n            return self._config['p']\n\n    @property\n    def p_tp(self):\n        r\"\"\"\n        Transmit power per antenna (:math:`P_{\\text{T},i}`) [in dB] relative\n        to an antenna array with 1/num_tx_ant of the total power.\n        Only available for the ``polarization_type`` \"transmit\"\n        \"\"\"\n        if self._config['p_tp'] is None:\n            return 0.0\n        else:\n            return self._config['p_tp']\n\n    @property\n    def p_rx(self):\n        r\"\"\"\n        Receiver power per antenna (:math:`P_{\\text{R},i}`) [in dB] relative\n        to an antenna array with 1/num_rx_ant of the total power.\n        Only available for the ``polarization_type`` \"receive\"\n        \"\"\"\n        if self._config['p_rx'] is None:\n            return 0.0\n        else:\n            return self._config['p_rx']\n\n    @property\n    def polarization_type(self):\n        \"\"\"\n        Type of polarization.\n\n        For \"uplink\", it refers to the polarization of the received signal.\n\n        For \"downlink\", it refers to the polarization of the transmitted signal.\n        \"\"\"\n        return self._config['polarization_type']\n\n    @polarization_type.setter\n    def polarization_type(self, value):\n        assert value in [\"uplink\", \"downlink\"], \\\n            \"Polarization type must be either uplink or downlink\"\n        self._config['polarization_type'] = value\n\n    @property\n    def rx_array(self):\n        \"\"\"\n        Receiver antenna array\n        \"\"\"\n        return self._config['rx_array']\n\n    @property\n    def tx_array(self):\n        \"\"\"\n        Transmitter antenna array\n        \"\"\"\n        return self._config['tx_array']\n\n    @property\n    def center_frequency(self):\n        \"\"\"\n        Center frequency [Hz]\n        \"\"\"\n        return self._config['center_frequency']\n\n    @property\n    def los_index(self):\n        \"\"\"\n        Index of LoS path\n\n        For each batch example, the first path with index 0 is assumed to be the\n        LoS path.\n        If the batch example does not contain a LoS path with index 0, the next\n        `los_index` entries are set to -1.\n        \"\"\"\n        return self._config['los_index']\n\n    @property\n    def scattering_pattern(self):\n        \"\"\"\n        Scattering pattern\n\n        The scattering pattern is \"omni\" for all transmitters.\n        \"\"\"\n        return self._config['scattering_pattern']\n\n    @property\n    def num_scatterers(self):\n        \"\"\"\n        Number of scatterers on the scattered path\n        \"\"\"\n        if self._config['scattering_pattern'] is None:\n            return None\n        return self._config['num_scatterers']\n\n    @property\n    def scatterer_ind(self):\n        \"\"\"\n        Indices of scatterers\n\n        The first `num_scatterers` paths in the path index array correspond\n        to the scatterers.\n        \"\"\"\n        if self._config['scattering_pattern'] is None:\n            return None\n        return self._config['paths'][:,:,:,:,:,0,self.num_scatterers]\n\n    @property\n    def keepdims(self):\n        \"\"\"\n        Indicates if the batch dimensions are kept\n        \"\"\"\n        return self._config['keepdims']\n\n    @keepdims.setter\n    def keepdims(self, value):\n        assert isinstance(value, bool), \"Value must be boolean.\"\n        self._config['keepdims'] = value\n\n    @property\n    def random_seed(self):\n        \"\"\"\n        Random seed used when setting the channel up\n        \"\"\"\n        return self._config['random_seed']\n\n    @random_seed.setter\n    def random_seed(self, value):\n        self._config['random_seed'] = value\n        self._set_rng_state()\n\n    @property\n    def complex_sampling(self):\n        \"\"\"\n        Indicates if complex-valued samples are drawn\n        \"\"\"\n        return self._config['complex_sampling']\n\n    def _set_rng_state(self):\n        \"\"\"Set RNG state for random sampling of the CIR\"\"\"\n        if self._"
"Here is the detailed information of sionna.rt.Scene.render_to_file:  sionna.rt.Scene.render_to_file(\u201cfilename\u201d), sionna.rt.Scene.render_to_file(\u201cfilename\u201d, camera)  \n\n**Method Description**:\nRenders the scene cut using the Mitsuba renderer and saves it to a file.\n\n**Input**:\n- `filename` (str): Name of the file to which the scene should be rendered.\n- `camera` (Camera, str): Instance of the Camera class or string with the camera name. If not provided, the current active camera is used.\n\n**Output**:\n- `str`: Path to the rendered file.\n\n**Error**:\n- `ValueError`: If the number of samples is non-positive.\n- `FileExistsError`: If an item with the same name as `filename` exists."
"To configure DeepMIMO for use with Sionna, follow these steps:\n\n1. Import the necessary libraries and set the GPU configuration.\n\n```python\nimport os\nimport tensorflow asjson\nimport DeepMIMO\nfrom DeepMIMO import DeepMIMO\ngpu_num = 0\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n2. Load the DeepMIMO configuration file for the scenario you want to run. You can choose between the 'Soil Moisture', 'Urban Microcell', 'Urban Macrocell', and 'rural low mobility' scenarios.\n\n```python\nDeepMIMO_params = DeepMIMO.load_params_data(\"DeepMIMO_params_S3.cfg\")\n```\n\n3. Configure Sionna to use the DeepMIMO configuration file. You need to import the Sionna package and set the `DeepMIMO_params` for the Sionna configuration.\n\n```python\nos.environ[\"SIONNA_Parameters\"] = \"DeepMIMO_params\"\nimport Sionna\nfrom Sionna import Sionna\n```\n\n4. Instantiate the DeepMIMO dataset. You need to specify the scenario, the number of paths, and whether to generate channel impulse responses (CIRs) or frequency responses.\n\n```python\ndataset = DeepMIMO(DeepMIMO_params, generate_full_covariance=True, gen_fading=True)\n```\n\n5. Use the Sionna DeepMIMO adapter to generate the channel responses.\n\n```python\nfrom Sionna.DeepMIMO import DeepMIMOAdapter\nadapter = DeepMIMOAdapter(dataset)\n```\n\n6. Now, you can generate CIRs or convert them to OFDM domain channel frequency responses.\n\n```python\nCIRs = adapter.generate_bs_uti_cir(15)\nCIRs_freq = adapter.generate_bs_uti_freq(15)\n```\n\n7. Use the Sionna DeepMIMO adapter to compute the channel for the desired input.\n\n```python\nimport tensorflow as tf\ntf.random.set_seed(4)\nu = tf.complex(tf.random.normal([len(adapter.uti_rows), len(adapter.uti_rows[0]), adapter.L], dtype=tf.float32),\n               tf.random.normal([len(adapter.uti_rows), len(adapter.uti_rows[0]), adapter.L], dtype=tf.float32))\nh = adapter(u)\n```\n\nPlease note that the code snippets provided are directly taken from the context and should be used as is. If your application requires additional functionality, you may need to import other packages or configure the DeepMIMO and Sionna components differently."
"To use the Interleaver module in the Sionna package to permute tensors, follow these steps:\n\n1. First, you need to import the required modules from the Sionna package. This includes the `RandomInterleaver` class from the `sionna.fec.interleaving` module and the `tf` module for TensorFlow operations.\n\n```python\nfrom sionna.fec.interleaving import RandomInterleaver\nimport tensorflow as tf\n```\n\n2. Create your tensor. The tensor should be a 2+D tensor of arbitrary shape. For example, you can create a tensor of Gaussian integers as follows:\n\n```python\nx = tf.constant([[1, 2, 3, 4], [5, 6, 7, 8]]) # You should replace this with your own tensor\n```\n\n3. Instantiate the `RandomInterleaver` class and configure it with the desired settings. You need to specify a seed for the random generator and, optionally, the axis along which to permute. If you don't specify the axis, the default behavior is to interleave along the last axis.\n\n```python\ninterleaver = RandomInterleaver(seed=1234, axis=1) # permute along the 2nd axis\n```\n\n4. Permute your tensor using the instance of `RandomInterleaver` you created. You can do this by calling the instance as a function and passing your tensor as an argument.\n\n```python\nx_int = interleaver(x)\n```\n\nThe output, `x_int`, will be a tensor with the same shape and dtype as `x`, but with the elements permuted along the specified axis.\n\nPlease note that the exact code may vary depending on the specific requirements of your application. The context does not provide any information about the shape or contents of the tensor to be interleaved."
"The `MMSEPICDetector` function is used to implement and test functionality of a Minimum Mean Square Error (MMSE) PIC detector for a multi-cell MIMO 5G New Radio (NR) scenario, as defined in the novel provided by Context `sionna.mimose.non_lin_sep_pic`. The function takes the necessary parameters, such as the batch size, the number of receivers, the number of receiver antennas, and others, to set up the detector.\n\nIt returns a sequence, `x_hat_mmse` , of estimated symbol vectors and the effective noise variance `no_eff` for each stream. This output provides MMSE equalization to minimize the mean square error.\n\nThe function utilizes the concept of pre-cancelling inter-stream interference (ISI) and noise to improve the quality of the received signal. It computes the MMSE estimate of the transmitted vector by using the received vectors, the known channel matrices, and the noise covariance matrices.\n\nThe function raises the `ValueError` if the 'order' is not 'first' or 'last', receiver_match' is not in ('single', 'all'), or if 'receiver_match' and 'received_stream_ids' are not given. It also uses assertions to ensure that the channel matrices and other parameters are in the correct format and dimensions."
"Here is the definition of RaisedCosineFilter: sionna.signal.RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/signal/filter.html#RaisedCosineFilter)\n\nsource code:\n```python\nclass RaisedCosineFilter(Filter):\n    # pylint: disable=line-too-long\n    r\"\"\"RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n\n    Layer for applying a raised-cosine filter of length ``span_in_symbols``\n    to an input ``x`` of length ``len(x)=samples_per_symbol``.\n\n    The raised-cosine filter is defined by\n\n    .. math::\n        h(t) =\n        \\begin{cases}\n        \\frac{1}{T} \\left(1 + \\cos\\left(\\frac{\\pi}{T}\\left(\\beta\\left(|t|\\,-\\,1\\right)\\,+\\,1\\right)\\right)\\right), & \\text { if } \\left|t\\right|\\leq T\\\\\n        \\frac{1}{2T} \\left(\\sin\\left(\\frac{\\pi}{T}\\left(\\beta\\left(|t|\\,-\\,1\\right)\\,-\\,1\\right)\\right) + \\sin\\left(\\frac{\\pi}{T}\\left(\\beta\\left(|t|\\,+1\\right)\\,+1\\right)\\right)\\right), & \\text { if } \\left|t\\right| = T\\\\\n        0, & \\text { otherwise}\n        \\end{cases}\n        where :math:`\\beta` is the roll-off factor and :math:`T` the symbol duration.\n\n    The filter length is equal to :math:`span\\_in\\_symbols \\times L`, where\n    :math:`L` is the smallest even integer greater or equal to :math:`\\frac{4\\pi}{\\beta\\Delta_w}`, and\n    :math:`\\Delta_w` is the angular frequency step.\n\n    The filter is applied through discrete convolution.\n\n    An optional windowing function ``window`` can be applied to the filter.\n\n    The `dtype` of the output is `tf.float` if both ``x`` and the filter coefficients have `dtype` `tf.float`.\n    Otherwise, the `dtype` of the output is `tf.complex`.\n\n    Three padding modes are available for applying the filter:\n\n    *   \"full\" (default): Returns the convolution at each point of overlap between ``x``\n        and the filter. The length of the output is N + M - 1. Zero-padding of the input ``x``\n        is performed to compute the convolution at the borders.\n    *   \"same\": Returns an output of the same length as the input ``x``. The convolution is computed\n        such that the coefficients of the input ``x`` are centered on the coefficient of the filter with\n        index (N-M)/2. Zero-padding of the input signal is performed to compute the convolution at the borders.\n    *   \"valid\": Returns the convolution only at points where ``x`` and the filter completely overlap.\n        The length of the output is N - M + 1.\n\n    Parameters\n    ----------\n    span_in_symbols: int\n        Filter span as measured by the number of symbols.\n\n    samples_per_symbol: int\n        Number of samples per symbol, i.e., the oversampling factor.\n\n    beta : float\n        Roll-off factor.\n        Must be in the range :math:`[0,1]`.\n\n    window: Window or string ([\"hann\", \"hamming\", \"blackman\"])\n        Instance of :class:`~sionna.signal.Window` that is applied to the filter coefficients.\n        Alternatively, a string indicating the window name can be provided. In this case,\n        the chosen window will have default parameters. Custom windows must be provided\n        as instance.\n\n    normalize: bool\n        If `True`, the filter is normalized to have unit power.\n        Defaults to `True`.\n\n    trainable: bool\n        If `True`, the filter coefficients are trainable variables.\n        Defaults to `False`.\n\n    dtype: tf.DType\n        The `dtype` of the filter coefficients.\n        Defaults to `tf.float32`.\n\n    Input\n    -----\n    x : [..., N], tf.complex or tf.float\n        The input to which the filter is applied.\n        The filter is applied along the last dimension.\n\n    padding : string ([\"full\", \"valid\", \"same\"])\n        Padding mode for convolving ``x`` and the filter.\n        Must be one of \"full\", \"valid\", or \"same\". Case insensitive.\n        Defaults to \"full\".\n\n    conjugate : bool\n        If `True`, the complex conjugate of the filter is applied.\n        Defaults to `False`.\n\n    Output\n    ------\n    y : [...,M], tf.complex or tf.float\n        Filtered input.\n        It is `tf.float` only if both ``x`` and the filter are `tf.float`.\n        It is `tf.complex` otherwise.\n        The length M depends on the ``padding``.\n    \"\"\"\n    def __init__(self,\n                 span_in_symbols,\n                 samples_per_symbol,\n                 beta,\n                 window=None,\n                 normalize=True,\n                 trainable=False,\n                 dtype=tf.float32,\n                 **kwargs):\n        super().__init__(span_in_symbols,\n                         samples_per_symbol,\n                         beta,\n                         window=window,\n                         normalize=normalize,\n                         trainable=trainable,\n                         dtype=dtype,\n                         **kwargs)\n\n    @property\n    def _coefficients_source(self):\n        h = self._raised_cosine(self.sampling_times,\n                               self.span_in_symbols,\n                               self.samples_per_symbol,\n                               self.beta,\n                               self.window,\n                               normalize=self.normalize)\n        return tf.constant(h, self.dtype)\n```"
"The PAM2QAM class in the Sionna package for Python, is a class designed to help with the execution of code that involves a digital baseband 2-ary (binary) Pulse Amplitude Modulation (PAM) constellation that is upsampled and filtered. Using this class, one can achieve the execution of a Keras layer implementing PAM2QAM mapping.\n\n[pam2qam](https://nvlabs.github.io/sionna/api/misc.html#pam2qam) function requires in this class:\n- pam : int\n  Could be {2,4} for now. Specifies the PAM order, i.e., the number of levels.\n\n- num_bits_per_symbol : int\n  The number of bits per a QAM symbol. Must be a multiple of pam.\n\n- dtype : tf.DType\n  Defaults to tf.complex64. Defines the datatype for internal calculations and the output dtype.\n\nThis class inherits from the Keras layer class and can be used as a layer in a Keras model. It operates a PAM2QAM mapping on the input by moving the input bits on the first stream to the real part and the second stream to the imaginary part.\n\nThis class helps to achieve in code execution the transformation of PAM into Quadrature Amplitude Modulation (QAM). On top of that, it helps to set the datatype for internal calculations and the output."
"To configure StreamManagement for a simple uplink scenario using Python code, you can follow these steps:\n\n1. Define the following variables:\n\n   `num_tx`: The number of transmitters (in both the rows and columns of the rx_tx_association matrix).\n\n   `num_rx`: The number of receivers (in both the rows and columns of the rx_tx_association matrix).\n\n   `num_streams_per_tx`: The number of streams transmitted by each transmitter.\n\n   `rx_tx_association`: An array that represents which receiver is associated with which transmitter for each stream. This array should be of shape `num_rx` x `num_tx` x `num_streams_per_tx`. In the given context, the `stream_management.rx_tx_association` function is used to generate this array. \n\n2. Instantiate a StreamManagement object named 'sm' with the following parameters:\n\n   - `num_streams_per_tx`\n   - `rx_tx_association`\n\n```python\nsm = StreamManagement(num_streams_per_tx,\n                      rx_tx_association,\n                      perfect_csi=True, # This parameter is not required for the configuration\n                      perfect_synchronization=True) # This parameter is not required for the configuration\n```\n\nIn the provided context, the `num_tx` is assumed to be 1, `num_rx` is assumed to be 1, `num_streams_per_tx` is set to 1, and `rx_tx_association` is generated using `stream_management.rx_tx_association` function. Please adjust these parameters according to your specific needs."
"Constellations in higher order modulation are sets of signal points in the complex plane that are used to encode multiple bits per symbol. The size of a constellation is equal to the number of bits encoded per symbol, with common examples being 2 (for Binary Phase Shift Keying, or BPSK) and json=([1, \\frac{-1}{\\sqrt{2}}], [ \\frac{j}{\\sqrt{2}}, \\frac{-j}{\\sqrt{2}}])</a></td>\n  </tr>\n  <tr>\n    <td><b>Bit-Channels</b></td>\n  </tr>\n  <tr>\n    <td></td>\n    <td><a href=\"https://nvlabs.github.io/sionna/api/channel.html#sionna.channel.BitDiscreteChannel\">BitDiscreteChannel</a></td>\n    <td>Supports Binary Phase Shift Keying (BPSK) and Quadrature Amplitude Modulation (QAM).</td>\n    <td><a href=\"https://nvlabs.github.io/sionna/api/channel.html#sionna.channel.BinarySymmetricChannel\" class=\"xref py-xref\"><a class=\"xref xreverseeoln\" href=\"https://nvlabs.github.io/sionna/api/channel.html#sionna.channel.BinarySymmetricChannel\">BinarySymmetricChannel</a></td>\n  </tr>\n  <tr>\n    <td></td>\n    <td><a href=\"https://nvlabs.github.io/sionna/api/channel.html#sionna.channel.BitPuncturing\" class=\"xref py-xref\"><a class=\"xref xreverseeoln\" href=\"https://nvlabs.github.io/sionna/api/channel.html#sionna.channel.BitPuncturing\">BitPuncturing</a></td>\n    <td>Forwards all but the parity bits of a low-density parity-check (LDPC) code over a given rateless erasure channel.</td>\n  </tr>\n  <tr>\n    <td></td>\n    <td><a href=\"https://nvlabs.github.io/sionna/api/channel.html#sionna.channel.BitPacking\" class=\"xref py-xref\"><a class=\"xref xreverseeoln\" href=\"https://nvlabs.github.io/sionna/api/channel.html#sionna.channel.BitPacking\">BitPacking</a></td>\n    <td>Splits a sequence of information bits into chunks that are independently encoded by a channel coder.</td>\n  </tr>\n  <tr>\n    <td></td>\n    <td><a href=\"https://nvlabs.github.io/sionna/api/channel.html#sionna.channel.BitUnpacking\" class=\"xref py-xref\"><a class=\"xref xreverseeoln\" href=\"https://nvlabs.github.io/sionna/api/channel.html#sionna.channel.BitUnpacking\">BitUnpacking</a></td>\n    <td>Reverses the effect of <a href=\"https://nvlabs.github.io/sionna/api/channel.html#sionna.channel.BitPacking\" class=\"xref py-xref\"><a class=\"xref xreverseeoln\" href=\"https://nvlabs.github.io/sionna/api/channel.html#sionna.channel.BitPacking\">BitPacking</a></td>\n  </tr>\n  <tr>\n    <td></td>\n    <td><a href=\"https://nvlabs.github.io/sionna/api/channel.html#sionna.channel.RatePuncturing\" class=\"xref py-xref\"><a class=\"xref xreverseeoln\" href=\"https://nvlabs.github.io/sionna/api/channel.html#sionna.channel.RatePuncturing\">RatePuncturing</a></td>\n    <td>Forwards all but the rate-1/2 QAM symbols of a coded bit stream over an erasure channel.</td>\n  </tr>\n</tbody></table>\n\nBit-wise operations are mainly utilized in the implementation of low-density parity-check (LDPC) codes where an iterative message passing decoding process is used. This decoding process benefits from binary operations that can manipulate and process data at the bit level.\n\nOn the other hand, constellations are sets of signal points in the complex plane that are used in modulation schemes. These are crucial in the definition of the mapper and demapper stages in a communication system. In higher order modulation, such as 16-QAM or 64-QAM, each constellation point represents a pattern of four or six bits, respectively.\n\nThe concept of constellations and bit-channels is fundamental in the design and analysis of communication systems. These elements play a crucial role in defining the complexity and performance of modulation schemes and in the understanding of error patterns in the transmission of data."
"The `pam` function in the Sionna mapping is used to map a discrete value from a set of possible values to a complex PAM (Pulse Amplitude Modulation) symbol. The function's output is a complex-valued PAM symbol corresponding to the input index.\n\nThe PAM symbol set is optimized for mapping bits in PUSCH and is defined as: \n`[1/sqrt(2)(-3,-1,1,3)]`. \n\nThis function is part of Sionna's mapping module which deals with mapping between bits, symbols and resource grids. \n\nThe function is defined as follows:\n`pam(b)`\nWhere `b` is the index or a tensor of arbitrary shape and dtype, and the output is a tensor with the same shape as `b` and complex dtype.\n\nThe output of the `pam` function is calculated using the following formula:\n`pam(b) = 1/sqrt(2)(-3+2b, -1+2b, 1+2b, 3+2b)`\n\nSionna's mapping module ensures that this function is differentiable by ensuring that the data type for the output of the function is complex64 for all inputs of integer data type, which allows the output to be used in subsequent mathematical operations."
"When using the \"List2LLR\" class in the Sionna package, there are several assumptions that need to be fulfilled:\n\n1. All channel outputs are assumed to be given, even if some entries are unknown or invalid. This is represented in a multidimensional array where the dimensions correspond to the different aspects of the communication system (e.g. antennas, users, OFDM symbols, and subcarriers).\n\n2. The class assumes that the likelihood ratios (LLRs) for all bits are either obtained by demapping methods or computed internally if the \"compute_llrs\" parameter is set to True. \n\n3. It is assumed that the \"List2LLR\" class is used in conjunction with a \"MI2SCR\" or \"MDPC\" object. The MI2SCR object generates initial LLRs and statistical properties of the bits for a given received sequence of channel observations. The \"List2LLR\" class updates these initial LLRs, and, if the \"compute_llrs\" parameter is set to True, it computes the LLRs from the frequency- and time-domain channel estimates and error variances.\n\n4. The class also assumes that the complex Gaussian prior of the received symbols is known. This prior is represented by the multidimensional array \"y\" and the diagonal covariance matrices \"r\" (or the Cholesky decomposition of the covariance matrices), whose dimensions depend on the number of receiver antennas (\"na\") and the number of time/frequency samples.\n\n5. Finally, the \"List2LLR\" class assumes that the code is executed in a TensorFlow environment. This allows for the use of the TensorFlow backend for computations."
"The `MMSEPICDetector` is a class within the 'sionna.mimo' module which implements multi-stream MIMO detection with an Expectation Maximization (EM) algorithm in the context of a Generalized Preprocessing and Successive Interference Cancellation (GP-SIC) receiver. The class assumes a specific wireless transmission model, which includes various parameter specifications. \n\nThe key parameters for the `MMSEPICDetector` class are:\n- **output**: Type of output, either \"bit\" for LLRs on bits or \"symbol\" for logits/xors on constellation symbols. \n- **demapping_method**: The demapping method used, with options of \"app\" or \"maxlog\". \n- **num_streams**: Number of transmitted streams.\n- **num_interfering_streams**: Number of interfering streams. This number includes the streams from the considered user and the interfering user.\n- **num_bits_per_symbol**: The number of bits per constellation symbol, e.g., 4 for QAM16.\n- **constellation_type**: Type of 2D complex-valued vector constellation, options are \"qam\" or \"pam\".\n- **num_tx**: Number of transmitters.\n- **num_rx**: Number of receivers.\n\nThe `MMSEPICDetector` class is used under the following conditions:\n- Expectation Maximization (EM) algorithm: This algorithm is applied to solve the multi-stream MIMO detection problem by replacing the interference covariance matrix with its estimate. The EM algorithm alternates between estimating the interfering user vector and performing detection.\n- Generalized Preprocessing and Successive Interference Cancellation: The MMSE-PIC detector is used as part of this receiver. The detector preprocesses the received signals and linearly decorrelates the interference. Subsequently, detection of the desired user is performed. The receiver closely resembles a group equalizer.\n  \nA note on output: The output of the MMSE PIC Detector is essentially a 2D vector whose elements correspond to the LLRs (or hard-decisions) of the bits of the received symbols."
"The QAM2PAM class in the Sionna novel Python package is used to transform QAM (Quadrature Amplitude Modulation) symbol indices to PAM (Pulse Amplitude Modulation) symbol indices. The class assumes that if an index in the PAM constellation is denoted by $k \\in \\{0,1,\\ldots,M-1\\}$, the corresponding indices for an QAM constellation are computed based on the following assumptions:\n\n\n- if $k$ is odd, i = 2(k-1) + 1 is the index in a QAM constellation,\n- if $k$ is even, i = 2(k-1) is the index in a QAM constellation.\n\n\nThe class is initialized by the parameters `num_bits_per_symbol` which is the number of bits per QAM symbol (e.g., 4 for QAM16) and `dtype` which is the precision type. The precision type is set to `tf.complex64` by default.\n\nThe transformation from QAM symbol indices to PAM symbol indices is performed by the `qam2pam` method. This method takes as input QAM symbol indices and returns PAM symbol indices. The `qam2pam` method also supports batch processing, such that a batch of QAM symbol indices can be passed and a batch of PAM symbol indices will be returned.\n\nHere is a a coded example of how to define the `QAM2PAM` class and tranform QAM symbol indices to PAM symbol indices:\n\n```python\nfrom sionna.mimo import QAM2PAM\n\n# Define the QAM2PAM class\nqam2pam = QAM2PAM(num_bits_per_symbol=4, # 16QAM\n                dtype=tf.complex64) \n\n# Transform QAM symbol indices to PAM symbol indices\npam_indices = qam2pam([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n```\n\nIn this example, `pam_indices` will hold the PAM symbol indices corresponding to the QAM symbol indices that were passed as input to the `qam2pam` method.\n\nRemember that the explanation provided pertains to the general design of the `QAM2PAM` class. The specific implementation and usage may vary based on its intended application or the requirements of the user."
"To verify that the generator matrix (GM) and parity-check matrix (PCM) are orthogonal in GF(2) using the `verify_gm_pcm` function from the Sionna package, you need to follow these steps:\n\n1. First, you need to import the necessary functions from the Sionna package. These include the `verify_gm_pcm` function, which is the main function used for verification, and the `build_pcm` and `build_gm` functions, which are used to generate random parity-check and generator matrices. \n\n```python\nfrom sionna.fec.utils import verify_gm_pcm, build_pcm, build_gm\n```\n\n2. Next, you need to create a random parity-check matrix (PCM) and generator matrix (GM). The GM must be binary and orthogonal to the PCM in GF(2).\n\n```python\npcm, gm = None, None\nsuccess = False\nwhile not success:\n    pcm = build_pcm(256, 512)\n    gm = build_gm(512, 256, pcm, is_pcm=True)\n    success, err_msg = verify_gm_pcm(gm, pcm)\n```\n\nIn this code, the `build_pcm` function is used to generate a random parity-check matrix, and the `build_gm` function is used to generate a corresponding generator matrix. The `verify_gm_pcm` function is then used to verify that the GM and PCM are orthogonal. If the matrices are orthogonal, the function will return a boolean `success` which will be `True`. If the matrices are not orthogonal, the function will return an error message explaining why the verification failed.\n\n3. Finally, you can print the result of the verification and use it to determine whether the GM and PCM are orthogonal. If the matrices are orthogonal, you can proceed with your computations.\n\n```python\nprint(\"Success:\", success)\n```\n\nThe `verify_gm_pcm` function also has an optional `tolerance` parameter, which can be used to account for numerical imprecisions when verifying the orthogonality of the matrices. This can be useful when working with floating-point representations of the matrices. For binary representations as in this case, the default tolerance of 1e-12 should be sufficient for most applications. However, if you require a higher tolerance, you can set it as follows:\n\n```python\nsuccess, err_msg = verify_gm_pcm(gm, pcm, tolerance=1e-20)\n```\n\nRemember that the ultimate test of orthogonality is performed in GF(2), so the generator and parity-check matrices must be binary. The `verify_gm_pcm` function will return an error if this condition is not met."
"To import the `LinearEncoder` class from the `sionna.fec.linear` module, you can use the following line of Python code:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n```\n\nKeep in mind that you need to have the necessary package installed in your Python environment to successfully import the class. In this case, you need to have the `sionna` package installed. If it's not installed yet, you can install it using pip:\n\n```python\npip install sionna\n```\n\nAfter successfully installing the package, you should be able to import the `LinearEncoder` class from the `sionna.fec.linear` module without any issues."
"The `OFDMDetectorWithPrior` class in the `sionna.ofdm` module is used for detecting Orthogonal Frequency-Division Multiplexing (OFDM) transmissions, by estimating the data symbols and the prior knowledge on the data, in order to facilitate detection of the OFDM symbols. This class assumes that a channel model, post-DFT equalizer, and prior knowledge on the channel were given. \n\nTo accomplish the detection process, the `OFDMDetectorWithPrior` class closely works with the `ResourceGrid`, the `StreamManagement`, and the `OFDMDetectorWithPrior` classes. An instance of the `OFDMDetectorWithPrior` class can be created by providing necessary parameters such as the detector type, the output, the resource grid, the stream management, the demapping method, the detection method, the number of detected streams, the window width, the number of estimated paths, and the swap memory flag. \n\nAfter creation, the `OFDMDetectorWithPrior` class can be used to detect the transmission by calling its object directly as a function, with the input being the received signal. The class can also provide certain output results like the estimated data symbol vectors, effective noise variance estimates, and the indices of the detected streams.\n\nThis `OFDMDetectorWithPrior` class represents a layer from a OFDM detection layer series of algorithms, and is suitable for use in detection processes where prior knowledge on the data or the channel is available."
"The function \"bin2int_tf\" is used to convert a binary tensor to an integer tensor. In the binary representation, numbers are expressed as combinations of 0s and 1s. The \"bin2int_tf\" function processes a binary tensor, in which each element is either 0 or 1, and converts this binary representation into an integer tensor.\n\nThe function takes a tensor \"y\" with dtype tf.int as input. This tensor represents the binary vector that needs to be converted into an integer. The output of the function is another tensor, \"x,\" with the same shape as the input, but with dtype tf.int. The new tensor holds the integer interpretation of the binary input. \n\nIn other words, if we have a binary tensor like `y = [0 1 1 0]`, the \"bin2int_tf\" function will return the integer tensor as its output, which is the integer value represented by the binary vector, in this case, `x = [2]`.\n\nNote that the function is specifically designed to handle binary tensors, and will not work if the input contains any elements other than 0s and 1s. This function is part of a utility module in the Sionna package, which contains general functions and classes used across the package."
"To use the `TB5GScrambler` from the Sionna library for 5G NR compliant scrambling, you first need to create a PUSCH configuration with default settings using the `PUSCHConfig` class. Then, you can create the scrambler using the created `PUSCHConfig`.\n\nHere is the usage in Python:\n\n```python\nfrom sionna.nr import PUSCHConfig\nfrom sionna.nr.scrambling import TB5GScrambler\n\n# Create PUSCH configuration with default settings\npusch_config = PUSCHConfig()\n\n# Create the scrambler using the PUSCH configuration\nscrambler = TB5GScrambler(pusch_config)\n\n# Now, you can use the scrambler to scramble a sequence\n# For example, let's scramble a sequence of 1s and 0s with a length of 'n'\n# 'c' would be the scrambled version of 'seq'\nc = scrambler(seq)\n\n# You can also provide the sequence directly to the TB5GScrambler \n# if it has been defined with the explicit data 'n' and 'num_bits_per_symbol'\n# For example, if you want to scramble a QAM sequence, you can define the\n# sequence with the explicit number of bits per QAM symbol\n# n and num_bits_per_symbol must be compliant with 3GPP specifications\nqam_config = QAMConfig(n, num_bits_per_symbol)\n\n# Define the QAM sequence with the explicit QAM configuration\nqam_sequence = QAMSource(qam_config)(batch_size, seq_length)\n\n# Scramble the QAM sequence\nqam_scrambled = scrambler(qam_sequence)\n```\n\nRemember to replace `seq` and `batch_size` with your actual sequence and batch size. The `PUSCHConfig` and `QAMConfig` should be created with the appropriate values of `n` and `num_bits_per_symbol` as per your use case. \n\nAlso, ensure that the 'TB5GScrambler' and other related classes from the Sionna library are installed correctly before running this code. You can find more details on how to install Sionna in the documentation."
"Here is the detailed information of int_mod_2: [sionna.fec.utils.int_mod_2(x)](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#int_mod_2)  \n  \nComputes the int_modulo operation for x with modulus 2.\n\nInput\n\n   x (int) \u2013 A non-negative integer.\n\nOutput\n\n   y (int) \u2013 The integer remainder after division of x by 2.  \n  \nsource code:  \n```python\ndef int_mod_2(x):\n    r\"\"\"Computes the int_modulo operation for ``x`` with modulus 2.\n\n    Input\n    -----\n        x : int\n            A non-negative integer\n\n    Output\n    -----\n        y : int\n            The integer remainder after division of ``x`` by 2.\n    \"\"\"\n    y = x & 1\n    return y\n```  \n  "
"Here is the detailed information of sionna.utils.SymbolSource:  \n\nLink of the source code: https://nvlabs.github.io/sionna/_modules/sionna/utils/misc.html#SymbolSource\n\nsource code:\n```python\nclass SymbolSource(Sequence):\n    # pylint: disable=line-too-long\n    r\"\"\"SymbolSource(constellation_type, num_bits_per_symbol, constellation, dtype=tf.complex64)\n\n    Generates a source of symbols, either random or sequentially provided.\n\n    The ``SymbolSource`` is a ``Sequence`` and can, thus, be used\n    similarly to a Keras layer with the ``@tf.function`` decorator.\n\n    Parameters\n    ----------\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type`` and\n        ``num_bits_per_symbol`` must be provided.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of the output. Defaults to tf.complex64.\n        ``real_dtype`` is automatically set to tf.complex2.dtype.\n\n    Output\n    ------\n    : [batch_size, sequence_length], tf.complex\n        The modulated constellation symbols.\n    \"\"\"\n    def __init__(self,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 dtype=tf.complex64):\n        # pylint: disable=line-too-long\n        r\"\"\"\n        Input\n        -----\n        constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n            For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n            must be provided.\n\n        num_bits_per_symbol : int\n            The number of bits per constellation symbol, e.g., 4 for QAM16.\n\n        constellation : Constellation\n            An instance of :class:`~sionna.mapping.Constellation` or `None`.\n            In the latter case, ``constellation_type`` and\n            ``num_bits_per_symbol`` must be provided.\n\n        dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n            The dtype of the output. Defaults to tf.complex64.\n            ``real_dtype`` is automatically set to tf.complex2.dtype.\n        \"\"\"\n        super().__init__()\n\n        # Create constellation object\n        if constellation is None:\n            assert constellation_type is not None and \\\n                   num_bits_per_symbol is not None, \\\n                   \"Either constellation or constellation_type and \" \\\n                   \"num_bits_per_symbol must be provided.\"\n            constellation = Constellation(constellation_type,\n                                           num_bits_per_symbol,\n                                           dtype=dtype)\n        else:\n            assert constellation_type is None and \\\n                   num_bits_per_symbol is None, \\\n                   \"Cannot provide both constellation and \" \\\n                   \"constellation_type and num_bits_per_symbol.\"\n        self._constellation = constellation\n\n        self.dtype = dtype\n        if dtype == tf.complex64:\n            self._real_dtype = tf.float32\n        else:\n            self._real_dtype = tf.float64\n\n    @property\n    def constellation(self):\n        \"\"\"The :class:`~sionna.mapping.Constellation` object.\"\"\"\n        return self._constellation\n\n    def __call__(self, input_shape, seed=None, with_labels=False):\n        \"\"\"Modulated symbols\n\n        Input\n        -----\n        input_shape : (batch_size, number_of_symbols), tf.int\n            The shape of the input. If `seed` is an explicit value, it\n            should be of shape [2] and dtype tf.int32.\n\n        Output\n        ------\n        : [batch_size, sequence_length], tf.complex\n            The modulated constellation symbols.\n        \"\"\"\n        if seed is not None:\n            if isinstance(seed, int):\n                seed = [seed]\n            elif isinstance(seed, (tuple, list)) and len(seed) == 1:\n                # Add an additional 0 to the seed to make it compatible with\n                # the Sequence object that expects an explicit seed for\n                # each call.\n                seed = list(seed) + [0]\n            else:\n                raise ValueError(\"seed must be None, an integer, or \" +\n                                \"a tuple of two integers.\")\n\n        shape = tf.concat([input_shape,\n                          [self.constellation._num_bits_per_symbol]], 0)\n        bits = sn_utils.binary_source(shape, seed, with_labels)\n        x = self.constellation.modulate(bits)\n        return x\n```\n"
"Here is the detailed information of ChannelModel:   \n  \n[sionna.channel.ChannelModel](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel)  \n\nAbstract class that defines an interface for channel models.\n\nAny channel model which generates channel impulse responses must implement this interface. All the channel models available in Sionna, such as RayleighBlockFading or TDL, implement this interface.\n\nPlease note that the ChannelModel generates channel impulse responses in the time domain. These can be converted to channel responses in the frequency domain using the channel_time_to_freq() and channel_freq_to_time() methods of a ChannelModel instance.\n\n**Input**\n\n- `batch_size` (int): Batch size.\n- `num_time_steps` (int): Number of time steps.\n- `sampling_frequency` (float): Sampling frequency [Hz].\n\n**Output**\n\n- `a` ([batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex): Path coefficients.\n- `tau` ([batch size, num_rx, num_tx, num_paths], tf.float): Path delays [s].\n\n**Abstract methods**\n1. **`__call__(batch_size, num_time_steps, sampling_frequency)`**\n\n    Generates and returns channel impulse responses.\n  \n    *Input**\n      - `batch_size` (int): Batch size.\n      - `num_time_steps` (int): Number of time steps.\n      - `sampling_frequency` (float): Sampling frequency [Hz].\n    \n    *Output*\n      - `a` ([batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex): Path coefficients.\n      - `tau` ([batch size, num_rx, num_tx, num_paths], tf.float): Path delays [s].\n  \n**Method: `cir_to_ofdm_channel(cir, resource_grid)`**\n  \nGenerate the channel frequency response from the channel impulse response.\n\nGiven a channel impulse response $(a_{m}(t), \\tau_{m}), 0 \\leq m \\leq M-1$, generated by the channel model, where $a_{m}(t)$ is the path coefficient and $\\tau_{m}$ the path delay, the channel frequency response for the $k^{th}$ subcarrier and $l^{th}$ OFDM symbol is computed as follows: $\\widehat{h}_{k, l} = \\sum_{m=0}^{M-1} a_{m}(t) e^{-j 2 \\pi f \\tau_{m}}$ where $f$ is the $k^{th}$ subcarrier frequency and $t$ the time step.\n\nThis method returns the channel frequency responses $\\{\\widehat{h}_{k, l}\\}_{k,l}$ for all transmitters and their antennas, on all frequency subcarriers, for the batch of channel input sequences.\n\n**Input**\n- `cir` (`[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps]`, tf.complex): Path coefficients.\n- `resource_grid` (ResourceGrid): Resource grid.\n\n**Output**\n- `h_freq` (`[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_ofdm_symbols, fft_size]`, tf.complex): Channel frequency responses."
"Building a custom `RadioMaterial` in the `Sionna` package involves defining the properties of the material that would affect radio wave propagation, such as conductivity, relative permittivity, permeability, and possibly other custom properties. These properties could be defined as scalar values or as n-dimensional arrays for cases such as anisotropic material properties. \n\nAfter defining the custom `RadioMaterial`, it needs to be attached to a `SceneObject`. The `SceneObject` would represent a component of the scene that the `RadioMaterial` is being defined for, such as a building, car, etc. This is crucial because when propagating `Paths`, which are generated using the `compute_paths()` method of a `Scene`, the `RadioMaterial` of the `SceneObject` is used for accurate radio wave propagation simulation.\n\nHere is a basic demonstration of how to build a custom `RadioMaterial` and attach it to a `SceneObject` in Sionna:\n\n```python\nfrom sionna.rt import RadioMaterial, Scene, SceneObject\n\n# Define the custom RadioMaterial\ncustom_material = RadioMaterial(conductivity=0.0001,\n                                 relative_permittivity=3,\n                                 relative_permeability=1,\n                                 antenna_polarization='V')\n\n# Instantiate the Scene and attach the RadioMaterial to a SceneObject\nscene = Scene()\nscene.add(SceneObject(name=\"my_object\",\n                      radio_material=custom_material,\n                      position=[x, y, z],\n                      orientation=[alpha, beta, gamma]))\n```\n\nIn the code above, you should replace `x, y, z, alpha, beta, gamma` with the actual values. The `position` parameter is for the position of the `SceneObject` in the scene, and the `orientation` parameter is for the orientation of the `SceneObject`. The `radio_material` parameter is where you attach the custom `RadioMaterial` to the `SceneObject`.\n\nPlease note that the custom `RadioMaterial` is defined by providing the necessary material properties like conductivity, relative permittivity, relative permeability, and antenna polarization as specified in the context. Anisotropic radio materials can be defined by providing a 3x3 tensor for `relative_permittivity` or `relative_permeability`.\n\nAlso, remember that the use of custom materials may not be supported by certain features of the `Sionna` package, such as the use of `ComputePaths`."
"To perform maximum a posteriori (MAP) decoding with a `BCJRDecoder` instance from the Sionna package, you can follow the steps below. Note that the `BCJRDecoder` instance will be used to decode the likelihood ratios (`llr_ch`) or a tuple of likelihood ratios (`llr_ch, llr_a`), and make sure to set the `hard_out` parameter to `True` if you want the decoder to provide hard decisions on the transmitted bits.\n\nFirst, create an instance of the BCJRDecoder, providing the necessary parameters such as the termination type, the polynomial, the number of bits per symbol, and the starting state of the encoder (if applicable). For example:\n\n```python\nfrom sionna.fec.linear import BCJRDecoder\n\nbcjr_decoder = BCJRDecoder(pcm, termination=\"tail\", polynom=\"rsc\", hard_out=True, l_min=sm, encoder_state=None)\n```\n\n, where `pcm` is a parity-check matrix imported using the appropriate method.\n\nIf your input is just `llr_ch` representing the channel output symbols, you can directly call the instance `bcjr_decoder` with `llr_ch` as the input, like this:\n\n```python\ndecoded_bits = bcjr_decoder(llr_ch)\n```\n\nHere, `llr_ch` should have a tensor shape of `[..., n]`, where `n` is the number of symbols transmitted.\n\nOn the other hand, if you also have access to the prior knowledge on the bits `llr_a`, which typically comes from a demapper in a larger communication system, you should provide these as an additional argument to the decoder, like so:\n\n```python\ndecoded_bits = bcjr_decoder((llr_ch, llr_a))\n```\n\nIn this case, `llr_ch` and `llr_a` should both have tensor shapes of `[..., n]`, and `llr_a` represents the a priori information of the transmitted bits.\n\nAfter running the decoder, `decoded_bits` will contain the estimated bits and be a tensor of shape `[..., n]`. If `hard_out=True`, the output will consist of hard bit decisions (i.e., binary values), otherwise, it will be soft estimates of the transmitted bits.\n\nThe type of the output tensor is dependent on the input parameters. If `hard_out=True`, the output will be of type `tf.float32`, with the last dimension being 1, i.e., `[..., n, 1]`. If `hard_out=False`, the output will be of the same shape as the input `llr_ch`, with the last dimension being `k`, representing the estimated information bits.\n\nRemember that the description above is for the `BCJRDecoder`, which is a state-of-the-art implementation of the BCJR algorithm for arbitrary binary parity-check codes. The actual implementation for a specific use case may vary depending on the exact requirements and the code structure."
"To use the `ebnodb2no` function in the 'Sionna' package, you need to understand its inputs and what they represent, as this function directly deals with simulation parameters related to antennas and radio propagation modelling in the domain of 5G NR simulations.\n\nHere are the steps to walk through the model:\n\n1. Import the necessary components: You should import the `ebnodb2no` function from the relevant Sionna package. This is typically done with an import statement like the following:\n\n```python\nfrom sionna.nr import ebnodb2no\n```\n\n2. Provide the input parameters: The function `ebnodb2no` requires two input parameters which are specified as follows:\n\n- **ebno_db** (float): This represents the desired Eb/No value in dB. Eb/No is the energy per bit to noise power spectral density, a key parameter in digital communication systems.\n- **dtype** (tf.DType): This is an optional parameter that represents the data type. It defaults to `tf.float32`, and typically doesn't need to be specified by the user.\n\n3. Call the function: You can now call `ebnodb2no` with the parameters you've defined, like so:\n\n```python\nno = ebnodb2no(ebno_db, dtype)\n```\n\n4. Understand the return value: The `ebnodb2no` function returns a floating point representing the noise power spectral density (`tf.float32`). The returned value is referred to as 'no' in the example above, representing the noise power spectral density that was calculated from the given Eb/No in dB and data type.\n\nRemember that the `ebnodb2no` function is a utility function used in simulations, specifically in the context of 5G NR simulations where these parameters are used in almost every component of the system model, including the transmitters, receivers, and the propagation environment. Keep in mind that the actual application may vary depending on the specific use case or simulation scenario."
"To evaluate the baseline and the two autoencoder-based communication systems, the author of the Sionna package performed a series of simulations. Here's how they did it:\n\n1. **Setting up the environment**: The author set up an environment using several components including Gaussian distributed channel coefficients, an OFDM channel, an re-coder/de"
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, follow these steps:\n\n1. Import the necessary modules:\n```python\nimport os\nimport tensorflow asjson tf\n```\n\n2. Specify the GPU you want to use. If you want to use the CPU, set `gpu_num` to an empty string (\"\"). In this example, GPU number 0 is specified:\n```python\ngpu_num = 0\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n```\n\n3. Set the TensorFlow log level to 3, which means only ERROR messages are printed:\n```python\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n4. List the physical devices available for TensorFlow and set the memory growth of the selected GPU. Memory growth needs to be enabled to allocate only as much GPU memory as needed for the runtime:\n```python\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\n5. To ensure reproducibility across different executions, set a global random seed:\n```python\ntf.random.set_seed(1)\n```\n\n6. Finally, test the TensorFlow installation and check the GPU status:\n```python\nfrom tensorflow.python.client device_lib import list_local_devices\nprint([d.name for d in list_local_devices() if \"GPU\" in d.name])\n```\n\nPlease note that the exact steps and the modules used may vary depending on your specific requirements and the environment you are working in."
"The `j_fun` function in the Sionna package is used to calculate the J-function which quantifies the mutual information per degree of freedom for a given complex Gaussian channel. This function utilizes the Q-function which is the tail probability of the standard normal distribution. \n\nHere's how you can use the \"j_fun\" function:\n\n```python\n    import numpy as np\n    from sionna.utils import j_fun\n    \n    # Define the channel parameter\n    num_rx = 4  # Number of receivers\n    num_rx_ant = 8  # Number of dual-polarized antennas per receiver\n    num_tx = 2  # Number of transmitters\n    num_tx_ant = 4  # Number of antennas per transmitter, here 4 for CDL\n    num_bits_per_symbol = 4  # 16-QAM\n    \n    # Assuming you have a received covariance matrix 'c' and a vector of\n    # non-negative eigenvalues 'd'. If not, generate some positive definite\n    # channel covariance matrix for illustration purposes.\n    # Note: The matrix should be in the numpy.complex128 format.\n    # If you are directly using c and d from a channel model, they should\n    # typically be in the correct format already.\n    # If not, you might need to convert them using a function like the following:\n    # c = np.complex128(c)\n    # d = np.maximum(0., np.real(d)).astype(np.complex128)\n\n    # Generate the J-function. This will return a real float value.\n    j = j_fun(num_bits_per_symbol, num_rx, num_rx_ant, num_tx, num_tx_ant, c, d)\n```\n\nRemember to replace `num_bits_per_symbol`, `num_rx`, `num_rx_ant`, `num_tx`, and `num_tx_ant` with the actual values corresponding to your use case. The function parameters `c` and `d` are the received covariance matrix and the vector of non-negative eigenvalues, respectively.\n\nThe function will return a real float \"J\" value which you can then use as needed in your application. No further user interaction is needed."
"Here is the definition of PUSCHTransmitter: sionna.nr.PUSCHTransmitter(pusch_configs, return_bits=True, output_domain='freq', dtype=tf.complex64, verbose=False, **kwargs)\nThe source code link of PUSCHTransmitter is [PUSCHTransmitter](https://nvlabs.github.io/sionna/_modules/sionna/nr/pusch_transmitter.html#PUSCHTransmitter)\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"Transmitters for the PUSCH sub-package of Sionna\"\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Layer\nfrom sionna.nr import PUSCHConfig, PUSCHCarrier\nfrom sionna.utils import generate_prng_seq\nfrom sionna.mimo import StreamManagement\nimport numpy as np\n\nclass PUSCHTransmitter(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"PUSCHTransmitter(pusch_configs, return_bits=True, output_domain=\"freq\", dtype=tf.complex64, **kwargs)\n\n    This class brings together multiple :mod:`sionna.nr` components to\n    build a PUSCH transmitter. It is designed to simulate transmissions\n    of multiple UEs to a gNB or multiple transmitters to a mutliple U\n    into a specified OFDM resource grid.\n\n    Parameters\n    ----------\n    pusch_configs : list of :class:`~sionna.nr.PUSCHConfig`\n        List of PUSCH configurations.\n\n    return_bits : bool\n        Indicates if the layer should return soft-symbol instead of bit\n        values. Defaults to `True`.\n\n    output_domain : One of [\"freq\", \"time\"]\n        Domain for the output signal. Defaults to \"freq\".\n\n    dtype : tf.DType\n        The data type for internal calculations and the output.\n        Defaults to `tf.complex64`.\n\n    Input\n    -----\n    : [batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], tf.complex\n        List of frequency-domain vectors that will be mapped to OFDM resource\n        grid\n\n    Output\n    ------\n    : [batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols,  for ``return_bits`` = `False`\n      : [batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols*num_slots_per_ofdm,  for ``return_bits`` = `True`\n        The output-domain PUSCH signal\n    \"\"\"\n    def __init__(self,\n                 pusch_configs,\n                 return_bits=True,\n                 output_domain=\"freq\",\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n\n        assert output_domain in [\"freq\", \"time\"], \\\n               \"output_domain must be 'freq' or 'time'\"\n        self._output_domain = output_domain\n\n        assert isinstance(return_bits, bool), \"return_bits must be bool\"\n        self.return_bits = return_bits\n\n        self._num_tx = len(pusch_configs)\n        self._num_tx_ant = pusch_configs[0].carrier.num_tx_ant\n        self._num_streams_per_tx = pusch_configs[0].num_layers\n        self._num_ofdm_symbols = pusch_configs[0].ofdm_symbol_duration\n        self._fft_size = pusch_configs[0].subcarrier_spacing\n        self._num_subcarriers = pusch_configs[0].resource_grid.num_subcarriers\n        self._num_resceivers = 1\n\n        self._pusch_carrier = PUSCHCarrier(pusch_configs[0])\n\n        # Create a resorcerer grid to be used by all PUSCHTransmitter\n        rg = pusch_configs[0].resource_grid\n        self._resource_grid = tf.broadcast_to(rg, [self._num_tx, self._num_resceivers])\n\n        # Create a common subcarrier mapping that is going to be used by all\n        # PUSCHTransmitter\n        pusch_configs[0].precoding.precoding_type = \"codebook\"\n        self._precoding_mapping = pusch_configs[0].resource_grid.subcarrier_mapping\n\n        # All the PUSCHConfigs are going to be validated and the weights\n        # are going to be generated during the call method\n        self._pusch_configs = pusch_configs\n\n        # StreamManagement object\n        self._stream_manager = StreamManagement(self._num_tx,\n                                                self._num_streams_per_tx,\n                                                \"PUSCH\",\n                                                \"transmitter\")\n\n    # pylint: disable=arguments-differ\n    def build(self, batch_size):\n        \"\"\"Build the PUSCH transmitter\"\"\"\n\n        # Generate the RNG sequence that will be used to for PRNG\n        c_init = [100, 200]\n        c = generate_prng_seq(self._num_tx, batch_size, self._num_tx_ant,\n                              self._num_streams_per_tx,\n                              self._num_ofdm_symbols,\n                              self._fft_size,\n                              c_init)\n\n        for pusch_config in self._pusch_configs:\n            pusch_config.build(c, self._resource_grid, self._output_domain,\n                                self._precoding_mapping)\n\n    def call(self, inputs):\n        # Users may sample the channel or the channel is externally sampled.\n        # In the former case, we need to generate the channel first\n        # then transmit signals.\n        # Generate the channel frequency response\n        # Shape: [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, \\\n        #        num_ofdm_symbols, fft_size]\n        if self._output_domain == \"freq\":\n            h = self._pusch_carrier.channel(samples_per_symbol=self._num_ofdm_symbols)\n            h = tf.squeeze(h, axis=1)\n        else:\n            h = inputs[0]\n\n        # Transmit the signal\n        # Shape: [batch_size, num_tx, num_tx_ant, num_ofdm_symbols, fft_size]\n        x = self._pusch_carrier.transmit(h)\n\n        # Reshape x into the expected shape\n        # Shape: [batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols, \\\n        #        fft_size]\n        x = tf.reshape(x, [-1, self._num_tx, self._num_tx_ant,\n                        self._num_streams_per_tx, self._num_ofdm_symbols,\n                        self._fft_size])\n\n        # Gather the respective streams for all transmitters\n        # pusch_config streams must be mapped onto resource grid prior to\n        # this operation\n        # StreamManagement\n        x = self._stream_manager(x)\n\n        if self.return_bits:\n            # Turn into a list to enable returning multiple tensors instead\n            # of a single one\n            x_list = tf.unstack(x, self._num_tx, 1)\n\n            # Get the PUSCH symbols from the resource grid. Separate real and\n            # imaginary parts to compute LLRs\n            y = []\n            for i in range(self._num_tx):\n                y.append(self._pusch_configs[i].resource_grid(x[i])\n                    [:,0,:,:])  # Only the real part is considered\n            # pylint: disable=unbalanced-tuple-unpacking\n            y = tf.stack(y, axis=1)\n            # Reshape y to the expected shape\n            #[batch_size, num_tx, num_codewords, num_scb, num_ofdm_symbols,..\n            #  ..fft_size]\n            y = tf.squeeze(y, axis=-2)\n\n        else:\n            y = self._resource_grid(x)\n\n        return y\n```"
"Here is the detailed information of verify_gm_pcm: sionna.fec.utils.verify_gm_pcm(gm, with_plot=True) \n  \nVerifies that the generator matrix is orthogonal with respect to the parity-check matrix.\n\nThis function implements Lemma 1 from [S. K. Planjery, H. D. Pfister, and A. Abdelaziz, \u201cDensity evolution for multi-dimensional generalized min-sum parity-check codes,\u201d in Proc. of ITW, 2010.]. It leverages the fact that for an orthogonal generator matrix, the row space of gm contains all codewords that are also in the row space of the parity-check matrix.\n\n**Input**\n\n- `gm` (ndarray): Binary generator matrix of shape `[k, n]`.\n- `with_plot` (bool): Indicates if a plot of the results should be generated.\n\n**Output**\n\n- `success` (bool): Indicates if the validation was successful.\n- `beta` (float): Value of \u03b2 used in the validation.\n  \nIf `with_plot` is set to True, the function returns \u03b2 and also generates a plot that visualizes the density of codewords in the row space defined by the generator matrix and the parity-check matrix. The plot is based on the idea of fig. 4 in [S. K. Planjery, H. D. Pfister, and A. Abdelaziz, \u201cDensity evolution for multi-dimensional generalized min-sum parity-check codes,\u201d in Proc. of ITW, 2010.].  \n  \n**Note: **This implementation only works for binary generator matrices.\n\nsource code:  \n```python\ndef verify_gm_pcm(gm, with_plot=True):\n    # pylint: disable=line-too-long\n    r\"\"\"Verifies that the generator matrix is orthogonal with respect to the parity-check matrix.\n\n    This function implements Lemma 1 from \\cite[SPPF10]_. It leverages the\n    fact that for an orthogonal generator matrix, the row space of ``gm``\n    contains all codewords that are also in the row space of the parity-check\n    matrix.\n\n    Input\n    -----\n    gm : ndarray\n        Binary generator matrix of shape `[k, n]`.\n\n    with_plot: bool\n        If ``with_plot=True`` a plot of the results will be generated.\n\n    Output\n    ------\n    success : bool\n        Indicates if the validation was successful.\n\n    betai : float\n        Value of :math:`\\beta` used in the validation.\n\n    If ``with_plot`` is set to :math:`\\text{True}`, the function returns\n    :math:`\\beta` and also generates a plot that visualizes the density of\n    codewords in the row space defined by the generator matrix and the\n    parity-check matrix. The plot is based on the idea of fig. 4 in \\cite[SPPF10]_.\n    \"\"\"\n    assert isinstance(with_plot, bool), \"with_plot must be bool.\"\n    # Encoding to full rank PCM such that we can find beta for the full PCM\n    pcm = gm2pcm(gm)\n    k, n = pcm.shape\n\n    # Verify that gm and pcm are full rank\n    assert k < n, \"Generator matrix cannot be full rank.\"\n\n    # Load node_deg and max_m from file (see [SPPF10]_)\n    if str(k).zfill(3)==\"011\":\n        # pylint: disable=C0301\n        with open(os.path.join(sionna_fec_utils.__path__[0], \"rmat_node_deg_m.inc.py\"), \"r\") as f:\n            exec(f.read())\n    else:\n        node_deg_m = load_pickle(os.path.join(sionna_fec_utils.__path__[0], \"rmat_node_deg_m.pkl\"))\n\n    # Iteratively encode batches until we find a codeword that is also in the PCM\n    success = False\n    idx = 0\n    while not success:\n        print(f\"Run verify_gm_pcm batch index: {idx}\")\n        coder = Encoder(generating_matrix=gm, with_pcm=False)\n        cw = coder.generate_codeword(k=1, n=n)\n        # pylint: disable = unsubscriptable-object\n        # pylint: disable = line-too-long\n        dist = min(np.sum(cw[None,:], axis=1).astype(int32), np.sum(np.invert(cw)[None,:], axis=1).astype(int32))\n        if dist in node_deg_m:\n            success = True\n        idx += 1\n    print(f\"Success of verify_gm_pcm: {success} (Satisfied node degree = {node_deg_m[dist]})\")\n\n    # We need to find the right beta such that the codewords are dense in the\n    # linear space defined by the pcm\n    # dist = np.sum(cw, axis=1)\n    # num_cws = np.sum(dist==0)\n    # beta = num_cws / n # Density of codewords in the linear space\n    # (see [SPPF10]_, Lemma 1)\n    #dist_a = np.sum(np.invert(cw), axis=1)\n    #num_cws_a = np.sum(dist_a==0)\n    #beta_a = num_cws_a / n # Density of codewords in the linear space\n    #plt_desired = 0.9 # For the plot\n    #plt_value = np.maximum(np.min(cw), np.min(np.invert(cw))) # For the plot\n    #if with_plot:\n    #    plt_figure = plt.figure()\n    #    plt.axes()\n    #    plt.xticks([], [])\n    #    plt.yticks([], [])\n    #    plt.text(x=-0.5, y=0, s=f\"$\\\\beta={beta}\\\\Rightarrow\\\\frac{{{num_cws}}}{{{n}}$ cw/chnl. dens.}\", horizontalalignment=\"left\", verticalalignment=\"center\")\n    #    plt.text(x=-0.5, y=1, s=\"$\\mathbf{C}$\", color=\"C0\", fontweight=\"bold\", horizontalalignment=\"left\", verticalalignment=\"top\")\n    #    plt.text(x=1, y=1, s=\"$\\\\mathbf{\\~{C}}$\", color=\"C3\", fontweight=\"bold\", horizontalalignment=\"left\", verticalalignment=\"top\")\n    #    for i in range(cw.shape[1]):\n    #        plt.text(x=i, y=1.03, s=f\"${cw[0,i]}$\", color=\"C0\", fontweight=\"bold\", horizontalalignment=\"center\", verticalalignment=\"bottom\")\n    #        plt.text(x=i, y=-0.15, s=f\"${cw[0,i]}$\", color=\"C0\", fontweight=\"bold\", horizontalalignment=\"center\", verticalalignment=\"top\")\n    #    for i in range(cw.shape[1]):\n    #        plt.text(x=i, y=1.03, s=f\"${cw[0,i]}$\", color=\"C0\", fontweight=\"bold\", horizontalalignment=\"center\", verticalalignment=\"bottom\")\n    #        plt.text(x=i, y=-0.15, s=f\"${cw[0,i]}$\", color=\"C0\", fontweight=\"bold\", horizontalalignment=\"center\", verticalalignment=\"top\")\n    #    for i in range(cw.shape[1]):\n    #        plt.text(x=i, y=pcm.shape[0]+0.03, s=f\"${cw[0,i]}$\", color=\"C0\", fontweight=\"bold\", horizontalalignment=\"center\", verticalalignment=\"bottom\")\n    #        plt.text(x=i, y=pcm.shape[0]-1.3, s=f\"${cw[0,i]}$\", color=\"C0\", fontweight=\"bold\", horizontalalignment=\"center\", verticalalignment=\"top\")\n    #    for i in range(pcm.shape[1]):\n    #        plt.text(x=pcm.shape[1]+0.3, y=pcm.shape[0]/2+i, s=f\"${pcm[0,i]}\", color=\"C1\", fontweight=\"bold\", horizontalalignment=\"left\", verticalalignment=\"center\")\n    #        plt.text(x=pcm.shape[1]+0.3, y=pcm.shape[0]/2+i, s=f\"${pcm[0,i]}}$\", color=\"C1\", fontweight=\"bold\", horizontalalignment=\"left\", verticalalignment=\"center\")\n    #    plt.xlim(-0.75, cw.shape[1]+1.25)\n    #    plt.ylim(pcm.shape[0], -0.5)\n    #    plt.imshow(cw[None,:], interpolation=\"none\", aspect=\"auto\")\n    #    plt.imshow(np.invert(cw)[None,:], interpolation=\"none\", aspect=\"auto\")\n    #    return beta, plt_figure\n```"
"The permittivity and permeability are fundamental concepts in electromagnetism, specifically in the study of wave propagation. \n\nPermittivity (denoted as \u03b5) represents the extent to which a medium can support an electric field. It is calculated as the ratio of the electric displacement field (D) to the electric field (E). In mathematical terms, this is expressed as \u03b5 = D/E.\n\nPermeability (denoted as \u03bc) is a measure of the opposition offered by a medium to the magnetic field. It is calculated as the ratio of the magnetic flux density (B) to the magnetic field (H). In mathematical terms, this is expressed as \u03bc = B/H.\n\nIn a medium that is both electrically and magnetically neutral, the refractive index (n) is defined as the square root of the product of the permeability and permittivity of the medium. This quantity plays a crucial role in the propagation of light and other electromagnetic waves."
"Here is the detailed information of RemoveNulledSubcarriers:   \n  \n[sionna.ofdm.RemoveNulledSubcarriers(resource_grid, verbose=False, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/resource_grid.html#RemoveNulledSubcarriers)\n\nRemoves nulled guard and/or DC subcarriers from a resource grid.\n\n**Parameters**\n\n- `resource_grid` (ResourceGrid): An instance of ResourceGrid.\n- `verbose` (bool): Defaults to False. If True, nulled subcarrier indices are printed.\n\n**Input**\n\n- `tensor` ([..., num_tx, num_streams, num_ofdm_symbols, fft_size], tf.complex): The original resource grid.\n\n**Output**\n\n- `tensor` ([..., num_tx, num_streams, num_ofdm_symbols, num_effective_subcarriers], tf.complex): The resource grid without nulled subcarriers.\n\n- `removed_indices` (tf.array): A tensor of shape [..., num_nulled_subcarriers], tf.int, listing the indices of the nulled subcarriers.\n\n**Note:** Nulled DC carriers are always removed.\n\n### Examples\n```python\nremove_nulled_subcarriers = RemoveNulledSubcarriers(resource_grid)\nrg = ResourceGrid(...)\ny = rg(ofdm_symbol_indices, pilot_pattern, pilot_ofdm_symbol_indices)\ny_eff = remove_nulled_subcarriers(y)\n```\n\n**Class API**\n\nThe API removes nulled subcarriers from a provided resource grid. This is useful for post-processing in a data link, when the resource grid is nulled according to a pilot pattern such as provided by `PilotPattern.get_pilot_pattern()`.\n\nThe class takes a `ResourceGrid` instance as input and returns a `tf.complex` tensor of the same shape, but with the nulled subcarriers removed. An additional output providing the indices of the removed nulled subcarriers is also provided. It can be used to inverse the operation on the receiver side, if needed.\n\n### Input\n\n- `tensor` ([batch_size, num_tx, num_streams, num_ofdm_symbols, fft_size]): The resource grid to process.\n\n### Output\n\n- `tensor` ([batch_size, num_tx, num_streams, num_ofdm_symbols, num_effective_subcarriers]): Resource grid with nulled subcarriers removed.\n- `removed_indices` ([batch_size, num_tx, num_streams, num_nulled_subcarriers]): Indices of the removed nulled subcarriers.\n\n### Parameters\n\n- `resource_grid`: An instance of `ResourceGrid`.\n- `verbose` (bool): Defaults to False. If True, nulled subcarrier indices are printed.\n\n### Property\n\n- `num_effective_subcarriers`: Number of effective subcarriers after the removal of nulled subcarriers."
"Here is the definition of LLRs2SymbolLogits: sionna.mapping.LLRs2SymbolLogits(constellation_type, num_bits_per_symbol, dtype=tf.float32, **kwargs)\n  \n[source code: https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#LLRs2SymbolLogits]\n  \nComputes logits (i.e., unnormalized log-probabilities) or log-likelihoods on constellation points from a tensor of log-likelihood ratios (LLRs) on bits.\n\n### Parameters\n\n- **constellation_type**: One of [\"qam\", \"pam\", \"custom\"], str.\n  - For \"custom\", an instance of Constellation must be provided.\n\n- **num_bits_per_symbol**: int\n  - Number of bits per constellation symbol, e.g., 4 for QAM16.\n\n- **dtype**: One of [tf.float32, tf.float64] tf.DType (dtype)\n  - The dtype for the input and output.\n  - Defaults to tf.float32.\n\n### Input\n\n- **llrs**: [..., n, num_bits_per_symbol], tf.float\n  - LLRs for every bit.\n\n### Output\n\n- **logits**: [..., n, num_points], tf.float\n  - Logits on constellation points.\n    - If the constellation is not \"custom\", the shape is [..., n, num_points].\n    - If the constellation is \"custom\", the shape is [..., n, num_points, num_symbols_per_constellation]."
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, follow these steps:\n\n1. Import the necessary libraries:\n```python\nimport os\nimport tensorflow asjson tf\n```\n\n2. Specify the GPU you want to use. If you want to use the CPU, set `gpu_num` to an empty string (\"\"). In this example, we're specifying GPU number 0:\n```python\ngpu_num = 0\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n```\n\n3. Set the TensorFlow log level to 3, which means only errors will be logged:\n```python\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n4. Get the list of all available GPUs:\n```python\ngpus = tf.config.list_physical_devices('GPU')\n```\n\n5. If GPUs are available, configure TensorFlow to use only the first GPU and allocate only as much memory as needed:\n```python\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\nIn the above code, `tf.config.experimental.set_memory_growth` is used to enable memory growth for the selected GPU. When memory growth is enabled, TensorFlow allocates only as much GPU memory as needed for the runtime components of the first GPU in the process. This can avoid memory fragmentation and ensure that the GPU memory is allocated in a unified manner."
"To compute codeword bits from information bits using the `LinearEncoder` class of the 'Sionna' package, you would first need to create an encoder with the appropriate generator matrix and then use the `encode` method of the encoder object. \n\nHere are the steps:\n\n1. Import the required classes from the Sionna package.\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n```\n\n2. Define the generator matrix (GM). The GM is a binary matrix of shape `[k, n]`, where `k` is the number of information bits and `n` is the codeword length (i.e, the number of codeword bits).\n\n3. Create an instance of the `LinearEncoder` class, passing the GM and the number of information bits as arguments.\n\n```python\n# Replace `gen_mat` with your actual generator matrix\n# It should be a binary numpy array or matrix\n# with shape `[k, n]` where `k` is the number of information bits\n# and `n` is the codeword length.\nencoder = LinearEncoder(gen_mat=gen_mat, k=k)\n```\n\nNow, you can use the `encode` method of the `encoder` object to encode the information bits and obtain the codeword bits.\n\nFor example:\n\n```python\n# Define `u` as a 2D tensor with shape `[batch_size, k]`, where `k` is the number of information bits\n# and `batch_size` is the number of examples you want to process.\n# The `tf.float32` dtype is used as an example; it should be adjusted\n# according to the specific requirements of the `encode` method.\nu = # Generate a 2D tensor with shape [`batch_size`, k] containing the information bits\n\n# Encode the information bits to obtain the codeword bits\nc = encoder(u)\n```\n\nThe output `c` is a tensor of shape `[batch_size, n]` containing the codeword bits.\n\nPlease ensure that you have the actual generator matrix `gen_mat` derived from the specific code or context in which you are working."
"Here is the detailed information of sionna.utils.flatten_last_dims:  \n\n[tf.keras.flatten_last_dim(tensor)](https://nvlabs.github.io/sionna/_modules/sionna/utils/tensors.html#flatten_last_dim)\n\nFlattens the last dimension of a tensor.\n\nThis function flattens the last dimension of a tensor by reshaping it to [-1, last_dim]. For example, if a tensor has shape [a, b, c, last_dim], the resulting tensor will have shape [a*b*c, last_dim].\n\n**Parameters**\n\n- `tensor` (tf.tensor): A tensor of any shape.\n\n**Returns**\n\n- `tf.tensor`: A tensor of shape [..., last_dim]."
"Here is the definition of Mapper: sionna.mapping.Mapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, normalize=False, center=False, dtype=tf.complex64, **kwargs)\n  \n  [Source code](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Mapper)  \n```python\nclass Mapper(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Mapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, normalize=False, center=False, dtype=tf.complex64, **kwargs)\n\n    Maps a tensor of binary values to a tensor of points from a constellation.\n\n    This class can be used to map real-valued \n    :math:`2^\\text{{num_bits_per_symbol}}` QAM constellation points to a complex\n    vector of a specified dtype. It can also directly map a tensor of\n    binary values to a constellation.\n\n    Parameters\n    ----------\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the mapper provides hard-decided symbols instead of soft-symbols.\n        Defaults to `False`.\n\n    normalize : bool\n        If `True`, the symbols are normalized to have unit power.\n        Defaults to `False`.\n\n    center : bool\n        If `True`, the constellation is centered on the origin.\n        Defaults to `False`.\n\n    dtype : [tf.complex64, tf.complex128], tf.DType\n        The output dtype. Defaults to `tf.complex64`.\n\n    Input\n    -----\n    (\u2026, n, num_bits_per_symbol), tf.float\n        A tensor of binary values.\n\n    Output\n    ------\n    (\u2026, n, 1), tf.complex\n        The mapped (or the hard-decided symbols) constellation points.\n        The output dtype is the one configured in the constructor.\n    \"\"\"\n\n    def __init__(self,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 normalize=False,\n                 center=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n\n        # Create constellation object\n        const_dtype = tf.complex64 if dtype is tf.complex64 else tf.complex128\n        self._constellation = Constellation.create_or_check_constellation(\n                                                        constellation_type,\n                                                        num_bits_per_symbol,\n                                                        constellation,\n                                                        dtype=const_dtype)\n        self.hard_out = hard_out\n        self.center = center\n        self.normalize = normalize\n\n    @property\n    def constellation(self):\n        \"\"\"The :class:`~sionna.mapping.Constellation` object.\"\"\"\n        return self._constellation\n\n    def call(self, inputs):\n        if self.hard_out:\n            return self._constellation.hard_decisions(inputs)\n        else:\n            x = self._constellation(inputs)\n            if self.normalize:\n                x = normalize(x, self._constellation.points_power)\n            if self.center:\n                x = center(x)\n            return x\n```  \n  "
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can use the TensorFlow library. Here are the steps:\n\n1. Import the necessary libraries:\n```python\nimport os\nimport tensorflow asjson tf\n```\n\n2. Specify the GPU you want to use. If you want to use the CPU, set `gpu_num` to an empty string (\"\"). In this example, we're using the first GPU, so we set `gpu_num` to 0:\n```python\ngpu_num = 0\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n```\n\n3. List the physical devices available for TensorFlow and set the memory growth of the selected GPU. Memory growth needs to be enabled to allocate only as much GPU memory as needed for the runtime allocations.\n```python\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\nIn this code, `tf.config.experimental.list_physical_devices('GPU')` returns a list of PhysicalDevice objects representing the GPU devices. `tf.config.experimental.set_memory_growth(gpus[0], True)` sets the memory growth for the first GPU."
"Here is the definition of BinaryErasureChannel: sionna.channel.BinaryErasureChannel(return_erased_bits=False, bipolar_input=False, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/discrete_channel.html#BinaryErasureChannel)\n\nsource code:\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"Layer for discrete binary erasure channel\"\"\"\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Layer\nfrom sionna.utils import expand_to_rank\n\nclass BinaryErasureChannel(Layer):\n    \"\"\"BinaryErasureChannel(return_erased_bits=False, bipolar_input=False, **kwargs)\n\n    Discrete Binary Erasure Channel which can optionally return the\n    positions of the erased bits.\n\n    :param return_erased_bits: Indicates if the positions of the erased bits\n        should be returned.\n    :type return_erased_bits: bool\n\n    :param bipolar_input: If `True`, the expected input is given as\n        `(+1,0)` instead of `(0,1)`.\n    :type bipolar_input: bool\n\n    Input\n    -----\n    : (x, pb) or x :\n        Tuple(or  Tensor) \u2013\n        : x :  tf.float32\n            Tensor of arbitrary shape.\n        : pb :  tf.float32\n            Tensor whose shape is equal to the shape of ``x``[:-1] and an\n            dtype of rank  lesser than that of ``x``.\n            Only values of ``0`` or ``1`` are allowed.\n\n    Output\n    ------\n    : Tuple :\n        : y :   tf.float32\n              Tensor of the same shape as ``x``.\n        : e :  tf.float32\n            Tensor of the same shape as ``x`` except for the last\n            dimension where it equals to ``k``.\n            It  contains the indicies of the erased bits.\n    \"\"\"\n    def __init__(self, return_erased_bits=False, bipolar_input=False, **kwargs):\n        super().__init__(**kwargs)\n        self._return_erased_bits = return_erased_bits\n        self._bipolar_input = bipolar_input\n\n    @property\n    def return_erased_bits(self):\n        \"\"\"Indicates if the positions of the erased bits should be returned.\"\"\"\n        return self._return_erased_bits\n\n    @property\n    def bipolar_input(self):\n        \"\"\"Indicates if the expected input is given as `(+1,0)` instead of `(0,1)`.\"\"\"\n        return self._bipolar_input\n\n    def call(self, inputs):\n        \"\"\"call(inputs) generates for every channel input a binary output and\n        optionally the positions of the erased bits.\n\n        Input\n        -----\n        inputs : Tuple(x, pb)\n            x : tf.float32\n                Tensor of arbitrary shape.\n            pb : tf.float32\n                Tensor whose shape is equal to the shape of ``x``[:-1] and an\n                dtype of rank  lesser than that of ``x``.\n                Only values of ``0`` or ``1`` are allowed.\n\n        Output\n        ------\n        : Tuple(y, e)\n            y :  tf.float32\n                Tensor of the same shape as ``x``.\n            e :  tf.float32\n                Tensor of the same shape as ``x`` except for the last\n                dimension where it equals to ``k``.\n                It contains the indicies of the erased bits.\n        \"\"\"\n        if self._bipolar_input:\n            x, pb = inputs\n            x = 2*x - 1\n        else:\n            x = inputs\n\n        pb = tf.cast(pb, x.dtype)  # match dtypes\n        e = tf.cast(tf.math.less(pb, 0.5), x.dtype)  # bp wherever pb<0.5\n        x_e = tf.cast(tf.where(e, -1, x), x.dtype)  # mask x with e\n\n        # mask output such that only x_e is taken where e==0\n        if self._return_erased_bits:\n            y = x_e\n        else:\n            y = x_e\n        e = expand_to_rank(e, tf.rank(x), axis=-1)\n\n        return (y, e)\n```"
"To set up a system simulation using the Sionna package, several components are required. These components are used to simulate an 5G NR compliant LDPC encoded system and include the following:\n\n1. **LDPC BP Decoder**: This is an LDPC (Low-Density Parity-Check) belief propagation decoder. It is specifically designed for iterative message passing decoding of a binary linear block code represented by a parity-check matrix. The LDPC BP Decoder is a key component in the system simulation as it performs the decoding of the transmitted data.\n\n2. **Gaussian LLR Source**: This component is used to generate Gaussian-distributed log-likelihood ratios (LLRs) with a specified variance. The LLRs are the unknown information bits of a code transferred into the parity-check domain, which is a widely used method in iterative decoding.\n\nThe provided context does not contain detailed information about the specific LDPC BP Decoder and Gaussian LLR Source components in the Sionna package. However, these components can be typically used as shown in the context, where the `LDPCBPDecoder` is instantiated with a specific parity-check matrix and the Gaussian LLR Source is called with the number of bits per symbol (NB), the symbol energy (Es), and the noise spectral density (No) to generate the LLRs.\n\nRemember to always refer to the official documentation or source code for detailed and component-specific usage information."
"PUSCHDMRSConfig is a class in Sionna\u2019s API that is used to define and configure the Dedicated Multicast Resource (DMRS) for User Equipment (UE) for 5G New Radio (NR) PUSCH. It includes various parameters that can be configured to define the DMRS transmission scheme. \n\nTo use the PUSCHDMRSConfig class, you need to create an instance of it and then set its properties either by directly assigning a value or by passing the desired values as keyword arguments during the instantiation. Note that PUSCHDMRSConfig is configured with certain default settings which can be modified based on your requirements.\n\nHere\u2019s a general process on how to use the PUSCHDMRSConfig class:\n\n1. Create an instance of PUSCHDMRSConfig class:\n\n```python\nfrom sionna.nr import PUSCHDMRSConfig\ndmrs_config = PUSCHDMRSConfig()\n```\n\n2. Set the configuration parameters either during the instantiation or by directly assigning a value to the property:\n\n```python\ndmrs_config.mapping_type = 2\ndmrs_config.different_port_ind = True\n```\n\nIn the above example, `mapping_type` is set to 2 which indicates Type 2 DMRS mapping. The `different_port_ind` parameter is set to True, which means that different DMRS antenna ports are used for different UEs.\n\nThe PUSCHDMRSConfig class includes various properties such as:\n\n- `config_type`: This indicates the DMRS configuration type, which can be either 1 or 2.\n- `dmrs_port_set`: This indicates the DMRS antenna port set.\n- `additional_position`: This indicates the DMRS additional position.\n- `dmrs_type`: This indicates the length of DMRS symbols. It can be either 'a' or 'b'.\n- `duration`: This indicates the number of DMRS symbols in a slot.\n- `frequency_hopping`: Indicates the DMRS frequency hopping configuration.\n- `frequency_hopping_disable`: Disables the DMRS frequency hopping when set to True.\n- `n_rnti`: This indicates the Radio Network Temporary Identifier (RNTI) DMRS set.\n- `n_id`: This indicates the DMRS scrambling ID.\n- `n_scid`: This indicates the DMRS scrambling ID for a specified carrier.\n- `n_cdm_groups_without_data`: Indicates the number of CDM groups without data transmission.\n- `cdm_group_without_data`: Defines the CDM group without data transmission.\n- `num_cdm_groups`: Indicates the number of CDM groups used in the DMRS transmission.\n- `cdm_groups`: Maps the DMRS symbols to CDM groups.\n- `w_f`: Represents the first frequency-cyclc shift applied to DMRS.\n- `w_t`: Indicates the time-cyclic shift applied to DMRS.\n- `l`: Represents the DMRS lattice internal cell index.\n\nRemember that the configuration parameters should be set as per the specifications of your 5G NR network and the requirements of your simulation or real-world application."
"To demonstrate encoding information bits using an instance of `ConvEncoder`, we first need to create an instance of the encoder. We will then use this instance to encode the information bits. \n\nLet's assume we have an information bit tensor `u` that we want to encode. `u` is a 2D tensor of type float32, with the last dimension being the number of information bits per codeword k. \n\nWe will create an instance of the encoder using the Sionna package, which can be installed using pip: `pip install sionna`. The encoder can encode `n`-state convolutional codes, and the codes are systematic and, if desired, can be rate-1/n. The generator polynomial is required to create the encoder. We will use a predefined polynomial for a (7, 4) code obtained by polynom2int([1,1,1,0,1,1,1], True) where the True indicates that the polynomial is primitive.\n\nHere is the Python code to demonstrate the encoding process: \n\n```python\n# Create the encoder instance\nencoder = ConvEncoder(r=1, n=7, k=4, polynomials='prim', t=1)\n\n# u is the information bits to be encoded with the shape [..., k]\n# The shape of u will depend on the specific application and the number of information bits k\n\n# Encode the information bits\nc = encoder(u)\n\n# c is the encoded codeword with the shape [..., n]\n# The shape of c will depend on the shape of u and the rate of the code. \n# In this case, since r=1 and k=4, the shape of c will be [..., 7]\n```\n\nHere is the depiction of the shapes and types of the input and output tensors:\n\n- `u`: A tensor of type float32 with a shape depending on the specific application and the number of information bits. The shape is `[..., k]` where `k` is the number of information bits per codeword.\n\n- `c`: A tensor of type float32 with a shape `[..., n]`. The shape depends on the shape of `u` and the rate of the code. The shape is `[..., 7]` if the (7, 4) code is used.\n\n*Note: The placeholders for `...` and the actual shape of `u` are just for the sake of illustration. The actual shape of `u` would depend on the specific application and the number of information bits.* \n\nThe Sionna package also provides a helpful method for plotting the impulse response of the channel, you can use it to verify that your setup is correct:\n\n```python\nchannel = Channel(L_band, return_llrs=False)\nchannel.plot_ir_h(f_s)\n```"
"The Demodulation Reference Signal (DMRS) Configuration in the Sionna API is used to define the properties of the DMRS pilot patterns in a 5G New Radio (NR) context. The DMRS Configuration includes parameters such as the duration, number of antenna ports, and DMRS ports set ID, among others.\n\nTo create a DMRS Configuration with the Sionna API, you would use a function like this, filling in the appropriate values for each parameter:\n\n```python\ndmrs_config = DMRSConfig(\n    duration=1, \n    dmrs_type=\"a\", \n    additional_position=2, \n    num_front_freq_ots=0, \n    num_layers=1, \n    l0=10, \n    l_prime=0, \n    mcs_index=0, \n    dmrs_port_set_id=0, \n    cdm_type=\"fd\", \n    cdm_transform_precoding=\"4i4d\", \n    num_cdm_groups_without_data=2, \n    cdm_length_l=2, \n    num_tx=1, \n    num_dmrs_ports=1, \n    num_resource_blocks=1, \n    num_cdm_groups_with_data=1\n)\n```\n\nTo visualize the pilot pattern, you would use the `show` method of the DMRS Configuration object. This method opens a dialog showing the DMRS pilot pattern. \n\n```python\ndmrs_config.show()\n```\nThis will open a visualization of the DMRS pilot pattern. The number of 'PilotDMRS' indicates the DMRS ports. The parameter 'PilotPatternMasked' shows which resource elements are nulled.\n\nPlease note that the exact code may vary depending on the specific requirements of your simulation. The code provided here is a general template and may need to be adjusted to fit your specific use case."
"To visualize common scattering patterns using the Sionna package, you can follow these steps:\n\n1. Import the necessary packages and modules. This includes Sionna, matplotlib, numpy, and tensorflow.\n\n```python\nimport sionna\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n```\n\n2. Set up the scene and load a specific geometry. You can use the `load_scene` function from the Sionna package to load a suitable scene.\n\n```python\nscene = sionna.rt.Scene(load=sionna.rt.scene.munich)\n```\n\n3. Configure the transmitter and array. You can use the `Transmitter` and `ReceiverArray` classes from the Sionna package for this.\n\n```python\nscene.tx_array = sionna.rt.PanelArray(num_rows=1,\n                                       num_cols=1,\n                                       polarization=\"V\", # Polarization can be \"V\" or \"H\"\n                                       pattern=\"iso\", # Pattern can be \"iso\", \"dipole\", or can be specified through a callable\n                                       carrier_frequency=scene.frequency)\nscene.rx_array = sionna.rt.PanelArray(num_rows=8,\n                                       num_cols=1,\n                                       polarization=\"V\",\n                                       pattern=\"iso\",\n                                       carrier_frequency=scene.frequency)\n```\n\n4. Add a transmitter and receiver to the scene. You can use the `Transmitter` and `Receiver` classes from the Sionna package for this.\n\n```python\nscene.add(Transmitter(name=\"tx\",\n                      position=[8.5,21,27],\n                      orientation=[0,0,0]))\nscene.add(Receiver(name=\"rx\",\n                   position=[40,80,1.5],\n                   orientation=[0,0,0]))\n```\n\n5. Compute the channel impulse response between the transmitter and receiver. You can use the `compute_paths` function from the scene, and then use the `cir` method to get the channel impulse response.\n\n```python\npaths = scene.compute_paths()\na, tau = [paths[key] for key in paths.keys()]\na = tf.squeeze(a, axis=-1)\ntau = sionna.channel.tau_scaling(tau, scene.frequency)\n```\n\n6. Visualize the common scattering patterns. You can use the `show` method of the `PanelArray` class for this.\n\n```python\nscene.rx_array.show(pattern=\"iso\", orientation=[0,90,0])\nplt.show()\n```\n\n7. (Optional) You can repeat the above steps for different carriers or frequencies to compare the scattering patterns at different frequencies.\n\nRemember that the visualization of the scattering pattern is frequency-dependent. Therefore, it can help you understand how the environment scatters the signal at different frequencies."
"To handle import errors for the Sionna package in Python, you need to use a try-except block to catch the ImportError raised when attempting to import the package. Here's how you can do it:\n\n1. First, attempt to import the Sionna package using the `import` statement inside a `try` block.\n\n```python\ntry:\n    import sionna\n```\n\n2. If the import is successful, the code execution will continue. However, if the import fails, an `ImportError` will be raised.\n\n3. You can catch this `ImportError` using an `except` block. Inside this block, you can handle the error. In this case, the error is handled by installing the Sionna package using `pip` and then attempting to import it again.\n\n```python\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n4. After the package is installed, you can attempt to import it again.\n\nThis method ensures that if the Sionna package is not already installed in the current Python environment, it will be installed automatically. This can be particularly useful in a Jupyter notebook or other interactive Python environments."
"To import the necessary Sionna APIs, you can follow the steps below:\n\n1. Import the `os` module. This module provides a way of using operating system dependent functionality like reading or writing to the environment.\n\n```python\nimport os\n```\n\n2. Set the environment variables for CUDA and TensorFlow. This is done to specify the GPU to be used and to control the log level of TensorFlow.\n\n```python\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n3. Import the Sionna package. If it's not already installed, the code will install it using pip.\n\n```python\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    os.system(\"pip install sionna\")\n    import sionna as sn\n```\n\n4. Import the necessary Sionna APIs. This includes the `AWGN` channel, the binary source, the encoder and decoder for the binary source, the mapper and demapper for the constellation, the QAM source, the LSTF pilot pattern, the OFDM resource grid, the frequency domain channel, and the function for estimating the channel.\n\n```python\nfrom sionna.channel import AWGN\nfrom sionna.utils import binary_source, encoder,  map_bits_to_constellations, qam_source, lstf, ofdm_resource_grid, time_to_ofdm_channel, estimate_lsf_ofdm, lmmse_ofdm_detector\n```\n\nPlease note that the code provided is directly taken from the context and should be used as is. If your specific use case requires a different set of APIs, you may need to adjust the imports accordingly."
"The `Descrambler` class from the `sionna.fec.scrambling` module is a layer for descrambling a given sequence of binary strings. The descrambler is a matched filter to the scrambler. The description assumes a similar description for the Scrambler. Please note that the binary format is referred to in a specific context, which could potentially change if the input sequence is of a different type.\n\nThe `Descrambler` takes a `Scrambler` instance as input, and reverses its process. It also takes an explicit seed to scramble, if the input sequence is not of random nature. The scrambling can be for either a random uniform set or a specific set defined by the user.\n\nHere is a sample of how to use `Descrambler`:\n```python\ndescrambler = Descrambler(scrambler)\nc = descrambler(c_scr) # Descrambling\n```\n\nHere, an instance of `Descrambler` is created with a previous instance of `Scrambler`. The input `c_scr` is in the binary format and is descrambled to `c` using the created descrambler.\n\nIn terms of parameters, the `Descrambler` class takes a `Scrambler` instance and an explicit seed of an integer type to scramble. The input type is an explicit sequence of 2D tensors of arbitrary shape and `dtype`, and the output is also of the same shape and `dtype`.\n\nThe `Descrambler` could raise an `AssertionError` if the input `seed` or `c` is not of the right type or shape. `TypeError` could be raised if the `scrambler` is not an instance of `Scrambler`.\n\nProperties of descrambler include the `scrambler` which is an instance of `Scrambler` used by the `Descrambler`. This property could be essential in certain descrambling processes where access to the original scrambling conditions is necessary.\n\nKeep in mind that the `Descrambler` is usually used in a pair with the `Scrambler` in what is referred to as a \"matched filter\" - they are equally essential in ensuring the sequence's randomness and consistency."
"To perform Polar decoding using an instance of `Polar5GDecoder` with log-likelihood ratios (LLRs) as inputs, keeping the array initialization within the context of the `Polar5GDecoder` class in mind, it's necessary to determine the input parameters based on the specifics of the 5G Polar code configuration.\n\nSince the code snippet from the context doesn't provide the specific `Polar5GDecoder` instance and the mode of initialization (`enc_polar` or `dec_polar`), I will demonstrate the decoding process with a general `Polar5GDecoder` assuming the following parameters based on the context:\n\n```python\nfrom sionna.fec.polar.decoding import Polar5GDecoder\nimport tensorflow as tf\n# Assume for example purposed enc_polar is an instance of Polar5GEncoder\n# and also dec_polar is an instance of Polar5GDecoder\nenc_polar = Polar5GEncoder(k=100, n=200)\ndec_polar = Polar5GDecoder(enc_polar, k=100, n=200)\n```\n\nHaving established the potential parameters for the 5G Polar code decoder, the decoding process can be initiated. It's important to note that the following code snippet assumes that `dec_input` is a tensor of LLRs with the shape `(..., n)`, representing the channel output symbols' likelihood ratios.\n\nThe context provides information about two modes of initializing the `Polar5GDecoder`:\n\n1. **Position-based initialization**: In this case, the decoder is initialized with the positions of the frozen bits within the Polar code of a specific length. This method is commonly utilized for successive cancellation (SC) decoding algorithms.\n2. **SC-frozen-set-size-based initialization**: This method is similar to position-based initialization but specifies the size of the frozen set, which is applicable in conjunction with list decoding approaches.\n\nNext, I will demonstrate the decoding process in Python using positions-based initialization. Please be aware that the actual implementation might vary depending on the `Polar5GDecoder` instance creation.\n\n```python\n# given dec_input as tensor of LLRs with the shape (..., n)\ndec_output = dec_polar(dec_input)  # Polar decoder output\n```\n\nThe code snippet shows the typical process for performing Polar decoding with positions-based initialization. However, the accuracy and performance of the decoding process can be affected by various constraints applied during the `Polar5GDecoder` instantiation, such as the decoder type (list or SC), the list size, and the specific list-based options, if applicable.\n\nTo accurately represent the Polar decoding process for 5G codes with positions-based initialization using Sionna APIs, further analysis would be needed, taking into consideration the specific context's complete code and the decoders' exact implementations."
"To load a scene from a file using the `load_scene()` function in the `rt` module of the Sionna package, you need to pass the filename of the scene to this function. The scene should be in a supported file format, such as Binary Scene Description (BSD) or Radiance (R48). \n\nHere's a Python code snippet on how to do this:\n\n```python\nfrom sionna.rt import load_scene\n\n# Assume `filename` is the path to your scene file\nfilename = \"path_to_your_scene_file_here\"\n\n# Load the scene\nscene = load_scene(filename)\n```\n\nIn this code, `load_scene()` is a function that reads the scene from the specified file and returns a `Scene` object. You can then use this object to perform various tasks in the ray-tracing simulation, such as computing propagation paths, tracing rays, and generating propagation maps."
