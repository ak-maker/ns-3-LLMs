"When creating a `Polar5GEncoder` instance in Sionna, you need to define the `k` and `n` parameters. \n\n- `k` is an integer parameter that defines the number of information bits per codeword, including rate-matching.\n- `n` is an integer parameter that defines the codeword length, including rate-matching.\n\nHere is an example of how you would instantiate a `Polar5GEncoder` in Python using Sionna:\n\n```python\nfrom sionna.fec.polar.encoding import Polar5GEncoder\nimport tensorflow as tf\n\n# Defining the k and n parameters\nk = 100  # Example value for the number of information bits\nn = 200  # Example value for the codeword length\n\n# Creating the Polar5GEncoder instance\nencoder = Polar5GEncoder(k=k, n=n, verbose=True, channel_type='uplink', dtype=tf.float32)\n```\n\nIn this example:\n- The `k` parameter is set to 100, which means there are 100 information bits per codeword, including rate-matching.\n- The `n` parameter is set to 200, which means the codeword length is 200, including rate-matching.\n- The `verbose` parameter is set to `True`, which means additional information about the encoding process will be printed.\n- The `channel_type` parameter is set to `'uplink'`, which specifies the scenario for which the encoder is optimized.\n- The `dtype` parameter is set when creating the encoder and defines the type of the output sequence. In this case, it is set to `tf.float32`."
"To import DeepMIMO and generate a dataset, you will need to follow a set of steps as outlined in the provided context:\n\n1. **Import the necessary libraries**: This includes the standard Python libraries such as os, tensorflow, numpy, matplotlib, and more. The specific libraries needed for DeepMIMO are also imported. They include Sionna, h5py, and tqdm.\n\n2. **Set up the environment**: This includes setting the GPU number and avoiding TensorFlow warnings.\n\n3. **Import Sionna and DeepMIMO**: First, you need to set the path for the Sionna package. Then, import Sionna. Afterward, import DeepMIMO by connecting to the DeepMIMO website and downloading the required files.\n\n4. **Generate a DeepMIMO configuration**: Use the Sionna library to generate a DeepMIMO configuration. This includes specifying the scenario, the carrier frequency, the antenna array configurations, the active user terminals, and more.\n\n5. **Set up the DeepMIMO dataset**: The DeepMIMO class is used to set up the DeepMIMO dataset. This includes defining the dataset size, the path to the DeepMIMO files, the file loading process, and more.\n\n6. **Generate data**: Use the DeepMIMO class to generate data. The data includes the channel frequency responses, the locations of the users, the locations of the base stations, and more.\n\n7. **Use the DeepMIMO dataset**: The generated DeepMIMO dataset can now be used. You can either use it to simulate PHY-layer link-level performance or use it to obtain channel impulse responses for use in other link-level simulations.\n\nEach of these steps is accompanied by the necessary Python code to perform the operation. Make sure to read the details and understand the code before using it in your project."
"To plot the weights after training and compare the new BER performance, you can follow these steps:\n\n1. Train the model: Before plotting the weights, you need to train the model. This is done using the `sim_train()` function. The training parameters are set using an instance of the `TrainingParameters` class.\n\n2. After the model is trained, you can access the trained weights. This is done using the `get_weights()` function of the layers of the model. The weights are returned as a list of numpy arrays.\n\n3. Plot the weights: The weights are plotted using the `show_weights()` function of the layers of the model. The weights are passed as an argument to the `show_weights()` function.\n\n4. Compare the new BER performance: The new BER performance is obtained by simulating the model using the `PlotBER` class. The simulation parameters are set using an instance of the `SimulationParameters` class. The simulation is performed on a range of SNR values using the `simulate()` function of the `PlotBER` class. The results are stored in a dictionary.\n\n5. Plot the BER performance: The BER performance is plotted using the `plot_ber()` function of the `PlotBER` class. The results and the legend are passed as arguments to the `plot_ber()` function.\n\nHere is the relevant code:\n\n```python\n# Train the model\ntrained_model = sim_train(model,\n                        training_parameters=TrainingParameters(),\n                        verbose=False)\n\n# Get the weights\nweights = model.decoder.get_weights()\n\n# Plot the weights\nmodel.decoder.show_weights(weights)\n\n# Compare the new BER performance\nber_plot.simulate(trained_model,\n                ebno_db=ebno_dbs,\n                batch_size=sim_params.batch_size,\n                num_target_bit_errors=1000,\n                legend=\"Trained model\")\n\n# Plot the BER performance\nber_plot.plot_ber(\"ber.png\",\n                ylim=(1e-3, 0.25),\n                xlim=(3, 7.5),\n                fontsize=20)\n```\n\nThis will give you a plot of the weights after training and a plot of the BER performance. The weights will give you an idea of how the model has learned to decode, and the BER performance will give you the overall performance of the model."
"To use the `generate_polar_transform_mat` function to create a Polar transformation matrix for a given Kronecker power, you need to follow these steps:\n\n1. Import the required functions from the sionna package.\n```python\nfrom sionna.fec.polar.utils import generate_polar_transform_mat\n```\n\n2. Call the `generate_polar_transform_mat` function with the desired Kronecker power as the input. The Kronecker power (`n_lift`) specifies how often the kernel is lifted.\n```python\ntransf_mat = generate_polar_transform_mat(n_lift)\n```\nIn the `generate_polar_transform_mat` function, the Polar transformation matrix is constructed using the Kronecker product of matrices, so the resulting matrix is of dimension ` [2^n_lift , 2^n_lift] `.\n\nThe function does not return specific parameters, but the resulting `transf_mat` can be used in the encoding and decoding processes of a Polar code when using the `LinearPolarEncoder` or `SCLPolarDecoder` classes."
"Definition of LayerDemapper: sionna.nr.LayerDemapper(layer_mapper, num_bits_per_symbol=1, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/nr/layer_mapping.html#LayerDemapper)  \n```python\nclass LayerDemapper(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"LayerDemapper(layer_mapper, num_bits_per_symbol=1, **kwargs)\n\n    Demaps MIMO layers to coded transport block(s) by following Sec. 6.3.1.3\n    and Sec. 7.3.1.3 in [3GPP38211]_.\n\n    This layer must be associated to a :class:`~sionna.nr.LayerMapping`\n    and performs the inverse operation.\n\n    It is assumed that ``num_bits_per_symbol`` consecutive LLRs belong to\n    a single symbol position. This allows to apply the LayerDemapper after\n    demapping symbols to LLR values.\n\n    If the layer mapper is configured for dual codeword transmission, a list of\n    both transport block streams is returned.\n\n    The class inherits from the Keras layer class and can be used as layer in a\n    Keras model.\n\n    Parameters\n    ----------\n    layer_mapper : LayerMapping\n        Associated LayerMapper.\n\n    num_bits_per_symbol : int, 1 (default)\n        Modulation order. Defines how many consecutive LLRs are associated\n        to the same symbol position.\n\n    Input\n    -----\n    inputs : [,num_layers, n/num_layers], tf.float\n        2+D tensor containing MIMO layer data sequences.\n\n    Output\n    ------\n    : [,n], or [[,n1], [,n2]], tf.float\n        2+D tensor containing the sequence of bits after layer demapping. If\n        ``num_codewords`` =2, a list of two transport blocks is returned.\n\n    Note\n    ----\n    As it is more convenient to apply the layer demapper after demapping\n    symbols to LLRs, this layer groups the input sequence into groups of\n    ``num_bits_per_symbol`` LLRs before restoring the original symbol sequence.\n    This behavior can be deactivated by setting ``num_bits_per_symbol`` =1.\n    \"\"\"\n    def __init__(self,\n                 layer_mapper,\n                 num_bits_per_symbol=1,\n                 **kwargs):\n        super().__init__(**kwargs)\n        self._num_bits_per_symbol = num_bits_per_symbol\n        self._check_config_consistency(layer_mapper)\n\n        # Configurable variables\n        self._num_streams = None\n        self._num_codewords = None\n        self._num_layers = None\n        self._num_boosting_bits = None\n        self._symbol_indices = None\n        self._l1_l2_ind = None\n        self._l12_ind = None\n        self._l_min = None\n        self._l_max = None\n        self._check_config()\n\n    #########################################\n    # Public methods and properties\n    #########################################\n\n    @property\n    def num_streams(self):\n        \"\"\"Number of transmitted streams.\"\"\"\n        return self._num_streams\n\n    @property\n    def num_codewords(self):\n        \"\"\"Number of codewords\"\"\"\n        return self._num_codewords\n\n    @property\n    def num_layers(self):\n        \"\"\"Number of MIMO layers (after demapping)\"\"\"\n        return self._num_layers\n\n    @property\n    def num_bits_per_symbol(self):\n        \"\"\"Modulation order. Defines how many consecutive LLRs are associated\n        to the same symbol position.\"\"\"\n        return self._num_bits_per_symbol\n\n    @property\n    def num_symbols(self):\n        \"Number of symbols per codeword\"\n        return self._layer_mapper.num_symbols\n\n    @property\n    def symbol_indices(self):\n        \"Demapped symbol indices\"\n        return self._symbol_indices\n\n    @property\n    def l1_l2_ind(self):\n        \"l1 and l2 indices for each codeword\"\n        return self._l1_l2_ind\n\n    @property\n    def l12_ind(self):\n        \"l1 and l2 indices combined to one index for each codeword\"\n        return self._l12_ind\n\n    @property\n    def l_min(self):\n        \"Smallest layer-indice (= number of boosters)\"\n        return self._l_min\n\n    @property\n    def l_max(self):\n        \"Largest layer-indice\"\n        return self._l_max\n\n    def call(self, inputs):\n        \"\"\"Applies layer demapping\n\n        This function extracts for each codeword and each stream the\n        corresponding l1 and l2 positions from the input tensor of LLRs.\n        Then, the LLRs are re-ordered according to the\n        ``symbol_indices`` such that ``num_bits_per_symbol`` LLRs\n        belong to a symbol position. Eventually, the LLRs are\n        assigned to the corresponding position according to\n        the index information ``l1_l2_ind`` and ``l12_ind``.\n\n        Input\n        -----\n        inputs : Tensor with shape [,n], where\n            LLRs are asssumed to be located. ``n`` is the total\n            number of bits and ``num_codewords`` the number of codewords\n\n        Output\n        ------\n        y : Tensor with shape [,n], where\n            LLRs are located\n        \"\"\"\n        if self._num_codewords==1:\n            y = self._demapping(inputs,\n                               self.symbol_indices[0],\n                               self.l1_l2_ind[0],\n                               self.l12_ind[0])\n\n            # Restore ordering of channels for the dual codeword case\n            if self._layer_mapper._dual_cw:\n                # we need to de-interleave the channels for the first codeword\n                y_cw0 = tf.gather(y, self.l12_ind[0], axis=-1)\n                # and interleave the channels of the second codeword\n                y_cw1 = tf.gather(y, self.l12_ind[1], axis=-1)\n                # concatenate the results\n                y = tf.concat([y_cw0, y_cw1], -1)\n        else:\n            y0 = self._demapping(inputs,\n                                self.symbol_indices[0],\n                                self.l1_l2_ind[0],\n                                self.l12_ind[0])\n            y1 = self._demapping(inputs,\n                                self.symbol_indices[1],\n                                self.l1_l2_ind[1],\n                                self.l12_ind[1)\n\n            # concatenate the results\n            y = tf.concat([y0, y1], -1)\n\n        return y\n\n    #########################################\n    # Internal utility functions\n    #########################################\n\n    def _check_config_consistency(self, layer_mapper):\n        \"\"\"Check if the layer mapper is configured for demapping\n        and if the  configuation is consistent to the\n        LayerDemapper.\"\"\"\n        # layer_demapper is only valid for zcm or wcm\n        if not layer_mapper.demapped_mod:\n            raise ValueError(\"The LayeredDemapper is only valid for the \\\n                              demodulation of the 3GPP modulation schemes.\")\n\n        if layer_mapper._stream_manager is None:\n            raise ValueError(\"The relation between the LayerMapper and \\\n                               LayerDemapper is unclear as the LayerManager \\\n                               is not initialized. Please use the \\\n                               DemodedStreamManagement class.\")\n\n        if self._num_bits_per_symbol != 1:\n            if layer_mapper.modulation == \"16QAM\":\n                if self._num_bits_per_symbol!=4:\n                    raise ValueError(\"For 16QAM, 4 bits per symbol are \\\n                                      expected.\")\n            elif layer_mapper.modulation == \"64QAM\":\n                if self._num_bits_per_symbol!= 6:\n                    raise ValueError(\"For 64QAM, 6 bits per symbol are \\\n                                      expected.\")\n            elif layer_mapper.modulation == \"256QAM\":\n                if self._num_bits_per_symbol!= 8:\n                    raise ValueError(\"For 256QAM, 8 bits per symbol are \\\n                                    expected.\")\n            elif layer_mapper.modulation in [\"pi_2BPSK\", \"pi_2DPSK\"]:\n                if self._num_bits_per_symbol!=2:\n                    raise ValueError(\"For higher modulations, 2 bits per \\\n                                    symbol are expected.\")\n        self._layer_mapper = layer_mapper\n        # The following parameters are extracted from the layer_mapper\n        self._num_streams = layer_mapper.num_streams\n        self._num_codewords = layer_mapper.num_codewords\n        self._num_bits_per_symbol = self._num_bits_per_symbol\n\n        # First get illegal symbol indices (=0)\n        c = layer_mapper.constellation.c\n        symb_ind = tf.where(c, tf.range(0, c.shape[-1]), c)\n        mask = tf.equal(symb_ind, 0)\n        n_il = tf.where(mask, symb_ind, tf.zeros_like(symb_ind))\n        # Then determine which symbols are mapped to the codewords\n        # for non-scrambled bit labeling\n        l1_l2_ind = layer_mapper.l1_l2_ind_non_scrambled\n        # Set the corresponding l1 and l2 indices to 0\n        # as these positions a not used.\n        # and combine the indices to one tensor\n        l1 = tf.where(l1_l2_ind, n_il, tf.zeros_like(n_il))\n        l2 = tf.where(l1_l2_ind, n_il, tf.zeros_like(n_il))\n        self._l1_l2_ind = [l1, l2]\n        self._l12_ind = tf.stack([l1, l2], -1)\n\n        # Compute first and last layer index for each codeword\n        # The l_min and l_max for each stream\n        l_min = layer_mapper.l_min\n        l_max = layer_mapper.l_max\n        self._l_min = l_min\n        self._l_max = l_max\n\n    def _check_config(self):\n        \"\"\"This function is used to set all derived\n        parameters which are not explicitly given.\"\"\"\n        if self._num_codewords==1:\n            l1 = self._l_min\n            l2 = self._l_max\n            self._symbol_indices = [tf.tile([symbol_indices], [l1-l2+1])\n                                     for symbol_indices in range(l1, l2+1)]\n        else:\n            # For the dual codeword case, each codeword has different\n            # l_min and l_max\n            l1_0 = self._l_min[0]\n            l2_0 = self._l_max[0]\n            l1_1 = self._l_min[1]\n            l2_1 = self._l_max[1]\n            self._symbol_indices = [tf.tile([symbol_indices], [l1_0-l2_0+1])\n                                     for symbol_indices in range(l1_0, l2_0+1)]\n            symbol_indices = [tf.tile([symbol_indices], [l1_1-l2_1+1])\n                               for symbol_indices in range(l1_1, l2_1+1)]\n            self._symbol_indices = self._symbol_indices + symbol_indices\n\n        self._num_bits_per_symbol = self._num_bits_per_symbol\n```"
"To create a PUSCHReceiver using the PUSCHTransmitter and simulate transmissions over the AWGN channel, you can follow these steps:\n\n1. Import the necessary modules and set up the environment. This includes importing the PUSCH configuration and creating a PUSCH transmitter and receiver. The PUSCH configuration can be set to default settings with the `PUSCHConfig()` function. The PUSCH transmitter can be created using the `PUSCHTransmitter(pusch_config)` function, and the PUSCHReceiver can be created using the `PUSCHReceiver(pusch_transmitter)` function.\n\n2. Set up the AWGN channel. This can be done using the `AWGN()` function.\n\n3. Simulate transmissions over the AWGN channel. This involves generating a transmit signal and info bits using the PUSCH transmitter, and then simulating the channel output using the AWGN channel. The transmit signal and info bits can be generated with the following code:\n\n```python\nbatch_size = 16\nno = 0.1 # Noise variance\nx, b = pusch_transmitter(batch_size) # Generate transmit signal and info bits\n```\n\n4. Compute the Bit Error Rate (BER). This can be done by recovering the info bits using the PUSCHReceiver and then computing the BER using the `compute_ber()` function. The BER can be printed to the screen for evaluation.\n\n5. If you want to visualize the simulation, you can plot the OFDM resource grid that is generated by the transmitter. This can be done using the `show()` function.\n\nRemember that the code snippets provided in the context are based on a specific Python package (Sionna in this case). You may need to adjust the code if you are using a different package."
"Here is the definition of SymbolInds2Bits: sionna.mapping.SymbolInds2Bits(num_bits_per_symbol, dtype=tf.float32, **kwargs) source code. The source code link of SymbolInds2Bits is [sionna.mapping.SymbolInds2Bits](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#SymbolInds2Bits).\n  \n```python\nclass SymbolInds2Bits(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    SymbolInds2Bits(num_bits_per_symbol, dtype=tf.float32, **kwargs)\n\n    Computes the binary representation of symbol indices.\n\n    Parameters\n    ----------\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol\n\n    dtype : tf.DType\n        Defaults to `tf.float32`. Defines the datatype for internal\n        calculations and the output dtype.\n\n    Input\n    -----\n    : tf.int\n        Tensor of arbitrary shape filled with symbol indices.\n\n    Output\n    ------\n    : ``input.shape + [num_bits_per_symbol]``, tf.float\n        Tensor of the same shape as ``input`` filled with the binary\n        representations of the symbol indices.\n\n    Note\n    ----\n    The binary representation is computed by casting the last dimension of\n    the input to `tf.string` and then to `tf.int` with `\"2\"` as second argument.\n    This is certainly not the most efficient way for symbol to bit\n    transformation but ensures internal consistency.\n    \"\"\"\n    def __init__(self,\n                 num_bits_per_symbol,\n                 dtype=tf.float32,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        self.num_bits_per_symbol = num_bits_per_symbol\n        assert self.num_bits_per_symbol > 0, \\\n            \"num_bits_per_symbol must be positive.\"\n\n    def call(self, inputs):\n        b = str(self.num_bits_per_symbol)\n        x = tf.strings.to_string(inputs)\n        x = tf.strings.pad_right(x, int(b), \"0\")\n        x = tf.strings.to_number(x, out_type=tf.int32, num_bits=0)\n        x = tf.cast(x, dtype=self.dtype)\n\n        shape = tf.concat([[-1], tf.shape(x), [self.num_bits_per_symbol]], 0)\n        x = tf.broadcast_to(x, shape)\n        return x\n```"
"Here is the detailed information of TimeChannel:   \n  \n[sionna.channel.TimeChannel(channel_model, bandwidth, max_delay_spread=3e-6, l_min=-6, l_max=6, normalize_channel=False)](https://nvlabs.github.io/sionna/_modules/sionna/channel/time_channel.html#TimeChannel)  \n  \nTime domain channel realizations can be generated and applied to channel inputs using this class.  \n  \nThe channel is assumed to be both non-sparse and full-rank. Non-sparseness means that all transmitters and receivers have their antennas either in the field of the other party, or if an antenna is not in the field of another party, it is not in the field for any channel realization. This is equivalent to having either reflection or diffraction present, but no multi-path propagation.\n\nThe channel model is set using the channel_model property. Valid values are the string \"rayleigh\", \"rician\", \"dual_random_rician\", and \"uwb\". For \"rayleigh\", \u201crician\", and \"dual_random_rician\", the bandwidth and maximum_delay_spread parameters are required. For \"uwb\", a model of the environment is required, such as \"office\", \"apartment\", etc. Note that \"uwb\" is not available if the network is not properly initialized using init_uwb().\n\nThe sinc filter is applied in the time domain. The sinc filter is windowed using the Blackman-Harris window. The sinc filter is not normalized by default. This means that if the sinc filter is applied to the input with an average energy of $P$, then the output has an energy of $P$ as well. If normalize_channel is set to True, then the channel is normalized over the i.i.d. channel realizations to ensure that on average, the energy per transmit antenna is $P$.\n\n### Parameters\n\n- `channel_model` (str): Channel model used for the link level simulations. Valid values are \"rayleigh\", \"rician\", \"dual_random_rician\", and \"uwb\". For \"rayleigh\" and \"rician\", the `bandwidth` and `max_delay_spread` parameters are required. For \"uwb\", an instance of `UwbModel` is required.\n- `bandwidth` (float): Bandwidth ($B$) [Hz]\n- `max_delay_spread` (float): Maximum delay spread [s]. Only used with \"rayleigh\", \"rician\", and \"dual_random_rician\" channel models. Defaults to 3 microseconds (3us).\n- `l_min` (int, default -6): Smallest filter lag of the discrete time channel impulse response.\n- `l_max` (int, default 6): Largest filter lag of the discrete time channel impulse response.\n- `normalize_channel` (bool, default False): If set to True, the channel is normalized over the channel realizations. Defaults to False.\n\n### Input\n\n- `b` ([batch size, num_tx, num_tx_ant, num_time_steps], tf.complex):  Baseband signals\n\n### Output\n\n- `b_hat` ([batch size, num_rx, num_rx_ant, num_time_steps], tf.complex): Channel output\n- `h_time` ([batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_steps + l_max - l_min], tf.complex): Channel responses. The smallest lag is l_min and the largest lag is l_max. These are the same as the l_min and l_max parameters of the TimeChannel class.  \n  \n**Note: **The channel responses h_time can be used to implement a channel equalizer (e.g., LMMSE, ZF, MMSE) as a function of time. The input to such an equalizer is then the received signal b_hat (= y - n), the channel response h_time, and the noise variance per received antenna. The output of the equalizer are the denoised received signals, i.e., s_hat, the noise variance estimates, and the bit/symbol estimates.  \n  \n### Properties\n\n**Property: `bandwidth`**\n- Bandwidth in Hz\n\n**Property: `channel_model`**\n- Channel model used for the link level simulations. Can be one of \"rayleigh\", \"rician\", \"dual_random_rician\", or \"uwb\".\n\n**Property: `delays`**\n- Delay lags for the discrete-time channel impulse response\n\n**Property: `l_max`**\n- Largest delay lag for the discrete-time channel impulse response\n\n**Property: `l_min`**\n- Smallest delay lag for the discrete-time channel impulse response\n\n**Property: `normalize_channel`**\n- Indicates if the channel is normalized over the channel realizations\n\n**Property: `num_delay_spread_samples`**\n- Number of delay spread samples\n\n**Property: `sampling_frequency`**\n- Sampling frequency in Hz\n\n**Property: `sim_observations`**\n- Number of simulation observations\n\n**Property: `sim_resolution`**\n- Simulation resolution in s"
"The Antenna class in the Sionna package is meant to define the configuration and properties of an antenna used in wireless communication simulations. An Antenna can be single- or dual-polarized and has a unique configuration, including its pattern and polarization.\n\nHere are the key attributes of the Antenna class:\n- pattern (str): Indicates the type of pattern the antenna is set to, which can be either \"iso\", \"dipole\", \"hw_dipole\", or \"tr38901\".\n- polarization (str): Denotes the type of polarization, which can be either \"V\" (vertical) or \"H\" (horizontal). For single-polarized antennas, there is only one polarization direction. For dual-polarized antennas, it is determined by the last dimension.\n- polarization_model (PolarizationModel): Model for polarization. It's set to \"lin_pol\" by default, and can be assigned to an instance of PolarizationModel.\n- dtype (tf.complex): Data type of the antenna pattern, set to tf.complex64 by default.\n\nThe Antenna class also contains several properties, which are used to return the corresponding attribute values. For instance, pattern and polarization are properties of the Antenna class, which return the pattern and polarization of the antenna when accessed.\n\nIn terms of its usage, an Antenna is not directly applied to a transmitter or receiver. Instead, it is part of an AntennaArray, which is then assigned to the transmitter or receiver. The AntennaArray represents the configuration of an array of antennas, and all elements of this array are sharing the same Antenna. This can be set through the scene property tx_array (for transmitters) or rx_array (for receivers).\n\nThough not provided in the context, typically an AntennaArray is to be created and the Antenna is assigned to it before it is assigned to the transmitters or receivers in the scene."
"```python\nclass TurboTermination(ABC):\n    # .....\n    \n    def get_num_term_syms(self):\n        num_term_bits = math.ceil(2 * self.conv_n * self.mu / 3)\n        return num_term_bits\n\n    def term_bits_turbo2conv(self, term_bits):\n        num_term_syms = self.get_num_term_syms()\n        term_bits1 = term_bits[0:num_term_syms//2]\n        term_bits2 = term_bits[num_term_syms//2: num_term_syms]\n        return term_bits1, term_bits2\n\n    def termbits_conv2turbo(self, term_bits1, term_bits2):\n        num_term_syms = self.get_num_term_syms()\n        total_term_bits = np.concatenate([term_bits1, term_bits2])\n        total_term_bits = np.pad(total_term_bits, [0, num_term_syms-len(total_term_bits)], mode='constant')\n        return total_term_bits\n```"
"To wrap everything in a Keras model for convenient BER simulations and comparison of model parameters, you can follow these steps:\n\n1. Import the necessary libraries and modules. This includes TensorFlow, Keras, and various modules from the Sionna package.\n\n2. Set up the environment and configure the GPU settings.\n\n3. Define a binary source and an encoder. The binary source is used to generate random data, and the encoder is used to encode the data. \n\n4. Define a mapper and a demapper. The mapper is used to map the encoded data to a complex-valued representation, and the demapper is used to demap the data back to binary form.\n\n5. Define a 5G LDPC code and initialize it. This code will be used to encode the data.\n\n6. Define a LMMSE equalizer. This is used to estimate the transmitted symbol from the received signal.\n\n7. Define a Gaussian  channel. This is a specific type of channel used to model the transmission of data.\n\n8. Define a 5G LDPC decoder. This decoder will be used to decode the encoded data.\n\n9. Define the Keras model. This model will be used to simulate the Bit Error Rate (BER) of the system. The model should take in the batch size and the EbNo as inputs, generate the transmitted bit sequence, encode it, map it, transmit it over the channel, demap the received signal, and decode it. The model should also calculate the BER, which is the ratio of the total number of bits transmitted to the number of bits received incorrectly.\n\n10. Run the BER simulations for different values of EbNo and batch size. This can be done by calling the `simulate` method of the model, passing in the range of EbNo values and the batch size.\n\n11. Plot the BER results to compare the different model parameters."
"The `build_type_grid` method of the `ResourceGrid` class is intended to return a tensor indicating the type of each resource element. A resource element can be one of four types:\n\n- 0: Data symbol\n- 1: Pilot symbol\n- 2: Guard carrier symbol\n- 3: DC carrier symbol\n\nThe method returns a tensor of shape [num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], and the output is of type `tf.int32`. It essentially returns for each transmitter and each stream the type of the resource elements of the corresponding resource grid.\n\nThe inputs to this method are expected to be:\n\n- `tx_ind` (of type `int`): Indicates the transmitter index.\n- `tx_stream_ind` (of type `int`): Indicates the index of the stream.\n\nIt seems from the given context that the function will mainly be used to identify the type of resource elements in the process of mapping data and pilot symbols into the resource grid for OFDM-based transmissions."
"Here is the detailed information of SymbolLogits2LLRs:   \n  \nLink of the source code:  https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#SymbolLogits2LLRs\n  \nComputes LLRs (or hard-decisions) on bits from a tensor of logits (i.e., unnormalized log-probabilities) or hard decisions on constellation points.\n\nParameters\n\n        num_bits_per_symbol (int) \u2013 The number of bits per constellation symbol, e.g., 4 for QAM16.\n\n        hard_out (bool) \u2013 If True, the layer provides hard-decided bits instead of soft-values. Defaults to False.\n\n        dtype (One of [tf.float32, tf.float64] tf.DType) \u2013 The dtype for the input and output. Defaults to tf.float32.\n\nInput\n\n        (..., n, num_points) \u2013 Logits for constellation points or hard-decisions on constellation points.\n\nOutput\n\n        (..., n, num_bits_per_symbol) \u2013 LLRs or hard-decisions for every bit.  \n  \nThis class calculates the LLRs using the definition given in the context.  \n  "
"Here is the detailed information of MaximumLikelihoodDetector:   \n  \n[sionna.ofdm.MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#MaximumLikelihoodDetector)  \n\nMaximum-likelihood (ML) detector for OFDM MIMO transmissions.\n\nThis layer implements maximum-likelihood (ML) detection for OFDM MIMO transmissions. Both ML detection of symbols or bits with either soft- or hard-decisions are supported. The OFDM and stream configuration are provided by a ResourceGrid and StreamManagement instance, respectively. The actual detector is an instance of MaximumLikelihoodDetector.\n\n**Parameters**\n\n- `output` (str): Type of output, either \"bit\" or \"symbol\". Whether soft- or hard-decisions are returned can be configured with the `hard_out` flag.\n- `demapping_method` (str): Demapping method used, either \"app\" or \"maxlog\".\n- `resource_grid` (ResourceGrid): Instance of ResourceGrid.\n- `stream_management` (StreamManagement): Instance of StreamManagement.\n- `constellation_type` (str): Type of constellation used, either \"qam\", \"pam\", or \"custom\". For \"custom\", an instance of Constellation must be provided.\n- `num_bits_per_symbol` (int): Number of bits per constellation symbol, e.g., 4 for QAM16. Required only for constellation types \"qam\" and \"pam\".\n- `constellation` (Constellation): Instance of Constellation or None. If None, `constellation_type` and `num_bits_per_symbol` must be provided.\n- `hard_out` (bool): If True, the detector computes hard-decided bit values or constellation point indices instead of soft-values. Defaults to False.\n- `dtype` (tf.DType): The dtype of `y`. Defaults to tf.complex64. The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n**Input**\n\n- `(y, h_hat, prior, err_var, no)` \u2013 Tuple:\n  - `y` ([batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex): Received OFDM resource grid after cyclic prefix removal and FFT.\n  - `h_hat` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex): Channel estimates for all streams from all transmitters.\n  - `prior` ([batch_size, num_tx, num_streams, num_data_symbols x num_bits_per_symbol] or [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float): Prior of the transmitted signals, expecting LLRs if \"bit\" output, or logits if \"symbol\".\n  - `err_var` ([Broadcastable to shape of h_hat], tf.float): Variance of the channel estimation error.\n  - `no` ([batch_size, num_rx, num_rx_ant] or only the first n dimensions, tf.float): Variance of the AWGN noise.\n\n**Output**\n\nDepending on the `output` setting:\n- If `output` equals \"bit\":\n  - `[batch_size, num_tx, num_streams, num_data_symbols, num_bits_per_symbol]`, tf.float: LLRs or hard-decisions for every bit of every stream.\n- If `output` equals \"symbol\":\n  - `[batch_size, num_tx, num_streams, num_data_symbols, num_points]`, tf.float or `[batch_size, num_tx, num_streams, num_data_symbols]`, tf.int: Logits or hard-decisions for constellation symbols for every stream. Hard-decisions correspond to the symbol indices."
"To initialize a `TurboEncoder` with custom generator polynomials, you can make use of the generator polynomial representation mentioned in the context which is in binary format. \n\nThe generator polynomial is a string of ones and zeros, with each digit representing the coefficient of the polynomial in binary form. These coefficients directly map to the connection between the shift registers in the encoder where the input sequences drive the data through the registers in a systematic way. \n\nAn example of a generator polynomial in the context is \"10011\", which is meant to be read from right to left with the zeroth bit being the most significant coefficient and the fifth bit the least significant. These bits represent the connections between the input and the registers in a polynomial code, in this case, the polynomial $1 + D^3 + D^4$. \n\nSo, to initialize a `TurboEncoder` with the \"10011\" generator polynomial, you would set `gen_poly=\"10011\"`. Here's the required code snippet as per the context:\n\n```python\nfrom sionna.fec.turbo import TurboEncoder\n\n# Assuming gen_poly is a string with the desired polynomial, rate should be in\n# accordance with the polynomial provided\ngen_poly = \"10011\" # An example polynomial, please replace with actual polynomial\nencoder = TurboEncoder(gen_poly=gen_poly,\n                       rate=1/3,\n                       terminate=True) \n```\n\nWhen you pass `gen_poly=\"10011\"` to the `TurboEncoder`, the encoder sets up the connectivity between the shift registers based on the given polynomial, in this case, the polynomial represents the code specified in the context, i.e., the polynomial $1 + D^3 + D^4$."
"To use the generator to sample the first few items of the dataset, you can follow these steps:\n\n1. Initialize the generator with the appropriate parameters. In this case, the generator is expecting an HDF5 file storing path coefficients and delays.\n\n```python\ngenerator = HD5CIRGen(filename)\n```\n\n2. Call the generator, which is a function that returns an iterator over the items in the dataset. Each item is a tuple of tensors `a` and `tau`, corresponding to the path coefficients and delays.\n\n```python\n(a,tau) in generator():\n```\n\nThe generator is implemented to yield the path coefficients `a` and delays `tau` one batch at a time. Each batch contains `batch_size` items, so calling the generator multiple times will sample multiple items from the dataset.\n\nThe output of the generator is a tuple of two tensors: `a` and `tau`, corresponding to the path coefficients and delays. The shape of the path coefficients tensor is `[, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps]`, and the shape of the delays tensor is `[, num_rx, num_tx, num_paths]`. These tensors can then be used as input to a channel model."
"To save the estimated matrices for future use, you can use the numpy `save` function. Here is a step-by-step guide:\n\n1. After estimating the covariance matrices, store them in appropriate variables. In the context, the estimated matrices are stored in `FREQ_COV_MAT`, `TIME_COV_MAT`, and `SPACE_COV_MAT`.\n\n2. Set the desired path for saving the matrices. \n\n3. Use the numpy `save` function to save the matrices to the specified path. The first argument is the path, the second argument is the variable to save.\n\nHere is the relevant code from the context:\n\n```python\n# Estimated matrices\nFREQ_COV_MAT, TIME_COV_MAT, SPACE_COV_MAT = estimate_covariance_matrices(batch_size, num_iterations)\n# Set the path to save the matrices\npath_freq = 'freq_cov_mat.npy'\npath_time = 'time_cov_mat.npy'\npath_space = 'space_cov_mat.npy'\n# Save the matrices\nnp.save(path_freq, FREQ_COV_MAT.numpy())\nnp.save(path_time, TIME_COV_MAT.numpy())\nnp.save(path_space, SPACE_COV_MAT.numpy())\n```\n\nIn this code, the estimated frequency, time, and space covariance matrices are saved to files with names specified in `path_freq`, `path_time`, and `path_space`."
"IDD in MIMO simulations is an approach that combines data detection and decoding in a iterative process to improve the quality of the received signal recovery. The concept is based on exchanging soft-information (represented by log-likelihood ratios, LLRs) between the data detector and the channel decoder.\n\nThe IDD MIMO receiver iteratively exchanges soft-information between the data detector and the channel decoder. The *a posteriori* information (which equals the *a priori* information minus the *a priori* information) is called *extrinsic information*. The detector receives LLRs that indicate the uncertainty of the received signal, and the decoder also receives these LLRs. \n\nIn the context, the IDD is explained with different types of detectors and decoders. For instance, the IDD with a LMMSE equalizer and a APP decoder is presented. The detector is provided with the decoder's *a posteriori* information and the detector's output is used to update the decoder. This process is repeated until a stopping criterion is met, or a maximum number of iterations is reached. \n\nThe IDD concept was also explained with reference to classical IDD, which is associated with the Turbo code, and SISO MMSE-PIC, which uses the full *a posteriori* information from the decoder.\n\nThe context also discusses the performance of IDD, showing simulations that indicate IDD with non-resetting decoding works better than resetting decoding, particularly for a low number of decoding iterations. \n\nIn the context of MIMO simulations, IDD is a crucial concept for improving the performance of wireless communication systems by considering multiple input multiple output (MIMO) transmissions."
"Here is the detailed information of Descrambler:   \n  \nSource code:\n\n```python\nclass Descrambler(Layer):\n    \"\"\"Descrambler for a given scrambler.\n\n    The class inherits from the Keras layer class and can be used as layer in a\n    Keras model.\n\n    Parameters\n    ----------\n    scrambler: Scrambler or TB5GScrambler\n        Associated Scrambler instance which\n        should be descrambled.\n\n    binary: bool\n        Defaults to True. Indicates whether bit-sequence should be flipped\n        (i.e., binary operations are performed) or the signs should be\n        flipped (i.e., soft-value/LLR domain-based).\n\n    dtype: None or tf.DType\n        Defaults to `None`. Defines the datatype for internal calculations\n        and the output dtype. If no explicit dtype is provided the dtype\n        from the associated interleaver is used.\n\n    Input\n    -----\n    (x, seed):\n        Either Tuple ``(x, seed)`` or ``x`` only (no tuple) if the internal\n        seed should be used:\n\n    x :  tf.float\n        1+D tensor of arbitrary shape.\n\n    seed : int\n        An integer defining the state of the random number\n        generator. If explicitly given, the global internal seed is\n        replaced by this seed. Can be used to realize random\n        scrambler/descrambler pairs (call with same random seed).\n\n    Output\n    ------\n        :  tf.float\n        1+D tensor of same shape as ``x``.\n\n    Raises\n    ------\n    AssertionError\n        If ``scrambler`` is not an instance of `Scrambler`.\n\n    TypeError\n        If `x` has dtype `tf.DType` not {tf.float32, tf.float64}.\n    \"\"\"\n\n    def __init__(self,\n                 scrambler,\n                 binary=True,\n                 dtype=None,\n                 **kwargs):\n\n        assert isinstance(scrambler, (Scrambler, TB5GScrambler)),\\\n             \"scrambler must be a valid Scrambler instance.\"\n        self._scrambler = scrambler\n\n        assert isinstance(binary, bool), \"binary must be bool.\"\n        self._binary = binary\n\n        if dtype is None:\n            dtype = self._scrambler.dtype\n        super().__init__(dtype=dtype, **kwargs)\n\n    #########################################\n    # Public methods and properties\n    #########################################\n\n    @property\n    def scrambler(self):\n        \"\"\"Associated scrambler instance.\"\"\"\n        return self._scrambler\n\n    #########################\n    # Utility methods\n    #########################\n\n    #################\n    # Keras layer\n    #################\n\n    def build(self, input_shape):\n        \"\"\"Build the model and initialize variables.\"\"\"\n        pass\n\n    def call(self, inputs):\n        r\"\"\"Descrambling function.\n\n        This function returns the descrambled version of ``inputs``:\n        :math:`x_\\text{descrambled} = \\textsc{scrambler}(x_\\text{crambled})`.\n\n        If ``seed`` is listed in the inputs, this function uses this to set the\n        state of the random number generator. This allows the usage of\n        non-fixed seeds.\n\n        For auditing, the input tensor ``x`` and the seed ``s`` are logged\n        if the corresponding flag is set (``log_inputs``).\n\n        Parameters\n        ----------\n        inputs\n            Either Tuple ``(x, seed)`` or ``x`` only (no tuple) if the\n            internal seed should be used:\n\n        x : tf.float\n            1+D tensor of arbitrary shape.\n\n        seed : int\n            An integer defining the state of the random number\n            generator. If explicitly given, the global internal seed is\n            replaced by this seed. Can be used to realize random\n            scrambler/descrambler pairs (call with same random seed).\n\n        Returns\n        -------\n        tf.float\n            1+D tensor of same shape as the input.\n\n        \"\"\"\n        if isinstance(inputs, (tuple, list)):\n            if len(inputs)==1: # if user wants to call with call([x])\n                seed = None\n                x = inputs\n            elif len(inputs)==2:\n                x, seed = inputs\n            else:\n                raise TypeError(\"inputs cannot have more than 2 entries.\")\n        else:\n            seed = None\n            x = inputs\n\n        # Scrambler potentially needs to set seed state. Cannot do this\n        # without knowing if graph is eager or not. Thus, we call to set state\n        # if seed is given.\n        if seed is not None:\n            tf.random.set_seed(seed)\n\n        # ensure that x is binary\n        if self._binary:\n            x = binary_op(x)\n        else: # if binary=False, flip signs\n            x = -tf.sign(x)\n\n        # call scrambler\n        if self._scrambler.binary:\n            y = self._scrambler(x)\n        else:\n            y = self._scrambler(x, seed=seed)\n\n        # flip signs again if binary was set to False (soft-values)\n        if not self._binary:\n            y = -y\n\n        return y\n```\n\nInformation source code:\n- [Pfister03](https://nvlabs.github.io/sionna/api/fec.scrambling.html#id2)\n- ETSI 3GPP TS 38.211 Physical channels and modulation, v.16.2.0, 2020-07"
"Here is the definition of KBestDetector: sionna.mimo.KBestDetector(output, num_streams, k, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, use_real_rep=False, list2llr=None, dtype=tf.complex64)\n\nThe source code link of KBestDetector is [KBestDetector](https://nvlabs.github.io/sionna/_modules/sionna/mimo/detection.html#KBestDetector). \n\n```python\nclass KBestDetector(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"KBestDetector(output, num_streams, k, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, use_real_rep=False, list2llr=None, dtype=tf.complex64)\n\n    MIMO K-Best detector\n\n    This layer implements K-Best MIMO detection as described\n    in (Eq. 4-5) of [FT:2005]_. It can either generate hard decisions (for\n    symbols or bits) or soft-values for bits.\n\n    The algorithm operates in either the complex or real-valued domain.\n    Although both options produce identical results, the former has the advantage\n    that it can be applied to arbitrary symbol constellations. It also reduces\n    the number of streams (or depth) by a factor of two.\n\n    The way soft-values are computed is determined by the ``list2llr``\n    function. The default solution\n    :class:`~sionna.mimo.List2LLRSimple` assigns a fixed demapping\n    function value to all bits which can be computed from the\n    log-likelihood ratios of the symbols using the constellation\n    object. More sophisticated solutions may be available.\n\n    Parameters\n    -----------\n    output : One of [\"bit\", \"symbol\"], str\n        The type of output, either bits or symbols. Whether soft- or\n        hard-decisions are returned can be configured with the\n        ``hard_out`` flag.\n\n    num_streams : tf.int\n        Number of transmitted streams\n\n    k : tf.int\n        The number of paths to keep. Cannot be larger than the\n        number of constellation points to the power of the number of\n        streams.\n\n    num_bits_per_symbol : tf.int or None\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the detector computes hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`.\n\n    use_real_rep : bool\n        If `True`, the detector uses the real-valued equivalent representation\n        of the channel. This only works with a QAM constellation. Defaults\n        to `False`.\n\n    list2llr : One of [None, \"app\", \"maxlog\"], str or \\\n                        a callable object (like a function) or None\n        The method used to compute LLRs from a list of candidate vectors.\n        If `None`, the default solution :class:`~sionna.mimo.List2LLRSimple`\n        is used.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of `y`. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n        \"\"\"\n\n    def __init__(self,\n                 output,\n                 num_streams,\n                 k,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 use_real_rep=False,\n                 list2llr=\"maxlog\",\n                 dtype=tf.complex64):\n\n        super().__init__()\n        assert dtype in [tf.complex64, tf.complex128],\\\n            \"The dtype must be tf.complex64 or tf.complex128\"\n\n        self._output = output\n        if self._output==\"bit\":\n            assert num_bits_per_symbol is not None, \\\n                \"num_bits_per_symbol must be provided for 'bit' output\"\n        self._hard_out = hard_out\n\n        # Create a KBestDetector object\n        self._detector = ft.KBestDetector_(dtype.real_dtype,\n                                            self._output,\n                                            num_streams,\n                                            k,\n                                            constellation_type,\n                                            num_bits_per_symbol,\n                                            constellation,\n                                            hard_out,\n                                            use_real_rep,\n                                            list2llr)\n\n    def call(self, inputs):\n        # x: Transmitter (or pre-coder) output\n        # h: Channel state information\n        # err_var: Variance of the channel noise\n\n        if self._output==\"bit\":\n            y, h, err_var = inputs\n        else:\n            y, h = inputs\n\n        # Get number of streams from input shape\n        tf.debugging.assert_type(tf.shape(y)[0], tf.int32,\n                                 message=\"Rank of inputs must be at least 2.\")\n        tf.debugging.assert_equal(tf.shape(y)[-2], self._num_streams, # pylint: disable=access-member\n                           msg=\"The second-last dimension of inputs must be %d.\"%self._num_streams)\n\n        # If number of streams is 1, call KBestDetector with num_streams-1\n        # and concatenate the result with the remainder\n        if self._num_streams==1:\n            llr = self._detector(y, h, err_var)\n            return tf.concat([llr, llr.numpy().max(1, keepdims=True)], 1)\n\n        return self._detector(y, h, err_var)\n```"
"The `position` and `orientation` properties are used to move scene objects in Sionna's ray tracing module. Scene objects include everything in the scene, such as cars, trees, buildings, etc., that are being modeled in the current simulation.\n\nThe `position` property represents the 3D position of the scene object in the scene's coordinate system. This is a key parameter for the placement of the scene object. The `position` property is a 3-element vector that can be accessed like so:\n\n```python\nposition = scene_object.position\nprint(\"Position:\", position)\n```\n\nThe `orientation` property of a scene object controls the orientation of the object. It is often expressed as a 3D rotation represented by a 3x3 matrix. In the context provided, it is represented by a quaternion, which is a 4-element vector that can be accessed like so:\n\n```python\norientation = scene_object.orientation\nprint(\"Orientation:\", orientation)\n```\n\nThe orientation of a scene object defines how it is rotated in the scene. By combining rotation matrices for different axes, you can express rotations about any axis. In the context provided, the orientation of the car is controlled by yaw, pitch, and roll angles, which are represented by the alpha, beta, and gamma parameters. These parameters can be used to define the orientation of the car in the scene.\n\nThe `position` and `orientation` properties are fundamental for setting up the scene, and for simulating the effects of mobility. Whether the scene is for a car, a building, or any other scene object, these properties will dictate where the object is placed and how it is oriented in the scene."
"To run the final evaluation for different system configurations in Sionna RT, you can follow these steps:\n\n1. Import the necessary modules and set up the environment. This includes importing Sionna and TensorFlow, setting up the GPU configuration, and setting the random seed for reproducibility.\n\n2. Define the simulation configuration. This includes the number of evaluation examples, the frequency, the antenna arrays, and the minimum and maximum number of antennas per ray.\n\n3. Create an instance of the Sionna RT ray tracer, using the default PlanarArray antenna array for the transmitters and receivers.\n\n4. Define a Keras layer for the channel model. This layer should initialize and run the ray tracer, build the channel impulse response, and compute the frequency response.\n\n5. Define the OFDM resource grid configuration.\n\n6. Define the neural receiver configuration, including the number of convolutional layers, the size of the convolutional kernels, and the number of antennas.\n\n7. Define the MeanSquareError class, which is a Keras metric for computing the mean square error (MSE) of two signals.\n\n8. Run the final evaluation for different system configurations. This involves looping over different numbers of transmit antennas, different numbers of receive antennas, and different distance scenarios. For each configuration, the code should generate a new batch of channel responses, based on the defined simulation parameters. It should then run the end-to-end system, compute the MSE, and store the results for later analysis.\n\nPlease note that the exact code for these steps is provided in the context, but you may need to adjust it slightly to fit your specific use case."
"To compute the exact Doppler shifts based on the equation provided in the Background Information, you can use the equation that relates the Doppler shift to the velocity of the receiver (or transmitter) and the angle of the link relative to the direction of the velocity vector. The equation is:\n\nf_d = f_c * V_t * cos(\u03b8_t) / c * (1 + \u03b8_c * \u03b8_t)\n\nwhere:\n- f_d is the Doppler shift\n- f_c is the carrier frequency\n- V_t is the velocity of the transmitter (or, in the case of the link from the scene to the transmitter, the velocity of the scene)\n- \u03b8_t is the angle of the link from the scene (or transmitter) relative to the x-axis\n- \u03b8_c is the angle of the link to the scene (or transmitter) it\u00f4s entering relative to the direction of the velocity vector. For a link leaving a scene, it is relative to the scene it's leaving.\n\nComputing the exact Doppler shifts entails the following steps:\n\n1. Compute the velocity vectors V_t and V_r for each link. These are the velocities of the scene and the receiver (or transmitter) respectively. You can obtain these by multiplying the speed of the scene (or transmitter) by the unit vector that points in the direction of the scene (or transmitter).\n\n2. Compute the angles \u03b8_t and \u03b8_r for each link. The angle \u03b8_t is the angle of the link from the scene (or transmitter) relative to the x-axis, and \u03b8_r is the angle of the link from the receiver (or, if the velocity vector of the scene is known, from the scene) relative to the x-axis.\n\n3. Compute the Doppler shift using the equation provided. For the link from the scene to the receiver, you should use the velocity vector of the scene. For the link from the scene to the transmitter, you should use the velocity vector of the transmitter.\n\nLet's compute the Doppler shift for the last link from the scene to the receiver. The velocity of the scene is stored in the variable scene.velocity. The angle of the link from the scene to the receiver can be obtained from the last row of the direction vector, which is stored in scene.rx.\u03b8[..., -1]. The Doppler shift can then be computed using the equation provided. \n\nHere is the code that does this:\n\n```python\nimport numpy as np\nfrom sionna.rt import Scene\n\n# Load the scene\nscene = Scene.load(Sionna.rt.scene.munich)\n\n# Get the velocity vector of the scene\nv_scene = scene.velocity\n\n# Get the angle of the link from the scene to the receiver\ntheta_r = scene.rx.\u03b8[..., -1]\n\n# Compute the Doppler shift\ndoppler_shift = scene.rx.\u03b8[..., -1].dot(v_scene) * cos(theta_r)\n```\n\nThis code will compute the exact Doppler shift for the last link from the scene to the receiver."
"Here is the definition of cir_to_time_channel: sionna.channel.cir_to_time_channel(cir, bandwidth, channel_model, normalize_delay_sums=True, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/utils.html#cir_to_time_channel)\n\nsource code:\n```python\ndef cir_to_time_channel(cir, bandwidth, channel_model, normalize_delay_sums=True,\n                        dtype=tf.complex64):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Computes the channel taps of the discrete complex-baseband channel\n    representation from the given channel impulse responses.\n\n    Given a cir :math:`(a_{m}, \\tau_{m})` composed of\n    :math:`M` paths with complex\n    amplitudes :math:`a_{m}` and delays :math:`\\tau_{m}`,\n    the channel taps are computed as follows:\n\n    .. math::\n        h_{b}(u, k) = \\sum_{m=0}^{M-1} a_{m} \\text{sinc}\\left( k - W\\tau_{m} \\right)\n\n    for :math:`b` the time step, :math:`u` the receiver, and\n    :math:`k` the position of a tap on the channel filter.\n\n    Input\n    ------\n    cir : [...,M,...], tf.complex\n        Tensor of arbitrary rank containing the circular\n        impulse responses :math:`(a_{m}, \\tau_{m})` of the\n        channel.\n\n    bandwidth : float\n        System bandwidth [Hz]\n\n    channel_model : str\n        An optional string specifying the the channel model\n        for which the parameters are valid. Must be one of\n        the strings in :meth:`sionna.channel.models_supported` unless\n        the cir is provided directly. If ``channel_model`` is\n        `None`, then ``cir`` must be provided.\n\n    normalize_delay_sums : bool\n        If set to `True`, the power of the channel taps is\n        normalized over the receive antenna dimension by the\n        average energy per receive antenna. Defaults to `True`.\n\n    dtype : tf.Dtype\n        Defines the datatype for internal calculations and the output\n        dtype. Defaults to `tf.complex64`.\n\n    Output\n    -------\n    h_time : [..., num_re, L_tot], tf.complex\n        Channel taps in the time domain,\n        where `L_tot` is the total channel memory which depends\n        on the CIR structure.\n\n    Note\n    ----\n    The `bandwidth` is required to scale the sinc filter.\n    \"\"\"\n\n    # Bandwidth scaling factor for the sinc filter\n    w = tf.cast(bandwidth, dtype.real_dtype)\n\n    if channel_model is not None:\n        # Retrieve parameters for the given model\n        parameters = channel_model_parameters(channel_model)\n        cir = reparameterize_cir(cir, *parameters, dtype=dtype)\n\n    # Apply the sinc filter\n    h_time = tf.signal.sinc(M_PI*w*cir.delay_spread)\n    h_time = tf.reduce_sum(h_time*cir.coeff, axis=-2)\n    h_time = scale_taps(cir.num_taps, h_time, cir.sampling_time,\n                        normalize_delay_sums=normalize_delay_sums)\n\n    return h_time\n```"
"To generate the Channel Frequency Response, you need to follow these steps:\n\n1. Create an instance of the `FlatFadingChannel` class, passing the necessary parameters such as the `awgn` flag (to indicate whether additive white Gaussian noise should be added), the `spatial_corr` flag (to indicate whether spatial correlation should be considered), and other required parameters like noise figure, carrier frequency, antenna arrays, and time correlation parameters.\n\n2. Call the instance, passing the batch size and the `K` parameter which represents the number of target user terminals. This will generate the channel frequency responses.\n\n3. The channel impulse response can be obtained from the channel frequency response using the `cir_to_ofdm_channel` function. This function requires you to provide the channel frequency response and the length of the `N_RB` resource grid.\n\n4. This will generate the discrete-time channel impulse response.\n\nHere is a code snippet that demonstrates these steps:\n\n```python\nCHANNEL_MODEL = FlatFadingChannel(awgn=True, normalize_channel=True, return_bit=False, spatial_corr=False, dtype=tf.complex64)\nchannel_freq = CHANNEL_MODEL(batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, delay_spread, carrier_freq)\nh_d = cir_to_time_channel(channel_freq, rg_l)\n```\n\nIn this code, `delay_spread` is the rms delay spread which affects the channel impulse response shape. `rg_l` is the length of the resource grid.\n\nTo generate the Discrete-Time Channel Impulse Response, you can make use of the `cir_to_time_channel` function of the `sionna.channel` module as mentioned above. This function converts the continuous-time channel impulse response to the discrete-time channel impulse response. It uses a biorthogonal sinc filter for pulse shaping and receive filtering. \n\nPlease note that the batch size and other parameters like `num_rx, num_rx_ant, num_tx, num_tx_ant` affect the number of samples in the discrete-time channel impulse response. The `delay_spread` parameter affects the rms delay spread of the channel, thus impacting the channel impulse response. The `rg_l` parameter represents the length of the resource grid, which also impacts the discrete-time channel impulse response."
"Higher order modulation allows multiple bits to be encoded into a single symbol, effectively increasing the data rate. The demapper is used to interpret these symbols and extract the corresponding bits. The decoder then performs error correction on these bits. \n\nIn the context of Bit-Interleaved Coded Modulation (BICM), higher order modulation is used to separate modulation and coding into two tasks. This simplifies the design and tuning of communication systems. \n\nThe demapper and decoder are closely linked in this process. The demapper translates the received symbols into 'log-likelihood ratios' (LLRs) for each bit, providing an estimate of the transmitted bits. The decoder uses these LLRs to perform error correction and recover the original data. \n\nFor example, in the provided context, the Sionna package is used to set up a communication system with 16-QAM modulation and a Low-Density Parity-Check (LDPC) code. The `Mapper` component is used to map bits into symbols, and the `Demapper` component is used to generate LLRs from received symbols. The `LDPCBPDecoder` then uses these LLRs to perform iterative belief propagation decoding on the codewords. \n\nThe higher order modulation and demapping process is visualized in the context provided, showing how data is encoded, mapped to symbols, transmitted over a noisy channel, demapped to LLRs, and then decoded."
"To demonstrate how to handle the situation where the `LDPCBPDecoder` is stateful, we need to look at an example using the Sionna package. In this context, the `LDPCBPDecoder` class has an argument called `msg_vn`. The `msg_vn` argument controls the handling of VN (variable node) messages within the BP decoding algorithm.\n\nThe significance of the `msg_vn` parameter relates to the statefulness of the `LDPCBPDecoder`. As this decoder is potentially iterative (can run multiple BP iterations), it needs to keep track of the VN messages from one call to another. This is particularly important if the decoder is to be run in a stateful manner, where the VN messages from one call are used as initial values for the next call. This allows the decoder to potentially converge more quickly if it is not fully converged already.\n\nIn the example provided in the context, the `LDPCBPDecoder` is instantiated with `trained_bp = LDPCBPDecoder(ldpc, num_iter=20, stateful=True, msg_vn='split')`. Here, `msg_vn='split'` means that the VN messages are handled in a stateful manner, and it also dictates the internal message handling. The `msg_vn` parameter could also be a number, indicating the size of the internal message storage if stateful VN messaging is desired.\n\nNow, if we want to make use of the statefulness of the `LDPCBPDecoder`, we have to ensure that the VN messages from one call to another are properly handled. The `msg_vn` parameter in the `LDPCBPDecoder` function represents the mechanism for achieving this. Subsequently, this parameter dictates how the VN messages are handled in the decoder's internal algorithm.\n\nIt's important to note that the Sionna package also supports a stateful version of the `LDPCBPDecoder` that internally uses a single set of VN message scaling factors for all calls, which can sometimes be a simpler and more effective approach. The choice between stateful and stateless operation depends on the specific requirements of the application and the available resources."
"Here is the detailed information of subcarrier_frequencies:   \nGets the frequency of the subcarriers in Hz. The order of the subcarriers is from -N/2 to N/2, or from 0 to N/2, for the even and odd number of subcarriers, respectively.\n\nIf n_synth_samp is given, the returned frequency array is normalized to have a [-0.5, 0.5) range and is of length n_synth_samp, which is useful to represent the frequency offset of the subcarriers with respect to a reference frequency array. The normalization is achieved by scaling the frequency values with the sampling frequency. If n_synth_samp is not given, the sampling frequency is also not given and a warning is raised.\n\nTo visualize the spectrum over a wider frequency range, this property can be recomputed with an updated sampling frequency, i.e., it is also possible to provide a callable which returns the sampling frequency.\n\nPlease note that this property returns the frequency of the OFDM resource grid, which is not equivalent to the frequency of the subcarriers, as the resource grid can start at a non-zero DC offset. Use the property dc_freq to get the subcarrier frequency.  \n   [BeginnerTutorial](https://nvlabs.github.io/sionna/api/utils.html#BeginnerTutorial) |   [source code](https://nvlabs.github.io/sionna/_modules/sionna/api/utils.html#subcarrier_frequencies)\n  \nsource code:\n```python\ndef subcarrier_frequencies(fft_size, n_synth_samp=None, sampling_frequency=1.):\n    \"\"\"Gets the frequency of the subcarriers in Hz.\n\n    The order of the subcarriers is from -N/2 to N/2, or from 0 to N/2, for\n    the even and odd number of subcarriers, respectively.\n\n    If ``n_synth_samp`` is given, the returned frequency array is normalized\n    to have a [-0.5,0.5) range and is of length ``n_synth_samp``, which is\n    useful to represent the frequency offset of the subcarriers with respect to\n    a reference frequency array. The normalization is achieved by scaling\n    the frequency values with the sampling frequency. If ``n_synth_samp`` is\n    not given, the sampling frequency is also not given and a warning is\n    raised.\n\n    To visualize the spectrum over a wider frequency range, this property can\n    be recomputed with an updated sampling frequency, i.e., it is also possible\n    to provide a callable which returns the sampling frequency.\n\n    Please note that this property returns the frequency of the OFDM resource grid,\n    which is not equivalent to the frequency of the subcarriers, as the\n    resource grid can start at a non-zero DC offset. Use the property\n    :obj:`~sionna.ofdm.ResourceGrid.dc_freq` to get the subcarrier frequency.\n\n    Input\n    ------\n    fft_size : int\n        FFT size, e.g., 64.\n\n    n_synth_samp : int or callable, None\n        Number of synthetic samples. If provided as an integer, the\n        sampling frequency is assumed to be one and this value is\n        interpreted as the number of samples. If `None`, then ``sampling_frequency``\n        must be provided and this value is interpreted as the relative\n        offset to the DC carrier frequency in units of the\n        sampling frequency. E.g., ``n_synth_samp`` = 1 means the carriers are\n        offset with half the base spacing to the right of the DC carrier, and\n        ``n_synth_samp`` = -1 with half the base spacing to the left.\n\n    sampling_frequency : float\n        Sampling frequency [Hz]. Not necessary if ``n_synth_samp``\n        is provided.\n\n    Output\n    ------\n    freq : [fft_size], float\n        Subcarrier frequencies [Hz]\n    \"\"\"\n    assert isinstance(fft_size, int), \"'fft_size' must be int.\"\n    assert fft_size>0, \"'fft_size' must be positive.\"\n\n    if n_synth_samp is None:\n        warnings.warn(\"subcarrier_frequencies: The returned frequency array is not relative to \"\n                      \"the DC subcarrier. In order to avoid this, you can provide a \"\n                      \"calable that returns the sampling frequency as third argument.\",\n                      UserWarning)\n        sampling_frequency = sampling_frequency\n        n_synth_samp = 0\n    else: # compute synthetic samples\n        assert callable(n_synth_samp), \"n_synth_samp must be None or a callable\"\n        sampling_frequency = 1.\n\n    freq_ind = np.arange(fft_size)\n    mid = (fft_size-1)/2\n    freq = (freq_ind - mid + n_synth_samp) / fft_size \\\n           * sampling_frequency\n    return freq\n```"
"To simulate the transmission of a single Gaussian impulse over a lumped amplification channel model consisting of multiple fiber spans and optical amplifiers (EDFA), you can follow these steps:\n\n1. **Set up the environment**: Import the necessary libraries and set up the TensorFlow and Sionna configurations.\n\n2. **Define the simulation parameters**: Set the carrier frequency, the impulse parameters, the fiber parameters, and the simulation parameters such as the simulation accuracy and the simulation time window.\n\n3. **Implement the channel model**: Implement the channel model, starting with the optical channel and the preview of the transmitted impulse.\n\n4. **Enable the lumped amplification**: Enable the lumped amplification by setting the fiber span and the EDFA parameters. The fiber span parameters include attenuation and dispersion parameters, while the EDFA parameters include the amplifier gain and the noise figure.\n\n5. **Simulate the transmission**: Use the `similarity_vecot` function to calculate the similarity vector and the `coverage_map` function to obtain a coverage map. These steps allow you to see the impact of each enabled impairment individually.\n\n6. **Visualize the results**: Plot the transmitted impulse, the received impulse, and the amplitude of the impulse response between the receiver and the transmitter.\n\nRemember that the code provided in the context is written in Python and uses the Sionna package for simulating optical communications systems. Make sure to use the correct syntax and functions from the Sionna package when implementing the steps."
"Here is the detailed information of CRCDecoder:  \nAllows cyclic redundancy check verification and removes parity-bits.\n\nThe CRC polynomials from Sec. 5.1 in [3GPPTS38212_CRC] are available: {CRC24A, CRC24B, CRC24C, CRC16, CRC11, CRC6}.\n\nThe class inherits from the Keras layer class and can be used as layer in a Keras model.\n\n### Parameters\n\n- **crc_encoder:** `CRCEncoder` An instance of CRCEncoder to which the CRCDecoder is associated.\n- **dtype:** `tf.DType` Defaults to `None`. Defines the datatype for internal calculations and the output dtype. If no explicit dtype is provided the dtype from the associated interleaver is used.\n\n### Input\n\n- **inputs:** `[,k+crc_degree]`, `tf.float32`. 2+D Tensor containing the CRC encoded bits (i.e., the last `crc_degree` bits are parity bits). Must have at least rank two.\n\n### Output\n\n- **(x, crc_valid):** Tuple:\n  - **x:** `[,k]`, `tf.float32`. 2+D tensor containing the information bit sequence without CRC parity bits.\n  - **crc_valid:** `[,1]`, `tf.bool`. 2+D tensor containing the result of the CRC per codeword.\n\n### Raises\n\n- **AssertionError**: If `crc_encoder` is not `CRCEncoder`.\n- **InvalidArgumentError**: When rank(`x`)<2.\n\n### Properties\n\n- **crc_degree**:\n  - CRC degree as string.\n  \n- **encoder**:\n  - CRC Encoder used for internal validation.  \n  "
"The `Constellation` class outputs a complex-valued vector of constellation points used in digital communications. The number of bits per constellation symbol is defined by the `num_bits_per_symbol` parameter. An initial value for these constellation points can be provided as a parameter. The `normalize` parameter, if set to `True`, ensures that the constellation is normalized to have unit power. Furthermore, the `center` parameter, if set to `True`, ensures that the constellation has a zero mean. \n\nThe `dtype` parameter defines the datatype for internal use and output. The output of the `Constellation` class is the constellation itself, which is a 2D vector where each element is a complex number corresponding to a constellation point in the signal space. The class also provides a method to generate a scatter plot of the constellation, which can be particularly useful for visualization and analysis."
"The datatype for the LinearEncoder output is defined as `tf.float32`. This is indicated in the provided context, within the documentation of the LinearEncoder class, specifically in the \"Parameters\" (args) section, where the `dtype` parameter is described as:\n\n- **`dtype` (*tf.DType*)**: Defines the datatype for the output dtype.\n\nThe specified datatype for the output of the `LinearEncoder` is tensorflow's float type `tf.float32`."
"Here is the detailed information of sionna.utils.matrix_pinv:   \n\n[sionna.utils.matrix_pinv(tensor)](https://nvlabs.github.io/sionna/_modules/sionna/utils/tensors.html#matrix_pinv)\n\nComputes the pseudo-inverse of a Hermitian positive definite tensor.\n\nHermitian positive pseudo-inverses the matrix pseudo-inverse for Hermitian positive definite matrices.\n\n### Parameters\n\n- **tensor** ([..., M, M]): A tensor of rank greater than or equal to 2. tensor must have the same type as the matrix type.\n\n### Returns\n\nA tensor of the same shape and type as `tensor` containing the pseudo-inverse of its last two dimensions.\n\n**Note: **This is a wrapper around the TensorFlow matrix pseudo-inverse function sionna.utils.matrix_pinv."
"Here is the the Sionna Sionna Demapper: sionna.mapping.Demapper(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, with_prior=False, dtype=tf.complex64, **kwargs)\n\nSource code:\n```python\nclass Demapper(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Demapping to bits or symbols.\n\n    This class defines a Keras layer implementing different\n    demapping (a.k.a., \"demodulation\") functions.\n    The demapping function is like :math:`\\log\\left(\\Pr\\left(b_i\\lvert y\\right)\\right)`\n    where :math:`b_i` is the :math:`i\\text{th}` bit label and :math:`y` the received symbol.\n\n    **Demapping methods**:\n\n    \"app\" :\n        Log-likelihood ratios (LLRs) are approximated with\n        :math:`\\operatorname{erfc}\\left(2^{0.5}\\left(\\Re\\left(y\\right)\\cdot LLR\\_s^{\\text{app}} + LLR\\_o^{\\text{app}}\\right)\\right)`.\n\n    \"maxlog\" :\n        Log-likelihood ratios (LLRs) are approximated with\n        :math:`\\log\\left(\\operatorname{Pr}\\left(b_i=1\\lvert y\\right)\\right) - \\log\\left(\\operatorname{Pr}\\left(b_i=0\\lvert y\\right)\\right)`.\n\n    \"maxlog_pmg\" :\n        Same as \"maxlog\" but with a parity-check matrix in the spirit of\n        polar or LDPC demapping applied. This requires knowledge about the\n        demapped bits positions and ends up to second order corrrect with\n        respect to the LLR estimation.\n\n    Parameters\n    ----------\n    demapping_method : One of [\"app\", \"maxlog\", \"maxlog_pmg\"], str\n        The demapping method used.\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the demapper provides hard-decided bit values instead\n        of soft-values. Defaults to `False`.\n\n    with_prior : bool\n        If `True`, the demapper also returns the demapping prior.\n        Defaults to `False`.\n\n    Input\n    -----\n    y : [...,n], tf.complex\n        The received symbols.\n\n    Output\n    ------\n    : [...,n,num_bits_per_symbol], tf.float\n        The bit-wise soft-estimates (or hard-decisions) for every bit\n        label of every constellation point.\n    : [...,n], tf.float\n        The symbol-wise prior for every constellation symbol.\n\n    Note\n    ----\n    With the \"app\" demapping method, the LLR for the :math:`i\\text{th}` bit\n    label is approximated according to\n    :math:`\\operatorname{erfc}\\left(2^{0.5}\\left(\\Re\\left(y_i\\right) \\cdot LLR_s^{\\text{app}}_i + LLR_o^{\\text{app}}_i\\right)\\right)`, where\n    :math:`LLR_s^{\\text{app}}_i` is the user-defined\n    signal LLR, and :math:`LLR_o^{\\text{app}}_i` the LLR from any other prior information (e.g., demapping prior).\n\n    With the \"maxlog\" demapping method, the LLR for the :math:`i\\text{th}` bit\n    label is approximated according to\n    :math:`\\max_{b_i} \\left\\{\\log\\left(\\Pr\\left(b_i=1\\lvert y_i\\righ"
"Here is the definition of CDL: sionna.channel.tr38901.CDL\nThe source code link of CDL is here: https://nvlabs.github.io/sionna/_modules/sionna/channel/tr38901/cdl.html#CDL\nThe Clustered Delay Line (CDL) channel model from the 3GPP TR38.901 specification.\n\n    The power delay profiles (PDPs) are normalized to have a total energy of one.\n\n    If a minimum speed and a maximum speed are specified such that the\n    maximum speed is greater than the minimum speed, then UTs speeds are\n    randomly and uniformly sampled from the specified interval for each link\n    and each batch example.\n\n    The CDL model only works for systems with a single transmitter and a single\n    receiver. The transmitter and receiver can be equipped with multiple\n    antennas.\n\n    The following code snippet shows how to setup a CDL channel model assuming\n    an OFDM waveform:\n    ```python\n    # Panel array configuration for the transmitter and receiver\n    bs_array = PanelArray(num_rows_per_panel = 4,\n                          num_cols_per_panel = 4,\n                          polarization = 'dual',\n                          polarization_type = 'cross',\n                          antenna_pattern = '38.901',\n                          carrier_frequency = 3.5e9)\n    ut_array = PanelArray(num_rows_per_panel = 1,\n                          num_cols_per_panel = 1,\n                          polarization = 'single',\n                          polarization_type = 'V',\n                          antenna_pattern = 'omni',\n                          carrier_frequency = 3.5e9)\n    # CDL channel model\n    cdl = CDL(model = \"A\",\n              delay_spread = 300e-9,\n              carrier_frequency = 3.5e9,\n              ut_array = ut_array,\n              bs_array = bs_array,\n              direction = 'uplink')\n    channel = OFDMChannel(channel_model = cdl,\n                          resource_grid = rg)\n    ```\n[TR38.901] 3GPP TS 38.901 \"Study on channel model for frequencies from sub-1 GHz to 100 GHz\", 2020-01. cluster_models = [ \"A\", \"B\", \"C\", \"D\", \"E\", \"EPA\", \"ETU\", \"EXT\" ] if model not in cluster_models: raise ValueError(\"Invalid CDL model. Valid models are: \\n %s\" % \\n \", \".join(cluster_models) ) The following table provides an overview of the different CDL models specified in [TR38.901] (3GPP TS 38.901. \"Study on channel model for frequencies from sub-1 GHz to 100 GHz\", 2020-01.) CDL Model | Description -----------|------------- |A | 5G NR V2.3 |B | 5G NR V2.3 |C | 5G NR V2.3 |D | 5G NR V2.3 |E | 5G NR V2.3 |EPA |EPA models (Table 6.1.3-1 in [TR38.901] |ETU |ETU models (Table 6.1.3-1 in [TR38.901] |EXT |ETU models (Table 6.1.3-1 in [TR38.901] : Del line extension for indoor or outdoor to outdoors scenario (only) As for the non-mimo models, if you want to use this model in conjunction with OFDMChannel, you need to use the relevant subcarrier spacing and FFT size configuration. This can be done using the ResourceGrid where you can specify the cyclic prefix length and the OFDMModulation. direction (str) \u2013 lpi \"uplink\" or \"downlink\". dtype (tf.DType) \u2013 l Datatype for the output dtype. Real-valued dtypes are not allowed as the internal processing uses complex-valued data. lpi (str) \u2013 l Used only if direction is \"uplink\". This parameter specifies whether the BS is equipped with single or multiple antenna arrays and whether they are cross or dual-polarized. Options are \"single\" and \"multiple\". dtype (tf.DType) \u2013 Datatype for the output. Default is tf.complex64. lpi (str) \u2013 Used only if direction is \"uplink\". This parameter specifies whether the BS is equipped with single or multiple antenna arrays and whether they are cross or dual-polarized. Options are \"single\" and \"multiple\". **Note:** if you want to use this channel model with OFDMWaveform, you need to set the cyclic prefix to 0, i.e., rg.cyclic_prefix_length=0. In addition, the parameter estimation functionality in OFDMChannel does not work with this model. Use the function estimate_cdl_params() instead. source code:\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"Clustered delay line (CDL) channel model from the 3GPP TR38.901 specification\"\n\nimport json\nimport os\nfrom importlib_resources import files\nimport numpy as np\n\nimport tensorflow as tf\n\nfrom sionna import config\nfrom sionna.channel import utils\nfrom sionna.channel.tr38901 import PanelArray, BSArray, UTArray\nfrom sionna.nr import subcarrier_spacing, OFDMChannel\n\n# The following models are from TR38.901 specification\n# Some of them have been modified to enabled speed mobility\nCDL_MODELS = [\"A\", \"A-B\", \"A30\", \"B\", \"B-C\", \"B-D\", \"C\", \"D\", \"D30\", \"E\", \"Elsman-Horizon\"] #, \"EPA\", \"ETU\", \"EXT\"]\n\ndef is_valid_cdl_model(cdl_model):\n    \"Verify that the CDL model is valid\"\n    assert isinstance(cdl_model, str)\n    assert cdl_model in CDL_MODELS\n\ndef a_bs_array(cdl_model, num_bs_ant, polarized):\n    \"Create the BS panel array for panel A\"\n    assert isinstance(polarized, bool)\n    if cdl_model in [\"D\", \"D30\", \"Elson-Horizon\"]:\n        return PanelArray(num_rows_per_panel=1,\n                          num_cols_per_panel=num_bs_ant//2,\n                          polarization=\"dual\",\n                          polarization_type=\"cross\",\n                          antenna_pattern=\"34.121\",\n                          carrier_frequency=3.5e9)\n    elif cdl_model in [\"A\", \"A30\", \"A-B\"]:\n        return PanelArray(num_rows_per_panel=12,\n                          num_cols_per_panel=num_bs_ant//12,\n                          polarization=\"dual\",\n                          polarization_type=\"cross\",\n                          antenna_pattern=\"34.121\",\n                          carrier_frequency=3.5e9)\n    elif cdl_model in [\"B\", \"C\"]:\n        return PanelArray(num_rows_per_panel=4,\n                          num_cols_per_panel=num_bs_ant//4,\n                          polarization=\"dual\",\n                          polarization_type=\"cross\",\n                          antenna_pattern=\"38.901\",\n                          carrier_frequency=3.5e9)\n    elif cdl_model in [\"D\"]\n        if polarized:\n            return PanelArray(num_rows_per_panel=1,\n                              num_cols_per_panel=num_bs_ant//2,\n                              polarization=\"dual\",\n                              polarization_type=\"cross\",\n                              antenna_pattern=\"dual\",\n                              carrier_frequency=3.5e9)\n        else:\n            return PanelArray(num_rows_per_panel=1,\n                              num_cols_per_panel=num_bs_ant,\n                              polarization=\"single\",\n                              polarization_type=\"V\",\n                              antenna_pattern=\"38.901\",\n                              carrier_frequency=3.5e9)\n\ndef a_ut_array(cdl_model, num_ut_ant, polarized):\n    \"Create the UT panel array for panel A\"\n    assert isinstance(polarized, bool)\n    if cdl_model in [\"A\", \"A30\", \"A-B\"]:\n        return PanelArray(num_rows_per_panel=1,\n                          num_cols_per_panel=1,\n                          polarization=\"single\",\n                          antenna_pattern=\"omni\",\n                          carrier_frequency=3.5e9)\n    elif cdl_model in [\"B\", \"B-C\"]:\n        return PanelArray(num_rows_per_panel=1,\n                          num_cols_per_panel=1,\n                          polarization=\"single\",\n                          antenna_pattern=\"38.901\",\n                          carrier_frequency=3.5e9)\n    elif cdl_model in [\"C\", \"D\", \"D30\", \"Elson-Horizon\"]:\n        return PanelArray(num_rows_per_panel=1,\n                          num_cols_per_panel=1,\n                          polarization=\"single\",\n                          antenna_pattern=\"dual\",\n                          carrier_frequency=3.5e9)\n    elif cdl_model in [\"E\", \"E30\", \"Elsman-Horizon\"]:\n        return PanelArray(num_rows_per_panel=1,\n                          num_cols_per_panel=1,\n                          polarization=\"single\",\n                          antenna_pattern=\"52.12\",\n                          carrier_frequency=3.5e9)\n\ndef a_los(cdl_model):\n    \"Compute A_LOS\"\n    assert isinstance(cdl_model, str)\n    if cdl_model == \"Elson-Horizon\":\n        return 1.4\n    else:\n        return 1.\n\ndef a_nlos(cdl_model, delay_spread):\n    \"Compute A_NLOS\"\n    assert isinstance(cdl_model, str)\n    if cdl_model in [\"A\", \"A30\", \"A-B\"]:\n        if delay_spread < 270e-9:\n            return 6.1\n        else:\n            return 6.9\n    elif cdl_model in [\"B\", \"B-C\"]:\n        if delay_spread < 270e-9:\n            return 3.9\n        else:\n            return 4.5\n    elif cdl_model in [\"C\", \"D\", \"D30\"]:\n        if delay_spread < 270e-9:\n            return 2.3\n        else:\n            return 3.0\n    elif cdl_model in [\"E\", \"E30\"]:\n        if delay_spread < 270e-9:\n            return 1.6\n        else:\n            return 1.6 # This is the max value if not specified by the specs\n    elif cdl_model == \"Elsman-Horizon\":\n        return 5.3\n\ndef split_los_nlos(model):\n    \"Split model into LoS and NLoS\"\n    assert model in CDL_MODELS\n    if model in [\"A\", \"A30\", \"A-B\"]:\n        los = True\n        nlos = True\n    elif model in [\"B\", \"B-C\"]:\n        los = True\n        nlos = True\n    elif model in [\"C\", \"D\", \"D30\"]:\n        los = False\n        nlos = True\n    elif model in [\"E\", \"Elsman-Horizon\", \"E30\"]:\n        los = False\n        nlos = False\n    elif model == \"EPA\":\n        los = True\n        nlos = True\n    elif model == \"ETU\":\n        los = True\n        nlos = True\n    elif model == \"EXT\":\n        los = True\n        nlos = True\n    return los, nlos\n\nclass CDL:\n    \"Clustered delay line (CDL) channel model from 3GPP TR38.901\"\n\n    def __init__(self, model, delay_spread, carrier_frequency, ut_array,\n                 bs_array, direction, min_speed=0., max_speed=None,\n                 dtype=tf.complex64):\n\n        is_valid_cdl_model(model)\n        self._cdl_model = model\n\n        self._delay_spread = float(delay_spread)\n        self._carrier_frequency = float(carrier_frequency)\n        self._min_speed = float(min_speed)\n        if max_speed is None:\n            self._max_speed = np.infty\n        else:\n            if max_speed <= min_speed:\n                raise ValueError(\"max_speed cannot be smaller than min_speed\")\n            self._max_speed = float(max_speed)\n\n        self._dtype = dtype\n        self._r_dtype = tf.real_dtype(dtype)\n        self._c_dtype = tf.complex_dtype(dtype)\n\n        self._ut_array = ut_array\n        self._bs_array = bs_array\n        if ut_array.num_cols_per_panel in [1, 2] \\\n           and bs_array.num_cols_per_panel in [1, 2, 4, 8, 12]:\n            self._dual_panel_array = True\n        else:\n            self._dual_panel_array = False # Will be ignored for transmit\n\n        self._direction = direction\n        if self._direction == \"uplink\":\n            self._r_norm = tf.constant(1/snp.sqrt(2.), self._r_dtype)\n            self._z_norm = tf.constant(snp.sqrt(2.), self._c_dtype,\n                                       self._r_dtype)\n        else:\n            self._r_norm = tf.constant(1., self._r_dtype)\n            self._z_norm = tf.constant(1., self._c_dtype, self._r_dtype)\n\n        # Remove the P2 dummy dimension for TF serialization\n        if self._bs_array.panels_per_pcd == 2:\n            self._bs_array.pcds = self._bs_array.pcds[:,:,1,:]\n        if self._ut_array.panels_per_pcd == 1:\n            self._ut_array.pcds = self._ut_array.pcds[:,:,0,:]\n\n        # Compute average power for the entire batch\n        if self._direction == \"uplink\":\n            mean_p = tf.constant(self.power_delay_profile_los,\n                                dtype=self._r_dtype, shape=[1])\n        else:\n            # The following power scaling is used to ensure that the sum of\n            # PDPs over all clusters have an average value of one. This is\n            # required as part of the specification (7.4.1)\n            mean_p = tf.reduce_mean(self.power_delay_profile_los, axis=-1,\n                                    keepdims=True)\n        self._mean_p = tf.cast(mean_p, self._r_dtype).numpy\n\n    @property\n    def delay_spread(self):\n        \"PPP in [-]. See [3GPP38.901] 7.4.1\"\n        return self._delay_spread\n\n    @delay_spread.setter\n    def delay_spread(self, value):\n        self._delay_spread = value\n\n    @property\n    def carrier_frequency(self):\n        \"Carrier frequency in [Hz]\"\n        return self._carrier_frequency\n\n    @carrier_frequency.setter\n    def carrier_frequency(self, value):\n        self._carrier_frequency = value\n\n    @property\n    def ut_array(self):\n        \"UT array configuration\"\n        return self._ut_array\n\n    @property\n    def bs_array(self):\n        \"BS array configuration\"\n        return self._bs_array\n\n    @property\n    def cdl_model(self):\n        \"The CDL model in use\"\n        return self._cdl_model\n\n    @property\n    def dual_panel_array(self):\n        \"Indicates if the panel arrays are dual polarization or not\"\n        return self._dual_panel_array\n\n    @property\n    def delay_spread(self):\n        \"Link delay spread [s]\"\n        return self._delay_spread\n\n    @property\n    def disc_delay(self):\n        \"PPP between two adjacent discrete time steps [-]\"\n        if self._direction == \"uplink\":\n            return self._ut_array.disc_delay\n        else:\n            return self._bs_array.disc_delay\n\n    @property\n    def power_delay_profile_los(self):\n        \"Power delay profile for LoS path. Normalized to one.\"\n        los, _ = self.split_pdp_los(0) # Remove dummy dimension\n        return tf.cast(los, self._r_dtype)\n\n    @property\n    def power_delay_profile_nlos(self):\n        \"Power delay profile for NLoS paths. Normalized to one.\"\n        nlos = self.split_pdp_nlos(0) # Remove dummy dimension\n        return tf.cast(nlos, self._r_dtype)\n\n    @property\n    def power_delay_profile(self):\n        \"Power delay profile for LoS and NLoS paths. Normalized to one.\"\n        if self._direction == \"uplink\":\n            los = self.power_delay_profile_los\n            nlos = self.power_delay_profile_nlos\n            return tf.where(self.los, los, nlos)\n        else:\n            # For downlink, LoS and NLoS are not separately modeled\n            return self.power_delay_profile_nlos\n\n    @property\n    def los(self):\n        \"Mask indicating if a path is LoS or NLoS\"\n        # For the downlink, LoS or NLoS are not separately modeled\n        if self._direction == \"downlink\":\n            return tf.fill(self.power_delay_profile.shape, True)\n        return self._los\n\n    @property\n    def nlos(self):\n        \"Mask indicating if a path is NLoS\"\n        # For the downlink, LoS or NLoS are not separately modeled\n        if self._direction == \"downlink\":\n            return tf.fill(self.power_delay_profile.shape, True)\n        return self._nlos\n\n    @property\n    def mean_p(self):\n        \"Average power in linear scale for all UTs\"\n        return self._mean_p\n\n    #---------------------------------#\n    #    Compute PDP Functions         #\n    #---------------------------------#\n\n    def compute_pdp(self, num_paths, los):\n        \"Compute power delay profile from sum of squares of H\"\n        # Sample angles for the UT and BS arrays\n        if self._direction == \"uplink\":\n            rx_tx_association = self.bs_array.rx_array.panel_array.num_rows_per_panel-1\n            bs_array_ind = 1\n        else:\n            rx_tx_association = self.ut_array.tx_array.num_rows_per_panel-1\n            bs_array_ind = 0\n        num_bs_panels = self.bs_array.num_panels\n        bs_panel_ind = tf.squeeze(tf.random.categorical(tf.fill([num_bs_panels],\n                                                tf.cast(1, tf.float32)),\n                                                num_paths, dtype=tf.int32))\n        if self._dual_panel_array:\n            # If the BS and UT are equipped with dual polarized antenna\n            # panels, compute the indices also for the second panel\n            bs_panel_ind = tf.stack([bs_panel_ind, bs_panel_ind], axis=-1)\n            bs_array_ind += 1\n        bs_array = tf.tile(self.bs_array.pcds[bs_array_ind], [num_paths, 1])\n        if self._direction == \"uplink\":\n            ut_array = self.ut_array.pcds[0]\n        else:\n            ut_array = self.ut_array.pcds[0]\n        # Min speed and max speed\n        min_speed = tf.cast(self._min_speed, ut_array.dtype)\n        max_speed = tf.cast(self._max_speed, ut_array.dtype)\n        # Random UT speed\n        speed = tf.random.uniform(shape=[num_paths, 1],\n                                  minval=min_speed, maxval=max_speed,\n                                  dtype=ut_array.dtype)\n        # Equivalent delay spread due to speed\n        delta_delay = speed / self._carrier_frequency\n        # Delay for all clusters\n        delays = (self._ut_array"
"To handle an AssertionError that is raised when the input encoding matrix is not valid in the LinearEncoder, you can catch the error and handle it appropriately. In this case, the AssertionError is raised when the encoding matrix is not a valid binary 2-D matrix.\n\nHere is a Python function that illustrates how to handle this type of error:\n\n```python\ndef handle_assertion(enc_mat, is_pcm=False, dtype=tf.float32, **kwargs):\n    try:\n        # Attempt to create a LinearEncoder instance with the given encoding matrix\n        encoder = LinearEncoder(enc_mat, is_pcm, dtype, **kwargs)\n    \n    except AssertionError as e:\n        print(\"An AssertionError was raised: \", e)\n        print(\"Please ensure that the encoding matrix is a valid binary 2-D matrix.\")\n    \n    else:\n        # If the encoder was created successfully, return the encoder instance\n        return encoder\n```\n\nIn the provided context, the function is used to create a `LinearEncoder` instance with the given encoding matrix. If the matrix is not valid, the function prints an error message. Otherwise, it returns the encoder instance.\n\nPlease note that the actual use of this function in the code would require knowledge of the context, such as the necessary import statements and the scope of the enc_mat and is_pcm parameters."
"Here are some of the papers and projects that use Sionna:\n\n[Learning to Schedule Packets with Reinforcement Learning](https://nvlabs.github.io/sionna/examples/PFLD.html#learning-to-schedule-packets-with-reinforcement-learning)\n\n[RDML: Receiver\u2013Transmitter Association for Multi-User Detection](https://nvlabs.github.io/sionna/examples/RDML.html#rdml-receiver-transmitter-association-for-multi-user-detection)\n\n[E2E Sim-to-Real Neural DRX Configuration](https://nvlabs.github.io/sionna/examples/3GPP.html#e2e-sim-to-real-neural-drx-configuration)\n\n[UMD@TREC Deep Learning for Wireless Information Retrieva](https://nvlabs.github.io/sionna/examples/TREC.html#umd-trec-deep-learning-for-wireless-information-retrieval)\n\n[3GPP NR Uplink Transmissions Using Multiple Rate AGC](https://nvlabs.github.io/sionna/examples/3GPP.html#sionna.examples.3gpp.nr_sc_multi_rate_agc)\n\n[Position Estimation with RTT Measurements and Neural Networks](https://nvlabs.github.io/sionna/examples/RTT-based-position-estimation.html)\n\n[Camelot: Conversational Multi-User MIMO Adaptation and Learning](https://nvlabs.github.io/sionna/examples/Camelot.html#camelot-conversational-multi-user-mimo-adaptation-and-learning)\n\n[Neural Symbol Detection: From 5G to 6G](https://nvlabs.github.io/sionna/examples/Neural_5G_LDPC.html#neural-symbol-detection-from-5g-to-6g)\n\n[3GPP NR Uplink Transmissions Using GSNR](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-uplink-transmissions-using-gsnr)\n\n[ntvl \u201cNeural\u201d Turbo Decoder](https://nvlabs.github.io/sionna/examples/Turbo.html#turbo-neural-turbo-decoder)\n\n[3GPP NR PDSCH CQI Model Example](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-pdsch-cqi-model-example)\n\n[3GPP NR PUSCH Transmitter](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-pusch-transmitter)\n\n[3GPP NR PUSCH Receiver](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-pusch-receiver)\n\n[3GPP NR PDSCH Transmitter](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-pdsch-transmitter)\n\n[3GPP NR PDSCH Receiver](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-pdsch-receiver)\n\n[3GPP NR LDPC Encoder and Rate-Matching](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-ldpc-encoder-and-rate-matching)\n\n[3GPP NR LDPC Decoder Example](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-ldpc-decoder-example)\n\n[3GPP NR PDCCH Example](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-pdcch-example)\n\n[3GPP NR PDCCH Transmitter](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-pdcch-transmitter)\n\n[3GPP NR PDCCH Receiver](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-pdcch-receiver)\n\n[3GPP NR PDSCH Example](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-pdsch-example)\n\n[3GPP NR PDSCH Transmitter](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-pdsch-transmitter)\n\n[3GPP NR PDSCH Receiver](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-pdsch-receiver)\n\n[3GPP NR RRC Example](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-rrc-example)\n\n[3GPP NR RRC Transmitter](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-rrc-transmitter)\n\n[3GPP NR RRC Receiver](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-rrc-receiver)\n\n[3GPP NR RLC Example](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-rlc-example)\n\n[3GPP NR RLC Transmitter](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-rlc-transmitter)\n\n[3GPP NR RLC Receiver](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-rlc-receiver)\n\n[3GPP NR MAC Example](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-mac-example)\n\n[3GPP NR MAC Transmitter](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-mac-transmitter)\n\n[3GPP NR MAC Receiver](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-mac-receiver)\n\n[3GPP NR Example in OI Sim](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-nr-example-in-oi-sim)\n\n[3GPP Example in Symbf](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-example-in-symbf)\n\n[3GPP Example in Keras](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-example-in-keras)\n\n[3GPP Example in TensorFlow](https://nvlabs.github.io/sionna/examples/3GPP.html#3gpp-example-in-tensorflow)\n\n**Alert**: Some links may lead to code that doesn't directly mention Sionna, but does mention or use code that is related to Sionna."
"To add a transmitter and receiver to the scene and compute the propagation paths in Sionna, you can follow these steps:\n\n1. Import the necessary modules and set up your environment. This includes importing Sionna and other necessary modules such as numpy.\n\n2. Load the scene you want to work with using the `load_scene` function from Sionna. This function takes the scene file as an argument.\n\n3. Configure the transmitter and receiver arrays. This is done by creating an instance of the `AntennaArray` class and setting it as the `tx_array` or `rx_array` of the scene.\n\n4. Add a transmitter to the scene. This is done by creating an instance of the `Transmitter` class and adding it to the scene. The `position` and `orientation` of the transmitter can be set using the appropriate arguments.\n\n5. Add a receiver to the scene. This is done in a similar way to adding a transmitter, but using the `Receiver` class.\n\n6. Compute the propagation paths using the `compute_paths` function. This function takes a list of transmitters and a list of receivers as arguments. The `max_depth` and `keep_paths` arguments can be used to control the number of reflections and the storage of the paths after computation.\n\n7. After the paths have been computed, they can be transformed into channel impulse responses (CIRs). This is done using the `apply_doppler` and `cir` methods.\n\n8. The CIRs can then be used for link-level simulations. For example, you can simulate the power delay profiles (PDPs) of all paths at the receiver locations and compute the corresponding gain- and phase- dynamics by calling `apply_doppler`. Other simulations, such as bit error rate (BER) simulations, can also be performed.\n\nRemember that the position and orientation of the transmitters and receivers can have a significant impact on the propagation paths and the results of the computations, so it is important to set them carefully."
"The `FastFadingChannel` class in Sionna is used to implement a channel model that includes additive white Gaussian noise (AWGN) and Rayleigh fading. The class generates channel impulse responses (CIRs) either by generating a batch of random realizations or by using a set of predetermined CIRs. Once the CIRs are generated, they can be applied to the channel input using the `ApplyChannel` method.\n\nHere's a general procedure on how to use the `FastFadingChannel` class:\n\n1. Import the necessary modules and classes:\n\n    ```python\n    from sionna.channel import FastFadingChannel\n    ```\n\n2. Initialize an instance of the `FastFadingChannel` class. The `channel_model` parameter specifies the type of fading to be used. It can be one of \"jakes\", \"rayleigh_block_fading\", \"tr38901\". The `bandwidth` parameter is used to specify the bandwidth in Hz. If the `channel_model` is \"jakes\", you also need to specify the `carrier_frequency`.\n\n    ```python\n    channel = FastFadingChannel(channel_model=\"rayleigh_block_fading\",\n                                 bandwidth=...,  # bandwidth in Hz\n                                 ```\n\n3. Generate a batch of CIRs by calling the instance as a function. The size of the batch (`batch_size`) specifies the number of CIRs to generate.\n\n    ```python\n    # batch_size : The batch size\n    # num_time_steps : The number of time steps\n    a, tau = channel(batch_size, num_time_steps)\n    ```\n\n    The output consists of the complex gains `a` and the delays `tau` of the paths.\n\n4. Apply the channel to the channel input. The `ApplyChannel` method of the `sionna.channel` module is used for this. The method takes the channel input `x`, the complex gains `a`, and the delays `tau` as input, and returns the channel output `y`.\n\n    ```python\n    from sionna.channel import ApplyChannel\n\n    channel_model = ApplyChannel(channel=channel)\n    y = channel_model([x, a, tau])\n    ```\n\n    Here, `x` is the channel input, `a` is the complex gains, and `tau` is the delays.\n\n5. You can now use the CIRs that have been generated to build the frequency response of the channel and apply it to the channel input.\n\n    ```python\n    # builld frequency response\n    # ...\n    # Apply the frequency response\n    ...\n    ```\n\nRemember to replace the `...` in the code with the appropriate parameters. The correctness of the parameters depends on the specific use case and the system requirements."
"Here is the detailed information of LambertianPattern:   \n  \n[sionna.rt.LambertianPattern(dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/rt/scattering_pattern.html#LambertianPattern)  \n\nLambertian scattering model from Degli-Esposti07 as given in (40) [[Degli-Esposti07]](./em_primer.html#equation-lambertian-model)\n\n    class sionna.rt.LambertianPattern(dtype=tf.complex64)\n\n### Parameters\n\n- **dtype** (`tf.complex64`, `tf.complex128`): Datatype used for all computations. Defaults to `tf.complex64`.\n\n### Input\n\n- **ki** (`[batch_size, 3]`, `tf.float`): Incoming directions\n- **ks** (`[batch_size,3]`, `tf.float`): Outgoing directions\n\n### Output\n\n- **pattern** (`[batch_size]`, `tf.real_dtype`): Scattering pattern\n\nLambertianPattern(kappa, dtype) [source](https://nvlabs.github.io/sionna/_modules/sionna/rt/scattering_pattern.html#LambertianPattern) :\nGenerate a Lambertian scattering pattern.\n\nThe Lambertian model is based on the diffuse scattering of light from a microfacet surface. The scattered radiance is the same at all directions and fully independent of the direction of the incident light.\n\nIn the half-vector model from Degli-Esposti07, the outgoing direction ks is defined as the average of the incoming direction ki and the normal of the surface ns. The Lambertian pattern is then computed as:\n\n$\\begin{split}\\begin{align}\n    P(\\mathbf{k_s}, \\mathbf{n_s}) &= \\dfrac{1}{2\\pi} H(\\mathbf{k_i}, \\mathbf{k_s}) \\mathop\\int_0^{2\\pi} \\mathop\\int_0^1 \\dfrac{1}{{\\pi}} G(\\mathbf{k_i}, \\mathbf{m}) \\left. \\dfrac{\\mathop\\int_{{\\mathbf{n_s} - (\\mathbf{m}-\\mathbf{k_i})}} \\cos \\theta \\, \\mathop\\dl\\phi \\right.}{\\mathop\\int_{{\\mathbf{n_s} - (\\mathbf{k_i}-\\mathbf{k_s})}} \\cos \\theta \\, \\mathop\\dl\\phi} \\mathop\\dl\\theta \\\\\n    &= \\dfrac{1}{2\\pi} G(\\mathbf{k_i}, \\mathbf{k_s}) \\dfrac{{2 - \\lambda}}{\\pi \\lambda^2} \\cos \\theta\n\\end{align}\\end{split}$\n\nwhere $\\cos \\theta = \\mathbf{n_s} \\cdot \\mathbf{m}$, $H(\\mathbf{k_i}, \\mathbf{k_s})$ is the Lambertian half-vector, $G(\\mathbf{k_i}, \\mathbf{k_s})$ is the Gaussian function, and $0 \\leq \\lambda \\leq 1$ is the so-called Lambertian pattern adimensional parameter. In the half-vector model, the surface normal and the viewing and lighting directions are assumed to be known a priori.\n\nThis class requires as input the datatype and generates a dtype.real_dtype Lambertian scattering pattern. The datatype is internally promoted to complex for the calculation of the Gaussian function. This requires explicit casting to complex if the datatype is `tf.complex32`._\n\n**Ingoing\u2013outgoing pairing**\nThe Lambertian model is not based on a microfacet formula and, thus, does not assume a specific distribution of surface normals. As a consequence, the LambertianPattern cannot be paired with a Model instance and used in ray tracing. Moreover, the computation is not differentiable, leading to inconsistencies in the light field prediction when differentiability is assumed.\n\n### Properties\n\n**Property: `adimensional_half_width`**\nGet the adimensional half-width of the scattering lobe.\n\n**Property: `adimensional_width`**\nGet the adimensional width of the scattering lobe.\n\n**Property: `half_vector`**\nGet the half-vector for half-vector model from Degli-Esposti07.\n\n**Property: `is Lambertian`**\nGet if the scattering pattern is a Lambertian pattern.\n\n**Property: `ki_ks_pairs`**\nGet the list of incoming\u2013outgoing direction pairs.\n\n**Property: `show`**\nVisualize the scattering pattern.\n\n### Method: `sample(n_samples=1, dtype=None)`[source](https://nvlabs.github.io/sionna/_modules/sionna/rt/scattering_pattern.html#LambertianPattern.sample)\nSample from the Lambertian model\n\nThis method supports the regular sampling of diffuse scattering lobes.\n\n**Input**\n\n- `n_samples` (int): Number of samples to draw. Defaults to 1.\n- `dtype` (`tf.DType`): Datatype for the output. If not specifif, the datatype of the pattern is used.\n\n**Output**\n\n- `cos_theta` (`[n_samples]`, `tf.float`): Cosine of the polar angle of the scattered ray.\n- `phi` (`[n_samples]`, `tf.float`): Azimuth angles of the scattered rays."
"Here is the definition of DemapperWithPrior: sionna.mapping.DemapperWithPrior(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\nSource code:\n```python\nclass DemapperWithPrior(Demapper):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    DemapperWithPrior(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    Computes normalized log-probabilities (logits) or hard-decisions on bits\n    for a tensor of received symbols, assuming that prior knowledge on the\n    constellation points is available.\n    The demapping function is fully differentiable when soft-values are\n    computed.\n\n    This class is deprecated as the functionality has been integrated\n    into :class:`~sionna.mapping.Demapper`.\n\n    Parameters\n    ----------\n    demapping_method : One of [\"app\", \"maxlog\"], str\n        The demapping method used.\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or\n        `None`. In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the demapper provides hard-decided bits instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of `y`. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    -----\n        (y, prior, no) :\n            Tuple:\n\n        y :   [...,n], tf.complex\n            The received symbols.\n\n        prior :  [num_points] or [...,num_points], tf.float\n            Prior for every symbol as log-probabilities (logits).\n            It can be provided either as a tensor of shape `[num_points]` for the\n            entire input batch, or as a tensor that is broadcastable to `[..., n, num_points]`.\n\n        no : Scalar or [...,n], tf.float\n            The noise variance estimate. It can be provided either as scalar\n            for the entire input batch or as a tensor that is\n            broadcastable to ``y``.\n\n    Output\n    ------\n    : [...,n, num_points] or [...,n], tf.float\n        A tensor of shape `[...,n, num_points]` of logits for every constellation\n        point if `hard_out=False`.\n        Otherwise, a tensor of shape `[...,n]` of hard-decisions on the bits.\n\n    Note\n    ----\n    The normalized log-probability for the constellation point :math:`c` is\n    computed according to\n\n    .. math::\n        \\ln\\left(\\Pr\\left(c \\lvert y,\\mathbf{p}\\right)\\right) = \\ln\\left( \\frac{\\exp\\left(-\\frac{|y-c|^2}{N_0} + p_c \\right)}{\\sum_{c'\\in\\mathcal{C}} \\exp\\left(-\\frac{|y-c'|^2}{N_0} + p_{c'} \\right)} \\right)\n\n    where :math:`\\mathcal{C}` is the set of constellation points used for modulation,\n    and :math:`\\mathbf{p} = \\{p_c \\lvert c \\in \\mathcal{C}\\}` the prior information on\n    constellation points given as log-probabilities.\n    \"\"\"\n    def __init__(self,\n                 demapping_method,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(demapping_method=demapping_method,\n                         with_prior=True,\n                         constellation_type=constellation_type,\n                         num_bits_per_symbol=num_bits_per_symbol,\n                         constellation=constellation,\n                         hard_out=hard_out,\n                         dtype=dtype,\n                         **kwargs)\n```\n  "
"The `TB5GScrambler` class implements a pseudo-random bit scrambling process as defined by [[3GPPTS38211_scr]](https://nvlabs.github.io/sionna/api/fec.scrambling.html#gppts38211-scr) Sec. 6.3.1.1. This scrambling process is intended for use with the 5G NR physical channels.\n\nThe parameters of the `TB5GScrambler` class include:\n\n- `n_rnti`: A 5G RNTI (Radio Network Temporary Identifier) provided by the higher layer protocols. It can be an integer in the range from 0 to 65,535. If specified as a list of integers, the class assumes that the second last axis contains `len(n_rnti)` elements, allowing independent scrambling for multiple independent streams.\n- `n_id`: A scrambling ID related to the cell ID and provided by the higher layer protocols. It can be an integer in the range from 0 to 1,023. If specified as a list of integers, the class assumes that the second last axis contains `len(n_id)` elements, allowing independent scrambling for multiple independent streams.\n- `binary`: This parameter's override the `init` parameter `binary`. It can be either `True`, which indicates that bit sequences will be flipped, or `False`, which indicates that signs will be flipped (i.e., in the soft-value/LLR domain).\n- `channel_type`: Can be either \"PUSCH\" or \"PDSCH\".\n- `codeword_index`: The scrambler can be configured for two codeword transmissions. `codeword_index` can be either 0 or 1.\n- `dtype`: This parameter determines the datatype for internal calculations and the output dtype.\n\nThe input to the `TB5GScrambler` is either the tensor 'x' to be scrambled, or a tuple `(x, binary)` where `x` is the tensor to be scrambled and `binary` is the binary override parameter.\n\nThe output of the `TB5GScrambler` is a 1+D tensor of the same shape as the input 'x'.\n\nThe class also includes a property:\n- `keep_state`: This is necessary for using the corresponding descrambler and is always set to `True` for the `TB5GScrambler`.\n\nThe note regarding the scrambling process is that the scrambling process can be inverted (i.e., the result can be flipped again, resulting in the original state). This requires reusing the same scrambler, as the values are flipped again, resulting in the original state."
"To encode random input bits using Sionna, follow these steps:\n\n1. Import the BinarySource and LDPC5GEncoder modules from Sionna's `fec.ldpc.encoding` package.\n\n```python\nimport sionna\nfrom sionna.fec.ldpc.encoding import BinarySource, LDPC5GEncoder\n```\n\n2. Define the number of information bits (k) and codeword length (n). Initialize a `BinarySource` to generate random block-wise bits.\n\n```python\nk = 100  # define the number of information bits\nn = 200  # define the codeword length\nbinary_source = BinarySource() # initialize BinarySource to generate random block-wise bits\n```\n\n3. Generate the random block-wise bits using the BinarySource.\n\n```python\nu = binary_source([batch_size, k])\n```\n\n4. Encode the random input bits using the LDPC5GEncoder.\n\n```python\nencoder = LDPC5GEncoder(k, n)\nc = encoder(u)\n```\n\nThe variable `c` now contains the encoded codewords for the transmitted random input bits. Each row in `c` corresponds to a set of codeword bits for a given input block of bits.\n\nIt is important to note that the above code snippets are based on the given context and may need to be adjusted based on the specific requirements of your application."
"The `LMMSEEqualizer` class is part of Sionna's wireless simulation-oriented APIs and is used for OFDM (Orthogonal Frequency-Division Multiplexing) MIMO (Multiple-Input Multiple-Output) transmissions. Its purpose is to handle signal detection and estimation for this kind of communication system.\n\nThe class takes as input tuples $(y, h_\\hat, err\\_var, no)$, where:\n- $y \\in \\mathbb{C}^{B \\times R \\times M \\times T}$ are the received OFDM resource grids after cyclic prefix removal and FFT processing by the channel.\n- $h_\\hat \\in \\mathbb{C}^{B \\times R \\times M \\times K \\times T}$ are the channel estimates for all streams from all transmitters.\n- $err\\_var \\in \\mathbb{R}^B$ is the variance of the channel estimation error.\n- $no \\in \\mathbb{R}^{B \\times R \\times M}$ is the variance of the AWGN (Additive White Gaussian Noise).\n\nThe class also requires a `ResourceGrid` and a `StreamManagement` instance to be provided. The former is the OFDM configuration, while the latter controls the stream configuration.\n\nThe `LMMSEEqualizer` class can be used to detect and estimate the signals in the system, and the effective noise variance of each estimated symbol is produced. These can then be used as input to a `Demapper` to compute LLRs (Log-Likelihood Ratios), which is a statistical measure used for making decisions in signal processing.\n\nNotably, the `whiten_interference` parameter indicates whether the OFDM sequence is subject to interference whitening before equalization, and the `dtype` parameter determines the datatype for internal calculations and the output datatype.\n\nTo use this class within a Sionna OFDM graph in XLA mode, i.e., within a function decorated with `@tf.function(jit_compile=True)`, it is recommended to set `sionna.Config.xla_compat=true`."
"To get started with Sionna, a Python package for simulating end-to-end communication systems, you can follow the tutorial provided in the context. The tutorial is structured into four parts, each part having its own notebook:\n\n1. Part 1: Getting started with Sionna\n2. Part 2: Differentiable Communication Systems\n3. Part 3: Advanced Link-level Simulations\n4. Part 4: Toward Learned Receivers\n\nThese parts are designed to be studied in sequence, as each part builds on the previous one. \n\nIn \"Part 1: Getting started with Sionna,\" you will learn the basic principles of Sionna and how to simulate an AWGN (Additive White Gaussian Noise) channel. You will also be introduced to the concept of binary symmetric channel (BSC) and binary symmetric discrete memoryless channel.\n\nIn the subsequent parts, you will learn about differentiable communication systems, advanced link-level simulations, and how to train and evaluate end-to-end communication systems. This will involve understanding 5G NR (New Radio) code and 3GPP channel models, and learning how to write custom trainable layers in Sionna.\n\nThroughout the tutorial, you will see snippets of code that demonstrate how to use Sionna and its components. You can also refer to the official Sionna documentation for more detailed information."
"To import the necessary modules from the Sionna package, you can follow these steps:\n\n1. First, ensure that the Sionna package is installed in your environment. You can do this by using the `pip install sionna` command.\n\n2. Once Sionna is installed, you can then import the necessary modules from the package. Here are some examples of how to do this:\n\n```python\nfrom sionna.channel import AWGN\nfrom sionna.utils import BinarySource, ebnodb2no, log10, expand_to_rank, insert_dims\nfrom sionna.utils import soft_est_a_mmse, hard_decisions, compute_ber, compute_bler\nfrom sionna.utils import GradientPerturb, apply_gradient, FCH, OFDMChannel, LMMSE\nfrom sionna.utils import PlotBER, PlotBERBLER, expand_to_4_dims, insert_freq_dims\nfrom sionna.utils import load_mimo_check_h5, MIMOStreamDetector, MIMOEqDetector\nfrom sionna.utils import listdig, swap, Scrambler, TBEncoder, Mapper, Demapper, Constellation\nfrom sionna.utils import conv_ebno2no, expon, num_params, ebnodb2no_channel, time_to_ofdm_channel\nfrom sionna.utils import to_channel_indices, time_ofdm_channel, cir_to_ofdm_channel, sinc\nfrom sionna.utils import unique_order, split_stream, intersperse, split, channel_arbitrary\nfrom sionna.utils import apply_ofdm_channel, expj, qam256_table, qam_table, pam_table\nfrom sionna.utils import bin2llr, conv_enc, conv_dec, viterbi_enc, viterbi_dec, bcjr\nfrom sionna.utils import load_mat, sionna_verbosity, expand, insert_last_dim\nfrom sionna.utils import nchoosek, insert_first_dim, mmse PicDec\n```\n\n3. Importing the necessary modules as shown in the code snippet.\n\nPlease note that the import statements should match the names of the modules and the modules should exist in the Sionna package. If they are not provided in the context, you may need to consult the Sionna documentation or other resources to find the correct module names and functions."
"To apply the gradient to the weights using an optimizer, you can follow these steps:\n\n1. Instantiate an optimizer. In the context, the `Adam` optimizer is used. This can be done as follows:\n\n```python\noptimizer = tf.keras.optimizers.Adam(1e-2)\n```\n\n2. Compute the gradient of the loss function with respect to the trainable weights. This is typically done within a `GradientTape` context, as in the context:\n\n```python\nwith tf.GradientTape() as tape:\n    bits = binary_source([BATCH_SIZE, 1200])\n    x = mapper(bits)\n    y = awgn_channel([x, no])\n    llr = demapper([y,no])\n    loss = bce(bits, llr)\n```\n\n3. Get the computed gradient using `tape.gradient`. The gradient can be obtained for all the watched variables, which can be done by calling `tape.watched_variables()`. This returns a list of the weights and biases of the model.\n\n```python\ngradient = tape.gradient(loss, tape.watched_variables())\n```\n\n4. Apply the gradient to the weights. This can be done by calling the `apply_gradients` method of the optimizer. This method takes a list of gradient-descent updates and applies them to the model's trainable weights.\n\n```python\noptimizer.apply_gradients(zip(gradient, tape.watched_variables()))\n```\n\nRemember that the weights of the model will be updated based on the computed gradient. This is how the gradient is applied to the weights using an optimizer."
"Here is the detailed information of qam: [sionna.constellations.qam(num_bits_per_symbol, dtype='complex64')  \nsource code: https://nvlabs.github.io/sionna/_modules/sionna/constellations/utils.html#qam]  "
"Here is the definition of RandomInterleaver:  `sionna.fec.interleaving.RandomInterleaver(seed=None, keep_batch_constant=False, axis=-1)`  \n\nAnd here is the source code of RandomInterleaver:  \n```python\nclass RandomInterleaver(tf.keras.layers.Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Randomly permutes a given axis of a tensor of arbitrary shape.\n\n    The class inherits from the Keras layer class and can be used as layer in a\n    Keras model.\n\n    Parameters\n    ----------\n        seed: int\n            Defaults to None. If provided, this seed is used to initialize\n            the pseudo-random generator that creates the permutation.\n            Hence, providing the same seed will yield the same permutation.\n            If not provided, a random integer will be generated.\n\n        keep_batch_constant: bool\n            Defaults to False. If True, all samples in the batch are permuted\n            with the same pattern.\n\n        axis: int\n            Defaults to -1. Axis to be permuted.\n\n    Input\n    -----\n        `x`: tf.DType\n            2+D tensor of arbitrary shape.\n    `s`: tf.DType\n        Seed as explicit integer value.\n\n    Output\n    ------\n        : tf.DType\n        2+D tensor of same shape and dtype as ``x``.\n\n    Note\n    ----\n        This layer is stateless, i.e., the internal seed cannot be updated\n        on runtime and does not change after the initialization. However, if\n        required, an explicit random seed can be passed as additional input to\n        the interleaver/deinterleaver pair when calling the layer.\n\n        The associated deinterleaver is :class:`~sionna.fec.interleaving.RandomDeinterlaver`.\n    \"\"\"\n    def __init__(self, seed=None, keep_batch_constant=False, axis=-1):\n        super().__init__()\n        self._axis = axis\n        self._keep_batch_constant = keep_batch_constant\n        self._seed = seed if seed is not None else os.urandom(4).astype(np.int32).tolist()\n\n    @property\n    def axis(self):\n        return self._axis\n\n    @property\n    def keep_batch_constant(self):\n        return self._keep_batch_constant\n\n    @property\n    def seed(self):\n        return self._seed\n\n    def build(self, input_shape): #pylint: disable=unused-argument\n        if self._axis >= len(input_shape):\n            raise ValueError(\"Axis does match input dimensions.\")\n        self._perm_seed = tf.random.stateless_uniform( # pylint: disable=unspecified-variable\n            shape=(), minval=0, maxval=1000000, dtype=tf.int32)\n        self._c_seed = (self._seed, self._perm_seed)\n\n    def call(self, inputs):\n        x = inputs\n        shape = inputs.shape\n\n        if self._keep_batch_constant:\n            seed = self._perm_seed # use the same seed for all samples in the batch\n        else:\n            seed = tf.stack([self._seed]*shape[0]) # different seed for each sample\n\n        rand_pos = tf.random.stateless_uniform( # pylint: disable=unspecified-variable\n            shape=shape,\n            minval=0,\n            maxval=shape[self._axis],\n            dtype=tf.int32,\n            seed=seed)\n\n        x = tf.gather(x, rand_pos, batch_dims=0, axis=self._axis,  # pylint: disable=unspecified-variable\n                       batch_dims_end=1)                                # pylint: disable=unspecified-variable\n\n        return x\n```  \n  "
"The function details of pam are as follows: (Note: The PAM constellation could be normalized to have unit power)\n  \n**Source code link:**\n  https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#pam\n\n```python\ndef pam(num_bits_per_symbol, normalize=True):\n    # pylint: disable=line-too-long\n    r\"\"\"Generates a PAM constellation.\n\n    This function generates a real-valued vector, where each element is\n    a constellation point of an M-ary PAM constellation. The bit\n    label of the `n` th point is given by the length-`num_bits_per_symbol`\n    binary represenation of `n`.\n\n    Input\n    -----\n    num_bits_per_symbol : int\n        The number of bits per constellation point.\n        Must be positive.\n\n    normalize : bool\n        If `True`, the constellation is normalized to have unit power.\n        Defaults to `True`.\n\n    Output\n    ------\n    : [2**num_bits_per_symbol], np.float32\n        The PAM constellation.\n\n    Note\n    ----\n    The bit label of the nth constellation point is given by the binary\n    representation of its position within the array and can be obtained\n    through ``np.binary_repr(n, num_bits_per_symbol)``.\n\n    The normalization factor of a PAM constellation is given in\n    closed-form as:\n\n    .. math::\n\n        \\sqrt{\\frac{1}{2^{n-1}}\\sum_{i=1}^{2^{n-1}}(2i-1)^2}\n\n    where :math:`n` is the ``num_bits_per_symbol`` number of bits\n    per symbol.\n    \"\"\"\n    if num_bits_per_symbol==1:\n        return tf.constant([-1.0, 1.0], dtype=PAM_DTYPE)\n\n    def _pam(constellation, normalize):\n        previous = pam(constellation-1, normalize=False)\n        even = (-(2*previous+1)) if normalize else -2*previous\n        odd = previous\n        return tf.concat([even, odd], 0)\n\n    constellation = _pam(num_bits_per_symbol, normalize)\n    return constellation\n```  \n  "
"The `return_crc_status` and `output_dtype` are parameters used in the `Polar5GDecoder` class of Sionna's Python library for simulation of wireless communication systems, which is designed for the decodin of Polar codes in compliance with the 5G standard.\n\nThe `return_crc_status` parameter is of type `bool` and it is set to `False` by default. When it is set to `True`, the `Polar5GDecoder` provides the cyclic redundancy check (CRC) status, indicating if a codeword was (most likely) correctly recovered. However, it's important to note that false positives are possible. The use of the CRC status allows the higher-level protocol to potentially reject frames with errors introduced during transmission.\n\nThe `output_dtype` parameter defines the datatype of the output from the decoder. In the context provided, it is a `tf.DType` (TensorFlow datatype), with a default value of `tf.float32`. Despite the output being internally calculated in `tf.float32`, which is a fast and convenient datatype for TensorFlow operations, the user can define the output to be in a different datatype if necessary.\n\nTo minimize the need for interactivity, the code should predefine the parameters for the `Polar5GDecoder`. The `output_dtype` and `return_crc_status` parameters, being part of the `Sionna.fec.polar.decoding.Polar5GDecoder` class, should be set based on the requirements of the specific application the code is designed to support.\n```python\n# Example of setting the parameters for the Polar5GDecoder\nfrom sionna.fec.polar.decoding import Polar5GDecoder\n# typically users should set these parameters based on the context\ndec = Polar5GDecoder(enc_polar, # assuming enc_polar is already defined\n                     dec_type='SC', \n                     list_size=8, \n                     num_iter=20, \n                     return_crc_status=False, \n                     output_dtype=tf.float32) # tf.float32 is the default output_dtype\n```\nIt is crucial to set parameters according to the specifications of the 5G standard, which includes compliance with the allowed Polar code rates and code lengths. The parameters should also align with the performance and resource requirements of the specific communication system being simulated."
"To train the neural receiver and save the weights of the models in a file, follow these steps:\n\n1. Set a seed for reproducibility. This is done to ensure that the training process yields the same results each time it is run. The seed is set using the `tf.random.set_seed` function.\n\n2. Instantiate the end-to-end model for training. This is done by creating an instance of the `OFDMSystemNeuralReceiver` class, with the `training` parameter set to `True`.\n\n3. Create an Adam optimizer for training. This is done using the `tf.keras.optimizers.Adam` class.\n\n4. Define the number of iterations for the training loop. The training loop will run this number of iterations, with each iteration performing a forward pass through the model and then applying the gradients.\n\n5. Sample a batch of SNRs (signal-to-noise ratio) for each iteration. This is done using TensorFlow's `tf.random.uniform` function, which generates random numbers between specified range.\n\n6. Start the training loop. For each iteration, a forward pass through the model is performed within a gradient tape. The loss is then computed, the gradients are calculated using the gradient tape, and then applied to the model using the `apply_gradients` function of the optimizer. The progress of the training is printed periodically.\n\n7. After each iteration of the training loop, the weights of the model are saved in a file. This is done using Python's `pickle.dump` function, which writes the weights to a file.\n\n8. Finally, the trained weights are evaluated and the output SINR (signal-to-interference-plus-noise ratio) is plotted.\n\nRemember that the `OFDMSystemNeuralReceiver` class and the training loop are implemented using Keras and TensorFlow, so the exact code to perform these steps is provided in the context. Make sure to use the exact same code in your implementation."
"Here are several links related to \"Part 1: Getting Started with Sionna\" in tutorials.\n\n[5G NR Physical Layer](https://nvlabs.github.io/sionna/api/phystutor-5g.html)\n\n[5G NR Physical Channels Tutorial](https://nvlabs.github.io/sionna/api/phystutor-ocn.html)\n\n[Ray Tracing and Site Specific Simulations using Sionna](https://nvlabs.github.io/sionna/api/rtstutor.html)\n\n[802.11 Tutorial](https://nvlabs.github.io/sionna/api/80211tutorial.html)\n\n[Optimization Tutorial](https://nvlabs.github.io/sionna/api/opt.html)"
"To run throughput tests using the Sionna Python package in Graph Mode, you can follow these steps:\n\n1. Import the necessary packages and set up your environment. This includes importing Sionna and TensorFlow, setting up your GPU configuration, and setting the seed for reproducibility.\n\n2. Define your model or function that you want to test. In the context, a model is defined that implements a communication system using 16-QAM encoding and decoding.\n\n3. Define your throughput function. This function should take the batch size and number of repetitions as inputs and return the throughput in bits per second. The function runs the model for the specified number of repetitions and calculates the average time taken for the model to process one batch.\n\n4. Run the throughput test in eager execution. This is done by calling the throughput function with the model and the batch size and number of repetitions as inputs. The batch size and number of repetitions determine the parallelism and number of samples used in the test.\n\n5. Define your graph mode function. This is similar to the throughput function, but it is decorated with `@tf.function` to enable graph mode execution. The function should take the same inputs and return the same outputs as the throughput function.\n\n6. Run the throughput test in graph execution. This is done by calling the throughput function with the model and the batch size and number of repetitions as inputs.\n\n7. Finally, compare the time taken to run the tests in eager and graph execution modes. This can give you an idea of the relative performance of the two modes. \n\nPlease note that the exact code and functions to use will depend on your specific use case and the model you are testing. The context provides a general outline, but you may need to adjust it to fit your needs."
"To configure a rate-1/2, constraint-length-3 convolutional code encoder using the `ConvEncoder` class from the Sionna package, you can do so in two ways, as shown in the context. I will demonstrate both methods with reference to the provided Python context, ensuring that the input parameters are appropriate for a rate-1/2 code and a constraint length of 3.\n\n1. **Instantiation with `rate` and `constraint_length` parameters:**\n\nHere's how you would instantiate a `ConvEncoder` with a rate-1/2 and constraint length-3 using the `rate` and `constraint_length` parameters directly:\n\n```python\nfrom sionna.fec.conv import ConvEncoder\n\n# Using rate and constraint_length parameters\nencoder = ConvEncoder(rate=1/2, constraint_length=3)\n```\n\n2. **Instantiation with `gen_poly` parameter:**\n\nAnd here's how you could create the same encoder using the `gen_poly` parameter. The `gen_poly` represents the generator polynomial for the encoder, which is a string list of 0's and 1's. For a rate-1/2 code, we need two polynomials, one for each of the two possible output bits for each state transition.\n\n```python\n# Using gen_poly parameter\ngen_poly = ['101', '111']\nencoder = ConvEncoder(gen_poly=gen_poly)\n```\n\nPlease ensure that the context provides necessary and valid information for the Sionna package. The code has been written in Python and makes use of the Sionna package which should be installed in your environment. The code has not been adjusted to be syntactically correct and is meant to be used as a reference. When using an actual API, verify the code's accuracy and ensure the `rate` and `constraint_length` parameters match those required for a rate-1/2, constraint-length-3 convolutional code."
"To use the RMa model, first create a topology where UTs and BSs are located, the column size of the `ut_array` and `bs_array` determines the number of antenna columns at the transmitter (UT) and receiver (BS). \n\nNext, set the topology using the `set_topology()` method. The `set_topology()` accepts the following parameters:\n\n- `ut_loc`: Locations of the UTs \n- `bs_loc`: Locations of BSs \n- `ut_orientations`: Orientations of the UTs arrays \n- `bs_orientations`: Orientations of the BSs arrays \n- `ut_velocities`: Velocities of UTs \n- `in_state`: Indoor/outdoor state of UTs \n\nAfter setting up the topology, the channel can be instantiated. The RMa channel model is set up assuming an OFDM waveform as shown in the code snippet. The code instantiates the RMa channel model assuming an OFDM waveform. `rg` is an instance of `ResourceGrid` that determines the frequency and time properties of the channel model.\n\n```python\n# UT and BS panel arrays\nbs_array = PanelArray(num_rows_per_panel = 4,\n                      num_cols_per_panel = 4,\n                      polarization = 'dual',\n                      polarization_type = 'cross',\n                      antenna_pattern = '38.901',\n                      carrier_frequency = 3.5e9)\nut_array = PanelArray(num_rows_per_panel = 1,\n                      num_cols_per_panel = 1,\n                      polarization = 'single',\n                      polarization_type = 'V',\n                      antenna_pattern = 'omni',\n                      carrier_frequency = 3.5e9)\n# Instantiating RMa channel model\nchannel_model = RMa(carrier_frequency = 3.5e9,\n                    ut_array = ut_array,\n                    bs_array = bs_array,\n                    direction = 'uplink')\n# Setting up network topology\n# ut_loc: UTs locations\n# bs_loc: BSs locations\n# ut_orientations: UTs array orientations\n# bs_orientations: BSs array orientations\n# ut_velocities: UTs velocities\n# in_state: Indoor/outdoor states of UTs\nchannel_model.set_topology(ut_loc,\n                           bs_loc,\n                           ut_orientations,\n                           bs_orientations,\n                           ut_velocities,\n                           in_state)\n# Instanting the OFDM channel\nchannel = OFDMChannel(channel_model = channel_model,\n                      resource_grid = rg)\n```\n\nAfter this, the channel can be used to generate channels either in the time domain or assuming perfect frequency synchronization."
"The `Trellis` structure, from the `sionna.fec.conv.utils` module, represents a Trellis for a given generator polynomial. The Trellis structure defines state transitions and output symbols (and bits) for each current state and input. It can be used to encode and decode information when working with convolutional codes.\n\nTo configure a `Trellis`, you will need to provide two main parameters: `gen_poly` and `rsc`.\n\n1. `gen_poly`: A generator polynomial is a polynomial used to generate the codewords in a code. In the context, it is a tuple of strings, where each string is a 0,1 sequence. If `None` is provided, `rate` and `constraint_length` must be provided. The `gen_poly` parameter is crucial for setting up the Trellis, as based on the provided generator polynomial, the polynomials in the Trellis structure are set.\n\n2. `rsc`: This is a boolean flag, which indicates whether the Trellis is recursive systematic or not. If the `rsc` parameter is set to `True`, the encoder is recursive systematic, meaning the first polynomial in `gen_poly` is used as the feedback polynomial. If `rsc` is `True`, the Trellis structure will be set based on the rsc property of the generator polynomial. The `True` rsc attribute implies use of the *recursive systematic* generator polynomial. Constraint_length should be then set to the desired length of the Trellis. The Trellis will start at t=0 and go until t=T where T is the `constraint_length`.\n\nIt's important to note that the `gen_poly` and `rsc` parameters must be supplied following the specifications that are provided in the context. An example of how they might be used would be in initializing a `Trellis` object:\n\n```python\nfrom sionna.fec.conv.utils import Trellis\n\ngen_poly = (\"<c01>\", \"<c02>\", None)\nrsc = True\ntrellis = Trellis(gen_poly, rsc)\n```\n\nIn this example, a generator polynomial is given as a string sequence of 0's and 1's enclosed in angle brackets. The `rsc` parameter is set to `True`. When the `gen_poly` and `rsc` parameters are provided, the `Trellis` object sets up a Trellis structure based on these parameters, and the encoder will be the one used by the recursive systematic encoder.\n\nIt's essential to emphasize that the described `gen_poly` should represent the generator matrix's polynomial functions, where `c0`, `c1`, and `c2` are placeholders for the coefficients of the polynomial functions. The `None` at the end of the `gen_poly` is necessary when the `rsc` parameter is `True`, per the context. It indicates that the last polynomial in the generator matrix is not a part of the Trellis since it is used as the initialization polynomial in recursive systematic case.\n\nTo reiterate, the `Trellis` structure is a crucial component when working with convolutional codes, as it defines the structure for the code's representation in the form of a polynomial generator matrix, paving the way for encoding and decoding while managing the code's complexity and performance."
"Here is the detailed information of CarrierConfig:   \n  \n[sionna.nr.CarrierConfig(**kwargs)  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/nr/carrier_config.html#CarrierConfig)  \n\nThe CarrierConfig objects sets parameters for a specific OFDM numerology, as described in Section 4 [3GPP38211].\n\nAll configurable properties can be provided as keyword arguments during the initialization or changed later.\n\n```python\n# Example\n>>> carrier_config = CarrierConfig(n_cell_id=41)\n>>> carrier_config.subcarrier_spacing = 30\n```\n[3GPP38.211]: \"NR; Physical channels and modulation\"\n  \n**Properties**\n\n- `cyclic_prefix`: Cyclic prefix length. Type: String, \"normal\" (default) | \"extended\".\n- `cyclic_prefix_length`: Cyclic prefix length. Type: Float, read-only.\n- `frame_duration`: Duration of a frame. Type: Float, read-only.\n- `frame_number`: System frame number. Type: Int, read-only.\n- `kappa`: Constant \u03ba. Type: Float, read-only.\n- `mu`: Subcarrier spacing configuration, \u0394f = 2^\u03bc15 kHz. Type: Int, 0 (default) | 1 | 2 | 3 | 4 | 5 | 6, read-only.\n- `n_cell_id`: Physical layer cell identity. Type: Int, 1 (default) | [0, \u2026, 1007], read-only.\n- `n_size_grid`: Number of resource blocks in the carrier resource grid. Type: Int, 4 (default) | [1, \u2026, 275], read-only.\n- `n_start_grid`: Start of resource grid relative to common resource block (CRB) 0. Type: Int, 0 (default) | [0, \u2026, 2199], read-only.\n- `num_slots_per_frame`: Number of slots per frame. Depends on the subcarrier_spacing. Type: Int, 10 (default) | 20 | 40 | 80 | 160 | 320 | 640, read-only.\n- `num_slots_per_subframe`: Number of slots per subframe. Depends on the subcarrier_spacing. Type: Int, 1 (default) | 2 | 4 | 8 | 16 | 32 | 64, read-only.\n- `num_symbols_per_slot`: Number of OFDM symbols per slot. Configured through the cyclic_prefix. Type: Int, 14 (default) | 12, read-only.\n- `slot_number`: Slot number within a frame. Type: Int, 0 (default), [0, \u2026, num_slots_per_frame], read-only.\n- `sub_frame_duration`: Duration of a subframe. Type: Float, 1e-3 (default), read-only.\n- `subcarrier_spacing`: Subcarrier spacing. Type: Float, 15 (default) | 30 | 60 | 120 | 240 | 480 | 960.\n- `t_c`: Sampling time for subcarrier spacing 480kHz. Type: Float, 0.509e-9 [s], read-only.\n- `t_s`: Sampling time for subcarrier spacing. Type: Float, 32.552e-9 [s], read-only.\n   ```python\n    t_c = 1/48000*2048\n    t_s = 1/ (subcarrier_spacing*2048)\n    t_n = (14+6*configuration.n_id_cell) * t_c\n    t_n_bar = configuration.n_ra * t_s\n    t_0 = configuration.n_ra * t_c\n    if configuration.n_sp_symb < 14:\n        t_n_bar = t_n_bar + configuration.n_sp_symb * t_c\n    else:\n        t_n_bar = t_n_bar + 14 * t_c + (configuration.n_sp_symb-14) * t_c + t_0\n    if configuration.n_sc_spec < 12:\n        t_n = t_n_bar + configuration.n_sc_spec * t_c\n    else:\n        t_n = t_n_bar + 12 * t_c + (configuration.n_sc_spec-12) * t_c + t_0\n    if self.slot_number%configuration.n_sc_spec<configuration.n_sc_spec-configuration.n_scpec-1:\n        t_n = t_n + t_0\n    if cyclic_prefix==\"extended\":\n        t_n = t_n + t_0\n        t_n_bar = t_n_bar + t_0\n        t_n_spec = t_0 + 2 * t_c + t_0 - t_0\n    else:\n        t_n_spec = t_0 + t_c + t_0 - t_0\n    if self.slot_number%configuration.n_sc_spec==configuration.n_sc_spec-1:\n        t_n = t_n + t_n_bar - t_n_spec\n    frame_duration = configuration.num_slots_per_frame * t_n + t_0\n    if cyclic_prefix==\"extended\":\n        frame_duration = frame_duration - t_0\n    super().setattr(\"frame_duration\", frame_duration)\n\n   ```"
"Here is the definition of Receiver: sionna.nr.Receiver(rx_tm, rx_tr, rx_decoder, num_streams=1, rx_port=0, return_state=False, output_dtype=tf.complex64, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/nr/receiver.html#Receiver)  \n\n```python\nclass Receiver(TrainableNeuralReceiver):\n    # pylint: disable=line-too-long\n    r\"\"\"Receiver(rx_tm, rx_tr, rx_decoder, num_streams=1, rx_port=0, return_state=False, output_dtype=tf.complex64, **kwargs)\n\n    Layer implementing a : [3GPPTS38214]_ compliant receiver, including\n    synchronization, demapping, and detection.\n\n    The layer inherits from the :class:`~sionna.ofdm.BaseReceiver` class\n    and is parameterized by a :class:`~sionna.channel.SynchDemap` and\n    a :class:`~sionna.nr.NRReceiver` instance.\n\n    The following figure shows the overall architecture of the Receiver.\n\n    .. figure:: ../figures/receiver.png\n        :align: center\n\n    Parameters\n    ----------\n    rx_tm : str, one of [\"UT\", \"RU\", \"RA\", \"RP\"]\n        Telescope model. See :class:`~sionna.channel.UT`, :class:`~sionna.channel.RU`,\n        :class:`~sionna.channel.RA`, or :class:`~sionna.channel.RP`\n        for more details.\n\n    rx_tr : str, one of [\"T1\", \"T2\", \"T3\", \"T4\"]\n        Receiver antenna model. See :class:`~sionna.channel.T1`, :class:`~sionna.channel.T2`,\n        :class:`~sionna.channel.T3`, or :class:`~sionna.channel.T4`\n        for more details.\n\n    rx_decoder : :class:`~sionna.nr.NRReceiver`\n        Instance of :class:`~sionna.nr.NRReceiver`.\n\n    num_streams : int\n        Number of decoding paths. Defaults to `1`.\n\n    rx_port : int\n        Receiver port. Defaults to `0`.\n\n    return_state : bool\n        If `True`, the hidden state of the receiver is returned.\n        Defaults to `False`.\n\n    output_dtype : tf.Dtype\n        Defaults to `tf.complex64`. Defines the datatype for internal\n        computations and the output dtype.\n\n    Input\n    -----\n    (x, no) :\n        Tuple:\n\n    x : [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex\n        Received OFDM resource grid after cyclic prefix removal and FFT\n\n    no : [batch_size, num_rx, num_rx_ant] or only the first n>=0 dims, tf.float\n        Variance of the AWGN.\n\n    Output\n    ------\n    y : [batch_size, num_rx, num_streams, num_ofdm_symbols, num_effective_subcarriers], tf.complex\n        Channel estimates for all streams and all OFDM symbols.\n\n    no : [batch_size, num_rx, num_streams], tf.float\n        Variance of the noise.\n\n    If `return_state` is `True`:\n    s : [batch_size, num_rx, num_streams, num_data_symbols], tf.complex\n        Estimated symbols.\n    no : [batch_size, num_rx, num_streams, num_data_symbols], tf.complex\n        Variance of the noise.\n    \"\"\"\n    def __init__(self,\n                 rx_tm=\"RA\",\n                 rx_tr=\"T1\",\n                 rx_decoder=nr_scatter_detector,\n                 num_streams=1,\n                 rx_port=0,\n                 return_state=False,\n                 output_dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(rx_tm=rx_tm,\n                         rx_tr=rx_tr,\n                         rx_decoder=rx_decoder,\n                         num_streams=num_streams,\n                         rx_port=rx_port,\n                         return_state=return_state,\n                         output_dtype=output_dtype,\n                         **kwargs)\n```\n  "
"The `ResourceGrid` in the Sionna Python package is used to define various parameters and structures that are common in OFDM-based waveforms. This grid can be used to map data and pilot symbols in a pre-defined pattern. The `ResourceGrid` can also include guard and DC carriers which are nulled. This grid, along with the `PilotPattern`, is a crucial component in the OFDM system simulation.\n\nThe `ResourceGrid` is used in the `ResourceGridMapper` module where it maps modulated data symbols to a `ResourceGrid`. It is used to map the data symbols along with pilot symbols onto the OFDM resource grid. The usage can be understood with the following example:\n\n```python\nrg = ResourceGrid(num_ofdm_symbols=14,\n                  fft_size=64,\n                  subcarrier_spacing=30e3,\n                  num_tx=1,\n                  num_streams_per_tx=1,\n                  num_guard_carriers=(5,6),\n                  dc_null=True,\n                  pilot_pattern=\"kronecker\",\n                  pilot_ofdm_symbol_indices=[2,11])\n\npilot_pattern = rg.pilot_pattern # Extract the PilotPattern from the ResourceGrid instance\n```\n\nIn this code snippet, a `ResourceGrid` is initialized with certain parameters such as the number of OFDM symbols, FFT size, subcarrier spacing, number of transmitters, number of streams per transmitter, number of guard carriers, presence of DC null, and the used pilot pattern. The pilot pattern is specified to be \"kronecker\" which is an instance of `KroneckerPilotPattern`. This pattern specifies that `num_tx` transmitters and `num_streams_per_tx` streams share the same set of pilot carriers which are mapped in a Kronecker pattern.\n\nThe `ResourceGrid` and its related functionalities are used for simulating OFDM-based waveforms in the Sionna package. This grid, when used in combination with other tools like the `PilotPattern`, serves as the building block for OFDM system simulation."
"To generate a batch of frequency responses, you can follow these steps:\n\n1. First, you need to have a batch of continuous-time channel impulse responses (CIRs). These CIRs represent the channel characteristics in the time domain. They can be generated using the `cir` method of a channel model. This method generates channel impulse responses for all links in the batch at a specific delay and with a specific nominal angle of arrival.\n\n2. Next, you can compute the channel frequency responses from the CIRs. This can be done using the `cir_to_ofdm_channel` function from the Sionna package. This function computes the Fourier transform of the continuous-time channel impulse response at a set of frequencies, corresponding to the different subcarriers.\n\n3. Finally, you can apply the channel frequency responses to an input signal. This can be done using the `ApplyOFDMChannel` layer from the Sionna package. This layer computes the frequency response of the channel at all the subcarriers by using the channel frequency response computed in the previous step. It also adds additive white Gaussian noise (AWGN) to the output.\n\nHere is a simplified code snippet that demonstrates these steps:\n\n```python\n# Set up the channel model\nfrom sionna.channel import GenerateOFDMChannel\nchannel_model = GenerateOFDMChannel(my_antenna_array, other_antenna_array, ...)\n# Generate batch of continuous-time channel impulse responses\na, tau = channel_model(batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps)\n# Generate the subcarrier frequencies\nfrequencies = subcarrier_frequencies(fft_size, subcarrier_spacing)\n# Generate the channel frequency responses\nh_freq = cir_to_ofdm_channel(frequencies, a, tau, normalize=True)\n# Apply the channel frequency responses to the channel input\nchannel_output = ApplyOFDMChannel(add_awgn=True)([x, h_freq])\n```\n\nIn this code, `x` represents the channel input, and `channel_output` represents the channel output. The `cir_to_ofdm_channel` function is used to compute the channel frequency responses from the CIRs, and the `ApplyOFDMChannel` layer is used to apply the channel frequency responses to the channel input."
"To configure transmitters and receivers for computing propagation paths in Sionna RT, you need to follow these steps:\n\n1. Load the scene using the `load_scene()` function.\n\n2. Configure the antenna array for all transmitters. This is done using the `PlanarArray` class. You need to specify the number of rows and columns for the antenna array, the vertical and horizontal spacing, the pattern and polarization. For example:\n\n```python\nscene.tx_array = PlanarArray(num_rows=8,\n                          num_cols=2,\n                          vertical_spacing=0.7,\n                          horizontal_spacing=0.5,\n                          pattern=\"tr38901\",\n                          polarization=\"VH\")\n```\n\n3. Configure the antenna array for all receivers. This is similar to configuring the transmitter, but you use the `RxArray` class. For example:\n\n```python\nscene.rx_array = RxArray(num_rows=1,\n                          num_cols=1,\n                          vertical_spacing=0.5,\n                          horizontal_spacing=0.5,\n                          pattern=\"dipole\",\n                          polarization=\"cross\")\n```\n\n4. Create a transmitter. This is done using the `Transmitter` class. You need to specify a name for the transmitter, its position, and its orientation. For example:\n\n```python\ntx = Transmitter(name=\"tx\",\n              position=[8.5,21,27],\n              orientation=[0,0,0])\n```\n\n5. Add the transmitter to the scene:\n\n```python\nscene.add(tx)\n```\n\n6. Create a receiver. This is similar to creating a transmitter, but you use the `Receiver` class instead:\n\n```python\nrx = Receiver(name=\"rx\",\n           position=[45,90,1.5],\n           orientation=[0,0,0])\n```\n\n7. Add the receiver to the scene:\n\n```python\nscene.add(rx)\n```\n\n8. Make the transmitter point towards the receiver. This is done using the `look_at()` function:\n\n```python\ntx.look_at(rx)\n```\n\nAfter configuring the transmitters and receivers, you can compute propagation paths using the `compute_paths()` function:\n\n```python\npaths = scene.compute_paths()\n```\n\n9. Visualize the paths using the `preview()` function:\n\n```python\nscene.preview(paths=paths)\n```\n    \nRemember to replace the specific parameters in the code snippets with the parameters that suit your specific needs."
"The SymbolDemapperWithPrior class is a deprecated part of the sionna.mapping package designed for computing normalized log probabilities (logits) or hard decisions on symbols, assuming that prior knowledge on the constellation points is available. It requires a tuple as input of received symbols (y), prior knowledge as log probabilities (prior), and the noise variance estimate (no).\n\n```python\nclass SymbolDemapperWithPrior(SymbolDemapper):\n    def __init__(self, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs):\n        # Calls the SymbolDemapper initializer\n        super().__init__(constellation_type=constellation_type, num_bits_per_symbol=num_bits_per_symbol, constellation=constellation, hard_out=hard_out, with_prior=True, dtype=dtype, **kwargs)\n```\n\nThe class has parameters such as constellation_type (e.g., \"qam\" or \"pam\"), num_bits_per_symbol, constellation, hard_out, and dtype. The \"constellation\" parameter is deprecated and is recommended to be used with the \"constellation_type\" parameter. \"hard_out\" is a boolean parameter that defaults to False; when set to True, the class computes hard-decided symbols instead of soft-values. \"dtype\" is used to set the datatype for internal calculations and the output datatype, with the default being tf.complex64.\n\nThe class outputs either soft-symbols or hard-decisions for each symbol. The normalized log-probability for a constellation point 'c' is calculated using the soft-value approach, leveraging the logit formula for the Pr(c|y): Ln(Pr(c|y)) = -(|y-c|^2 / N + pc - ln(Sum(C exp(pc)))).\n  \nAlthough the class is deprecated, it provides valuable functionality for certain tasks like demapping symbols in complex numerical domains with given priors, making it easier to work with applied signal processing tasks and machine learning models."
"To enable diffuse reflections and observe their impact on the coverage map in the Sionna package, you should use the `diffuse_reflection` parameter in the radio materials. \n\nA diffuse reflection occurs when a radio wave hits a surface and bounces off in different directions. In the context provided, the coverage map is generated based on a specific radio scene, which includes various parameters such as the frequency, material, and scene objects. The `diffuse_reflection` parameter is set to `True` for the `concrete` material in the given scene. Here is the relevant code snippet:\n\n```python\nscene = load_scene(sionna.rt.scene.simple_street_canyon)\nscene.objects[\"concrete\"].radio_material.diffuse_reflection = True\n```\n\nIn this code, we load the scene and then set the `diffuse_reflection` parameter to `True` for the `concrete` material.\n\nAfter enabling diffuse reflections, you can compute a new coverage map in the updated scene. This coverage map will reflect the impact of the diffuse reflections. The coverage map is computed using the `coverage_map()` method from the scene object. \n\nPlease note that the coverage map is simulated for a specific carrier frequency and with a specified number of samples, so you need to ensure that these parameters suit your requirements. Also, as described in the context, the number of samples can significantly impact the computational time and memory usage."
"To compute the mean squared error (MSE) between the transmitted and recovered symbols, you can follow these steps:\n\n1. First, you need to compute the difference between the transmitted and recovered symbols. This can be done using the `tf.subtract` function. The transmitted symbols are represented by the tensor `x`, and the recovered symbols are represented by the tensor `x_hat`. The corresponding operation is `tf.subtract(x, x_hat)`.\n\n2. The MSE is defined as the average of the squared differences between the transmitted and received signals. Therefore, after computing the differences, you can simply call the `tf.reduce_mean` function on the squared differences. The operation to compute the MSE is `tf.reduce_mean(tf.square(tf.subtract(x, x_hat)))`.\n\n3. Finally, you can print or use the value of the MSE for further computations. The complete set of operations to compute the MSE in TensorFlow is as follows:\n\n```python\n# Compute the difference between the transmitted and received signals\ndiff = tf.subtract(x, x_hat)\n\n# Compute the MSE\nmse = tf.reduce_mean(tf.square(diff))\n```\n\nIn the provided context, the MSE is also printed alongside the estimated effective noise variance `no_eff`. The MSE is computed using the soft-symbol estimates (recovered symbols) and the true noise variance `no` provided during estimation. The `no_eff` parameter is an estimated effective noise variance of the received signal, which is often used as a scalar to represent the noise in a MIMO system. The MSE is printed for verification, and the effective noise variance is printed as part of the soft-symbol estimation process."
"The 'create_or_check_constellation' method in the Constellation class is a utility function that allows you to either create a new constellation or verify that an existing one is consistent with the requirements of a requested constellation type, number of bits per symbol, and dtype (tf.complex64 or tf.complex128).\n\nIf the `constellation` parameter is `None`, the method will create a new constellation object of type `constellation_type` and with `num_bits_per_symbol` bits per symbol. However, if a `constellation` object is provided (along with the appropriate `constellation_type` and `num_bits_per_symbol`), the method will check that the `constellation` object is consistent with the requested `constellation_type` and `num_bits_per_symbol`. If it is, the `constellation` object is returned. Otherwise, an assertion is raised.\n\nThis function is particularly useful because it allows for the creation of a constellation object or the checking of an existing one in a single line of code. The parameters of the method are used to specify the constellation type and bits per symbol either for creating or for verifying, and the `dtype` parameter is used to set the complex type of the constellation. By configuring these parameters, the method can cater to several types of constellations, including custom ones."
"The `scat_keep_prob` is an argument in the context of ray tracing with the Sionna package, specifically related to the computation of scattered paths (those that have undergone a reflection or refraction and then propagated further). This argument determines the fraction of scattered paths that will be retained in the ray tracing process. \n\nIn ray tracing, many millions of rays may be computed to fully characterize a propagation environment. The number of scattered paths can be particularly large because, after hitting a surface, a ray splits into a transmitted ray and a reflected ray, and each of these rays can then propagate further. For instance, if a ray hits a surface that is configured to reflect and is then retransmitted, there will be multiple \"child\" rays associated with the original \"parent\" ray.\n\nGiven this context, the `scat_keep_prob` argument is used to randomly drop some of these scattered paths during the ray tracing process. The amount of dropped paths is determined by this argument, which is used as the probability in a random sampling process. The scattered paths that are not dropped are then scaled by the inverse of this probability, increasing their importance in the final output. \n\nThe purpose of having such a mechanism in ray tracing is to manage the potentially large number of scattered paths, ensuring efficient computation while maintaining the representability of the channel impulse responses. Dropping some scattered paths allows the computation to scale better for large environments and complex scenes. The choice of which paths to drop and which to retain is left to a stochastic process, as determined by the specified probability."
"Here is the detailed information of sionna.rt.r_hat: [sionna.rt.r_hat(theta, phi)](https://nvlabs.github.io/sionna/_modules/sionna/rt/utils.html#r_hat)\n\nComputes the spherical unit vector $\\hat{\\mathbf{r}}(\\theta, \\varphi)$ as defined in [(1)](https://nvlabs.github.io/sionna/em_primer.html#equation-spherical-vecs)\n\n**Input**\n\n- `theta` (arbitrary shape, tf.float): Zenith angles $\\theta$ [rad].\n- `phi` (same shape as theta, tf.float): Azimuth angles $\\varphi$ [rad].\n\n**Output**\n\n- `theta` (same shape as inputs, tf.float): First unit vector component.\n- `phi` (same shape as inputs, tf.float): Second unit vector component.\n\nsource code:\n```python\ndef r_hat(theta, phi):\n    r\"\"\"\n    Computes the spherical unit vector\n    :math:`\\hat{\\mathbf{r}}(\\theta, \\varphi)` as defined in :eq:`spherical_vecs`\n\n    Input\n    -------\n    theta : arbitrary shape, tf.float\n        Zenith angles :math:`\\theta` [rad]\n\n    phi : same shape as ``theta``, tf.float\n        Azimuth angles :math:`\\varphi` [rad]\n\n    Output\n    -------\n    x : same shape as inputs, tf.float\n        First unit vector component\n\n    y : same shape as inputs, tf.float\n        Second unit vector component\n    \"\"\"\n    x = tf.cos(theta)*tf.cos(phi)\n    y = tf.cos(theta)*tf.sin(phi)\n    z = -tf.sin(theta)\n    return x, y, z\n```"
"Here is the detailed information of OFDMDetectorWithPrior:   \n[sionna.ofdm.OFDMDetectorWithPrior(detector, output, resource_grid, stream_management, constellation_type, num_bits_per_symbol, constellation, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#OFDMDetectorWithPrior)  \n\nLayer that wraps a MIMO detector for use with the OFDM waveform and the detection prior knowledge.\n\nThe parameter detector is a callable (e.g., a function) that implements a MIMO detection algorithm with or without prior for arbitrary batch dimensions. Examples of such detectors are sionna.mimo.MaximumLikelihoodDetectorWithPrior or sionna.mimo.LMMSEDetectorWithPrior. Both receive as inputs a tuple $(\\mathbf{y}, \\mathbf{h}, \\mathbf{prior})$ such that:\n\n- **y** ([\u2026,num_rx_ant], tf.complex) \u2014 1+D tensor containing the received signals.\n- **h** ([\u2026,num_rx_ant,num_streams_per_rx], tf.complex) \u2014 2+D tensor containing the channel matrices.\n- **prior** ([\u2026,num_streams_per_rx,num_bits_per_symbol] or [\u2026,num_streams_per_rx,num_points], tf.float) \u2014 Prior for every symbol of every stream provided as LLRs (for constellations, typically as output by a demapper).\n\nIt generates one of the two possible outputs:\n- **b_hat** ([\u2026,num_streams_per_rx,num_bits_per_symbol], tf.float) \u2014 LLRs or hard-decisions for every bit of every stream, if output equals \"bit\".\n- **x_hat** ([\u2026,num_streams_per_rx, num_points], tf.float or [\u2026,num_streams_per_rx], tf.int) \u2014 Logits or hard-decisions for constellation symbols for every stream, if output equals \"symbol\".\n\n**Note:**\nThe input to this layer is a list of length 2. It must generate outputs of at least dimension 1. If this does not work, try to re-implement the detector generating layer. It must be callable with the given signature.\n\n**Example**\nA parameter `det_params` providing y, h, prior, and containing other parameters required by the detector:\n```python\ndetector = MaximumLikelihoodDetectorWithPrior(output='bit', det_params=det_params)\n```\nUsing the detector:\n```python\ndetector_with_prior = OFDMDetectorWithPrior(detector=detector,\n                            output='bit',\n                            resource_grid=rg,\n                            stream_management=sm,\n                            constellation_type=\"qam\",\n                            num_bits_per_symbol=bits_per_symbol,\n                            constellation=constellation)\n```\nAssuming y ([batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex) and h ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex) have been computed from baseband received signal y and channel estimates h, and prior is provided based on the received constellation, the detection output is computed as:\n```python\nb_hat = detector_with_prior([y, h, prior])\n```"
"Here is the detailed information of GaussianPriorSource:   \n  \nThis layer generates fake logits as if the all-zero codeword were transmitted  \n    according to an AWGN channel with noise variance ``no``.  \n  \nThe logits are defined as  \n  \n\\\\[ \\text{logit}_{\\text{awgn}} = \\frac{x}{2 \\operatorname{log_2} e} \\left( \\frac{1}{no} \\right)\\\\]  \n  \nwhere the variance of the AWGN is `no`. The log-likelihood for the all-zero codeword is  \n    \\\\[ \\text{LLR}_{\\text{all-zero}} = \\frac{x}{2 \\operatorname{log_2} e} \\left( \\frac{1}{no} \\right)\\\\]  \n  \nBrannstrom [[Brannstrom]](https://nvlabs.github.io/sionna/api/fec.utils.html#brannstrom)  \n    proposed an approximation function for the mutual information in the form of  \n    LLRs as Gaussian prior on the all-zero codeword. This function is  \n    implemented by this class. It relates the bit energy to the LLR of the  \n    all-zero codeword via  \n  \n\\\\[ \n\\begin{align}\n    \\frac{E_b}{\\text{LLR}_{\\text{all-zero}}} &\\approx 0.339 \\\\\n    \\text{J}\\left(\\text{MI}(\\text{LLR}) \\right) &\\approx \\exp \\left(-2 \\text{MI}(\\text{LLR}) \\right) \\text{.}\n\\end{align}\n\\quad \\text{where} \\quad MI}(\\text{LLR}) = \\left\\{ \n    \\begin{array}{ll}\n        \\text{log_2'}\\left( 1 + \\exp\\left( \\text{LLR} \\right) \\right) & \\text{if } \\text{LLR} > 0 \\\\\n        \\text{log_2'}\\left( 1 + \\exp\\left( -\\text{LLR} \\right) \\right) & \\text{otherwise.}\n    \\end{array}\n\\\\]\n  \nwhere log_2' is defined as log_2'$(z) = \\max\\{\\log_2 (z), -20\\}$.  \nThe Gaussian prior on the all-zero codeword is then  \n  \n\\\\[ \\text{LLR} \\sim \\mathcal{N} \\left( \\frac{LLR_{\\text{all-zero}}}{2} , \\frac{1}{I} \\right) \n    \\ \\sim \\mathcal{N} \\left( 0.9194, \\frac{1}{I} \\right) \n\\quad \\text{where} \\quad I=\\frac{E_b}{\\text{no}} \\ \\text{.}\n\\\\]  \n  \nThis class can be used to according to the Sionna framework [[SionnaSionna]].  \nGenerated values are clipped to $[10^{-20}, 10^{20}]$.  \n  \n### Parameters\n\n- `output_shape` (int32) : The output shape of the 1+D tensor.\n- `no` (float) : The noise variance.\n- `dtype` (tf.DType) : The datatype for internal calculations and the output. Defaults to tf.float32.\n\n### Input\n\n- `size` (tf.int32) : The size of the output tensor.\n\n### Output\n\n- (output_shape, dtype) : 1+D tensor of Gaussian distributed values with shape `output_shape` and dtype `dtype`.\n\nsource code:  \n```python\nclass AWGNGen(tf.keras.layers.Layer): # pylint: disable=too-few-public-methods\n    \"\"\"AWGN generator\"\"\"\n\n    def __init__(self, channel_mode, dtype=tf.float32, **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        assert channel_mode in supported_channel_modes(), msg_nt(\"channel_mode\")\n        self._channel_mode = channel_mode\n\n    def __call__(self, inputs):\n        output_shape, no = inputs\n        return awgn_sample(output_shape, no, self._channel_mode)\n```\n\n  "
"The source code of QAM2PAM is here: https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#QAM2PAM\nThe source code of  QAM2PAM is as follows:\n```python\nclass QAM2PAM:\n    r\"\"\"\n    QAM2PAM(num_bits_per_symbol)\n\n    Transforms QAM symbol indices to PAM symbol indices.\n\n    For indices in a QAM constellation, computes the corresponding indices\n    for the two PAM constellations corresponding the real and imaginary\n    components of the QAM constellation.\n\n    Parameters\n    ----------\n    num_bits_per_symbol : int\n        The number of bits per QAM constellation symbol, e.g., 4 for QAM16.\n\n    Input\n    -----\n    ind_qam : Tensor, tf.int\n        Indices in the QAM constellation\n\n    Output\n    -------\n    ind_pam1 : Tensor, tf.int\n        Indices for the first component of the corresponding PAM modulation\n\n    ind_pam2 : Tensor, tf.int\n        Indices for the first component of the corresponding PAM modulation\n    \"\"\"\n    def __init__(self, num_bits_per_symbol):\n        base = [2**i for i in range(num_bits_per_symbol//2-1, -1, -1)]\n        base = tf.constant(base, tf.int32)\n        indices = tf.range(0, 2**num_bits_per_symbol, dtype=tf.int32)\n        real_ind = tf.bitwise.right_shift(tf.expand_dims(indices, 1), 0)\n        imag_ind = tf.bitwise.right_shift(tf.expand_dims(indices, 1), 1)\n        real_ind = tf.bitwise.bitwise_and(real_ind, base[0])\n        imag_ind = tf.bitwise.bitwise_and(imag_ind, base[0])\n        self._ind_pam1 = tf.bitwise.bitwise_or(real_ind, imag_ind)\n        imag_ind = tf.bitwise.left_shift(imag_ind, 1)\n        self._ind_pam2 = tf.bitwise.bitwise_or(real_ind, imag_ind)\n\n    def __call__(self, ind_qam):\n\n        ind_pam1 = tf.gather(self._ind_pam1, ind_qam, axis=0)\n        ind_pam2 = tf.gather(self._ind_pam2, ind_qam, axis=0)\n\n        return ind_pam1, ind_pam2\n```\n```python\ndef show_qam2pam():\n    qam2pam = QAM2PAM(4)\n    qam_symbols = Constellation(\"qam\", 16)()\n    pam_symbols1, pam_symbols2 = qam2pam(qam_symbols.indices)\n\n    show = BinarySource(7)\n    cw = CodedBits((1,2), 7)\n    cws = cw()\n    qam = QAMModulator(16)\n    pam = QAM2PAM(4)\n    qam_bits = qam(cws)\n    qam_symbols = qam.convolve(qam_bits)\n    pam_symbols1, pam_symbols2 = pam(qam_symbols)\n\n    plt.figure(figsize=(16,4))\n    plt.subplot(121)\n    plt.scatter(pam_symbols1.numpy()[::100,0], pam_symbols1.numpy()[::100,1], s=100, marker=\"x\")\n    plt.scatter(pam_symbols2.numpy()[::100,0], pam_symbols2.numpy()[::100,1], s=50, marker=\"o\")\n    plt.xlim(-3.5,3.5)\n    plt.ylim(-3.5,3.5)\n    plt.grid()\n    plt.title(\"PAM symbol mapping\")\n    plt.xlabel(\"Real part\")\n    plt.ylabel(\"Imaginary part\")\n    plt.xticks([-3, -1, 1, 3])\n    plt.yticks([-3, -1, 1, 3])\n    plt.subplot(122)\n    plt.scatter(qam_symbols.indices[::100], qam_symbols.codes[::100], s=100, marker=\"x\")\n    plt.scatter(qam_symbols.indices[::100], qam_symbols.codes[::100], s=50, marker=\"o\", facecolors=\"none\")\n    plt.xlim([-0.5, 16])\n    plt.grid()\n    plt.title(\"QAM symbol mapping\")\n    plt.xlabel(\"QAM symbol index\")\n    plt.ylabel(\"QAM constellation value\")\n    plt.xticks([0, 4, 8, 12, 16])\n\n    return pam_symbols1, pam_symbols2\n```\n\n```python\nshow_qam2pam()\n```\n[Result of the code above](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#QAM2PAM)"
"To load the required Sionna components, you can follow these steps:\n\n1. Set the environment for GPU usage and import the necessary libraries. This includes TensorFlow, with GPU support, matplotlib for plotting, and the Sionna package. If Sionna is not already installed, you can install it using pip.\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Avoid warnings from TensorFlow\n```\n\n2. Import the necessary components from Sionna. This includes the `Sionna` class for system setup, the `MIMOOFDMChannel` class for simulating the transmissions over an OFDM waveform and an i.i.d. Rayleigh fading channel, and the `ResourceGrid`, `Carrier`, `Antenna`, `AntennaArray`, `CDL`, and `UMi` classes for handling the OFDM resource grid, antenna configurations, and channel models.\n\n```python\nfrom sionna import Sionna\nfrom sionna.channel import MIMOOFDMChannel, IIDRayleighFadingChannel\nfrom sionna.ofdm import ResourceGrid, Carrier\nfrom sionna.channel import Antenna, AntennaArray\nfrom sionna.channel import CDL, UMi\n```\n\n3. Configure the notebook to use only a single GPU and allocate only as much memory as needed. You can then import the necessary TensorFlow components, including `allow_growth` from `tensorflow.config.experimental`.\n\n```python\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\ntf.get_logger().setLevel('ERROR')  from tensorflow.config.experimental import allow_growth\n```\n\n4. Load the Sionna components. If the Sionna package is not already installed, install it using pip.\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\nPlease note that the code snippets provided in the context include the necessary error handling to ensure that the packages are installed if they are not already available in the environment."
"To use Sionna's API, you need to import the necessary modules and set up the GPU configuration. Here's how you can do it:\n\n1. Import the necessary modules:\n\n```python\nimport os\nimport tensorflow asjson tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport sys\nfrom sionna.channel import cir_to_time_channel\nfrom sionna.rt import load_scene, PlanarArray, Transmitter, Receiver, RadioMaterial, Camera, LambertianPattern, DirectivePattern, BackscatteringPattern\nfrom sionna.rt.utils import r_hat\nfrom sionna.constants import PI, SPEED_OF_LIGHT\nfrom sionna.utils import expand_to_rank\n```\n\n2. Set up the GPU configuration:\n\n```python\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\ntf.get_logger().setLevel('ERROR')\ntf.random.set_seed(1)\n```\n\nIn the code above, you are setting the `gpu_num` to 0, which means you are using the first GPU. If you want to use the CPU, you can set `gpu_num` to an empty string. \n\nYou are also setting the environment variables `CUDA_VISIBLE_DEVICES` and `TF_CPP_MIN_LOG_LEVEL`. The `CUDA_VISIBLE_DEVICES` variable is used to specify the GPU number. The `TF_CPP_MIN_LOG_LEVEL` variable is used to control TensorFlow logging. \n\nFinally, you are importing TensorFlow, and setting the GPU options to run TensorFlow on the GPU."
"Coverage maps describe the received power from a specific transmitter at every point on a plane. An important characteristic of coverage maps is that they enable an analysis of signal quality across a specific area, which isn't limited to the positions of receivers or transmitters.\n\nIn the provided context, there isn't any specific information about CoverageMap other than its required computation function `coverage_map()`. However, I can surmise some information based on typical ray tracing methodologies.\n\nCoverageMap would be uniquely defined for a specific scene and by the scene's elements (radio materials, transmitters, receivers, their associated antenna patterns, etc.). It can be visualized within the Scene's preview or rendering functions, or externally within a Preview or Renderer. \n\nThe coverage map would be a discrete representation of signal strength across a 2D plane, with the plane divided into small rectangular bins. The signal strength within each bin is represented by the power that a receiver with a specific orientation would observe at this point. \n\nPlease note that the actual class structure, properties, and methods of CoverageMap would depend on the specific implementation within the Sionna package, which would need to be verified from the Sionna documentation or source code. This is only a hypothetical explanation based on general ray tracing principles."
"To decode a set of log-likelihood ratio (LLR) values using the TurboDecoder in the Sionna package, you need to provide an array-like object, `llr`, containing LLR values for a binary convolutional turbo code. The input requirements for decoding with TurboDecoder are:\n\n- `llr` is a tensor containing LLR values with a specific meaning and of a specific shape. The LLR tensor has a float datatype. The last dimension must be 3 and it represents the LLR for the channels `a`, `b`, and `c` respectively.\n\nThe output of TurboDecoder is affected by the `hard_out` parameter. If `hard_out=True`, the decoder outputs hard decisions (i.e., bit-wise decisions). In this case, the output is of shape `[..., k]` and datatype `tf.float32`. It contains the estimated sequence of information bits. If `hard_out=False`, the decoder provides the soft-information (i.e., LLR values) of the estimated codeword. The output is of shape `[..., n]` and datatype `tf.float32`. It contains the LLR values of the estimated codeword bits.\n\nInput requirement summarized for decoding with TurboDecoder:\n\n- `llr`: Tensor containing LLR values, tf.float32, shape=[batch_size, num_turbo_symbols, 3].\n- `hard_out`: Boolean, if `True`, decoder outputs hard bits; otherwise, soft-values are decoded.\n\nOutput: Array of LLR values or array of hard bits, corresponding to the information bits of the input codeword sequence."
"Here is the detailed information of sionna.rt.antenna.iso_pattern:  [sionna.rt.antenna.iso_pattern(theta, phi, slant_angle=0.0, polarization_model=2, dtype=tf.complex64)](https://nvlabs.github.io/sionna/api/sionna/rt/antenna.html#sionna.rt.antenna.iso_pattern)\n\nIsotropic antenna pattern with linear polarizarion\n\nInput\n\ntheta (array_like, float) \u2013 Zenith angles wrapped within [0, \u03c0] [rad]\n\nphi (array_like, float) \u2013 Azimuth angles wrapped within [-\u03c0, \u03c0) [rad]\n\nslant_angle (float) \u2013 Slant angle of the linear polarization [rad]. A slant angle of zero means vertical polarization. Defaults to 0.\n\npolarization_model (int, one of [1,2]) \u2013 Polarization model to be used. Options 1 and 2 refer to polarization_model_1() and polarization_model_2(), respectively. Defaults to 2.\n\ndtype (tf.complex64 or tf.complex128) \u2013 Datatype. Defaults to tf.complex64.\n\nOutput\n\nc_theta (array_like, complex) \u2013 Zenith pattern\n\nc_phi (array_like, complex) \u2013 Azimuth pattern\n\nsource code:\n```python\ndef iso_pattern(theta, phi, slant_angle=0.0,\n                polarization_model=2, dtype=tf.complex64):\n    r\"\"\"\n    Isotropic antenna pattern with linear polarizarion\n\n    Input\n    -----\n    theta: array_like, float\n        Zenith angles wrapped within [0,pi] [rad]\n\n    phi: array_like, float\n        Azimuth angles wrapped within [-pi, pi) [rad]\n\n    slant_angle: float\n        Slant angle of the linear polarization [rad].\n        A slant angle of zero means vertical polarization.\n        Defaults to 0.\n\n    polarization_model: int, one of [1,2]\n        Polarization model to be used. Options :func:`polarization_model_1`\n        and :func:`polarization_model_2`,\n        Defaults to polarization_model_2`\n\n    dtype : tf.complex64 or tf.complex128\n        Datatype.\n        Defaults to `tf.complex64`\n\n    Output\n    ------\n    c_theta: array_like, complex\n        Zenith pattern\n\n    c_phi: array_like, complex\n        Azimuth pattern\n    \"\"\"\n    rdtype = dtype.real_dtype\n    k = tf.cast(np.sqrt(1/2), dtype)\n    theta = tf.cast(theta, rdtype)\n    phi = tf.cast(phi, rdtype)\n    slant_angle = tf.cast(slant_angle, rdtype)\n    if not theta.shape== phi.shape:\n        raise ValueError(\"theta and phi must have the same shape.\")\n    if polarization_model==1:\n        c_theta = k*tf.cos(theta)\n        c_phi = k*tf.cos(phi)\n    elif polarization_model==2:\n        c_theta = k*(tf.cos(theta)*tf.cos(slant_angle)\n                     - tf.sin(theta)*tf.sin(slant_angle)*tf.cos(phi))\n        c_phi = k*(tf.cos(theta)*tf.sin(slant_angle)\n                   *tf.sin(phi) + tf.sin(theta)*tf.cos(slant_angle))\n    return c_theta, c_phi\n```"
"Here's how to use the \"ApplyTimeChannel\" and \"ApplyOFDMChannel\" Keras layers as part of the simulation process:\n\nSimulation Process:\n1. Import necessary packages and modules. This includes TensorFlow, Sionna, and other utilities mentioned in the context that are required for the simulation.\n2. Define and create the necessary channel components. This includes the channel encoder, channel model (eg. AWGN), and the channel decoder. These are typically provided as part of the simulation or modeling process.\n3. Define the `ApplyTimeChannel` layer or `ApplyOFDMChannel` layer. These are used to apply the channel model to the input signal sequence.  \n4. In a custom simulation function or class, generate a channel output by passing the channel input and noise variance to the `ApplyTimeChannel` or `ApplyOFDMChannel` layer.  \n5. Calculate the bit error rate (BER) by comparing the transmitted bits and the recovered bits.\n\nExample Code Snippet:\n\n```python\n# Necessary components\nimport tensorflow as tf\nfrom sionna.channel import ApplyTimeChannel, AWGN\n\n# Parameters\nnum_bits_per_symbol = 2 # QPSK\norder = 4\nsequence_length = 1024\ntaps = 128\nsymbol_length = 80\nebno_db = 15\n\n# Create the channel\nchannel = ApplyTimeChannel(AWGN())\n\n# ... Other components and parameters ...\n\n# In a custom simulation function or class\n# Generate the channel output\n# 'enc_bits' is the transmitted bits, 'no' is the noise variance\ny = channel([enc_bits, no])  # For single-input models, use: y = channel(no)\n\n# Calculate the BER\n# 'est_bits' is the estimated bits, 'src_bits' is the transmitted bits\nber = compute_ber(src_bits, est_bits)\n```\n\nPlease note that the code provided is a general template and may need to be adjusted based on the specific requirements of your simulation. This includes the parameters passed to the `ApplyTimeChannel` or `ApplyOFDMChannel` layer, the specific simulation process, and any additional steps such as encoding and decoding."
"The `Demapper` class from the Sionna library is used to compute log-likelihood ratios (LLRs) or hard-decisions on bits for a tensor of received symbols. Several parameters can be provided to customize the demapping process, including the demapping method, the constellation type, the number of bits per constellation symbol, the constellation, the data type, and any additional keyword arguments.\n\nTo compute the LLRs with the `Demapper` class, you would instantiate a `Demapper` object with the desired configuration, and then call this object with the tensor of received symbols as an argument. The LLRs can be either soft-decision or hard-decision and whether they are computed with or without prior knowledge of the bits.\n\nHere's a basic step-by-step guide on how to compute LLRs with the `Demapper` class:\n\n1. Import the `Demapper` class from the appropriate Sionna module.\n```python\nfrom sionna.mapping import Demapper\n```\n\n2. Define the demapping parameters. In this case, the demapping method is \"app\", the constellation type is \"qam\", the number of bits per constellation symbol is 4, the constellation is `constellation`, soft-decision LLRs are computed, and neither the symbols nor the LLRs are assumed to have prior knowledge.\n```python\ndemapping_method = \"app\"\nconstellation_type = \"qam\"\nnum_bits_per_symbol = 4\ndemapper = Demapper(demapping_method, constellation_type, num_bits_per_symbol, constellation=constellation, hard_out=False, with_prior=False, dtype=tf.complex64)\n```\n\n3. Compute the LLRs. Replace `y` with your actual received symbols.\n```python\nllrs = demapper(y)\n```\n\nThe `Demapper` class is designed to be flexible and customizable. You can use it to compute LLRs for a wide range of communication scenarios with different demapping methods and constellation types. Make sure to refer to the Sionna documentation for more details on how to use the `Demapper` class and the accepted parameter values."
"To obtain the Channel Impulse Responses (CIRs) in the model, you need to follow these steps:\n\n1. First, create the desired channel model (eg. RayleighBlockFading, TDL, CDL, UMi, UMa, RMa). This is done using the various classes provided in the context, such as `RayleighBlockFading` or `TDL`. You need to provide the model, the spread of nominal delay in picoseconds, and the carrier frequency in Hz. \n\n2. Once the channel model is created, it is used to generate a batch of CIRs. This is done by calling the channel model object with the batch size. The CIRs are generated when an instance of a channel model class is called with a specified batch size.\n\n3. The generated CIRs can be converted to the frequency domain or time domain. This conversion is done using the `cir_to_ofdm_channel` or `cir_to_time_channel` function, depending on whether you want to generate frequency domain or time domain channel responses. You need to provide the CIRs and the type of waveform (normal or zero padded).\n\n4. The generated frequency or time domain channel responses can then be applied to the channel input. This is done using the `ApplyOFDMChannel` or `ApplyTimeChannel` layer.\n\nHere is a code snippet from the context that demonstrates these steps:\n\n```python\n# Create a channel model\nchannel_model = RayleighBlockFading(num_rx=1,\n                                     num_rx_ant=32,\n                                     num_tx=8,\n                                     num_tx_ant=2)\n\n# Generate a batch of CIRs\nbatch_size = 64\ndelay_spread = 300e-9 # 300ns\ncir = channel_model(batch_size, delay_spread)\n```\n\nIn this snippet, a Rayleigh block fading model is created and used to generate a batch of CIRs. The CIRs are then converted to frequency domain channel responses. These responses are then applied to the channel input."
"Here is the detailed information of List2LLRSimple:   \n  \nSource code:   \n```python\nclass List2LLRSimple(List2LLR):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    List2LLRSimple\n    \n    Class that implements simple form of List2LLR, \n    as the underlying MIMO detector does not require all\n    the complexities.\n\n    This class is used with List2LLR which is used by the MIMO detectors\n    to compute LLRs.\n    \n    Parameters\n    ----------\n    None\n    \"\"\" # NOQA\n\n    def __init__(self):\n\n        super().__init__(\"simple\")\n```\n\n\nThe parameters of the class are: The method parameter, which specifies the method used to compute the LLRs. \n\nThe input of the class instance is:\n\n-  **dists** ([,num_streams], tf.float) - A tensor of distance metrics for each symbol.\n-  **path_inds** ([,num_streams,num_paths], tf.int32) - A tensor of symbol indices for every stream of every path.\n-  **path_syms** ([,num_path,num_streams], tf.complex) - A tensor of constellation symbols for every stream of every path.\n-  **is_valid** ([,num_paths], tf.bool) - A tensor indicating whether the paths are valid or not. This is used to mask out the symbols of invalid paths.\n-  **num_bits_per_symbol** (tf.int32) - The number of bits per constellation symbol.\n\nThe output of the class instance is:\n\n-  **llr** ([,num_streams,num_bits_per_symbol], tf.float) - Computed LLRs.\n\n    class List2LLRMax(List2LLRSimple):\n    # pylint: disable=line-too-long\n    r\"\"\"List2LLRMax\n    \n    This class defines a parameterized callable to compute the LLRs\n    as the maxlog solution on a list of candidate vectors (or paths),\n    as, for instance, provided by a Viterbi detector.\n    \n    The maxlog LLR for the :math:`i\\text{th}` bit is then given by\n    \n    .. math::\n        LLR(i) = \\ln\\left(\\frac{\\sum_{j \\in \\mathcal{J}_{i,0}}^N \\hat{c}_{j,i}}{\\sum_{j \\in \\mathcal{J}_{i,1}}^N \\hat{c}_{j,i}}\\right)\n    \n    where :math:`\\mathcal{J}_{i,b}^N` is the set of :math:`N` indices for which\n    :math:`c_{j,i} = b`.\n    \n    This class is equivalent to `List2LLRSimple` except that it uses maxlog\n    instead of a log-sum-exp operation. It is used to test the behavior of\n    custom MIMO detectors that implement maxlog-like update rules.\n    \n    Input\n    -----\n    dists : [,N], tf.float\n        A tensor of distance metrics for each symbol.\n\n    path_inds : [,num_streams,num_paths], tf.int32\n        A tensor of symbol indices for every stream of every path.\n\n    path_syms : [,num_path,num_streams], tf.complex\n        A tensor of constellation symbols for every stream of every path.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol.\n\n    Output\n    ------\n    llr : [,num_streams,num_bits_per_symbol], tf.float\n        Computed LLRs.\n    \"\"\"\n    \n    def __call__(self, dists, path_inds, path_syms, is_valid):\n        # pylint: disable=line-too-long\n        \"\"\"Compute LLRs from a (possibly pruned) list of candidate solutions (or paths)\n        as provided by a MIMO detector.\n\n        The resulting LLR for the :math:`i\\text{th}` bit is either\n\n        .. math::\n                LLR(i) = \\ln\\left(\\sum_{j \\in \\mathcal{J}_{i,0}}^N \\exp\\left(\\hat{c}_{j,i}\\right)\\right)\n\n        or (for the class parameter `method` equal to \"maxlog\")\n\n        .. math::\n                LLR(i) = \\max\\left(\\left\\{\\hat{c}_{j,1} - \\hat{c}_{j,0} : j \\in \\mathcal{J}_{i,0}\\right\\},\n                        \\left\\{\\hat{c}_{j,0} - \\hat{c}_{j,1} : j \\in \\mathcal{J}_{i,1}\\right\\}\n                        \\right).\"\"\"\n\n        # Maxlog solution\n        llr = tf.reduce_max(self._maxlog(dists, path_inds, path_syms, is_valid), -1)\n\n        return llr\n```  \n  "
"Here is the definition of MaximumLikelihoodDetector: sionna.ofdm.MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#MaximumLikelihoodDetector)  \n\n```python\nclass MaximumLikelihoodDetector(OFDMDetector):\n    # pylint: disable=line-too-long\n    r\"\"\"MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    Maximum-likelihood (ML) detection for OFDM MIMO transmissions.\n\n    This layer implements maximum-likelihood (ML) detection\n    for OFDM MIMO transmissions. Both ML detection of symbols or bits with\n    either soft- or hard-decisions are supported. The OFDM and stream\n    configuration are provided by a :class:`~sionna.ofdm.ResourceGrid` and\n    :class:`~sionna.mimo.StreamManagement` instance, respectively. The\n    actual detector is an instance of :class:`~sionna.mimo.MaximumLikelihoodDetector`.\n\n    Parameters\n    ----------\n    output : One of [\"bit\", \"symbol\"], str\n        Type of output, either bits or symbols. Whether soft- or\n        hard-decisions are returned can be configured with the\n        ``hard_out`` flag.\n\n    demapping_method : One of [\"app\", \"maxlog\"], str\n        Demapping method used\n\n    resource_grid : ResourceGrid\n        Instance of :class:`~sionna.ofdm.ResourceGrid`\n\n    stream_management : StreamManagement\n        Instance of :class:`~sionna.mimo.StreamManagement`\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        Instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the detector computes hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (DType)\n        The dtype of `y`. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    ------\n    (y, h_hat, err_var, no) :\n        Tuple:\n\n    y : [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex\n        Received OFDM resource grid after cyclic prefix removal and FFT\n\n    h_hat : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex\n        Channel estimates for all streams from all transmitters\n\n    err_var : [Broadcastable to shape of ``h_hat``], tf.float\n        Variance of the channel estimation error\n\n    no : [batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float\n        Variance of the AWGN noise\n\n    Output\n    ------\n    One of:\n\n    : [batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream if ``output`` equals `\"bit\"`.\n\n    : [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int\n        Logits or hard-decisions for constellation symbols for every stream\n        if ``output`` equals `\"symbol\"`.\n        Hard-decisions correspond to the symbol indices.\n    \"\"\"\n    def __init__(self,\n                 output,\n                 demapping_method,\n                 resource_grid,\n                 stream_management,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(   output=output,\n                            demapping_method=demapping_method,\n                            detector=MaximumLikelihoodDetector_,\n                            loss=None,\n                            resource_grid=resource_grid,\n                            stream_management=stream_management,\n                            constellation_type=constellation_type,\n                            num_bits_per_symbol=num_bits_per_symbol,\n                            constellation=constellation,\n                            hard_out=hard_out,\n                            dtype=dtype,\n                            **kwargs)\n```\n\n\n```python\nclass MaximumLikelihoodDetector_(OFDMDetector):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Maximum-likelihood detector for OFDM MIMO transmissions.\n\n    This class is a computerized layer that implements\n    maximum-likelihood (ML) detection for OFDM MIMO transmissions.\n    Both detection of symbols or bits with either\n    soft- or hard-decisions are supported. The OFDM and stream\n    configuration are provided by a :class:`~sionna.ofdm.ResourceGrid` and\n    :class:`~sionna.mimo.StreamManagement` instance, respectively.\n\n    The class is implemented as a layer of a Keras model.\n\n    Parameters\n    ----------\n    resource_grid : ResourceGrid\n        Instance of :class:`~sionna.ofdm.ResourceGrid`\n\n    stream_management : StreamManagement\n        Instance of :class:`~sionna.mimo.StreamManagement`\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        Instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    output : One of [\"bit\", \"symbol\"], str\n        Type of output, either bits or symbols. Whether soft- or\n        hard-decisions are returned can be configured with the\n        ``hard_out`` flag.\n\n    hard_out : bool\n        If `True`, the detector computes hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (DType)\n        The dtype of `y`. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    ------\n    (y, h_hat, prior, err_var, no) :\n        Tuple:\n\n    y : [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex\n        Received OFDM resource grid after cyclic prefix removal and FFT\n\n    h_hat : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex\n        Channel estimates for all streams from all transmitters\n\n    prior : [batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float\n        Prior of the transmitted symbols.\n        If ``output`` equals `\"bit\"`, LLRs of the transmitted bits are expected.\n        If ``output`` equals `\"symbol\"`, logits of the transmitted constellation points are expected.\n\n    err_var : [Broadcastable to shape of ``h_hat``], tf.float\n        Variance of the channel estimation error\n\n    no : [batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float\n        Variance of the AWGN noise\n\n    Output\n    ------\n    One of:\n\n    : [batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream if ``output`` equals `\"bit\"`.\n\n    : [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int\n        Logits or hard-decisions for constellation symbols for every stream\n        if ``output`` equals `\"symbol\"`.\n        Hard-decisions correspond to the symbol indices.\n    \"\"\"\n    def __init__(self,\n                 resource_grid,\n                 stream_management,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 output=\"bit\",\n                 hard_out=False,\n                 dtype=tf.complex64,\n                **kwargs):\n        super().__init__(  resource_grid=resource_grid,\n                            stream_management=stream_management,\n                            constellation_type=constellation_type,\n                            num_bits_per_symbol=num_bits_per_symbol,\n                            constellation=constellation,\n                            detector=\"ml\",\n                            output=output,\n                            hard_out=hard_out,\n                            dtype=dtype,\n                            **kwargs)\n```"
"Here is the detailed information:   \nSionna currently includes models of the 5G channel which enable various simulation\nscenarios (listed in the table below) due to the multitude of parameters that can be\nconfigured. This documentation section describes these different parameters and how\nthey can be configured.\n5G system level simulations with Sionna rely on the specification of different 3GPP\n[ETSI] norms which can be selected by setting the system_level_sim parameter of\nsionna.channel.rank.indoor_5g_ranking() and sionna.channel.rank.mimo_5g_ranking() to\neither \"3GPP\" or \"OTO\". The former applies the specification of 3GPP for system level\nsimulations according to [3GPP38.901_system_level] and [3GPP37.901],\nwhereas the latter uses the specification from [EKr_scratch].\nPlease note that the OTO model only provides channel impulse responses but no\ntime evolution of the channel, hence requiring additional processing to generate\nchannel responses. In contrast, the 3GPP model provides channel responses directly.\n\nThe 3GPP specification is based on carrier frequencies of 2.5 GHz, 3.5 GHz, and 28 GHz.\nThe OTO specification is based on a carrier frequency of 2.14 GHz.\n\nThe 3GPP specification is in general supposed to emulate the O2 channel in the 2.6 GHz\nband which has a 3.5 GHz carrier frequency. In case of the O2 channel, the RMa and UMi\nscenarios are combined in the event of Line-of-Sight (LoS) propagation due to reflection\noff buildings, resulting in the so-called RMa-UMi model. This is also the default model in\nSionna (see [3GPPTS38211]). However, it is also possible to use the UMi, RMa, or RMa\nscenarios separately.\n\nThe norm also significantly impacts which features are available. For example, only the\n3GPP specification provides beam management features.\n\nThe RAN specifications for 3.5 GHz and 28 GHz can be found in [3GPP38.141-3GPP38.901] and\n[3GPP38.331-3GPP38.900], respectively.\n\nPROPERTY DESCRIPTION\nIMPLEMENTATION Rank-based MIMO 5G channel model\nSUPPORTED SCENARIOS Carrier frequencies of 2.5 GHz, 3.5 GHz, 28 GHz Norms: \"3GPP\", \"OTO\" Scenario : \"rm_uma\", \"rm_overdense\", \"rm_in_h\", \"umim\", \"dl\", \"a2a\" Only \"3GPP\" in dl and ul carrier frequencies of 2.6 GHz, 3.5 GHz, 1.9 GHz, 800 MHz System level simulations:Tested for \"3GPP\" in dl and ulBeams included only for \"3GPP\"ERRORS Scenario \"rm_uma\" needs parameterSetIdx, which must be 0Scenario \"rm_overdense\" needs parameterSetIdx, which must be 0Scenario \"rm_in_h\" not supported for \"OTO\" Scenario \"a2a\" requires that the flag dualCarrier is set to True, and that the x- and y-direction have different carrier frequencies, which must be specified by the frequency parameter. Moreover, the antenna arrays of the transmitter and receiver should not be equal.dist_d 3.16 m is the smallest allowed value Example code doesn't show how to set dist_ds (which is required when using the \"rm_overdense\" or \"rm_in_h\" scenario) No check for RAN specifications 3.5 GHz or 28 GHz is included, although it is recommended to use the correct norm to ensure that the channel model is usable for these specifications. For 3.5 GHz, the flag inlte should be set to True to simulate the uplink with non-line-of-sight (NLoS) only. The link level models are only indicative of the real system and strongly depend on the scenario and the system setup. Not all 3GPP features are necessarily implemented, e.g., the PUSCH features depend on the carrier, DMRS configuration, and cell ID. The OTO scenario does not provide be directionality, i.e., all transmit directions are evaluated and summed to obtain the total transmit signal. This can be simulated by using multiple OtoChannel instances and appropriately scaling the amplitudes. The 3GPP scenario in Sionna uses the same carrier frequency for the x- and y-directions. Hence, it does not directly support scenarios with different frequencies. However, multiple ChannelModel instances can be used to simulate this. \nSOURCE CODE Scenario \"rm_uma\" needs parameterSetIdx, which must be 0Scenario \"rm_overdense\" needs parameterSetIdx, which must be 0Scenario \"rm_in_h\" not supported for \"OTO\" Scenario \"a2a\" requires that the flag dualCarrier is set to True, and that the x- and y-direction have different carrier frequencies, which must be specified by the frequency parameter. Moreover, the antenna arrays of the transmitter and receiver should dist_d 3.16 m is the smallest allowed value Example code doesn't show how to set dist_ds (which is required when using the \"rm_overdense\" or \"rm_in_h\" scenario) No check for RAN specifications 3.5 GHz or 28 GHz is included, although it is recommended to use the correct norm to ensure that the channel model is usable for these specifications. For 3.5 GHz, the flag inlte should be set to True to simulate the uplink with non-line-of-sight (NLoS) only. The link level models are only indicative of the real system and dist_d 3.16 m is the smallest allowed value Example code doesn't show how to set dist_ds (which is required when using the \"rm_overdense\" or \"rm_in_h\" scenario) No check for RAN specifications 3.5 GHz or 28 GHz is included, although it is recommended to use the correct norm to ensure that the channel model is dist_d 3.16 m is the smallest allowed value Example code doesn't show how to set dist_ds (which is required when using the \"rm_overdense\" or \"rm_in_h\" scenario) No check for RAN specifications 3.5 GHz or 28 GHz is included, although it is recommended to use the correct norm to ensure that the channel model is dist_d 3.16 m is the smallest allowed value Example code doesn't show how to set dist_ds (which is required when using the \"rm_overdense\" or \"rm_in_h\" scenario) No check for RAN specifications 3.5 GHz or 28 GHz is included, although it is recommended to use the correct norm to ensure that the channel model is dist_d 3.16 m is the smallest allowed value Example code doesn't show how to set dist_ds (which is required when using the \"rm_overdense\" or \"rm_in_h\" scenario) No check for RAN specifications 3.5 GHz or 28 GHz is included, although it is recommended to use the correct norm to ensure that the channel model is dist_d 3.16 m is the smallest allowed value Example code doesn't show how to set dist_ds (which is required when using the \"rm_overdense\" or \"rm_in_h\" scenario) No check for RAN specifications 3.5 GHz or 28 GHz is included, although it is recommended to use the correct norm to ensure that the channel model is dist_d 3.16 m is the smallest allowed value Example code doesn't show how to set dist_ds (which is required when using the \"rm_overdense\" or \"rm_in_h\" scenario) No check for RAN specifications 3.5 GHz or 28 GHz is included, although it is recommended to use the correct norm to ensure that the channel model is dist_d 3.16 m is the smallest allowed value Example code doesn't show how to set dist_ds (which is required when using the \"rm_overdense\" or \"rm_in_h\" scenario) No check for RAN specifications 3.5 GHz or 28 GHz is included, although it is recommended to use the correct norm to ensure that the channel model is dist_d 3.16 m is the smallest allowed value Example code doesn't show how to set dist_ds (which is required when using the \"rm_overdense\" or \"rm_in_h\" scenario) No check for RAN specifications 3.5 GHz or 28 GHz is included, although it is recommended to use the correct norm to ensure that the channel model is dist_d 3.16 m is the smallest allowed value Example code doesn't show how to set dist_ds (which is required when using the \"rm_overdense\" or \"rm_in_h\" scenario) No check for RAN specifications 3.5 GHz or 28 GHz is included, although it is recommended to use the correct norm to ensure that the channel model is dist_d 3.16 m is the smallest allowed value Example code doesn't show how to set dist_ds (which is required when using the \"rm_overdense\" or \"rm_in_h\" scenario) No check for RAN specifications 3.5 GHz or 28 GHz is included, although it is recommended to use the correct norm to ensure that the channel model is dist_d 3.16 m is the smallest allowed value Example code doesn't show how to set dist_ds (which is required when using the \"rm_overdense\" or \"rm_in_h\" scenario) No check for RAN specifications 3.5 GHz or 28 GHz is included, although it is recommended to use the correct norm to ensure that the channel model is dist_d 3.16 m is the smallest allowed value Example code doesn't show how to set dist_ds (which is required when using the \"rm_overdense\" or \"rm_in_h\" scenario) No check for RAN specifications 3.5 GHz or 28 GHz is included, although it is recommended to use the correct norm to ensure that the channel model is dist_d3.16 m is the smallest allowed value Example code doesn't show how to set dist_ds (which is required when using the \"rm_overdense\" or \"rm_in_h\" scenario) No check for RAN specifications 3.5 GHz or 28 GHz is included, although it is recommended to use the correct norm to ensure that the channel model is usable for these specifications. For 3.5 GHz, the flag inlte should be set to True to simulate the uplink with non-line-of-sight (NLoS) only. The link level models are only indicative of the real system and \n                                                     \n                                                        Channel modeling\n                                                      The following sections describe how the 5G channel model is configured in Sionna for different scenarios.\n3GPP Scenario \"rm_uma\"\nThe UMa model is configured with a carrier frequency of 3.5 GHz, which implies an OMinS spacing of 10 MHz. The setup is shown in the following code snippet.\n```python\nfrom sionna.channel import generate_3gpp_channel_model\n# Create the channel model\nchannel_model = generate_3gpp_channel_model(\"rm_uma\",\n                                              carrier_frequency=3.5e9,\n                                              o2i_model=\"low\",\n                                              direction=\"uplink\")\n```\n3GPP Scenario \"rm_overdense\"\nThe OMinS model is configured with a carrier frequency of 3.5 GHz, which implies an OMinS spacing of 15 kHz. The setup is shown in the following code snippet.\n```python\nfrom sionna.channel import generate_3gpp_channel_model\n# Create the channel model\nchannel_model = generate_3gpp_channel_model(\"rm_overdense\",\n                                              carrier_frequency=3.5e9)\n```\n3GPP Scenario \"rm_in_h\"\nThe inH model is configured with a carrier frequency of 3.5 GHz and a UT velocity of 10 m/s. The setup is shown in the following code snippet.\n```python\nfrom sionna.channel import generate_3gpp_channel_model\n# Create the channel model\nchannel_model = generate_3gpp_channel_model(\"rm_in_h\",\n                                              carrier_frequency=3.5e9,\n                                              ut_velocity=[10.0, 0.0, 0.0])\n```\n3GPP Scenario \"umim\"\nThe \"UMi\" model is configured with a carrier frequency of 3.5 GHz, a \"basestation\" ut velocity of 10 m/s, and a \"receiver\" ut velocity of 0 m/s. The setup is shown in the following code snippet.\n```python\nfrom sionna.channel import generate_3gpp_channel_model\n# Create the UMi channel model\nchannel_model = generate_3gpp_channel_model(\"umim\",\n                                              carrier_frequency=3.5e9,\n                                              ut_velocity=[10.0, 0.0, 0.0],\n                                              rx_tx_velocity_corr=True)\n```\n3GPP Scenario \"dl\"\nThe \"DL\" model is configured with a carrier frequency of 3.5 GHz and a 1 km cell radius. The setup is shown in the following code snippet.\n```python\nfrom sionna.channel import generate_3gpp_channel_model\n# Create the channel model\nchannel_model = generate_3gpp_channel_model(\"dl\",\n                                              carrier_frequency=3.5e9,\n                                              cell_type=\"large\",\n                                              urban_macro_params={\"inter_site_distance\" : 500},\n                                              panel_array_num_rows=4,\n                                              panel_array_num_cols=4)\n```\n3GPP Scenario \"a2a\"\nIn the A2A model, the carrier frequency is set to 3.5 GHz, the ut is assumed to be in the middle of the a and b streets, and the bs direction is defined by a single panel with a downtilt of 5 degrees.\n```python\nfrom sionna.channel import PanelArray\nfrom sionna.channel import generate_3gpp_channel_model\n# Specify the transmitter and receiver antenna arrays\narray = PanelArray(num_rows=1,\n                    num_cols=1,\n                    polarization=\"dual\",\n                    polarization_type=\"VH\",\n                    antenna_pattern=\"38.901\",\n                    carrier_frequency=3.5e9)\n# Create the channel model\nchannel_model = generate_3gpp_channel_model(\"a2a\",\n                                              carrier_frequency=3.5e9,\n                                              ut_array=array,\n                                              bs_array=array,\n                                              los=True)\n```\n\n[3GPPTS38211_system_level]: https://www.3gpp.org/ftp/Specs/archive/38_series/38.211/try3GPPTS38211_system_level.pdf\n[3GPPTS37101]: https://www.3gpp.org/ftp/Specs/archive/37_series/37.121/try3GPPTS37101.zip\n[3GPPTS37001]: https://www.3gpp.org/ftp/Specs/archive/37_series/37.001/try3GPPTS37001.zip\n[EKr_scratch]: https://kr.ncbrt.wiasberlin.de/realistic-ota/uploads-to-realistic-ota/model-specifications-ekr_scratch_v1.0.pdf\n[3GPPTS38211]: https://www.3gpp.org/ftp/Specs/archive/38_series/38.211/try3GPPTS38211.pdf\n[IEEE80211]: https://ieeexplore.ieee.org/abstract/document/8115639\n[KEHR_scratch]: https://kr.ncbrt.wiasberlin.de/realistic-ota/uploads-to-realistic-ota/model-specifications-kehr_scratch_v1.0.pdf\n[OTO]: https://www.3gpp.org/ftp/Specs/archive/37_series/37.900/3GPP_TS_37.900_-_Scenario_Models_for_IFHG_System_Level_Simulation_v16.0.0.pdf\n[Man431_scratch]: https://kr.ncbrt.wiasberlin.de/realistic-ota/uploads-to-realistic-ota/manet-431_scratch_v1.0.pdfAlgorithmException                         \u5206\u4eab\u94fe\u63a5\n\n[rank.indoor_5g_ranking]: https://nvlabs.github.io/sionna/_modules/sionna/channel/rank/indoor_5g_ranking.html#indoor_5g_ranking)\nfunction generate_5g_ranking(ue_array, bs_array, carrier_frequency, o2i_model, dtype=tf.complex64)\nGenerates 5G ranking curves for the transmitter and receiver.\n\nThe ranking curves consist of two transmit and receiver antenna arrays whose antenna pattern is defined as a uniform antenna array (UAA). All cross- and co-pol antenna patterns are computed using the Oulu channel model [EKR_scratch].\n\nThe EKR model requires to specify the element pattern of the UAA. The function generate_ranking() returns the combination of two such patterns that maximizes the spectral efficiency [rank.utils].\n\n**Input**\n\n- `ue_array` (PanelArray): Antenna array used by the receivers located at the users\u2019 side. Only single-antenna users are supported.\n- `bs_array` (PanelArray): Antenna array used by the transmitters located at the base station side.\n- `carrier_frequency` (float): Carrier frequency in Hz.\n- `o2i_model` (str): Outdoor-to-indoor loss model. One of \"low\" | \"mid\" | \"high\".\n- `dtype` (tf.Dtype): Datatype used for all computations. Defaults to tf.complex64.\n\n**Output**\n\n- `rx_ranking` (ndarray of complex): Ranking curve from the perspective of the receiver. Notches can be observed for some antenna patterns.\n- `tx_ranking` (ndarray of complex): Ranking curve from the perspective of the transmitter. Notches can be observed for some antenna patterns.\n\n[Open in colab](https://colab.research.google.com/github/NVlabs/sionna/blob/main/examples/Sionna_tutorial.ipynb)"
"To run the channel modeling in Sionna, you need to follow these steps:\n\n1. **Import necessary libraries and configure GPU settings**: Import the necessary libraries for the operation. Configure the GPU settings to use only a single GPU and allocate only as much memory as needed.\n\n2. **Define simulation parameters**: Define the parameters for the simulation. This includes the number of transmit and receive antennas, the number of OFDM symbols, the FFT size, the subcarrier spacing, the carrier frequency, the speed of sound, the minimum delay, the sampling frequency, and the number of samples.\n\n3. **Define the `compute_ber` function**: This function is used to compute the bit error rate (BER). It takes the transmitted and received signals as input, and returns the carrier frequency, the speed of sound, the signal length, the threshold, the number of bits per symbol, and the demapping method.\n\n4. **Generate a batch of random QAM symbols**: Generate a batch of random QAM symbols. The number of bits per symbol is configured to be 2.\n\n5. **Create an instance of the `ResourceGrid` class**: Create an instance of the `ResourceGrid` class. This class defines a grid where resource elements are mapped onto.\n\n6. **Define the LS channel estimator, the LMMSE equilization function, and the receive processing function**: The LS channel estimator estimates the channel based on the pilot symbols. The LMMSE equalization function is used to compute soft-symbols. The receive processing function computes hard decisions from the computed log-likelihood ratios.\n\n7. **Simulate an OFDM MIMO transmission over the CP-cycles**: Simulate an OFDM MIMO transmission over the CP-cycles. The simulation is done in two modes: in the first mode, the transmitter generates a new set of precoded data symbols at each transmission. In the second mode, the transmitter keeps the same set of precoded data symbols for the entire batch of CP-cycles.\n\n8. **Compute the BER**: Compute the BER for different values of Eb/No. This is done by calling the `compute_ber` function with the transmitted bits and the receiver's output.\n\nRemember to use the appropriate Sionna APIs and refer to the Sionna documentation for detailed instructions."
"Here is the detailed information of load_alist:   \n[sionna.fec.utils.load_alist(path)](https://nvlabs.github.io/sionna/api/sionna/fec/utils.html#load_alist)  \n\nRead alist-file [MacKay] and return nested list describing the\nparity-check matrix of a code.\n\nMany code examples can be found in [UniKL].\n\nInput\n\n   path (str) \u2013 Path to file to be loaded.\n\nOutput\n\n   alist \u2013 A nested list containing the imported alist data.\n\nsource code:  \n```python\ndef load_alist(path):\n    # pylint: disable=anomalous-backslash-in-string\n    r\"\"\"Read `alist`-file [MacKay]_ and return nested list describing the\n    parity-check matrix of a code.\n\n    Many code examples can be found in :doc:`UniKL`.\n\n    Input\n    -----\n        path: str\n            Path to file to be loaded\n\n    Output\n    -----\n        alist:\n            A nested list containing the imported alist data.\n    \"\"\"\n    with open(path, 'r') as file:\n        alisting = file.read().split()\n    alist = []\n    for row in alisting:\n        if row[0] in ('c', 'x'):\n            continue\n        elif row[0]=='0':\n            alist.append(0)\n        elif row[0]=='1':\n            alist.append(1)\n        else:\n            alist.append(int(row))\n    return alist\n```"
"Here are some useful links of it:\n\n[Overview of the](https://nvlabs.github.io/sionna/api/nr.html) 5G NR PUSCH Tutorial\n\n[Interactive 5G NR PUSCH Tutorial](https://colab.research.google.com/github/nvlabs/sionna/blob/main/examples/5G_NR_PUSCH_Tutorial.ipynb)\n\n[Run in Google Colab](https://colab.research.google.com/github/nvlabs/sionna/blob/main/examples/5G_NR_PUSCH_Tutorial.ipynb)\n\n[Run on GPU via Google Colab](https://colab.research.google.com/github/nvlabs/sionna/blob/main/examples/5G_NR_PUSCH_Tutorial.ipynb)\n\n[Run in Jupyter Notebook](https://nvlabs.github.io/sionna/api/nr.html#pusch)"
"The `cameras` property of the Scene class provides a list of all the cameras that are currently a part of the scene. These cameras can either be defined in the scene file or instantiated using the API. \n\nEach camera defines a position and view direction for rendering the scene. You can switch between cameras for rendering or list the cameras to see which ones are available. For example, if a scene has two cameras named \"cam0\" and \"cam1\", you can switch to \"cam1\" using the `render(\"cam1\")` function.\n\nA new camera can be instantiated by creating a new `Camera` object, giving it a name and specifying its position. The `look_at` method can be used to point the new camera at a specific target. After defining the new camera, it needs to be added to the scene using `scene.add(cam)`. \n\nCameras play a crucial role in rendering the scene and providing different perspectives. This capability is particularly useful in visualizing and debugging scenes."
"Here is the detailed information of RaisedCosineFilter:   \n  \n[sionna.signal.RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, \\*\\*kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/signal/filter.html#RaisedCosineFilter)  \n\n### Parameters\n\n- `span_in_symbols` (int): Filter span measured as number of symbols.\n- `samples_per_symbol` (int): Number of samples per symbol, i.e., the oversampling factor.\n- `beta` (float): Roll-off factor. Must be in the range $[0,1]$.\n- `window` (Window or string ([\"hann\", \"hamming\", \"blackman\"])): The window function applied to the filter coefficients. If a string, it should be one of [\"hann\", \"hamming\", \"blackman\"]. Custom windows must be provided as an instance of Window.\n- `normalize` (bool): If True, the filter is normalized to have unit power. Defaults to True.\n- `trainable` (bool): If True, the filter coefficients are trainable variables. Defaults to False.\n- `dtype` (tf.DType): The dtype of the filter coefficients. Defaults to tf.float32.\n\n### Input\n\n- `x` ([..., N], tf.complex or tf.float): The input to which the filter is applied. The filter is applied along the last dimension.\n- `padding` (string ([\"full\", \"valid\", \"same\"])): Padding mode for convolving x and the filter. Must be \"full\", \"valid\", or \"same\". Defaults to \"full\".\n- `conjugate` (bool): If True, the complex conjugate of the filter is applied. Defaults to False.\n\n### Output\n\n- `y` ([..., M], tf.complex or tf.float): Filtered input. It is tf.float only if both x and the filter are tf.float. It is tf.complex otherwise. The length M depends on the padding."
"Link of the source code: https://nvlabs.github.io/sionna/_modules/sionna/signal/upsampling.html#Upsampling\n\nClass: `Upsampling(samples_per_symbol, lpf_length, lpf_cutoff_freq, lpf_norm=True, return_seq=False, dtype=tf.complex64, **kwargs)`\n\nUpsample a baseband signal using the insertion of zeros and a low-pass filter.\n\nThis layer inserts a specified number of zeros between consecutive symbols of a baseband signal and then applies a low-pass filter of length lpf_length to it. The provided number of samples per symbol, the filter length, and the filter cut-off frequency determine the filter coefficients that are used for the upsampling process.\n\n### Parameters\n\n- `samples_per_symbol` (int): The number of samples per symbol, i.e., the upsampling factor.\n- `lpf_length` (int): The length of the low-pass filter, i.e., the number of filter coefficients.\n- `lpf_cutoff_freq` (float): The cut-off frequency of the low-pass filter in terms of the normalized Nyquist frequency. It must be in the range (0, 0.5).\n- `lpf_norm` (bool): If True, the filter is normalized to have unit power. Defaults to True.\n- `return_seq` (bool): If True, the full upsampled sequence is returned. If False, only the upsampled symbols are returned. Defaults to False.\n- `dtype` (tf.Dtype): The dtype of the input and output. Defaults to tf.complex64.\n\n### Input\n\n- `x` ([..., n], tf.complex64): The baseband signals to upsample.\n\n### Output\n\n- `y` ([..., n * samples_per_symbol], tf.complex64 or tf.comcomplex128): The upsampled baseband signals. If `return_seq` is True, the full upsampled sequence is returned."
"The `polarization_model_1` and `polarization_model_2` functions in the `sionna.rt.antenna` module are intended to transform antenna patterns into corresponding linearly polarized patterns with defined zenith angles (\u03b8) and azimuth angles (\u03c6). These functions are primarily designed for use with antenna patterns that are defined as either functions or tabulated values.\n\nThe key inputs for both of these functions are:\n\n- `c_tilde_theta`: The zenith pattern to be transformed. This can either be a function or a value array defining the zenith pattern.\n- `slant_angle`: Defining the slant angle for the linear polarization. This can be a float value.\n- Other parameters that might be required, depending on the specific model used.\n\nThe output of these functions is two zenith patterns (c_theta and c_phi) corresponding to the pattern transformation for linear polarization.\n\nHere are usage examples of both models:\n\n\nFor `polarization_model_1`: \n```python\npolarization_model_1(c_tilde_theta, slant_angle)\n```\n\nFor `polarization_model_2`: \n```python\npolarization_model_2(c_tilde_theta, slant_angle)\n```\n\nThese functions are used in scenarios where it's necessary to change the polarization of an antenna to a defined linear polarization state. This might be required in situations where antennas need to be aligned or adjusted for specific purposes in wireless communication systems or other related technologies."
"Here is the detailed information of Mapper:   \n  \n[sionna.mapping.Mapper(constellation=None, binary=True, with_projection=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Mapper)  \n\nMaps a tensor of binary values to a tensor of points from a constellation.\n\nThis class is a high-level abstration of the task of mapping bits to constellation symbols. It can be used as a trainable variable, i.e., the constellation points are trainable.\n\n### Parameters\n\n- **constellation** (`Constellation`) : An instance of `Constellation` or None. In the latter case, `constellation` has to be specified through the `constellation` parameter.\n- **binary** (`bool`) : Defaults to True. Indicates whether the bit sequence should be binary or not. If set to True, the bit sequence will be mapped to a constellation according to the 3GPP standard.\n- **with_projection** (`bool`) : Defaults to False. Indicates whether all bits should be mapped to a constellation point and then projected to the real-valued domain. Projection on the real-valued domain can be useful to reduce the PAPR of the transmitted signal.\n- **dtype** (`tf.complex64, tf.complex128, `tf.DType) : The output dtype. Defaults to `tf.complex64`.\n\n### Input\n\n- **(b, n)**, `tf.float` : A tensor of binary values.\n\n    - **b** (`[..., n]` or `[..., n, 2]`, `tf.float`) : Tensor of binary values.\n    - **n** (`int`) : The number of bits per symbol, or, in the case of QAM, half the number of bits per symbol.\n\n### Output\n\n- **(b,)**, `tf.complex` : The mapped constellation symbols.\n\n### Properties\n\n- **`y`**\n  The last output of the mapping process. It is set to `None` if the `with_projection` is set to `False`.\n\n- **`x`**\n  The last input of the mapping process.\n  "
"The `LDPC5GEncoder` class from the Sionna library is used to instantiate an encoder for 5G New Radio (NR) compliant Low-Density Parity-Check (LDPC) codes. These codes are specified for a range of possible information bits (k) and a corresponding codeword length (n). The constructor method for `LDPC5GEncoder` has several parameters, which I outline below:\n\n- `k` (int): This is the number of information bits per codeword you want to encode. It must adhere to the constraints specified for 5G NR LDPC codes, which include, as of this writing, only two possible values: `k = 1456` or `k = 5764`.\n\n- `n` (int): This is the desired codeword length. For 5G NR, the codeword length is primarily preset to one of two possible values: `n = 1456` or `n =  5764`.\n\n- `seed` (None or int): This parameter is used to initialize the pseudo-random generator that is utilized to fill the parity-check matrix during the construction process. You can either supply an integer seed value for explicit seeding or provide `None` to prompt the system to generate an ad-hoc random seed.\n\n- `dtype` (tf.DType): Specifies the output data type of the layer. It defaults to `tf.float32`.\n\nThere are additional parameters that are specific to rate-matching procedures, which are governed by the structure of the `RadioNode` for which the encoder is instantiated. These parameters include `node_id`, `num_tx`, `tbs`, `tbs_index`, `target_coderate`, and `tmi`.\n\nTo instantiate an encoder, you would typically provide values for the `k` and `n` parameters. The other parameters, such as `seed`, `dtype`, etc., can either be supplied according to your needs or they can be left as their default values (`None`, `tf.float32`, respectively). When providing the k and n values, make sure they adhere to the specifications set forth for 5G NR LDPC codes, as provided in the context documentation."
"- 'complex2real_vector': This function splits the complex-valued vector into its real and imaginary parts. It is used to transform a complex-valued equivalent representing of a real-valued into complex-valued equivalent in the MIMO (Multiple input, multiple output) detection algorithm.\n\n- 'real2complex_vector': This function merges a real-valued vector, consisting of the real and imaginary parts of a complex vector, into its complex-valued representation. It is the inverse operation of 'complex2real_vector'.\n\n- 'complex2real_matrix':  This function splits the complex-valued matrix into real and imaginary parts. It is used to transform a complex-valued equivalent representing of a real-valued into complex-valued equivalent in the MIMO (Multiple input, multiple output) detection algorithm.\n\n- 'real2complex_matrix': This function merges a real-valued matrix, consisting of the real and imaginary parts of a complex matrix, into its complex-valued representation. It is the inverse operation of 'complex2real_matrix'.\n\n- 'complex2real_covariance': This function splits the complex-valued covariance tensor into its real and imaginary parts. It used to transform complex-valued equivalent representing of a real-valued into complex-valued equivalent in the MIMO (Multiple input, multiple output) detection algorithm.\n\n- 'real2complex_covariance':  This function merges a real-valued covariance tensor, consisting of the real and imaginary parts of a complex covariance tensor, into its complex-valued representation. It is the inverse operation of 'complex2real_covariance'.\n\n- 'complex2real_channel': This function transforms a complex-valued MIMO channel into its real-valued equivalent. It is used to transform complex-valued representations into the MIMO detection algorithms.\n\n- 'real2complex_channel':  This function transforms a real-valued MIMO channel into its complex-valued equivalent. It is used to transform real-valued representations into the MIMO detection algorithms.\n\nFor each of these functions, the input and output are described along with their uses cases in the MIMO detection algorithm. The MIMO (Multiple input, multiple output) detection algorithm is extensively used in the 4G and 5G wireless communication networks for improving signal detection, data transmission, and reception. These functions are pivotal for maintaining the integrity and clarity of data being transmitted between devices in wireless communication networks."
"Here is the detailed information of FlatFadingChannel:   \nApplying random channel matrices to a vector input and adding AWGN.\n\nThis class combines GenerateFlatFadingChannel and ApplyFlatFadingChannel and computes the output of a flat-fading channel with AWGN.\n\nFor a given batch of input vectors  \ud835\udc31\u2208\u2102^K , the output is:\n\n\ud835\udc32=\ud835\udc07\ud835\udc31+\ud835\udc27\n\nwhere  \ud835\udc07\u2208\u2102^{M\u00d7K}  are the randomly generated flat-fading channel matrices, \ud835\udc27\u2208\u2102^{M} \\sim\ud835\udca9(0,\ud835\udc41)  is an AWGN vector that is optionally added.\n\nA SpatialCorrelation can be configured and the channel realizations optionally returned. This is useful to simulate receiver algorithms with perfect channel knowledge.\n\nParameters\n\n- **num_tx_ant** (int) \u2013 Number of transmit antennas.\n- **num_rx_ant** (int) \u2013 Number of receive antennas.\n- **add_awgn** (bool) \u2013 Indicates if AWGN noise should be added to the output. Defaults to True.\n- **spatial_corr** (SpatialCorrelation, None) \u2013 An instance of SpatialCorrelation or None. Defaults to None.\n- **dtype** (Complex tf.DType) \u2013 The dtype of the output. Defaults to tf.complex64.\n\nInput\n\n- **(x, no)** \u2013 Tuple:\n  - **x** ([batch_size, num_tx_ant], tf.complex) \u2013 Tensor of transmit vectors.\n  - **no** (Scalar or Tensor, tf.float) \u2013 The noise power no is per complex dimension. Only required if add_awgn is set to True. Will be broadcast to the dimensions of the channel output if needed.\n\nOutput\n\n- **(y, h)** \u2013 Tuple:\n  - **y** ([batch_size, num_rx_ant, num_tx_ant], tf.complex) \u2013 Channel output.\n  - **h** ([batch_size, num_rx_ant, num_tx_ant], tf.complex) \u2013 Channel realizations. Will only be returned if spatial_corr != None."
"Here is the definition of PilotPattern: sionna.ofdm.PilotPattern(mask, pilots, trainable=False)\n\nThis is the link of the source code: [PilotPattern](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/pilot_pattern.html#PilotPattern)\n\n```python\nclass PilotPattern(CompositeObject):\n    # pylint: disable=line-too-long\n    r\"\"\"pilot_pattern(mask, pilots, trainable=False)\n\n    Defines a pilot pattern composed of ``mask`` and ``pilots``.\n\n    Parameters\n    ----------\n    mask : Tensor\n        A boolean :math:`N_T \\times N_R \\times N_{\\text{OFDM}} \\times N_{\\text{subcarriers}}` tensor that indicates for each\n        ofdm symbol and subcarrier, if it is reserved for a pilot transmission by\n        one of the transmitters and their associated streams. If\n        ``trainable==True``, then ``mask`` can also be a\n        :math:`N_T \\times N_R \\times N_{\\text{OFDM}} \\times N_{\\text{subcarriers}} \\times N_\\text{stream}` tensor of boolean\n        that indicates for each individual pilot symbol of each transmitter and\n        its associated stream if it is reserved. In this case, the\n        number of streams :math:`N_\\text{stream}` must be equal to the number of\n        transmitted streams. It is assumed that all transmitters send pilot\n        sequences for all their streams.\n\n    pilots : Tensor\n        A complex :math:`N_T \\times N_R \\times N_{\\text{OFDM}} \\times N_{\\text{subcarriers}}` tensor of\n        that defines for each ofdm symbol and subcarrier the pilot symbols\n        to be transmitted.\n\n    trainable : bool\n        If `True`, the ``pilots`` will be used as :class:`~sionna.channel.PilotSequence` and\n        can be [possibly] trained. Defaults to `False`.\n\n    Note\n    ----\n    The parameters ``mask`` and ``pilots`` are used to instantiate a\n    :class:`~sionna.channel.PilotPattern`. Refer to its\n    documentation for further details.\n\n    Examples\n    --------\n    The following code snippet shows how to setup a custom :class:`~sionna.ofdm.PilotPattern` without\n    using the predefined nset that assumes a time-domain topology of transmitters\n    and streams.\n\n    >>> mask = np.zeros([num_tx, num_streams_per_tx, num_ofdm_symbols, num_subcarriers], dtype=bool)\n    >>> mask[0, 0, [2,11], :] = 1;\n    >>> num_ofdm_symbols = 14\n    >>> num_effective_subcarriers = 12\n    >>> pilots = np.zeros([num_tx, num_streams_per_tx, num_pilot_symbols], dtype=complex)\n    >>> pilots[0, 0, 0:12] = [1,1,1,1,1,1,1,1,1,1,1,1]\n    >>> pp = PilotPattern(mask, pilots)\n    >>> pp\n    <sionna.ofdm.pilot_pattern.PilotPattern object at 0x7f5d7851f160>\n\n    >>> pp.show()  # show non-zero elements of the pilot pattern\n\n    The next example shows how to setup a pilot pattern that\n    follows the time-frequency grid structure of :class:`~sionna.ofdm.ResourceGrid`:\n\n    >>> resource_grid = ResourceGrid()\n    >>> pp = PilotPattern(resource_grid=resource_grid)\n    r\"\"\"\n    def __init__(self, mask, pilots, trainable=False, normalize=False,\n                 resource_grid=None):\n\n        # Create an orthonormal pilot sequence per pilot symbol\n        num_orthogonal_pilots = np.minimum(pilots.shape[-1], mask.shape[-1])\n        pilots_ = create_orthogonal_pilots(num_orthogonal_pilots,\n                                            pilots.shape[-1],\n                                            normalize=normalize)\n        pilots = tf.constant(pilots_, dtype=pilots.dtype)\n        trainable_ = False\n\n        # Create PilotPattern instance\n        pp_ = PilotPatternFromPilots(mask, pilots, trainable,\n                                      normalize=normalize)\n        self._pp_norm = None\n\n        # Save attributes\n        self._mask = mask\n        self._normalize = normalize\n        self._trainable = trainable\n        self._resource_grid = None\n        self.pilots = pilots\n        self.trainable = trainable\n\n        # Invert normalization on init\n        if normalize:\n            self.normalize(trainable=False)\n\n        super().__init__(children=pp_)\n\n\n    @property\n    def mask(self):\n        r\"\"\"Mask of the pilot pattern.\n\n        Returns\n        -------\n        mask : :math:`N_T \\times N_R \\times N_{\\text{OFDM}} \\times N_{\\text{subcarriers}}` or :math:`N_T \\times N_R \\times N_{\\text{OFDM}} \\times N_{\\text{subcarriers}} \\times N_\\text{stream}`\n            where N_T is the number of transmitters, N_R the number of receivers, N_{\\text{OFDM}} the number of OFDM symbols,\n            N_{\\text{subcarriers}} the number of subcarriers,\n            and N_\\text{stream} the number of streams.\n        \"\"\"\n        return self._mask[self._pp_norm]\n\n    @property\n    def num_time_or_ofdm_symbols(self):\n        \"\"\"Number of time-frequency resource elements allocated to the pilot pattern.\"\"\"\n        return tf.reduce_sum(self._mask, axis=(2,3))\n\n    @property\n    def num_subcarriers(self):\n        \"\"\"Number of subcarriers of the mask.\"\"\"\n        return self._mask.shape[-1]\n\n    @property\n    def num_effective_subcarriers(self):\n        \"\"\"Number of subcarriers that can be used for data or pilot\n        symbols. For the OFDM :class:`~sionna.ofdm.ResourceGrid`, this\n        number can be smaller than the ``fft_size`` of the resource grid due\n        to nulled subcarriers or the DC carrier. \"\"\"\n        return self._mask.shape[-1]\n\n    @property\n    def num_ofdm_symbols(self):\n        \"\"\"Number of OFDM symbols of the mask.\"\"\"\n        return self._mask.shape[2]\n\n    @property\n    def num_pilot_symbols(self):\n        \"\"\"Number of pilot symbols per transmiter.\"\"\"\n        return self._mask.shape[-1]\n\n    @property\n    def num_tx(self):\n        \"Number of transmitters.\"\n        return self._mask.shape[0]\n\n    @property\n    def num_streams_per_tx(self):\n        \"Number of streams per transmitter.\"\n        return self._mask.shape[1]\n\n    @property\n    def pilots(self):\n        \"\"\"Pilots of the pilot pattern.\n\n        Returns\n        -------\n        pilots : :math:`N_T \\times N_R \\times N_{\\text{OFDM}} \\times N_{\\text{subcarriers}} \\times N_\\text{pilots}`\n            or : :math:`N_T \\times N_R \\times N_{\\text{OFDM}} \\times N_{\\text{subcarriers}} \\times N_\\text{stream} \\times N_\\text{pilots}`\n            where N_T is the number of transmitters, N_R the number of receivers, N_{\\text{OFDM}} the number of OFDM symbols,\n            N_{\\text{subcarriers}} the number of subcarriers,\n            and N_\\text{pilots} the number of pilot symbols.\n        \"\"\"\n        return self._children[0].pilots\n\n    @property\n    def pilots_tmp(self):\n        \"\"\"Deprecated. Please use :attr:`~PilotPattern.pilots` instead.\"\"\"\n        return self.pilots\n\n    @property\n    def pilots_mask(self):\n        \"\"\"Mask showing the ofdm symbols from which pilots are drawn.\n\n        This mask has the same shape as ``mask`` but shows only for each\n        ofdm symbol, from which of the ``num_pilot_symbols`` pilots per\n        transmitter, pilots are drawn.\n\n        Returns\n        -------\n        pilots_mask : :math:`N_T \\times N_R \\times N_{\\text{OFDM}} \\times N_\\text{stream} \\times N_\\text{pilots}`\n            or : :math:`N_T \\times N_R \\times N_{\\text{OFDM}} \\times N_\\text{subcarriers} \\times N_\\text{pilots} \\times N_\\text{stream}`\n        \"\"\"\n        return self._children[0].pilots_mask\n\n    @property\n    def pilots_zero(self):\n        \"\"\"Deprecated. Please use :attr:`~PilotPattern.pilots_mask` instead.\"\"\"\n        return self.pilots_mask\n\n    @property\n    def resource_grid(self):\n        \"\"\"Returns the :class:`~sionna.ofdm.ResourceGrid` to which this\n        pilot pattern is applied.\"\"\"\n        return self._resource_grid\n\n    ## Public methods\n\n    def show(self):\n        \"\"\"Show non-zero elements of the pilot pattern\n\n        Returns\n        -------\n        mask : :math:`N_T \\times N_R \\times N_{\\text{OFDM}} \\times N_{\\text{subcarriers}}` or :math:`N_T \\times N_R \\times N_{\\text{OFDM}} \\times N_{\\text{subcarriers}} \\times N_\\text{stream}`\n            An OFDM resource grid is used to indicate the non-zero elements\n            of the pilot pattern. For every transmitter and its associated\n            streams, the non-zeroed elements of the pilot symbols are indicated\n            by this resource grid.\n        \"\"\"\n        return self._children[0].show()\n```"
"In order to use Sionna, you need to import the necessary packages including TensorFlow and NumPy. Here is how you can do it:\n\n1. Import TensorFlow: You can import TensorFlow using the following code:\n```python\nimport tensorflow as tf\n```\nIn the context, it is recommended to use TensorFlow 2.10-2.15. You can also follow the [installation guide](https://www.tensorflow.org/install) on the TensorFlow website.\n\n2. Import NumPy: NumPy is a library for the Python programming language, which includes support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays. You can import NumPy using the following code:\n```python\nimport numpy as np\n```\n\n3. Import Sionna: After importing TensorFlow and NumPy, you can import Sionna. As per the context, Sionna requires TensorFlow 2.10-2.15 and Python 3.8-3.11. You can import Sionna using the following code:\n```python\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n```\nIn this code, we first try to import Sionna. If the package is not already installed (caught by the `ImportError`), we install it using pip and then import it.\n\nPlease make sure to use the correct package names and versions as per the context."
"Here is the detailed information of LinearInterpolator:   \n  \nSource code link: https://nvlabs.github.io/sionna/_modules/sionna/ofdm/channel_estimation.html#LinearInterpolator  \nsource code:\n```python\nclass LinearInterpolator(BaseChannelInterpolator):\n    # pylint: disable=line-too-long\n    r\"\"\"LinearInterpolator(pilot_pattern, time_avg=False)\n\n    Linear channel estimate interpolation on a resource grid.\n\n    This class computes for each element of an OFDM resource grid\n    a channel estimate based on ``num_pilots`` provided channel estimates\n    and error variances through linear interpolation.\n    It is assumed that the measurements were taken at the nonzero positions\n    of a :class:`~sionna.ofdm.PilotPattern`.\n\n    The interpolation is done first across sub-carriers and then\n    across OFDM symbols.\n    Parameters\n    ----------\n    pilot_pattern : PilotPattern\n        An instance of :class:`~sionna.ofdm.PilotPattern`\n\n    time_avg : bool\n        If enabled, measurements will be averaged across OFDM symbols\n        (i.e., time). This is useful for channels that do not vary\n        substantially over the duration of an OFDM frame.\n        Defaults to `False`.\n\n    Input\n    -----\n    h_hat : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex\n        Channel estimates for the pilot-carrying resource elements\n\n    err_var : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex\n        Channel estimation error variances for the pilot-carrying resource elements\n\n    Output\n    ------\n    h_hat : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], tf.complex\n        Channel estimates accross the entire resource grid for all\n        transmitters and streams\n\n    err_var : Same shape as ``h_hat``, tf.float\n        Channel estimation error variances accross the entire resource grid\n        for all transmitters and streams\n    \"\"\"\n    def __init__(self, pilot_pattern, time_avg=False):\n        super().__init__()\n\n        assert(pilot_pattern.num_pilot_symbols>0),\\\n            \"\"\"The pilot pattern cannot be empty\"\"\"\n\n        self._time_avg = time_avg\n\n        # Reshape mask to shape [-1,num_ofdm_symbols,fft_size]\n        mask = np.array(pilot_pattern.mask)\n        mask_shape = mask.shape # Store to reconstruct the original shape\n        mask = np.reshape(mask, [-1] + list(mask_shape[-2:]))\n\n        # Reshape the pilots to shape [-1, num_pilot_symbols]\n        pilots = pilot_pattern.pilots\n        pilots = np.reshape(pilots, [-1, pilots.shape[-1]])\n\n        # Compute pilot indices (across sub-carriers and OFDM symbols)\n        num_zero_pilots = np.sum(np.abs(pilots)==0, -1, keepdims=True)\n        not_pilot_ind = np.where(num_zero_pilots, np.ones_like(num_zero_pilots),\n                                 np.zeros_like(num_zero_pilots))\n        pilot_ind = np.where(np.abs(pilots)==0, np.ones_like(not_pilot_ind),\n                             np.zeros_like(not_pilot_ind))\n\n        # Compute indices for pilots\n        indices = np.zeros_like(mask, dtype=np.int32)\n        indices = indices - 1 # Set all indices to -1\n        indices = np.where(pilot_ind, indices, np.argmax(mask, -1))\n        indices = np.where(pilot_ind, indices, np.zeros_like(pilot_ind))\n        indices = np.squeeze(indices, -1)\n\n        # Compute indices for non-zero pilots\n        indices_pilots = np.where(pilots, indices, np.zeros_like(pilots))\n        indices_pilots = np.reshape(indices_pilots,\n                                    mask_shape[0:2] + pilots.shape)\n\n        # Sort indices based on pilot index\n        indices_pilots = np.sort(indices_pilots, axis=-1)\n\n        # Divide h_hat and err_var by the number of pilots per resource element\n        h_hat = np.array(h_hat)\n        err_var = np.array(err_var)\n        h_hat = np.where(mask, h_hat, 0)\n        err_var = np.where(mask, err_var, 0)\n        ne = np.sum(np.abs(pilots), axis=-1, keepdims=True)\n        h_hat = np.divide(h_hat, ne)\n        err_var = np.divide(err_var, ne)\n\n        # Reshape to put OFDM symbols as last dimension\n        h_hat = np.transpose(h_hat, axes=list(range(6))+[5])\n        err_var = np.transpose(err_var, axes=list(range(6))+[5])\n\n        self._mask = mask\n        self._pilots = pilots\n        self._pilot_ind = indices_pilots\n        self._h_hat = h_hat\n        self._err_var = err_var\n\n    def __call__(self, h_hat, err_var):\n\n        # Implement linear channel estimate interpolation\n        if self._time_avg\n            # Average over the time dimension\n            h_hat_ = tf.reduce_sum(h_hat, axis=5)\n            err_var_ = tf.reduce_sum(err_var, axis=5)\n            num_time_steps = tf.cast(h_hat.shape[5], h_hat_.dtype)\n            h_hat_ = tf.divide(h_hat_, num_time_steps)\n            err_var_ = tf.divide(err_var_, num_time_steps)\n        else:\n            h_hat_ = h_hat\n            err_var_ = err_var\n\n        # Reshape to shape: [-1, num_ofdm_symbols, fft_size]\n        batch_dims = tf.shape(h_hat)[:-2]\n        h_hat_ = tf.squeeze(h_hat_, axis=batch_dims)\n        err_var_ = tf.squeeze(err_var_, axis=batch_dims)\n\n        h_hat_interp, err_var_interp = super().interpolate(h_hat_, err_var_,\n                                                self._pilots, self._mask,\n                                                self._pilot_ind)\n\n        # Reshape to the expected shape\n        new_shape = np.array(self._mask.shape)\n        new_shape[0:-2] = new_shape[-2::-1] # Reshape like a resource grid\n        new_shape[-1] = new_shape[-2] # Move the last dimension to the position of\n        interp_shape = np.prod(new_shape[:-1]) # The last dimension is removed\n        h_hat_interp = tf.reshape(h_hat_interp, [interp_shape, new_shape[-1]])\n        err_var_interp = tf.reshape(err_var_interp, [interp_shape, new_shape[-1]])\n\n        # Overwrite undefined channel estimates with h_hat\n        mask_ = tf.reshape(self._mask, [-1, 1])\n        h_hat_interp = tf.where(mask_, h_hat_interp, self._h_hat)\n        err_var_interp = tf.where(mask_, err_var_interp, self._err_var)\n\n        # Reshape to the shape of the input h_hat\n        tensor_rank = tf.rank(h_hat)\n        output_shape = tf.concat([batch_dims, [new_shape[-2], new_shape[-1]]], 0)\n        h_hat_interp = tf.reshape(h_hat_interp, output_shape)\n        err_var_interp = tf.reshape(err_var_interp, output_shape)\n\n        return h_hat_interp, err_var_interp\n```  \n  "
"Here is the detailed information of SymbolLogits2Moments:   \nSource code link: https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#SymbolLogits2Moments  \n\nComputes the mean and variance of a constellation from logits (unnormalized log-probabilities) on the constellation points.\n\nMore precisely, given a constellation  of size , this layer computes the mean and variance according to\n\n$\\begin{split}\\begin{align}\n    \\mu &= \\sum_{n = 0}^{N-1} c_n \\Pr \\left(c_n \\lvert \\mathbf{\\ell} \\right)\\\\\n    \\nu &= \\sum_{n = 0}^{N-1} \\left( c_n - \\mu \\right)^2 \\Pr \\left(c_n \\lvert \\mathbf{\\ell} \\right)\n\\end{align}\\end{split}$\n\nwhere $\\mathbf{\\ell} = \\left[ \\ell_0, \\dots, \\ell_{N-1} \\right]$ are the logits, and\n\n$\\Pr \\left(c_n \\lvert \\mathbf{\\ell} \\right) = \\frac{\\exp \\left( \\ell_n \\right)}{\\sum_{i=0}^{N-1} \\exp \\left( \\ell_i \\right) }.$\n\n### Parameters\n\n- **constellation_type** (str): One of \"qam\", \"pam\", or \"custom\". For \"custom\", an instance of Constellation ust be provided.\n\n- **num_bits_per_symbol** (int): The number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation_type in [qam, pam].\n\n- **constellation** (Constellation): An instance of Constellation or None. In the latter case, constellation_type and num_bits_per_symbol must be provided.\n\n- **dtype** (tf.DType): The dtype for the input and output. Defaults to tf.float32.\n\n### Input\n\n- **logits** ([...,n, num_points], tf.float): Logits on constellation points.\n\n### Output\n\n- **mean** ([...,n], tf.float): Mean of the constellation.\n- **var** ([...,n], tf.float): Variance of the constellation."
"The 'cir_to_ofdm_channel' function is part of the 'Sionna' Python wireless simulation package and is used to compute the frequency response of the channel at frequencies. This function operates with the assumption that the channel impulse response (CIR) is constant over the duration of an OFDM symbol.\n\nThe inputs to this function are:\n- Frequencies: A tensor of prescribed OFDM resource grid size, representing the computed frequencies.\n- A: The channel matrices. This tensor represents the amplitudes of the paths of the channel impulse response.\n- Tau: The delays of the paths in the channel impulse response.\n- Normalize: If set to True, the normalization condition of the Discrete Fourier Transform (DFT) is applied. By default, it's set to True.\n\nThe output of this function is the channel frequency response at the given frequencies.\n\n'cir_to_ofdm_channel' function is utilized in link-level simulations, where it computes the frequency response of the channel for use in Orthogonal Frequency-Division Multiplexing (OFDM) simulations. This serves as a crucial component in the process of generating a frequency-domain representation of the wireless channel from the time-domain CIR. The output can then be used to apply the channel to an OFDM resource grid in subsequent stages of the simulation."
"The `EPDetector` class is a layer that wraps the MIMO EP detector for use with OFDM waveforms. It is a part of the Sionna package which is used for simulating wireless communication systems. The MIMO EP detector is based on the Expectation Propagation (EP) algorithm, which is a heuristic method used for iterative decoding of low-density parity-check (LDPC) codes.\n\nThe parameters of the `EPDetector` class include:\n- `output`: Type of output, which can be either 'bit' or 'symbol'. This parameter specifies whether soft- or hard-decisions are returned.\n- `resource_grid`: Instance of `ResourceGrid`.\n- `stream_management`: Instance of `StreamManagement`.\n- `num_bits_per_symbol`: Number of bits per constellation symbol, e.g., 4 for QAM16. This parameter is only required for constellation types in qam and pam, and is optional for the other types.\n- `hard_out`: If set to True, the detector computes hard-decided bit values or constellation point indices instead of soft-values. Defaults to False.\n- `l`: Number of iterations for the detector. This parameter is set to 10 by default.\n- `beta`: Parameter for update smoothing. This is a value in the range from 0 to 1 and is set to 0.9 by default.\n- `dtype`: Defines the precision for internal calculations. Defaults to tf.complex64.\n\nThe `EPDetector` class is used in simulations related to MIMO transmissions, particularly in the processing of received signals in order to make bit or symbol decisions. The detector works in conjunction with the 'ResourceGrid' and 'StreamManagement' instances which configure the OFDM resource grid and stream mapping. The `EPDetector` performs iterations of message passing between the received stream signals and the detector, aiming to improve the quality of the detector output. The class is particularly useful for dealing with multiple input multiple output (MIMO) systems where complicated interference patterns can occur. "
"To set up and run an instance of the EDFA class in Sionna, you will need to populate the parameters for the class constructor. The following is a list of parameters that you will need to specify, based on the provided context:\n\n- `g`: Gain (as a scalar, defaults to 4.0); you can set this as a parameter in your function, like so: `gain = 4.0`.\n- `f`: Carrier frequency [Hz] (defaults to 7.0); set this using a parameter: `f = 7.0`.\n- `f_c`: Amplifier's center frequency [Hz] (defaults to 193.55e12); assign this to a parameter: `f_c = 193.55e12`.\n- `dt`: Time step [s] (defaults to 1e-12); if you need this in your function, set it as a parameter: `dt = 1e-12`.\n- `with_dual_polarization`: If set to `True`, it considers axis [-2] as x- and y-polarization and applies the noise per polarization (defaults to `False`); you can set this via a parameter: `with_dual_polarization = False`.\n- `dtype`: Defines the datatype for internal calculations and the output dtype (defaults to tf.complex64); if you want to set this in your function, determine the datatype and set it as a parameter: `dtype = tf.complex64`.\n\nMake sure to adhere to the proper Python syntax when creating your function. For example, here is how you might set up a EDFA instance with Sionna:\n\n```python\nfrom sionna.channel.optical import EDFA\n\nimport tensorflow as tf\n\n# Define the parameters\ng = 4.0\nf = 7.0\nf_c = 193.55e12\ndt = 1e-12\nwith_dual_polarization = False\ndtype = tf.complex64\n\n# Create and run the instance of the EDFA class\nclass InitializeEDFA(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        self.edfa = EDFA(\n            g=g,\n            f=f,\n            f_c=f_c,\n            dt=dt,\n            with_dual_polarization=with_dual_polarization,\n            dtype=dtype\n        )\n\n    def call(self, inputs):\n        # Implement the model logic here\n        pass\n\ninitialize_edfa = InitializeEDFA()\n# You can now use initialize_edfa as an instance of the EDFA class\n# and call its methods as needed\n```\n\nRemember to replace the parameters in the `__init__()` method with the ones that fit your use case.\n\nAs for running the instance, you would need to define a model that uses the EDFA instance as a layer, and then you can run the model. The provided context does not include the complete information for setting up and running the instance of the EDFA class, so you would need to complete the implementation based on the specific requirements of your simulation."
"The `render_to_file()` function in the `Scene` class of the Sionna package is used to render the current scene to an image file. This function allows the user to specify a camera for the rendering and a file path for the image.\n\nThe function takes the following parameters:\n\n- **cam**: This is a string specifying the name of the camera to be used for the rendering. The camera must be previously created and added to the scene. If no `cam` parameter is provided, the current preview camera is used.\n\n- **filename**: This is a string specifying the name of the file to save the image to. The file will be saved in the local directory of the user. The type of the file (e.g., .png, .jpg) is inferred from the string.\n\n- **resolution**: This is an integer list of two elements specifying the width and height of the image to be rendered. Higher resolutions will result in better quality images.\n\nOther parameters that can be provided include `preview`, `background`, `shadow_samples`, `ao_samples`, `return_cam`, `return_paths`, and `return_lambert_debug`. These parameters allow the user to control various aspects of the rendering process, such as whether to include a preview of the scene and how to handle lighting effects.\n\nThe `render_to_file()` function will use the camera and other settings specified to render the scene and then save the resulting image to the specified file."
"The \"wrap_angle_0_360\" function is part of the \"sionna.channel\" package and is designed to wrap an angle to the range of (0,360) degrees. The function takes an angle as an input and returns the angle wrapped to the range of (0,360) if it was provided in a different range. \n\nTo use this function, you simply need to call it with the angle you want to wrap as the parameter. The function will return the angle wrapped to (0,360).\n\nHere is how you can use it:\n\n```python\nimport tensorflow as tf\nfrom sionna.channel import wrap_angle_0_360\n\n# Define the angle you want to wrap\nangle = tf.constant(450, tf.float32)\n\n# Call the function with the angle as the parameter\nwrapped_angle = wrap_angle_0_360(angle)\n\nprint(wrapped_angle)\n```\n\nIn this example, the \"wrap_angle_0_360\" function will return 90 because 450 is outside the (0,360) range and 450-360 equals 90."
"The definition of ChannelModel: `sionna.channel.ChannelModel`\n\n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel)\n\n```python\nfrom abc import ABC, abstractmethod\n\nclass ChannelModel(ABC):\n    \"\"\"Abstract class defining an interface for channel models\"\"\"\n\n    @property\n    @abstractmethod\n    def dtype(self):\n        \"\"\"The dtype of the output.\"\"\"\n        pass\n\n    @abstractmethod\n    def __call__(self, batch_size, num_time_steps, sampling_frequency):\n        \"\"\"Generates and returns channel impulse responses.\n\n        The channel impulse responses are tuple\n        :math:`(\\mathbf{H}, \\boldsymbol{\\tau})` where :math:`\\mathbf{H}\\in\\mathbb{C}^{M\\times K}`\n        is the matrix of path coefficients and\n        :math:`\\boldsymbol{\\tau} \\in \\mathbb{R}^K` are the path delays.\n        Path delays are always positive and\n        correspond to the time that a signal takes to travel from a transmit\n        to a receive antenna (or vice-versa).\n\n        Input\n        ------\n        batch_size : int\n            Batch size\n\n        num_time_steps : int\n            Number of time steps\n\n        sampling_frequency : float\n            Sampling frequency [Hz]\n\n        Output\n        -------\n        a : [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex\n            Path coefficients\n\n        tau : [batch size, num_rx, num_tx, num_paths], tf.float\n            Path delays [s]\n        \"\"\"\n        pass\n```"
"Here is the detailed information of function sionna.rt.Scene.render_to_file: \n\nsionna.rt.Scene.render_to_file(self, filename, camera, override_cam = False, render_paths = False, path_num = 0)\n\nRenders the scene from the viewpoint of a camera to a file\n\nFor easy rendering to files from an integrated environment (like Jupyter notebooks), this function is handy as it doesn\"t require you to access the renderer directly.\n\n```python\nfrom sionna.rt import load_scene\n\n# Load example scene\nscene = load_scene(sionna.rt.scene.munich)\n\n# Render scene to file from preview camera\nscene.render_to_file(\"preview.png\")\n\n# Render scene to file from camera with bird's eye view\nscene.render_to_file(\"topview.png\", \"Camera-TopView\")\n```\n\n**Note:**\nThe number of samples specified in `render_samples`, `camera.samples`, and by the `antialias` property of the renderer determine the quality of the rendered image (higher is better), at the cost of longer rendering time.\n\nAdditionally, for transparent materials like glass, you might need to set the `max_bounces` property of the renderer to a higher value than the default of 3 to obtain a clean image.\n\n### Input\n\n- `filename` (str): Name of the file to which the rendered image will be saved.\n- `camera` (Camera or str): Instance of Camera or string with the name of a camera found in the scene. Used to determine the viewpoint for the rendering. \n- `override_cam` (Camera): If set, the `camera` parameter is ignored and this Camera instance is used to render the scene.\n- `render_paths` (bool): If `True`, the paths used to render the scene (for debugging) are returned.\n- `path_num` (int): Path number (relevant if `render_paths` is `True`).\n\n### Output\n\n- `paths, target_paths, rendered_image`: The computed paths, target (i.e., desired) paths, and rendered image, respectively. The paths and target paths are returned only if `render_paths` is `True`.\n\nThis function will raise an exception if the scene or the camera is not found in the loaded scenes. It will also raise an exception if `filename` is not a str or if `render_paths` is not a bool."
"To configure DeepMIMO for use with Sionna, follow these steps:\n\n1. **Import necessary libraries and configure GPU settings:**\n   You will need to import the necessary libraries such as Sionna, TensorFlow, and other utility libraries. Additionally, you can configure the GPU settings to avoid warnings from TensorFlow.\n\n2. **Load the required Sionna component:**\n   You will need to load the `sionna.mimo.DeepMIMOChannel` component from the Sionna library. This component generates channel impulse responses (CIRs) for the DeepMIMO dataset.\n\n3. **Configure DeepMIMO:**\n   DeepMIMO is configured using a Python dictionary. You need to specify the DeepMIMO dataset you want to use, the scenario, the carrier frequency, the antenna array configurations, and other parameters related to time-domain and OFDM.\n\n4. **Initialize the DeepMIMO component:**\n   Pass the DeepMIMO configuration dictionary to the `sionna.mimo.DeepMIMOChannel` constructor to initialize the DeepMIMO component.\n\nHere is a sample Python code snippet that demonstrates these steps:\n\n```python\n# Import Sionna\nimport sionna\n# Configure the GPU settings\nsionna.utils.configure_gpu()\n# Load the DeepMIMO component\nload_deep_mimo = True # Set to False to load a Sionna performance profile\ntry:\n    # Try loading the DeepMIMO Sionna adapter\n    from sionna.mimo import DeepMIMOAdapter\n    # Create a DeepMIMO adapter with the active DeepMIMO dataset\n    deep_mimo_adapter = DeepMIMOAdapter(load_deep_mimo=load_deep_mIMO)\n    # Select the scenario and carrier frequency for the DeepMIMO dataset\n    deep_mimo_adapter.select_scenario('O2_60')\n    # Configure the DeepMIMO dataset for which the CIRs should be generated\n    # This implicitly sets the antenna array parameters\n    deep_mimo_adapter.active_setup['carrier_frequency'] = 3.5e9\n    deep_mimo_adapter.active_setup['ue']['antenna']['los'] = 'first'\n    deep_mimo_adapter.active_setup['base_station']['antenna']['panel_array']\\\n    ['rows'] = 4\n    deep_mimo_adapter.active_setup['base_station']['antenna']['panel_array']\\\n    ['columns'] = 4\n    # Create a DeepMIMO component generating CIRs\n    cir_generator = sionna.channel.CIRGenerator(deep_mimo_adapter=\\\n                                                 deep_mimo_adapter)\nexcept ImportError:\n    # Sionna DeepMIMO adapter is not installed. Install the adapter\n    # and then repeat the import.\n    print(\"Sionna DeepMIMO adapter is not installed. Install the adapter and then repeat the import.\")\n```\n\nPlease ensure that the configuration parameters are set according to your specific requirements and the DeepMIMO dataset you are using."
"To use the Interleaver module in the Sionna package to permute tensors, you can follow these steps:\n\n1. Import the required modules:\n    ```python\n    from sionna.fec.interleaving import RandomInterleaver, Interleaver, Deinterleaver\n    import tensorflow as tf\n    ```\n\n2. Set up the system:\n\n    ```python\n    # set-up system\n    interleaver = RandomInterleaver(seed=1234, # an explicit seed can be provided\n                                    keep_batch_constant=False, # if True, all samples in the batch are permuted with the same pattern\n                                    axis=-1) # axis which shall be permuted\n\ndeinterleaver = Deinterleaver(interleaver=interleaver) # connect interleaver and deinterleaver\n    ```\n\n3. Use the system:\n\n    ```python\n    # c has arbitrary shape (rank>=2)\n    c_int = interleaver(c)\n\n# call deinterleaver to reconstruct the original order\n    c_deint = deinterleaver(c_int)\n    ```\n\nIn the code above, c is the tensor you want to permute. The call `c_int = interleaver(c)` will permute the tensor c using the setup from the interleaver. If you want to set a new seed for each call, you can pass a tuple with the tensor c and the seed s to the interleaver. The internal seed of the interleaver does not change after initialization, but if an explicit seed is provided in the tuple, it will be used to generate the random pattern. \n\nPlease note that each dimension of c represents a different code word, so the permutation will be done individually for each dimension. The keep_batch_constant parameter, if set to True, will use the same permutation for all the code words in a batch. \n\nFor more advanced usage, the explicit seed of the interleaver can be passed to the Deinterleaver. This will be used to reconstruct the original order from the permuted tensor."
"The `MMSEPICDetector` function is a part of Sionna's novel Python package and is used for detecting signals in a Multiple Input Multiple Output (MIMO) context with possible a Priori information. It wraps the MIMO MMSE PIC detector for use with OFDM waveform and is particularly suitable for channels with high rank and/or large MIMO settings.\n\nThe function takes several parameters including the OFDM and stream configuration, the detection method which is either 'symbol' or 'bit', the demapping method, the number of MMSE PIC detection iterations, the constellation type, the number of bits per symbol, the constellation, hard output specifications, and the data type preference for internal processing and output. \n\nIn specific, the function's parameters are:\n- `output`: Type of output, either bits or symbols. This determines the type of data (i.e., bits or symbols) that are returned by the function. Whether soft or hard decisions are returned can be configured using the `hard_out` parameter.\n- `resource_grid`: An instance of `ResourceGrid`.\n- `stream_management`: An instance of `StreamManagement`.\n- `demapping_method`: Demapping method, which is either \"app\" or \"maxlog\".\n- `num_iter`: Number of MMSE PIC iterations, which indicates how many times the MMSE PIC detector will iterate to refine its estimation and detection of the transmitted signal.\n- `constellation_type`: Type of constellation, which is relevant if `constellation` is not None. It can be \"qam\", \"pam\", or \"custom\". For \"custom\", an instance of `Constellation` must be provided.\n- `num_bits_per_symbol`: Number of bits per constellation symbol, e.g., 4 for QAM16. This parameter is only required for \"qam\" and \"pam\" constellation types.\n- `constellation`: Constellation, an instance of `Constellation` or None. In the latter case, `constellation_type` and `num_bits_per_symbol` must be provided.\n- `hard_out`: If True, the detector computes hard-decided bit values or constellation point indices instead of soft-values. This parameter determines the output format of the function.\n- `dtype`: Specifies the data type. The internal data type and output data type are controlled by `dtype` in most cases.\n\nThe function returns one of the following outputs, depending on the parameters:\n- LLRs or hard-decisions for every bit of every stream, if `output` is \"bit\".\n- Logits or hard-decisions for constellation symbols for every stream, if `output` is \"symbol\".\n\nTo use this function, you need to create a correct instance of `ResourceGrid` and `StreamManagement` for your specific OFDM setup. These usually entail specifying data such as the OFDM `fft_size`, the number of 'n' or 'nu' streams, the 's' pilot pattern, and possibly other configurations. \n\nYou should choose \"bit\" output for maximizing data rate since this setting allows for more efficient processing than \"symbol\" output. Note that the choice between soft- or hard-decisions is application-dependent, where hard decisions are generally preferred for their computational efficiency.\n\nIn terms of output, we mean that the function will output certain data (either in the form of bits or symbols) that represent the information or signal being detected. "
"Here is the definition of RaisedCosineFilter: sionna.signal.RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/signal/filter.html#RaisedCosineFilter)\n\nsource code:\n```python\nclass RaisedCosineFilter(Filter):\n    # pylint: disable=line-too-long\n    r\"\"\"RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, dtype=tf.float32, **kwargs)\n\n    Layer for applying a raised-cosine filter of length ``span_in_symbols``\n    to an input ``x`` of length ``samples_per_symbol``.\n\n    The raised-cosine filter is defined by\n\n    .. math::\n        h(t) =\n        \\begin{cases}\n        \\frac{1}{T} \\left(1 + \\cos\\left(\\frac{\\pi}{\\beta}\\left(|t|-\\frac{1}{2}\\right)\\right) \\right), \\ \\ \\ \\text{if} \\ \\beta \\in (0,1)\\\\\n        \\frac{1}{T} \\left(\\sin\\left(\\frac{\\pi}{\\beta}\\left(|t|-\\frac{1}{2}\\right)\\right)\\frac{2\\beta}{\\pi} + \\cos\\left(\\frac{\\pi}{\\beta}\\left(|t|-\\frac{1}{2}\\right)\\right) \\right), \\ \\ \\ \\text{if} \\ \\beta \\in (0,1)\\\\\n        \\frac{1}{T} \\left(\\frac{\\sin(\\pi|t|)}{\\pi|t|} \\right), \\ \\ \\ \\text{if} \\ \\beta = 1\\\\\n        \\frac{1}{T}e^{-\\frac{t}{T_j}}\\left(\\cos\\left(\\frac{\\pi}{\\alpha}(t+T_j)\\right) + \\frac{\\sin\\left(\\frac{\\pi}{\\alpha}(t+T_j)\\right)}{\\frac{\\pi}{\\alpha}(t+T_j)}\\right), \\ \\ \\ \\text{if} \\ \\beta = 0\n        \\end{cases}\n\n    where :math:`\\beta` is the roll-off factor, :math:`T` the symbol duration,\n    :math:`T_j` the excess time delay, and :math:`\\alpha = \\frac{1}{2T} \\log{2}`\n    the reciprocal Nyquist bandwidth.\n\n    The filter length ``span_in_symbols`` is equal to the filter symbol duration\n    :math:`T` in multiples of ``samples_per_symbol``. If\n    ``samples_per_symbol`` is greater than one, the filter is\n    expanded by inserting zeros after every filter coefficient.\n    This downsampling factor can be set using the `samples_per_symbol`\n    property.\n\n    The filter is applied through discrete convolution.\n\n    An optional scaling factor can be applied to the filter\n    coefficients by providing a tuple ``(coefficients, scaling_factor)``.\n    The scaling factor is applied after the filter coefficients have been\n    expanded to the desired length by polyphase filtering.\n\n    The `dtype` of the output is the same as the `dtype` of the input ``x``.\n    The `dtype` of the filter coefficients is defined by the underlying\n    ``tf.complex`` implementation.\n\n    Parameters\n    ----------\n    span_in_symbols: int\n        Filter span as measured by the number of symbols.\n\n    samples_per_symbol: int\n        Number of samples per symbol, i.e., the oversampling factor.\n\n    beta: float\n        Roll-off factor.\n        Must be in the range :math:`(0,1)`.\n\n    dtype: tf.DType\n        The `dtype` of the input ``x`` and the desired `dtype` of the\n        output. It defaults to `tf.float32`. The `dtype` of the filter\n        coefficients is computed from the complex-valued `dtype` of the\n        filter when expanded to the full length.\n\n    Input\n    -----\n    x : [...,n], tf.complex or tf.float\n        The input to which the filter is applied.\n        The filter is applied along the last dimension.\n\n    Output\n    ------\n    y : [...,k], tf.complex or tf.float\n        Filter output.\n        The filter is applied along the last dimension.\n        The length k depends on the ``full_length`` of the filter.\n\n    Note\n    ----\n    The algorithm is implemented naively which is sub-optimal\n    in terms of computational complexity. However, the\n    algorithm is transparent which is beneficial for educational\n    purposes. If required, the algorithm can be pre-computed\n    and the resulting matrix can be applied through matrix\n    multiplication which is computationally much more efficient.\n    \"\"\"\n    def __init__(self,\n                 span_in_symbols,\n                 samples_per_symbol,\n                 beta,\n                 coefficients=None,\n                 scaling_factor=None,\n                 dtype=tf.float32,\n                 **kwargs):\n        super().__init__(span_in_symbols,\n                         samples_per_symbol,\n                         beta,\n                         coefficients=coefficients,\n                         scaling_factor=scaling_factor,\n                         dtype=dtype,\n                         **kwargs)\n\n    @property\n    def beta(self):\n        return self._beta\n\n    @property\n    def excess_bw(self):\n        \"\"\"Excess bandwidth in radian.\"\"\"\n        return self._excess_bw\n\n    @property\n    def passband_cutoff_freq(self):\n        \"\"\"Cutoff frequency for a passband signal in per nyalquist\"\"\"\n        return 1/self._ts/self._excess_sp_factor\n\n    @property\n    def t(self):\n        \"Time support of the filter in seconds\"\n        return self._span_in_symbols*self._ts\n\n    @property\n    def coefficients(self):\n        return self._coefficients_padded\n\n    @property\n    def scaling_factor(self):\n        \"\"\"Scaling factor applied to the filter coefficients.\"\"\"\n        return self._scaling_factor\n\n    @property\n    def _excess_sp_factor(self):\n        \"\"\"See :cite:`Proakis2007` Eq.4rd Ed., Chap.7\"\"\"\n        if self._beta == 0:\n            return 1\n        else:\n            return self.t/self._ts*(1+self._alpha_sp_factor) \\\n                    - self._alpha_sp_factor \\\n                    /(2*np.pi)*np.sin(2*np.pi*self._alpha_sp_factor)\n\n    @property\n    def _alpha_sp_factor(self):\n        \"\"\"See :cite:`Proakis2007` Eq.4rd Ed., Chap.7\"\"\"\n        if self._beta == 0:\n            return 0\n        else:\n            return self._excess_bw/self.passband_cutoff_freq \\\n                    - self._passband_cutoff_freq\n\n    def show(self, response='impulse', scale='lin'):\n        r\"\"\"Plot the impulse or magnitude response\n\n        Plots the impulse response (time domain) or\n        the magnitude response (frequency domain) of the filter.\n\n        For the computation of the magnitude response, a minimum\n        of 1024 frequency points is assumed.\n\n        Input\n        -----\n        response: str, one of [\"impulse\", \"magnitude\"]\n            The desired response type.\n            Defaults to \"impulse\"\n\n        scale: str, one of [\"lin\", \"db\"]\n            The y-scale of the magnitude response.\n            Can be \"lin\" (i.e., linear) or \"db\" (, i.e., Decibel).\n            Defaults to \"lin\".\n        \"\"\"\n        response = response.lower()\n        assert response in [\"impulse\", \"magnitude\"],\\\n            \"Invalid response type\"\n        if response==\"impulse\":\n            x = self._span_in_symbols\n            x = np.linspace(-x/2, x/2, x.shape[0])\n            x_label = r\"$\\tau$ /symbols\"\n            y = np.abs(self.coefficients.numpy())\n            y = np.concatenate([np.flip(y[1:],axis=0), y],axis=0)\n            y = np.real(np.fft.ifft(np.fft.fft(y)))\n            y = np.abs(y)\n            y = np.concatenate([y[1:], y], axis=0)\n        else:\n            # Calculate the magnitude response\n            freq = np.fft.fftfreq(1024, 1.0)\n            h = np.abs(np.fft.fft(self.coefficients.numpy(), 1024))\n            x_label = \"Normalized frequency (fft-size/sample-rate)\"\n            y = h\n            # Linear scale\n            if scale==\"lin\":\n                x = freq\n                x_label=r\"$f$ / \" + self.fs/1e3 + \" kHz\"\n            # Log-scale\n            elif scale==\"db\":\n                x = 10*np.log10(freq)\n                x_label=r\"$f$ / \" + self.fs/1e3 + \" kHz\" + r\" (dB)\"\n\n        # Plot the response\n        plt.figure(figsize=(12,6))\n        plt.plot(x, y)\n        plt.xlabel(x_label)\n        plt.ylabel(r\"$|H(f)|$\")\n        plt.grid(True)\n        plt.title(\"Filter \" + self.name)\n        # Set limits on x-axis to (0,2) for beta=0, to avoid NaNs\n        if self.beta==0 and response==\"magnitude\":\n            plt.xlim(0,2)\n        plt.show()\n```"
"The PAM2QAM class in the Sionna mapping module is utilized to transform Pulse Amplitude Modulation (PAM) symbol indices to QAM symbol indices, specifically for indices within a QAM constellation. The class computes the indices for the two PAM constellations that correspond to the real and imaginary components of the QAM constellation.\n\nIn the context of code execution, this class would be used within a larger pipeline for signal processing and modulation. More specifically, if you have a tensor with PAM symbol indices, you would instantiate a PAM2QAM object with the correct number of bits per symbol (e.g., 4 for QAM16) and call this object with the tensor as an argument. The output of this operation would be a tensor with the transformed symbol indices, which could then feed into subsequent stages of the processing pipeline.\n\nThe transformation from PAM to QAM is a crucial part of signal processing in scenarios such as in 5G NR physical channels, where modulation schemes are defined. This class contributes to ensuring that the correct modulation is applied and helps in achieving efficient and accurate data transmission, which is essential in communication systems."
"In the given context, the Python code to configure StreamManagement for a simple uplink scenario is provided:\n\n```python\n# Define the number of UT and BS antennas\nNUM_TX = 1\nNUM_RX = 1\nNUM_STREAMS_PER_TX = 1\n\n# The number of transmitted streams is equal to the number of UT antennas\n# in both uplink and downlink\nRX_TX_ASSOCIATION = np.array([[1]])\n\n# Instantiate a StreamManagement object\nSTREAM_MANAGEMENT = sn.mimo.StreamManagement(RX_TX_ASSOCIATION, NUM_STREAMS_PER_TX)\n```\n\nHere, `NUM_TX` represents the number of transmitters, `NUM_RX` represents the number of receivers, and `NUM_STREAMS_PER_TX` represents the number of streams per transmitter. The `RX_TX_ASSOCIATION` is an array used to denote the association between receivers and transmitters. In the given context, as there is only a single transmitter and receiver, the `RX_TX_ASSOCIATION` array is `[[1]]`, indicating that the only receiver communicates with the only transmitter. \n\nThe `StreamManagement` object is then instantiated using the `RX_TX_ASSOCIATION` array and the `NUM_STREAMS_PER_TX`. The `StreamManagement` object determines the data streams that are to be transmitted to and received from the various antennas."
"Constellations are the set of signal points in the complex plane that are used to represent digital signals. These constellation points are selected in such a way that they are equidistant from each other and form a geometric pattern. The number of constellation points is equal to the number of bits in each symbol. In the context of higher order modulation, modulation schemes like QAM (Quadrature Amplitude Modulation) and PAM (Pulse Amplitude Modulation) are examples of constellations.\n\nBit-channels, on the other hand, refer to the individual binary channels that are created when multiple bits are mapped onto a single symbol in higher order modulation. Each bit is represented by either a +1 or a -1, and these are used to modulate a carrier signal in order to convey digital data.\n\nTo generate higher order constellations like QPSK (Quadrature  Phase Shift Keying) and 16-QAM (Quadrature Amplitude Modulation), you can use the `Constellation` class from the `sionna.mapping` module. Here is a code snippet that shows how to generate the constellations:\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sionna.mapping import Constellation\n\n# Generate the QPSK constellation\nconstellation_qpsk = Constellation(\"qam\", num_bits_per_symbol=2)\n\n# Generate the 16-QAM constellation\nconstellation_16qam = Constellation(\"qam\", num_bits_per_symbol=4)\n```\n\nThe generated constellations can be visualized using the `show` method of the `Constellation` class. For example:\n\n```python\n# Visualize the QPSK constellation\nconstellation_qpsk.show()\n\n# Visualize the 16-QAM constellation\nconstellation_16qam.show()\n```\n\nThis will generate scatter plots of the constellation points. In the case of QPSK, the points will be on a unit circle in the complex plane, and in the case of 16-QAM, the points will be on a Cartesian grid in the complex plane."
"The `pam` function in the sionna.mapping module is used to generate a constellation of real-valued points for a M-ary PAM (Pulse Amplitude Modulation) format. The number of bits per symbol is the function's primary parameter, denoted as `num_bits_per_symbol`. An optional `normalize` parameter can be provided; if set to `True`, the constellation is normalized to ensure it has unit power.\n\nThe constellation is a vector of size `2^n`, where `n` is the number of bits per symbol. Each element of the vector corresponds to a constellation point, and the points are laid out such that they have the maximum Euclidean distance to each other, aiding in the error detection and correction process.\n\nThe function outputs a `2^n`-sized vector in which each element is a constellation point. The points are represented as `np.float32` values and the normalization factor is applied if it's mentioned during the function call.\n\nIt's worth noting that the function's recursive implementation is particularly suitable for very high-dimensional constellations, as it can quickly generate the necessary extremely large set of points. However, for very large constellations, it may be more practical to use a non-recursive method. \n\nIn the 5G standard, this function is used for among other purposes, signal transmission and reception, data processing, and error correction. The PAM constellation generated by this function can be used for mapping data bits into symbols in the process of modulation and demodulation in communication systems."
"To use the \"List2LLR\" class in the Sionna package, there are several assumptions that need to be fulfilled:\n\n1. The channel model is a binary, memoryless channel, represented by its Transition (or error) probability and its symmetric BLP. This applies to both uplink and downlink transmissions.\n\n2. All coding schemes are symmetric, channel combining and splitting are therefore performed using the same binary index.\n\n3. Only binary inputs and LLRs (with defined as signs of either -1 or 1) are supported.\n\n4. The LLRs that are combined to form a Log-Likelihood Ratio (LLR) message must be either from a method that returns LLRs defined as sines or a method that returns LLRs defined as signs.\n\n5. The datatype of the input sequence of LLRs must be compatible with the 'List2LLR' class definition, which typically is tf.float32.\n\n6. The class assumes that the all-zero codeword is used for cw initialization and does not support the option of using a non-binary codeword.\n\n7. The \"List2LLR\" class does not support partial preloading of the shift register.\n\n8. The method for generating the impulse responses must be 'gen_irst_h' as it is assumed by the 'List2LLR' class.\n\n9. The class makes use of the `SplitUncodedLLRs` class for splitting the c into the individual codeword components. The method for combining the codewords is given by `combining_descriptor`.\n\n10. The class requires complete knowledge of the channel, the channel quality information (CQI) values are required for each receiver.\n\nPlease note that the provided code snippet is for initializing the \"List2LLR\" class, further application-specific parameters need to be provided based on the use case. The class parameters should be chosen carefully to best suit the scenario in which the class will be employed."
"The `MMSEPICDetector` class is part of the 'sionna' package and is used for Symbol or Bit-Labelled Multiple Input Multiple Output (MIMO) detections with the Orthogonal Frequency-Division Multiplexing (OFDM) waveform. This layer wraps the MIMO MMSE PIC detector for use with the OFDM waveform. The functionality of the `MMSEPICDetector` is to minimize the mean squared error (MSE) to achieve near-optimal performance in MIMO detection.\n\nThe parameter that this class takes is:\n\n- `output`: This parameter specifies the type of output, which can be either 'bit' for bits or 'symbol' for symbols. You can choose whether soft- or hard-decisions are returned using the `hard_out` flag. The default output is soft-decisions for 'symbol'.\n\nThe `MMSEPICDetector` requires certain conditions to be true for efficient detection. It assumes that for the channel estimates to be accurate, the signal-to-noise ratio (SNR) should be high. Also, it is recommended that for the detection to be effective, the number of receive antennas should be at least the number of transmitted antennas. The 'sionna.rt.to_rx_channel' function needs to be accurate, and the channel model should be in a geometric or non-stochastic model. Also, the channel model, `sionna.rt.ofdm.channel_recursion`, should be in a non-stochastic model. It is also assumed that the channel state information (CSI) is continuous."
"The `QAM2PAM` class is a part of the `sionna.mapping` module. It is used to transform QAM (Quadrature Amplitude Modulation) symbol indices to PAM (Pulse Amplitude Modulation) symbol indices. For instance, in a 4-QAM constellation, the four symbols map to the real and imaginary components of a signal that is transmitted.\n\nThe class takes the number of bits per constellation symbol as an input. For a 16-QAM constellation, the input would be like `QAM2PAM(4)`. The output would be two indices, `ind_pam1` and `ind_pam2`, corresponding to the PAM symbol indices. These indices point to the positions at which the PAM constellation symbols are mapped from the QAM constellation symbols.\n\nThe mathematical transformation from QAM constellation to PAM constellation is prescribed in the 3GPP TS 38.211 specification, which is primarily used in wireless communications. \nIt is based on the principles of digital communications and modulation techniques that are explained in the context. \nThe specific functions that perform this transformation can be found in the source code of the Sionna package, which is not directly available in this notebook."
"To use the Sionna package to verify that the generator matrix and parity-check matrix are orthogonal in GF(2) with the \"verify_gm_pcm\" function, you need to follow these steps:\n\n1. First, you need to import the necessary functions from the Sionna package. You can use the following code:\n\n```python\nfrom sionna.fec.utils import verify_gm_pcm\nimport numpy as np\n```\n\n2. Next, you need to define your generator matrix (gm) and parity-check matrix (pcm). The matrices should be numpy arrays with binary values.\n\n3. You can call the \"verify_gm_pcm\" function with your generator matrix and parity-check matrix as arguments. You also need to specify the \"print_result\" argument, which defaults to True. If you want to see the result, you can set it to True.\n\n```python\nresult = verify_gm_pcm(gm, pcm, print_result=True)\n```\n\nThe function will check if the matrices are orthogonal in GF(2). If the matrices are orthogonal, it will return True. Otherwise, it will return False.\n\nPlease note that both matrices must be full rank to pass the orthogonality test. If any of the matrices are not full rank, the function will return False, indicating that the matrices are not orthogonal."
"To import the `LinearEncoder` class from the `sionna.fec.linear` module, you can use the following line of code:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n```\n\nThis statement is in accordance with the Python package structure where you specify the module(in this case, `sionna.fec.linear`) and then the class name (`LinearEncoder`)."
"The `OFDMDetectorWithPrior` class is used to implement a MIMO (Multi-Input, Multi-Output) detector for Orthogonal Frequency-Division Multiplexing (OFDM) waveforms, assuming prior knowledge of the bits or constellation points is available. This class preprocesses the received signals, the channel estimate, and the prior information and then computes the noise-plus-interference covariance matrix for each receiver according to the configuration set by the `resource_grid` and `stream_management` objects. These steps are done to properly OFDM and stream configuration.\n\nAfter this preprocessing, a MIMO detection algorithm with prior is applied through the use of a callable object (e.g., a function) represented by the parameter `detector`. This can be an existing detector like `MaximumLikelihoodDetectorWithPrior` or a custom detector as long as it meets the specifications. The output type of the detector can be either bits or symbols. If it is symbols, soft- or hard-decisions are supported.\n\nIn summary, the `OFDMDetectorWithPrior` class is designed to facilitate the detection of streams in OFDM systems by providing a preprocessed set of signals to detect, using prior information. The ability to use a custom detector provides flexibility in the detector algorithm, while the class's support for soft- and hard-decisions expands the range of compatible detectors."
"The \"bin2int_tf\" function is used to convert a binary tensor into an integer tensor. The binary representation is provided in the \"arr\" parameter, which contains either 0s or 1s. The conversion is performed across the last dimension of the tensor, from the most significant digit to the least significant digit.\n\nA specific use of this function is not provided in the context. However, based on the described functionality, this function can be used in situations where a binary tensor representation needs to be converted into an integer tensor representation. This could be helpful in scenarios related to data processing and manipulation, particularly in the context of digital communication where binary representations are commonly used."
"To use the `TB5GScrambler` for 5G NR compliant scrambling, you need to create an instance of the scrambler by providing the parameters `c_init` (including binary flag indicating if initialization should be combined), and optionally the `n_rnti` (provided at run-time) and the `n_id` (specified in the setup phase).\n\nHere is how you can set up the `TB5GScrambler` for 5G NR compliant scrambling:\n\n```python\nfrom sionna.fec.scrambling import TB5GScrambler\nscrambler = TB5GScrambler(c_init=1234, # explicit random seed\n                           binary=True, # indicate if bits should be flipped\n                           n_rnti=1, # RNTI identifier provided at run time\n                           n_id=1) # Scrambling ID n_id provided in the setup phase\n```\n\nIn this setup:\n- `c_init` is the initialization sequence of the Pseudo-Random Bit Sequence (PRBS) generator. Here a value is specified, but usually, you would choose a sequence of 0s and 1s.\n- The `binary` parameter indicates whether bits should be flipped. In the context, it's set to True, but if you were scrambling a sequence of symbols, you might set this to False.\n- `n_rnti` is the Radio Network Temporary Identifier (RNTI). If you're using this in a real 5G setup, this would be assigned to the user equipment by the network.\n- `n_id` is the Scrambling ID. This is a parameter specified in the setup phase.\n\nThen, you can call the scrambler on your data `c`:\n```python\nc_scr = scrambler(c)\n```\nHere, `c` is your arbitrary sequence of 0s and 1s (or symbols), and `c_scr` will hold the scrambled sequence.\n\nPlease note that the values for `c_init`, `n_rnti`, and `n_id` can be chosen according to the application's needs and setup. Also, typically, the initialization and parameters like RNTI and Scrambling ID would be provided by the network, so here they are set to typical placeholder values (1 and 23 respectively)."
"Here is the detailed information of int_mod_2: [sionna.fec.utils.int_mod_2(x)](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#int_mod_2)  \n  \nComputes the binary modulo-2 operation for an int input.\n\nFor example, let x be int tensor, s.t. x=10. Then, x will be  represt in binary as 1010. int_mod_2(x) will calculate 1010 modulo-2 which is 0, and the function will return 0.\n\n### Input\n\n- `x` (int tensor): This is the input to the int_mod_2 function.\n\n### Output\n\n- `int` : This returns the output of the int_mod_2 function, x modulo-2 operation.\n\nsource code:  \n```python\ndef int_mod_2(x):\n    r\"\"\"Computes the binary modulo-2 operation for an int input.\n\n    For example, let ``x`` be int tensor, s.t. ``x``=10.\n    Then, ``x`` will be  represt in binary as 1010.\n    ``int_mod_2(x)`` will calculate 1010 modulo-2 which is 0, and the function\n    will return 0.\n\n    Input\n    -----\n        x : int tensor\n            This is the input to the int_mod_2 function.\n\n    Output\n    -----\n        : int\n            This returns the output of the int_mod_2 function.\n            ``x`` modulo-2 operation.\n    \"\"\"\n    return tf.math.mod(x, 2)\n```"
"Here is the detailed information of sionna.utils.SymbolSource:   \n  \nProvides an (infinite) sequence of QAM symbols.  \n  \n### Parameters\n\n- `num_bits_per_symbol` (int): The number of bits per constellation symbol, e.g., 4 for QAM16.\n- `return_indices` (bool): If `True`, the symbol indices are returned instead of the symbols themselves. Defaults to `False`.\n- `dtype` (tf.DType or None): The dtype for the output. Defaults to `tf.complex64`.\n\n### Input\n\n- `shape` (1D tensor/array/list, int): The desired shape of the output tensor. Note that the first dimension is not affected by this operation.\n\n### Output\n\n- `shape`, `tf.complex`, `[num_symbols, ...]`: A tensor of QAM symbols (or symbol indices) of the desired shape.\n\nsource code:\n```python\nclass SymbolSource(Sequence):\n    \"\"\"Provides an (infinite) sequence of QAM symbols.\n\n    Parameters\n    ----------\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n\n    return_indices : bool\n        If `True`, the symbol indices are returned instead\n        of the symbols themselves.\n        Defaults to `False`.\n\n    dtype : tf.DType\n        The dtype for the output. Defaults to `tf.complex64`.\n\n    Input\n    -----\n    shape : 1D tensor/array/list, int\n        The desired shape of the output tensor.\n        Note that the first dimension is not affected by this operation.\n\n    Output\n    ------\n    : shape, tf.complex, [num_symbols, ...]\n        A tensor of QAM symbols (or symbol indices) of the desired shape.\n    \"\"\"\n\n    def __init__(self,\n                 num_bits_per_symbol,\n                 return_indices=False,\n                 dtype=tf.complex64):\n        super().__init__()\n        self.num_bits_per_symbol = num_bits_per_symbol\n        self.return_indices = return_indices\n        self.dtype = dtype\n        self.modulator = Modulator(\"qam\", num_bits_per_symbol, dtype=dtype)\n\n    @property\n    def num_symbols(self):\n        \"\"\"The number of (finite) constellation symbols.\"\"\"\n        return 2**self.num_bits_per_symbol\n\n    @property\n    def num_bits(self):\n        \"The number of bits per symbol, i.e., the constelation cardinality.\"\n        return self.num_bits_per_symbol\n\n    def __len__(self):\n        return 10000\n\n    def __getitem__(self, key):\n        num_symbols = np.prod(key.as_list()[:-1])\n        shape = key.as_list()\n\n        shape[-1] = 2 # Force two dimensions, as required by the modulator\n\n        symbols = self.modulator([num_symbols])\n        symbols = tf.reshape(symbols, shape)\n        if self.return_indices:\n            return symbols\n        else:\n            symbol_bits = split_constellation(self.modulator.constellation,\n                                            self.modulator.constellation_indices,\n                                            self.modulator.num_bits_per_symbol)\n            symbol_bits = tf.reshape(symbol_bits, [1]+shape)\n            symbol_bits = tf.cast(symbol_bits, tf.float32) # QAM symbols are .5 and -.5\n            symbols = symbol_bits[...-1]\n            return symbols\n```"
"Input\n\n- **batch_size** (int): Batch size.\n- **num_time_steps** (int): Number of time steps.\n- **sampling_frequency** (float): Sampling frequency [Hz].\n\nOutput\n\n- **a** ([batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex): Path coefficients.\n- **tau** ([batch size, num_rx, num_tx, num_paths], tf.float): Path delays [s].\n\nsource code:\n```python\nfrom abc import ABC, abstractmethod\n\nclass ChannelModel(ABC):\n    \"\"\"Abstract class defining an interface for channel models\"\"\"\n\n    @abstractmethod\n    def __init__(self, batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps, dtype=tf.complex64):\n        \"\"\"Abstract constructor\n\n        The batch size, number of receivers, number of receiver antennas,\n        number of transmitters, number of transmitter antennas, number of paths,\n        and number of time steps must be specified.\n\n        The `dtype` of the outputs can be specified and defaults to `tf.complex64`.\n        \"\"\"\n\n        self._batch_size = batch_size\n        self._num_rx = num_rx\n        self._num_rx_ant = num_rx_ant\n        self._num_tx = num_tx\n        self._num_tx_ant = num_tx_ant\n        self._num_paths = num_paths\n        self._num_time_steps = num_time_steps\n\n        assert self._num_time_steps > 0, \\\n        \"`num_time_steps` must be positive.\"\n\n        self._sampling_frequency = tf.constant(sampling_frequency, dtype=dtype)\n\n        super().__init__(dtype=dtype)\n\n    @property\n    def batch_size(self):\n        \"\"\"Batch size\"\"\"\n        return self._batch_size\n\n    @property\n    def num_time_steps(self):\n        \"\"\"Number of time steps\"\"\"\n        return self._num_time_steps\n\n    @property\n    def sampling_frequency(self):\n        \"\"\"Sampling frequency [Hz]\"\"\"\n        return self._sampling_frequency\n\n    @abstractmethod\n    def __call__(self):\n        # The signature of this method is not correct because we don't\n        # know in advance the number of time steps of the simulated data.\n        # We could use the strategy of TDL here, i.e., simulate the channel\n        # in chunks of a certain duration (time steps), and dynamically\n        # generate the channels by calling this method multiple times.\n        #\n        #  def __call__(self, num_time_steps):\n        #    ...\n        raise NotImplementedError(\"You should implement this method.\")\n```"
"To build a custom `RadioMaterial` in the `Sionna` wireless simulation tool, you can follow these steps:\n\n1. Define the material properties: \n   - `relative_permittivity`: The relative permittivity of the material. It indicates how much the material gets polarized in the presence of an electric field. A value of 1 represents vacuum.\n   - `conductivity`: The conductivity of the material. It can be a scalar or a tensor of any shape. A higher conductivity means more electric energy is dissipated as heat.\n   - `scattering_coefficient`: This applies to scattered field and represents the fraction of the incident energy that is scattered.\n   - `xpd_coefficient`: This is the cross-polar discrimination in the scattered field. It is set to 0 when there is no cross-polarization.\n\n2. Create a RadioMaterial instance by providing the defined parameters.\n\n3. Use the RadioMaterial instance to define a custom scene object. The RadioMaterial is attached to the SceneObject using its name. If the RadioMaterial has been set as `radio_material` of the `SceneObject`, then the material is automatically applied when the `SceneObject` is added to the scene.\n\nIn code, it would look something like this:\n\n```python\ncustom_material = RadioMaterial(\"my_material\",\n                                relative_permittivity=2.0,\n                                conductivity=5.0,\n                                scattering_coefficient=0.3,\n                                xpd_coefficient=0.1,\n                                scattering_pattern=LambertianPattern())\nobj = scene.get(\"my_object\") # obj is a SceneObject\nobj.radio_material = custom_material # \"my_object\" is made of \"my_material\"\n```\n\nPlease note that the values of the material properties are typically numbers and cannot be tensors of any shape. If you want to make the material trainable, as shown in the last code snippet of the context, you can define the material parameters as TensorFlow variables or tensors. This gives you the possibility to make the material properties trainable."
"To perform maximum a posteriori (MAP) decoding with an instance of `BCJRDecoder`, you will need to create an instance of the decoder, which can be done by providing the `BCJRDecoder` class with the necessary parameters. From the given context, the parameters for the `BCJRDecoder` class are explained, but I will re-illustrate them for clarity:\n\n```python\nfrom sionna.fec.conv import BCJRDecoder\n\n# For a given instance of a ConvEncoder encoder, 'encoder', the BCJRDecoder is created with the following input parameters:\n\ndecoder = BCJRDecoder(encoder=encoder,    # If an encoder instance is provided, other parameters are ignored\n                      gen_poly=gen_poly,    # Generator polynomial for rate 1/2 convolutional codes\n                      rate=1/2,             # Rate of the code\n                      constraint_length=3, # Constraint length of the encoder\n                      hard_out=True)        # Explaining this parameter is the main focus of this part\n```\n\nNow, let's elaborate on the two possible types of input for decoding and the meaning of the `hard_out` parameter:\n\n1. **Input llr_ch: `llr_ch`**\n   The Maximum Likelihood (ML) decoder of a Binary Symmetric Channel (BSC) with Log-Likelihood Ratios (LLRs) as input is implemented by the `BCJRDecoder` class. The input LLRs represent the channel output probabilities parameterized by a real value. If the `hard_out` parameter is set to `True`, the decoder will output binary hard decisions (i.e., 0 or 1), which signifies the decoded information bit (either as an actual bit value or as a logical \"ask me again\" value like in computer memory setups). If `hard_out` is set to `False`, the decoder will output soft-decisions, providing a full-bitwise posterior probability distribution on the estimated codeword, indicating for each bit the probability of being a '0' or a '1'.\n\n2. **Input (llr_ch, llr_a): (llr_ch, llr_a)**\n   The `llr_ch` parameter represents the channel LLRs as explained above. The `llr_a` parameter corresponds to the LLRs of the a priori information, often associated with the message source. A message source is assumed to generate bits with a certain probability distribution. These generated bits may then be manipulated by processes like encoding, error adding, etc., before being transmitted. The LLRs for the a priori information reflect the confidence of the decoding process on the received bit sequence, based on the prior knowledge it had about the probabilities of these bits being a '0' or a '1'.\n\nThe `hard_out` parameter, which you specifically asked about, is crucial in determining the type of output from the BCJRDecoder. It specifies whether the output should be a hard decision bit vector representing the information bits (i.e., a binary vector of 0s and 1s) or soft information bit-wise estimates. In the former case, this results in a binary vector that directly indicates the decoded information bits. In the latter case, if set to `False`, the output will be a vector that provides, for each bit, the probability of being a '0' or a '1', indicating the confidence level of the decoding for each bit.\n\nThe type of output tensor from the decoder will therefore depend on the `hard_out` parameter:\n- If `hard_out` is `True`, the output tensor is a 2+D tensor of shape `[..., n]`, which contains the hard decided binary values of the information bits.\n- If `hard_out` is `False`, the output tensor is a 2+D tensor of shape `[..., n, 2]`, which presents the bit-wise soft information, i.e., the posterior probability of each bit.\n\n**Note:** The output tensor preserves the input tensor's outer dimensions and maintains the decoding output's structure in a Keras layer, facilitating the integration of the decoder into a Keras model as a layer."
"To use the `ebnodb2no` function, you will need to provide certain inputs and follow certain steps.\n\nInputs:\n1. `ebno_db`: This is the value of Eb/No (the energy per information bit to noise power spectral density ratio) in dB.\n2. `num_bits_per_symbol`: This is an integer value representing the number of bits per constellation symbol.\n3. `coderate`: This is a float value indicating the coderate used.\n4. `resource_grid`: This is an optional parameter. It represents an instance of a ResourceGrid, which is used for OFDM transmissions.\n\nSteps:\n1. The function requires these inputs in a specific order to compute the noise variance 'No'.\n2. The noise variance 'No' is inversely computed by using the given Eb/No value and various parameters like the energy per constellation symbol, the energy per information bit, and the coderate. Additional factors like the energy scaled for the cyclic prefix and the number of transmitted streams per transmitter may be considered, if provided.\n\n3. For OFDM transmissions, the energy 'Es' is scaled according to the ratio between the total number of resource elements in a resource grid with non-zero energy and the number of resource elements used for data transmission. Also, the additionally transmitted energy during the cyclic prefix is taken into account, as well as the number of transmitted streams per transmitter. Note that if the `resource_grid` parameter is not provided, this step will not be performed.\n\n4. The function returns the computed noise variance 'No'. The return type is a float. The noise variance is computed in linear scale."
"To evaluate the baseline and the two autoencoder-based communication systems, you can follow these steps:\n\n1. **Baseline Evaluation**: This is the most straightforward evaluation. The baseline is implemented using QAM with Gray labeling and conventional demapping for an AWGN (Additive White Gaussian Noise) channel. The model is defined as a class `Baseline` which inherits from the Keras `Model` class. The `call` method of the `Baseline` class is used to simulate the communication system, including the transmitter, channel, and receiver. The baseline is evaluated by simulating the Bit Error Rate (BER) and Block Error Rate (BLER) over a range of SNR (Signal-to-Noise Ratio) values using the `simulate` method of the `PlotBER` class.\n\n2. **Autoencoder-based Communication Systems**: The two autoencoder-based communication systems are evaluated in the same way as the baseline. They are implemented using different methods for handling the transmitter and receiver.\n\n   - **Method 1**: In this method, a complex binary latent vector is generated using a Binary Source. A Dense Layer is used to map this to the constellation points, and the AWGN channel is simulated. The receiver uses the conventional QAM demapping rule and a Binary Hard Decision is made to get the binary representation of the transmitted symbol. The `PlotBER` class is used to simulate the BER and BLER over a range of SNR values.\n\n   - **Method 2**: This method is similar to Method 1, but it uses a different binary source and does joint decoding to improve performance. The `PlotBER` class is used to simulate the BER and BLER over a range of SNR values.\n\n3. **Running the Evaluation**: The `ebno_db` values for the SNR range are defined using `np.arange`. The specified SNR range is then evaluated for each system. The `simulate` method of the `PlotBER` class is used to run the evaluation and plot the results.\n\nRemember to set the `trainable` parameter to `False` for all the communication system components during the evaluation to ensure that they are used as-is, without any training."
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can follow these steps:\n\n1. Import the `tensorflow` module in Python.\n\n```python\nimport tensorflow as tf\n```\n\n2. Check the list of available GPUs on your system.\n\n```python\ngpus = tf.config.list_physical_devices('GPU')\nprint('Number of GPUs available :', len(gpus))\n```\n\n3. If multiple GPUs are available, set the `gpu_num` variable to the index of the GPU you want to use. If only one GPU is available, you can skip this step.\n\n4. Try to set the notebook to allocate only as much memory as needed on the GPU. This can be done using the `tf.config.set_in_memory_growth` function. This function attempts to allocate only as much GPU memory as needed for the runtime allocations.\n\n```python\ntf.config.set_in_memory_growth(gpus[gpu_num], True)\n```\n\n5. To ensure that the `tf.config.set_in_memory_growth` function is effective, catch the `RuntimeError` that it may raise if the GPU has already been initialized. This can be done using a `try`/`except` block.\n\n```python\ntry:\n    tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\nexcept RuntimeError as e:\n    print(e)\n```\n\n6. Finally, print the number of GPUs that are now available for the notebook.\n\n```python\ngpus = tf.config.list_physical_devices('GPU')\nprint('Number of GPUs available :', len(gpus))\n```\n\nPlease note that the `gpu_num` variable is the index of the GPU you want to use. You can change this to the index of the GPU you want to use. For example, if you want to use the first GPU, you would set `gpu_num` to 0. If you want to use the second GPU, you would set `gpu_num` to 1."
"To use the \"j_fun\" function in the Sionna package to calculate the J-function, you can follow these steps:\n\n1. Import the necessary function from the sionna package.\n\n```python\nfrom sionna.fec.utils import j_fun\n```\n\n2. Define the mean (mu) of the Gaussian distributed LLRs. It can be a float or a numpy array of floats.\n\n3. Call the \"j_fun\" function with the defined mean as the argument.\n\n```python\nj_fun(mu)\n```\n\nThe function will return a numpy array with the same shape and datatype as the `mu` which is the J-function evaluated at the mean of the Gaussian distributed LLRs.\n\nPlease be aware that the provided information is based on the context and the Sionna package documentation. Make sure to refer the official package documentation or validate the usage from the context when using the function."
"Here is the definition of PUSCHTransmitter: sionna.nr.PUSCHTransmitter(pusch_config, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/nr/pusch_transmitter.html#PUSCHTransmitter)\n\n```python\n#\n# SPDX-3-Clause-License\n#\n# Copyright 2021-2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n#\n# Licensed under the SPDX License Usage Examples code use only\n# Use only included code from sionna if (i) the code is used for verification\n# and validation only, (ii) the code is not used in the pr"
"Here is the detailed information of verify_gm_pcm:   \n  \n[sionna.fec.utils.verify_gm_pcm(gm, pcm)](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#verify_gm_pcm)  \n\nVerify that generator matrix gm and parity-check matrix pcm are orthogonal in GF(2).\n\nFor an all-zero syndrome, it must hold that\n\n$H \\mathbf{c}^t = H * (\\mathbf{u} * \\mathbf{G})^t = H * \\mathbf{G} ^t * \\mathbf{u}^t =: \\mathbf{0}$\n\nwhere $\\mathbf{c}$ denotes an arbitrary codeword and $\\mathbf{u}$ the corresponding information bits.\n\nAs $\\mathbf{u}$ can be arbitrary it follows that\n\n$H * \\mathbf{G} ^t =: \\mathbf{0}.$\n\nInput\n\n        gm (ndarray) \u2013 Binary generator matrix of shape [k, n].\n        pcm (ndarray) \u2013 Binary parity-check matrix of shape [n-k, n].\n\nOutput\n\n        bool \u2013 True if gm and pcm define a valid pair of parity-check and generator matrices in GF(2).  \n  "
"The permittivity and permeability are key parameters that describe the behavior of materials in the context of electromagnetics.\n\nPermittivity (denoted as $\\eta$) represents the measure of how a material responds to an electric field, and it is associated with the capacitance of the material. The permeability (denoted as $\\mu$) refers to the material's response to a magnetic field.\n\nThese quantities are typically given as the square root of the ratio of the corresponding field quantities in vacuum (i.e., the electric field or the magnetic field) and the impedance of the material. The impedance is defined as the square root of the ratio of the permeability to the permittivity. Therefore, the permittivity and permeability are given by the square roots of the corresponding relative quantities (which are the dielectric constant and the magnetic relative permeability) of the material.\n\nIn symbols:\n- Permittivity: $\\eta = \\sqrt{\\varepsilon_r \\mu \\varepsilon_0}$\n- Permeability: $\\mu = \\sqrt{\\mu_r \\varepsilon_0}$\n   \nwhere $\\varepsilon_r$ is the dielectric constant, $\\varepsilon_0$ is the vacuum permittivity, $\\mu_r$ is the magnetic relative permeability, and $\\varepsilon_0$ is the vacuum permeability. Note that in many materials, the permeability is very close, or equal, to the vacuum permeability, and therefore the difference can be neglected."
"Here is the detailed information of RemoveNulledSubcarriers:   \n  \n[sionna.ofdm.RemoveNulledSubcarriers(keep_guard=0)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/resource_grid.html#RemoveNulledSubcarriers)  \n\nRemoves nulled subcarriers from a resource grid.\n\nThis layer removes nulled subcarriers from a OFDM ResourceGrid. Nulled subcarriers are often used to to ensure that a transmitter and receiver are using compatible FFT sizes and to avoid ICI caused by pilots on strong subcarriers.\n\nThe input can be of shape (batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size) or just (batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols) if no guard and dc carriers are removed.\n\n### Parameters\n\n- `keep_guard` (bool): Defaults to False. If True, the guard and dc carriers are not removed.\n\n### Input\n\n- `inputs` ([batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size] or [,batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols], tf.complex): The resource grid.\n\n### Output\n\n- `outputs` ([batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols, num_allowed_subcarriers], tf.complex): The resource grid without nulled subcarriers. The number of allowed subcarriers is smaller (or equal) to the fft_size.\n\n### Properties\n\n**Property: `num_allowed_subcarriers`**\n- The number of allowed subcarriers after removal of nulled subcarriers."
"Here is the definition of LLRs2SymbolLogits: sionna.mapping.LLRs2SymbolLogits(num_bits_per_symbol, hard_out=False, dtype=tf.float32, **kwargs)\n\nThe link of the source code of LLRs2SymbolLogits is: https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#LLRs2SymbolLogits\n\nHere is the explanation of LLRs2SymbolLogits: This layer computes logits (i.e., unnormalized log-probabilities) or hard decisions on constellation points from a tensor of log-likelihood ratios (LLRs) on bits.\n\nThe parameters are:\n\n- **num_bits_per_symbol**: The number of bits per constellation symbol, e.g., 4 for QAM16.\n- **hard_out**: If set to True, the layer provides hard-decided constellation points instead of soft-values. Defaults to False.\n- **dtype**: The dtype for the input and output. Defaults to tf.float32.\n\nThe LLR definition that is used in this class is different from that found in many textbooks in communications, where the LLR is defined as $LLR(i) = \\\\ln\\\\left(\\\\frac{\\\\Pr\\\\left(b_i=0\\\\lvert y\\\\right)}{\\\\Pr\\\\left(b_i=1\\\\lvert y\\\\right)}\\\\right)$. The definition has been chosen such that it is equivalent with that of logits. This is different from many textbooks in communications, where the LLR is defined as $LLR(i) = \\\\ln\\\\left(\\\\frac{\\\\Pr\\\\left(b_i=0\\\\lvert y\\\\right)}{\\\\Pr\\\\left(b_i=1\\\\lvert y\\\\right)}\\\\right)$."
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can follow these steps:\n\n1. Import the necessary libraries:\n```python\nimport tensorflow as tf\n```\n\n2. List the physical devices available for tensorflow to use:\n```python\ngpus = tf.config.list_physical_devices('GPU')\nprint('Number of GPUs available :', len(gpus))\n```\nThis will print the number of GPU devices available. If only one GPU is available, you can skip the next step. However, if multiple GPUs are available, you need to set the notebook to use only a single GPU and allocate only as much memory as needed.\n\n3. Set the notebook to use only a single GPU and allocate only as much memory as needed:\n```python\ngpu_num = 0 # Index of the GPU to be used\n\ntf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n```\nIn this code, `tf.config.set_visible_devices(gpus[gpu_num], 'GPU')` is used to specify that only the GPU with the specified index should be used. The index is zero-based, so `gpu_num = 0` means the first GPU.\n\n4. Set the memory growth option for the specified GPU:\n```python\ntf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n```\nThe `tf.config.experimental.set_memory_growth` function is used to enable memory growth for the specified GPU. When memory growth is enabled, TensorFlow allocates only as much GPU memory as needed for the runtime allocations: it starts out allocating very little memory, and as the program gets run and more GPU memory is needed, TensorFlow extends its GPU memory region to fulfill the runtime's needs."
"To compute codeword bits from information bits using the `LinearEncoder`, you need to follow a specific set of steps. However, since the context does not provide the necessary information to demonstrate these steps directly, I will outline the general process based on the typical use of an `LinearEncoder` with binary parity-check and generator matrices.\n\n1. **Importing the Encoder**: You need to import the `LinearEncoder` from the `sionna.fec.linear` module. If the generator or parity-check matrix is not already available, you can initialize the encoder with an appropriate matrix.\n\n2. **Defining the Information Bits**: The information bits represent the raw data that you want to encode. These bits are typically in binary format, with the number of bits equal to `k`, which is the number of information bits per codeword.\n\n3. **Encoding the Information Bits**: Once the `LinearEncoder` is initialized, you can use it to encode the information bits. The `LinearEncoder` expects the information bits to be provided as an input either in the form of a numpy array or a tensor. When you call the encoder with the information bits as an argument, it returns the codeword bits.\n\nHere is a Python snippet that demonstrates these steps:\n\n```python\nimport numpy as np\nfrom sionna.fec.linear import LinearEncoder\n\n# Define the parity-check matrix\npcm = np.array([[1, 1, 1, 0, 1, 0, 0],\n                [0, 1, 1, 1, 0, 1, 0],\n                [1, 1, 0, 1, 0, 0, 1]])\n\n# Initialize the encoder with the parity-check matrix\nencoder = LinearEncoder(enc_mat=pcm, is_pcm=True)\n\n# Define a set of information bits u\n# For example, let's assume u has shape [...,k] and is filled with random 0's and 1's\nk = 10  # Number of information bits per codeword\nu = np.random.randint(0, 2, size=(100, k)).astype(np.float32)\n\n# Encode the information bits to obtain the codeword bits\nc = encoder(u)\n```\n\nIn the context of a LinearEncoder, it's important to note that the input matrix should be binary and of full rank if you are supplying a parity-check matrix. If you opt to initialize the encoder with a generator matrix, please ensure that it meets the necessary criteria (typically being binary and of shape `[k, n]` where `k` is the number of information bits and `n` is the codeword length)."
"Here is the detailed information of sionna.utils.flatten_last_dims:  \n\n[sionna.utils.flatten_last_dims(tensor, num_dims=2)](https://nvlabs.github.io/sionna/_modules/sionna/utils/tensors.html#flatten_last_dims)\n\nFlattens the last n dimensions of a tensor.\n\nThis operation flattens the last num_dims dimensions of a tensor. It is a simplified version of the function flatten_dims.\n\nParameters\n\n- `tensor` (A tensor): The tensor to flatten.\n- `num_dims` (An integer): The number of dimensions to combine. Must be greater than or equal to two and less or equal than the rank of tensor.\n\nReturns\n\n- A tensor of the same type as `tensor` with num_dims-1 lesser dimensions, but the same number of elements."
"Here is the definition of Mapper:  \"sionna.mapping.Mapper(constellation=None, binary=False, with_mapping_indices=False, dtype=tf.complex64, **kwargs)\"\n  \nsource code:  \n```python\nclass Mapper(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    The :class:`~sionna.mapping.Mapper` is a\n    :class:`~sionna.mapping.DifferentialBase` used to map a sequence of\n    bits to a constellation symbol. It can be made trainable\n    to enable the learning of geometric shaping.\n\n    This class is a layer implementing the Keras API by defining\n    the ``call`` method.\n\n    Parameters\n    ----------\n    constellation : :class:`~sionna.mapping.Constellation` or `None`\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, :const:`~sionna.mapping.Constellation.arity` and\n        :const:`~sionna.mapping.Constellation.bits_per_symbol` must be\n        specified.\n\n    binary : bool\n        Defaults to `True`. If `True`, the `constellation` is\n        set through its :obj:`~sionna.mapping.Constellation` property.\n        Otherwise, the constellation is set during initialization or through\n        the :meth:`~sionna.mapping.Mapper.constellation` property.\n\n    with_mapping_indices : bool\n        Defaults to `False`. If `True`, the function also returns the symbol\n        indices corresponding to the mapped bits.\n\n    dtype : tf.DType\n        Defaults to `tf.complex64`. Defines the datatype for internal\n        calculations and the output dtype.\n\n    Input\n    -----\n    (bits, : [B1, B2, \u2026, BN], tf.float)\n        A tensor of arbitrary rank filled with ones and zeros.\n\n    Output\n    ------\n    : [, :  ...,  num_points], tf.complex\n        The mapped constellation symbols.\n\n    : [, :  ...,  num_points], tf.int\n        Mapped constellation symbol indices. This\n        tensor is only returned if ``with_mapping_indices`` is `True`.\n    \"\"\"\n    def __init__(self,\n                 constellation=None,\n                 binary=True,\n                 with_mapping_indices=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n\n        # Instantiate a constellation object or set it directly\n        self._constellation = Constellation.create_or_check_constellation(\n                                                        constellation,\n                                                        binary=binary,\n                                                        dtype=dtype)\n        self._with_mapping_indices = with_mapping_indices\n\n    @property\n    def constellation(self):\n        return self._constellation\n\n    @constellation.setter\n    def constellation(self, value):\n        if not isinstance(value, Constellation):\n            raise TypeError(\"Not a valid Constellation object.\")\n        self._constellation = value\n\n    @property\n    def binary(self):\n        \"\"\"Indicates whether the mapper is configured for binary operations.\"\"\"\n        return self._constellation.binary\n\n    @property\n    def with_mapping_indices(self):\n        \"\"\"Indicates whether symbol indices are returned.\"\"\"\n        return self._with_mapping_indices\n\n    def call(self, inputs):\n        x = inputs\n        y = self._constellation(x)\n        if self.with_mapping_indices:\n            return y, self._constellation.mapping_indices\n        return y\n```\n  "
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can follow these steps:\n\n1. Import the necessary libraries:\n```python\nimport tensorflow as tf\n```\n\n2. Check the number of GPUs available:\n```python\ngpus = tf.config.list_physical_devices('GPU')\nprint('Number of GPUs available :', len(gpus))\n```\nThis will print the number of GPUs available. If only one GPU is available, you can skip the rest of the steps. If more than one GPU is available, you can set the notebook to use only a single GPU by specifying the GPU number.\n\n3. Set the GPU number to be used:\n```python\ngpu_num = 0 # Index of the GPU to be used\n```\n\n4. Set the environment variables for the GPU to be used:\n```python\ntry:\n    tf.config.set_visible_devices([], 'GPU')\n    tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n    print('Only GPU number', gpu_num, 'used.')\n    tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\nexcept RuntimeError as e:\n    print(e)\n```\nThe first line sets the notebook to use no GPU. The second line sets the notebook to use the GPU with the specified index. The third line allows memory to be allocated when requested by the program. \n\n5. To ensure that this configuration is used for all TensorFlow operations, you can set the environment variables globally:\n```python\ntf.get_logger().setLevel('INFO')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n6. Finally, you can use the `nvidia-smi` command to check the GPU usage and memory allocation:\n```python\n!nvidia-smi\n```\nThis will display the GPU information, including the GPU number, GPU utilization, and memory usage."
"The definition of BinaryErasureChannel is `sionna.channel.BinaryErasureChannel(return_llrs=False, bipolar_input=False, llr_max=100., dtype=tf.float32)`. The source code is [BinaryErasureChannel](https://nvlabs.github.io/sionna/_modules/sionna/channel/discrete_channel.html#BinaryErasureChannel), which is implemented in [discrete_channel.py](https://nvlabs.github.io/sionna/_modules/sionna/channel/discrete_channel.html). \n\nThe BinaryErasureChannel is a discrete channel where a bit is either correctly received or erased. In the binary erasure channel, bits are always correctly received or erased with erasure probability \ud835\udc5d\ud835\udc4f. \n\nThis class inherits from the Keras Layer class and can be used as a layer in a Keras model.\n\n### Parameters\n\n- **return_llrs** (bool):  Defaults to False. If True, the layer returns log-likelihood ratios (LLRs) instead of binary values based on pb.\n- **bipolar_input** (bool):  Defaults to False. If True, the expected input is {-1,1} instead of {0,1}.\n- **llr_max** (tf.float):  Defaults to 100. Defines the clipping value of the LLRs.\n- **dtype** (tf.DType):  Defines the datatype for internal calculations and the output dtype. Defaults to tf.float32.\n\n**Input**\n\n- **(x, pb)** - Tuple: \n  - **x** ([,n], tf.float32): Input sequence to the channel.\n  - **pb** (tf.float32): Erasure probability. Can be a scalar or of any shape that can be broadcasted to the shape of x.\n\n**Output** - [,n], tf.float32: Output sequence of same length as the input x. If return_llrs is False, the output is -1 where each erasure happened, and 0 otherwise. If return_llrs is True, it returns soft-values instead of -1/0.\n\nWe note that the BinaryErasureChannel doesn't support the erase bit flag, unlike the BinarySymmetricChannel and BinaryZChannel."
"To set up the environment for the Sionna simulation, the following components are required:\n\n1. LDPC Belief Propagation (BP) Decoder: This is a `class` within the Sionna library that is used for decoding LDPC codes. It can be made trainable and is implemented with either the box plus (boxplus-phi) or the min-sum algorithm.\n\n2. Gaussian LLR Source: This is another `class` within the Sionna package used to generate Gaussian log-likelihood ratios (LLRs). The LLR defines the channel transition probabilities in the model.\n\nThese components are used in the process of setting up the `LDPCBPDecoder` and the model for Forward Error Correction (FEC) simulation.\n\nThe LDPC BP Decoder is instantiated with the following parameters:\n- `encoder` (LDPC5GEncoder): An instance of the LDPC5GEncoder used for the encoding process.\n- `trainable` (bool): Indicates whether the decoder is trainable. Defaults to False.\n- `cn_type` (str): Specifies the check node processing function of the decoder. Can be 'boxplus-phi' or 'minsum'. Defaults to 'boxplus-phi'.\n- `hard_out` (bool): If True, the decoder provides hard-decided bit values. Defaults to True.\n- `track_exit` (bool): If True, the decoder tracks EXIT (Extrinsic Information Transfer) characteristics. Note that this requires the all-zero codeword as input. Defaults to False.\n- `return_infobits` (bool): If True, only the information bits are returned. Otherwise, all positions are returned. Defaults to True.\n- `prune_pcm` (bool): If True, degree-1 variable nodes and connected check nodes are removed. Defaults to True.\n- `num_iter` (int): Defines the number of iterations of the decoder. Defaults to 20.\n- `stateful` (bool): If True, the decoded VN messages from the last decoding iteration are returned, and `msg_vn` or None needs to be given as a second input when calling the decoder. Defaults to False.\n- `output_dtype` (tf.DType): Specifies the output datatype of the decoder. Defaults to tf.float32.\n\nThe Gaussian LLR Source is set up with the following parameters:\n- `llr_max` (float): The maximum value assigned to an LLR. Defaults to 100.\n- `dtype` (tf.DType): The datatype of the output. Defaults to tf.float32.\n\nThese components are used to instantiate the necessary tools and simulators for the FEC simulation."
"To use the PUSCHDMRSConfig class and its properties in the Sionna's API, you will instantiate a PUSCHDMRSConfig object with the required parameters. \n\nFor example, to define a DMRS configuration for a PUSCH transmission with configuration type 2 and a length of 1, you would do the following:\n\n```python\nfrom sionna.nr import PUSCHDMRSConfig\n\ndmrs_config = PUSCHDMRSConfig(config_type=2, length=1)\n```\n\nOnce you've created a PUSCHDMRSConfig object, you can modify its properties directly. For instance, if you want to use an additional_position for your DMRS, you can set it like this:\n\n```python\ndmrs_config.additional_position = 1\n```\n\nRemember to always refer to the documentation to understand the meaning and range of valid values for each property. \n\nThe PUSCHDMRSConfig class is designed to provide configuration options for the generation of demodulation reference signals (DMRS) for a physical uplink shared channel (PUSCH), according to the 3GPP 38.211 standard. The class's properties are typically designed to mirror the possible configuration options available in that standard. \n \nNote: This instruction assumes configuration for a PUSCH transmission with configuration type 2 and a length of 1. Be sure to adapt the configuration parameters to your specific needs, based on the requirements of the 3GPP 38.211 standard."
"To demonstrate the encoding of information bits using an instance of `ConvEncoder`, we need to follow these steps:\n\n1. Create an instance of the `ConvEncoder` with the appropriate parameters. The `ConvEncoder` parameters include generator polynomials (`r`) which dictate the connections between the shift registers, and the rate at which bits are taken out of the registers (not including the systematic part).\n\n2. The input bit sequence to be encoded should be in the form of a 2D or higher dimensional tensor, where the last dimension contains the information bits (`k` bits). The type of the input tensor is `tf.float32`.\n\n3. Call the created `ConvEncoder` instance with the tensor containing the information bits as the input. The `ConvEncoder` outputs the encoded codewords, which are also in the form of a tensor. The encoded codewords have dimensions similar to the input tensor, with the last dimension being `n` (the length of the codeword).\n\nLet's now go through an illustration of these steps and their corresponding input and output tensors:\n\n```python\nimport tensorflow as tf\nfrom sionna.fec.conv import ConvEncoder\n\n# Assume u is your tensor with shape [...,k] containing the information bits.\n# For the sake of demonstration, let's set k to 4.\nk = 4\nu = tf.random.normal(shape=[32, k], dtype=tf.float32)\n\n# Create a ConvEncoder instance with a single constraint length (5) and\n# a memory of 4. The memory is the number of shift registers in the encoder.\nencoder = ConvEncoder(k, n, tf.constant([23, 33], dtype=tf.int))\n\n# c will contain the codewords with shape [...,n]\nc = encoder(u)\n```\n\nIn this example, the input is a tensor `u` of information bits with shape `[...,4]`.\nThe output is a tensor `c` of the encoded codewords with shape `[...,n]`.\n\nOn the last line, `c` is the output from the encoder. It is important to note that the shape of `c` will depend on the dimensions of `u`, the last of which should correspond to the number of information bits (`k`). The other dimensions will be retained to maintain the structure of the original input tensor.\n\nIt's also crucial to mention that the generator polynomials `r` used to initialize the `ConvEncoder` in the actual implementation would need to be defined based on the specific requirements of the system and the characteristics of the underlying convolutional code that the encoder is intended to implement."
"The DMRS Configuration in the Sionna S/W package is achieved using the `PUSCHDMRSConfig` class. DMRS stands for Demodulation Reference Signals and is a sort of pilot signal in the time-frequency grid that allows the receiver to align and demodulate the data stream. \n\nAn instance of the `PUSCHDMRSConfig` class has parameters that can be adjusted as per the user requirements. These include `additional_position`, `allowed_dmrs_ports`, `beta`, `cdm_groups`, `config_type`, `deltas`, `dmrs_port_set`, `length`, `n_id`, `n_scid`, `num_cdm_groups_without_data`, `nushifts`, `type_a_position`, and others. These parameters allow configuration of the DMRS to a significant degree. \n\nThe pilot pattern can be visualized using the `show` method of the `PUSCHDMRSConfig` class. This method takes several parameters including `show_gb`, `subcarrier_spacing`, `n_reg_per_prb`, `start_prb`, `lamb`, `show_users`, `cbar`, and `ax`. These parameters would generate a DMRS pilot pattern of the configuration which can be visualized as output."
"To visualize common scattering patterns using the Sionna package, you can use the `LambertianPattern().visualize()` and `DirectivePattern(alpha_r=10).visualize()` methods. Here's a step-by-step guide:\n\n1. Import the necessary modules:\n\n```python\nfrom sionna.rt import LambertianPattern, DirectivePattern\n```\n\n2. Create the required pattern objects:\n\n```python\nlambertian_pattern = LambertianPattern()\ndirective_pattern = DirectivePattern(alpha_r=10)\n```\n\n3. Visualize the patterns:\n\n- To visualize the Lambertian scattering pattern, use the following code:\n\n```python\nlambertian_pattern.visualize();\n```\n\nThis will generate a 3D plot of the scattering pattern.\n\n- To visualize the directive scattering pattern, use the following code:\n\n```python\ndirective_pattern.visualize();\n```\n\nThis will generate a 3D plot of the directive scattering pattern.\n\nRemember that the directive scattering pattern can be more concentrated around the specular direction, with the degree of concentration controlled by the `alpha_r` parameter. A larger `alpha_r` means the scattered energy is more concentrated around the specular direction."
"To handle import errors for the Sionna package, the code first attempts to import the package. If the package is not found and triggers an `ImportError`, the code then enters a `except` block. \n\nIn the `except` block, the code first determines the root cause of the `ImportError` by checking the `__spec__` attribute of the `sionna` module. If the `__spec__` is None, it means that the package is not installed. In this case, the code uses the `os.system` function to run the `pip install` command to install the package. \n\nAfter the package is installed, the code attempts to import the package again. If the package is successfully imported in the second attempt, the code can continue. If the second import still fails, it could be due to issues with the system's Python installation or the `pip install` process."
"To import the necessary Sionna APIs, you can follow the steps below:\n\n1. Import the `os` module and set the environment variables. The `GPU_NUM` variable is used to specify the GPU number to use. If you want to use the CPU, you can set `GPU_NUM` to an empty string.\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n2. Import the Sionna package. If it's not already installed, the code will install it using pip.\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n3. Import the necessary Sionna APIs. The `sn` prefix is commonly used for Sionna APIs.\n\n```python\nimport sionna as sn\nfrom sionna.mimo import StreamManagement\nfrom sionna.ofdm import ResourceGrid, LSChannelEstimator, LMMSEEqualizer\nfrom sionna.ofdm import OFDMModulator, OFDMDemodulator, ZFPrecoder, RemoveNulledSubcarriers\nfrom sionna.channel.tr38901 import AntennaArray, CDL, Antenna\nfrom sionna.channel import cir_to_ofdm_channel, subcarrier_frequencies, cir_to_time_channel\nfrom sionna.channel import ApplyOFDMChannel, ApplyTimeChannel, OFDMChannel, TimeChannel\nfrom sionna.channel import cir_to_ofdm_channel_time, cir_to_time_channel_time\nfrom sionna.fec.ldpc import LDPC5GEncoder\nfrom sionna.fec.ldpc import LDPC5GDecoder\nfrom sionna.mapping import Mapper, Demapper, Constellation, CameraArray, Scene, LoadScene\nfrom sionna.mapping import SceneObject\nfrom sionna.utils import Quaternion, ricker, dricker\nfrom sionna.utils import sim_snr, PlotBER, cir_to_ofdm_channel_freq\nfrom sionna.utils import ebnodb2no, PlotSER\nfrom sionna.utils import zero_forcing_precoding, get_precoding_matrix\n```\n\nPlease note that the code snippets provided in the context are based on the assumption that the necessary Sionna APIs are already installed in your environment. If not, you may need to install the Sionna package and the APIs as per the guidance in the context."
"The Descrambler class is a part of the 'sionna.fec.scrambling' module and is used to reverse the scrambling operation that was performed on a binary or soft value sequence. It takes as input either a scrambling seed and binary flag, or a Scrambler instance. \n\n- If provided a Scrambler instance, the Descrambler makes an internal copy of the associated Scrambler. This ensures that the descrambler remains functional even if the original Scrambler instance is altered or lost. \n- The binary flag, when set to True, indicates that the Descrambler should perform flipping operations (i.e., binary operations) rather than reverse the signs (like in the soft value/LLR domain). The scrambling can only be properly reversed if the binary flag is set to True, assuming Scrambler was initially created with `binary=True`.\n- The 'dtype' parameter is used to define the datatype for internal calculations and the output dtype. If no explicit dtype is provided, the dtype from the associated interleaver is used.\n\nInput: \n        (x, seed)\n    - Either as a tuple (x, seed) or just x (no tuple) is seed is not given.\n    - `x` is a 1+D tensor of arbitrary shape and of type tf.float.\n    - `seed` should be an integer and of type `tf.int32`, indicating the state of the random number generator. If explicitly given, the global internal seed is replaced by this seed. This can be used to realize scrambler/descrambler pairs (call with same random seed).\n\nOutput:\n    - Returns a 1+D tensor `y` of same shape and type as `x`.\n\nIt raises an AssertionError if\n- the Scrambler input is not of type 'Scrambler'.\n- the 'seed' input is not an int.\n  \nIt raises TypeError if the 'dtype' of 'x' is not as expected, specifically, it should be tf.float.\n\nThis class inherits from the Keras layer class and can be used as layer in a Keras model. \nThe descrambler must have the same datatype (`dtype`) as the associated scrambler. \nTo use the descrambler in a model, it should be instantiated with the model parameter set to True. \nIf the descrambler is in binary mode, the binary flag should be set to True. Example setting descrambler:\n```python\ndescrambler = Descrambler(scrambler=tb_scr, binary=True)\n```\n\nThe property `scrambler` is used to access details about the Scrambler instance that the Descrambler is associated with. \n  "
"To perform Polar decoding using an instance of `Polar5GDecoder` with log-likelihood ratios (LLRs) as inputs, you will need to follow these steps:\n\n1. Import the necessary modules and set up the environment:\n\n    ```python\n    from sionna.fec.polar.decoding import Polar5GDecoder\n    import tensorflow as tf\n    import numpy as np\n    ```\n\n2. Define the parameters for your simulation:\n\n    ```python\n    k = 100  # Number of information bits\n    n = 200  # Number of codeword bits\n    n_iter = 20  # Number of iterations for the belief propagation algorithm\n    ```\n\n3. Instantiate the `Polar5GDecoder` class:\n\n    ```python\n    # Make sure the decoder is set to use the belief propagation algorithm\n    decoder = Polar5GDecoder(enc_polar=enc_polar, dec_type=\"BP\", list_size=1, num_iter=n_iter)\n    ```\n\n4. Generate a random array of LLRs to serve as input to the decoder:\n\n    ```python\n    # Assume llr is a tensor of shape [..., n] containing the channel LLRs\n    ```\n\n5. Perform the Polar decoding:\n\n    ```python\n    u_hat = decoder(llr)\n    ```\n\nThe resulting `u_hat` tensor contains the estimates of the transmitted information bits. Please note that the exact way to generate the LLRs will depend on your specific use case and data format. The steps provided above assume that you already have a set of LLRs ready to be decoded."
"To load a scene from a file using the `load_scene()` function from the Sionna package, you can follow these steps:\n\n1. Import the necessary module from the Sionna package.\n\n```python\nfrom sionna.rt import load_scene\n```\n\n2. Call the `load_scene()` function with the filename of the scene you want to load.\n\n```python\nscene = load_scene(scene_filename)\n```\n\nIn the code snippet above, `scene_filename` is the name of the scene file you want to load. The `load_scene()` function will return a `Scene` object that represents the scene you've loaded. You can then use this object to carry out operations related to the scene, such as rendering or modifying its properties. \n\nPlease note that the actual filename and the specific path within the file system must be provided in the `scene_filename`. The `scene_filename` here should be a string that looks like this: \"path_to_file/scene_name\". Replace \"path_to_file\" with the actual path to the file in your system and \"scene_name\" with the name of the scene."
