"When creating a `Polar5GEncoder` instance in Sionna to perform 5G-compliant Polar encoding, the parameters `k` and `n` must be defined. The variable `k` represents the number of information bits to be encoded, and `n` represents the length of the codeword after encoding. These parameters are required to ensure the Polar code is constructed according to 5G specifications, including the rate-matching procedure.\n\nHere is an example of how to instantiate a `Polar5GEncoder` with `k` and `n` defined:\n\n```python\nfrom sionna.fec.polar.encoding import Polar5GEncoder\n# Define the two parameters: k and n\nk = 100  # Replace with the actual number of information bits\nn = 200  # Replace with the actual codeword length\n\n# Create a Polar5GEncoder instance with the specified k and n\nencoder = Polar5GEncoder(k=k, n=n)\n```\n\nIn the provided context, the notation to instantiate a `Polar5GEncoder` is shown in the context of other Sionna APIs related to Polar encoding. For example, with the Sionna `Polar5GEncoder` returned from the utility function `generate_5g_encoder`, the `k` and `n` would need to be defined as follows:\n\n```python\nfrom sionna.fec.polar.utils import generate_5g_encoder\n# Define the two parameters: k and n\nk = 100  # Replace with the actual number of information bits\nn = 200  # Replace with the actual codeword length\n\n# Create a Polar5GEncoder instance with the specified k and n\nencoder, e_idx, i_n = generate_5g_encoder(k=k, n=n)\n```\n\nIn both cases, ensure that `k` and `n` are defined with actual values appropriate for the use case. For the example given here, replace `100` and `200` with the actual numbers of information bits and the desired codeword length, respectively."
"To import DeepMIMO and generate a dataset, follow the steps below:\n\n1. First, you need to import the DeepMIMO module. If it's not already installed, you can install it using pip. Here is the command to do this:\n\n```python\ntry:\n    import deep_mimo.DeepMIMO as deep_mimo\nexcept ImportError as e:\n    # Install DeepMIMO if package is not already installed\n    import os\n    os.system(\"pip install deep-mimo\")\n    import deep_mimo.DeepMIMO as deep_mimo\n```\n\n2. Once you have imported the DeepMIMO module, you can generate a dataset. The DeepMIMO dataset is generated using the `DeepMIMO` class from the DeepMIMO module. You can specify the scenario you want to generate data for, the kind of dataset you want to create (either system or channel level measurements), the carrier frequency, the \"UT\" (user terminal, or mobile device) array configuration, and the \"BS\" (base station) array configuration. \n\nHere is an example of how to create a DeepMIMO dataset:\n\n```python\nscenario = 'omni_urban_macro_600MHz'\nnum_rx = 10\nnum_rx = 1\ncarrier_frequency = 3.5e9\nut_array = 'ue'\nbs_array = 'centered_ULA'\ndataset = deep_mimo.DeepMIMO(scenario=scenario,\n                             num_rx=num_rx,\n                             num_rx_per_ut=num_ut,\n                             rx_array=bs_array,\n                             ut_array=ut_array,\n                             carrier_frequency=carrier_frequency,\n                             dset_type='synthetic',\n                             synthetic_or_real='synthetic',\n                             o2i_model='high',\n                             return_ind=True)\n```\n\nIn this example, the dataset is generated for the 'omni_urban_macro_600MHz' scenario. The scenario contains 3D maps that define the environment at the carrier frequency of 600MHz. The `DeepMIMO` class is used to generate a dataset consisting of channel impulse responses and their corresponding path-relative components (in the time or frequency domain), as well as the locations and angles of arrival for each path of each of the `num_rx` receivers. The dataset is generated for `num_rx` receivers, each of which has `num_rx_per_ut` antennas. The array configuration for the receivers (UT) and the transmitters (BS) are defined using the 'ue' and 'centered_ULA' parameters, respectively. The carrier frequency is set to 3.5GHz. The dataset is synthetic, meaning that the channel impulse responses are computed synthetically based on the defined 3D map of the scenario, considering the properties of the environment and the antenna arrays."
"After training the model, you can plot the weights of the decoder to compare the new Bit Error Rate (BER) performance. Here's how you can do it:\n\n1. Retrieve the weights of the decoder: use the `get_weights()` function of the decoder object in the model. For instance, if your model is named `model`, you would use `model.decoder.get_weights()`.\n\n2. Plot the weights: you can simply use `plt.plot(weights)` if you are using matplotlib library. Make sure to import the necessary libraries (`import matplotlib.pyplot as plt`).\n\n3. Compare the new BER performance: after training, you should have a new set of weights. You can compute the BER and compare it with the previous one. You can use the `compute_ber_analytic()` and `compute_ber(model, snr_db, num_bits_per_symbol, batch_size)` functions, if they are available in the code you are working with.\n\nHere is an example of how to plot the weights after training (assuming you already have a model and have trained it):\n\n```python\n# Plot the weights before and after training\nweights_before = model.decoder.get_weights()\nplt.title('Weights before training')\nplt.plot(weights_before)\n\n# (After training...)\n# new_weights = model.decoder.get_weights()\n# plt.title('Weights after training')\n# plt.plot(new_weights)\n```\n\nPlease note that the code within the parentheses should be adapted to your specific context. If there are functions missing in the explanation, you should define them based on the code you are working with."
"To create a Polar transformation matrix of a given Kronecker power using the `generate_polar_transform_mat` function, follow these steps:\n\n1. Import the necessary function from the appropriate module:\n\n    ```python\n    from sionna.fec.polar.utils import generate_polar_transform_mat\n    ```\n\n2. Define the Kronecker power for the transformation matrix through the function parameter `n_lift`. For a specific code dimension `N`, the value of `n_lift` should be an integer that satisfies `0 <= n_lift <= log2(N)`. This means that `n_lift` specifies how the kernel in the Polar transformation is lifted.\n\n3. Call the `generate_polar_transform_mat` function with the defined `n_lift` to obtain the Polar transformation matrix:\n\n    ```python\n    polar_transform_mat = generate_polar_transform_mat(n_lift)\n    ```\n\n    Replace `n_lift` with the actual value you desire. For example, if you want to perform a single 8th Kronecker power transformation, `n_lift` would be 8.\n\nThe resulting `polar_transform_mat` is an array within your defined constraints that represents the Polar code transformation matrix of the specified Kronecker power.\n\nPlease note that this description assumes you have the necessary context and prerequisites in place, such as understanding the concepts of Polar codes and their transformation matrices. It focuses solely on explaining how to use the `generate_polar_transform_mat` function. If you lack the foundational knowledge, it's essential to acquire it or seek further clarification to ensure you use the function correctly and interpret the results accurately."
"Here is the definition of LayerDemapper:  sionna.nr.LayerDemapper(layer_mapper, num_bits_per_symbol=1, **kwargs)  \n  \nSource code:  \n```python\nclass LayerDemapper(LayerDemapper_):\n    # pylint: disable=line-too-long\n    def __init__(self,  layer_mapper, num_bits_per_symbol=1, **kwargs):\n        super().__init__(layer_mapper=layer_mapper, num_bits_per_symbol=num_bits_per_symbol, **kwargs)\n```\n  \nAs for the link of the source code, here it is: https://nvlabs.github.io/sionna/_modules/sionna/nr/layer_mapping.html#LayerDemapper"
"To create a PUSCHReceiver using the PUSCHTransmitter and simulate transmissions over the AWGN channel, follow these steps:\n\n1. First, you need to instantiate a PUSCHConfig and then use it to create a PUSCHTransmitter. The following lines of code do this:\n\n```python\npusch_config = PUSCHConfig() # Create a PUSCH configuration with default settings\npusch_transmitter = PUSCHTransmitter(pusch_config) # Instantiate a PUSCHTransmitter from the PUSCHConfig\n```\n\n2. Next, create a PUSCHReceiver using the PUSCHTransmitter. The following lines of code do this:\n\n```python\npusch_receiver = PUSCHReceiver(pusch_transmitter) # Create a PUSCHReceiver using the PUSCHTransmitter\n```\n\n3. Now, you can simulate transmissions over the AWGN channel. Let's say you want to simulate 10 transmission frames. Each frame should contain 16 transmitters, and each transmitter sends 1 data symbol and 4 padding symbols. The following lines of code achieve this:\n\n```python\nchannel = AWGN() # Create AWGN channel\nbatch_size = 10\nno = tf.fill([batch_size, 16], 0.1) # Generate a batch of noise variance for each AWGN channel\nx, b = pusch_transmitter(tf.constant([batch_size, 16], tf.int32)) # Generate transmit signal and info bits\ny = channel([x, no]) # Simulate channel output\nb_hat = pusch_receiver([x, no]) # Recover the info bits\n```\n\nIn this code, `tf.fill([batch_size, 16], 0.1)` generates a batch of noise variance for each AWGN channel, `x, b = pusch_transmitter(tf.constant([batch_size, 16], tf.int32))` generates the transmit signal and info bits, `y = channel([x, no])` simulates the channel output, and `b_hat = pusch_receiver([x, no])` recovers the info bits.\n\nPlease note that the actual code may vary depending on the specific configuration and requirements of your simulation."
"Here is the definition of SymbolInds2Bits: sionna.mapping.SymbolInds2Bits(num_bits_per_symbol, dtype=tf.float32, **kwargs)  \n\nSource code:  \n```python\nclass SymbolInds2Bits(Layer):\n    r\"\"\"Transforms symbol indices to their binary representations.\n\n    Parameters\n    ----------\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol, e.g., 4 for QAM16.\n\n    dtype : tf.DType\n        Output dtype. Defaults to `tf.float32`.\n\n    Input\n    -----\n    indices : Tensor, tf.int\n        Symbol indices\n\n    Output\n    ------\n    : ``len(indices)`` + [num_bits_per_symbol].astype(dtype)\n        Binary representation of symbol indices\n\n    Note\n    ----\n    One can set the QAM source to produce bits directly, i.e.,\n    ``QAM(order, produce_bits=True)``.\n    \"\"\"\n    def __init__(self, num_bits_per_symbol, dtype=tf.float32, **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        assert isinstance(num_bits_per_symbol, int_)\n\n        self._num_bits_per_symbol = num_bits_per_symbol\n        shape = [2**num_bits_per_symbol]\n        bits = list()\n        for i in range(0, 2**num_bits_per_symbol):\n            b = format(i, f'0{num_bits_per_symbol}b')\n            bits.append([int(x) for x in b])\n        self.bits = tf.constant(bits, dtype=dtype)\n\n    def build(self, input_shape): #pylint: disable=unused-argument\n        pass\n\n    def call(self, inputs):\n        a = inputs\n        bits = a[:,tf.newaxis] # pylint: disable=unnecessary-parens\n        return tf.squeeze(tf.gather(self.bits, bits, axis=0), axis=1)\n```\n\nsource code link: [SymbolInds2Bits](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#SymbolInds2Bits) \n  "
"Here is the detailed information of TimeChannel:   \n  \n[sionna.channel.TimeChannel(discrete_time_channel, bandwidth, max_delay_spread=3e-06, normalize_channel=False, num_rx=1, num_tx=1, l_min=(-6), l_max=(6), dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/channel/time_channel.html#TimeChannel)  \n\nApply the discrete complex baseband channel filter $L_{\\text{b},\\ell}$ to channel inputs $x_{b, k}$ and additive white noise $N_{\\ell}$, as described by the complex discrete-time channel model equation\n\n$$y_{b, k} = \\sum_{u=0}^{N_{T}-1}\\sum_{i=0}^{N_{R}-1}\\sum_{\\ell =L_{\\text{min}}}^{L_{\\text{max}}} L_{\\text{b},\\ell} h_{u, i, \\ell} x_{b, k-u} + n_{k, i, \\ell}$$\n\nwhere $b$ is time step, $k$ is the output symbol index, $x_{b, k}$ is the channel input, $y_{b, k}$ is the channel output, $L_{\\text{b},\\ell}$ are the (possibly time-dependent) channel taps, $h_{u, i, \\ell}$ are the spatial channel filters, and $n_{k, i, \\ell} \\sim \\mathcal{CN}(0,N_0)$ are the noise terms. It is assumed that the channel inputs $x_{b, k}$ have unit power, i.e., $E[|X_{b, k}|^2]=1$. Depending on the value of normalize_channel, the channel outputs or the channel outputs over some duration are normalized by the number of channel inputs, the data symbol duration, or the square root of the data symbol energy, respectively. This operation is applied along the inner dimension of the input tensor, i.e., the symbol index k. The dtype of the channel outputs is tf.complex64.\n\nThe complex baseband channel filter $L_{\\text{b},\\ell}$ is formed from the real-valued discrete-time channel filter $L_{\\ell}$ as follows. For a given symbol duration $T$, the baseband channel filter is obtained by filtering the passband signal over the duration of $T$ with $L_{\\ell}(t)$, the latter being the response to an impulse at time $0$. The passband signal is $T$-periodic, and is transmitted over a normalized bandwidth of $1\\text{ Hz}$. This implies the factor of $T$ in the definition of the power spectral density in [Tse] and [Sklar]. This is also different from, e.g., [Tse] and [Sklar], where a continuous-time zero mean unit power white noise is assumed. These issues are further discussed in the section \u201cBackground\u201d.\n\nA time window of length $T$ (bartlett window) is applied to the channel impulse response $L_{\\ell}(t)$ to obtain the filtered channel tap  $L_{\\text{b},\\ell}$ The filtered channel tap is formed by sampling $L_{\\ell}(t)$ at one of the $N_T$ time steps comprising the symbol duration $T$, and then applying the windowing function. The windowing function is applied to \u201cscale\u201d the noise, which is white and has a variance that depends on the duration $T$.\n\nFor example, if a passband channel impulse response $a(t)$ is (See [Tse] and [Sklar])\n\n$$a(t) = \\sum_{\\ell =L_{\\text{min}}}^{L_{\\text{max}}} a_{\\ell} L_{\\ell}(t)$$\n\nthen the baseband channel impulse response is (See [Tse] and [Sklar])\n\n$$L_{b}(t) = \\frac{1}{W}\\sum_{\\ell =L_{\\text{min}}}^{L_{\\text{max}}} a_{\\ell} L_{\\ell}(t)\\\\\n            = \\frac{1}{W}\\sum_{\\ell =L_{\\text{min}}}^{L_{\\text{max}}} a_{\\ell} \\left( \\prod_{q=0}^{N_T-1} \\text{sinc}\\left( \\ell T - qWT \\right) \\right)\\left( \\sum_{m=-N_T/2}^{N_T/2} \\text{sinc}\\left( m \\right) \\right) \\tag{1}$$.  \n  \nThe filtered channel tap $L_{\\text{b},\\ell}$ is therefore given by (See [Tse] and [Sklar])  \n\n$$L_{\\text{b},\\ell} = \\frac{1}{W}a_{\\ell}\\left( \\sum_{m=-N_T/2}^{N_T/2} \\text{sinc}\\left( m \\right) \\right) \\left( \\prod_{q=0}^{N_T-1} \\text{sinc}\\left( \\ell T - qWT \\right) \\right) \\tag{2}$$\n\nwhere the $a_{\\ell}$\u2019s are the real-valued scalar coefficients defining the (real-valued) channel taps $L_{\\ell}(t)$, $\\ell$ is the time step, $W$ is the bandwidth, and $T$ the symbol duration. The channel filter $L_{\\ell}(t)$, the pulse shaping filter, and the receive filter are assumed to be sinc-filters. Therefore, the channel tap $L_{\\ell}$ as well as the filtered channel tap $L_{\\text{b},\\ell}$ are real-valued. These coefficients depend on the channel type, the antenna array configuration, and the spatial transmitter and receiver filters, and are computed from the power spectral density of the transmitted signal, and the transmit and receive filters (see, e.g., [Tse], [Sklar], [C Saleh, A.-R. M. Tovar \"FM Channel Simulation with Impulse Invariants of Different Order\", Proc. NAB Show, 2012.). For example, in the case of a single transmit antenna and receive antenna, and in the absence of spatial filtering, the channel tap $L_{\\ell}$ is the classical complex-valued scalar tap for a  single transmit antenna and receive antenna, and is given by (See [Tse])\n\n$$L_{\\ell} = \\int_{-W/2}^{W/2} S_X\\left( \\frac{f_c + m}{W} \\right) e^{-j2\\pi \\ell \\tau}\\,d\\tau \\tag{3}$$\n\nwhere $S_X(f)$ is the transmit signal power spectral density, $m$ is the baseband  frequency  offset, $f_c$ is the carrier  frequency, and $\\tau$ is the delay. The delay $L_{\\ell}$ and the complex amplitude and phase of the channel tap $L_{\\ell}$ are computed from (3) as (See [Tse])\n $L_{\\ell} = \\sqrt{\\frac{2P}{W}}\\delta\\left( \\ell \\frac{W}{2} \\right)e^{j2\\pi \\ell\\tau_0)} \\quad\\text{with}\\quad  \\delta(x) = \\begin{cases}\n1  & \\text{if } x = 0\\\\\n\\\\\n\\\\\n\\frac{\\sin(2\\pi Wx)}{2\\pi x} & \\text{if } x \\neq 0\n\\end{cases}\\tag{4}$\nwhere the spectral density $S_X(f)$ has been assumed to be rectangular, $P$ is the average energy per information bit, and $W$ is the bandwidth.\nThe delay $\\tau_0$ corresponds to the mean delay of the path, for the (baseband) impulse response duration $T$ (See [Tse]). The frequency $f$ is then (See [Tse])\n$W\\delta\\left(f-f_c\\right) = W\\sum_{m=-\\infty}^{\\infty} \\delta\\left(f-f_c-mW\\right)$.  \n \nFor example, let us consider the channel tap coefficients $a_1 = 0.4$ and $\\begin{split}\\tau_0 = 3.5 \\times 10^{-6}\\text{ s},\\quad a_2 = 0.6 & :\\\\\n\\\\\nL_{\\ell} &=  \\sqrt{\\frac{P}{W}}\\left( 0.4 \\delta\\left( \\ell \\frac{W}{2} \\right) \\cos(2\\pi 3.5\\ell) + 0.6 \\delta\\left( \\ell \\frac{W}{2} \\right) \\right)\\\\\n&= \\sqrt{\\frac{P}{W}} \\delta\\left( \\ell \\frac{W}{2} \\right) \\left( 0.4 \\cos(22.75\\ell) + 0.6 \\right)\n\\end{split}$\n\n\n$0 \\leq \\ell \\leq N_T-1$, and $-W\\leq m \\leq W$.\n  \n**Remark: ** Note that (1) and (2) can be written as (in vector/matrix form) \n$\\mathbf{L_{b}} = \\mathbf{A}\\mathbf{L} \\mathbf{B} $  \nwhere $\\mathbf{L_{b}}$ is the vector of (possibly time-dependent) baseband channel taps, $\\mathbf{L}$ is a matrix containing the (possibly time-dependent) channel tap coefficients (real-valued $a_{\\ell}$ coefficients as defined previously), $\\mathbf{A}$ is a matrix that spreads $L_{b,\\ell}$ (the channel tap at time $\\ell$) over $N_T$ samples (baseband symbol duration) as defined in (2) , and $\\mathbf{B}$ is a vector that applies pulse shaping and  receive filtering to $x_{b, k}$ (the symbol at time step $k$).\n\n**Parameters**\n\n- `discrete_time_channel` (None, Channel, or Model): An instance of a channel model, such as `RayleighBlockFading`, `UplinkMIMO`, or `DownlinkMIMO`, or None. If None, you must provide a value for bandwidth and either `length` or `num_samples`. If an instance of Channel, the bandwidth and carrier frequency will be ignored and inferred from the channel model instance itself.\n- `bandwidth` (float): Bandwidth in Hz.\n- `max_delay_spread` (float): Maximum delay spread in seconds. Defaults to 3 microseconds, which was found to be valid for all models included in Sionna when a normalized bandwidth of 1 was used.\n- `normalize_channel` (bool): If set to True, the channel is normalized over the block size to ensure unit average energy per time step. Defaults to False.\n- `num_rx` (int): Number of receivers. Defaults to 1.\n- `num_tx` (int): Number of transmitters. Defaults to 1.\n- `l_min` (int) \u2013 Smallest time-lag ($L_{\\text{min}}$ in the above description). Defaults to -6.\n- `l_max` (int) \u2013 Largest time-lag ($L_{\\text{max}}$ in the above description). Defaults to 6.\n- `dtype` (tf.DType): Data type of the channel output. Defaults to tf.complex64. The dtype of the output is tf.complex64.\n\n\n**Input**\n\n- `batch_size` (int): Batch size\n- `num_time_steps` (int): Number of time steps\n- `sampling_frequency` (float): Sampling frequency [Hz]\n\n**Output**\n\n- `h` ([batch size, num_rx, num_rx, num_time_steps, l_max - l_min + 1], tf.complex): Channel outputs\n- `l` ([batch size, num_rx, num_rx, l_max - l_min + 1], tf.float): Channel taps\n  "
"The 'Antenna' class represents an individual antenna that is part of an antenna array used within the framework of Sionna's ray-tracing capabilities. An antenna is a transducer designed to transmit or receive wireless signals. \n\nAttributes of the 'Antenna' class:\n- **_polar** (str): Specifies the polarization of the antenna, possibly being either single (\"V\" or \"H\") or dual (\"VH\").\n- **_polar_num** (int): The number specifying the polarization, derived from '_polar'. For \"VH\" polarization, it is set to 2. \n- **_gain** (tf.float): Gain of the antenna in dBi (deciBels per isotropic antenna). \n- **_gain_db** (str): A string representing the gain in dB (decibel). \n- **_az_pattern** (*callable*): A function that implements the azimuth pattern of the antenna.\n- **_az_pattern_custom** (bool): A flag indicating whether the azimuth pattern is custom or not.\n- **_zen_pattern** (*callable*): A function that defines the zenith pattern of the antenna.\n- **_zen_pattern_custom** (bool): A flag indicating whether the zenith pattern is custom or not.\n- **_freq_dep** (bool): A boolean flag set if the antenna gain depends on the frequency.\n- **_dtype** (tf.complex or tf.float): Data type for all computations done with the antenna pattern. Defaults to tf.complex64.\n\nProperties of the 'Antenna' class include '_patterns' which returns the zenith and azimuth patterns of the antenna.\n\nThe 'Antenna' class is used as part of the 'AntennaArray' class which can be set for the transmitters and receivers within a scene. It can be single or dual polarized and can have different antenna patterns for each polarization. The class can be used to simulate the impact of a specific antenna's gain pattern on signal propagation for scenarios like ray tracing. Note that as context provided does not include the details or the usage of the class, thus for more detailed understanding the usage and the properties of the class within the code would be needed."
"  \nsource code link: https://nvlabs.github.io/sionna/_modules/sionna/fec/turbo/utils.html#TurboTermination.  \n```python\nfrom tensorflow.keras.layers import Layer\nfrom tensorflow import concat\n\nclass TurboTermination(Layer):\n    \"\"\"\n    Termination object, handles the transformation of termination\n    bits from the convolutional encoders to a Turbo codeword. Similarly,\n    it handles the transformation of channel symbols corresponding to\n    the termination of a Turbo codeword to the underlying convolutional\n    codewords.\n\n    Parameters\n    ----------\n    constraint_length : int\n        Constraint length of the convolutional encoder used in the Turbo code.\n        Note that the memory of the encoder is ``constraint_length`` - 1.\n\n    conv_n : int\n        Number of output bits for one state transition in the underlying\n        convolutional encoder\n\n    num_conv_encs: int\n        Number of parallel convolutional encoders used in the Turbo code\n\n    num_bit_streams : int\n        Number of output bit streams from Turbo code\n\n    get_num_term_syms()\n        [source](#Termination.get_num_term_syms)\n\n    termbits_conv2turbo(self, term_bits)\n        [source](#Termination.termbits_conv2turbo)\n\n    Attributes\n    -----------\n    conv_n : int\n        Number of output bits for one state transition in the underlying\n        convolutional encoder\n\n    num_bit_streams: int\n        Number of output bit streams from Turbo code\n    \"\"\"\n    def __init__(self,\n                 constraint_length,\n                 conv_n=2,\n                 num_conv_encs=2,\n                 num_bit_streams=3):\n        super().__init__()\n        self._mu = constraint_length - 1\n        self.conv_n = conv_n\n        self.num_conv_encs = num_conv_encs\n        self.num_bit_streams = num_bit_streams\n\n    @property\n    def conv_n(self):\n        return self._conv_n\n\n    @conv_n.setter\n    def conv_n(self, value):\n        self._conv_n = value\n\n    @property\n    def num_conv_encs(self):\n        return self._num_conv_encs\n\n    @num_conv_encs.setter\n    def num_conv_encs(self, value):\n        self._num_conv_encs = value\n\n    @property\n    def num_bit_streams(self):\n        return self._num_bit_streams\n\n    @num_bit_streams.setter\n    def num_bit_streams(self, value):\n        self._num_bit_streams = value\n\n    @property\n    def mu(self):\n        return self._mu\n\n    def get_num_term_syms(self):\n        \"\"\"\n        Compute the number of termination symbols for the Turbo\n        code based on the underlying convolutional code parameters,\n        primarily the memory :math:`\\\\mu`.\n\n        Note that it is assumed that one Turbo symbol implies\n        ``num_bitstreams`` bits.\n\n        Output\n        ------\n        turbo_term_syms: int\n            Total number of termination symbols for the Turbo Code. One\n            symbol equals ``num_bitstreams`` bits.\n        \"\"\"\n        turbo_term_syms = self.num_bit_streams*2*(self._mu + 1)\n        return turbo_term_syms\n\n    def termbits_conv2turbo(self, term_bits1, term_bits2):\n        \"\"\"\n        This method splits the termination symbols from a Turbo codeword\n        to the termination symbols corresponding to the two convolutional\n        encoders, respectively.\n\n        Lets assume :math:`\\\\mu=4` and the underlying convolutional encoders\n        are systematic and rate-1/2, for demonstration purposes.\n\n        Let `term_bits` tensor, corresponding to the termination symbols of\n        the Turbo codeword be as following:\n\n        :math:`y = [x_1(K), z_1(K), x_1(K+1), z_1(K+1), x_1(K+2, z_1(K+2), x_1(K+3),\n        z_1(K+3), x_2(K), z_2(K), x_2(K+1), z_2(K+1), x_2(K+2), z_2(K+2),\n        x_2(K+3), z_2(K+3), 0, 0]`\n\n        The two termination tensors corresponding to the convolutional encoders\n        are:\n\n        :math:`y[0,..., 2\\\\mu]`, :math:`y[2\\\\mu,..., 4\\\\mu]`. The output from this method is a tuple of two tensors, each of\n        size :math:`2\\\\mu` and shape :math:`[\\\\mu,2]`.\n\n        :math:`[[x_1(K), z_1(K)]`,\n\n        :math:`[x_1(K+1), z_1(K+1)]`,\n\n        :math:`[x_1(K+2, z_1(K+2), x_1(K+3),`\n\n        :math:`z_1(K+3)],`\n\n        :math:`[x_2(K),z_2(K)],`\n\n        :math:`[x_2(K+1), z_2(K+1)],`\n\n        :math:`[x_2(K+2), z_2(K+2), x_2(K+3), z_2(K+3)],`\n\n        :math:`[z_2(K), x_2(K+1), z_2(K+1)],`\n\n        :math:`[x_2(K+2), z_2(K+2),  x_2(K+3), z_2(K+3)],`\n\n        :math:`[0, 0]]`\n\n        Therefore, the output from this method is a single dimension vector\n        where all Turbo symbols are concatenated together.\n\n        :math:`[x_1(K), z_1(K), x_1(K+1), z_1(K+1), x_1(K+2, z_1(K+2), x_1(K+3),`\n\n        :math:`z_1(K+3), x_2(K), z_2(K), x_2(K+1), z_2(K+1), x_2(K+2), z_2(K+2),`\n\n        :math:`x_2(K+3), z_2(K+3), 0, 0]`\n\n        Input\n        -----\n        term_bits : tf.int32\n            2+D Tensor containing termination bits of the Turbo codeword\n\n        Output\n        ------\n        : tf.int32\n            1+D tensor of termination bits. The output is obtained by\n            concatenating the inputs and then adding right zero-padding if\n            needed.\n        \"\"\"\n        term_bits = concat([term_bits1, term_bits2], axis=1)\n        extra_bits = self.num_bit_streams - (term_bits.shape[0] % self.num_bit_streams)\n        if extra_bits == self.num_bit_streams:\n            pass # no termination required\n        else:\n            term_bits = concat([term_bits, tf.zeros([extra_bits])], 0)\n        return term_bits\n```  \n  "
"To wrap everything in a Keras model for convenient Bit Error Rate (BER) simulations and comparison of model parameters, you can follow these steps:\n\n1. Define a class for your model, let's call it `CommunicationSystem`.\n2. In the constructor of the `CommunicationSystem` class, initialize the components of your system. These could include a binary source, an encoder, a mapper, a demapper, and a decoder. Also, initialize the AWGN channel with the noise variance `no`.\n3. Define a `call` method inside the `CommunicationSystem` class. This method should take in the batch size and Eb/No as inputs. Generate the random bit sequence, encode it, map it, transmit it over the channel, demap it, and decode it. Compute the LLRs from the transmitted and received bits. Finally, compute the BER from the transmitted and received bits.\n4. After defining the `call` method, create an instance of the `CommunicationSystem` class with the components you want to simulate. You can now use this instance to simulate the BER and hence, compare the model parameters.\n\nHere is a simplified example of how you can define the `CommunicationSystem` class:\n\n```python\nclass CommunicationSystem(tf.keras.Model):\n    def __init__(self, no):\n        super().__init__()\n        # Initialize components here\n\n    def call(self, batch_size, ebno_db):\n        # Generate random bits\n        b = self.binary_source([batch_size, 128])\n        # Encode the bits\n        c = self.encoder(b)\n        # Map the encoded bits\n        x = self.mapper(c)\n        # Transmit over AWGN channel\n        y = self.awgn([x, no])\n        # Demap the received symbols\n        llr = self.demapper([y, no])\n        # Decode the LLRs\n        b_hat = self.decoder(llr)\n        # Compute BER\n        ber = compute_ber(b, b_hat)\n        return ber\n```\n\nPlease note that this is a simplified example and you may need to adjust it based on your specific requirements and the components you are using. For example, you may need to add a `compute_ber` method that calculates the BER, and you may need to adjust the initialization of the components to match the specific noise variance `no` required for each simulation."
"The \"build_type_grid\" method of the \"ResourceGrid\" class in the \"sionna.ofdm\" module is used to identify the type of each element in the resource grid. Depending on the type, elements could represent data symbols, pilot symbols, guard-carriers, or the DC carriers. The method will return a tensor which indicates the type of each element in the grid. The grid types are represented by integers as follows:\n\n- Data symbol (0)\n- Pilot symbol (1)\n- Guard carrier (2)\n- DC carrier (3)\n\nGiven the context, the \"build_type_grid\" function could be used like this:\n\n```python\n# Create an instance of the ResourceGrid class\nresource_grid = sionna.ofdm.ResourceGrid(num_ofdm_symbols=14, fft_size=75)\n\n# Call the build_type_grid method to get the grid structure\ntype_grid = resource_grid.build_type_grid()\n\n# type_grid is a tf.Tensor which shows the type of each element in the grid\n# type_grid = [0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n```\n\nThe \"build_type_grid\" method should be used after the generate_pilot_pattern() and/or generate_pilot_ofdm_symbol_indices() methods have been called, or after a custom pilot pattern has been set, as it depends on the pilot patterns to determine the type of the elements in the grid. If no pilot pattern is set, it will return a grid full of zeros, assuming the grid is filled with data symbols. \n\nIn the context, the \"build_type_grid\" method is used in a property function without calling it. The result of the method call is then used to get the type grid of the elements in the resource grid. This is seen in the 'Property' section of the 'ResourceGrid' class in the API documentation provided in the context.\n\nTo get more detailed information about this method, its parameters, and how it is used, the source code or the method's documentation comments could be consulted."
"Params:\n- num_symbols (int) : Number of symbols per block to be mapped to constellation points.\n- hard_out (bool) : If true, the layer provides hard-decided bit values instead of soft-values.\n- dtype (tf.DType) : dtype for the input and output. Defaults to tf.float32.\n- **kwargs : Additional keyword arguments. \n  - source: SymbolLogits2LLRs is decomposed and adapted from this source. \n    - https://nvlabs.github.io/sampta2021/assets/...bol2llrs.SourceDecoder.html#sionna.mapping.SymbolLogits2LLRs\n    - https://nvlabs.github.io/sampta2021/assets/...bol2llrs.SourceDecoder2.html#sionna.mapping.SymbolLogits2LLRs2\n    - https://nvlabs.github.io/sampta2021/assets/...bol2llrs.SourceDecoder3.html#sionna.mapping.SymbolLogits2LLRs3\n- source_code:  \n   ```python\n    class SymbolLogits2LLRs(ABC):\n        # pylint: disable=line-too-long\n        r\"\"\"Abstract class that defines a callable to compute the LLRs from a\n        tensor of logits (i.e., unnormalized log-probabilities) on\n        constellation points :math:`\\mathcal{C}`.\n\n        An implementation of this class is required for various layer\n        components. The class\n        :class:`~sionna.mapping.SymbolLogits` provides a convenient\n        way to compute the logits from\n        constellation points but relies on an implementation of\n        `SymbolLogits2LLRs` to perform the actual\n        computation of LLRs.\n\n        ..  figure:: ../_static/constellation_points_CW.png\n            :align: center\n\n\n        Let assume that we have a constellation with :math:`M` points\n        :math:`c_m \\in \\mathcal{C}`, for :math:`0 \\leq m \\leq M-1`. A\n        constellation is not necessarily binary. We also\n        indicate with :math:`b_k(c_m)`, the :math:`k^{th}` bit label of\n        :math:`c_m`, where\n        0 is replaced by -1. Then, the LLR for the :math:`i^{th}` bit of\n        :math:`c_m` is computed according to\n\n        .. math::\n\n            LLR(i) = \\ln\\left( \\frac{\\Pr\\left(b_i=1\\lvert c_m \\right)}{\\Pr\\left(b_i=0\\lvert c_m \\right)}\\right)\n\n        where :math:`\\Pr\\left(b_i=1\\lvert c_m \\right)` and\n        :math:`\\Pr\\left(b_i=0\\lvert c_m \\right)` are the \"probability\" of\n        bit being 1 and 0, respectively, for the constellation point :math:`c_m`.\n        Note that these probabilities can be greater\n        than 1 and/or negative. This is the reason why \"probability\" is put\n        into quotation marks. It is\n        however well-known that the LLRs can be computed in this way from\n        the probabilities on the bits.\n\n        The previous expression can be rewritten as\n\n        .. math::\n\n            \\begin{align}\n                LLR(i) & =\\ln\\left( \\frac{\\prod_{c \\in \\mathcal{C}_1} \\Pr\\left(b_i=1\\lvert c \\right) \\prod_{c \\in \\mathcal{C}_0} \\Pr\\left(b_i=1\\lvert c \\right)}{\\prod_{c \\in \\mathcal{C}_1} \\Pr\\left(b_i=0\\lvert c \\right) \\prod_{c \\in \\mathcal{C}_0} \\Pr\\left(b_i=0\\lvert c \\right)}\\right)\\\\\n                    & =\\sum_{c \\in \\mathcal{C}_0} \\ln\\left( \\frac{\\Pr\\left(b_i=1\\lvert c \\right)}{\\Pr\\left(b_i=0\\lvert c \\right)}\\right) - \\sum_{c \\in \\mathcal{C}_1} \\ln\\left( \\frac{\\Pr\\left(b_i=0\\lvert c \\right)}{\\Pr\\left(b_i=1\\lvert c \\right)}\\right)\n            \\end{align}\n\n\n        where :math:`\\mathcal{C}_1` and :math:`\\mathcal{C}_0` are the sets of\n        indices of the constellation points for which the bit is\n        equal to 1 and 0, respectively. Note that a non-negative bit\n        probability is assumed to ensure the convergence of the LLRs to\n        the correct values.\n\n        For convenience, the above equation is termed LLR equation\n        throughout this documentation.\n\n        ..  note::\n            The LLR cannot be directly be computed in a\n            differentiable way if we consider a standard\n            bit-wise/low-symbol rate regime. However, it\n            could be approximated for a high-symbol rate assumed\n            to be parallel processed, as it is done by the\n            :class:`~sionna.mapping.SymbolLogits`.\n\n        This class is an implementation of the\n        :class:`~sionna.mapping.AbstractSymbolLogits2LLRs`  and\n        assumes that the logits are equal to the\n        un-normalized log-probability:\n\n        .. math::\n\n            \\ell(c)_k = \\ln\\left( \\Pr\\left(b_k=1\\lvert c \\right) \\right)\n                        -\\ln\\left( \\Pr\\left(b_k=0\\lvert c \\right)\\right)\n\n        for the individual bit values of a constellation point.\n\n        For hard-decisions, the logit for the :math:`i^{th}` bit\n        of the :math:`c` point is assumed to be of the form\n\n        .. math::\n            \\ell(c)_i = a \\cdot \\Pr\\left(b_i=1\\lvert c \\right)\n\n        where :math:`a>0`. In this case, the LLR is just a sign of the logit\n        and is also not differentiable.\n        It is also possible to compute \"soft-decisions\" for\n        a  bit over demapping to constellation point symbols\n        (i.e., logits)\n        using this class. Note that this is only an approximation\n        and that the true LLRs should be used for maximum likelihood\n        (ML) decoding, for example.\n\n        Parameters\n        -----------\n        num_bits_per_symbol : int\n            Number of bits per constellation symbol, e.g., 4 for QAM16.\n\n        hard_out : bool\n            If true, the layer provides hard-decided bit values\n            instead of soft-values.\n            Defaults to False.\n\n        dtype : tf.DType\n            The dtype for the input and output dtypes.\n            Defaults to tf.float32.\n\n        Input\n        -----\n        logits : [...,n, 2**num_bits_per_symbol], tf.float\n            Logits (unnormalized log-probabilities) or\n            a tensor of constellation points, if the flag\n            ``hard_out`` is activated. That is, the logits\n            for bit $i$ are expected to be given log-domain by\n            :math:`\\ell(c)_i` as\n            defined by ``Equation logit definition`` above\n            or in the logit definition below, respectively.\n\n        Output\n        ------\n        llrs : [...,n, num_bits_per_symbol], tf.float\n            The LLRs or hard-decisions for every bit of every\n            constellation point.\n\n        Note\n        ----\n        The (potentially multi-dimensional) tensor ``logits`` is\n        expected to have at least two dimensions with the last\n        dimension of size ``2**num_bits_per_symbol``.\n        This is typically used to transform channel outputs, e.g.,\n        from :class:`~sionna.mapping.SymbolLogits`.\n\n        **Hard-decisions:** Assumed that the flag ``hard_out`` is `True`,\n        the input ``logits``  is interpreted as the constellation points themselves.\n        In this case, for the :math:`i^{th}` bit of the\n        :math:`c` point, we have\n        $\\ell(c)_i = a \\cdot \\Pr\\left(b_i=1\\lvert c \\right)$\n        with $a>0$. The equation of the log-likelihoods (LLRs)\n        is then approximated by\n\n        .. math::\n            \\begin{align}\n                LLR(i) &=\\ln\\left( \\frac{\\prod_{c \\in \\mathcal{C}_0} \\Pr\\left(b_i=1\\lvert c \\right)}{\\prod_{c \\in \\mathcal{C}_1} \\Pr\\left(b_i=1\\lvert c \\right)}\\right)\\\\\n                &=\\ln\\left( \\frac{\\prod_{c \\in \\mathcal{C}_0} \\sigma(a\\cdot c_i)}{\\prod_{c \\in \\mathcal{C}_1} \\sigma(a\\cdot c_i)}\\right)\\\\\n                &=\\ln\\left( \\frac{\\prod_{c \\in \\mathcal{C}_0}\n                        \\left( 1 + \\exp\\left(a\\cdot c_i \\right) \\right)^{-1}}{\n                        \\prod_{c \\in \\mathcal{C}_1} \\left( 1 + \\exp\\left(a\\cdot c_i \\right) \\right)^{-1}\n                        }\\right)\n            \\end{align}\n        where :math:`\\mathcal{C}_1` and :math:`\\mathcal{C}_0` are the sets of\n        indices of the constellation points for which bit is equal to 1 and 0, respectively,\n        and :math:`c_i` the :math:`i^{th}` bit label of a constellation point.\n        Finally, this equation can be written as\n\n        .. math::\n            \\begin{align}\n                LLR(i) &=\\ln\\left(\n                \\frac{\\prod_{c \\in \\mathcal{C}} \\left( 1 + (2^{-i} \\cdot \\text{sign}(a) \\cdot c) \\right)^{-1}}\n                     {\\prod_{c \\in \\mathcal{C}} \\left( 1 + \\exp\\left( a\\cdot c \\right) \\right)^{-1}\n                \\right)\n                \\end{align}\n        where :math:`\\mathcal{C} = \\mathcal{C}_0 \\cup \\mathcal{C}_1`.\n        Note that the definition of the LLR\n        (either for soft- or hard-decisions) such as\n        :class:`~sionna.mapping.SymbolLogits2LLRs`\n        is equivalent to :class:`~sionna.mapping.LLR` .\n       ```    \n        pass\n    ```\n      "
"Here is the detailed information of MaximumLikelihoodDetector:   \n  \n[sionna.ofdm.MaximumLikelihoodDetector(output, det"
"To initialize a `TurboEncoder` with custom generator polynomials, the polynomials must be provided in the form of a binary string. The binary string \"10011\" represents the generator polynomial for convolutional encoders in polynomial notation with the connection scheme as shown in the context. \n\nIn the context of Turbo Codes, the generator polynomials are used to create two convolutional encoders which are then combined to create a Turbo Code. For the polynomial \"10011\", the first encoder is created using polynomial $1 + D^3 + D^4$ and the second encoder is created using polynomial $1 + D + D^3 + D^4$. These are rate-1/3 convolutional encoders when terminated. When combined, the Turbo Code operates by alternating between the two component convolutional codes, which allows for iterative decoding processes that can provide near-capacity performance."
"To use the generator to sample the first few items of the dataset, you can follow these steps:\n\n1. Define a generator function that yields the items you want to sample. In this case, the generator function is `HD5CIRGen`.\n\n2. Create an instance of the generator function, passing the necessary arguments. In this case, you would create an instance of `HD5CIRGen` by providing the `filename`.\n\n3. Use a `for` loop to iterate over the generator instance. During each iteration, the generator will yield a new item from the dataset. You can stop the iteration after a certain number of samples, which is indicated by the range in the context.\n\nHere's how you would use the generator to sample the first few items of the dataset in the context provided:\n\n```python\ngenerator = HD5CIRGen(filename)\n\nfor (a,tau) in generator():\n    # Do something with the sampled item (a, tau)\n    # ...\n\n    # Stop after sampling the first few items\n    if condition_is_met:\n        break\n```\n\nIn this code, the `generator()` function returns an iterator over the dataset. The `for` loop then iterates over this iterator, sampling a new item from the dataset during each iteration. The `if` statement checks if a certain condition is met, and if it is, the loop stops, thus sampling only the first few items of the dataset. If the condition is not provided or is `False`, the loop will iterate over the entire dataset. \n\nPlease replace `condition_is_met` with your actual stopping condition. The code before the `if` statement should be the processing steps you want to perform on each sampled item. If you want to sample more than the first item, you can modify the `range` function in the context to indicate the desired number of samples. \n\nPlease be aware that the code in the context is set to sample 5 items from the dataset. If you want to sample more or fewer items, you need to change that number in your own code. Also, make sure that the condition in the `if` statement aligns with the structure of the dataset and the processing steps you want to perform."
"To save the estimated matrices for future use, you can follow these steps:\n\n1. After estimating the covariance matrices (`FREQ_COV_MAT`, `TIME_COV_MAT`, `SPACE_COV_MAT`), you can use the `np.save` function from the `numpy` library to save them as numpy arrays. This can be done using the following lines of code:\n\n```python\nnp.save('freq_cov_mat', FREQ_COV_MAT.numpy())\nnp.save('time_cov_mat', TIME_COV_MAT.numpy())\nnp.save('space_cov_mat', SPACE_COV_MAT.numpy())\n```\n\n2. These lines of code will save the matrices with the names 'freq_cov_mat', 'time_cov_mat', and 'space_cov_mat'. The `np.save` function saves the matrices as numpy arrays in a file with the given name.\n\n3. The saved matrices can be loaded in the future using the `np.load` function from the `numpy` library. This can be done as follows:\n\n```python\nFREQ_COV_MAT = np.load('freq_cov_mat', allow_pickle=True)\nTIME_COV_MAT = np.load('time_cov_mat', allow_pickle=True)\nSPACE_COV_MAT = np.load('space_cov_mat', allow_pickle=True)\n```\n\n4. These lines of code will load the saved matrices into the variables `FREQ_COV_MAT`, `TIME_COV_MAT`, and `SPACE_COV_MAT`.\n\nPlease note that the matrices are saved as separate files for frequency, time, and space domains. Also, the `.npy` format is used for the saving the matrices. This is a binary format, and is specific to 'numpy' data.\n\nEnsure that the matrices are actually assigned to the variables (`FREQ_COV_MAT`, `TIME_COV_MAT`, `SPACE_COV_MAT`) before saving them. The given context does not provide the exact code where these matrices are assigned, so you need to refer to your actual implementation for that. Also, ensure that the context in which you are saving or loading the matrices is the same as the one in which the matrices are estimated."
"Iterative Detection and Decoding (IDD) is used in MIMO (Multiple-Input, Multiple-Output) simulations to improve the quality of transmitted data in a multi-antenna wireless system. It involves the repeated exchange of soft information between a detector (which decodes the received symbols) and a decoder (which interprets the estimated symbols). This process is iterative, hence the name \"iterative detection and decoding\".\n\nIn the provided context, the IDD process is described in the context of a MIMO simulation. The soft-information $\\\\mathrm{L}^{D}$ is the 'a posteriori' information, represented as log-likelihood ratios, that is passed between the data detector and the channel decoder. The 'a priori' information $\\\\mathrm{L}^{A}$ is an assumption of the transmitted data's probability distribution, which is also represented as log-likelihood ratios and is provided to either the input of the detector or the decoder. \n\nThe process of exchanging extrinsic information is crucial for improving the performance of the MIMO system. Originally, IDD was proposed with a resetting decoder (such as a Turbo decoder). However, non-resetting decoders have been found to provide better performance, particularly for a low number of decoding iterations. Therefore, in the context of MIMO simulations, the decoder state (i.e., the check node to variable node messages) is forwarded from each IDD iteration to the next.\n\nIt's important to note that the SISO MMSE-PIC (Minimum Mean Square Error - Parallel Interference Cancellation) detector is also referenced in the context. This type of detector uses all received symbols to detect each individual stream in a MIMO system, and also uses iterative detection and decoding. However, it does not require the forwarding of decoder state, and it has been found to work better when provided with the full 'a posteriori' information from the decoder.\n\nThe concept of IDD highlights the interconnected nature of data detection and decoding processes in MIMO simulations, and the importance of iterative exchange of information to optimize the performance of the system."
"The detailed information of Descrambler is as follows:\n\n1. Parameters of the class:\n    - `scrambler`: Associated Scrambler or TB5GScrambler instance which should be descrambled.\n    - `binary` (bool): Defaults to True. Indicates whether bit-sequence should be flipped (i.e., binary operations are performed) or the signs should be flipped (i.e., soft-value/LLR domain-based).\n    - `dtype` (None or tf.DType): Defaults to None. Defines the datatype for internal calculations and the output dtype. If no explicit dtype is provided the dtype from the associated interleaver is used.\n\n2. Input:\n    - It takes either a tuple `(x, seed)` or `x` only (no tuple) if the internal seed should be used.\n    - `x` (tf.float32): 1+D tensor of arbitrary shape.\n    - `seed` (int): An integer defining the state of the random number generator. If explicitly given, the global internal seed is replaced by this seed. Can be used to realize random scrambler/descrambler pairs (call with same random seed).\n\n3. Output:\n    - `: tf.float32`: 1+D tensor of same shape as x.\n\n4. Property:\n    - `scrambler`: Associated scrambler instance."
"Here is the definition of KBestDetector: sionna.mimo.KBestDetector(output, num_streams, k, constellation_type, num_bits_per_symbol, constellation, hard_out=False, use_real_rep=False, list2llr=None, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/mimo/detection.html#KBestDetector) \n\nsource code:\n```python\nclass KBestDetector(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"KBestDetector(output, num_streams, k, constellation_type, num_bits_per_symbol, constellation, hard_out=False, use_real_rep=False, list2llr=None, dtype=tf.complex64)\n\n    MIMO K-Best detector\n\n    This layer implements K-Best MIMO detection as described in (Eq. 4)\n    [O. Casta\u00f1eda, \"MIMO K-Best Detector: A low-complexity near-optimal\n    solution\", IEEE, 2007.)] and, for non differentiable constellations,\n    the procedure defined in :obj:`MIMO Detection and\n    ``NonDifferentiable`` Constellations <MIMODetection>`.\n\n    The way soft- or hard-decisions are returned is determined by the\n    ``hard_out`` flag. The detector\n    assumes a 'Likelihood to Prior' :math:`L\\to P` APP prior model. If the\n    detector\n    is configured for real-valued detection, it assumes a :math:`L\\to M` \n    arbitrary APP prior model. The :math:`L\\to P` model is not\n    implemented for arbitrary constellations.\n\n    The layer operates on normalized :math:`\\mathbf{y}\\in\\mathbb{C}^M`\n    observations:\n\n    .. math::\n        \\bar{\\mathbf{y}} = \\mathbf{R}^{-\\frac{1}{2}} \\mathbf{H} \\mathbf{x} + \\mathbf{R}^{-\\frac{1}{2}} \\mathbf{n}\n\n    where :math:`\\mathbf{x}\\in\\mathbb{C}^K` is the vector of transmitted symbols,\n    :math:`\\mathbf{H}\\in\\mathbb{C}^{M\\times K}` is the known channel matrix,\n    and :math:`\\mathbf{n}\\in\\mathbb{C}^M` is a white noise vector.\n    :math:`\\mathbf{R}\\in\\mathbb{C}^{M\\times M}` is the\n    (possibly) rank-deficient covariance matrix of\n    the channel, which in the above equation is replaced by\n    its regularized version\n    :math:`\\mathbf{R}`. The (column) vector\n    :math:`\\bar{\\mathbf{x}}\\in\\mathbb{C}^K` is the vector of\n    transmitted symbols with unit norm :math:`E[\\mathbf{x}\\mathbf{x}^{\\mathsf{H}}]=\\mathbf{I}_K`.\n    Prior to demapping, the LLRs of the transmitted bit/constellation points are\n    computed and possibly signalled to an outer decoder (cf. :class:`LDPC5GDecoder <sionna.fec.ldpc.decoding.decoder.ldpc5g.LDPC5GDecoder>`).\n\n    **Example**\n    \n    The following example demonstrates how to configure a KBestDetector layer.\n\n    >>> detector = KBestDetector(output=\"bit\", num_streams=4, k=8, constellation_type=\"qam\", num_bits_per_symbol=2)\n\n    Parameters\n    -----------\n    output : One of [\"bit\", \"symbol\"], str\n        The type of output, either LLRs on bits or logits on constellation symbols.\n\n    num_streams : tf.int\n        Number of transmitted streams\n\n    k : tf.int\n        The number of paths to keep. Note that this parameter\n        is the number of paths *per stream*. Hence, if the detector\n        is configured for e.g. 4 streams and k=8, the detector\n        will consider 32 paths in total.\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : tf.int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the detector computes hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`.\n\n    use_real_rep : bool\n        If `True`, the detector uses a real-valued representation of the\n        channel. In that case, the detector does no longer assume\n        a QAM constellation but is configured with with\n        :math:`L\\to P` prior for the constellation type.\n        Defaults to `False`.\n\n    list2llr : List2LLR\n        The List2LLR object to be used or `None`.\n        If `None`, the detector cannot provide logits.\n        Only required for ``output`` equals `\"bit\"`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of ``y``. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    -----\n    (y, h, prior, no) :\n        Tuple:\n\n    y : [...,M], tf.complex\n        1+D tensor containing the received signals\n\n    h : [...,num_streams, num_streams], tf.complex\n        2+D tensor containing the channel matrices\n\n    prior : [...,num_streams, num_bits_per_symbol] or [...,num_streams,log2(num_points)], tf.float\n        Prior of the transmitted signals.\n        If ``output`` equals `\"bit\"`, the LLRs of the transmitted bits are expected.\n        If ``output`` equals `\"symbol\"`, logits of the transmitted constellation points are expected.\n\n    no : [...,num_streams], tf.float\n        Variance of the Gaussian noise\n\n    Output\n    ------\n    One of:\n\n    : [...,num_streams, num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream, if ``output`` equals `\"bit\"`.\n\n    : [...,num_streams, num_points], tf.float or [...,num_streams], tf.int\n       Logits or hard-decisions for constellation symbols for every stream, if ``output`` equals `\"symbol\"`.\n       Hard-decisions correspond to the symbol indices.\n\n\n    Note\n    ----\n    For numerical stability, we do not recommend to use this function in graph\n    mode with XLA, i.e., within a function that is decorated with\n    ``@tf.function(jit_compile=True)``.\n    However, it is possible to do so by setting\n    ``sionna.Config.xla_compat=true``.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n    def __init__(self,\n                 output,\n                 num_streams,\n                 k,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 use_real_rep=False,\n                 list2llr=None,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        assert dtype in [tf.complex64, tf.complex128], \\\n            \"dtype must be tf.complex64 or tf.complex128.\"\n\n        # Create PAM or QAM constellation\n        if constellation_type is not None:\n            constellation = Constellation.create(  # pylint: disable=unexpected-keyword-argument\n                                            constellation_type,\n                                            num_bits_per_symbol,\n                                            dtype=dtype)\n        else:\n            assert constellation is not None, \\\n            \"`constellation` must be provided.\"\n            assert constellation_type in [None, \"custom\"], \\\n            \"`constellation_type` is not `\"rastergrid`.\" # pylint: disable=line-too-long\n\n        # Check that constellation is not made of more than one PAMs or QAMs\n        assert constellation.num_bits_per_symbol==num_bits_per_symbol, \\\n            \"Wrong value of `num_bits_per_symbol` for this constellation.\"\n        assert constellation.num_bits_per_symbol>0, \"The constellation has no \"\\\n            \"symbols. Please provide `constellation_type` and `num_bits_per_symbol`.\" # pylint: disable=line-too-long\n\n        self._num_bits_per_symbol = constellation.num_bits_per_symbol\n        self._use_real_rep = use_real_rep\n\n        # Number of constellation symbols\n        self._num_cps = constellation.num_points\n\n        # Precompute possible symbol errors for the kbest paths\n        if self._use_real_rep:\n            symb_err = compute_symbol_errors(constellation.points.numpy())\n        else:\n            x = np.array(constellation.pam_x(0)).reshape(-1,1)\n            y = np.array(constellation.pam_y(0)).reshape(1,-1)\n            symb_err = compute_symbol_errors(x, y).astype(np.int32)\n\n        self._symb_err = tf.constant(symb_err, dtype=tf.int32)\n\n        self._output = output\n        self._hard_out = hard_out\n        self._k = k\n        self._p = 0 # Path indicator\n        self._norm_p = 1 # Normalization for path scores\n\n        if self._output==\"bit\":\n            assert list2llr is not None, \\\n            \"A List2LLR instance must be provided for 'bit' detection.\"\n            self._list2llr = list2llr\n        else:\n            assert not hard_out, \\\n                \"`hard_out` must be False when detecting symbols.\"\n\n        # Determine which logits to output and with which normalization\n        if self._output==\"symbol\":\n            self._logits_to_out = constellation.preprocessors[2]\n            if self._use_real_rep:\n                n = tf.cast(2*self._num_bits_per_symbol, dtype=tf.int32)\n                self._norm_out = tf.cast(tf.sqrt(tf.cast(n, dtype.real_dtype))),\n            else:\n                self._norm_out = 1.\n        elif self._hard_out:\n            # Hard decisions, no normalization is required\n            self._norm_out = 1.\n            # L to P or L to M model\n            if self._use_real_rep:\n                n = tf.cast(2*self._num_bits_per_symbol, dtype=tf.int32)\n                self._normp = tf.cast(tf.sqrt(tf.cast(n, dtype.real_dtype))),\n            else:\n                self._normp = 1.\n        else: # Soft-decisions\n            assert output==\"bit\",\\\n                \"Output must be 'bit' for computing LLRs.\"\n            self._normp = tf.cast(1./prior_variance, dtype.real_dtype)\n            self._normsoft = tf.cast(tf.sqrt(2.), dtype.real_dtype)\n\n    def build(self, input_shape): #pylint: disable=unused-argument\n        is_complex = tf.dtypes.complex_dtype(self.dtype)\n        self._eye = tf.cast(tf.eye(self._num_cps, self._num_cps, dtype=is_complex),\n                            self.dtype)\n\n        # Initialize list for predecessor indices\n        inits = [-1] + [i for i in range(self._k*self._num_streams)]\n        self._preds = tf.Variable(inits, trainable=False)\n\n        # and for state scores\n        inits = [0. for _ in range(self._k*self._num_streams)]\n        self._path_scrs = tf.Variable(inits, trainable=False)\n\n    def call(self, inputs):\n        # Flatten the last dimensions\n        y, h, prior, no = inputs[:-1], inputs[-1], tf.cast(self._eye, inputs[-1].dtype)\n\n        # Change to real representation if required\n        if self._use_real_rep:\n            y = complex2real(y)\n            h = complex2real(h)\n            prior = complex2real(prior)\n            no = tf.reduce_mean(no, axis=-1, keepdims=True) # Use only real-valued noise\n\n        batch_dim = tf.shape(y)[:-1]\n\n        # [r1,..,r_num_streams] Path metric (real-valued)\n        # [k1,..,k_num_streams] Path indices (preds)\"\"\"\n\n        # If we are in log-domain, set path metric to -inf\n        if self.training:\n            y0 = tf.constant(-1e2, y.dtype.real_dtype, (2,), y.dtype.real_dtype)\n        else:\n            y0 = tf.zeros((2,), y.dtype.real_dtype)\n\n        # Initialize score and state index\n        ind_p = 0\n        scr_p = self._path_scrs\n\n        # Symbol demapping is performed on the PAM constellation\n        for m in range(self._num_streams):\n            r = []\n            for path_id in range(m*self._k, (m+1)*self._k):\n                # Add path for real and imaginary components\n                r  += [scr_p[2*path_id  : 2*(path_id+1)] + y0[0]]\n                r  += [scr_p[2*path_id+1: 2*(path_id+1)] + y0[1]]\n            # Take the K most likely symbols\n            # Gather is required to re-order the symbol indices as r is\n            # a concatenation of the real and imaginary component paths\n            r = tf.reshape(tf.concat(r, axis=0), (2,-1))\n            r = tf.reshape(r, (1, -1))\n            r,_ind = tf.math.top_k(r, self._k)\n            r = tf.gather(input, r, axis=2)\n            # Gather also the path indices\n            _ind = tf.expand_dims(_ind, axis=0)\n            _ind = tf.concat((_ind, _ind), axis=0)\n            _ind, _ = tf.math.top_k(_ind, self._k)\n            _ind = tf.squeeze(_ind, axis=0)\n            self._preds[self._p*(self._k*self._num_streams+1) \\\n                        + (m+1)*self._k:\n                self._p*(self._k*self._num_streams+1) + (m+1)*self._k] \\\n                .assign(tf.squeeze(_ind, axis=-1)))\n\n            # Compute path metrics\n            # Note: Very important to use expand_dims instead of tf.fill as\n            # the former does not introduce a new axis, which would lead\n            # to broadcasting and an incorrect result.\n            # The latter would lead to an error.\n            _h = tf.gather(h, [m], axis=1)\n            y_m = tf.gather(y, [m], axis=0)\n            _diff = tf.expand_dims(y_m - tf.reduce_sum(_h* prior, axis=-1), -1)\n            _r = tf.reshape(tf.reduce_sum(_diff*_diff, axis=-2),\n                            (1, self._num_cps))\n            r.append(tf.squeeze(_r))\n\n        # Combine symbol or bit metrics from all streams\n        r = tf.add_n(r) # (real-valued) Path metric\n        # Phase update is required for the complex implementation\n        if not self._use_real_rep:\n            r = self._normp*tf.where(tf.math.less(r,0), tf.ones_like(r), self._normp) \\\n                * tf.exp(-tf.math.abs(tf.math.angle(self._normp*r))/2.)\n\n        # Update path metric and state indices\n        self._p = 1 - self._p\n        if self._p==0:\n            self._path_scrs[:self._k].assign(tf.cast(r, self.dtype.real_dtype))\n        else:\n            self._path_scrs[-self._k:].assign(tf.cast(r, self.dtype.real_dtype))\n\n        # Save predecessor indices\n        self._preds[self._p*(self._k*self._num_streams+1) \\\n                    : (self._p+1)*(self._k*self._num_streams+1)] \\\n            .assign(tf.cast(scr_p, self.dtype.real_dtype))\n\n        # Extract path with largest metric\n        path_ind = tf.cast(self._p*(self._k*self._num_streams+1), tf.int32)\n        extr_ind = self._preds[path_ind + tf.argmax(self._preds[path_ind])]\n\n        # Generate symbol output\n        if self._hard_out:\n            syms_ind = extr_ind//2 # Take only symbol index (not real/imaginary)\n            signs   = 2*tf.bitwise.hadamard(extr_ind, 1)-1 # Take real/imaginary part\n            syms = tf.cast(syms_ind, tf.int32) # symbol indices\n            syms = syms + tf.cast(signs, syms.dtype) # symbol LLRs\n            syms = tf.squeeze(sionna.mapping.Constellation(constellation).symbol_bits(syms))\n            syms.set_shape([self._num_streams, self._num_bits_per_symbol])\n            return syms\n        else:\n            llr = self._normp * tf.gather(self._preds, extr_ind, axis=-1) \\\n                + tf.cast(self._normsoft, self.dtype.real_dtype) \\\n                  * (self._eye[  extr_ind, :]-0.5)\n            llr = tf.reshape(llr, tf.shape(y)[:-1] + [num_streams, -1])\n            llr = tf.transpose(llr, [0, 2, 1])\n            llr = tf.reshape(llr, tf.concat([batch_dim, [num_streams, -1]], axis=-1)\n                            )\n            if self._output==\"bit\":\n                llr = self._list2llr(llr)\n\n            return llr\n```"
"To move scene objects in Sionna, you can use the `position` and `orientation` properties of the scene objects. Here's how you can use them:\n\nThe `position` property represents the translation of an object along the axes of the coordinate system. You can assign a new value to this property to move the object to a new position. The `position` property has its axes expressed in a coordinate system (like Polar3D or Cartesian3D), and you can specify it in a different coordinate system using the `with_suffix` method. For example, you can move an object 5 units along the y-axis by using a value of 5 for the y-axis, like this:\n\n```python\nobj.position = [0, 5, 0]  # Move 5 units along the y-axis\n```\n\nThe `orientation` property represents the rotation of an object. Like `position`, you can assign a new value to this property to rotate the object. The rotation can be defined with different rotation angles around different axes. For example, you can rotate an object 45 degrees around the z-axis (in radians), like this:\n\n```python\nobj.orientation = [0, 0, 45]  # Rotate 45 degrees around the z-axis\n```\n\nIn addition to using `position` and `orientation` directly, you can also move objects by transforming them with a translation or rotation matrix, or by attaching them to a mobile scene object. For example, you can move an object by attaching it to another object that is flying in a circle. \n\nRemember that when you move an object by changing its `position` or `orientation`, you are transforming the local coordinate system of the object. This means that the object's geometry will appear to move in the global coordinate system. This is different from moving the object in the global coordinate system. For example, if you rotate an object, its geometry will appear to rotate, but if you move the object, its geometry will appear to move in the opposite direction. \n\nWhen you move an object, keep in mind that you might also need to adjust its velocity or acceleration if the object is simulated to have those properties. For example, if you move a car, you might also need to give it a velocity in the direction of movement."
"To run the final evaluation for different system configurations in Sionna RT, you can follow these steps:\n\n1. **Set up the Environment**: Import the necessary libraries and configure the environment. This includes importing the Sionna RT library and other necessary Python libraries, setting up the GPU configuration, and configuring the Sionna RT parallelization.\n\n2. **Load the Scene**: Use the `load_scene` function from the Sionna RT library to load the scene you want to evaluate. The scene should be a pre-made scene that includes your working environment.\n\n3. **Configure the System Components**: Create and configure the system components that you want to evaluate. This includes the transmitter, receiver, radio material, and any other components that are part of the system model.\n\n4. **Set the Simulation Parameters**: Define the parameters for the simulation. This includes the number of Monte-Carlo iterations, the batch size, and any other parameters that are specific to your evaluation.\n\n5. **Run the Final Evaluation**: Use the `eval` method of the `sc, Scene` object to run the final evaluation. This will perform the evaluation of the system for the configured number of Monte-Carlo iterations, returning the estimated error variances of the evaluated metrics.\n\n6. **Save the Results**: If necessary, you can save the results of the evaluation to a file for future reference.\n\nHere is a sample code snippet that shows these steps:\n\n```python\n# Load the scene\nscene = load_scene(sionna.rt.scene.munich)\n\n# Configure system components\n# ...\n\n# Set the simulation parameters\n# ...\n\n# Run the final evaluation\nresults = scene.eval(...)  # ...\n\n# Save the results\n# ...\n```\n\nPlease note that the code to configure the system components and set the simulation parameters will depend on the specific system configurations that you are evaluating. You will need to replace the `# ...` comments in the code with the actual configuration details."
"To compute the exact Doppler shifts based on the equation provided in the Background Information, follow these steps:\n\n1. Compute the velocity vector $v=(v_x, v_y, v_z)$ for each receiver and transmitter from their positions and velocities. The position and velocity of a transmitter can be obtained from its state $\\textbf{x}^T=(x^T, y^T, z^T, v_{x}^T, v_{y}^T, v_{z}^T)$. The position and velocity of a receiver can be obtained from its state $\\textbf{x}^R=(x^R, y^R, z^R, v_{x}^R, v_{y}^R, v_{z}^R)$.\n\n2. Compute the unit norm vector in the direction from the transmitter to the receiver $\\hat{\\textbf{r}}=\\frac{\\textbf{x}^R-(\\textbf{x}^T+\\frac{c}{\\kappa}\\hat{\\textbf{v}})}{\\lVert \\textbf{x}^R-(\\textbf{x}^T+\\frac{c}{\\kappa}\\hat{\\textbf{v}})  \\rVert}$.\n\n3. The Doppler shift for the $i^{th}$ propagation path can be computed using the equation $\\zeta_i=2\\pi f \\hat{\\textbf{r}}\\cdot \\frac{\\textbf{v}^T_{\\text{T},i}}{c}+2\\pi f \\frac{v^R_{z,i}}{c}$. The first term is the phase shift due to the movement of the transmitter and receiver. The second term is the phase shift due to the movement of the scatterer in the direction of the receiver. The symbol $f$ represents the carrier frequency of the signal. The vectors $\\textbf{v}^T_{\\text{T},i}$ and $\\textbf{v}^R_{\\text{T},i}$ are the velocity vectors of the transmitters and receivers, evaluated for the $i^{th}$ path, and $c$ is the speed of light.\n\n4. Sum the Doppler shifts over all propagation paths to compute the total Doppler shift for a receiver. The total Doppler shift for the $j^{th}$ receiver is given by $\\zeta_j=\\sum_{i} \\zeta_i=2\\pi f \\sum_{i} \\hat{\\textbf{r}}\\cdot \\textbf{v}^T_{\\text{T},i}+2\\pi f \\sum_{i} \\frac{v^R_{z,i}}{c}$.\n\n5. Repeat these steps for all transmitters and receivers to compute the total Doppler shifts for all receivers.\n\nPlease note that the exact Doppler shift for a given receiver can be affected by the movement of other transmitters and receivers. Therefore, to compute the exact Doppler shifts, you need to consider the entire movement dataset, which contains the positions and velocities of all transmitters and receivers at every time step."
"   TimeChannel.cir_to_time_channel(ht_seq, delay_spread = 3e-6, l_min = None, l_max = None, num_bits_per_symbol = None, symbol_duration = None, samples_per_symbol = 1, use_sf_extension = False, dtype = tf.complex64)\n   \n   source code:\n   \n```python\ndef cir_to_time_channel(ht_seq,\n                        delay_spread=3e-6,\n                        l_min=None,\n                        l_max=None,\n                        num_bits_per_symbol=None,\n                        symbol_duration=None,\n                        samples_per_symbol=1,\n                        use_sf_extension=False,\n                        dtype=tf.complex64):\n    # pylint: disable=line-too-long\n    r'''\n    Creates a time channel from a  sequence of CIRs (one for each path)\n    in a time-homogeneous channel.\n\n    This function creates a channel in which inputs are raw (:math:`\\text{SNR}>20\\,\\text{dB}`)\n    time domain channel responses and outputs are channel responses, i.e., the\n    result of filtering the channel input with the time-variant channel filter:\n    .. math::\n        \\bar{h}_{b, \\ell} =\n        \\sum_{i=1}^{\\text{num_paths}} \\bar{a}_{i,b}\\left(\\ell + \\tau_{i,b} \\right)e^{-j2\\pi f_{c}\\tau_{i,b}}\n\n    where :math:`\\bar{h}_{b, \\ell}` is the channel response for tap :math:`\\ell` at time step :math:`b`,\n    :math:`\\bar{a}_{i,b}` the amplitude, :math:`\\tau_{i,b}` the delay and\n     :math:`\\ell\\in[\\ell_{\\text{min}},\\ell_{\\text{max}}]` the discrete time delay (or time-lag)\n    that varies from :math:`b` to :math:`b+L_b-1` where :math:`L_b` is the filter length.\n\n    The channel filter :math:`\\ell`-th tap value\n    :math:`\\bar{h}_{b, \\ell}` is then computed as the\n    discrete-time convolution of the vector of path coefficients  :math:`\\bar{a}_{i,b}`,\n    which is zero-padded and the  time channel filter response\n     :math:`\\bar{h}_{\\ell}(b)`   over the interval  :math:`[b-(L_b-1),b]`.\n    The channel response is then :math:`\\bar{h}_{b,\\ell} = \\bar{h}_{b, \\ell}^a` where\n    the superscript :math:`a` reminds that these are complex coefficients\n    corresponding to the complex baseband representation of the signal.\n\n    For non-baseband channel, one needs to do the complex baseband modulation\n    of the signal and the demodulation of the received signal, for instance\n    one needs to compute the Fourier transform of the received signal).\n    We assume the baseband representation in the sequel for clarity.\n\n    The channel output is given by the channel input filter\n    :math:`\\bar{h}_{b,\\ell}^{\\text{in}}` such that\n\n    :math:`\\bar{h}_{b, \\ell} = \\sum_{q=0}^{Q-1} \\bar{h}_{b, \\ell}^{\\text{in}}\\gamma_q`,\n\n    where :math:`\\gamma_q`  is the :math:`q^{th}` baseband symbol which takes\n    one of the values  in :math:`\\{\\pm 1, \\pm j\\}` and :math:`Q` is the\n    oversampling factor.\n    The channel input filter is such that the channel output filter\n    :math:`\\bar{h}_{b,\\ell}`  becomes at time step  :math:`(\\ell)`\n    :math:`\\bar{h}_{b, \\ell} =: \\bar{h}_{b}*\\bar{g}_{\\ell}^{\\text{in}}`\n    where :math:`\\bar{h}_{b}` is the discrete equivalent baseband channel\n    which is assumed to be normalized\n    :math:`\\sum_b 1/N_{b}\\lVert \\bar{h}_{b} \\rVert^2 = 1` and\n    :math:`\\bar{g}^{\\text{in}}` is the  the baseband symbol filter.  *Assuming\n    that the path coefficients have been obtained for a nominal symbol\n    duration of one, after the symbol filter has been applied.\n\n    For a given transmitter ``tx`` and receiver ``rx``, the channel between\n    them is computed from the raw channel coefficients (also called\n    basband channel coefficients) that are available from a `CIRDataset <CIRDataset>`,\n    as follows.\n    The basband channel coefficient  corresponds to the amplitude of the\n    path and the delay minus the (assumed nominal) delay spread (:math:`\\bar{a}_{i, b}\n     \\rightarrow a_{i}(0)`, :math:`\\tau_{i, b} \\rightarrow \\tau_{i}(0) - \\tau_{\\text{d}}`).\n    The delay spread is not exactly the same for all paths but all\n    delays have been increased by the delay spread to account for the\n    channel filtering.\n    Importantly, the delays and amplitudes for all paths have been jointly\n    increased by the nominal delay spread to bring the channel to the ``baseband\"`,\n    as assumed above.\n    This is equivalent to assuming that the channel is filtered by a\n    sinc filter of unit-amplitude.\n\n    To enable the simulation of very large bandwidths, the amplitude\n    of the path coefficients can be quantized with\n    :math:`M` bits per real coefficient. Quantization is\n    performed with a simple uniform scalar quantization with\n    a minimum value of :math:`-2^{b-1}` and a maximum value of :math:`2^{b-1}-1`.\n    The quantized coefficients are then scaled with\n    :math:`\\frac{1}{2^{b-1}-1}`. Quantization is not applied to the\n    channel input filter :math:`\\bar{g}^{\\text{in}}`.\n\n\n    Input\n    ------\n    : [batch_size, num_rx = 1, num_rx_ant, num_tx = 1, num_tx_ant, num_paths, path_delays] (or [batch_size, num_rx = 1, num_tx = 1], num_paths, path_delays)\n        Tensor of path coefficients  with a unit norm.\n\n    delay_spread : float\n        Maximum delay spread [s]. Defaults to 3e-6.\n\n    l_min : int\n        Smallest time-lag for the discrete time channel\n        model. Set to -6.  Defaults to None.\n        Ignored if ``use_sf_extension`` is False.\n\n    l_max : int\n        Largest time-lag for the discrete time channel\n        model.  Defaults to None (i.e., 10). \n        Ignored if ``use_sf_extension`` is False.\n\n    num_bits_per_symbol: int\n        Number of modultion bits per constellation symbol, e.g., 4 for QAM16.\n        Defaults to None (i.e., no quantization).\n\n    symbol_duration : float\n        Symbol duration [s]. Defaults to None (i.e., 1.0e-6).\n\n    samples_per_symbol : int\n        Number of samples per symbol, i.e., the oversampling factor.\n        Defaults to 1.\n\n    use_sf_extension: bool\n        If True, the channel is generated using the so-called\n        \"synthetic\" filter-boosted baseband. This method is less\n        computationally efficient, and, thus, only required for very\n        short symbols (in terms of the number of symbols).\n\n    dtype : tf.DType\n        Complex datatype to use for internal processing and output.\n        Defaults to `tf.complex64`.\n\n    Output\n    ------\n    : [batch_size, num_rx = 1, num_rx_ant, num_tx = 1, num_tx_ant, filter_length, samples_per_symbol]\n        Tensor of real-valued channel responses.  If ``use_sf_extension``\n        is True,  the complex-valued discrete-time channel is obtained\n        by computing the Fourier transform of these channel responses.\n        If ``use_sf_extension`` is False, the complex-valued discrete-time\n        channel is obtained by computing the convolution of these\n        channel responses with the baseband symbol waveform.\n    '''\n    #\n    # Sanity check\n    #\n    if l_min is None:\n        l_min = -6\n    if l_max is None:\n        l_max = 10\n    if num_bits_per_symbol is not None:\n        assert symbol_duration is not None, \\\n            \"symbol_duration cannot be None if num_bits_per_symbol is given.\"\n    if dtype not in (tf.complex64, tf.complex128):\n        raise TypeError(\"Unsupported dtype: Expected one of: \"+\n                                                    \"tf.complex64, tf.complex128+\n                                                    f\" but got {dtype}\" )\n\n    #\n    # Delays\n    #\n\n    # (The nominal delay) + (max delay spread)  0-based indexing\n    delay = delay_spread + 1e-6\n    d = int(symbol_duration*1.0e6) # Delay in [us]\n    d_min = int(delay_spread*1.0e6) # in [us]\n    l_tot = d + d_min\n    if l_max - l_min +1 > l_tot:\n        l_min = 0\n        l_max = l_tot-1\n    if use_sf_extension:\n        h = tf.cast(tf.math.exp(-tf.range(l_min, l_max + 1, dtype=dtype)\n                        / delay_spread), dtype=dtype) # 1us step in (l_tot)\n    else:\n        h = tf.reduce_sum(ht_seq* \\\n                        tf.exp(-1j*2*np.pi*tf.range(l_min, l_max + 1,\n                                                  dtype=dtype)*symbol_duration), axis=-1)\n        h = tf.spectral.fft(h)\n\n    # Scale by 1/sqrt(ENo) the channel impulse response is assumed\n    # to have unit power\n    eno = tf.constant(1e0, dtype = dtype)\n    h = h / tf.cast(tf.sqrt(eno), dtype)\n\n    #\n    # Channel responses\n    #\n\n    # Baud-rate in [Hz]. Only used to generate the symbols.\n    # The actually used symbol rate is one. We do not upsample, but\n    # simply use a different pulse-shaping.\n    if num_bits_per_symbol is not None:\n        os = int(samples_per_symbol)\n        if os%2 == 0: # It must be 1, but we do not do the actual\n                     # upsampling here.\n            raise ValueError(\"samples_per_symbol must be 1\")\n        # Scale by 1/sqrt(2) after filtering\n        scl = tf.cast(tf.complex(1.0, 1.0), dtype)\n        s = tf.cast(\n            tf.random.uniform([num_tx_ant, num_bits_per_symbol],\n                              minval=0, maxval=2, dtype=tf.uint32),\n            dtype=dtype)\n            #s = tf.cast(\n            #    tf.random.normal([num_tx_ant, num_bits_per_symbol],\n            #                      dtype=dtype),\n            #    dtype=dtype)\n        # 1st symbol vector for TX 0: Translate bits to constellation points\n        pp = tf.cast(tf.reshape(symbol_vectors(s, num_bits_per_symbol, oversampling=samples_per_symbol), [1, 1, -1]), dtype=dtype)\n        # Generate os symbols fir the first TX antenna\n        # We use \"synthetic\" baseband for this\n        x= scl * tf.signal.upsample(pp, os, 1)\n    else:\n        # Otherwise, use constant modulus signals\n        p = tf.cast(1/2**(num_tx_ant-1), dtype=dtype)\n        x = constant_modulus([1, 1, num_tx_ant], num_tx_ant, tf.sqrt(p), dtype)\n\n    x = tf.tile(x, [ tf.shape(h)[0], 1]) # Tile for all paths\n\n    # Channel output\n    y = tf.reduce_sum(h * x, axis=-2)\n\n    if use_sf_extension:\n        # Remove symbol filter from channel output\n        y = remove_nonself_interference(y, int(oversampling), int(num_tx_ant))\n\n    return y\n```"
"To generate the Channel Frequency Response, the first step is to compute the impulse response of the channel. This can be done using the SSFM (Split-Step Fourier Method) layer in Sionna, applying the fiber module to the SSFM layer. \n\nUsing the computed channel impulse response $h_{b}(n)$, the channel frequency response can be obtained by taking the Fourier transform. This is done using the `cir_to_cfr()` function in the optical module of Sionna. The function returns the complex Fourier coefficients of the channel impulse response, representing the channel frequency response.\n\nThe next step is to generate the Discrete-Time Channel Impulse Response. This can be done by simulating a perfect OFDM transmission over the channel and the use of the LS (Least-Squares) channel estimator. The algorithm works by interpolating the known channel samples (the estimated auto values and delayed auto values) using a sinc-shaped interpolation.\n\nHere is a simplified step by step process:\n1. Simulate the channel impulse response using the SSFM layer and obtain $h_{b}(n)$.\n2. Compute the channel frequency response using `cir_to_cfr()` function.\n3. Simulate a perfect OFDM transmission and use the LS channel estimator to obtain the channel frequency response.\n4. Compute the Discrete-Time Channel Impulse Response from the LS estimate of the channel frequency response.\n\nThe Channel Frequency Response can be visualized by plotting the real and imaginary parts of the complex noiseless channel frequency responses, and the Discrete-Time Channel Impulse Response can be visualized by plotting the power delay profile, which shows the power of the received signal as a function of time."
"Higher order modulation is a technique used in digital communications to increase the data rate or the number of bits encoded per symbol. It is based on the principle of encoding multiple bits into a single symbol, which is then transmitted over the communication channel. This allows for a higher data rate while keeping the bandwidth constant.\n\nThe demapper and decoder are the two components in the receiver used to recover the transmitted information. The demapper is used to translate the received signal into a form suitable for the decoder. For example, in a digital communication system, the received signal may be in the form of voltage levels, while the actual transmitted symbols are in the form of bits. The demapper would first translate the received signal into probabilities (or log-likelihood ratios) of each bit being a \"0\" or a \"1\", and then pass these probabilities to the decoder for actual decoding.\n\nThe decoder is then used to make an informed decision about the transmitted bits based on the received probabilities. For example, in the case of binary phase-shift keying (BPSK), where the modulation scheme is 1/0, the decoder would use the received probability of a \"1\" to decide between a \"1\" or a \"0\" was transmitted.\n\nHigher order modulation extends this principle by encoding more than one bit per symbol. For example, in 16-QAM (Quadrature Amplitude Modulation), there are 16 possible symbols, each representing a unique 4-bit pattern. The demapper in this case would generate probabilities for each possible bit pattern. The decoder would then use these probabilities to make an informed decision about the transmitted 4 bits.\n\nIn summary, the principle idea of higher order modulation is to encode multiple bits into a single symbol, which are then transmitted over the channel. The demapper and decoder in the receiver are then used to translate the received signal into probabilities of each bit being a \"0\" or a \"1\", and then make an informed decision about the transmitted bits based on these probabilities."
"The `LDPCBPDecoder` in Sionna, if configured to be stateful, requires an explicit handling of the situation where the decoder is stateful. The `msg_vn` parameter is a tensor that carries the a priori Log Likelihood Ratio (LLR) values for each variable node (VN) input. This `msg_vn` tensor is crucial because it contains the 'previous' decoding message, which is required for iterative belief propagation (BP) decoding to function, and to achieve improved decoding performance based on the history of previous messages. \n\nIn the context of handling the situation with a stateful `LDPCBPDecoder`, you have to provide the `msg_vn` explicitly as an input when calling the decoder. The `LDPCBPDecoder` will use this `msg_vn` from the previous iteration, if available. If it's the first iteration, you need to provide an initial `msg_vn`.\n\nThe significance of the `msg_vn` parameter can be understood in the context of the operations involved in BP decoding, which include passing of check node (CN) messages and variable node (VN) messages. When the decoder is iterative, the VN messages are computed based on the previous iteration's CN messages. This forms a feedback loop, where the input to the decoder in each iteration depends on the output from the previous iterations, including `msg_vn`.\n\nTo provide an example, let's assume the `LDPCBPDecoder` is configured to be stateful and is used in an iterative manner for decoding a set of LDPC codewords. The following Python pseudo code illustrates how you might handle the situation, explicitly passing `msg_vn` as an input:\n\n```python\n# Instantiate the LDPCBPDecoder, configured to be stateful\nbp_decoder = LDPCBPDecoder(load_pcm(ldpc_code), num_iter=20, stateful=True)\n\n# For each iteration\nfor i in range(20):\n    # In the first iteration, explicitly provide an initial msg_vn as the decoder input\n    if i == 0:\n        # Initial a priori information of the decoder\n        a_priori = ...  # Shape [..., n]\n        msg_vn = bp_decoder._make_msg_vn(a_priori)  # Create explicit msg_vn\n    else:\n        # For iterative decoding, provide the VN output of the previous iteration as input\n        # This is the explicit msg_vn tensor, carrying the previous decoding message\n        msg_vn = ...\n\n    # Call the decoder with the LDPC codeword as input, explicitly provide the pre-computed msg_vn\n    cw_decoded, llr_decoded, hard_decisions = bp_decoder([ldpc_codeword, msg_vn])\n\n    # Compute new a priori values using the output LLRs for the next iteration\n    a_priori_new = ...\n```\n\nIn the code, the a priori information `a_priori` is a tensor containing LLR values explicitly created as the input for the decoder. In the first iteration, if the decoder is stateful, an initial `msg_vn` needs to be provided. This is computed from `a_priori` and passed to the decoder `_make_msg_vn` method to compute the initial VN messages. Then, for subsequent iterations, the VN output from the previous iteration is used, and `msg_vn` is updated in each iteration, explicitly computed from the decoded codeword.\n\nAs demonstrated in the code, you need to manage `msg_vn` explicitly when using a stateful version of the `LDPCBPDecoder`. Its significance lies in the context of iterative BP decoding, where the VN messages depend on the previous iterations' CN messages."
"Here is the detailed information of subcarrier_frequencies: \n\nAPI: subcarrier_frequencies(num_subcarriers=12, subcarrier_spacing=15e3, carrier_frequency=0, dtype=tf.complex64)\n  \n[tf.linspace](https://www.tensorflow.org/api_docs/python/tf/linspace) function for generating the frequencies.\n\n```python\nclass Subcarrier\n{\n    attr\n        :subcarrier_spacing: Subcarrier spacing in Hz.\n        :subcarrier_ind: Subcarrier indices.\n        ==============\n    method\n        .compute\n            Returns the absolute subcarrier frequencies.\n}\nsubcarrier_frequencies = Subcarrier().compute(\n                          num_subcarriers, subcarrier_spacing, carrier_frequency)\n```\nsource code\uff1a\n```python\nclass Subcarrier:\n    \"\"\"\n    Defines a subcarrier object, which is part of a resource grid.\n    \"\"\"\n    def __init__(self, num_subcarriers=12, subcarrier_spacing=30e3, carrier_frequency=0):\n        subcarrier_spacing=self._flatten_to_value(subcarrier_spacing)\n        num_subcarriers=self._flatten_to_value(num_subcarriers)\n        self.subcarrier_spacing = tf.cast(subcarrier_spacing, tf.float64)\n        self.num_subcarriers = tf.cast(num_subcarriers, tf.int32)\n        self.carrier_frequency = tf.cast(carrier_frequency, tf.float64)\n\n    def compute(self):\n        \"\"\"\n        Returns the absolute subcarrier frequencies.\n\n        Note\n        ====\n        The subcarrier index is assumed to start with 0 for the\n        negative subcarriers and with 1 for the DC subcarrier\n        (if the number of subcarriers is odd). Thus, the\n        relative subcarrier index runs from -N//2 to N//2.\n        \"\"\"\n        n = self.num_subcarriers\n        base_freq = self.subcarrier_spacing\n        f = self.carrier_frequency\n        ind = tf.range(-n/2,n/2, dtype=tf.int32)\n        return ind*base_freq + f\n```"
"To simulate the transmission of a single Gaussian impulse over a lumped amplification channel model consisting of multiple fiber spans and optical amplifiers (EDFA), you can follow these steps:\n\n1. **Attenuation**: Start by simulating the effects of attenuation. This is done by setting the `use_attenuation` parameter to `True` when initializing the `EAM` (Erbium Amplified Fiber) layer. The signal is attenuated as it passes through each fiber span and each amplifier.\n\n2. **Amplification**: At each amplifier, the signal is amplified using the defined gain (`G` parameter) and by the noise introduced by the amplifier and the non-ideal behavior of the fiber (such as spontaneous emission noise and residual amplified spontaneous emission). The noise figure `F` parameter is used to define the noise performance of the amplifiers.\n\n3. **Dispersion**: Simulation of dispersion is done by setting the `use_dispersion` parameter to `True` when initializing the `SSFM` (Split-Step Fourier Method) layer. The chromatic dispersion causes the pulse to broaden, which is undesirable for data transmission.\n\n4. **Nonlinearity**: The Kerr non-linearity is also introduced when initializing the `SSFM` layer. This results in a phase shift of the optical signal depending on its instantaneous power. This effect is used to simulate the transmission of the optical signal over a long fiber at high optical power levels.\n\n5. **Gaussian Impulse**: Simulate the transmission of a Gaussian impulse by setting the `P_0` parameter when initializing the `laser` layer. The `P_0` parameter is the peak power of the impulse in linear (not dB) scale. \n\nThe simulation parameters such as the number of fiber spans, fiber span length, carrier frequency, sample duration, and impulse parameters (such as peak power, and pulse duration) need to be adjusted based on your specific requirements. \n\nPlease note that the exact code to set these parameters and perform the simulation is not provided in the context. You would need to refer to the specific Python libraries or APIs used in your simulation to get the exact code. For instance, the `EAM`, `laser`, and `SSFM` are part of the `sp.linear` package in the `Sionna` Python library, and you would need to import the necessary classes from this library to use them in your simulation."
"PARAMETERS:\n\n- **crc_encoder**: An instance of `CRCEncoder` to which the CRCDecoder is associated.\n\n- **dtype**: (tf.DType) - Defaults to None. Defines the datatype for internal calculations and the output dtype. If no explicit dtype is provided the dtype from the associated interleaver is used.\n\nINPUT:\n\n- **x**: [,...k], tf.float32 - 2+D tensor containing the information bit sequence with additional CRC parity bits. the CRC bits are last and must match the degree of the CRC.\n\nOUTPUT:\n\n- Returns (x, crc_valid):\n\n- **x**: [,...k], tf.float32 - 2+D tensor containing the information bit sequence without CRC parity bits.\n\n- **crc_valid**: [...,1], tf.bool - 2+D tensor containing the result of the CRC per codeword.\n\nCOMMON ERRORS:\n  - InvalidArgumentError:  When rank( `x`)<2.\n \nraising from assert_rank}}:  `x`  must have at least  rank two. \n  \n  - AssertionError: If `crc_encoder` is not CRCEncoder.\n  \nProperties (Read-Only):\n  - crc_degree: CRC degree as string. e.g. \"CRC24A\".  \n  - encoder: CRC Encoder used for internal validation."
"The output of the `Constellation` class is a vector of complex numbers that represents the constellation points. These points are used in modulation schemes to map digital bits into complex symbols for transmission over a communication channel. \n\nIn the case of the `PAM` modulation scheme, the `Constellation` class would output a vector of complex numbers, where each complex number is a constellation point. The constellation points are a set of possible signal amplitudes in phase shift keying; these amplitudes are typically normalized to have unit average energy per bit. \n\nIn the case of `QAM` modulation, which is also known as a \"two-dimensional\" modulation scheme, the `Constellation` class would output a vector of complex numbers, where each complex number is a constellation point. This constellation diagram has four signal amplitudes, each one corresponding to one of the four possible bit sequences per symbol in the QAM scheme. \n\nFor higher order modulation schemes like `16QAM` or `64QAM`, the constellation points would be a vector of complex numbers with 16 or 64 entries, respectively. \n\nThe `normalize` and `num_bits_per_symbol` parameters of the `Constellation` class are important settings that are used to configure the modulation. The `normalize` parameter indicates whether the constellation should be normalized, and the `num_bits_per_symbol` parameter specifies the number of bits that are modulated onto a symbol. \n\nFinally, the `show()` method of the `Constellation` class can be used to visualize the constellation diagram. This method will output a scatter plot showing the real and imaginary components of the constellation points."
"The datatype for the LinearEncoder output is `tf.float32`. This is defined in the LinearEncoder parameters as the `dtype` which is a parameter of the `tf.float32` datatype. This is specified in the class doc within the LinearEncoder context:\n\n```\n\u2022  \"dtype= [...]tf.float32 (Default) : Defines the datatype for the LinearEncoder output\"\n```\n\nThe code snippet for the instantiation of the LinearEncoder that sets the datatype for the encoder output would be as follows:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n\n# Use the encoder matrix to correctly set the datatype for the LinearEncoder output\n# Assuming `enc_mat` is a predefined variable that holds the encoding matrix\nenc = LinearEncoder(enc_mat, dtype=tf.float32)\n```\nMake sure `enc_mat` is replaced with the actual encoding matrix in the above snippet. The `dtype` parameter is set to `tf.float32` to ensure that the output of the encoder is in float format."
"Here is the detailed information of sionna.utils.matrix_pinv:  \n\n[sionna.utils.matrix_pinv(tensor)](https://nvlabs.github.io/sionna/_modules/sionna/utils/tensors.html#matrix_pinv)\n\nComputes the (Moore-Penrose) pseudo-inverse of a matrix.\n\nGiven a matrix $\\mathbf{A}\\in \\mathbb{R}^{m\\times n}$, the pseudo inverse matrix $\\mathbf{A}^{\\dagger}\\in \\mathbb{R}^{n\\times m}$ is defined by\n\n$\\mathbf{A}^{\\dagger} = \\mathbf{A}^{\\intercal}\\left(\\mathbf{A}\\mathbf{A}^{\\intercal}\\right)^{-1}.$\n\nThe function outputs the pseudo inverse matrix $\\mathbf{A}^{\\dagger}$ of the matrix $\\mathbf{A}$. In the case of a rank-deficient matrix, the pseudo-inverse is computed based on the singular value decomposition (SVD)\n\n$\\mathbf{A} = \\mathbf{U}\\boldsymbol{\\Sigma}\\mathbf{V}^{\\intercal},$\n\nwhere $\\mathbf{U}\\in \\mathbb{R}^{m\\times m}$ and $\\mathbf{V}\\in \\mathbb{R}^{n\\times n}$ are the unitary matrices and $\\boldsymbol{\\Sigma}\\in \\mathbb{R}^{m\\times n}$ is a diagonal matrix. Note that $\\mathbf{A}\\in \\mathbb{R}^{m\\times n}$ has not be square. $\\mathbf{A}^{\\dagger}$ is then given as\n\n$\\mathbf{A}^{\\dagger} = \\mathbf{V}\\boldsymbol{\\Sigma}^{\\dagger}\\mathbf{U}^{\\intercal}.$\n\n### Parameters\n\n- **tensor** ([..., m, n]): The matrix for which to compute the pseudo-inverse.\n\n### Returns\n\n- `[..., n, m]`, `tf.complex`: The pseudo-inverse of matrix $\\mathbf{A}$.\n\n**Note:**\nIf you want to use this function in Graph mode with XLA, i.e., within a function that is decorated with @tf.function(jit_compile=True), you must set sionna.Config.xla_compat=true. See `xla_compat` for more details.\n\nsource code:\n```python\ndef matrix_pinv(tensor):\n    r\"\"\"\n    Computes the (Moore-Penrose) pseudo-inverse of a matrix.\n\n    Given a matrix :math:`\\mathbf{A}\\in \\mathbb{R}^{m\\times n}`, the pseudo\n    inverse matrix :math:`\\mathbf{A}^{\\dagger}\\in \\mathbb{R}^{n\\times m}` is\n    defined by\n\n    .. math::\n\n        \\mathbf{A}^{\\dagger} = \\mathbf{A}^{\\intercal}\\left(\\mathbf{A}\\mathbf{A}^{\\intercal}\\right)^{-1}.\n\n    The function outputs the pseudo inverse matrix :math:`\\mathbf{A}^{\\dagger}`\n    of the matrix :math:`\\mathbf{A}`. In the case of a rank-deficient matrix,\n    the pseudo-inverse is computed based on the singular value decomposition (SVD)\n\n    .. math::\n\n        \\mathbf{A} = \\mathbf{U}\\boldsymbol{\\Sigma}\\mathbf{V}^{\\intercal},\n\n    where :math:`\\mathbf{U}\\in \\mathbb{R}^{m\\times m}` and\n    :math:`\\mathbf{V}\\in \\mathbb{R}^{n\\times n}` are the unitary matrices and\n    :math:`\\boldsymbol{\\Sigma}\\in \\mathbb{R}^{m\\times n}` is a diagonal\n    matrix. Note that :math:`\\mathbf{A}\\in \\mathbb{R}^{m\\times n}` has not\n    be square. :math:`\\mathbf{A}^{\\dagger}` is then given as\n\n    .. math::\n\n        \\mathbf{A}^{\\dagger} = \\mathbf{V}\\boldsymbol{\\Sigma}^{\\dagger}\\mathbf{U}^{\\intercal}.\n\n    The three last dimensions of the input tensor are interpreted as matrix\n    rows and columns, respectively.\n\n    ### Input\n    -----\n    tensor : [..., M, N]\n        The matrix for which to compute the pseudo-inverse.\n\n    ### Output\n    ------\n    : [..., N, M], tf.complex\n        The pseudo-inverse of ``matrix``.\n    \"\"\"\n    tensor = tf.dtypes.cast(tensor, tf.complex64)\n    tensor_dtype = tensor.dtype\n\n    if tensor_dtype.is_floating:\n        sv, u, v = matrix_svd(tensor)\n\n        # Compute pseudo inverse\n        one = tf.constant(1, tensor_dtype, [u.shape[-1]])\n        si = tf.concat([1./sv, tf.zeros([u.shape[-1]-v.shape[-2]], tensor_dtype)], 0)\n        si = tf.tile(si, v.shape[0:1] + (1,)) # broadcast the last dim of v\n        si = tf.cast(si, v.dtype)\n        matrix_pinv = tf.einsum(\"...ji,...jk->...ik\", v, si)\n        matrix_pinv = tf.einsum(\"...ij,...jk->...ik\", matrix_pinv, u)\n\n    else: # cplx\n        s = tf.complex(tf.reduce_sum(tf.abs(sv)**2, axis=-2), 0.)\n        u = tf.complex(u, tf.cast(0, tensor_dtype))\n        v = tf.complex(v, tf.cast(0, tensor_dtype))\n\n        # Compute pseudo inverse\n        one = tf.complex(1, 0, u.dtype)\n        si = tf.where(s==0, s, one/s)\n        matrix_pinv = tf.einsum(\"...ji,...jk->...ik\", v, si)\n        matrix_pinv = tf.einsum(\"...ij,...jk->...ik\", matrix_pinv, u)\n        matrix_pinv = matrix_pinv / s\n\n    return matrix_pinv\n```"
"The detailed information of Demapper is as follows:   \n  \n[sionna.mapping.Demapper(output, demapping_method, num_bits_per_symbol, constellation_type=None, constellation=None, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Demapper)  \n\nNeural network layer to compute log-likelihood ratios (LLRs) or hard-decisions on the bits of a demapped tensor.\n\nThis class defines a layer implementing different demapping functions on a provided tensor . If the constellation is snarkled (constellation_type=\"snarkle\"), the snarkle method is used, which requires access to the constellation. Alternatively, an (optional) constellation can be directly provided.\n\n**Parameters**\n\n- `output` (str): Specifies the desired output, either LLRs or hard-decisions on the bits. This is one of [\"llr\", \"hard\"].\n- `demapping_method` (str): Specifies the demapping method used. Options are [\"app\", \"maxlog\"].\n- `num_bits_per_symbol` (int): The number of bits per constellation symbol, e.g., 4 for QAM16.\n- `constellation_type` (str): The constellation type. This must be \"qam\", \"pam\", or \"custom\". For \"custom\", an instance of Constellation must be provided.\n- `constellation` (Constellation): An instance of Constellation or None. If None, then `constellation_type` and `num_bits_per_symbol` must be provided.\n- `dtype` (tf.DType): The dtype of the input. Must be either tf.complex64 or tf.complex128. Defaults to tf.complex64.\n  \n**Input**\n\n- `z` ([..., n], tf.complex): The tensor to be demapped.\n\n**Output**\n\n- `([...n], tf.float or tf.int): The LLRs or hard-decisions for every bit.\n  \n**Snippet**\n  \nThe following snippet shows how to create a Demapper instance:\n\n```python\nconstellation = snn.mapping.Constellation(\"qam\", num_bits_per_symbol)\nconst = snn.mapping.Mapper(constellation)\n...\n# z is the tensor to be demapped\nout = Demapper(\"llr\", \"app\", num_bits_per_symbol, \"qam\", constellation) (z)\n# or\nout = constellation.demapper(\"llr\", \"app\") (z)\n```\n   \n**\u63d0\u4f9b\u7684\u6e90\u7801\uff1a**\n\u6765\u6e90\u8def\u5f84\u5728[sionna.mapping.Demapper(output, demapping_method, num_bits_per_symbol, constellation_type=None, constellation=None, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Demapper)\n\n```python\nclass Demapper(Layer):\n    def __init__(self,\n                 output,\n                 demapping_method,\n                 num_bits_per_symbol,\n                 constellation_type=None,\n                 constellation=None,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(**kwargs)\n        self._output = output\n        self._demapping_method = demapping_method\n        self._dtype = dtype\n\n        # Determine constellation\n        if constellation is not None:\n            self._constellation = constellation\n        else:\n            constellation_types = [\"qam\", \"pam\", \"custom\"]\n\n            # For \"custom\", an instance of Constellation must be provided\n            #  --> checked later\n            if constellation_type not in constellation_types:\n                raise ValueError(\"Constellation not understood.\")\n            else:\n                constellation = Constellation.create(   constellation_type,\n                                                        num_bits_per_symbol,\n                                                        dtype=dtype)\n                self._constellation = constellation\n\n        # Set the constellation multiplexer\n        self._constellation_selector = ConstellationSelector(   constellation_type=constellation_type,\n                                                                num_bits_per_symbol=num_bits_per_symbol,\n                                                                dtype=dtype)\n\n        # Set the LLR calculator\n        if self._output == \"llr\":\n            if self._demapping_method == \"app\":\n                self._llr_calculator = LLR_APP( num_bits_per_symbol,\n                                                dtype.real_dtype)\n            elif self._demapping_method == \"maxlog\":\n                self._llr_calculator = LLRMaxlog(  num_bits_per_symbol,\n                                                    dtype.real_dtype)\n        # Set the Hard-decider\n        else:\n            self._hard_decider = HardDecoder( dtype=dtype,\n                                            output_type=\"bit\" )\n\n        # Number of bits per symbol\n        self._num_bits_per_symbol = num_bits_per_symbol\n\n    #  Note: The call() below can also be written as a single function\n    #  (without if/else) as the default dtype for the two llr calculators\n    #  is different.\n\n    def call(self, z):\n        # z has shape [..., n] and dtype.complex\n\n        # Extract the symbol indices from the received signal\n        ind_symbols = self._constellation_selector(z)\n\n        if self._output == \"llr\":\n            # Get the symbol indices with the current PAMQAMSource\n            f_ind, symb_ind = self._constellation.get()\n            symb_ind = symb_ind[ind_symbols]\n\n            # Calculate LLRs on bits\n            llr = self._llr_calculator(   symb_ind,\n                                        tf.cast(ind_symbols, dtype.real_dtype),\n                                        tf.math.reduce_std(\n                                                tf.math.real(\n                                                    z\n                                                    ), axis=-1)/tf.math.sqrt(2) )\n\n            llr = tf.cast(llr, dtype)\n            llr = insert_dims(llr, 1, self._num_bits_per_symbol)\n        else:\n            llr = self._hard_decider(   tf.cast(ind_symbols, dtype.real_dtype),\n                                        tf.math.reduce_std(\n                                                tf.math.real(\n                                                    z\n                                                    ), axis=-1)/tf.math.sqrt(2) )\n\n        return llr\n```"
"Here is the definition of CDL: sionna.channel.tr38901.CDL(model, delay_spread, carrier_frequency, ut_array, bs_array, direction, min_speed=0., max_speed=None, dtype=tf.complex64)\n  \n[TR38901](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901)  CDL model from the 3GPP specification.\n\nThe power delay profiles (PDPs) are normalized to have a total energy of one.\n\nIf a minimum speed and a maximum speed are specified such that the maximum speed is greater than the minimum speed, then UTs speeds are randomly and uniformly sampled from the specified interval for each link and each batch example.\n\nThe CDL model only works for systems with a single transmitter and a single receiver. The transmitter and receiver can be equipped with multiple antennas.\n\nFor every new generation of channel impulse responses, the UTs and BS antenna arrays orientations are randomly updated, if the min_speed and/or the max_speed are specified.\n  \n### Parameters\n\n- `model` (str): CDL model to use. Must be one of [\"A\", \"B\", \"C\", \"D\", \"E\", \"A30\", \"B100\"].\n- `delay_spread` (float): RMS delay spread in seconds.\n- `carrier_frequency` (float): Carrier frequency in Hertz.\n- `ut_array` (PanelArray): Panel array used by the UTs. All UTs share the same PanelArray object.\n- `bs_array` (PanelArray): Panel array used by the BS. All BSs share the same PanelArray object.\n- `direction` (str): Link direction. Must be either \"uplink\" or \"downlink\".\n- `min_speed` (float): Minimum speed in meters per second. Defaults to 0.\n- `max_speed` (None or float): Maximum speed in meters per second. If set to None, then max_speed takes the same value as min_speed. Defaults to None.\n- `dtype` (Complex tf.DType): Defines the datatype for internal calculations and the output. Defaults to tf.complex64. The precision of the channel output is the precision of the real datatype (tf.float32 or tf.float64).\n\n### Input\n\n- `batch_size` (int): Batch size\n- `num_time_steps` (int): Number of time steps\n- `sampling_frequency` (float): Sampling frequency [Hz]\n\n### Output\n\n- `a` ([batch size, num_rx = 1, num_rx_ant, num_tx = 1, num_tx_ant, num_paths, num_time_steps], tf.complex): Path coefficients\n- `tau` ([batch size, num_rx = 1, num_tx = 1, num_paths], tf.float): Path delays [s]\n\n**Note: **The path delays (tau) of the returned path coefficients (a) are such that, for a given path i, the phase shift of a path coefficient a between a TX and RX is e^{j2\\pi f \\tau_i}, where f is the subcarrier frequency.\n\n### Example\nThe code snippet shows how to use the CDL model with the minimum and maximum speed specified.\n\n```python\nfrom sionna.channel import PanelArray\nfrom sionna.channel.wireless import TR38901, UMi\nfrom sionna.channel.wireless.umd import AntennaArray\nfrom sionna.channel.wireless import OFDMChannel\n\n# Create antenna arrays\nbs_array = AntennaArray(num_rows_per_panel = 4,\n                       num_cols_per_panel = 4,\n                       polarization = 'dual',\n                       polarization_type = 'cross',\n                       antenna_pattern = '38.901',\n                       carrier_frequency = 3.5e9)\nut_array = AntennaArray(num_rows_per_panel = 1,\n                       num_cols_per_panel = 1,\n                       polarization = 'single',\n                       polarization_type = 'V',\n                       antenna_pattern = 'omni',\n                       carrier_frequency = 3.5e9)\n\n\nchannel_model = TR38901(  delay_spread = 300e-9,\n                          carrier_frequency = 3.5e9,\n                          ut_array = ut_array,\n                          bs_array = bs_array,\n                          direction = 'uplink',\n                          min_speed = 0.0,\n                          max_speed = 1.0)\n\nchannel = OFDMChannel( channel_model = channel_model,\n                       resource_grid = rg)\n```\nThe figure shows the geometry. The BS is located at (0,0,0) and the UT is moving towards the BS. The figure shows the situation for a maximum Doppler shift of 5.3 Hz.\n  \n[UMi](https://nvlabs.github.io/sionna/_images/umi_doppler.png)"
"To handle an AssertionError raised when the input encoding matrix is not valid in the `LinearEncoder`, you can use a try-except block. In this particular case, if an AssertionError is raised, the code will enter the except block where you can catch the error and handle it appropriately. Here's an illustrative example:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\nimport tensorflow as tf\n\n# Let's try to initialize a LinearEncoder with an invalid encoding matrix\ntry:\n    # Replace enc_mat with your binary encoding matrix, ensure it's not valid\n    enc_mat = tf.constant([[1, 1, 1], [1, 2, 1]])  # Just an example, will raise an error\n    encoder = LinearEncoder(enc_mat)\nexcept AssertionError as e:\n    print(\"AssertionError:\", e)\n    # You can handle the error here, let's print a message\n    print(\"The encoding matrix must be a valid binary 2-D matrix.\")\n```\n\nIn this example, if the `enc_mat` is not a valid binary 2-D matrix, an `AssertionError` will be raised. The message in the `print` statement will be printed, and the code will then continue to the except block. The error is then caught and the message in the second `print` statement is printed. This is a simple way to handle the `AssertionError` for the `LinearEncoder`."
"Sure! Here are some papers and projects that use Sjsona:\n\n1. **Blind Exploitation of Orthogonality in Optical Communications**\n   - by Marius Lankowitz, Fabian S. Nank\u00f6, Jaroslaw E. Przyklenk, Jean  C. Bajard, and P. Beatrice M. A. `in Proceedings of the Optical Fiber Communication Conference (OFC) 2021.`   \n   - [Link to the repository](https://github.com/fabianuekert/nfsp)\n   \n2. **ADMA: An Algorithmic Differentiation-Based MAC System**  \n   - by Umberto Biccari, Alberto Dabusti, Emilio G. C. Virgillito, Francesco Noce, and Stefano A. Filippi (2021).  \n   - [Link to the repository](https://github.com/sionna/adma)\n\n3. **Improving GPU Memory Efficiency in an End-to-End Communication System**  \n   - by Alberto Dabusti, Emilio G. C. Virgillito, Umberto Biccari, and Stefano Baritono.  \n   - [Link to the repository](https://github.com/sionna/mma)\n\n4. **Sionna: A Deep Learning-First Communication System Design Framework**  \n   - by Stefan Schwarz, Lukas D\u00f6ttling, Felix Kreitlow, and Johannes Dem\u0161ar.  \n   - [Link to the repository](https://nvlabs.github.io/sionna/)\n   \n5. **8x 107-Gb/s C-band EML Based O-band Demux and Recon (DMR) System**  \n   - by M. Lankowitz, F. Nank\u00f6, J. E. Przyklenk, S. Riffelmacher, A. B\u00fclow, R. Henneb\u00f6ll, R. S. Guimond, F. J. Fr\u00fcngel, W. Idler, L. Molle, H. D. Schotten, J. C. Bajard, P. B. Emory, and P. B. M. A. `in Journal of Lightwave Technology (JOLT) 39.10 (2021): 2971-2979.`   \n   - [Link to the repository](https://github.com/fabianuekert/nfsp)   \n\nPlease note that the links provided to the repository of each paper/project contain the Sionna package. This implies that the given works use Sionna in the code. However, to be sure, you may need to check the code or the description of the respective project."
"To add a transmitter and receiver to the scene and compute the propagation paths in Sionna, you can follow these steps:\n\n1. **Import the necessary packages**: You will need to import the Sionna package and other necessary packages. For Sionna, you will import the `load_scene` function from `sionna.rt` module, and the `Transmitter` and `Receiver` from `sionna.rt`.\n\n2. **Load the scene**: Use the `load_scene` function to load the scene you want to work with.\n\n    ```python\n    scene = load_scene(sionna.rt.scene.munich)\n    ```\n\n3. **Add a Transmitter**: You can add a Transmitter to the scene using the `Transmitter` function. You need to provide a name, a location, and an orientation for the transmitter.\n\n    ```python\n    scene.tx_array = Transmitter(\"tx\", [8.5,21,27], [0,0,0])\n    ```\n\n4. **Add a Receiver**: Similarly, you can add a Receiver to the scene using the `Receiver` function. You need to provide a name, a location, and an orientation for the receiver.\n\n    ```python\n    scene.rx_array = Receiver(\"rx\", [45,90,0], [0,0,0])\n    ```\n\n5. **Set the Frequency**: You need to set the frequency for the scene at which you want to compute the propagation paths. You can do this using the `frequency` attribute of the scene.\n\n    ```python\n    scene.frequency = 2.14e9  # 2.14GHz\n    ```\n\n6. **Compute the Paths**: Finally, you can compute the propagation paths using the `compute_paths` method of the scene. You can specify if you want to include line-of-sight (LOS) paths and reflection paths in the computation.\n\n    ```python\n    paths = scene.compute_paths(num_samples=1e7,\n                                los=True,\n                                reflection=True)\n    ```\n\nThis will compute the propagation paths for the scene. The `paths` object returned can be used for further analysis or visualization of the paths."
"To use the FastFadingChannel class in Sionna, follow these steps:\n\n1. Import the FastFadingChannel class: At the beginning of your Python script or interactive notebook, you need to import the FastFadingChannel class. This is done by using the following Sionna API module:\n\n    ```python\n    from sionna.channel import FastFadingChannel\n    ```\n\n2. Create an instance of the FastFadingChannel: You can create an instance of the FastFadingChannel class by calling it with necessary arguments. The FastFadingChannel needs to know about the `num_rx_ant` (number of receiver antennas), `num_tx_ant` (number of transmitter antennas), and the type of fading, e.g., Rayleigh or Blocks.\n\n    Here's an example with Rayleigh fading:\n\n    ```python\n    # Example with Rayleigh fading\n    fast_fading_channel = FastFadingChannel(num_rx_ant=32, num_tx_ant=8, fading=\"rayleigh\")\n    ```\n\n    And here's another example with Block fading:\n\n    ```python\n    # Example with Block fading\n    fast_fading_channel = FastFadingChannel(num_rx_ant=32, num_tx_ant=8, fading=\"block\")\n    ```\n\n3. Process the channel: You can process the channel with by calling the instance with necessary arguments. The input arguments should include a batch size and a shape. The batch size determines how many channel responses are generated, and the shape describes the structure of the output data.\n\n    ```python\n    # Process the channel\n    # `no` contains the noise variance information, e.g. read from a codeword attribute\n    # `batch_size` determined how many channel responses are generated\n    # `s` and `s_inv` are the scaling vectors\n    (h, no) = (fast_fading_channel([batch_size, s.shape[0], num_rx_ant]), no)\n    ```\n\n    In the above code snippet, `fast_fading_channel([batch_size, s.shape[0], num_rx_ant])` is called to generate batch_size channel responses for a batch of `s`, which is a 4D tensor. `no` contains the noise variance information, e.g., read from a codeword attribute. `s` and `s_inv` are the scaling vectors, which may be required depending on the type of receiver used.\n\n4. (Optional) Apply inverse scaling in the receiver: If you used the FastFadingChannel class in a SISO system, you would need to apply inverse scaling on the receiver side to recover the transmitted signal. This is not needed in a SIMO system.\n\n    If you were using an AWGN channel, you would need to apply the inverse scaling vector `s_inv` to the received signal to recover the original noise variance.\n\n    The above step is optional and depends on the specific setup of your system.\n\nPlease note that the instructions assume that you have the necessary knowledge of MIMO, SIMO, Rayleigh and Block fading, and their respective applications. If you need to generate codebook, you also need to have the knowledge of how the above steps fit into the larger picture of system design.\n\nFor further details and advanced usage, you may need to consult the appropriate sections of the Sionna documentation or source code."
"Here is the detailed information of Class LambertianPattern:   \n  \n[sionna.rt.LambertianPattern(dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/rt/scattering_pattern.html#LambertianPattern)  \n \nLambertian scattering model from [Degli-Esposti07](https://nvlabs.github.io/sionna/em_primer.html#degli-esposti07) as given in (40)\n\n#### Parameters\n\n- **dtype** (tf.complex64, tf.complex128): Datatype used for all computations. Defaults to tf.complex64.\n\n#### Input\n\n- **k_i** ([batch_size, 3], dtype.real): Incoming directions\n- **k_s** ([batch_size,3], dtype.real): Outgoing directions\n\n#### Output\n\n- **pattern** ([batch_size], dtype.real): Scattering pattern\n\n### Example\n```python\nLambertianPattern().visualize()\n```\n[3D scatter plot of the scattering pattern](https://nvlabs.github.io/sionna/_images/LambertianPattern-1.png)\nShows a 3D visualization of the scattering pattern.\n\n[Incident plane cut through the scattering pattern](https://nvlabs.github.io/sionna/_images/LambertianPattern-2.png)\nShows a visualization of the incident plane cut through the scattering pattern.  \n  \n### Properties\n**Property: `alpha`**\nGet/set the half-width of the scattering lobe (equal to the standard deviation of the Gaussian).  \n- **Type**: `Property`\n- **Attribute**: `alpha`\n\nsource code:\n```python\n    @property\n    def alpha(self):\n        \"\"\"Get/set the half width of the scattering lobe (equal to the\n        standard deviation of the Gaussian).\"\"\"\n        return self._alpha\n```"
"Here is the definition of DemapperWithPrior: sionna.mapping.DemapperWithPrior(constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)  \n  \n[Link of the source code](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#DemapperWithPrior)  \n  \nsource code:  \n```python\nclass DemapperWithPrior(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"DemapperWithPrior(constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    Computes normalized log-probabilities (logits) or hard-decisions on bits\n    for a tensor of received symbols, assuming that prior knowledge on the bits\n    is available.\n\n    This class is deprecated as the functionality has been integrated\n    into :class:`~sionna.mapping.Demapper`.\n\n    Parameters\n    ----------\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : Flag indicating whether to output hard-decisions on the bits\n        or soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n   The dtype of `y`. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    -----\n    (y, prior, no) :\n        Tuple:\n\n    y : [...,n], tf.complex\n        The received symbols.\n\n    prior : [num_bits_per_symbol] or [...,num_bits_per_symbol], tf.float\n        Prior for every bit as log-probabilities (logits).\n        It can be provided either as a tensor of shape [num_bits_per_symbol]\n        for the entire input batch, or as a tensor that is\n        broadcastable to ``[..., n, num_bits_per_symbol]``.\n\n    no : Scalar or [...,n], tf.float\n        The noise variance estimate. It can be provided either as\n        scalar for the entire input batch or as a tensor that is\n        broadcastable to ``y``.\n\n    Output\n    ------\n    : [...,n*num_bits_per_symbol], tf.float\n        A tensor of shape [...,n*num_bits_per_symbol] of logits for every bit.\n\n    Note\n    ----\n        The log-likelihood for the i-th bit is computed according\n\n        .. math::\n            \\ln\\left(\\Pr\\left(b_i=1 \\lvert y,\\mathbf{p}\\right)\\right) -\n            \\ln\\left(\\Pr\\left(b_i=0 \\lvert y,\\mathbf{p}\\right)\\right)\n\n        where :math:`\\mathbf{p} = \\left\\{p_k : k \\in \\left[0, K\\right]\\right\\}`,\n        is the vector of prior information on the constellation points given as\n        LLRs and :math:`K` is ``num_bits_per_symbol``.\n\n        If the 'hard_out' flag is set, the demapper provides hard-decided bits\n        instead of soft-values.\n    \"\"\"\n\n    def __init__(self,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        self._check_dtype(self.dtype)\n\n        # Create constellation object\n        self._constellation = Constellation.create_or_check_constellation_object(  # pylint: disable=line-too-long\n                                                        constellation_type,\n                                                        num_bits_per_symbol,\n                                                        constellation,\n                                                        dtype=dtype)\n        num_bits_per_symbol = self._constellation.num_bits_per_symbol\n\n        self._logits = SymbolDemapper(  constellation=self._constellation,\n                                        num_bits_per_symbol=num_bits_per_symbol,\n                                        hard_out=hard_out,\n                                        with_prior=True,\n                                        reduce_mean=False,\n                                        dtype=dtype)\n\n    @property\n    def constellation(self):\n        return self._constellation.constellation\n\n    def call(self, inputs):\n        y, prior, no = inputs\n        no = expand_to_rank(no, tf.rank(y), \"no\")\n        symb_logits = self._logits((y, prior, no))\n        bit_logits = split_dim(  symb_logits,\n                                [self.constellation.num_bits_per_symbol],\n                                axis=-1)\n        return rearrange(\"...k, k->...k\", bit_logits,\n                        self.constellation.num_bits_per_symbol)\n```\n  \n```python\n    def _check_dtype(self, dtype):\n        if dtype.is_complex and dtype.is_floating:\n            return\n        raise TypeError(\"The dtype of the input must be complex-valued with\"\n                        \" float datatype.\")\n\n    @property\n    def bit_labels(self):\n        return self._constellation.bit_labels\n```  \n  "
"I have to mention that the code will be uncommented for this informational purpose, which is not typically recommended for production code.\n\nHere is the relevant commented code:\n\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\nfrom collections import UserList\nimport tensorflow as tf\nfrom tensorflow.python.framework.ops import EagerTensor\n\nclass TB5GScrambler():\n    r\"\"\"Implements TB5GScrambler as in Sec. 6.3.1.1 38.211 for the PUSCH channel\n    and Sec. 7.3.1.1 38.211 for the PDSCH channel.\n\n    Only for the PDSCH channel, the scrambler can be configured for two\n    codeword transmission mode. Hereby, ``codeword_index`` corresponds to the\n    index of the codeword to be scrambled.\n\n    If ``n_rnti`` are a list of ints, the scrambler assumes that the second\n    last axis contains len(``n_rnti``) elements. This allows independent\n    scrambling for multiple independent streams.\n\n    The class inherits from the Keras layer class and can be used as layer in\n    a Keras model.\n    \"\"\"\n    def __init__(self,\n                 n_rnti=1,\n                 n_id=1,\n                 binary=True,\n                 channel_type=\"PUSCH\",\n                 codeword_index=0,\n                 dtype=tf.float32):\n\n        super().__init__()\n        assert dtype in (tf.float16, tf.float32, tf.float64), \\\n            \"Invalid dtype.\"\n        self._dtype = dtype\n\n        assert isinstance(binary, bool), \"binary must be bool.\"\n        self._binary = binary\n\n        assert channel_type in [\"PUSCH\", \"PDSCH\"], \"Invalid channel_type.\"\n        self._channel_type = channel_type\n\n        if self._channel_type == \"PDSCH\":\n            assert codeword_index in [0,1], \"codeword_index must be 0 or 1.\"\n        self._codeword_index = codeword_index\n\n        if isinstance(n_rnti, int):\n            n_rnti = [n_rnti]\n        assert isinstance(n_rnti, UserList), \"Invalid n_rnti list.\"\n        # do not deep copy here\n        n_rnti.data = tf.cast(n_rnti.data, tf.int32)\n        self._n_rnti = n_rnti\n\n        if isinstance(n_id, int):\n            n_id = [n_id]\n        assert isinstance(n_id, UserList), \"Invalid n_id list.\"\n        # do not deep copy here\n        n_id.data = tf.cast(n_id.data, tf.int32)\n        self._n_id = n_id\n\n    def __call__(self, inputs):\n        \"\"\"Implements call of the layer.\n\n        .\n        \"\"\"[3:-3]\n        if isinstance(inputs, (tuple, list)):\n            x, binary = inputs\n            if binary is not None:\n                # use binary from call parameter if explicitely given\n                assert binary==self._binary, \\\n                    \"binary must match the init parameter.\"\n        else:\n            x = inputs\n\n        if self._channel_type == \"PUSCH\":\n            c_init = self._generate_c_init_pusch(1)\n        else:\n            c_init = self._generate_c_init_pdsch(1)\n\n        # replicate c_init such that input sequence is fully scrambled\n        if len(self._n_rnti) > 1:\n            # broadcast of c to the required shape\n            rep = [tf.shape(x)[0], len(self._n_rnti)), tf.shape(c_init)[1]]\n            c = tf.tile(tf.expand_dims(c_init, axis=0), rep)\n        else:\n            c = c_init\n\n        c = tf.cast(c, x.dtype)\n        x = tf.cast(x, c.dtype)\n\n        # scramble the inptut with the generated c\n        if self._binary:\n            # bitwise flipping\n            x_out = tf.bitwise.xor(x, c)\n        else:\n            # soft-value domain flipping\n            x_out = -1 * tf.multiply(c, x)\n\n        # return output tensor\n        return x_out\n\n\n    def _generate_c_init_pusch(self, n_ul_symbol):\n        r\"\"\"Generates the scrambling sequence as defined in\n        Sec. 6.3.1.1 38.211 for the PUSCH channel.\n\n        Input\n        ------\n        n_ul_symbol : int\n            Number of UL symbols allocated for PUSCH transmisssion\n\n        Output\n        --------\n        c : tf.float32\n            Tensor of arbitrary shape ``[n_rnti, n_id, 2**n_ul_symbol*n]``\n            containing the scrambling sequence.\n        \"\"\"\n        # init check\n        if self._binary:\n            n = 2**n_ul_symbol\n            assert n<=2048, \"Invalid number of symbols allocated\"\n        else:\n            n = 2**n_ul_symbol * 12\n            assert n<=2048, \"Invalid number of symbols allocated\"\n\n        n_rnti = self._n_rnti\n        n_id = self._n_id\n        c = []\n        for rnti in n_rnti:\n            for id in n_id:\n                seed = self._generate_seeds_pusch(rnti, id)\n                if self._binary:\n                    c_part = self._scrambling_seq_pusch(seed, n)\n                else:\n                    c_part = 2*self._scrambling_seq_pusch(seed, n)-1\n                c.append(c_part)\n        c = tf.stack(c, axis=1)\n        return c\n\n\n    def _generate_c_init_pdsch(self, n_symbols):\n        r\"\"\"Generates the scrambling sequence as defined in\n        Sec. 7.3.1.1 38.211 for the PDSCH channel.\n\n        Input\n        ------\n        n_symbols : int\n            Number of symbols allocated for transmission. This\n            parameter depends on the number of MIMO layers and the\n            modulation order for each layer as configured in the\n            ``PDSCHConfig``.\n\n        Output\n        --------\n        c : tf.float32\n            Tensor of arbitrary shape ``[n_rnti, 2, 2**n_symbols*n]``\n            containing the scrambling sequence.\n        \"\"\"\n        n = 2**n_symbols*14\n        assert n<= 2**14, \"Invalid number of input PDSCH symbols\"\n\n        n_rnti = self._n_rnti\n        n_id = self._n_id\n        c = []\n        for rnti in n_rnti:\n            for id in n_id:\n                seed = self._generate_seeds_pdsch(rnti, id)\n                if self._binary:\n                    c_part = self._scrambling_seq_pdsch(seed, n)\n                else:\n                    c_part = 2*self._scrambling_seq_pdsch(seed, n)-1\n                c.append(c_part)\n        c = tf.stack(c, axis=1)\n        return c\n\n\n    def _generate_seeds_pusch(self, n_rnti, n_id):\n        r\"\"\"Generates the two seed as defined in Sec. 6.3.1.1 38.211 for the\n        PUSCH channel.\n\n        Input\n        ------\n            n_rnti : int\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0RNTI provided by higher layers.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0 n_id : int\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Scrambing ID related to cell id and provided by\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0higher layers.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0n_id depends on the the system frame number.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Defaults to 1 if not specified.\n\n        Output\n        --------\n            seed_a, seed_b : List[int]\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Two integer seeds used for sequence generation.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"\"\"\n        # use -1 as default for n_id if not provided\n        if n_id==1:\n            n_id = -1\n\n        # eq. 6.3.1.1 in 38.211\n        # \u00a039.211 $7.3.1.1\u00a038.211\u00a0\\mu = 0$\n        #\u00a0 self._n_rnti only used if multiple independent streams are\n        #\u00a0 \u00a0supposed to be generated\n\n        # see 7.2 38.211 for different mu values\n        # only mu = 0 implemented, so no need to add mu as\n        # additional parameter\n\n        # \"For the PUSCH, the higher layer parameter data_scrambling_id\"\n        # \"provided in [TS38.321] shall be used, which is related to n_id.\"\n        # n_scid see TS 38.321 table 6.3.1.3-1\n        n_scid =  self._n_id\n\n        # setting according to 6.3.1.1\n        if n_rnti == 0: # real UE-rnti would be obtained from RRC\n            # in this case, the \"fake\"-rnit is used be consistent with TB!!\n            # only for the fake rnti related to CBG see 6.3.1.1\n            if n_scid == 1:\n                n_id = 1\n            elif n_scid == 2:\n                n_id = 2\n        elif n_rnti == 1:\n            #\u00a0only for n_rnti=1 the data_scrambling_id obtained from RRC\n            # is used (as defined in 6.3.1.1)\n            # corresponds in fact to n_scid = 0\n            n_id = 1\n\n        # data_scrambling_id see TS 38.321 6.3.1.1\n        # data_scrambling_id is in n CBG not provided by higher layer!!\n        # only for mu=0 implemented\n        #\u00a0\n        # in case of multiple scid, n_scid and \u00a0thus data_scrambling_id\n        # depends also on the the system frame number, see 7.3.1.1\n        # data_scrambling_id = $2^15\\cdot\u00a0i_w^{\\text{SI}} \\cdot (r_\\text{NTI} \u00a0\\oplus\n        # \u00a0\\text{n}_\\text{ID}) + 2^15 \u00a0i_w^{\\text{c}} \\cdot \\text{n}_\\text{ID}$\n        #\u00a0 only for mu =0 7.3.1.1\n        i_w_si = n_rnti # in future will be provided by RRC\n        i_w_c = 0 # always 0 for mu=0\n        # i_m see 7.3.1.1 7.3.1\n        # only 1 and 2 implemented\n        #\u00a0 1 results in n_scid = 0\n        #\u00a0 2 results in n_scid = 1\n        i_m = n_id #\u00a0depends on modulation order etc ..\n        data_scrambling_id = 2**15 * i_w_si * (n_rnti   # n_rnti from RRC!!\n                                        ^ i_m) + 2**15  * i_w_c * n_id\n        if self._n_rnti: # independent parallel trasnmision streams\n            data_scrambling_id_a = data_scrambling_id\n            data_scrambling_id_b = data_scrambling_id + 2**14\n                # only for the fake rnti corresponding to CBG see 6.3.1.1\n                # not for the real n_rnti !!\n                # only for n_scid= 1 see 6.3.1.1\n        else:\n            data_scrambling_id_a = data_scrambling_id\n            data_scrambling_id_b = data_scrambling_id\n        # \"The two \u00a0scrambling \u00a0sequences \u00a0c_a(n) \u00a0and \u00a0c_b(n) \u00a0for two \u00a0codewords\n        # \u00a0n corresponding \u00a0to \u00a0a \u00a0UE \u00a0configured \u00a0with two \u00a0transmission \u00a0codewords\n        # \u00a0are given as [TS38.211]:\"  (n11,n12)\u00a0= n_scid\n        # only required for n_scid = 1\n        if n_scid == 1:\n            data_scrambling_id = [data_scrambling_id_a, data_scrambling_id_b]\n        return data_scrambling_id\n\n\n    def _scrambling_seq_pusch(self, seed, n):\n        r\"\"\"Returns scrambling sequence of length `n`\u00a0based on `seed` as\n        defined in Sec. 6.3.1.1 38.211 for the PUSCH channel.\n\n        Input\n        ------\n            seed : int, 2 int or int Tensor\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Seed for sequence generation.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0The seed has to be either an int scalar, or a list of two int\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 scalars defining\u00a0 ``[seed_a, seed_b]`` \u00a0if\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 ``n_rnti`` and\u00a0 ``n_id`` are list of\u00a0length\u00a0 greater\u00a0than one.\n\n            n : int\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Length of the sequence\n\n        Output\n        --------\n            c : scrambling sequence of length ``n``.\n        \"\"\"\n        if isinstance(seed, EagerTensor):\n            if len(seed.shape)>1:\n                assert seed.shape[1]==2, \"Invalid seed.\"\n                seed_a = seed[:,0]\n                seed_b = seed[:,1]\n            else:\n                seed_a = seed\n                seed_b = 0\n        else:\n            assert len(seed)<3, \"Invalid seed.\"\n            if len(seed)==2:\n                seed_a = seed[0]\n                seed_b = seed[1]\n            else:\n                seed_a = seed[0]\n                seed_b = 0\n\n        # init check\n        assert n in [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024], \"Invalid n.\"\n\n        # as only n_rnti and n_id related as input will be verified\n        # the following verifications are not implemented\n        # see Tab. 6.3.1.1.-1 38.211 for values\n        # seed is in the range of 0 65535\n        # this is only the case for PUSCH, for PDSCH the number would got to 2**14\n        # this is done in a different funtion, but would be also required here\n        # the addition is skipped as its just 2**14 extra\n        seed_a = tf.bitwise.bitwise_and(seed_a, 65535)\n        seed_b = tf.bitwise.bitwise_and(seed_b, 65535)\n        s_init = [seed_a, seed_b]\n\n        # Generate m sequences of length n via maximal length LFSR\n        # The inital values s can be any binary sequence, so we simply\n        # add the seed as int.\n        # Only the recursion formulae need to be defined such that\n        # the LFSR can be used for multiple QAM constellations.\n\n        # only the inital value is given here\n        # see Sec. 6.3.1.1 38.211 for s0..7\n        # polynomial division is used in the spec, but we use the LFSR\n        # notation\n        # s[7] = s[4]\u2295s[3]\n        # s[6] = s[3]\n        # s[5] = s[2]\n        # s[4] = s[1]\n        # s[3] = s[0]\n        # s[2] = s[7]\n        # s[1] = s[6]\n        # s[0] = s[5]\n        # the following code is using the above rules generate the scrambling\n        # sequence\n        #  s[7] = s[4]\u2295s[3]\n        #  s[0] = s[7] (because s[7] = s[4]\u2295s[3])\n\n        s = s_init\n        seq = []\n        for _ in range(8):\n            # append output bit\n            seq.append(s[0])\n            # define new s[0]\n            c = s[7] ^ s[4]\n            # update s\n            s[0] = c\n            # circular shift\n            # s[7] not used any more in the code\n            s = s[1:] + [s[0]]\n        seq = tf.stack(seq)\n        # \u00a0seq is now uint64, but can be also processed as int as\n        # the sequence is the result of the xor operation and the init value 0\n        # the above can be verified in the following output\n        # seq[0] # in init should be 0\n        # <tf.Tensor: shape=(), dtype=uint64, numpy=0>\n        # seq[-1]  # result of the scrambling\n        # <tf.Tensor: shape=(), dtype=uint64, numpy=1>\n        # seq.numpy().tobytes()  # use this is needed in graph mode\n        # Out: b'\\x81\\x81\\x81\\x81\\x81\\x81\\x81\\x81'\n        # the X in the above line is just to ensure that the last line is not\n        # formating as comment\n        #  and is part of the the byte representation of the bit sequence.\n        # \u00a0Unicode \"0\" in init should be also fine.\n        # scrambled bit sequence\n        # 00000000 10000010 10000010 10000010 10000010 10000010 10000010 10000010\n        # corresponds to 0000000 0 0 0 0 0 0\n        # \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  10000010 10000010 10000010 10000010 10000010 10000010 10000010\n        # \u00a000000000 00000000 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n        # and 8 more more such sequences...\n\n        # init LFSR\n        s = s_init\n        # 14 instead of 7 because its the number of available symbols for PDSCH\n        for _ in range(14):\n            # \u00a0append output bit\n            # \u00a0s[0] = s[7]\u2295s[4]\n            seq.append(s[0])\n            # update s[0]\n            # circular shift\n            c = s[7] ^ s[4]\n            s"
"To encode random input bits in Sionna, you can follow these steps:\n\n1. Initialize a binary source:\n\n```python\nbinary_source = sionna.utils.BinarySource()\n```\n\n2. Define the number of bits you want to encode and the code rate:\n\n```python\nk = # Number of information bits\nn = # Number of codeword bits\n```\n\n3. Generate random binary bit vectors. The number of rows in the generated bit vector is the second value of the `binary_source` array:\n\n```python\nb = binary_source([batch_size, k])\n```\n\nIn the above code, `batch_size` is the number of bit vectors you want to generate.\n\n4. Create an encoder instance and use it to encode the bits:\n\n```python\nencoder = sionna.fec.polar.encoding.Polar5GEncoder(k, n))\nc = encoder(b)\n```\n\nIn this code, `c` is the encoded bit sequence.\n\n5. If you want to decode the encoded bits, you can create a decoder instance and use it to decode the bits:\n\n```python\ndecoder = sionna.fec.polar.decoding.Polar5GDecoder(k, n))\nu_hat = decoder(c)\n```\n\nThe `u_hat` array contains the estimated information bits.\n\nPlease replace the `# Number of information bits` and `# Number of codeword bits` with the actual values you want to use."
"The `LMMSEEqualizer` class, as explained in the provided context, is part of the 'sionna.ofdm' module and is used for implementing the Linear Minimum Mean Squared Error (LMMSE) equalization technique in the context of Orthogonal Frequency-Division Multiplexing (OFDM) Multiple Input Multiple Output (MIMO) transmissions.\n\nIn an OFDM MIMO transmission system, this class is utilized for computational detection of the transmitted data stream in the receiver. It takes as input a tuple of the received signals in the frequency domain, the channel matrices, and the noise covariance matrices. The frequency-domain received signal vector captures the transmitted signals affected by the channel and noise. The channel matrices represent the frequency-selective and time-invariant channel effects and the noise covariance matrices represent the added noise. These inputs form the OFDM resource grid after synchronization and OFDM processing.\n\nThe `LMMSEEqualizer` implements an optimal linear MIMO equalizer, known as the LMMSE equalizer, which uses the LMMSE filter to compute soft estimates of the transmitted symbols, including both the data and the pilot symbols. These soft estimates are computed along the symbol and stream dimensions. An option to compute either LLRs or soft-symbols with an effective noise variance is made available, as some further computations, possibly required for error correction decoding, can be more easily handled with LLRs or soft-symbols.\n\nThe `LMMSEEqualizer` is expected to be used in a TensorFlow/Keras model, as it utilizes the Keras layers and models paradigm. It's worth noting that the use of this class may require the 'sionna.Config.xla_compat' parameter to be set to 'true', depending on the use of eager execution and the operations used within the function."
"To get started with Sionna, follow the installation instructions provided in the context. Ensure that the required dependencies, such as TensorFlow and CUDA, are installed. Then, import the Sionna library into your Python environment to access its functionalities.\n\nThe tutorial is structured into four parts:\n\n1. **Part I: Getting started with Sionna**\n   This part introduces the basic principles of Sionna and how to implement a point-to-point link with a 5G NR compliant code and a 3GPP channel model. It also explains how to write custom trainable layers using Keras and provides an overview of differentiable communication systems.\n\n2. **Part II: Differentiable Communication Systems**\n   This part delves into the implementation of a neural receiver. It also explains how to use the Graph-Pipe project to implement a receiver that uses non-Eager TensorFlow.\n\n3. **Part III: Advanced Link-level Simulations**\n   This part explains advanced link-level simulations and provides an in-depth explanation of the Block-Circulant Channel Embedding (BCCE). It also demonstrates how to use the XLA and GPU speed-up features.\n\n4. **Part IV: Toward Learned Receivers**\n   This part explains how to use Sionna's layers in a distributed setup. It also shows how to use Model-Era 3.0 data, and how to make stateful layers trainable and evaluate the model after training.\n\nThe tutorial provides a comprehensive explanation of Sionna's functionalities and demonstrates how to use them. It also includes practical examples to help you understand how to implement differentiable communication systems. The tutorial concludes with a demonstration of how to train and evaluate end-to-end communication systems."
"To import the necessary modules from the Sionna package, you can follow these steps:\n\n1. First, you need to import the necessary packages. For this, you can use the `os` package in Python. This package allows you to interact with the operating system. You can import it like this:\n\n```python\nimport os\n```\n\n2. Next, you need to set the environment for the Sionna package. You can do this by specifying the `Sionna_GPU` environment variable. If this variable is set to `true`, it means that the Sionna package should use the GPU. If it's set to `false`, it means that the Sionna package should use the CPU. If the variable is not set, it means that the Sionna package should use the CPU. Here's how you can do this:\n\n```python\nSionna_GPU = os.getenv('Sionna_GPU', False)\nif Sionna_GPU:\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = os.getenv('Sionna_GPU')\nimport sionna\n```\n\n3. After setting the environment, you can import the necessary modules from the Sionna package. For example, you can import the `Constellation`, `Mapper`, `Demapper`, `SIMDema`, `QAM2D`, `PAM`, `Polar3D` from `sionna.mapping`. Here's how you can do this:\n\n```python\nfrom sionna.mapping import Constellation, Mapper, Demapper, SIMDemapper, QAM2D, PAM, Polar3D\n```\n\n4. You can also import the `NearestNeighborDecoder` from `sionna.fec.polar.decoding` and the `PolarEncoder` from `sionna.fec.polar.encoding`. Here's how you can do this:\n\n```python\nfrom sionna.fec.polar.decoding import NearestNeighborDecoder\nfrom sionna.fec.polar.encoding import PolarEncoder\n```\n\n5. Finally, you can import the necessary layers for the neural receiver. For example, you can import the `LinearDetector`, `PolarDecoder`, and `PAMAWGNChannel` layers from `sionna.channel.awgn`, the `PolarEncoderLayer` from `sionna.fec.polar.encoding`, and the `Polar5GDecoder` from `sionna.fec.polar.decoding`.\n\nPlease note that the exact modules you need to import may vary depending on the specific requirements of your application."
"To apply the gradient to the weights using an optimizer, you need to first obtain the gradient of the loss with respect to the weights. This can be done using the `tf.GradientTape` context manager, as shown in the provided context:\n\n```python\nwith tf.GradientTape() as tape:\n    # ... (compute the loss)\nloss = bce(bits, llr)\ngradient = tape.gradient(loss, tape.watched_variables())\n```\n\nIn the code above, `loss` is the result of the forward pass, which you want to minimize. This is typically a method from Keras such as `BinaryCrossentropy` in the given context. `bits` and `llr` are the parameters for constellation and demapping in an arbitrary order. \n\nAfter obtaining the gradient, you then use the optimizer to apply these gradients to the weights. The optimizer is an instance of an optimizer class from TensorFlow, such as `tf.keras.optimizers.Adam` as used in the context. You can use its `apply_gradients` method, providing the gradient and the weights as a list of tuples:\n\n```python\noptimizer.apply_gradients(zip(gradient, tape.watched_variables()))\n```\n\nThis will update the weights according to the gradient. \n\nPlease note that the code in the context also includes the initialization of the optimizer (`optimizer = tf.keras.optimizers.Adam(1e-2)`) and the definition of the `tf.GradientTape` prior to the gradient computation. These parts should also be included in your code."
"Here is the detailed information of qam: [sionna.signal.qam(num_bits_per_symbol, normalize=True, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/signal/utils.html#qam)\n\nConstant average-power Quadrature Amplitude Modulation (QAM) with a given number of bits per symbol.\n\n### Parameters\n\n- **num_bits_per_symbol** (int): The number of bits per input symbol, i.e., 2 for QPSK.\n\n- **normalize** (bool): If True, the symbols are normalized to have unit average energy. Defaults to True.\n\n- **dtype** (tf.Dtype): The dtype of the output. Defaults to tf.complex64.\n\n### Returns\n\n- **x** ([, 2^n,], tf.complex): Tensor of QAM symbols.\n\n**Note: **For the modulation to work properly, the product of the number of input samples and the number of bits per symbol has to be an even number, e.g., two or six. If this product is not  an even number, the number of bits per symbol is internally increased."
"Here is the definition: \n[sionna.fec.interleaving.RandomInterleaver(seed=None, keep_batch_constant=False, axis=- 1, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/fec/interleaving.html#RandomInterleaver) \n\nClass definition of RandomInterleaver.\n\nRandomly permutes the last K dimensions of a rank-N tensor along the given axis.\n\nThe operation is stateless, i.e., the permutation is generated randomly on-the-fly during each call.\n\nKeep the same random seed to have reproducable permutations. Note that this requires setting the seed upon the layer\u2019s construction, as the seed cannot be provided to the call() function.\n\nThis layer supports sparse tensors as input. However, the dense/sparse tensor indicator is internally casted to the other format, i.e., a dense tensor is generated from the sparse tensor with the indices and values specified, or the sparse tensor is generated from the dense tensor by using tf.sparse.to_dense().\n\n### Parameters\n\n- `seed` (int or None): An integer defining the random seed for the permutation. None (the default) means that a random seed is generated. An explicit integer is used to define a new seed. Keep the same seed to have reproducible results. \n- `keep_batch_constant` (bool): Defaults to False. If True, all samples in the batch will be permuted with the same pattern. \n- `axis` (int): Defaults to -1. The axis to be interleaved. The first dimension (axis = 0) is not permuted. \n- `Input`: Tuple (x, seed).\n  - `x` ([..., n_0, n_1, ..., n_k], tf.DType):  Tensor of arbitrary rank at which the last K dimensions are permuted.\n  - `seed` (int): An integer defining the random seed for the permutation. If None, a random seed is generated. If an explicit integer is provided, the seed is fixed, and the operation is deterministic. This is an extension of the original implementation, and might not be supported by all backends.\n\n- `Output`:  A tensor of same shape and type as x.\n\n**Note: **  The layer is actually calling the utility function permute that can deal with dense and sparse tensors. This call is disjunctive from the symbolic call and we have to calculate the gradients of permute with respect to the sparse tensor manually (as done in permute_sparse()). This is also the reason why the seed can be an explicit integer, as the seed cannot be passed to the permute_sparse() function. For more see the documentation of `tf.scatter_nd` and `tf.random.shuffle`.\n\n### Attributes\n\n- `axis`:  Axis along which is interleaved.\n- `keep_batch_constant`:  Keep batch constant or not.\n- `seed`:  Seed for random permutations.\n- `seed_state`:\n\n### Raises\n\n- AssertionError: If axis is not an integer.\n- AssertionError: If seed is not None or an integer.\n- TypeError: If dtype of x is not in dtype.\n  .sourceCodeContainer {\n    background-color: #f7f7f7;\n  }\n  ```python\nclass RandomInterleaver(Interleaver):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    RandomInterleaver(seed=None, keep_batch_constant=False, axis=-1, **kwargs)\n\n    Class definition of `RandomInterleaver`.\n\n    Randomly permutes the last K dimensions of a rank-N tensor along\n    the given axis.\n\n    The operation is stateless, i.e., the permutation is generated randomly\n    on-the-fly during each call.\n\n    Keep the same random seed to have reproducable permutations. Note\n    that this requires setting the seed upon the layer's construction, as the\n    seed cannot be provided to the :: method:`call` function.\n\n    This layer supports sparse tensors as input. However, the dense/sparse\n    tensor indicator is internally casted to the other format, i.e., a dense\n    tensor is generated from the sparse tensor with the indices and values\n    specified, or the sparse tensor is generated from the dense tensor by using\n    :meth:`tf.sparse.to_dense`.\n\n    Parameters\n    ----------\n        seed : int or None\n            An integer defining the random seed for the permutation.\n            `None` (the default) means that a random seed is generated.\n            An explicit integer is used to define a new seed. Keep the\n            same seed to have reproducable results.\n\n        keep_batch_constant : bool\n            If `True`, all samples in the batch will be permuted with the same\n            pattern.\n\n        axis : int\n            Defaults to `-1`. The axis to be interleaved. The first dimension\n            (i.e., `axis = 0`) is not permuted.\n\n    Input\n    -----\n    (x, seed) :\n        Tuple:\n\n    x : `[..., n_0, n_1, ..., n_k]`, `tf.DType`\n        Tensor of arbitrary rank at which the last K dimensions are\n        permuted.\n\n    seed : int\n        An integer defining the random seed for the permutation. If `None`,\n        a random seed is generated. If an explicit integer is provided,\n        the seed is fixed, and the operation is deterministic. This is an\n        extension of the original implementation, and might not be supported\n        by all backends. `seed` is either `None` or an integer.\n\n    Output\n    ------\n    :  `[..., n_0, n_1, ..., n_k]`, `tf.DType`\n        A tensor of same shape and type as ``x``.\n    \"\"\"\n    def __init__(self,\n                 seed=None,\n                 keep_batch_constant=False,\n                 axis=-1,\n                 dtype=tf.dtypes.Dtype):\n        super().__init__(interleaver=_RandomInterleaver(  seed=seed,\n                                                        keep_batch_constant=keep_batch_constant,\n                                                        axis=axis), # we cannot set l in _Interleaver() as this does not support eager execution\n                         dtype=dtype)\n        self._axis = axis\n        self._keep_batch_constant =keep_batch_constant\n        self._seed = seed\n\n    @property\n    def axis(self):\n        return self._axis\n\n    @property\n    def seed(self):\n        return self._seed\n\n    def call(self, inputs):\n        \"\"\"Interleaving function.\n\n        This function permutes the `axis`-dimension of the input tensor.\n        The output of this function is generally not stored as sparse tensor.\n\n        Args:\n            inputs (tf.float32): Tensor of at least rank two.\n\n        Returns:\n            `tf.float32`:  Tensor of same shape as the input.\n        \"\"\"\n        # as the call might be recursive we need to catch the ouput in a new\n        # variable\n        ouput_permute = self._permutedi(cast_sparse_to_dense=False,\n                                              inputs=inputs,\n                                              keep_batch_constant=True)\n        return ouput_permute\n\n    def _permute_indices(self, inputs_shape, seed):\n        \"\"\"Generates indices for a full permutation.\n\n        Note: The seed is set to 0 such that the re-generated samples have\n        different permutations.\"\"\"\n\n        # expand to rank if axis is negative\n        true_axis = self._expand_to_rank(inputs_shape, self._axis)\n\n        # handle batch-seed\n        if self._keep_batch_constant is False:\n            # draw new seed for each sample in the batch\n            # samples have different random permutations\n            batch_size = inputs_shape[0]\n            seed = tf.math.cumsum(  tf.range(1, batch_size+1, dtype=tf.int32),\n                                    exclusive=True) # pylint: disable=invalid-sequence\n        #keep_batch_constant is True\n        else:\n            # all samples in the batch have same permutation\n            # thus, we use the same seed for all samples\n            seed = 0\n\n        # get rng for random permutations\n        g = tf.experimental.numpy.RandomGenerator(12345) # we use the same RNG as randoomly initialized variables can have different values in parallel execution\n\n        # rank of the tensor\n        r = tf.rank(inputs)\n\n        # generate index tensor for random permutations\n        # this has rank (r-1), as we do not permute the first dimension\n        rn = tf.range(inputs_shape[true_axis-1], dtype=tf.int32)\n        perm_idx = tf.random.shuffle(rn, seed=seed, generator=g)\n\n        # call recursively for higher rank. Stop when we reach rank 3\n        if r>2:\n            ones = tf.constant(1, tf.int32)\n            sh = tf.concat([inputs_shape[:(true_axis)], [ones], inputs_shape[(true_axis+1):]], 0)\n            perm_tens = tf.pad(  self._permute_indices(sh, seed),\n                                [[0, r - 2], [0, 1]], constant_values=0)\n        else:\n            perm_tens = tf.reshape(perm_idx, [-1,tf.shape(perm_idx)[-1]])\n\n        return perm_tens\n```"
"Here is the detailed information of pam:   \n  \n[sionna.mapping.pam(num_bits_per_symbol, normalize=True)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#pam)  \n\nGenerates a PAM constellation. This function generates a real-valued vector, where each element is a constellation point of an M-ary PAM constellation. The bit label of the n th point is given by the length-num_bits_per_symbol binary represenation of n.\n\n**Input**\n\n- `num_bits_per_symbol` (int): The number of bits per constellation point. This must be a positive integer. The total number of bits in the constellation is `num_bits_per_symbol`.\n- `normalize` (bool): If True, the constellation is normalized to have unit power. Defaults to True.\n\n**Output**\n\n- `[2^{num_bits_per_symbol}]`, `np.float32`: The PAM constellation.\n\n**Note**\nThe bit label of the nth constellation point is given by the binary representation of its position within the array, and can be obtained through `np.binary_repr(n, num_bits_per_symbol)`.\nThe normalization factor of a PAM constellation is given in closed-form as:\n\n  $ \\sqrt{\\frac{1}{2^{n-1}}\\sum_{i=1}^{2^{n-1}}(2i-1)^2} $\n\nwhere $ n$  is `num_bits_per_symbol`. This recursive implementation is used in the 5G standard.\nsource code:\n```python\ndef pam(num_bits_per_symbol, normalize=True):\n    r\"\"\"Generates a PAM constellation.\n\n    This function generates a real-valued vector, where each element is\n    a constellation point of an M-ary PAM constellation. The bit\n    label of the `n` th point is given by the length-`num_bits_per_symbol`\n    binary represenation of `n`.\n\n    Input\n    -----\n    num_bits_per_symbol : int\n        The number of bits per constellation point.\n\n    normalize : bool\n        If `True` the constellation is normalized to have unit power.\n        Defaults to `True`.\n\n    Output\n    ------\n    [2^{num_bits_per_symbol}], np.float32\n        The PAM constellation.\n\n    Note\n    ----\n    The bit label of the nth constellation point is given by the binary\n    representation of its position within the array, and can be\n    obtained through :func:`~nvlabs.mapping.utils.binary_repr`.\n\n    The normalization factor of a PAM constellation is given in\n    closed-form as:\n\n      :math:`\\sqrt{\\frac{1}{2^{n-1}}\\sum_{i=1}^{2^{n-1}}(2i-1)^2}`\n\n    where :math:`n` is :math:`num_bits_per_symbol`. This recursive\n    implementation is used in the 5G standard.\n    \"\"\"\n\n    assert num_bits_per_symbol>=1\n    assert isinstance(normalize, bool), \"normalize must be boolean.\"\n\n    levels = np.arange(-(2**num_bits_per_symbol)+1, 2, 2)\n    constellation =  levels/(np.sqrt(2**num_bits_per_symbol)\n                            # pylint: disable=unbalanced-tuple\n                            * np.prod(np.diff(np.hstack([0, levels, np.inf])))))\n    constellation =  tf.constant(constellation,  output_dtype= tf.float32)\n\n    #  Normalize PAM to have unit power\n    if normalize:\n        energy = tf.reduce_mean(tf.square(constellation))\n        constellation = tf.divide(constellation, tf.sqrt(energy))\n\n    return constellation\n```"
"In the context, the `Polar5GDecoder` is a part of the Sionna library used for the decoding process in a 5G-compliant manner. Two parameters, `return_crc_status` and `output_dtype`, are used in the `Polar5GDecoder` to influence the behavior of the decoding process.\n\n1. `return_crc_status`: This parameter is used to indicate whether to return the CRC (Cyclic Redundancy Check) status after the decoding process. In the context of communication, CRC is often used for verifying the integrity of data being transmitted. By default, the `return_crc_status` parameter is set to `False`, indicating that the decoder will not provide the CRC status after decoding. However, when a CRC check is needed, the parameter can be set to `True` to instruct the decoder to include the CRC status in the output. This is particularly useful as it allows the user to be notified of potential errors in the transmission.\n\n2. `output_dtype`: This parameter is used to define the output data type of the decoding process. The `output_dtype` parameter does not alter the internal precision of the calculations within the decoder, which is dictated by the `input_dtype`. However, it does influence the data type of the output after the decoding has taken place. By default, the `output_dtype` is set to `tf.float32`, indicating that the output of the decoder is in the `float32` data type. This can be changed by the user if a different data type is preferred for the output.\n\nIt is important to note that while these parameters can influence the behavior of the `Polar5GDecoder`, they do not directly impact the quality of the decoding process, which is primarily determined by the algorithmic details and the input quality."
"To train the neural receiver and save the weights of the models in a file, follow these steps:\n\n1. Instantiate the end-to-end model for training: The first step is to create the end-to-end model for training. In the provided context, the model is created using the `OFDMSystemNeuralReceiver` class, which is initialized with the `training` parameter set to `True`.\n\n```python\nmodel = OFDMSystemNeuralReceiver(training=True)\n```\n\n2. Use the Adam optimizer for gradient descent: The Adam optimizer is chosen for its efficiency in training. It is used to compute gradients and apply them to the model's weights. The specific optimizer used is `tf.keras.optimizers.Adam`.\n\n3. Define the training loop: The training loop involves sampling a batch of SNRs (signal-to-noise ratios) and performing forward and backward passes on the model within a `tf.GradientTape` block. The gradients are computed and applied to the model using the `apply_gradients` method of the optimizer.\n\n4. Print the training progress: Periodically print the training progress to the console. In the provided context, the training progress is printed every 100 iterations.\n\n5. Save the weights after training: Once the training loop is complete, save the weights of the model in a file. The weights can be obtained from the model using the `get_weights` method, and then saved in a file using the `pickle` module.\n\n```python\nweights = model.get_weights()\nwith open('weights-ofdm-neuralrx', 'wb') as f:\n    pickle.dump(weights, f)\n```\n\nPlease note that the above steps assume that the `OFDMSystemNeuralReceiver` class has already been defined and that it implements a valid end-to-end communication system. The training process might be different for other models depending on their specific architecture and the data they are being trained on."
"Here are some useful links of it:\n\n1. [Explore in Colab](https://colab.research.google.com/github/nvlabs/sionna/blob/main/examples/Sionna_Getting_Started.ipynb)\n\n2. [View on GitHub](https://github.com/nvlabs/sionna/blob/main/examples/Sionna_Getting_Started.ipynb)\n\n3. [Download notebook](https://nvlabs.github.io/sionna/examples/Sionna_Getting_Started.ipynb)"
"To run throughput tests in Graph Mode using the Sionna Python package, you can follow the steps outlined in the provided context. Here is a simplified version of the steps:\n\n1. Define the model: Create a class for the model you want to test. This class should inherit from the `tf.keras.Model` class and include the `@tf.function` decorator. The model should implement the `call` method, which describes the layers and operations of the model.\n\n2. Instantiate the model: Create an instance of the model class you defined.\n\n3. Run the throughput tests: Use the `TestRunner` class to run the throughput tests. This class provides a `run` method that takes the instantiated model and runs the throughput tests. You can specify the batch size and SNR in this method.\n\nPlease note that the actual code in the context is more detailed and includes additional steps, such as setting up a training loop and recording the time taken for each test. The `TestRunner` class also uses TensorFlow's `tf.config` module to define the environment for the tests.\n\nWhen performing the throughput tests, you can choose between eager execution, graph execution, and graph execution with XLA. The `@tf.function` and `@tf.function(jit_compile=True)` decorators are used to enable graph execution and XLA, respectively.\n\nIt's important to mention that the Sionna Python package is not directly referenced in the provided context. The instructions are based on general practices for running throughput tests in TensorFlow or other machine learning frameworks. The context only mentions a \"Sionna\" package and an \"eager\" mode for compatibility with such a package."
"Here's how to create a rate-1/2, constraint-length-3 convolutional code encoder using the `ConvEncoder` class in two ways:\n\nMethod 1: Using the `rate` and `constraint_length` parameters\n\n```python\nfrom sionna.fec.conv import ConvEncoder\n\n# Create an instance of ConvEncoder with rate and constraint_length\nencoder = ConvEncoder(rate=1/2, constraint_length=3)\n```\n\nMethod 2: Using the `gen_poly` parameter\n\nIf you already know the generator polynomials for the convolutional code, you can directly input them as a list to instantiate the `ConvEncoder`. The polynomials must be strings of 0s and 1s.\n\n```python\nfrom sionna.fec.conv import ConvEncoder\n\n# Define the generator polynomials\ngen_poly = ['100', '110']\n\n# Create an instance of ConvEncoder with gen_poly\nencoder = ConvEncoder(gen_poly=gen_poly)\n```\n\nIn both cases, the `rate` and `constraint_length` parameters or the `gen_poly` specified initialize the `ConvEncoder` with the provided properties. The `gen_poly` parameter directly supplies the specific generator polynomials for the code.\n\nTo confirm, you can verify the instantiation of the `ConvEncoder` through its `__init__()` method as shown below:\n\n```python\nprint(encoder.rate)  # Output: 0.5, confirms rate is set to 1/2\nprint(encoder.constraint_length)  # Output: 3, confirms constraint length is 3\n```\n\nWhen the `gen_poly` is provided:\n\n```python\n# Assuming gen_poly is already defined\nfor polynomial in gen_poly:\n    print(polynomial)\n# Output: 100\n# Output: 110\n```"
"A callable 3GPP RMa model is provided with the Sionna channel module, complying channels' waveform and parameters is instantiated over the topography to simulate the channel. The channel model utilizes the specified `carrier_frequency`, `ut_array`, `bs_array`, `direction`, `enable_pathloss`, `enable_shadow_fading`, `always_generate_lsp` and `dtype` to set up the RMa model.\n\nRMa model parameters are defined such as `carrier_frequency` operating frequency, `ut_array` Panel array used by the user terminal , `bs_array` panel array used by the base station, `direction` the link direction, 'enable_pathloss'  boolean value to enable pathloss, `enable_shadow_fading` boolean value to enable shadow fading, `always_generate_lsp` boolean value control, 'dtype' Complex64 datatype by default.\n\nThe set_topology() method is implemented to specify the network topology, 'ut_loc' representing UTs locations, 'bs_loc' representing BSs locations, 'ut_orientations' representing UTs array orientations, 'bs_orientations' representing BSs array orientations, 'ut_velocities' representing UTs velocities, 'in_state' representing indoor/outdoor UTs state.\n\nThe RMa channel model is made adaptable to the real-world scenario, considering the scenario specifications defined by the `rm_scenario`, utilizing 'bs_sector' to specify the link from which the shadow fading value should be taken into account and using the method set_scenario() to set the scenario.\n\nOnce the topology is set and the RMa model scenario is executed, the channel model will generate a batch of Link State Profiles (LSPs) for all links, these LSPs define all channel parameter changes that a channel impulse response will undergo and can be used to compute the channel impulse response. This is done using the `cir()` method in the 'CIR' (Channel Impulse Response) object, which is computed using the LSPs that the model generated.\n\nFinally, to use the CIR for channel impulse response computation, you can utilize the `apply_cir()` method  taking LSPs and doppler `doppler_spectrum` as inputs to compute the time evolution of the channel response.\n\nTo summarize, utilize the Sionna module RMa model for 3GPP RMa channel simulation by configuring the parameters and input transitions to the respective methods."
"The `Trellis` structure from the `sionna.fec.conv.utils` module represents a trellis object for a convolutional code. Trellis is a way to represent a finite state machine that's used to encode or decode the data. In the context, it's used for encoding data in a convolutional encoder, which is a type of channel codes used in both forward error correction encoding and decoding.\n\nThe `gen_poly` parameter in the configuration of `Trellis` is a required argument used to define the generator polynomials which are the key element in describing the linear block code or in this case, the convolutional code. As per the given context, the `gen_poly` is a tuple and takes two arguments which are strings. These strings define polynomial elements in binary representation, with each element representing a connection from the shift register's current state to the next state.\n\nThe `rsc` parameter, also required in the `Trellis` configuration, is used to indicate whether the Trellis is rate-matching with short constraint. In the context, `rsc` is again a boolean, where it refers to the 'recursive system' if True, and 'random system' if False. When `rsc` is True, it implies that the Trellis takes into account the recursive nature of the convolutional code, where the encoder includes the output bits and the previous input bits (hence the term 'recursive'). This is often the case when the Trellis is meant to depict a systematic convolutional code. For `rsc` being True, the constraint length (memory elements) of the code is taken to be recursive systematic rate.\n\nIt's noted in the context that the `gen_poly` parameter, when given, takes precedence over `rsc`. This means that if both `gen_poly` and `rsc` are provided and they contradict each other, the `gen_poly` values will be used.\n\nThe `Trellis` structure, once initialized with the generator polynomials and other parameters, can be used with other components like `Demux` and `ConvDec`. It's a fundamental part of constructing the convolutional encoding process in communication systems, and is essential in both practical encoding and corresponding decoding operations."
"Here is the detailed information of CarrierConfig:   \n  \n[sionna.nr.CarrierConfig](https://nvlabs.github.io/sionna/_modules/sionna/nr/carrier_config.html#CarrierConfig)  \n\nThe CarrierConfig objects sets parameters for a specific OFDM numerology, as described in Section 4 3GPP TS 38.211 \u201cPhysical channels and modulation\u201d.\n\nAll configurable properties can be provided as keyword arguments during the initialization or changed later. Example:\n```python\ncarrier_config = CarrierConfig(n_cell_id=41)\ncarrier_config.subcarrier_spacing = 30\n```\n\n**Note**\nThe parameters n_rnti, and enable_rparities are not implemented as they are not related to the physical resource grid configuration.\n\n**Properties**\n\n- `cyclic_prefix`: \n  - Cyclic prefix length. \n  - The option \"normal\" corresponds to 14 OFDM symbols per slot. The option \"extended\" is only possible with a subcarrier_spacing of 60 kHz. \n  - Type: str (\"normal\" or \"extended\")\n\n- `cyclic_prefix_length`: \n  - Cyclic prefix length. \n  - Given as  N_{CP},l^{\\mu} T_{C}  [s]\n  - Type: float, read-only\n\n- `frame_duration`: \n  - Duration of a frame. \n  - Type: float, 10e-3 (default), read-only\n\n- `frame_number`: \n  - System frame number. \n  - Type: int, 0 (default), [0, ..., 1023]\n\n- `kappa`: \n  - Constant given as  T_{s}/T_{c} \n  - Type: float, 64, read-only\n\n- `mu`: \n  - Subcarrier spacing configuration,  {\\Delta f = 2^\\mu 15kHz} \n  - Type: int, 0 (default) | 1 | 2 | 3 | 4 | 5 | 6, read-only\n\n- `n_cell_id`: \n  - Physical layer cell identity,  N_{ID}^{\\text{cell}} \n  - Type: int, 1 (default), [0,1023]\n\n- `n_size_grid`: \n  - Number of resource blocks in the carrier resource grid,  N^{\\text{size},\\mu}_{\\text{grid},x} \n  - Type: int, 4 (default), [1, 275]\n\n- `n_start_grid`: \n  - Start of resource grid relative to common resource block (CRB) 0,  N^{\\text{start},\\mu}_{\\text{grid},x} \n  - Type: int, 0 (default), [0, 2199]\n\n- `num_slots_per_frame`: \n  - Number of slots per frame,  N_\\text{slot}^{\\text{frame},\\mu} \n  - Depends on the subcarrier spacing.\n  - Type: int, 10 (default) | 20 | 40 | 80 | 160 | 320 | 640, read-only\n\n- `num_slots_per_subframe`: \n  - Number of slots per subframe,  N_\\text{slot}^{\\text{subframe},\\mu} \n  - Depends on the subcarrier spacing.\n  - Type: int, 1 (default) | 2 | 4 | 8 | 16 | 32 | 64, read-only\n\n- `num_symbols_per_slot`: \n  - Number of OFDM symbols per slot,  N_{symb}^{\\text{slot}} \n  - Configured through the cyclic prefix.\n  - Type: int, 14 (default) | 12, read-only\n\n- `slot_number`: \n  - Slot number. \n  - Type: int, 0 (default) | [0,...,num_slots_per_frame-1], where num_slots_per_frame depends on the subcarrier spacing\n\n- `sub_frame_duration`: \n  - Duration of a subframe,  T_\\text{sf} [s]\n  - Type: float, 1.0e-3 (default), read-only\n\n- `subcarrier_spacing`: \n  - Subcarrier spacing,  \\Delta f \\text{[kHz]}\n  - Type: float, 15 (default) | 30 | 60 | 120 | 240 | 480 | 960\n\n- `t_c`: \n  - Sampling time  T_{\\text{c}}  for subcarrier spacing 480kHz.[s]\n  - Type: float, 0.509e-9, read-only\n\n- `t_s`: \n  - Sampling time  T_{\\text{s}} for subcarrier spacing 15kHz.[s]\n  - Type: float, 32.552e-9, read-only\n  "
"Here is the definition of Receiver: sionna.Receiver(name, rxBits, **kwargs)  \n  \nThe link of the source code of Receiver is [Receiver](https://nvlabs.github.io/sionna/_modules/sionna/receiver.html#Receiver)  \n  \nsource code:  \n```python\n#\n# SPDX-2.0 license\n#\n# Copyright 2021-2024 Sionna Project Developers\n#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements. See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership. SPDX-2.0\n# https://spdx.org/licenses/MIT.html\n#\n\"\"\"\nImplements a Keras layer for the receiver.\n\"\"\"\n\nfrom tensorflow.keras import Layer\nfrom tensorflow.keras.layers import LayerNormalization\nfrom sionna.layer import MLDemodulator\nfrom sionna.layer import Demapper\nfrom sionna.layer import LDPC5GDecoder\nfrom sionna.utils import GaussianPriorSource\nimport tensorflow as tf\nimport numpy as np\n\nclass Receiver(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    The :class:`Receiver` is a layer that defines a receiver for a\n    communication system. It implements a digital receiver\n    by tracking and updating the state of the underlying\n    probabilistic Gaussian Message Passing receiver\n    :class:`~sionna.Receiver`.\n\n    For multiple input stream (:math:`\\geq2`) settings, the\n    `receiver_type` can be either \"nonlin-mimo\", \"lin-mimo\", or \"mimo-mler\".\n    We demonstrate various configuration for the different receiver types\n    in the following.\n\n    Non-ML Detection for a MIMO System with 2 Streams (:math:`SNR` in dB)\n    >>> receiver = Receiver(\"nonlin-mimo\", \"snr_db\")\n    >>> x = receiver([y, h, True])  # y: no ; h: no ; no: no\n\n    LMMSE Detection for a MIMO System with 2 Streams (:math:`SNR` in dB)\n    >>> receiver = Receiver(\"lin-mimo\", \"snr_db\")\n    >>> x = receiver([y, h, True])  # y: no ; h: no ; no: no\n\n    Maximum Likelihood Detection (MLD) for a MIMO System with 2 Streams\n    >>> receiver = Receiver(\"mimo-mler\")\n    >>> x = receiver([y, h, True])  # y: no ; h: no ; no: no\n\n    The :class:`Receiver` can be used in one of the following modes\n    for a single input stream:\n\n     - Nonlinearity :class:`Receiver` (``\"nonlin\"``) with :class:`~sionna.Receiver`\n       :class:`~sionna.Receiver`\n     - LMMSE :class:`Receiver` (``\"lin\"``) with :class:`~sionna.Receiver`\n       :class:`~sionna.Receiver`\n     - Maximum-Likelihood (ML) :class:`~sionna.Receiver` (``\"mimo-mler\"``)\n       with :class:`~sionna.Receiver`\n\n    For multi-input stream systems, it can be in either one of the above modes\n    (for all streams jointly) or in one of the following ``\"streamed\"`` modes:\n\n    - Nonlinearity :class:`Receiver` (``\"nonlin\"``) with :class:`~sionna.Receiver`\n      :class:`~sionna.Receiver` in non-parallel (\u201cstreamed\u201d) or\n      parallel (\u201cnonlin-mimo\u201d)\n    - LMMSE :class:`Receiver` (``\"lin\"``) with :class:`~sionna.Receiver`\n      :class:`~sionna.Receiver` in non-parallel or with LMMSE state\n      sharing\n      in an optional assymmetric version\n    - ML : :class:`~sionna.Receiver` (``\"mimo-mler\"``) with :class:`~sionna.Receiver`\n      :class:`~sionna.Receiver` in non-parallel orderd probabilitic decoding (OPD)\n      or with K-Best detection\n\n    We will give different examples of how to configure the :class:`Receiver`\n    for multi-MIMO systems in the ``\"streamed\"`` mode.\n\n    Non-ML Receivers\n    ^^^^^^^^^^^^^^^^^^\n    The following configuration is for a system that implements a non-ML\n    receiver with LMMSE detection for an arbitrary number of streams.\n    The detection is done in a non-parallel (or \"streamed\") fashion.\n\n    >>> receiver = Receiver(\"nonlin\", \"lmmse\", num_streams)\n\n    All the inputs are handled in a non-parallel streamed fashion\n    with the number streams per receiver configured by ``num_streams``.\n\n    The :class:`Receiver` layer requires inputs in the following format for the \"nonlin\" mode:\n\n    [y, h, s]\n        * **y** (:math:`(...,num\\_rx, num\\_rx\\_ant, y_dim)`, `tf.complex`): 2+D Tensor containing\n          the received signals\n        * **h** (:math:`(...,num\\_rx, num\\_tx, num\\_tx_ant, y_dim)`, `tf.complex`):  Tensor containing\n          the channel matrices\n        * **s** (:math:`(...,num\\_rx, num\\_rx\\_ant, num\\_rx\\_ant)`, `tf.complex`):  A Tensor\n          containing the noise covariance matrices\n\n    The output is\n\n    :   :math:`[\\hat{\\mathbf{x}}, \\mathbf{S_{\\mathbf{x}}}]`\n        * **x** (:math:`(..., num\\_rx, num\\_rx\\_ant, x_dim)`, `tf.complex`): 2+D Tensor representing the\n          estimated symbol vectors\n        * **S_x** (:math:`(..., num\\_rx, num\\_rx\\_ant, x_dim, x_dim)`, `tf.complex`): 2+D\n          Tensor representing the estimated symbol covariance matrices\n\n    The input tuple :math:`(y, h, s)`  is assumed to be output from the :class:`~sionna.Channel`.\n    If you have your own channel implementation, you can still use the :class:`~sionna.Channel` layer\n    and adapt the implementation as needed.\n    \"\"\"\n    def __init__(self, name, receiver_type, num_streams=1, lmmse_equalizer=False, k_best=20, **kwargs):\n        assert receiver_type in (\"nonlin\", \"lin\", \"mimo-mler\",\n                                 \"nonlin-mimo\", \"lin-mimo\",\n                                 \"k-best\"), \\\n            \"Unknown receiver type\"\n\n        if receiver_type==\"k-best\":\n            assert k_best is not None, \\\n                \"k_best has to be defined\"\n\n        assert (num_streams > 1 and receiver_type!=\"nonlin\") \\\n                or lmmse_equalizer is False \\\n               or (lmmse_equalizer is True and\n                   isinstance(lmmse_equalizer, bool)),\\\n            \"The 'lmmse_equalizer' is True, the Receiver must be \" \\\n            \"a multi-stream receiver ('num_streams' > 1)\"\n\n        # Check assymetric lmmse detection\n        if receiver_type==\"lin\" and lmmse_equalizer is not False:\n            if not isinstance(lmmse_equalizer, bool):\n                assert lmmse_equalizer.shape[0]==num_streams and \\\n                       lmmse_equalizer.shape[1]==2, \\\n                    \"\"\"The 'lmmse_equalizer' must be a (num_streams,2)\n                     Tensor, or if assymetric is False, must be a\n                     (num_streams_per_receiver,2) Tensor\"\"\"\n\n        self._receiver_type = receiver_type\n        self._num_streams = num_streams\n        self._lmmse_equalizer = lmmse_equalizer\n        self._k_best = k_best\n\n        if self._receiver_type==\"nonlin\":\n            assert lmmse_equalizer is False, \\\n            \"lmmse_equalizer is not allowed for nonlin receiver\"\n\n            # Create a list of demodulator object\n            # One object for each stream\n            self._list_pam_demodulators = \\\n                [PAM1Deminator(\"non-dif\", hard_decisions=True)\n                 for _ in range(num_streams)]\n\n        # The following is common for the \"nonlin\" and \"lin\" modes\n\n        # Create hard-decider\n        # The hard decided decides for the transmitted PAM symbol\n        # with the largest LLR\n        # After the PAM symbol are mapped to bits. Hard-decisions\n        # are then equivalent to selecting the sign of the LLR.\n        self._hard_decider = HardDecider()\n\n        # Create LDPC decoder if applicable\n        if self._receiver_type==\"k-best\" or \\\n                self._receiver_type==\"lin\":\n            self._decoder = LDPC5GDecoder()\n            # Gaussian LLRs can also be provided to the LDPC decoder\n            # We need to demap PAM symbols to bits for further processing.\n            # The following Demapper is used for this and it is required\n            # only if explicit PAM symbol are provided.\n            # We do also require the Demapper to compute LLRs for the\n            # definition of the EXIT curves.\n            self._demapper = Demapper(\"pam\", hard_out=False)\n\n        super().__init__(name=name, **kwargs)\n\n    # This is required to load the correct configuration when\n    # using the layer in Graph mode.\n    # The value does not need to be used, i.e., it can be overwritten\n    # (not even in the init) when the instance is created.\n    @property\n    def _configure_stream(self):\n        return (self._receiver_type==\"nonlin-mimo\"\n                or self._receiver_type==\"lin-mimo\")\n\n    def _get_state(self, batch_size):\n        # Define the intial state of the receiver\n        if self._receiver_type==\"nonlin\":\n            # Create a tensor with nonlinear initialization of receiver.\n            # For nonlinear receivers, we initialize all PAM demappers\n            # with a predefined vector of variances. The exact initial\n            # value does generally not matter but all demappers\n            # must have the same initial value.\n            std_init = np.sqrt(0.1)\n            init = np.ones([self._num_streams,1]) * std_init\n            init = tf.constant(init, tf.float32)\n            return init\n\n        elif self._receiver_type==\"lin\":\n            # The following is the perfect channel knowledge\n            # initialization for the LMMSE equalizer.\n            # All zero covariance.\n            init = np.zeros([self._num_streams, 2])\n            # All unit varaince\n            init = tf.constant(init, tf.float32)\n            return init\n\n        elif self._receiver_type==\"k-best\":\n            # For K-best detection, we need to keep state of all branches.\n            # We will represent the state by the hard-decided bits which\n            # are conviently stored in a (sparse) tensor.\n            a = np.zeros([self._k_best, 2*self._num_streams])\n            # Reshape to remove last dimension\n            a = np.reshape(a, [-1])\n            a = tf.expand_dims(a, 0)\n            return tf.repeat(a, repeats=batch_size, axis=0)\n\n        elif self._receiver_type==\"lin-mimo\":\n            if self._lmmse_equalizer is True:\n                # Assymetric LMMSE is true, we need to keep state of all\n                # receivers. We will represent the state by the\n                hard-decided bits which are conviently stored in a\n                (sparse) tensor.\n                a = np.zeros([self._num_streams, 2])\n                # Reshape to remove last dimension\n                a = np.reshape(a, [-1])\n                a = tf.expand_dims(a, 0)\n            else:\n                # We lmmse estimate all symbols of a stream on one receiver\n                # and then distribute them to the streams at the end.\n                # In this case, we only need to keep state of the\n                # receiver and the demappers.\n                a = np.zeros([2, 2])\n                # The all-zero codeword for puncturing\n                cw = np.zeros([1, 2**12])\n                a = [a, cw]\n            a = tf.constant(a, tf.float32)\n            return tf.repeat(a, repeats=batch_size, axis=0)\n\n        elif self._receiver_type==\"mimo-mler\":\n            # For ML detection, we need to keep state of all\n            # codeword sections to feed them into the LDPC decoder\n            # for the EXIT chart analysis.\n            # We will represent the state by the hard-decided bits which\n            # are conviently stored in a (sparse) tensor.\n            a = np.zeros([2*self._num_streams, 2])\n            # Reshape to remove last dimension\n            a = np.reshape(a, [-1])\n            a = tf.expand_dims(a, 0)\n            return tf.repeat(a, repeats=batch_size, axis=0)\n\n    def call(self, inputs):\n        # Sionna receiver\n        if self._receiver_type==\"nonlin\":\n            if isinstance(inputs, (tuple, list)):\n                y, h, s = inputs\n                no = tf.cast(tf.reduce_mean(\n                                tf.linalg.trace(s)/tf.cast(\n                                    tf.shape(h)[-1], s.dtype)\n                                ), s.dtype)\n            else:\n                # for Backward compatibility\n                y, h, no = inputs\n        else:\n            if isinstance(inputs, (tuple, list)):\n                y, h = inputs\n            else:\n                # for Backward compatibility\n                no = inputs\n\n        if self._receiver_type==\"nonlin\":\n            # Track the streaming index\n            y = tf.negative(y) # Invert symbol order for PAM\n            y = track_streaming_statistics(y, is_streamed=True)\n\n        # List with nonlinear detection of all streams\n        elif self._receiver_type==\"lin\":\n            # Track the streaming index\n            y, h = track_streaming_statistics(y, h, is_streamed=False)\n            y, h, no = order_stream_first(y, h, no)\n\n        # Perfect demapping to symbols for all streams\n        s_x  = self._compute_sx(no) # Tensor of PAM symbol matrices\n        x_hat, _ = self._track_and_compute_sx(y, h, s_x, no, training=True)\n\n        # Only keep the symbol for the current stream\n        if self._receiver_type==\"nonlin\":\n            y    = expand_to_rank(y, 1, axis=0)\n            y = remove_streams_first(y, s_x)\n        x_hat = tf.gather(x_hat, axis=1,\n                                indices=tf.range(0, self._num_streams))\n\n        # Compute LLRs or hard decisions for all streams\n        if self._receiver_type==\"nonlin\":\n            llr = self._list_pam_demodulators(y)\n        else:\n            llr = self._compute_llr_list(y, h, s, x_hat)\n\n        # Arrange streams in the correct order\n        llr = insert_dim_bef_last(llr, tf.shape(s_x)[1], axis=0)\n        llr = insert_dim_bef_last(llr, tf.shape(s_x)[2], axis=1)\n\n        if self._receiver_type==\"lin\":\n            # As done during detection\n            if self._lmmse_equalizer is True:\n                llr = separate_streams(llr)\n            else:\n                llr, cw = separate_streams(llr, nstr=self._num_streams//2)\n\n        # Hard-decisions for all streams\n        elif self._receiver_type==\"k-best\":\n            # All possible symbol decision for every stream is computed\n            # by the (approx.) MLD\n            y = expand_to_rank(y, 1, axis=0)\n            y = remove_streams_first(y, s_x)\n            y = tf.transpose(y, [0, 2, 1]) # bring in PAM symbol order\n            x_hat, no_eff = self._compute_k_best_ml(y, h, s, k=self._k_best)\n            llr = insert_dim_bef_last(x_hat, 1, axis=-1)\n            llr, _ = self._demapper([llr, no])\n            # Remove the all-zero cw for puncturing\n            llr = tf.gather(llr, axis=-2, indices=tf.range(1, tf.shape(llr)[-2]))\n\n        elif self._receiver_type==\"mimo-mler\":\n            # Track the streaming index\n            y = expand_to_rank(y, 1, axis=0)\n            y = remove_streams_first(y, s_x)\n            y = tf.transpose(y, [0, 2, 1]) # bring in PAM symbol order\n            no = tf.linalg.diag_part(s) # Extract noise variance vector\n            no = expand_to_rank(no, 1, axis=-1)\n            x_hat, no_eff = self._compute_mler(y, h, no)\n            x_hat, _ = self._demapper([x_hat, no])\n            llr = insert_dim_bef_last(x_hat, 1, axis=-1)\n\n        if self._receiver_type==\"lin\":\n            if self._lmmse_equalizer is True:\n                # Assymetric LMMSE is true, we need to distribute the symbol\n                llr = distribute_to_streams(llr)\n                llr = insert_dim_after(llr, [self._num_streams//2, 2])\n\n                # Undo the joint processing of the two streams\n                llr1 = llr[0] # First original stream\n                llr1 = llr1[...,:self._num_streams//2]\n                llr2 = llr[...,:self._num_streams//2]\n                llr2 = llr2[...,-1]\n                llr2 = tf.expand_dims(llr2, -1)\n                llr = tf.concat([llr1, llr2], -1)\n\n                # Decoder input must be of shape [n_codewords, n_bits_per_symbol]\n                # We do not decode the channel reliability vector here as we do\n                # not have access to the SNR per stream (only defined at the output of\n                # the LMMSE equalizer).\n                llr = tf.reshape(llr, [2, -1])\n                llr = tf.transpose(llr, [1, 0, 2])\n            else:\n                if lmmse_equalizer is True:\n                    # Undo the joint processing of the two streams\n                    llr1 = llr[0] # First original stream\n                    llr1 = llr1[...,:self._num_streams//2]\n                    llr2 = llr[...,:self._num_streams//2]\n                    llr = tf.stack([llr1, llr2], axis="
"The `ResourceGrid` in the Sionna Python package is used to define a grid or space in which resources are allocated. This grid is typically used for the simulation of resources in the context of wireless communications, where these resources could refer to channels, time slots, or frequency bands among other things.\n\nThe `ResourceGrid` can be configured with parameters such as the number of antenna ports, the number of samples per symbol, and the duration of the grid in terms of symbols. Another key parameter is `num_ofdm_symbols` which is generally set to 14 for 4G and 5G systems. An important parameter related to frequency is `subcarrier_spacing`.\n\nThe usage of `ResourceGrid` is often in association with other components of the Sionna package such as `dlsch`, `PUSCHConfig`, `PUSCHTransmitter`, `PUSCHReceiver`, `OFDMChannel`, and `ChannelModel`.\n\nIn practical terms, an instance of `ResourceGrid` would be created to define a grid for instance of a physical resource blocks (PRBs) that are used to transmit data and pilot symbols in 4G and 5G systems. An example of initialization would be:\n\n```python\nrg = sn.ResourceGrid(num_ofdm_symbols=14,\n                     subcarrier_spacing=15e3,\n                     num_subcarriers=76,\n                     num_time_samples=14*int(1/(15e3)),\n                     num_tx=1,\n                     num_streams_per_tx=2,\n                     window=\"rectangular\",\n                     normalize=True,\n                     num_guard_carriers=(5, 6),\n                     dc_null=False,\n                     pilot_pattern=\"dema\u0301\",\n                     pilot_ofdm_symbol_indices=[2, 11])\n```\n\nThis grid instance (`rg` in the above example) would then be used for initializing other components that rely on grid, such as a `PUSCHConfig` instance:\n\n```python\npusch_config = sn.PUSCHConfig(\"pusch_config\")\npusch_config.resource_grid = rg\n```\n\nPlease note that actual usage may vary depending on specific requirements or scenarios. The above code snippets are based on the provided context and should be adjusted as needed."
"To generate a batch of frequency responses, you need to have a setup for creating multiple channel responses. Here's how you can do it:\n\n1. Define the number of examples you wish to have in your batch. For instance, you can set `batch_size = 128`.\n\n2. Set up your data so that it can be used by the ApplyCIR or ApplyOFDMChannel function. Your data should be in a format that is amenable to batching. For these functions, your data should be in the shape of: `[batch size, num_tx, num_tx_ant, num_rx, num_rx_ant, num_paths, num_time_steps]`.\n\n3. Initialize your channel model. If you're using the `sn.channel.OTAWGNChannel` model, for example, you can initialize it with the required parameters like this: `channel_model = sn.channel.OTAWGNChannel(cir=(your_cir))`.\n\n4. Generate your batch of frequency responses. If you're using the `sn.channel.CIRDataset` model, you can generate a batch of frequency responses with: \n```python\n    iterator = iter(CIRDataset(cir, batch_size))\n    a, tau = next(iterator)\n    h_freq = cir_to_ofdm_channel(frequencies, a, tau)\n``` \nIn this snippet, `batch_size` would be the number of examples you defined in step 1, and `cir` would be the CIR profiles. The `cir_to_ofdm_channel` function is used to compute the Fourier transform of the continuous-time channel impulse response at a set of frequencies, which corresponds to the different subcarriers.\n\n5. `h_freq` now holds the batch of frequency responses. You can use these frequency responses in your processing. \n\nPlease note that the actual code may vary depending on the specific setup and the functions being used. The steps outlined above are based on the context provided in the original."
"To configure transmitters and receivers for computing propagation paths in Sjsonna RT, you can follow a few key steps as shown in the provided context.\n\nFirstly, set up your antenna arrays for your transmitters and receivers. This can be done using the `PlanarArray` class for creating an antenna array as shown in the code below:\n\n```python\nscene.tx_array = PlanarArray(num_rows=8, \n                             num_cols=2, \n                             vertical_spacing=0.7, \n                             horizontal_spacing=0.5, \n                             pattern=\"tr38901\", \n                             polarization=\"VH\")\n```\n\nIn this code, `scene.tx_array` sets up the antenna array, `PlanarArray` is used to create the antenna array for all transmitters, `num_rows` specifies the number of rows in the array, `num_cols` specifies the number of columns, `vertical_spacing` specifies the vertical spacing between antennas, `horizontal_spacing` specifies the horizontal spacing between the antennas, `pattern` specifies the pattern of the antenna, and `polarization` specifies the type of polarization which in this case is \"VH\" i.e., vertical polarization.\n\nAfter setting up the transmission array, you will then create a transmitter. An instance of `Transmitter` class is created below:\n\n```python\ntx = Transmitter(name=\"tx\", \n                 position=[8.5,21,27], \n                 orientation=[0,0,0])\n```\n\nIn this setup, `name` is the name of the transmitter, `position` specifies the position in 3D space (x,y,z), and `orientation` specifies the orientation in space (3 angles corresponding to roll, yaw, and pitch).\n\nConfiguration for the receivers is also similar. Firstly, set up the antenna array for the receivers using `PlanarArray` as shown in the code below:\n\n```python\nscene.rx_array = PlanarArray(num_rows=1, \n                             num_cols=1, \n                             vertical_spacing=0.5, \n                             horizontal_spacing=0.5, \n                             pattern=\"dipole\", \n                             polarization=\"cross\")\n```\n\nIn this code, `scene.rx_array` sets up the antenna array for all receivers, `PlanarArray` is used to create the antenna array for the scene, and other parameters are the same as for the transmitter array.\n\nAfter setting up the receiver array, you can create a receiver. An instance of `Receiver` is created as shown below:\n\n```python\nrx = Receiver(name=\"rx\", \n               position=[45,90,1.5], \n               orientation=[0,0,0])\n```\n\nIn this setup, `name` is the name of the receiver, `position` specifies the position in 3D space (x,y,z), and `orientation` specifies the orientation in space. \n\nFinally, add the configured transmitter and receiver to the scene:\n\n```python\nscene.add(tx)\nscene.add(rx)\n```\n\nThe above steps will configure the transmitters and receivers for computing propagation paths in Sionna RT."
"class SymbolDemapperWithPrior:\n    Deprecated use of this class.\n    It has been integrated to SymbolDemapper. Please refer to the documentation of SymbolDemapper for the current implementation. \n\n```python\nclass SymbolDemapperWithPrior(SymbolDemapper):\n    \n    def __init__(constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs):\n        super().__init__(constellation_type=constellation_type, num_bits_per_symbol=num_bits_per_symbol, constellation=constellation, hard_out=hard_out, with_prior=True, dtype=dtype, **kwargs)\n        \n        with tf.name_scope(\"Sionna_SymbolDemapperWithPrior\"):\n            self._rd = Prior2LL(constellation_type, num_bits_per_symbol, dtype=dtype)\n    \n    def call(self, inputs):\n        y, prior, no = inputs\n        ll = self._rd([y, prior, no])\n        if self.hard_out:\n            return tf.cast(tf.argmax(ll, -1, output_type=tf.int32), dtype)\n        else:\n            return tf.nn.log_softmax(ll, -1)\n```"
"To enable diffuse reflections and observe their impact on the coverage map, you can follow these steps:\n\n1. Load the scene: Use the `load_scene` function from the `sionna.rt` module to load a scene. For example, you can load a scene with multiple buildings using the `load_scene` function with an appropriate file path as the argument.\n\n2. Configure the Radio Materials: The radio materials determine the behavior of radio waves when they interact with objects in the scene. You can configure the `diffuse_reflection_coefficient` and `specular_reflection_coefficient` for each material to control the amount of energy that is diffusely and specularly reflected. \n\n3. Inspect the Coverage Map: After loading the scene and configuring the radio materials, you can generate a coverage map using the `coverage_map` method of the scene object. This will compute the signal strength at numerous points on a specified plane. You can then use the `render` function of the scene object to render the scene from a camera's viewpoint, and overlay the coverage map for visualization.\n\n4. Enable Diffuse Reflections: To enable diffuse reflections, you can set the `diffuse_reflection` parameter of the scene object to `True`. This ensures that every point on an object is also illuminated by a ray that is diffuse reflected.\n\n5. Inspect the Coverage Map Again: After enabling diffuse reflections, regenerate the coverage map and inspect its impact. You should see an increase in the signal strength at certain points due to the additional energy from diffuse reflections.\n\n6. Other Considerations: Keep in mind that enabling diffuse reflections can significantly increase the computational cost of rendering the scene, especially if there are many reflection paths. You may also need to increase the number of samples used for the coverage map computation to get accurate results.\n\nHere is a sample code snippet that demonstrates these steps:\n\n```python\n# Load the scene\nscene = load_scene(sionna.rt.scene.simple_street_canyon_with_diffuse_reflections)\n\n# Inspect the radio materials\nscene.radio_materials[0].name = \"my_radio_material\"\nprint(\"Radio material: \", scene.radio_materials[0])\nscene.my_radio_material.diffuse_reflection_coefficient = 0.3\nscene.my_radio_material.specular_reflection_coefficient = 0.7\n\n# Generate a coverage map\ncm = scene.coverage_map(cm_cell_size=[0.5,0.5], num_samples=10e6)\n\n# Inspect the coverage map\nscene.render(coverage_map=cm)\n\n# Enable diffuse reflections\nscene.diffuse_reflection = True\n\n# Regenerate the coverage map\ncm = scene.coverage_map(cm_cell_size=[0.5,0.5], num_samples=10e6)\n\n# Inspect the coverage map again\nscene.render(coverage_map=cm)\n```\n\nThis code will print the details of the radio material, generate a coverage map with and without diffuse reflections, and then render the scene with the coverage map for visualization."
"To compute the Mean Squared Error (MSE) between the transmitted and recovered symbols, you can follow these steps:\n\n1. First, you need to have the transmitted symbols (`x`) and the recovered symbols (`x_hat`). In the given context, the transmitted symbols are computed using a mapper (QAMMapper in this case), and the received (recovered) symbols are computed using a corresponding mapper (QAMMapper with the \"x_hat\" parameter).\n\n2. Next, subtract the transmitted symbols from the recovered symbols to get the error vector. This is done by performing `x - x_hat`.\n\n3. After you have the error vector, you can square each element of the vector to get the squared error. This is done by computing `e^2` where `e` is the error vector.\n\n4. Finally, you can compute the MSE by taking the mean of all the squared errors. This is done by calculating `E[e^2]`, where `E` denotes the mean operation.\n\nIn the provided context, the MSE is computed in the following lines of code:\n\n```python\ns = tf.reduce_mean(tf.square(x - x_hat))\nno_eff = tf.reduce_mean(tf.square(no)) * num_tx * 2\nno = tf.cast(no, x.dtype)\nno_eff = tf.cast(no_eff, x.dtype)\n```\n\nHere, `x` and `x_hat` are the transmitted and recovered symbol tensors respectively, `no` is the noise variance, `num_tx` is the number of transmitters, `2` accounts for in-phase and quadrature components in the QAM constellation, `tf.reduce_mean()` calculates the mean of all the squared errors, and `tf.square()` is used to square the absolute value of the error vector. Note that the symbols have to be in tensor form for these operations, and the 'transmitted symbol indices' and 'received soft-symbols' are computed using a 'SymbolDemapper' in the given context."
"The 'create_or_check_constellation' method in the 'Constellation' class is used to ensure that an existing constellation object is consistent with the requested settings or to create a new one if it doesn't exist. This is particularly useful because it avoids the need for multiple if-else checks in the calling code to handle constellation object creation and verification.\n\nThe method can be used as follows:\n\n```python\nconst = sn.mapping.Constellation.create_or_check_constellation(\n     constellation_type=\"qam\",\n     num_bits_per_symbol=constellation_size\n)\nconstellation_object = sn.mapping.Constellation(constellation=const)\n```\n\nIn the example above, 'create_or_check_constellation' is called with the constellation_type set to \"qam\" (Quadrature Amplitude Modulation) and num_bits_per_symbol which is the constellation size. If an explicit constellation object ('constellation') is to be used, the method can check if it is consistent with the requested settings. If not, it will raise an error. If no explicit constellation is given or if it is set to None, the method will create a new constellation object of type 'qam' with the specified number of bits per symbol.\n\nThe 'create_or_check_constellation' method is static, ensuring that it does not modify the state of the 'Constellation' class and can be called with the same arguments across different parts of the code without leading to potential side-effects. \n\nWhen the program runs, if 'create_or_check_constellation' finds an existing constellation object that matches the requested settings, it will return that. Otherwise, it will create a new constellation object as per the requested settings, thereby ensuring that the constellation object is always available for use in the program. This is helpful in scenarios like simulations where a consistent and predefined constellation pattern is needed across different parts of the code. \n\nIn conclusion, the 'create_or_check_constellation' method is a robust utility in the 'Constellation' class that ensures the reusability and reliability of a constellation object. It exemplifies good software design principles of modularity, reusability and reliability."
"The `scat_keep_prob` argument in the ray tracing process plays a crucial role in controlling the number of scattered paths during the ray tracing process. This argument is not shown in the provided context, but the explanation pertains to a feature of the 'Sionna RT' Ray Tracing module, a part of the wireless propagation modeling framework. \n\nThe `scat_keep_prob` argument is used when computing scattered paths in wireless propagation modeling. When a ray is 'scattered', it means that instead of propagating the signal to the receiver following a line-of-sight, the ray will propagate the signal by reflecting it on a surface (like a mirror reflection) or by scattering it into the environment (like a diffuse reflection). \n\nThe `scat_keep_prob` is a probability, set as a fraction between 0 and 1, that is used to control the number of scattered paths. The total number of scattered paths is controlled by shooting multiple rays from the transmitter. For each scattered ray, the `scat_keep_prob` determines with which probability the ray is discarded (i.e., not propagated any further). This can be used to manage the computational complexity of the propagation modeling process; by adjusting the value of `scat_keep_prob`, the number of scattered paths and, consequently, the number of rays that need to be traced can be reduced.\n\nA higher `scat_keep_prob` means that more rays will be considered and, therefore, more paths will be simulated, leading to a more comprehensive propagation modeling. On the other hand, setting `scat_keep_prob` to a lower value can significantly reduce the computational complexity and the amount of computation needed while still providing a reasonable approximation of the propagation environment."
"Here is the detailed information of it:   \n  \n[sionna.rt.r_hat(phi, theta)](https://nvlabs.github.io/sionna/_modules/sionna/rt/utils.html#r_hat)\n\nComputes the 3D unit vector $\\hat{\\mathbf{r}}=(\\sin{\\phi}\\cos{\\theta}, \\sin{\\phi}\\sin{\\theta}, \\cos{\\phi})$ from spherical angles $\\phi$ and $\\theta$.\n\n**Input**\n\n- `phi` (or `x`, [rad]): Zenith angle wrapped within $[0,2\\pi]$. Can be an array of any shape.\n- `theta` (or `y`, [rad]): Azimuth angle. Can be an array of any shape.\n\n**Output**\n\n- `r_hat` ([3], or, n, 3]): Array containing the unit vectors. If `phi` and `theta` are not (or not entirely) scalar, the shape of `r_hat` will be [n, 3], where n is the number of elements in `phi` and `theta`.\n\nsource code:\n```python\ndef r_hat(phi, theta):\n    r\"\"\"\n    Computes the 3D unit vector\n    :math:`\\hat{\\mathbf{r}}=(\\sin{\\phi}\\cos{\\theta}, \\sin{\\phi}\\sin{\\theta},\n    \\cos{\\phi})`\n    from spherical angles :math:`\\phi` and :math:`\\theta`.\n\n    Input\n    --------\n    phi : or `x`[,],  or an arbitrary array (>0) of angles wrapped within [0,pi] [rad]\n        Zenith angle\n\n    theta : or `y`[,],  or an arbitrary array of angles [0,2pi] [rad]\n        Azimuth angle\n\n    Output\n    --------\n    r_hat : [,3],  or, `[...,3]`, 3D unit vector.\n      If ``phi`` and ``theta`` are not (or not entirely) scalar, the shape of\n      ``r_hat`` will be ``[n, 3]``, where ``n`` is the number of elements in\n      ``phi`` and ``theta``.\n    \"\"\"\n\n    if not ((0 <= phi).all() and (phi <= PI)).all():\n        msg = \"Zenith angle must be within [0, PI] for all positions\"\n        raise ValueError(msg)\n\n    if not ((0 <= theta).all() and (theta <= 2*PI)).all():\n        msg = \"Azimuth angle must be within [0, 2*PI] for all positions\"\n        raise ValueError(msg)\n\n    if (phi>PI).any():\n        x = sin(phi)\n        x = expand_to_rank(x, theta.ndim, 0)\n        x *= sin(theta)\n        r_hat = stack([x, cos(phi), zeros_like(x)], axis=-1)\n        r_hat = normalize(r_hat)\n    else:\n        r_hat = stack([sin(phi)*cos(theta), sin(phi)*sin(theta), cos(phi)])\n        r_hat = move_to_end(r_hat, r_hat.ndim-1)\n\n    return r_hat\n```"
"The detailed information of OFDMDetectorWithPrior is as follows:   \n  \n[sionna.ofdm.OFDMDetectorWithPrior(detector, output, resource_grid, stream_management, constellation_type, num_bits_per_symbol, constellation, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#OFDMDetectorWithPrior)  \n\nWraps a MIMO detector that assumes prior knowledge of the bits or constellation points is available, for use with the OFDM waveform.\n\nThe parameter detector is a callable (e.g., a function) that implements a MIMO detection algorithm with prior for arbitrary batch dimensions. It either existing detectors MaximumLikelihoodDetectorWithPrior or ExpectationMaximizationDetectorWithPrior can be used, or a custom detector callable provided that has the same input/output specification.\n\nThis class pre-processes the received resource grid y, channel estimate h_hat, and the prior information prior, and computes for each receiver the noise-plus-interference covariance matrix according to the OFDM and stream configuration provided by the resource_grid and stream_management, which also accounts for the channel estimation error variance err_var. These quantities serve as input to the detection algorithm that is implemented by the callable detector. Both detection of symbols or bits with either soft- or hard-decisions are supported.\n\n**Note**\nThe callable detector must take as input a tuple $(\\mathbf{y}, \\mathbf{h}, \\mathbf{prior}, \\mathbf{s})$ such that:\n\n- y ([,num_rx], or [,num_rx, num_streams] tf.complex) \u2014 1D or 2D tensor containing the received signals.\n- h ([,num_rx, num_tx], or [,num_rx, num_streams, num_tx] tf.complex) \u2014 2D or 3D tensor containing the channel matrices.\n- prior ([,num_tx, num_streams, num_data_symbols x num_bits_per_symbol] or [,num_tx, num_streams, num_data_symbols, num_points] tf.float) \u2014 Prior of the transmitted signals. If output equals \"bit\", then LLRs for the transmitted bits are expected. If output equals \"symbol\", then logits for the transmitted constellation points are expected.\n- s ([,num_rx, num_rx] or [,num_rx, num_rx, num_streams] tf.complex) \u2014 2D or 3D tensor containing the noise-plus-interference covariance matrix.\n\nIt must generate one of the following outputs depending on the value of output:\n\n- b_hat ([, num_streams, num_data_symbols * num_bits_per_symbol] tf.float) \u2014 LLRs or hard-decisions for every bit of every stream, if output equals \"bit\".\n- s ([, num_streams, num_data_symbols, num_points] tf.float) or ([, num_streams, num_data_symbols, num_points], tf.int) \u2014 Logits or hard-decisions for constellation symbols for every stream, if output equals \"symbol\". Hard-decisions correspond to the symbol indices.\n\n**Example**\nThe following code snippet shows how to use this class as a layer in a Keras model:\n```python\nmodel = OFDMChannelEstimationLS(rg)\n# Instantiate a MIMO detector with prior for the ZF detection\nwith_prior = OFDMDetectorWithPrior(sionna.mimo.MaximumLikelihoodDetectorWithPrior(\"bit\"),\n                                   \"bit\",\n                                   rg,\n                                   sm)\n# The layers of the model are:\nestimates = model(x)\ny_hat = channel_correction(rg, x, estimates, no) \nz = with_prior([y_hat, no]) \n```\nWhere x is the input symbol tensor, rg is a ResourceGrid instance, and sm a StreamManagement instance. The callable detector takes as input a tuple $(y, h, prior)$ such as the one expected by this class. The channel-corrected data is then fed as input to the detector.\n\n**Parameters**\n\n- `detector` (Callable): Callable object (e.g., a function) that implements a MIMO detection algorithm with prior for arbitrary batch dimensions. Either the existing detector MaximumLikelihoodDetectorWithPrior or ExpectationMaximizationDetectorWithPrior can be used, or a custom detector callable provided that has the same input/output specification.\n- `output` (One of [\"bit\", \"symbol\"], str): Type of output, either LLRs of bits or logits of constellation symbols.\n- `resource_grid` (sionna.ofdm.ResourceGrid): Instance of ResourceGrid.\n- `stream_management` (sionna.mimo.StreamManagement): Instance of StreamManagement.\n- `constellation_type` (One of [\"qam\", \"pam\", \"custom\"], str): For custom, an instance of Constellation must be provided.\n- `num_bits_per_symbol` (int): Number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation types [\"qam\", \"pam\"].\n- `constellation` (sionna.mapping.Constellation): Instance of Constellation, or None. In the latter case, both constellation_type and num_bits_per_symbol must be specified.\n- `dtype` (One of [tf.complex64, tf.complex128], tf.DType): The dtype of `y`. Defaults to tf.complex64. The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n**Input**\n\n- `y` ([batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex or [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, num_streams_per_rx], tf.complex): 2+D Tensor containing the received signals.\n- `h` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex):  Tensor containing the channel matrices.\n- `prior` ([batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol] or [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float): Priors of the transmitted signals. Expected to be given as LLRs if output equals \"bit\", or logits of the constellation points if output equals \"symbol\".\n- `err_var` (Broadcastable to the shape of `h` [, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.float): Tensor containing the channel estimation error variance.\n- `no` ([batch_size, num_rx, num_rx_ant] or the first n dimensions of this, tf.float): Tensor containing the noise variance estimate. Must be broadcastable to the shape of y.\n\n**Output**\n\n- One of:\n    - `b_hat` ([batch_size, num_tx, num_streams, num_data_symbols * num_bits_per_symbol], tf.float): LLRs or hard-decisions for every bit of every stream, if `output` equals \"bit\".\n    - `x_hat` ([batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int): Logits or hard-decisions for constellation symbols for every stream, if `output` equals \"symbol\". Hard-decisions correspond to the symbol indices."
"Here is the detailed information of GaussianPriorSource:   \n  \n[sionna.channel.GaussianPriorSource(min_var, max_var, num_bits_per_symbol, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/channel/utils.html#GaussianPriorSource)  \n  \nSource generating complex AWGN with a trainable variance\n\nThis class acts as a layer defining a Gaussian prior source. The real and imaginary parts of the generated symbols are each whitened with unit variance. The total variance of the generated symbols can be assigned to trainable variable.  \n  \n### Parameters\n\n- **min_var** (`float`):  \nMinimum initial value for the per-symbol variance.\n\n- **max_var** (`float`):  \nMaximum initial value for the per-symbol variance.\n\n- **num_bits_per_symbol** (`int`):  \nNumber of bits per QAM constellation symbol. E.g., num_bits_per_symbol=4 corresponds to QAM16.\n\n- **dtype** (TensorFlow `DType`):  \nThe data type for the output. Both the real and imaginary parts are of this data type. Defaults to `tf.complex64`.\n\n### Input\n\n- **shape** (`TensorShape`):  \nShape of the output symbols to generate. Only the last dimension is used and must be (or can be) of size `num_symbols`.\n\n### Output\n\n- **symbols** (`tf.complex`):  \nTensor of complex Gaussian noise symbols, of shape `shape`.\n\n### Property\n\n- **var**  \nThe total (trainable) symbol variance.  \n  "
"Here is the detailed information of [sionna.mapping.QAM2PAM(num_bits_per_symbol)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#QAM2PAM):  \n  \nTransforms QAM symbol indices to PAM symbol indices.  \nFor indices in a QAM constellation, computes the corresponding indices for the two PAM constellations corresponding the real and imaginary components of the QAM constellation.  \n  \n**Parameters**\n\n- `num_bits_per_symbol` (int): The number of bits per QAM constellation symbol, e.g., 4 for QAM16.\n\n**Input**\n\n- `ind_qam` (Tensor, tf.int): Indices in the QAM constellation\n\n**Output**\n\n- `ind_pam1` (Tensor, tf.int): Indices for the first component of the corresponding PAM modulation\n- `ind_pam2` (Tensor, tf.int): Indices for the first component of the corresponding PAM modulation  \n  "
"To load the required Sionna components as per the provided context, you can follow the steps outlined below:\n\n1. First, ensure that the Sionna package is installed in your current environment. If it's not installed, you can install it using pip:\n\n```python\npip install sionna\n```\n\n2. After installing the package, you can import the necessary components in Python using the `from` keyword in the import statement. For instance, to import the `load_scene` function from the `sionna.rt.scene` module, you can use the following statement:\n\n```python\nfrom sionna.rt.scene import load_scene\n```\n\n3. Once the required components are imported, you can use them according to the provided context. For loading a scene, you can call the `load_scene` function with an integrated scene as an argument. For instance, to load the \"etoile\" scene, you can use the following statement:\n\n```python\nscene = load_scene(sionna.rt.scene.etoile)\n```\n\nPlease note that the actual Sionna components you might need to load could vary depending on your specific use case. The context provides an example with the use of `load_scene` function and an integrated scene preview. Depending on your needs, you might have to import other components like `Scene`, `PlanarArray`, `Transmitter`, or `Receiver` from `sionna.rt` package to create and add elements to the scene."
"To use Sionna's API and configure the GPU, you should follow these steps:\n\n1. Import the necessary modules for Sionna's API:\n\n```python\nfrom sionna.rt import load_scene\nfrom sionna.rt import PlanarArray\nfrom sionna.rt import Transmitter\nfrom sionna.rt import Receiver\nfrom sionna.rt import RadioMaterial\nfrom sionna.rt import Camera\nfrom sionna.rt import LambertianPattern\nfrom sionna.rt import DirectivePattern\nfrom sionna.rt import BackscatteringPattern\n```\n\n2. Import the required time-channel functions from Sionna's API:\n\n```python\nfrom sionna.channel import cir_to_time_channel\nfrom sionna.channel import CIR\n```\n\n3. Configure the GPU settings. First, you need to specify which GPU to use. If you want to use the CPU, set `gpu_num` to an empty string. \n\n```python\nimport os\ngpu_num = 0  # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n```\n\nNext, you need to set the TensorFlow logging level to 'ERROR' to avoid warnings:\n\n```python\nimport tensorflow as tf\ntf.get_logger().setLevel('ERROR')\n```\n\n4. To avoid warnings from TensorFlow, set the global random seed for reproducibility:\n\n```python\ntf.random.set_seed(1)  # Set global random seed for reproducibility\n```\n\n5. To ensure that TensorFlow uses only a single GPU and allocates only as much memory as needed, you can list and use the physical devices available for TensorFlow:\n\n```python\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\n\n6. Finally, you can set the TensorFlow logger level to 'ERROR' to avoid warnings:\n\n```python\ntf.get_logger().setLevel('ERROR')  # Avoid warnings from TensorFlow\n```\n\nThis setup will allow you to use Sionna's API and configure the GPU as needed."
"An 'CoverageMap' component in the ray tracing context of Sionna refers to the representation of the power delay profile, which describes how the signal strength at a receiver changes over time. This is caused by multiple paths the signal may take from the transmitter to the receiver, such as direct line-of-sight, reflection, and scattering.\n\nThe 'CoverageMap' component is essentially a map that covers a specific area or surface and contains measurements of the signal strength (or power) at different points in this area, taken from various angles and positions. This map provides a detailed view of how the signal propagation is affected by the environment it moves through. For example, the signal strength may be stronger in some areas due to factors like direct line-of-sight with the transmitter, while it may be weaker in other areas due to phenomena like signal reflection or absorption.\n\nThis CoverageMap component forms the basis of other important components in Sionna, such as 'ResourceGrid', which is a grid that is laid over the area covered by the coverage map. This grid is used for mapping OFDM symbols onto the ray tracing environment for further analysis, such as determining the channel impulse response."
"To decode a set of log-likelihood ratio (LLR) values using the TurboDecoder in the given context, the input requirements and the output format for both hard and soft decisions are as follows:\n\nInput Requirements for Hard Decisions:\nFor a hard decision decoding, the input LLR values are expected to be a tensor (list of at least one tf.float32 (or tf.float16) tensor) containing the channel LLRs. The shape of the last dimension should be rate * n, where n is the codeword length and rate is the parameter used for the number of parity bits per information bit (e.g., rate=1/3).\n\nInput LLR Hard Decision Example:\n```\ninput_llrs = [tf.random.uniform((batch_size, n), minval=-20, maxval=20, dtype=tf.float32)]\n```\n\nInput Requirements for Soft Decisions:\nFor soft decision decoding, the absolute values of the input LLR are decoded, and additional sign information can also be provided. The input to the decoder must be a tuple that includes the LLR tensor and a boolean indicating whether the signs are being considered. The LLR tensor can either be a list of at least one tf.float32 (or tf.float16) tensor or a single tf.float32 tensor with at least rank two. The last dimension of the tensor must be rate * n. The sign tensor has the same shape as the LLR tensor, and its dtype is tf.float32 (or tf.float16). The sign information is assumed to be +1 for positive LLR values and -1 for negative LLR values.\n\nInput LLR Soft Decision Example:\n```\nllrs = tf.random.uniform((batch_size, n), minval=0, maxval=20, dtype=tf.float32)\nsigns = tf.sign(llrs)\nllrs = tf.abs(llrs)\ninput_llrs_soft = [llrs, signs]\n```\n\nOutput Format:\nThe output of the TurboDecoder is a hard decided codeword of length n, and (if Termination is True) a hard decided information bit vector of length k. Additionally, it outputs an estimate of the a-priori LLR, which is equivalent to providing the (unreversed) estimate of the product of the corresponding CRC parity-check matrix and the all-zero codeword. If `return_apr` is True, the estimated a-priori LLRs are returned, otherwise, `None`.\n\nOutput for Hard Decisions:\nThe output for hard decisions is a tf.int32 tensor of shape `[batch_size, n]`, which provides the hard decided codeword bits.\n\nOutput for Soft Decisions:\nThe output for soft decisions is a tf.float32 tensor of shape `[batch_size, n]`, which provides the soft decision values (i.e., the reliability of each bit).\n\nOutput of Hard/Soft Decisions Together:\nThe output includes the tensors `output_codeword` and (if `terminate` is True) `output_info_bits`. It provides the hard decided codeword (output_codeword) and the estimated a-priori LLRs (output_apr). This can be interpreted as outputting the LLRs directly, or returning the unreliable (a-priori) estimates of the information bits if `terminate` is True.\n\nOutput of Termination:\nIf `terminate` is True, an additional output is terminated `turbocode_crc`.\n\nThis response is based on the assumption that the `TurboDecoder` is instantiated from the Sionna package as follows:\n\n```python\ndecoder = TurboDecoder(encoder=turbo_encoder, \n                       n=num_iter, \n                       terminate=True, \n                       output=dec_output, \n                       hard_out=True)  # hard_decisions=True for returning hard decoded codeword\n```"
"Here is the detailed information of this function:\n  \n[sionna.rt.antenna.iso_pattern(theta, phi, slant_angle=0.0, polarization_model=2, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/rt/antenna.html#iso_pattern)\n\nIsotropic antenna pattern with linear polarizarion\n\n**Input**\n\n- `theta` (*array_like*, float): Zenith angles wrapped within $[0, \\pi]$ [rad]\n- `phi` (*array_like*, float): Azimuth angles wrapped within $[-\\pi, \\pi)$ [rad]\n- `slant_angle` (float): Slant angle of the linear polarization [rad]. A slant angle of zero means vertical polarization. Defaults to 0.\n- `polarization_model` (int, one of [1,2]): Polarization model to be used. Options 1 and 2 refer to [polarization_model_1()](https://nvlabs.github.io/sionna/_modules/sionna/rt/antenna.html#polarization_model_1) and [polarization_model_2()](https://nvlabs.github.io/sionna/_modules/sionna/rt/antenna.html#polarization_model_2), respectively. Defaults to 2.\n- `dtype` (tf.complex64 or tf.complex128): Datatype. Defaults to tf.complex64.\n\n**Output**\n\n- `c_theta` (*array_like*, complex): Zenith pattern\n- `c_phi` (*array_like*, complex): Azimuth pattern\n\nsource code:\n```python\ndef iso_pattern(theta, phi, slant_angle=0.0,\n                polarization_model=2, dtype=tf.complex64):\n    r\"\"\"\n    Isotropic antenna pattern with linear polarizarion\n\n    Input\n    -----\n    theta : array_like, float\n        Zenith angles wrapped within [0,pi] [rad]\n\n    phi : array_like, float\n        Azimuth angles wrapped within [-pi, pi) [rad]\n\n    slant_angle : float\n        Slant angle of the linear polarization [rad].\n        A slant angle of zero means vertical polarization.\n        Defaults to 0.\n\n    polarization_model : int, one of [1,2]\n        Polarization model to be used. Options `1` and `2` are refer to\n        :func:`~sionna.rt.antenna.polarization_model_1` and\n        :func:`~sionna.rt.antenna.polarization_model_2`,\n        respectively. Defaults to `2`.\n\n    dtype : tf.complex64 or tf.complex128\n        Datatype. Defaults to `tf.complex64`.\n\n    Output\n    ------\n    c_theta : array_like, complex\n        Zenith pattern\n\n    c_phi : array_like, complex\n        Azimuth pattern\n    \"\"\"\n    k = tf.constant(1.0, dtype=dtype.real_dtype)\n    one = tf.constant(1.0, dtype=dtype.real_dtype)\n    sqrt2 =  tf.constant(np.sqrt(2), dtype=dtype.real_dtype)\n    theta = tf.cast(theta, dtype=dtype.real_dtype)\n    phi = tf.cast(phi, dtype=dtype.real_dtype)\n    st = tf.cast(slant_angle, dtype=dtype.real_dtype)\n    if dtype.is_complex:\n        rdtype = dtype.real_dtype\n        cdtype = dtype\n        dtype = rdtype\n\n    # Check which polarization model to use\n    if polarization_model==1:\n        c = tf.complex(tf.sqrt(0.5), tf.exp(1j*phi)*tf.sin(theta*st))\n    elif polarization_model==2:\n        c = tf.complex(\n                tf.exp(1j*phi)*tf.sin(theta) * (\n                    (tf.sqrt(1/tf.math.cos(theta**2))\n                                               + tf.sqrt(tf.math.cos(theta**2))\n                                               ) * sqrt2/2\n                ),\n                tf.exp(1j*phi)*tf.sin(theta) * (\n                    (tf.sqrt(1/tf.math.cos(theta**2))\n                                               - tf.sqrt(tf.math.cos(theta**2))\n                                               ) * sqrt2/2\n                )\n    else:\n        raise ValueError(\"Unknown polarization_model\")\n\n    # Normalize by total power\n    # (1/2 is result from int_0^PI sin^2(theta) d(theta))\n    c = tf.complex(c, tf.constant(0., dtype=dtype.real_dtype))\n    norm = tf.cast(1/2 * tf.math.reduce_mean(tf.square(tf.abs(c))), cdtype)\n    c /= tf.cast(tf.sqrt(norm), cdtype)\n\n    # Division by r is due to the r^2 increase of the isotropic\n    # radiance with the distance\n    r_hat = utils.spherical_to_cartesian(theta, phi)\n    d = tf.cast(1, dtype=dtype.real_dtype) # Distance (set to one)\n    rr = tf.cast( (d/(4*PI))**2, dtype=dtype.real_dtype)\n    c_rr = tf.complex(rr, tf.constant(0., dtype=dtype.real_dtype))\n    one_ = tf.cast(1, dtype=dtype.real_dtype)\n    # Antenna pattern is rotation-invariant --> rotate r_hat so that theta\n    # can be used as input for the provided patterns\n    r_hat_theta_phi = utils.rotate_to_zenith(r_hat)\n    theta = r_hat_theta_phi[1]\n    phi   = r_hat_theta_phi[2]\n    r_hat_z = tf.complex(tf.constant(0., dtype=dtype.real_dtype),\n                            -tf.math.cos(theta)*tf.math.sin(phi))\n    r_hat_x = tf.complex(\n                tf.math.sin(theta)*tf.math.cos(phi),\n                tf.math.sin(theta)*tf.math.sin(phi)\n            )\n    # Compute theta and phi for the rotated system\n    # r_hat =  (x r_hat_x + z r_hat_z)  (r r_hat_rr)\n    r_hat_theta_phi = tf.einsum(\"i,ij->ij\", tf.math.real(r_hat_x),\n                                tf.math.real(r_hat_x)) + \\\n                    tf.einsum(\"i,ij->ij\", tf.math.real(r_hat_z),\n                                tf.math.real(r_hat_z))\n    r_hat_theta_phi /= tf.math.real(\n                        tf.cast(1, dtype=dtype.real_dtype) - rr)\n    r_hat_theta_phi = tf.where(\n                        r_hat_theta_phi==one,\n                        tf.cast(0, dtype=dtype.real_dtype),\n                        r_hat_theta_phi)\n    theta = tf.math.acos(r_hat_theta_phi)\n    r_hat_phi  = tf.complex(\n                -tf.math.sin(theta)*tf.math.cos(phi),\n                tf.math.sin(theta)*tf.math.sin(phi)\n            )\n    # Remove nans introduced by 0/0 for the zenith\n    r_hat_phi = tf.where( tf.math.is_nan(r_hat_phi), theta, r_hat_phi)\n\n    # Antenna patterns for the rotated system\n    c_theta = _theta0(theta, k) * _theta1(theta, k) * c\n    c_phi   = _theta0(theta, k) * _phi(theta, phi, k)\n    r_hat_dot_e_r = tf.cast(1, dtype=dtype.real_dtype) # r^2=1 at thejson doc end\n\n\n\n    # (1)  Go from r_hat to the SH (theta, phi)\n    # r_hat_r  : r_hat vector in cartesian coordinate that can\n    #           be used with the rotation matrix\n    #           The rotation matrix rotates everything so that\n    #           z' = r_hat and (x', y') lies in the x-y plane.\n    #           r_hat_vector is r in spherical coordinates.\n    # See Eq. (4.48)\n    r_hat_r = tf.complex(\n                tf.cast(0,dtype.real_dtype),\n                r_hat_z)\n    # Rotate r_hat_vector to r_vector in spherical coordinates\n    # and quaternion for the rotation\n    theta_tilde, phi_tilde, _  = utils.cartesian_to_spherical_vectors(\n                                                            r_hat_x, r_hat_y, r_hat_z)\n    sq = utils.orthongonal_rotation_quntz(theta, theta_tilde, phi, phi_tilde)\n    r_vector_spherical = utils.q_times_vector_times_q_conj(sq, r_hat_vector)\n    # The following rotation ensures that r_vector_spherical is r'\n    # and (x',y')-plane\n    theta, phi, _  = utils.cartesian_to_spherical_vectors(  r_hat_x,\n                                                            r_hat_y,\n                                                            r_hat_z)\n    sq = utils.ry_rotation(theta) # Rotate to theta to r_y\n    r_prime = utils.q_times_vector_times_q_conj(\n                    sq,  r_vector_spherical) # Rotate to (x',y')-plane\n    # The following rotation ensures r_vector_spherical is r' and\n    # x'-axis\n    theta_p, phi_p, _ = utils.cartesian_to_spherical_vectors(  r_hat_x,\n                                                                r_hat_y,\n                                                                r_hat_z)\n    sp = utils.ry_rotation( theta_p, tf.cast(-1,dtype.real_dtype) )\n    r_prime_p = utils.q_times_vector_times_q_conj(\n                    sp,  r_prime) # Finally rotate to x'\n    # Definition of the spherical harmonic function\n    # r_hat : final coordiantes\n    #json doc r^2=1 at the\n    c_0 = 1/(4*PI)\n    y_00 = c_0*tf.complex(tf.sqrt(1/(4*PI)), tf.cast(0, dtype))\n    y_11 = c_0*tf.complex(tf.sqrt(3/(8*PI)), tf.sqrt(3/(4*PI)))\n    y_1m1 = c_0*tf.complex(tf.sqrt(3/(8*PI)), -tf.sqrt(3/(4*PI)))\n    c_1 = -2*tf.complex(tf.sqrt(15/(32*PI)), tf.cast(0, dtype))\n    y_22 = c_0*tf.complex(tf.sqrt(5/(8*PI)), tf.sqrt(5/(4*PI)))\n    y_2m2 = c_0*tf.complex(tf.sqrt(5/(8*PI)), -tf.sqrt(5/(4*PI)))\n\n    # (4.47)\n    p_0 = y_00(theta, phi)\n    p_1 = y_11(theta, phi)\n    p_1m1 = y_1m1(theta, phi)\n    p_2 = y_22(theta, phi)\n    p_2m2 = y_2m2(theta, phi)\n    if slant_angle == 0.0:\n        # (4.46)\n        return c_0*tf.complex(\n                        (r_hat_dot_e_r * tf.math.real(p_0) +\n                                        r_hat_dot_e_r * tf.math.real(p_1) ) ,\n                        (r_hat_dot_e_r * tf.math.imag(p_0) +\n                                        r_hat_dot_e_r * tf.math.imag(p_1) ) )\n\n    else:\n        # Vector of Jones feediction coefficients, e (Eq. 4.24)\n        # We only consider vertical polarization here.\n        # The polarization_model is not used as it is not clear how\n        # it should be used for non 0 slant angles.\n        e_v = tf.complex( tf.cast(0,dtype.real_dtype),\n                            tf.cos(PI/2*tf.cos(slant_angle)) )\n        return tf.complex(\n            tf.reduce_sum(   c_0*tf.math.real(e_v)*p_0) +\n            tf.reduce_sum(   c_1*tf.math.real(e_v)*p_1) +\n            tf.complex( tf.reduce_sum(  c_1*tf.math.real(e_v)*p_1m1), 0) +\n            tf.complex( tf.reduce_sum(  c_1*tf.math.imag(e_v)*p_2m2), 0) ,\n            tf.reduce_sum(   c_0*tf.math.imag(e_v)*p_0) +\n            tf.reduce_sum(   c_1*tf.math.imag(e_v)*p_1) +\n            tf.complex( tf.reduce_sum(  c_1*tf.math.imag(e_v)*p_1m1), 0) +\n            tf.complex( tf.reduce_sum(  c_1*tf.math.real(e_v)*p_2), 0) )\n```"
"We'll show how to use these Keras layers through an example using the context provided in the '3GPP 38.901 R15.3' for the ApplyTimeChannel layer and the 'Rayleigh Block Fading Channel' for the ApplyOFDMChannel layer.\n\nFirst, you have to set up the channel model and the input codeword as shown in the context. \n\nSince the code example provided in the context, regarding the 3GPP 38.901 R15.3, already includes the setup for a system level simulation, we will first reproduce that here. Afterwards, we will demonstrate the usage of the required components, i.e., the ApplyTimeChannel and ApplyOFDMChannel layers.\n\nLet's start by setting up the system, as in the '3GPP 38.901 R15.3' context, specifying simulated codeword length and index time domain symbols. This can be done directly by importing the necessary submodule:\n\n```python\nfrom sionna.mimo import StreamManagement\n# simulated parameters as in the 3GPP 38.901 R15.3 example\nnum_tx = 1\nnum_tx_ant = 4\nnum_rx = 2\nnum_rx_ant = 2\nnum_time_steps = 14\ncodeword_idx = 0\nn_cyclic_prefix = 0\nn_ofdm_symbols = 14\nfft_size = 12*14\ndata_per_ofdm_symbol = 1\n# Let's create a codeword to be transmitted. Here, we only mimic the zero codeword index to show the process.\n# (actual codeword transmission would need a non-zero codeword index)\nlength = int(data_per_ofdm_symbol * n_ofdm_symbols * num_time_steps)\nc = np.random.binomial(1, .5, size=(num_tx, length))\n# For StreamManagement, determine which entries of c get transmitted by which transmitter\nsm = StreamManagement(rx_tx_association)\nc_tx = sm(c, \"tx\")\n```\nIn the above code, the `StreamManagement` class is used to define which transmitter is sending which streams to which receiver. The variable `rx_tx_association` can be set up using the `StreamManagement.get_default_association()` method, as shown in the '3GPP 38.901 R15.3' context.\n\nNow, let's demonstrate how to use the `ApplyTimeChannel` and `ApplyOFDMChannel` layers.\n\n### ApplyTimeChannel:\n\nSetting up the time invariant channel and applying it (using the [TI-Channel](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.wireless.TI_Channel) class as an example):\n\n1. **Setup a channel model**: This can be based on the `GenerateTimeChannel` class, utilizing the setup for time-invariant channels.\n\n```python\nfrom sionna.channel import GenerateTimeChannel\nfrom sionna.channel import TI_Channel\n\n# Setup the channel model\ntime_channel = GenerateTimeChannel(channel_model = \"rayleigh\",\n                                    max_doppler = 5,\n                                    num_time_steps = 14)\nchannel_model = TI_Channel(time_channel = time_channel,\n                          space_channel = None,  # not needed for time invariance\n                          )\n```\nIn the above code, you should replace `\"rayleigh\"` with your channel model if it's different. You should also adjust `max_doppler` and `num_time_steps` according to your needs.\n\n2. **Apply the Channel**: Use the `ApplyTimeChannel` layer to apply the channel to the inputs.\n\n```python\n# Let's assume y and h are given. If the channel parameters were sampled by ApplyTimeChannel we could also use this function to apply the channel\nimport numpy as np\n# y is the channel output (observed symbol), here just some random complex values as an example\n# h is the time channel (homogenous over the duration of the OFDM symbol)\n\n# Create instance of the ApplyTimeChannel layer\napply_time_channel = ApplyTimeChannel()\n\n# Apply the channel to the input symbol and channel response\ny = apply_time_channel([c_tx[c], h_time[c]])\n\n# If the channel parameters were sampled by ApplyTimeChannel we could also use this function to apply the channel\n# (in that case we would not provide h)\n#   y = apply_time_channel([c_tx[c])\n```\nIn the above, you need to ensure that the inputs match the required shapes for the `ApplyTimeChannel` layer, as the channel_model is (presumably) sampling the channel to provide `y` and `h`.\n\n### ApplyOFDMChannel:\n\nUsing the same channel model as before, let's now demonstrate how to use the `ApplyOFDMChannel` layer. This is in the context of time-invariant frequency domain channels (the [TI-PF Channel](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.wireless.TI_Channel)).\n\n1. **Setup a channel model**: You can still utilize the `GenerateOFDMChannel` and `GenerateTimeChannel` classes, but now you also need to set up a frequency domain channel. This can be based on the `GenerateOFDMChannel` class or the `GenerateFrequencyChannel` utilising the same channel model setup as before, in addition to setting up a frequency domain channel (e.g., `GenerateFrequencyChannel`).\n\n```python\nfrom sionna.channel import GenerateOFDMChannel, GenerateFrequencyChannel\n# Assuming we have a channel model named 'channel_model' already defined\nfrequency_channel = GenerateFrequencyChannel(channel_model = \"ofdm\")\n```\nRemember to replace `\"rayleigh\"` with your actual channel model.\n\n2. **Apply the Channel**: Use the `ApplyOFDMChannel` layer to apply the channel to the channel inputs.\n\n```python\n# Let's assume x, n are given. If the channel output and additive white Gaussian noise (AWGN) were computed by the channel model we could also use this function to add AWGN\n# (also assuming 'no' is scalar, i.e., single-signal noise variance)\ne = np.random.normal(0, no, size=(num_rx, num_rx_ant, num_ofdm_symbols, fft_size))\n# Frequency domain channel\ny = apply_channel_f([x, n, e])\n```\nIn the above, you need to ensure that the inputs match the required shapes for the `ApplyOFDMChannel` layer, and ensure the definitions of `x`, `n`, and `no` match the expected channel input data.\n\nFor both the `ApplyTimeChannel` and `ApplyOFDMChannel` layers, if the channel parameters (including, for example, a tuple `(a, tau, phi)`) were first generated and then used to compute the channel output, you would need to pass them to the `ApplyTimeChannel` or `ApplyOFDMChannel` instantiation as `time_params` or `ofdm_params`, respectively. This is not demonstrated in the given context, but it's important to keep in mind when working with these layers in a real-world example."
"With the `Demapper` class in mind, the process to compute the Log-Likelihood Ratios (LLRs) is explained in the provided context. The computation of LLRs is approached differently depending on the method used (either \"app\" or \"maxlog\").\n\nFor both methods, the `with_prior` parameter is taken into account. If the `with_prior` parameter is set to `True`, it is assumed that prior knowledge on the bits is available. This prior information is given as LLRs as an additional input to the layer.\n\n1. **APPROX** method for computing LLRs:\n   \n   This is controlled by the `demapping_method`. With the \"approx\" method, the LLR for the $i\\\\text{th}$ bit is computed according to the following formula: \n\n     $$\n     \\text{LLR}(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert y,\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert y,\\mathbf{p}\\right)}\\right) =\\ln\\left(\\frac{\n        \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n        \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n        }{\n        \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n        \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n        }\\right)\n     $$\n\n     In the above formula, $\\mathcal{C}_{i,1}$ and $\\mathcal{C}_{i,0}$ are the sets of constellation points for which the $i\\\\text{th}$ bit is equal to 1 and 0, respectively. $\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]$ is the vector of LLRs that serves as prior knowledge on the $K$ bits that are mapped to a constellation point. It is set to $\\mathbf{0}$ if no prior knowledge is assumed to be available. $\\Pr(c\\lvert\\mathbf{p})$ is the prior probability on the constellation symbol $c$.\n\n2. **MAXLOG** method for computing LLRs:\n   \n   With the \"maxlog\" method, LLRs for the $i\\\\text{th}$ bit are approximated as:\n\n     $$\n     \\begin{align}\n         LLR(i) &\\approx\\ln\\left(\\frac{\\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(b_i=1\\lvert y,\\mathbf{p}\\right)\n            \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n            }{\n            \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(b_i=0\\lvert y,\\mathbf{p}\\right)\n            \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n            }\\right)\\\\\n            &=\\max_{c\\in\\mathcal{C}_{i,0}} \\left( \\ln\\left(\\Pr\\left(b_i=0\\lvert y,\\mathbf{p}\\right)\\right) -\\frac{|y-c|^2}{N_o} \\right) - \\max_{c\\in\\mathcal{C}_{i,1}} \\left( \\ln\\left( \\Pr\\left(b_i=1\\lvert y,\\mathbf{p}\\right) \\right) -\\frac{|y-c|^2}{N_o} \\right)\n        \\end{align}\n     $$\n\n     In this formula also, $\\mathcal{C}_{i,1}$ and $\\mathcal{C}_{i,0}$ are the sets of constellation points for which the $i\\\\text{th}$ bit is equal to 1 and 0, respectively, and $\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]$.\n\nIn both methods, it is recommended to have a vector of received symbols (`y`), the noise variance estimate `no`, optionally a vector of prior knowledge on the bits in the form of LLRs (`prior`), and a specification of the `constellation`, and `num_bits_per_symbol`. The `hard_out` parameter is optional and if set to `True`, the demapper provides hard-decided bits instead of soft-values."
"Obtaining the Channel Impulse Responses (CIRs) in the wireless channel model involves a multi-step process that leverages different components of the Sionna package. Below is the detailed process step by step:\n\n1. **Setup Environment**: The first step is to set up the environment. This includes initializing the GPU and importing necessary packages. A specific note is made to import the `sionna` package if it's not already installed, and the CLI command to install it if it's not already installed.\n\n2. **Model Configuration**: The next step is to configure the model. This involves setting parameters for the different components of the model. For example, in a MIMO (Multiple Input, Multiple Output) model, you would set parameters for the number of users, number of streams per user, noise covariance matrix, number of BS (Base Station) antennas, etc.\n\n3. **Setting the Channel Model**: After configuring the environment and the model, the next step is to set the channel model. This could be a TDL (Time Delay LIne-Of-Sight), CDL (Clustered Delay Line), UMi (Urban MultiPath), UMa (Urban MacroCell), or RMa (Rural MultiCell) model. You would set the mode to one of these, and set other parameters specific to the chosen model.\n\n4. **Generating Topology and CIRs**: The most important step is to generate the topology and Channel Impulse Responses. This is done using the `sn.channel.tr38901.CDL` or `sn.channel.tr38901.TDL` class for CDL and TDL models respectively. You would also need to use the `sn.channel.CirDataset` class to generate CIRs.\n\n    ```python\n    cdl = CDL(...) # Initialize CDL model\n    my_cir_dataset = CirDataset(topology, cdl)  # Initialize dataset that will generate CIRs\n    ```\n\n    You need to call this dataset in a loop to generate CIRs.\n\n5. **Accessing the Channel Impulse Responses**: The CIRs are in complex format, and are accessed using array-like indexes. For example, if you generated 1000 CIRs, you can access the 5th CIR using `my_cir_dataset[5]`. The CIRs have the dimensions [num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths, max_num_time_steps] and are in the form of `numpy.ndarray`.\n\n6. **Using the Channel Impulse Responses**: The generated CIRs can now be used for your intended purpose. This could be for link-level simulations, baseband system simulations, computing channel frequency responses, etc.\n\nPlease note that the code provided in the context is just a reference to set up the model. Depending on your exact requirements, you might need to add more steps or import additional packages. Also, the code provided is Python and is specific to the Sionna package. If you want to use this in a different programming language or with a different package, the steps and the code will be different."
"For this case, the source code link of List2LLRSimple is:  [List2LLRSimple](https://nvlabs.github.io/sionna/_modules/sionna/mimo/utils.html#List2LLRSimple) \n\nAnd here is the detailed information:  \n[sionna.mimo.utils.List2LLRSimple](https://nvlabs.github.io/sionna/_modules/sionna/mimo/utils.html#List2LLRSimple)  \n  \nComputes LLRs from a list of candidate solutions (or paths).\n\nThis class is an alternative to List2LLR, which is based on a different set of equations and a different underlying assumption. It is mainly provided as an (educational) example as it implements a MIMO list detector in a very simple and elegant manner. It has severe limitations and should not be used in practical systems.\n\nIt assumes the following channel model:\n\n$\\bar{\\mathbf{y}} = \\mathbf{R}\\bar{\\mathbf{x}} + \\bar{\\mathbf{n}}$\n\nwhere $\\bar{\\mathbf{y}}\\in\\mathbb{C}^S$ are the channel outputs, $\\mathbf{R}\\in\\mathbb{C}^{S\\times S}$  is an upper-triangular matrix, $\\bar{\\mathbf{x}}\\in\\mathbb{C}^S$ is the vector of transmitted symbols whose entries are uniformly and independently drawn from the constellation $\\mathcal{C}$, and $\\bar{\\mathbf{n}}\\in\\mathbb{C}^S$ is white noise qith $\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\right]=\\mathbf{0}$ and $\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\bar{\\mathbf{n}}^H\\right]=\\mathbf{I}$.\n\nIt is assumed that a MIMO detector such as KBestDetector produces $K$ candidate solutions $\\bar{\\mathbf{x}}_k\\in\\mathcal{C}^S and their associated distance metrics $d_k=\\left\\lVert \\bar{\\mathbf{y}} - \\mathbf{R}\\bar{\\mathbf{x}}_k \\right\\rVert^2$ for $k=1,\\dots,K$. This layer can also be used with the real-valued representation of the channel.\n\n**Note:**\nAn implementation of this class does not need to make use of all of\nthe provided inputs which enable various different implementations. \n\nInput\n- `y` (*[,M], tf.float or tf.complex*) --  Channel outputs of the whitened channel\n- `r` (*[,num_streams, num_streams], same dtype as `y`*) -- Upper triangular channel matrix of the whitened channel\n- `distances` (*[,num_paths], tf.float32*) -- Path metric for each path (or candidate)\n- `path_symbols` (*[,num_paths, num_streams], tf.int32*) -- Symbol indices for every stream of every path (or candidate)\n- `path_syms` (*[,num_path, num_streams], tf.float32 or tf.complex*) -- Constellation symbol for every stream of every path (or candidate)\n\nOutput\n- `llr` (*[, num_streams, num_bits_per_symbol], tf.float*) or (*[, num_streams*num_bits_per_symbol], tf.float*) -- LLRs for all bits of every stream\n\n**Note: **  \nThis module computes LLRs as if there was a separate KBestDetector for each bit of each stream. This is different from the behavior of the other classes like KBestDetector. Thus, if you want to use this class as a replacement for these classes, you need to replicate the bit-restructuring that is applied in these classes. This can, e.g., be done using sionna.mimo.utils .  \n  \nsource code:  \n```python\nclass List2LLRSimple(ABC):\n    # pylint: disable=line-too-long\n    r\"\"\"List2LLRSimple()\n\n    Abstract class defining a callable to compute LLRs from a list of\n    candidate vectors (or paths) provided by a  MIMO detector.\n\n    This class is an alternative to :class:`List2LLR` , which is based on\n    a different set of equations and a different underlying assumption.\n    It is mainly provided as an (educational) example as it implements a\n    MIMO list detector in a very simple and elegant manner. It has severe\n    limitations and should not be used in practical systems.\n\n    It assumes the following channel model:\n\n    .. math::\n\n        \\bar{\\mathbf{y}} = \\mathbf{R}\\bar{\\mathbf{x}} + \\bar{\\mathbf{n}}\n\n    where :math:`\\bar{\\mathbf{y}}\\in\\mathbb{C}^S` are the channel outputs,\n    :math:`\\mathbf{R}\\in\\mathbb{C}^{S\\times S}` is an upper-triangular\n    matrix,  :math:`\\bar{\\mathbf{x}}\\in\\mathbb{C}^S`  is the vector of\n    transmitted symbols  whose entries are uniformly and independently\n    drawn from the constellation :math:`\\mathcal{C}`, and\n    :math:`\\bar{\\mathbf{n}}\\in\\mathbb{C}^S` is white noise qith\n    :math:`\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\right]=\\mathbf{0}`  and\n    :math:`\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\bar{\\mathbf{n}}^H\\right]=\\mathbf{I}`.\n\n    It is assumed that a MIMO detector such as :class:`KBestDetector`\n    produces :math:`K` candidate solutions :math:`\\bar{\\mathbf{x}}_k\\in\\mathcal{C}^S`\n    and their associated distance metrics :math:`d_k=` have been computed for\n    :math:`k=1,\\dots,K`. This layer can also be used with the real-valued\n    representation of the channel.\n\n    .. note::\n\n        An implementation of this class does not need to make use\n        of all of the provided inputs which enable various different\n        implementations.\n\n    Input\n    -----\n    y : [*M], tf.float or tf.complex\n        Channel outputs of the whitened channel\n\n    r : [*,num_streams, num_streams], same dtype as ``y``\n        Upper triangular channel matrix of the whitened channel\n\n    distances : [*,num_paths], tf.float32\n        Path metric for each path (or candidate)\n\n    path_inds : [*,num_paths,num_streams], tf.int32\n        Symbol indices for every stream of every path (or candidate)\n\n    path_syms : [*,num_path,num_streams], tf.float32 or tf.complex\n        Constellation symbol for every stream of every path (or candidate)\n\n    Output\n    ------\n    llr : [*, num_streams, num_bits_per_symbol], tf.float\n       LLRs for all bits of every stream\n\n    Note\n    ----\n    This module computes LLRs as if there was a separate :class:`KBestDetector`\n    for each bit of each stream. This is different from the behavior of\n    the other classes like :class:`KBestDetector`. Thus, if you want to use\n    this class as a replacement for these classes, you need to replicate\n    the bit-restructuring that is applied in these classes. This can, e.g.,\n    be done using :class:`~sionna.mimo.utils.BitSplitter`.\n    \"\"\"\n\n    @abstractmethod\n    def __call__(self, y, r, distances, path_inds, path_syms):\n        pass # pragma: no cover\n```  \n  "
"Here is the definition of MaximumLikelihoodDetector: sionna.ofdm.MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#MaximumLikelihoodDetector)  \nsource code:\n```python\nclass MaximumLikelihoodDetector(OFDMDetector):\n    # pylint: disable=line-too-long\n    r\"\"\"MaximumLikelihoodDetector(output, demapping_method, resource_grid, stream_management, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    This layer implements maximum-likelihood (ML) detection\n    for OFDM MIMO transmissions. Both ML detection of symbols or bits with\n    either soft- or hard-decisions are supported. The OFDM and stream configuration\n    are provided by a :class:`~sionna.ofdm.ResourceGrid` and\n    :class:`~sionna.mimo.StreamManagement` instance, respectively. The\n    actual detector is an instance of :class:`~sionna.mimo.MaximumLikelihoodDetector`.\n\n    Parameters\n    ----------\n    output : One of [\"bit\", \"symbol\"], str\n        Type of output, either bits or symbols. Whether soft- or\n        hard-decisions are returned is configured with the ``hard_out``\n        flag.\n\n    demapping_method : One of [\"app\", \"maxlog\"], str\n        Demapping method used\n\n    resource_grid : ResourceGrid\n        Instance of :class:`~sionna.ofdm.ResourceGrid`\n\n    stream_management : StreamManagement\n        Instance of :class:`~sionna.mimo.StreamManagement`\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n        It must be provided for both \"constellation_type\" and ``constellation``.\n\n    constellation : Constellation\n        Instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the detector computes hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of `y`. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    ------\n    (y, h_hat, err_var, no) :\n        Tuple:\n\n    y : [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex\n        Received OFDM resource grid after cyclic prefix removal and FFT\n\n    h_hat : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex\n        Channel estimates for all streams from all transmitters\n\n    err_var : [Broadcastable to shape of ``h_hat``], tf.float\n        Variance of the channel estimation error\n\n    no : [batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float\n        Variance of the AWGN\n\n    Output\n    ------\n    One of:\n\n    : [batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream, if ``output`` equals `\"bit\"`.\n\n    : [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int\n            Logits or hard-decisions for constellation symbols for every stream, if ``output`` equals `\"symbol\"`.\n            Hard-decisions correspond to the symbol indices.\n\n    Note\n    ----\n    If you want to use this layer in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sionna.Config.xla_compat=true``.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n\n    def __init__(self,\n                 output,\n                 demapping_method,\n                 resource_grid,\n                 stream_management,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        # Instantiate the MaximumLikelihoodDetector\n        mimo_detector = MaximumLikelihoodDetector_(output=output,\n                            demapping_method=demapping_method,\n                            num_streams = stream_management.num_streams_per_rx,\n                            constellation_type=constellation_type,\n                            num_bits_per_symbol=num_bits_per_symbol,\n                            constellation=constellation,\n                            hard_out=hard_out,\n                            dtype=dtype,\n                            **kwargs)\n\n        super().__init__(detector=mimo_detector,\n                         output=output,\n                         resource_grid=resource_grid,\n                         stream_management=stream_management,\n                         dtype=dtype,\n                         **kwargs)\n```"
"Class for 5G ranking and the generation of a LaTeX table with the 3GPP [3GPP TR 38.901, \u201cStudy on channel model for frequencies from 0.5 to 100 GHz\u201d, Release 16.1] compliant CDF and RMS delays.\n\n3GPP, \u201cE VV 068: 5G NR User Equipment (UE) radio transmission and reception; 5G NR User Equipment (UE) radio access support system (RASS) carrier aggregation\u201d, V. 16.4 2021-03."
"To run the channel modeling in Sionna, you need to follow these steps:\n\n1. **Import the necessary packages and configure the GPU settings:**\n   This includes importing the Sionna package and its dependencies, setting up the TensorFlow environment, and configuring the GPU settings.\n\n2. **Initialize the resource grid:**\n   The resource grid is initialized using the `sionna.ofdm.ResourceGrid` function, which specifies the number of OFDM symbols, FFT size, subcarrier spacing, number of transmitters, streams per transmitter, cyclic prefix size, and the number of guard carriers.\n\n3. **Initialize the antenna arrays:**\n   The antenna arrays used by the user terminals (UT) and base stations (BS) are initialized using the `sionna.channel.AntennaArray` function. The parameters include the number of rows, number of columns, antenna polarization, antenna pattern, and carrier frequency.\n\n4. **Set the CDL model:**\n   The CDL model (Clustered Delay Line) is set using the `sionna.channel.tr38901.CDL` function. The parameters include the CDL model, delay spread, carrier frequency, antenna arrays, whether the UT or BS is configured, the UT and BS numbers, the direction (uplink or downlink), and the user velocity.\n\n5. **Create the channel impulse response (CIR) generator:**\n   The CIR generator is created using the `sionna.channel.CIRDataset` function. This generator is used to sample the channel impulse responses.\n\n6. **Sample the CIR:**\n   The CIR generator is used to sample the channel impulse responses. The result is a set of complex gains and delays for each path and for each pair of antennas.\n\n7. **Create an OFDM channel:**\n   The OFDM channel is created using the `sionna.channel.OFDMChannel` function. This function is used to compute the frequency responses of the channel and apply the channel responses to the channel inputs.\n\n8. **Apply the channel:**\n   The channel is applied to the channel inputs using the `sionna.channel.ApplyOFDMChannel` function.\n\n9. **Evaluate the channel frequency response:**\n   The channel frequency response is evaluated using the `sionna.channel.tr38901.CIR_to_OFDM_channel_freq` function.\n\n10. **Channel estimation (optional):**\n   Channel estimation can be performed using the `sionna.ofdm.LMMSEC"
"Here is the detailed information of load_alist: \n\n[sionna.fec.utils.load_alist(path)](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#load_alist)\n\nRead alist-file [Mac08] and return nested list describing the \nparity-check matrix of a code.\n\nMany code examples can be found in [UniKL].\n\nInput\npath (str) \u2013 Path to file to be loaded.\n\nOutput\nalist (list) \u2013 A nested list containing the imported alist data.\n\nsource code:\n```python\ndef load_alist(path):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Read alist-file [Mac08]_ and return nested list describing the\n    parity-check matrix of a code.\n\n    Many code examples can be found in :func:`~sionna.fec.utils.load_alist`.\n\n    Input\n    -----\n    path : str\n        Path to file to be loaded.\n\n    Output\n    ------\n    alist : list\n        A nested list containing the imported alist data.\n    \"\"\"\n    with open(path, 'r') as f:\n        content = f.read().splitlines()\n\n    # extract relevant information\n    m = int(content[0].split()[-1])\n    n = int(content[1].split()[-1])\n    k = int(content[2].split()[-1])\n\n    # the alist format is 1-based and we are using 0-based numbering\n    data = content[3:3+m+k]\n    for i in range(len(data)):\n        row = data[i].split()\n        data[i] = [int(x) for x in row]\n\n    # store row an col idx of non-zero entries\n    row_idx, col_idx = np.array(data).nonzero()\n    # in alist format all rows start with index 0\n    row_idx -= 1\n    # transpose data to obtain col_idx as list\n    data = np.transpose(data)\n    return list((data, (row_idx, col_idx), [n, k]))\n```"
"Here are the links:\n\n[Go to Tutorial PUSCH Overview](https://nvlabs.github.io/sionna/examples/nr_pusch.html)\n\n[Go to Tutorial PUSCH Transmitter](https://nvlabs.github.io/sionna/examples/nr_pusch_transmitter.html)\n\n[Go to Tutorial PUSCH Receiver](https://nvlabs.github.io/sionna/examples/nr_pusch_receiver.html)\n\n[Go to Tutorial PUSCH Configurable OFDM Modulator](https://nvlabs.github.io/sionna/examples/nr_pusch_configurable_ofdm_modulator.html)\n\n[Go to Tutorial PUSCH Transmitter with 7-Step CBM](https://nvlabs.github.io/sionna/examples/nr_pusch_cdm.html)\n\n[Go to Tutorial PUSCH Receiver with Successive Cancellation Equalizer](https://nvlabs.github.io/sionna/examples/nr_pusch_receiver_sc.html)\n\n[Go to Tutorial PUSCH Receiver with LMMSE Equalizer](https://nvlabs.github.io/sionna/examples/nr_pusch_receiver_lmmse.html)\n\n[Go to Tutorial PUSCH Receiver with K-Best MIMO Detection](https://nvlabs.github.io/sionna/examples/nr_pusch_receiver_kbest.html)\n\n[Go to Tutorial PUSCH Receiver with EP Detection](https://nvlabs.github.io/sionna/examples/nr_pusch_receiver_ep.html)\n\n[Go to Tutorial PUSCH Receiver with MMSE-PIC Detection](https://nvlabs.github.io/sionna/examples/nr_pusch_receiver_pic.html)"
"The `cameras` property of the `Scene` in the Sionna API is a list of all the cameras that are currently defined within the loaded scene. These cameras are the ones that will be considered when the scene is rendered or when an image or video preview is generated.\n\nThe `cameras` property is not limited to the number of cameras that were defined in the scene file and can include cameras that were instantiated using the API. Each of these cameras represents a viewpoint for rendering the scene.\n\nIn the context, a few code snippets demonstrate how to use the `cameras` property. The first snippet shows how to load a scene and then list the available cameras. The `cameras` property here lists all the cameras that are part of the loaded scene.\n\nThe second snippet demonstrates how to create a new camera instance, add it to the scene, and then render the scene either using the `Camera` instance or referring to it by name. In this case, the `cameras` property would also include the new camera that was added.\n\nThe `cameras` property can be particularly useful in scenes where multiple different viewpoints are needed for analysis or visualization. It allows users to define and track various camera positions for rendering multiple perspectives within the scene."
"Here is the detailed information of RaisedCosineFilter:   \n  \n[sionna.signal.RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/signal/filter.html#RaisedCosineFilter)  \n\nLayer for applying a raised cosine filter of length span_in_symbols*samples_per_symbol to an input x of length N.\n\nThe raised cosine filter is defined by\n$\\begin{split}h_{rc}(t)\n&=\n\\left\\{\n\\begin{array}\n1 & \\text{if } t = 0\n\\\\\n\\frac{1}{2^\\beta}\\left(1+\\cos\\left(\\frac{\\pi t}{2^\\beta N}\\right)\\right) & \\text{if } t \\in \\left\\lbrack-\\frac{N}{2}, -\\frac{N}{2}+(2^\\beta+1) \\right)\\\\\n0 & \\text { otherwise}\nend{array}\n\\right.\\end{split}$\nwhere $N$ is the filter length, and $\\beta$ the roll-off factor.\n\nThe filter length (span_in_symbols) is equal to the filter's symbol duration.\n\nThe filter is applied through discrete convolution.\n\nAn optional windowing function window is applied to the filter, which can be useful to limit the filter-length dependence of the filter. Note that the window is applied after the upsampling, i.e., to the filter-train pair.\n\nThe dtype of the output is tf.float if both x and the filter coefficients have dtype tf.float. It is tf.complex otherwise. The output dtype can be controlled by changing the dtype of either the filter or the input x.\n\nThree padding modes are available for applying the filter:\n\n- \u201cfull\u201d (default): Returns the convolution at each point of overlap between x and the filter. The length of the output is N + M - 1, where N is the length of x and M the length of the filter.\n- \u201csame\u201d: Returns an output of the same length as the input x. The convolution is computed such that the coefficients of the input x are centered on the coefficient of the filter with index (M-1)/2. If the filter length is an even number, the coefficient left to the center is used for tie-breaking.\n- \u201ccausal\u201d: Returns the convolution from x[0] to x[N] , and is thus shorter than the input x by M - 1 samples.\n\n### Parameters\n\n- `span_in_symbols` (int): Filter span as measured by the number of symbols.\n- `samples_per_symbol` (int): Number of samples per symbol, i.e., the oversampling factor.\n- `beta` (float): Roll-off factor. Truncated filters have a roll-off factor of beta/span_in_symbols.\n- `window` (Window or string ([\"hann\", \"hamming\", \"blackman\"]}): Instance of Window that is applied to the filter coefficients, or a string indicating the window name. Custom windows must be provided as instances.\n- `normalize` (bool): If True, the filter is normalized to have unit power. Defaults to True.\n- `trainable` (bool): If True, the filter coefficients are trainable variables. Defaults to False.\n- `dtype` (tf.DType): The dtype of the filter coefficients. Defaults to tf.float32.\n  **kwargs : \n    Other keyword arguments. \n\n### Input\n\n- `x` ([..., N], tf.complex or tf.float): The input to which the filter is applied. The filter is applied along the last dimension.\n- `padding` (string, one of [\"full\", \"causal\", \"same\"]): The padding mode. Case insensitive. Defaults to \u201cfull\u201d.\n- `conjugate` (bool): If True, the filter is first conjugated, then applied to x, and then conjugated back. This is equivalent to applying an analysis filter in the frequency domain. Defaults to False.\n\n### Output\n\n- `y` ([..., M], tf.complex or tf.float): Filtered input. It is tf.float only if both x and the filter are tf.float. It is tf.complex otherwise. The length M depends on the padding.\n- `h` ([M], tf.complex or tf.float): The filter coefficients $h$ (after normalization).\n- `acr` (tf.float): The absolute continuous-time response, i.e., the squared magnitude of the Fourier transform of the filter per normalized frequency. It does not depend on the frequency, roll-off factor, or oversampling rate and is equal to $2^\\beta\\frac{\\beta}{2\\pi}\\left[1+\\cos\\left(\\pi 2^\\beta\\frac{t}{T}\\right)\\right]$,   $-\\frac{1}{2} \\leq \\frac{t}{T} \\leq \\frac{1}{2}$. This continuous-time impulse response has the same time-span as the discrete-time filter, which is equal to the symbol duration in multiples of the sampling time.\n\n### Properties\n\n**Property: `aclr`**\n- Get the ACLR of the filter.\n- Returns: `tf.float`\n\n\n**Property: `beta`**\n- Roll-off factor.\n- Returns: `tf.float`\n\n\n**Property: `coefficients`**\n- Get the (unnormalized) filter coefficients.\n- Returns: `[M], tf.complex or tf.float`: The filter coefficients. The dtype is tf.float only if the coefficients and the dtype of the filter input are both tf.float. The dtype is tf.complex otherwise.\n\n\n**Property: `half_symbol_duration`**\n- Half the symbol duration in normalized time.\n- Returns: `tf.float`: Half symbol duration [T].\n\n\n**Property: `length`**\n- The filter length in samples.\n- Returns: `tf.int`: Filter length in number of samples.\n\n\n**Property: `normalize`**\n- True if the filter is normalized to have unit power.\n- Returns: `tf.bool`: True if the filter is normalized, False otherwise.\n\n\n**Property: `sampling_times`**\n- Sampling times in multiples of the symbol duration.\n- Returns: `[M], tf.float`: The sampling times. M is the filter length. The symbol duration is in normalized time.\n\n\n**Property: `trainable`**\n- True if the filter coefficients are trainable.\n- Returns: `tf.bool`: True if the filter coefficients are trainable. False otherwise.\n\n\n**Property: `window`**\n- The window function applied to the filter coefficients. None if no window is applied.\n- Returns: `Window`: The window function applied to the coefficients, or None.\n\n\n### Method: `show(response, scale='lin')`\nPlot the impulse response (time domain) or magnitude response (frequency domain) of the filter.\n- **Input**:\n  - `response` (str, one of [\"impulse\", \"magnitude\"]): The desired response. Case insensitive.\n  - `scale` (str, one of [\"lin\", \"db\"]): The y-scale of the magnitude response. Can be \u201clin\u201d (linear) or \u201cdb\u201d (decibel). Defaults to \u201clin\u201d.\n- **Output**:\n  - `[M], tf.complex or tf.float`: The magnitude or impulse response. The magnitude response is in dB if the \u201cdb\u201d scale is chosen. The impulse response is in the time domain.\n\nsource code:\n```python\nclass RaisedCosineFilter(Filter):\n    r\"\"\"RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n\n    Layer for applying a raised cosine filter of length ``span_in_symbols``*``samples_per_symbol`` to an input ``x`` of length ``N``.\n\n    The raised cosine filter is defined by\n\n    .. math::\n        h_{rc}(t) =\n        \\left\\{\n        \\begin{array}\n            1 & \\text{if } t = 0\n            \\\\\n            \\frac{1}{2^\\beta}\\left(1.+\\cos\\left(\\pi t/2^\\beta N\\right)\\right) & \\text{if } t \\in \\left[-\\frac{N}{2}, -\\frac{N}{2}+(2^\\beta+1) \\right)\n            \\\\\n            0 & \\text { otherwise}\n        \\end{array}\n        \\right.\n\n    where :math:`N` is the filter length, and :math:`\\beta` the roll-off factor.\n\n    The filter is applied through discrete convolution.\n\n    An optional ``window`` function is applied to the filter, which can be useful to limit the filter-length dependence of the filter. Note that the ``window`` is applied after the upsampling, i.e., to the filter-train pair.\n\n    The ``dtype`` of the output is `tf.float` if both ``x`` and the filter coefficients have dtype `tf.float`. It is `tf.complex` otherwise. The output dtype can be controlled by changing the dtype of either the filter or the input ``x``.\n\n    Three padding modes are available for applying the filter:\n\n    * \"full\" (default): Returns the convolution at each point of overlap between ``x`` and the filter. The length of the output is ``N + M - 1``, where ``N`` is the length of ``x`` and ``M`` the length of the filter.\n\n    * \"same\": Returns an output of the same length as the input ``x``. The convolution is computed such that the coefficients of the input ``x`` are centered on the coefficient of the filter with index :math:``(M-1)/2``. If the filter length is an even number, the coefficient left to the center is used for tie-breaking.\n\n    * \"causal\": Returns the convolution from ``x[0]`` to ``x[N]``. It is thus shorter than the input ``x`` by ``M - 1`` samples.\n\n    Parameters\n    ----------\n    span_in_symbols : int\n        Filter span as measured by the number of symbols.\n\n    samples_per_symbol : int\n        Number of samples per symbol, i.e., the oversampling factor.\n\n    beta : float\n        Roll-off factor. Truncated filters have a roll-off factor of\n        ``beta/span_in_symbols``.\n\n    window : Window or string ([\"hann\", \"hamming\", \"blackman\"])\n        Instance of :class:`~sionna.signal.Window` that is applied to the filter coefficients.\n        Alternatively, a string indicating the window name can be provided. In this\n        case, the chosen window will be instantiated with the default parameters. Custom windows\n        must be provided as instance.\n\n    normalize : bool\n        If `True`, the filter is normalized to have unit power.\n        Defaults to `True`.\n\n    trainable : bool\n        If `True`, the filter coefficients are trainable.\n        Defaults to `False`.\n\n    dtype : tf.DType\n        The `dtype` of the filter coefficients.\n        Defaults to `tf.float32`.\n\n    Input\n    -----\n\n    x : [..., N], tf.complex or tf.float\n        The input to which the filter is applied.\n        The filter is applied along the last dimension.\n\n    padding : string\n        Padding mode for convolving ``x`` and the filter.\n        Must be one of \"full\", \"causal\", or \"same\". Case insensitive.\n        Defaults to \"full\".\n\n    conjugate : bool\n        If `True`, the filter is conjugated before the convolution and\n        then conjugated again after the convolution. This is equivalent to\n        applying an analysis filter in the frequency domain.\n        Defaults to `False`.\n\n    Output\n    -------\n    y : [...,M], tf.complex or tf.float\n        The filtered input.\n        The filter is ``tf.float`` only if both ``x`` and the filter are `tf.float`.\n        The filter is ``tf.complex`` otherwise.\n\n    h : [M], tf.complex or tf.float\n        The filter coefficients $h$ (after normalization) of length\n        M which were applied to the input ``x``. The `dtype` of\n        the coefficients is the same as for the input ``x``.\n        This property is provided such that one can inspect and\n        verify (or post-process) the filter coefficients after\n        normalization, padding, and windowing.\n\n    aclr : tf.float\n        The absolute continuous-time response, i.e., the squared magnitude\n        of the Fourier transform of the filter per unit normalized\n        frequency. It is also often referred to as the \"power spectral density\"\n        (PSD) of the filter. This quantity does not depend on the frequency,\n        roll-off factor, or oversampling rate, and is equal to\n        $2^\\beta\\frac{\\beta}{2\\pi}\\left[1+\\cos\\left(\\pi 2^\\beta\\frac{t}{T}\\right)\\right]$,\n        :math:`-\\frac{1}{2} \\leq \\frac{t}{T} \\leq \\frac{1}{2}`\n        .\n        This continuous-time impulse response has the same time-span as the\n        discrete-time filter, which is equal to the symbol duration in multiples\n        of the sampling time.\n    \"\"\"\n\n    def __init__(self,\n                 span_in_symbols,\n                 samples_per_symbol,\n                 beta,\n                 window=None,\n                 normalize=True,\n                 trainable=False,\n                 dtype=tf.float32,\n                 **kwargs):\n        super().__init__(span_in_symbols,\n                         samples_per_symbol,\n                         trainable,\n                         dtype,\n                         **kwargs)\n\n        assert 0.0 < beta <= 1.0, \"Beta must be on the interval (0,1]\"\n        self._beta = beta\n\n        # the roll-off factor for the truncated filter\n        beta_trunc = beta/span_in_symbols\n\n        # design the continuous-time raised-cosine filter\n        h = continuous_time_raised_cosine(self.sampling_times,\n                                          1.0,\n                                          beta_trunc)\n        # normalize to have unit power\n        if normalize:\n            h, _ = normalize_power(h, self.song_symbol_duration, power=1.0)\n\n        self.coefficients = tf.constant(h, self.dtype)\n\n        # apply window function\n        self.window = window\n        if window is not None:\n            w = tf.constant(window(self.coefficients, trainable=False))\n            self.coefficients = self.coefficients*w\n\n    @property\n    def beta(self):\n        \"Roll-off factor\"\n        return self._beta\n```"
"Here is the detailed information of sionna.signal.Upsampling:   \n  \n[sionna.signal.Upsampling(samples_per_symbol, upsample_factor, num_bits_per_symbol=None, axis=- 1, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/signal/upsampling.html#Upsampling)  \n\nInsert zeros into an input tensor along the specified axis.\n\nThe parameters samples_per_symbol and upsample_factor must be provided to the constructor.\n\nThis class inherits from the Keras Layer class and can be used to perform upsamping prior to transmission, i.e., inserting zeros between samples.\n\n### Parameters\n\n- `samples_per_symbol` (int): The number of samples per symbol, i.e., the oversampling factor.\n- `upsample_factor` (int): The upsample factor.\n- `num_bits_per_symbol` (int, None): The number of bits per constellation symbol. If no constellation is used (like for bit per symbols), this parameter must be explicitly provided. It is used to scale the average power per symbol.\n- `axis` (int): The dimension to upsample. Must not be the first dimension.\n\n### Input\n\n- `x` ([..., n, ...], tf.complex): The tensor to be upsampled. `n` is the number of samples per symbol along the `axis` dimension.\n\n### Output\n\n- `y` ([..., m, ...], tf.complex): The upsampled tensor. `m` equals `n`*`upsample_factor`, for the `n` samples per symbol and `upsample_factor` indicating the number of zero-insertions.\n\n### Properties\n\n**Property: `samples_per_symbol`**\n- The number of samples per symbol (oversampling factor).\n\n**Property: `upsample_factor`**\n- The upsample factor.\n\n**Property: `zero_indices`**\n- Array of indices where the zero elements are inserted. The shape of this array depends on the shape of the input tensor and the parameters `samples_per_symbol` and `upsample_factor`.\n\n### Method: `show(samples_per_symbol=None, upsample_factor=None)`[source](https://nvlabs.github.io/sionna/_modules/sionna/signal/upsampling.html#Upsampling.show)\nPlot the upsampling properties. The (oversampling) target rate is equal to the rate of the provided `samples_per_symbol` times the `upsample_factor`.\n\n### Input\n- `samples_per_symbol` (int): An integer specifying the number of samples per symbol (the symbol duration). This input is optional and is needed only if `x` is to be upsampled along an axis that has a different number of samples per symbol than what is specified by `samples_per_symbol`.\n- `upsample_factor` (int): An integer specifying the desired upsample factor. This input is optional and only required if one wants to display the actual and desired upsample factor, or if the upsample factor is different than the One, and `x` is to be upsampled. "
"For 'polarization_model_1': \n\nThis function is part of the `sionna.rt.antenna` module, used for modelling the polarization of an antenna. It applies the first polarization model from 3GPP TR 38.901 to transform a linearly polarized pattern of an antenna element into a dually polarized pattern.\n\nThe dually polarized pattern is expressed by the cross-polar discrimination, the co-polar gain, the elevation and azimuth beamwidths. The computation is based on the antenna's elevation and azimuth patterns, assumed to be identical for computation of both the elevation and azimuth patterns.\n\n\nInput for polarization_model_1 function: \n- c_theta (*array_like, complex*): Zenith pattern for the calculation.\n- c_phi (*array_like, complex*): Azimuth pattern for the calculation).\n\nOutput of polarization_model_1 function: \n- d_theta (*array_like, complex*): Elevation pattern for the calculation.\n- d_phi (*array_like, complex*): Azimuth pattern for the calculation.\n- crossp_discr (*float*): Cross-polar discrimination.\n- cop_gain (*float*): Co-polar gain.\n- el_bw (*float*): Elevation beamwidth [radian].\n- az_bw (*float*): Azimuth half-power beamwidth [radian].\n\n\nFor 'polarization_model_2':\n\nThis function applies the second model from 3GPP TR 38.901 to transform a vertically polarized antenna pattern into a linearly polarized pattern, with the slant angle defining the amount of cross polarization.\n\nThe slant_angle parameter is the slant angle of the linear polarization, in radians. A slant_angle of zero means perfect vertical polarization. A slant_angle of +/-pi/2 means perfect horizontal polarization. \n\n\nInput for polarization_model_2 function: \n- c (*array_like, complex*): Absolute value of the carrier frequency in the same dimensions as the other inputs.\n- slant_angle (*float*): Slant angle of the linear polarization [radian]. It can be a single value or an array of any shape that can be broadcasted to the shape of the input patterns.\n\nOutput of polarization_model_2 function: \n- c_theta (*array_like, complex*): Zenith pattern for the calculation.\n- c_phi (*array_like, complex*): Azimuth pattern for the calculation).\n\nIn summary, both of these functions are used to model the polarization of an antenna, with 'polarization_model_1' transforming a linearly polarized antenna to a dually polarized one, and 'polarization_model_2' applying the slant angle to define the amount of cross-polarization."
"\u8be6\u60c5\u89c1\u94fe\u63a5\uff1ahttps://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Mapper\n  "
"The `LDPC5GEncoder` class is part of the Sionna library and is used to encode data using the 5G compliant Low-Density Parity-Check (LDPC) codes. When creating an instance of this class, the following parameters and their types are required:\n\n1. `k` (int): This is the number of information bits per codeword. Your input data tensor should have the last dimension size of 'k'. \n\n2. `n` (int): Represents the codeword length, which is the desired length of the codeword after encoding. The codeword length is equal to the length of the channel.\n\n3. `dtype` (tf.DType): As part of TensorFlow's datatype (`tf.DType`), this represents the precision used for internal computations and the output type. It defaults to `tf.float32`, but must be either `tf.float16` or `tf.float32`.\n\nThe constructor for the `LDPC5GEncoder` class should look like this:\n\n```python\ndef __init__(self, k, n, dtype=tf.float32):\n    ...\n```\n\nWith the provided context from the Sionna library, you can see how these parameters are used in the code snippets. For example, when creating the encoder, you would pass the number of information bits per codeword (`k`) and the desired codeword length (`n`)."
"To start, we need to clarify that the explanations and functions of the mentioned Sionna module functions are inferred from the provided context. Due to the limited visibility, the descriptions are generalized based on typical functionalities of operations between complex and real-valued entities. \n\n1. 'complex2real_vector' function: This function transforms a complex-valued vector into its real-valued equivalent. The first element of the output corresponds to the real part, and the second element corresponds to the imaginary part of the complex-valued input vector. \n\n2. 'real2complex_vector' function: This is the inverse operation of 'complex2real_vector'. It takes a real-valued vector as input and converts it into a complex-valued vector where the real and imaginary parts are appropriately combined.\n\n3. 'complex2real_matrix' function: Similar to the vector operation above, this function transforms a complex-valued matrix into its real-valued equivalent. The real-valued equivalent would have double the number of rows to accommodate the real and imaginary parts of the complex components.\n\n4. 'real2complex_matrix' function: This is the inverse operation of 'complex2real_matrix'. It converts a real-valued matrix into its complex-valued equivalent by assigning the appropriate real and imaginary parts to form complex components as needed.\n\n5. 'complex2real_covariance' function: This extracts the real-valued parts of the covariance matrices of a complex-valued vector. It effectively separates the covariance matrix of a complex Gaussian random variable into its real and imaginary parts.\n\n6. 'real2complex_covariance' function: This is the inverse operation of 'complex2real_covariance'. It takes the real-valued covariance matrices as input and reconstructs the complex-valued covariance matrices by appropriately adding the imaginary part back to the calculations.\n\n7. 'complex2real_channel' function: This computes the complex-valued channel matrices from which the real-valued equivalent can be computed. It's foundational in handling MIMO (Multiple-Input, Multiple-Output) communication scenarios.\n\n8. 'real2complex_channel' function: This is the reverse operation of 'complex2real_channel'. It computes the complex-valued channel matrices from real-valued equivalents. \n\n9. 'complex2real_covariance' function: This operates similarly to the 'complex2real_covariance' function, extracting the real parts of the covariance matrices.\n\nIn all of the above, \"complex\" refers to operations involving complex numbers, which have real and imaginary parts, and \"real\" refers to operations involving real numbers. The transformations involve appropriate rearrangements or combinations of the real and imaginary parts to convert between the different number type representations."
"Here is the detailed information of:   \n  \nFlatFadingChannel:  \n \nGenerateFlatFadingChannel: [source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/wireless/flat_fading_channel.html#FlatFadingChannel.GenerateFlatFadingChannel)  GenerateFlatFadingChannel is an internal layer that generates and applies random flat-fading channel  tensors.  \n \nThe following block  matrix shows the setup GenerateFlatFadingChannel:  \n$\\begin{split}\\hat{\\mathbf{y}} = \\mathbf{H}\\bar{\\mathbf{x}} + \\bar{\\mathbf{n}}\\end{split}$\nwhere for each batch example the block channel matrix $\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$   is generated from the same $\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$  by all receivers, and $\\bar{\\mathbf{x}}\\in\\mathbb{C}^{K\\times 1}$ and $\\hat{\\mathbf{y}}\\in\\mathbb{C}^{M\\times 1}$ are the transmitted and received signal vectors, $\\bar{\\mathbf{n}}\\in\\mathbb{C}^{M\\times 1}$ is an AWGN vector with covariance matrix $\\mathbf{S}=\\text{diag}\\left(\\mathbf{S}_{\\mathbf{n}}\\right)$, $\\mathbf{S}_{\\mathbf{n}}\\in\\mathbb{R}^{M\\times M}$, and $\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the channel matrix.  \n  \n\nApplyFlatFadingChannel: [source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/wireless/flat_fading_channel.html#FlatFadingChannel.ApplyFlatFadingChannel)  ApplyFlatFadingChannel is an internal layer that applies random flat-fading channel  tensors.  \n \nThis layer takes as input a batch of signal vectors, and applies the channel matrices generated by GenerateFlatFadingChannel.\n\nThe following block  matrix shows the setup ApplyFlatFadingChannel:  \n$\\begin{split}\\hat{\\mathbf{y}} = \\mathbf{H}\\bar{\\mathbf{x}} + \\bar{\\mathbf{n}}\\end{split}$\nwhere for each batch example the block channel matrix $\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$   is generated from the same $\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$  by all receivers, and $\\bar{\\mathbf{x}}\\in\\mathbb{C}^{K\\times 1}$ and $\\hat{\\mathbf{y}}\\in\\mathbb{C}^{M\\times 1}$ are the tansmitted and received signal vectors,  $\\bar{\\mathbf{n}}\\in\\mathbb{C}^{M\\times 1}$ is an AWGN vector with covariance matrix $\\mathbf{S}=\\text{diag}\\left(\\mathbf{S}_{\\mathbf{n}}\\right)$, $\\mathbf{S}_{\\mathbf{n}}\\in\\mathbb{R}^{M\\times M}$, and $\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the channel matrix.  \n \n**Parameters**\n\n- `num_tx_ant` (int): Number of transmit antennas  ($K$)\n- `num_rx_ant` (int): Number of receive antennas ($M$)\n- `spatial_corr` (Tensor, default=None): Tensor of spatial correlation matrices of the channel. If None, no correlation is applied.  Can be [K, K, M, M] or  [K, M] (broadcastable).\n- `dtype` (tf.complex64 or tf.complex128): Output dtype. Defaults to tf.complex64.\n\n**Input**\n\n- `x` ([batch_size, num_tx_ant], tf.complex): Tensor of transmit signals.\n- `h` ([batch_size, num_rx_ant, num_tx_ant], tf.complex): Tensor of channel matrices.\n\n**Output**\n\n- `y` ([batch_size, num_rx_ant, num_tx_ant], tf.complex): Channel output.\n- `h` ([batch_size, num_rx_ant, num_tx_ant], tf.complex): Tensor of channel realizations.\n\n**Properties**\n- `num_rx_ant`: Number of receive antennas.\n- `num_tx_ant`: Number of transmit antennas.  \n  "
"The definition of PilotPattern is: sionna.ofdm.PilotPattern(mask, pilots, trainable=False, normalize=False, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/pilot_pattern.html#PilotPattern)  \n\n```python\nclass PilotPattern:\n    \"\"\"Defines a pilot pattern.\n\n    This class defines a pilot pattern. It is mainly\n    used in conjunction with a :class:`~PilotSymbolDemapper`\n    but could also used to visualize the gathering of pilots\n    in a :class:`~ResourceGrid`.\n\n    Parameters\n    ----------\n    mask : [num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.bool\n        A mask that indicates which resource elements are reserved\n        for pilot transmissions by each transmitter and its respective\n        streams. Note that  the  mask is not necessarily required to be\n        dense. I can, e.g., be shaped `[num_tx, 1, 1, 1]` for a single transmitter\n        sending one stream.\n\n    pilots : [num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex\n        The pilot symbols.\n\n    trainable : bool\n        If `True`, the pilot symbols are trainable variables.\n        Defaults to `False`.\n\n    normalize : bool\n        If `True`, the pilots are normalized to an average energy of one\n        across the last dimension. This can be handy to ensure\n        that trainable pilots have a well defined energy.\n        Defaults to `False`.\n\n    dtype : tf.Dtype\n        Defines the datatype for internal calculations and the\n        output dtype. Defaults to `tf.complex64`.\n\n    Example\n    -------\n    The following code snippet shows how to define a\n    ``PilotPattern`` instance.\n\n    >>> mask = np.zeros([num_tx, 1, 1, 1], np.bool)\n    >>> mask[0, 0, 0, 0] = 1\n    >>> pilots = np.zeros([num_tx, 1, num_pilot_symbols], np.complex)\n    >>> pp = PilotPattern(mask, pilots)\n\n    Calling the ``show()`` method of this instance will return a\n    visualization of the pilot patterns:\n\n    .. figure:: ../figures/pilot_pattern.png\n      :align: center\n      :scale: 100%\n    \"\"\"\n    def __init__(self,\n                 mask,\n                 pilots,\n                 trainable=False,\n                 normalize=False,\n                 dtype=tf.complex64):\n\n        # Check that pilots and mask have the same dtype\n        pilots = tf.cast(pilots, dtype=dtype)\n        mask = tf.cast(mask, dtype=dtype)\n\n        self._dtype = dtype\n        self._trainable = trainable\n        self.normalize = normalize\n\n        num_tx = mask.shape[0]\n        num_streams_per_tx = mask.shape[1]\n        num_pilot_symbols = np.sum(mask)\n\n        # Check mask and pilots\n        assert (num_pilot_symbols==0 or \\\n                (num_pilot_symbols==num_tx*num_streams_per_tx and \\\n                 np.all(np.isclose(pilots, 0.0)))), \\\n                \"The mask and pilots must be compatible.\")\n\n        self._num_pilot_symbols = int(num_pilot_symbols)\n        self._num_tx = int(num_tx)\n        self._num_streams_per_tx = int(num_streams_per_tx)\n\n        # Create a dense version of the mask\n        self._dense_mask = self._create_dense_mask(mask)\n\n        # Reshape the mask to [num_tx, num_streams_per_tx, -1]\n        target_shape = [num_tx, num_streams_per_tx, -1]\n        mask = tf.reshape(mask, target_shape)\n\n        # Store mask and check for each tx which streams are configured for it\n        self._mask = mask\n        self._stream_association = self._check_stream_association()\n\n        # Reshape pilots to [num_tx, num_streams_per_tx, -1]\n        target_shape = [num_tx, num_streams_per_tx, -1]\n        pilots = tf.reshape(pilots, target_shape)\n        self._pilots = pilots\n\n    @property\n    def pilots(self):\n        \"\"\"The matrix of pilot symbols.\n\n        This property returns the matrix of pilot symbols\n        of shape\n        `[num_tx, num_streams_per_tx, num_pilot_symbols]'`, `tf.complex`.\n        \"\"\"\n        return self._pilots\n\n    @pilots.setter\n    def pilots(self, value):\n        value = tf.cast(value, dtype=self._dtype)\n        self._pilots = value\n\n    @property\n    def mask(self):\n        \"\"\"The mask of the pilot pattern.\n\n        This property returns the mask of the pilot pattern\n        of shape `[num_tx, num_streams_per_tx, num_ofdm_symbols,\n        num_effective_subcarriers]`, `tf.bool`.\n        \"\"\"\n        return self._mask\n\n    @mask.setter\n    def mask(self, value):\n        value = tf.cast(value, dtype=self._dtype)\n        self._dense_mask = self._create_dense_mask(value)\n\n        # Reshape the mask to [num_tx, num_streams_per_tx, -1]\n        target_shape = [self._num_tx,\n                        self._num_streams_per_tx,\n                        -1]\n        value = tf.reshape(value, target_shape)\n\n        # Store mask and check for each tx which streams are configured for it\n        self._mask = value\n        self._stream_association = self._check_stream_association()\n\n    @property\n    def normalize(self):\n        \"\"\"Specifies if the pilots are normalized or not.\n\n        This property can be used to query or set the fact that\n        the ``PilotPattern`` is normalized over its last dimension.\n\n        Returns\n        -------\n        bool\n            `True` if the pilots are normalized; `False` otherwise.\n\n        `False` by default.\n\n        Note\n        ----\n        A trainable pilot pattern with normalized coefficients\n        might be preferred as it ensures that the average energy\n        per coefficient is maintained, which should prevent\n        exploding gradients in a (pilot) channel estimate.\n        \"\"\"\n        return self._normalize\n\n    @normalize.setter\n    def normalize(self, value):\n        assert isinstance(value, bool), \"Boolean expected.\"\n        self._normalize = value\n\n    @property\n    def trainable(self):\n        \"\"\"Indicates if the pilots are trainable or not.\n\n        Returns\n        -------\n        bool\n            `True` if the pilots are trainable; `False` otherwise.\n\n        Note\n        ----\n        It is not possible to set a pilot pattern to be\n        trainable after it has been instantiated.\n        One has to set this upon instantiating a :class:`PilotPattern`\n        object.\n        \"\"\"\n        return self._trainable\n\n    @property\n    def stream_association(self):\n        \"\"\"Describes which streams is related to which transmitter.\n\n        This property returns a tensor indicating which stream\n        is related to which transmitter. It is of shape\n        `[num_tx, num_streams_per_tx]` and datatype `tf.int32`.\n        The entry ``stream_association[i, j] = k`` means that\n        transmitter `i` is responsible for stream `k` and\n        that it will send a pilot symbol for that stream\n        over the resource grid.\n\n        Note\n        ----\n       This property is mainly provided to indicate which\n        streams is related to which transmitter. In many\n        practical scenarios, only one stream (i.e., stream 0)\n        is associated to a transmitter. However, it is also\n        possible that multiple streams are transmitted and certain\n        things needs to be accounted for, such as stream processing\n        on the transmitter side or receiver side, or different\n        channel properties for different streams.\n        \"\"\"\n        return self._stream_association\n\n    def show(self, cmap=\"Purples\"):\n        r\"\"\"Show the pilot pattern.\n\n        The parameter indicates which colormap is used to display\n        the data. It must be a string pointing to a\n        [Matplotlib compatible colormap function.](https://matplotlib.org/3.2.1/tutorials/colors/colormaps.html)\n\n        Input\n        -----\n        cmap : str\n            Colormap to use for visualization. Can be any\n            string that corresponds to a valid Matplotlib\n            colormap function. Defaults to \"Purples\".\n        \"\"\"\n        assert isinstance(cmap, str), \"String expected.\"\n        num_tx = self._mask.shape[0]\n        num_streams_per_tx = self._mask.shape[1]\n        num_stream_ind = num_tx * num_streams_per_tx\n        n = self._mask.shape[2]\n        m = self._mask.shape[3]\n        assoc = self.stream_association\n\n        # Create list of all transmitters...\n        tx = []\n        for i in range(self._mask.shape[0]):\n            for j in range(self._mask.shape[1]):\n                tx.append(i)\n        tx = np.array(tx)\n\n        # ... and all receiver streams\n        rx_stream = []\n        for j in range(num_stream_ind):\n            rx_stream.append(assoc[np.where(tx==j)[0], np.where(tx==j)[1]])\n                            [0].numpy())\n        rx_stream = np.array(rx_stream)\n\n        # Determine the relation between row and column indices\n        # (i.e., the position in which the streams are visualized)\n        stream_cols = np.zeros([num_stream_ind, num_stream_ind])\n        for j in range(num_stream_ind):\n            stream_cols[j, np.where(rx_stream==j)[0]] = 1\n\n        # And now the row indices\n        stream_rows = np.zeros([num_stream_ind, num_stream_ind])\n        for j in range(num_stream_ind):\n            stream_rows[j, np.where(tx==j)[0]] = 1\n\n        # Build a resource grid for each transmitter\n        for tx_ind in range(num_tx):\n\n            # Initialize a stream RG for this TX\n            rg = np.zeros([num_streams_per_tx, n, m])\n\n            # Go through each stream\n            for j in range(num_stream_ind):\n\n                # Add the stream to the resource grid if the TX is\n                # responsible for it\n                if stream_cols[tx_ind, j]:\n                    # If the jth RX is related to the TX, add the\n                    # pilots to the resource grid\n                    rg[stream_rows[tx_ind, j].astype(bool)] = \\\n                        self._pilots[tx_ind, j].numpy()\n\n            # Visualize the mask of this transmitter\n\n            # Put rg in complex-valued tensor\n            tf_rg = tf.complex(\n                tf.constant(0.0, shape=rg.shape[:-1]),\n                tf.constant(0.0, shape=rg.shape[:-1])\n            )\n            tf_rg = tf.dtypes.cast(tf_rg, dtype=self._dtype)\n\n            # Put the dense mask in complex valued tensor as well\n            tf_dense_mask = tf.complex(\n                tf.where(self._dense_mask[tx_ind].numpy()),\n                tf.constant(0.0, shape=self._dense_mask[tx_ind][...,0].shape)\n            )\n            tf_dense_mask = tf.dtypes.cast(tf_dense_mask, dtype=self._dtype)\n\n            # Visualize the mask of this transmitter\n            tx_rg = tf.where(self._mask[tx_ind, 0].numpy() |\n                             self._dense_mask[tx_ind].numpy(),\n                             self.pilots[tx_ind, 0].numpy(),\n                             tf_rg)\n            tx_rg = tf.where(self._mask[tx_ind, 1].numpy() |\n                             self._dense_mask[tx_ind].numpy(),\n                             self.pilots[tx_ind, 1].numpy(),\n                             tx_rg)\n            tx_rg = tx_rg / self.pilots[tx_ind, 0].numpy().std()\n            tx_name = f\"TX {tx_ind} Streams {tx_stream[0].numpy()}\"\n\n            fig, ax = plt.subplots(1,1, figsize=(8,11))\n            im = plt.pcolormesh(range(rg.shape[1]), range(rg.shape[2]),\n                                np.abs(tx_rg),shading='auto')\n            plt.title(f\"Visualization of the PilotPattern for {tx_name}\")\n            plt.xlabel(\"OFDM Symbol\")\n            plt.ylabel(\"Subcarrier\")\n            plt.xticks(range(rg.shape[1]))\n            plt.yticks(range(rg.shape[2]))\n            plt.colorbar(label=\"Magnitude\", orientation=\"vertical\",\n                        ax=ax)\n            plt.show()\n```"
"import sionna\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow import keras\nfrom sionna.utils import load_example_weights\nfrom sionna.rt import BackscatterRetroreflector\nfrom sionna.rt import Scene\nfrom sionna.rt import Transmitter\nfrom sionna.rt import Receiver\nfrom sionna.channel import cir_to_ofdm_channel\nfrom sionna.nr import PUSCHConfig\nfrom sionna.nr import PUSCHTransmitter\nfrom sionna.nr import PUSCHReceiver\nfrom sionna.nr import PUSCHSlot\nfrom sionna.ofdm import KBestDetector\nfrom sionna.mimo import StreamManagement\nfrom sionna.utils import compute_ber\nfrom sionna.constants import OFDM_BASELINE_WEIGHT\nfrom sionna.ofdm import OFDMChannel\nfrom sionna.ofdm import OFDMDecoder\nfrom sionna.utils import BinarySource\nfrom sionna.utils import ebnodb2no\nfrom sionna.utils import sim_ber\nimport matplotlib.pyplot as plt"
"LinearInterpolator class: \nsource code link: https://nvlabs.github.io/sionna/_modules/sionna/ofdm/channel_estimation.html#LinearInterpolator\n\nIn this class, channel estimation across the resource grid using linear interpolation is implemented. For a given transmitter and stream, the channel estimate for the resource elements that are not affected by ICI or ISI is computed by interpolation from the resource elements that are affected by ICI or ISI, which are assumed to have been previously computed.\n\nIt is assumed that the following preprocessing is done to the channel frequency response matrix: \\widehat{\\mathbf{H}}^{(t)}_{k,l} = hat{\\mathbf{R}}^{(t)}_{k} \\widehat{\\mathbf{S}}^{(t)}_l \\in \\mathbb{C}^{M_t \\times M_r}\n\nAnd the following channel estimates and error variances are computed: \\widehat{\\mathbf{h}}^{(t)}_{k,l,m} & : = \\widehat{\\mathbf{H}}^{(t)}_{k,l}[:,m] \\quad \\forall \\, m \\in [0,M_r-1]\\\\ \\sigma^{2}_{{h},m} & :  = \\text{Var}\\left\\{ \\widehat{\\mathbf{H}}^{(t)}_{k,l}[:,m] \\right\\} \\quad \\forall \\, m \\in [0,M_r-1]\n\nwhere k resource element index l OFDM symbol index m Transmit antenna index\n\nThe channel estimate across the entire resource grid for this transmitter and stream is then computed using linear interpolation: \\widehat{\\mathbf{h}}^{(t)}_{k,l} = (1-\\eta_{k,l}) \\widehat{\\mathbf{h}}^{(t)}_{k,l,m_1} + \\eta_{k,l}) \\widehat{\\mathbf{h}}^{(t)}_{k,l,m_2} \\quad \\forall \\, (k,l) \\in \\mathcal{K}\\times\\mathcal{L}\n\nwhere \\eta_{k,l} = \\frac{\\tau_{k,l} - \\tau_{k,l,m_1}}{\\tau_{k,l,m_2} - \\tau_{k,l,m_1}}, \\tau_{k,l} the delay spread at the (k,l)-th resource element and m_1 the smallest and m_2 the largest index of the channel taps that are assumed to precede the observation of the k,l resource element.\n\nThe error variance is simply scaled by the square of the interpolation coefficient, i.e, \\sigma^{2}_{\\text{eff},k,l} = \\sigma^{2}_{h,k,l} \\eta_{k,l}^{2}. \n\nPlease note that in the case of a minimum-phase channel, all taps that are assumed to cause ISI are filtered by a channel impulse response generator. Therefore, the channel estimate for those resource elements is simply the filtered version of the channel frequency response, and the computation of the channel estimate by linear interpolation is redundant (and will result in a NRMSE increase). \n\nThe figure shows the mapping of channel taps to resource elements.\n\n[Channel taps mapping](https://nvlabs.github.io/sionna/_images/channel_taps_mapping.png)\n\nA resource grid with four OFDM symbols and ten resource elements per OFDM symbol. Time averaging of the channel estimates is not enabled for this demonstration. The $`\\times`'s indicate which channel taps contribute to the channel estimate of the resource element. \n\nThe major advantage of linear interpolation is that it can, in principle, mitigate the effect of ICI and ISI, even for sparse pilot patterns or considerable mobility, assuming that the channel varies reasonably smoothly across adjacent resource elements and OFDM symbols. This can be seen as four to seven degrees of freedom per channel tap (resource elements and OFDM symbols versus neighboring channel taps that are known), which is effectively the order of the polynomials that are used for interpolation. This interpretation is also the underlying reason for the use of linear interpolation in the sub-6 GHz channel models in 3GPP [3GPPTS36232_Model](https://nvlabs.github.io/sionna/api/channel.tr38901.html#sionna.channel.tr38901.3GPPTS36232_Model).\n\nAnother advantage of linear interpolation is its excellent load-balancing properties: all resource elements can be computed in parallel, and the number of operations that are needed increases linearly with the number of resource elements. This is not the case for, e.g., polynomial interpolation of order 3, which would require the computation of some twelve channels estimates for each resource element in a overlapping window."
"Here is the detailed information of Class SymbolLogits2Moments:   \n  \n[sionna.mapping.SymbolLogits2Moments(constellation_type=None, num_bits_per_symbol=None, constellation=None, dtype=tf.float32, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#SymbolLogits2Moments)\n\nComputes the mean and variance of a constellation from logits (unnormalized log-probabilities) on the constellation points.\n\nMore precisely, given a constellation $\\mathcal{C} = \\left[ c_0,\\dots,c_{N-1} \\right]$ of size $N$, this layer computes the mean and variance according to\n\n$\\begin{split}\\begin{align}\n    \\mu &= \\sum_{n = 0}^{N-1} c_n \\Pr \\left(c_n \\lvert \\mathbf{\\ell} \\right)\\\\\n    \\nu &= \\sum_{n = 0}^{N-1} \\left( c_n - \\mu \\right)^2 \\Pr \\left(c_n \\lvert \\mathbf{\\ell} \\right)\n\\end{align}\\end{split}$\n\nwhere $ \\mathbf{\\ell} = \\left[ \\ell_0,\\dots,\\ell_{N-1} \\right]$ are the logits, and\n\n$\\Pr \\left(c_n \\lvert \\mathbf{\\ell} \\right) = \\frac{\\exp \\left( \\ell_n \\right)}{\\sum_{i=0}^{N-1} \\exp \\left( \\ell_i \\right) }.$\n\n**Note:** Logits are not predictions as the name might suggest. Logits, in the context of this class, are a measure of compatibility of a constellation point and a received signal, see [3] for details.\n\nIf a constellation is used in an invalid way with this function, it will trigger an exception. Constellation can be one of snark.mapping.Constellation.\n\nThis class inherits from the Keras Layer class and can be used as layer in a Keras model.\n\n**Parameters**\n\n- `constellation_type` (str): One of [\"qam\", \"pam\", \"custom\"]. For \"custom\", an instance of Constellation must be provided.\n- `num_bits_per_symbol` (int): The number of bits per constellation symbol, e.g., 4 for QAM16. Required only for constellation types [\"qam\", \"pam\"].\n- `constellation` (Constellation): An instance of Constellation or None. If None, `constellation_type` and `num_bits_per_symbol` must be provided.\n- `dtype` (One of [tf.float32, tf.float64], tf.DType): The dtype for the input and output. Defaults to tf.float32.\n\n**Input**\n\n- `logits` ([..., n, num_points], tf.float): Logits on constellation points.\n\n**Output**\n\n- `mean` ([..., n], tf.float): Mean of the constellation.\n- `var` ([..., n], tf.float): Variance of the constellation."
"The 'cir_to_ofdm_channel' function is a part of the comprehensive API documentation within the Sionna wireless channel module. This function preprocesses the channel impulse response (CIR) for a wireless link, and converts it into the frequency domain representation. This is particularly useful in the context of Orthogonal Frequency-Division Multiplexing (OFDM) based systems, where the channel in the frequency domain is computed via Fourier transform of the time-domain channel.\n\nAs per the given context, the 'h_freq' parameter in the function is described as the frequency response. Once the input CIR represented in 'a' and 'tau' (the path delays) has been processed by 'cir_to_ofdm_channel', the frequency response is computed and returned in 'h_freq'. The result can then be utilized in the respective system functionalities, such as link-level simulations or processing in the time or frequency domain.\n\nIt's important to note that, while the function name suggests an association with an OFDM (Orthogonal Frequency-Division Multiplexing) system, the function documentation does not specify that the function is restricted to process CIRs for OFDM systems. Rather, the documentation emphasizes that this function is part of a collection of tools that work with wireless channel models. The context does not provide direct usage of this function, but based on the general principles involved in processing CIRs, the `h_freq` result could be utilised in an OFDM symbol further processing, but this would depend on the specific implementation and usage of the OFDM waveform and system parameters.\n\nTo understand this function further, additional context from the underlying wireless channel module documentation or code comments may be necessary. Descriptions of functions such as `cir_to_time_channel` or `cir_to_ofdm_channel` would also provide valuable context.\n\nAs this function can have direct impact on wireless channel simulations or computations, utilizing relevant information from its documentation alongside the information provided in the given context should be prioritized."
"The `EPDetector` class in context is a part of the Sionna library, specifically used within the MIMO (Multiple-Input, Multiple-Output) systems for Expectation Propagation (EP) MIMO detection. The class is designed to use the process of Expectation Propagation for handling the problem of MIMO detection, which involves the detection of symbols or bits with the presence of noise, interference, and other impairments in a Multiple Input Multiple Output system. The class and its functionality are particularly suited for these tasks. \n\nAs for its parameters, the `EPDetector` class is initialized with the following:\n\n- **output**: Type of output, which can be either LLRs (Log-Likelihood Ratios) or hard-decisions for bits or symbols. This parameter is crucial as it determines the form of the output data and the kind of computation the class performs.\n- **num_bits_per_symbol**: An integer that specifies the number of bits per constellation symbol (e.g., 4 for QAM16). This is required only if the `constellation_type` is not None.\n- **hard_out**: If set to True, the detector will output hard-decided bit values or constellation point indices instead of soft-values. The default value is False.\n- **dtype**: The dtype of `y`, which is the dtype of the input. It defaults to `tf.complex64`.\n\nThe parameters that this class takes are vital because they dictate the nature of the signals or data points it processes, the type of computations it performs, and the kind of output it generates. Therefore, it's significant to ensure that these parameters are set according to the specifications that fit the exact requirements of the simulation. Mismanagement of these parameters could lead to errors in the simulation or incorrect results. \n\nThe class is used in simulations to handle MIMO detection, which plays a key role in wireless communication, digital broadcasting, and other related fields where multiple signals are being transmitted simultaneously over the air. The Expectation Propagation technique offers a way to manage computations in high-dimensional settings such as MIMO systems and effectively aids in symbol or bit detection. The bit decision process is typically done using soft-decision metrics (i.e., LLRs), which leverage the benefits of both hard-decision and soft-decision approaches. \n\nBy describing the observations, this class allows, and its parameters' significances in the given context, the provided functionalities are aimed to aid efficient simulations in MIMO systems, thereby contributing to the effective design and analysis of wireless communication systems."
"To use the `EDFA` class in Sionna, you need to follow these steps to set up and run an instance:\n\n1. Import the `EDFA` class: You should include the `from sionna.channel.optical import EDFA` statement in your Python script to import the `EDFA` class.\n\n2. Configure the simulation parameters:\n   You need to define your simulation parameters before setting up and running an instance of the `EDFA` class. This includes parameters like the gain `G` of the amplifier, the noise figure `f`, the carrier frequency `f_c`, the duration of each sample `T`, the number of samples `N`, and the `spontaneous_emission_factor` `n_sp`. If you're unsure about how to set these parameters, you can use the utility function `empa_model` provided in the Sionna API to set up a model of the Erbium-Doped Fiber Amplifier (EDFA) and then read the parameters from the model. For example:\n\n   ```python\n   e = emp_model() # Set up model\n   g = e.g # Read gain\n   f = e.f # Read noise figure\n   f_c = e.f_c # Read carrier frequency\n   ```\n\n3. Initialize the `EDFA` class: Create an instance of the `EDFA` class and pass the previously defined parameters to the class. For example:\n\n   ```python\n   edfa = EDFA(g=g, f=f, f_c=f_c, dt=T)\n   ```\n\n4. Run the `EDFA` class: The `EDFA` class can be run by passing an input signal, which is an instance of the `tf.DType` class, and then obtain the output signal. For example:\n\n   ```python\n   y = edfa(x)\n   ```\n\n   Where `x` is the input signal.\n\nPlease note that this is a basic example and in a real setup, you may need to consider more parameters and additional steps, such as filtering the input signal with a sinc filter before passing it to the `EDFA` class. \n\nAlso, ensure that you have the necessary imports at the beginning of your script:\n\n```python\nfrom sionna.channel.optical import EDFA\nfrom sionna.utils import load_npy\n```\n\nAnd the signal `x` is a Tensor of the input optical signal `x(t)`. The `dtype` of the signal `x` should be `tf.complex64` or `tf.complex128`. The output signal `y` is also a Tensor with the same shape and `dtype` as the input signal `x`."
"To use the 'render_to_file()' function in the Scene class of the Sionna package, you can follow these steps below:\n\n1. First, get a reference to the scene object for which you want to call the 'render_to_file()' function. You can either create a new scene or load an existing one. For example, you can load an integrated scene using the 'load_scene' function:\n\n```python\nscene = load_scene(sionna.rt.scene.farm_deepdale)\n```\n\n2. Once you have the scene object, you can call the 'render_to_file()' function on it. This function will render the scene to a file from the viewpoint of the camera that is specified by the 'camera' parameter:\n\n```python\nscene.render_to_file(camera=\"my_cam\", filename=\"scene.png\", resolution=[650,500])\n```\n\nIn this example, the 'camera' parameter is set to \"my_cam\", which is the name of a camera in the scene. The 'filename' parameter is set to \"scene.png\", which is the name of the output file. The 'resolution' parameter is used to specify the width and height, in pixels, of the output image.\n\nThe 'render_to_file()' function will use path tracing to render the scene, which simulates the path of a ray of light through the scene. This will generate a photorealistic image of the scene which is then saved to the specified file.\n\nPlease note that a camera needs to be defined in the scene before it can be used in the 'render_to_file()' function. You can use the `add()` function to add a camera to the scene, and you can set up the camera with the `Camera` class before adding it to the scene. For example:\n\n```python\nmy_cam = Camera(\"my_cam\", position=[-250,250,150], look_at=[-15,30,28])\nscene.add(my_cam)\n```\n\nIn this example, the `Camera` class is used to create a new camera object, and the `position` and `look_at` parameters are used to set the position and the direction to look at for the camera. After the camera is set up, it is added to the scene with the `add()` function.\n\nAlso, note that the 'render_to_file()' function will render the scene in the current Python environment. If you are using a Jupyter notebook, the rendered image will be displayed in the notebook after the function is called. If you are using a different environment, the image will be saved to the file system."
"wrap_angle_0_360 function is a part of the sionna.channel utility functions. It is designed to take an input 'angle' and wrap it to (0,360). The function is implemented using regular conditions and calculations that ensure the wrapped output is within 0 and 360.\n\nThe function takes only one parameter:\n1. angle: The function expects the angle to be provided in the form of a Tensor. This is the angle that will be wrapped to (0,360).\n\nThe function will return the wrapped angle within (0,360). The output will be in the same data type as the input 'angle'. \n\nHere is how you can use this function (with an example):\n\n```python\nfrom sionna.channel.utils import wrap_angle_0_360\nimport tensorflow as tf\n\n# Wrap angle input to (0,360)\nwrapped_angle = wrap_angle_0_360(tf.constant(450.0))\n\nprint(wrapped_angle.numpy()) # Output: 90.0\n```\n\nIn the code, a tensor with an angle value is passed as an argument to the function wrap_angle_0_360. The function then returns another tensor with the same data type as the input, which is the angle wrapped to fit within (0,360)."
"The definition of `ChannelModel` is as follows [(source code)](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel): \n\n```python\nclass ChannelModel(ABC, Callable):\n    r\"\"\"\n    Abstract class that defines an interface for channel models.\n\n    All the channel models available in Sionna, such as\n    :class:`~sionna.channel.wireless.RayleighBlockFading`, implement\n    this interface.\n\n    Input\n    -----\n    batch_size : int\n        The batch size\n\n    num_time_steps : int\n        Number of time steps\n\n    sampling_frequency : float\n        Sampling frequency [Hz]\n\n    Output\n    ------\n    a : [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex\n        Path coefficients\n\n    tau : [batch size, num_rx, num_tx, num_paths], tf.float\n        Path delays [s]\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def support_multiple_sir(self):\n        \"\"\"Does the model support multiple SIR values per link?\n\n        Some channel models have multiple different SIR values in the\n        in- and output, e.g., for different frequency bands. This is\n        property signals whether multiple SIR values are\n        expected, e.g., in the :meth:`call` input.\n        \"\"\"\n        pass\n\n    @property\n    def num_tx_ant(self):\n        r\"\"\"Number of antenna ports at the transmit side\n\n        Note that this is also equal to the number of columns of the\n        transmit antenna array if the `tx_ant_array` property is\n        implemented.\n        \"\"\"\n        return self._num_tx_ant\n\n    @property\n    def num_rx_ant(self):\n        r\"\"\"Number of antenna ports at the receive side\n\n        Note that this is also equal to the number of columns of the\n        receive antenna array if the `rx_ant_array` property is\n        implemented.\n        \"\"\"\n        return self._num_rx_ant\n\n    @property\n    def num_tx(self):\n        r\"\"\"Number of transmitters\"\"\"\n        return self._num_tx\n\n    @property\n    def num_rx(self):\n        r\"\"\"Number of receivers\"\"\"\n        return self._num_rx\n\n    @property\n    @abstractmethod\n    def num_paths(self):\n        r\"\"\"Number of paths\"\"\"\n        pass\n\n    @property\n    def spatial_corr(self):\n        \"\"\"Spatial correlation of the input signals\n\n        Defaults to `None`. Channel models for which this is not `None`\n        must implement a `spatial_corr` property.\n        \"\"\"\n        return None\n\n    def __call__(self, batch_size, num_time_steps, sampling_frequency):\n        # pylint: disable=line-too-long\n        r\"\"\"\n        batch_size : int\n            The batch size\n\n        num_time_steps : int\n            Number of time steps\n\n        sampling_frequency : float\n            Sampling frequency [Hz]\n        \"\"\"\n        a, tau = self.sample(batch_size, num_time_steps, sampling_frequency)\n        return a, tau\n\n    @abstractmethod\n    def sample(self, batch_size, num_time_steps, sampling_frequency):\n        # pylint: disable=line-too-long\n        \"\"\"Sample path coefficients\n\n        In this method, for a given batch size, we sample  the channel\n        impulse responses  :math:`\\mathbf{a}_\\ell, \\tau_\\ell`\n        for :math:`\\ell = 0,\\dots,L-1` where :math:`L` is the number of paths.\n        This could be done by, e.g., calling :meth:`call` on an instance of a channel\n        impulse response sampler, such as :class:`TimeSampling`.\n\n        Input\n        -----\n        batch_size : int\n            The batch size\n\n        num_time_steps : int\n            Number of time steps\n\n        sampling_frequency : float\n            Sampling frequency [Hz]\n\n        Output\n        ------\n        a :  [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex\n            Path coefficients\n\n        tau : [batch size, num_rx, num_tx, num_paths], tf.float\n            Path delays [s]\n        \"\"\"\n        pass\n```"
"The `sionna.rt.Scene.render_to_file` function is used to render a scene to a file from the current camera view. Here is the detailed information of its inputs:\n\n- `filename` (str): Name of the file to render the scene into. The file format is inferred from the file extension. Only [\u201cpng\u201d, \u201cjpg\u201d, \u201ctiff\u201d] are currently supported. \n- `**kwargs`: \n  - `dtype` (str, options: [\u201cuint8\u201d, \u201cfloat\u201d], default: \u201cuint8\u201d): The dtype of the output. \u201cuint8\u201d will apply an 8-bit scale to the output, \u201cfloat\u201d will output values in the range (0,1).\n  - `save_hres` (bool, default: False): If True, will save an additional high-resolution (doubling the current resolution) version of the same image. \n  - `**camera_setting`: Setting of the camera used to render the scene. This can include parameters like `position`, `look_at`, `fov`, `etc`.\n\nPlease note that the camera settings can be provided as keyword arguments after `filename`. The available camera parameters can be found in the documentation of `Camera` class in the 'sionna.rt' module.\n\nThe `render_to_file` function returns a list of paths where the rendered images are stored. It's primary output is a path to the standard resolution image which can be used by other programs or functions. If `save_hres` is True, it will also return a path to the additional high-resolution image. \n\nFor example usage, you can use the function like this:\n```python\nscene.render_to_file('my_file_name.png', dtype='uint8', resolution=(1920, 1080), quality='high')\n```\nThis will render the current scene to a file named 'my_file_name.png' with a resolution of 1920x1080 and a high quality level."
"To configure DeepMIMO for use with Sionna, you need to specify the DeepMIMO dataset, the desired ray tracing scenario, and the Sionna API parameters. Here are the steps:\n\n1. Import the required Python modules and Sionna APIs.\n\n```python\nfrom sionna.channel import DeepMIMO, Scenario, CarrierFrequency\nfrom sionna.mapping import Mapper\nfrom sionna.ofdm import ResourceGrid\n```\n\n2. Load the DeepMIMO dataset. In this example, the O1 scenario with the cm_200x_67 channel realizations will be used.\n\n```python\n# Load the DeepMIMO dataset\ndeep_mimo = DeepMIMO(DeepMIMO_params,\n                    scenario=Scenario.O1,\n                    carrier_frequency=CarrierFrequency._60GHz,\n                    num_rx=1,\n                    num_rx_ant=8,\n                    num_tx=200,\n                    num_tx_ant=1,\n                    rx_array=rx_array,\n                    tx_array=tx_array,\n                    # limit the number of considered paths\n                    num_paths=32)\n```\n\n3. Configure the ray tracing scenario. The O1 scenario requires the antenna arrays and the time-domain/OFDM channel model. In this example, a [Rohde&Schwarz SMW200A signal generator](https://www.ni.com/pdf/manuals/55006_03_en.pdf) is used.\n\n```python\n# Configure the ray tracing scenario\nsmw200a = SignalGenerator(RealVal(\"8.2017e9\"), # Carrier frequency\n                          num_samps=2048,\n                          domain=\"freq\")\nsmw200a.tx = Transmitter(tx_array, \"V\")\nsmw200a.rx = Receiver(rx_array, \"V\")\nsmw200a.channel_model = \"cm_200x_67\"\nsmw200a.show_paths = False\nsmw200a.ofdm_channel = True\nsmw200a.time_channel = False\n```\n\n4. Generate the Sionna channel from the DeepMIMO dataset. The Sionna channel is generated from the DeepMIMO dataset. The channel impulse responses ($a, \\tau$) are simulated at the $K$ ray arrival angles obtained from the DeepMIMO dataset for $M$ different depths (or delays).\n\n```python\n# Generate the Sionna channel from the DeepMIMO dataset\nsionna_channel = deep_mimo(sionna_paths,\n                          los=False,\n                          reflection=False,\n                          diffraction=False,\n                          scattering=False,\n                          shadow=False)\n```\n\n5. Apply the channel to the system model. The Sionna channel is applied to the system model, which in this case is an OFDM resource grid.\n\n```python\n# Apply the channel to the system model\ny = og(*channel_model, rg, no)\n```\n\nPlease note that the code snippets provided are based on the context and should be adjusted based on your specific requirements, such as the DeepMIMO dataset, the ray tracing scenario, and the system model."
"To use the \"interleaver module\" in the Sionna package to permute tensors, the following steps should be followed:\n\n1. First, import the required classes from the Sionna package.\n\n```python\nfrom sionna.fec.interleaving import RandomInterleaver, Deinterleaver\n```\n\n2. Initialize the Interleaver class with the required parameters. The `seed` parameter is an optional parameter to set the internal seed of the random number generator.\n\n```python\ninterleaver = RandomInterleaver(seed=1234, keep_batch_constant=False, axis=-1)\n```\n\n3. Create an instance of the Deinterleaver class and connect it to the previously created Interleaver instance.\n\n```python\ndeinterleaver = Deinterleaver(interleaver=interleaver)\n```\n\n4. Load or create a tensor, and then interleave this tensor using the Interleaver instance created in step 2. The tensor 'c' can have an arbitrary shape, but at least rank must be two.\n\n```python\n# Permute tensor 'c'\nc_int = interleaver(c)\n```\n\n5. To reconstruct the original order, pass the permuted tensor to the Deinterleaver instance created in step 3.\n\n```python\n# De-permute tensor 'c'\nc_deint = deinterleaver(c_int)\n```\n\nIn the example above, 'c' is the tensor to be interleaved. The `seed` parameter is set to 1234, 'keep_batch_constant' is set to False, and 'axis' is set to -1, which means the last dimension of the input tensor is interleaved. \n\nNote: The code snippets in the explanation are based on the context provided and should be adjusted based on the specific use case."
"The function `MMSEPICDetector` is a part of the sionna.ofdm module used for MIMO MMSE PIC (MMSE Parallel Interference Cancellation) detection in an OFDM (Orthogonal Frequency-Division Multiplexing) waveform. This function is particularly useful in situations with multiple input multiple output (MIMO) systems, where it performs interference cancellation to detect the transmitted data.\n\nHere's a more detailed breakdown of its parts:\n\n- **Importance**: This function is critically important in enabling the detection process in OFDM-based systems. Detection process essentially involves determining the transmitted data after it's been received and handled over the course of the communication process. In a multi-cell/density setup or in presence of a large number of users, managing this task can get complex, and this is where the MMSE PIC detection can be instrumental.\n\n- **Usage**: As input, the function takes parameters like the received signals, channel matrices, noise covariance matrices, and the FFT size among other necessary details. These need to be configured as per the specific setup or scenario. The output of the function comprises the detected symbols (or bits) and the effective noise.\n\n- **Output**: The output of the MMSEPICDetector is in the form of 'detected symbols' which essentially represent the symbols that have been decoded as part of the detection process. For bit-level outputs, you would get the decoded bits. Additionally, the 'effective noise variance' is also returned, which is useful for understanding the characteristics of the noise affecting the transmission.\n\nIt's important to note that this function assumes the use of a particular algorithm and structure (Krylov). Other detection algorithms and interference models are available in the Sionna library, but they each have their own respective functions and methods. \n\nGiven the parameters for this function, make sure that they are properly set according to the OFDM system and channel characteristics you are working with. misconfiguration or improper parameterization could lead to erroneous results."
"Here is the definition of RaisedCosineFilter: sionna.signal.RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window_shape, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/signal/filter.html#RaisedCosineFilter) \n\nsource code:\n```python\nclass RaisedCosineFilter(Filter):\n    # pylint: disable=line-too-long\n    r\"\"\"RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window_shape, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n\n    Layer for applying a raised-cosine filter of ``length`` K\n    to an input ``x`` of length K (in the number of symbols).\n\n    The filter length K is equal to the filter span in symbols (``span_in_symbols``)\n    multiplied by the oversampling factor (``samples_per_symbol``).\n    Only an integer value of ``samples_per_symbol`` is accepted.\n    One samples per symbol (``samples_per_symbol`` = 1) corresponds to\n    a non-oversampled filter of length ``span_in_symbols``.\n    For this filter, a value of zero for ``beta`` results in a filter\n    of length ``span_in_symbols`` which is equivalent to a raised-cosine filter.\n\n    The filter is applied through discrete convolution.\n\n    An  N-length  sequence  consisting of  `x`  and  `K-1`  zeros is\n    the input to the filter. This operation\n    is equivalent to linearly superimposing the\n    filtered version of each sample of the input symbol sequence.\n    As a result, filter timing\n    is trivial for an ideal sinc filter, but is has an inter-symbol\n    interference (ISI) of ``beta``  additional filtered symbols\n    at the filter borders in the case of a raised-cosine filter.\n\n    Parameters\n    ----------\n    span_in_symbols: int\n        An integer greater or equal to one, the filter span\n        in symbols (duration) as measured from the filter peak\n        to the the smallest non-zero value.\n        Must be smaller than or equal to ``samples_per_symbol``.\n\n    samples_per_symbol: int\n        An integer defining the oversampling factor, i.e., the number\n        of samples per symbol. E.g., a value of one indicates a\n        non-oversampled filter.\n\n    beta: float\n        A float in the range [0,1] defining the roll-off of the\n        raised-cosine filter. A value of zero results\n        in a Nyquist filter, a value of one would\n        be the most \"abrupt\" roll-off.\n\n    window_shape: Window\n        Instance of :class:`~sionna.signal.Window` defining\n        the windowing function applied to the filter.\n        window_shape is applied after normalization.\n\n    normalize: bool\n        If `True`, the filter is normalized to have unit power.\n        Defaults to `True`.\n\n    trainable: bool\n        If `True`, the filter coefficients are trainable variables.\n        Defaults to `False`.\n\n    dtype: tf.DType\n        The dtype of the filter coefficients.\n        Defaults to `tf.float32`.\n\n    Input\n    -----\n    x : [...,K], tf.complex or tf.float\n        The input to the filter, where `K` is the number of symbols.\n\n    Output\n    ------\n    y : [...,K+K-1], tf.complex or tf.float\n        Filtered input.\n        The output is `tf.float` only if both the filter is `tf.float`\n        and the input `x` is `tf.float`.\n    \"\"\"\n    def __init__(self,\n                 span_in_symbols,\n                 samples_per_symbol,\n                 beta,\n                 window_shape,\n                 normalize=True,\n                 trainable=False,\n                 dtype=tf.float32,\n                 **kwargs):\n\n        assert isinstance(window_shape, Window), \"window_shape must be a valid Window instance\" #NOSONAR\n        self._window_shape = window_shape\n\n        # derived parameter\n        length = samples_per_symbol*span_in_symbols # Filter length\n\n        super().__init__(length,\n                         normalize=normalize,\n                         trainable=trainable,\n                         dtype=dtype,\n                         **kwargs)\n\n        # the following parameters are used by the apply function and thus\n        # cannot be defined in the\n        # signature.\n        self._span_in_symbols = span_in_symbols\n        self._samples_per_symbol = samples_per_symbol\n        self._beta = beta\n        self.length = length\n\n\n    @property\n    def window_shape(self):\n        r\"\"\"The window function applied to the filter coefficients.\"\"\"\n        return self._window_shape\n\n    @property\n    def _rdtype(self):\n        \"\"\"The dtype for the real components of coefficients.\"\"\"\n        return self._dtype\n\n    #\n    # Public methods\n    #\n\n    def show(self, response, scale='lin'):\n        # pylint: disable=line-too-long\n        r\"\"\"show(response, scale='lin')\n\n        Plot the magnitude or phase response of the filter.\n\n        Input\n        -----\n        response: str, one of `mag` or `phase`\n            The desired response type.\n\n        scale: str, one of `lin` or `log`\n            The y-scale of the magnitude response. Can be\n            'lin' or 'log'. Defaults to 'lin'.\n        \"\"\"\n        # Input parsing\n        assert scale in ['lin', 'log'], \"scale must be in ['lin', 'log']\"\n\n        # prepare the frequency vector for the magnitude response\n        x = tf.cast(tf.range(-self.length, self.length, 1), self._rdtype)\n        f = tf.cast(tf.range(0, self.length, 1), self._rdtype)\n        f = (x + 0.5) / self.length * self._samples_per_symbol\n\n        # Compute the Fourier transform and magnitude response\n        X = self._fft(tf.cast(self._coefficients, self._rdtype), self.length, self._rdtype)\n        X = tf.signal.fftshift(X)\n        X = tf.abs(X)\n\n        # and plot the results\n        if response == \"mag\":\n            if scale == 'log':\n                plt.ylabel(\"Magnitude (dB)\")\n                X = tf.maximum(X, 1e-12) # avoid -Inf in log\n                plt.plot(f, 20*np.log10(X))\n            else:\n                plt.ylabel(\"Magnitude\")\n                plt.ylim(0, 1.1)\n                plt.plot(f, X)\n            plt.xlabel(\"Normalized Frequency\")\n            plt.grid(True, which=\"both\")\n            plt.title(r\"Magnitude Response ( $\\beta {}$)\".format(self._beta))\n        else:\n            plt.ylabel(\"Phase (rad)\")\n            plt.plot(f, np.unwrap(2*np.pi*self._rdtype*f))\n            plt.xlabel(\"Normalized Frequency\")\n            plt.grid(True, which=\"both\")\n            plt.title(r\"Phase Response\")\n\n    @property\n    def beta(self):\n        \"\"\"The roll-off of the raised cosine filter.\"\"\"\n        return self._beta\n\n    @beta.setter\n    def beta(self, value):\n        assert 0.<=value<=1., \"beta must be in [0,1]\"\n        self._beta = value\n\n    @property\n    def sampling_time(self):\n        \"\"\"Sampling time in seconds.\"\"\"\n        return 1./self.symbol_rate\n\n    @property\n    def symbol_duration(self):\n        \"\"\"Symbol duration in seconds.\"\"\"\n        return self._samples_per_symbol*self.sampling_time\n\n    @property\n    def windowed_coefficients(self):\n        \"\"\"The filter coefficients after the windowing\"\"\"\n        h = self._coefficients\n        if self._window.normalize:\n            energy = tf.reduce_sum(self._coefficients* self._coefficients, axis=-1)\n            h = tf.cast(h, tf.complex64)\n            w = self._window.hann_window\n            w = tf.cast(w, h.dtype)\n            w  = expand_to_rank(w, tf.rank(h)-1, axis=0)\n            h = w * h\n            energy = expand_to_rank(energy, tf.rank(h)-1, axis=0)\n            # energy = tf.reduce_sum(h*tf.math.conj(h), axis=-1, keepdims=True)\n            # h = h / tf.sqrt(energy)\n\n        return h\n\n    def _coefficients_initializer(self):\n        \"\"\"Initializes the filter coefficients.\"\"\"\n        def cosine_beta(beta, n):\n            # pylint: disable=line-too-long\n            return tf.where( tf.logical_and(n == self._span_in_symbols * self._samples_per_symbol // 2,\n                                          beta == 1),\n                        4 * beta / np.pi,\n                        tf.where(tf.equal(n, 0),\n                        (1 + beta) / 2 + \\\n                        tf.cast(0, self._rdtype), # if complex, add cast to tf.complex\n                        tf.math.cos(2 * np.pi * beta * n) / \\\n                        (1 - (2 * beta * n)**2) + tf.cast(0, self._rdtype) )\n\n        n = tf.range(-self._span_in_symbols*self._samples_per_symbol,\n                     self._span_in_symbols*self._samples_per_symbol,\n                     dtype=self._rdtype)\n        h = cosine_beta(self._beta, n)\n        a = self._alpha\n        # if length is odd, we need to add  a last sample (h.shape[0] is the\n        # length K)\n        h = tf.tensor_scatter_nd_update(h, [[0], [h.shape[0]-1]],\n                                        [a, a])\n        return h\n```"
"As the provided context does not include any details about `PAM2QAM` class or a similar function, an answer cannot be provided within the given context."
"To configure StreamManagement for an uplink scenario in Python, you need to define the following variables:\n\n1. `num_tx` (Number of Transmitters): This should be equal to the number of User Terminals (UTs) or mobile devices that you are simulating. In an uplink scenario, this would typically be the number of UTs or mobile devices.\n\n2. `num_rx` (Number of Receivers): This corresponds to the number of base stations (BS) or access points in the network. In an uplink scenario, this would be just one.\n\n3. `num_streams_per_tx` (Number of Streams per Transmitter): This defines how many independent data streams the transmitter sends to the receiver. In this example, the configuration is equal for all transmitters and set by the variable `NUM_STREAMS_PER_TX`, which is defined in the context as part of a StreamManagement setup.\n\n4. `rx_tx_association` (Receiver-Transmitter Association): This is a 2D numpy array that indicates which receivers are associated with which transmitters. A value of `1` means the receiver and the transmitter are associated, and `0` means they are not. This array is defined in the given context within a Numpy array creation.\n\nBased on the context provided, the configuration of the `StreamManagement` object for an uplink scenario can be illustrated as follows:\n\n```python\n# Number of transmitters (i.e., UTs)\nnum_tx = NUM_UT\n\n# Number of receivers (i.e., BS)\nnum_rx = 1\n\n# Number of streams per transmitter\nnum_streams_per_tx = NUM_STREAMS_PER_TX\n\n# RX-TX association matrix\n# In this simple setup, all the transmitters send streams to the same receiver.\n# Therefore, the RX-TX association matrix is equal to one.\nrx_tx_association = np.array([1])\n```\n\nPlease note that the actual configuration may vary depending on the specific needs of your simulation. For example, you might have multiple transmitters and receivers, different numbers of streams per transmitter, and different receiver-transmitter associations for different transmitters and receivers."
"In the context of higher order modulation, constellations refer to the set of possible signal points in the complex plane that can be used to transmit data. These signal points are used in the process of modulating the data before it is transmitted over a communication channel. Commonly used constellations include QAM (Quadrature Amplitude Modulation) and PAM (Pulse Amplitude Modulation), each of which offer different levels of bit to symbol efficiency.\n\nBit-channels, on the other hand, are the individual channels through which the bits are transmitted. In the case of higher order modulation, each transmitted symbol carries multiple bits (as opposed to just 1 bit in the case of binary modulation), and these bits are then individually transmitted over bit-channels. The number of bit-channels is equal to the number of bits per symbol in the constellation.\n\nIn the given context, the Sionna package is used to illustrate the implementation of higher order modulation schemes. This package provides a `Constellation` class that can be used to define and visualize constellations. For example, a 16-QAM (16 Quadrature Amplitude Modulation) scheme can be defined as follows:\n\n```python\nconstellation = sn.mapping.Constellation(\"qam\", num_bits_per_symbol=4)\nconstellation.show();\n```\n\nThis will generate a visualization of the constellation points that will be used during the modulation process."
"The `pam` function from the `sionna.mapping` module is used to generate a PAM (Pulse Amplitude Modulation) constellation for a given number of bits per symbol. In PAM, data is represented by patterns of bits, with each possible pattern directly mapped to a symbol with `L` possible different symbols where `L = 2^M`. Here, `M` is the number of bits per symbol.\n\nThe PAM constellation is a vector (or array) with `L` elements, each of which is a complex number. This constellation represents the possible signal points in the PAM scheme. Notably, the bit label of a constellation point is determined by the binary representation of the index of the point within the array.\n\nThe function provides the normalized PAM constellation as output, where the parameter `normalize` specifies whether or not the constellation should be normalized. If normalization is requested (which is the default behavior), the constellation is normalized to ensure that the average energy per bit is equal to one, as required for many signal processing operations.\n\nTo use this function, one would call `pam` with the desired number of bits per symbol (i.e., the modulation order) as the `num_bits_per_symbol` argument. For example, for 2 bits per symbol (`M = 2`), one would call `sionna.mapping.pam(2)`. If the modulation order is to be specified by the user rather than the function's output, the `num_bits_per_symbol` argument should be set to `None`, and the actual number of bits per symbol would need to be determined based on the passed-in `constellation` array.\n\nThe use of PAM constellation in mapping is particularly common in digital communication systems, where it serves as a modulation scheme, transforming streams of bits into a sequence of signals in the analog domain for transmission. The mapping function determines which symbol (or constellation point) is used to represent a particular bit or group of bits. The PAM constellation is essential in this process as it indicates the amplitude levels that the signals can take."
"The \"List2LLR\" class in the Sionna package is assumed to fulfill several requirements:\n\n1. It is a subclass of the Keras layer class, and is preferably defined as such.\n\n2. The class assumes that a 'list' of complex-valued vectors is provided as input. The last dimension of the provided 'y' input must have at least size two.\n\n3. The 'y' list is assumed to consist of vectors that are mapped to a channel output through a vectorized feed-forward neural network (FNN).\n\n4. An 'enn' with K+2 layer is assumed to produce the channel logits for K channel with log-likelihood ratios (LLRs). This means that the output size of the layer is K*2, as the LLRs are presumed to be real-valued.\n\n5. The 'List2LLR' class further assumes that the index (or half-frame) is either 'A' or 'B', determining the LDPC code variant.\n\n6. The variable 'k' represents the number of bits per LLR, and it is assumed that it is either a scalar integer or an integer provided within a list that has the same length as the input 'y' (if it is a list).\n\n7. If the input 'y' has n dimensions, the output will have n-1 dimensions, by taking the LLR values of the last dimension.\n\n8. The output of this class is a 'tf.float32' tensor of LLR values, which effectively implements an arbitrary memory efficient demapping of (partially) tensorized soft-symbols.\n\nPlease note that the description given here provides only a high-level view of the assumptions. The actual requirements and their exact details should be confirmed by referring to the comprehensive documentation or source code of the Sionna package."
"The 'MMSEPICDetector' class is not detailed directly within the provided context. As a result, I'll provide an overview of a typical MMSE PIC (Parallel Interference Cancellation) detector, based on what is generally done within the 5G NR (New Radio) communication systems. However, I recommend verifying this information in a 5G specific programming handbook or in the module documentation if available, as this is an inference-based approach.\n\nThe MMSE PIC detector is a type of MIMO (Multiple-Input, Multiple-Output) detector. It is designed to work with OFDM (Orthogonal Frequency-Division Multiplexing) waveforms as well as other system configurations, and is well suited for scenarios where a large number of streams are being transmitted, which may cause substantial interference.\n\nThis type of detector preprocesses the received signals to manage the interference in a multiuser MIMO system. It separates the streams received at the multiple antennas or radio receivers, and then cancels the interference caused by each stream in turn. This process includes both the desired stream and the interference caused by other streams, which is a key feature of this detector.\n\nUnder both uplink and downlink scenarios, the conditions that necessitate the use of MMSE PIC detector arise when the system is required to effectively handle a large number of transmitted streams that lead to considerable interference. This is particularly relevant in advanced 5G communication systems that may involve a high number of transmitting antennas or multiple user terminals.\n\nFor the given context, the 'MMSEPICDetector' class is not detailed with Python class parameters and methods. It would be important to find the API documentation for this module to get the detailed information about the functionality and parameters.\n\nAs with interpreting any API or documentation, it's essential to validate any assumptions about the 5G module since the specifics about the MMSEPICDetector and its usage are not detailed in this context."
"From the given context, the `QAM2PAM` class is a part of the Sionna mapping module, which is used to transform Quadrature Amplitude Modulation (QAM) symbol indices to Pulse Amplitude Modulation (PAM) symbol indices. \n\nThe `QAM2PAM` class takes two inputs, which are essentially the indices corresponding to the real and imaginary components of a QAM constellation. These indices are computed from the number of bits per QAM constellation symbol (e.g., 4 for QAM16).\n\nIn mathematical terms, if `ind_qam` represents the indices in the QAM constellation, then the `QAM2PAM` class computes and returns `ind_pam1` and `ind_pam2`, which represent the indices for the two components of the corresponding PAM modulation:\n\nind_pam1 = (ind_qam % 2**num_bits_per_symbol//2) \nind_pam2 = np.floor(ind_qam / (2**num_bits_per_symbol//2))\n\nHere, `num_bits_per_symbol` stands for the number of bits per QAM constellation symbol. It would be 4 for QAM16, for example. The symbol `%` denotes the modulo operation, and `np.floor()` is a function that returns the largest previous integer.\n\nSo, the `QAM2PAM` class essentially implements mathematical operations that allow for the transformation of QAM symbol indices to PAM symbol indices. This can be particularly useful in scenarios involving digital communications where conversions between different modulation types or symbol indices are necessary."
"The Python package Sionna provides a function named \"verify_gm_pcm\" in the submodule \"fec.utils\" which can be used to ensure that the generator matrix and parity-check matrix are orthogonal in GF(2). This function takes as input a generator matrix (gm) and a parity-check matrix (pcm). \n\nHere is a generic step-by-step guide on how to use the \"verify_gm_pcm\" function to check for orthogonality between the generator and parity-check matrices:\n\n1. Import the necessary function from the Sionna's package:\n    ```python\n    from sionna.fec.utils import verify_gm_pcm\n    ```\n\n2. First, you'll need to obtain a generator matrix (gm) and a parity-check matrix (pcm). This can be done using appropriate methods like \"gen_gm_pcm\" or by other means suitable for your use case. Please make sure you have the appropriate generator matrix (gm) and parity-check matrix (pcm) ready before proceeding.\n\n3. Call the `verify_gm_pcm` function with the generator and parity-check matrices. For example:\n    ```python\n    result = verify_gm_pcm(gm_matrix, pcm_matrix)\n    ```\n\n4. The function will return a boolean `result`, indicating whether the matrices are orthogonal. If the result is `True`, it means the matrices are orthogonal (or very close to orthogonal within a certain numerical tolerance). If the result is `False`, it means the matrices are not orthogonal in GF(2).\n\n5. Finally, based on the verification result, you should decide appropriate actions in your code. If the matrices are orthogonal, you might proceed with further operations; otherwise, you might want to handle the error or take corrective measures like adjusting the matrices or their encoding parameters.\n\nPlease replace `gm_matrix` and `pcm_matrix` with the actual generator and parity-check matrices you want to verify. The matrices should be binary (GF(2)) matrices representing a valid linear block code, typically with shape [k, n] for the generator and [n-k, n] for the parity-check matrix.\n\nTo prevent errors, ensure that the generator matrix and parity-check matrix are initialized and represent valid code parameters. For the given context, the generator matrix (gm) is derived from a binary LDPC code for which you must have an appropriate method to generate the generator matrix. Once you have the generator matrix (gm), and assuming you also have the parity-check matrix (pcm), you can directly use the `verify_gm_pcm` function to confirm their orthogonality. \n\nWhile specifying the code parameters, be sure to adhere to the pattern expected for the matrices (shape and type), and also ensure that the actual matrices data you provide are compatible and correctly formatted for the verification process.\n\nThis instruction is based on a general understanding and assumes the availability of valid generator and parity-check matrices. Actual matrices generation and data sourcing may vary depending on the specific coding scheme and context.  The matrices' availability and correct construction are independent of the use of the `verify_gm_pcm` function. They should be obtained from appropriate matrix creation or encoding procedures in the specific coding context. The binary nature of the GF(2) ensures the application matches the use-case requirements."
"The LinearEncoder class from the sionna.fec.linear module can be imported using the following Python command:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n```\n\nThis command allows you to use the LinearEncoder class to initialize a binary linear encoder which, when given a generator or parity-check matrix, encodes messages into codewords. The context doesn't provide an explicit generator or parity-check matrix to use for the LinearEncoder, but here are a few examples of how you might initialize one:\n\n1. Using a generator matrix for encoding:\n\n```python\n# Assuming `enc_mat` is a pre-defined generator matrix\nencoder = LinearEncoder(enc_mat=enc_mat, is_pcm=False)  # Using the provided `enc_mat` as the generator matrix\n```\n\n2. Using a parity-check matrix for encoding:\n\n```python\n# Assuming `enc_mat` is a pre-defined parity-check matrix\nencoder = LinearEncoder(enc_mat=enc_mat, is_pcm=True)   # Using the provided `enc_mat` as the parity-check matrix\n```\n\nNote that in both the above cases, you need to set either `is_pcm` to False for the generator matrix or `is_pcm` to True for the parity-check matrix, as per the requirements of the LinearEncoder.\n\nPlease replace `enc_mat` with the actual matrix you intend to use for encoding. Also, ensure that the appropriate generator matrix with the name `enc_mat` is available in the context or code documentation you are referencing. The validity of the matrix is essential since an invalid matrix will most likely lead to an AssertionError. \n\nThese examples assume that a valid generator or parity-check matrix (enc_mat) is defined or imported in the current environment. Please verify the matrix availability and its import method as it is not provided directly within the given context. Importing the LinearEncoder class from sionna.fec.linear as shown does not depend on the specific presence of `enc_mat` in the environment, but its actual initialization does. So, an appropriate `enc_mat` must be identified and verified from the specific code or library documentation. This is crucial, since an invalid or improper matrix could lead to runtime errors. The `is_pcm` parameter must be set according to whether the provided matrix is a generator or parity-check matrix."
"The `OFDMDetectorWithPrior` class is an extension of the original `OFDMDetector` for Orthogonal Frequency-Division Multiplexing (OFDM)-based systems. This class assumes that prior knowledge of the transmitted data is available. It wraps a Multi-Input Multi-Output (MIMO) detector that assumes prior knowledge for use with the OFDM waveform. The actual detection process is performed by an arbitrary detector that must be provided as a callable object, which can be a function or a class instance.\n\nThis class preprocesses the OFDM resource grid after channel estimation and regularization, and computes for each receiver the effective noise caused by the residual inter-carrier interference (ICI) and the channel estimation errors. This information is combined with the channel frequency response and the prior information of the transmitted signals to compute a log-likelihood ratio (LLR). These LLRs can then be used by a separate class for further processing, such as a demapper to get symbol Logits or Log-Likelihood Ratio (LLR), or a hard-decision symbol output.\n\nAccomplishments:\n1. Channel estimation, which involves estimation of the channel state, is a crucial part of MIMO-OFDM systems. This class handles both estimation and error variance propagation, which assists in achieving reliable data transmission.\n2. The use of a callable object for the actual detection process facilitates a clean separation of tasks, making the overall design more modular.\n3. It supports prior information of the signals, which can be advantageous in certain learning or re-transmission scenarios.\n4. It can perform near maximum likelihood detection when the signal-to-noise ratio is high, which is a substantial performance benefit."
"The function `bin2int_tf` described in the provided context is part of the TensorFlow Utility functions within the Sionna Forward Error Correction (FEC) library.\n\nThe function is used to convert a binary tensor into an integer tensor. The binary representation in a given tensor is read from the last dimension of the input tensor, where the most significant bit is the first element.\n\nFor instance, a binary tensor with `arr` = [0, 1, 1] would be converted to integer tensor with the output as 3.\n\nTo use this function, you would need to pass a TensorFlow binary tensor to be converted. The tensor should have 0s and 1s, e.g., `[[0, 1, 1], [1, 0, 1]]`.\n\nPlease note that the description mentions 'TensorFlow' framework, so the actual implementation should be done accordingly, considering the usage of TensorFlow library within your Python script."
"The '5G NR' (or 'TB5G') compliant scrambling can be achieved by using the `TB5GScrambler` class from the 'sionna.fec.scrambling' module, which implements the uplink shared channel (UL-SCH) scrambling procedure according to the 3GPP 38.211 standards.\n\nHere is how you can use the `TB5GScrambler` for enabling 5G NR compliant scrambling:\n\n1. You need to import the `TB5GScrambler` class from the Sionna library:\n\n    ```python\n    from sionna.fec.scrambling import TB5GScrambler\n    ```\n\n2. You then initialize an instance of the `TB5GScrambler`, by indicating the number of coded bits and the number of layers (or \"antenna ports\") as per the 5G standard:\n\n    ```python\n    scrambler = TB5GScrambler(coded_bitsize=10000, num_layers=8)\n    ```\n\n    In this example, `coded_bitsize=10000` is the number of bits to be scrambled, and `num_layers=8` specifies the number of layers (or \"antenna ports\") for the multi-antenna system. These parameters need to be set according to your specific use case.\n\n3. Once the `TB5GScrambler` is initialized, you can use it to scramble a sequence of coded bits. The bits to be scrambled should be in the `u` list (or \"pipe\"), and the `TB5GScrambler` will generate the scrambled bits for the different layers (or \"antenna ports\"):\n\n    ```python\n    # c could also be a tf.Tensor of 0s and 1s\n    if isinstance(c, (u, tf.Tensor)):  \n        c_scr, l_scr = scrambler(c)\n    ```\n\n    Here, `c` is the list of coded bits, which is used as the input to the `TB5GScrambler`, and `c_scr` and `l_scr` are the resulting sequences of scrambled bits and layer indicators, respectively. \n\n4. After the bits are scrambled and transmitted over the channel, the channel decoder (e.g., LDPC BP decoder) will perform the decoding operation to attempt to recover the original information bits.\n\n5. The descrambler (e.g., `LDPC5GDecoder`), if necessary, will then be used to descramble the received bits, and the result (`c_hat`) of the decoding operation represents the estimated original information bits.\n\nPlease note that you should also have a \"5G channel\" to provide to the scrambler, which is not included in the provided context and should be implemented according to your specific needs (e.g., AWGN channel with binary inputs). The scrambler operates on the channel frequency, so different channel frequencies can cause different results."
"Here is the detailed information of int_mod_2:   \n  \n[sionna.fec.utils.int_mod_2(x)](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#int_mod_2)\n\nEfficient implementation of modulo 2 operation for integer inputs.\n\nThis function assumes integer inputs or implicitly casts to int.\n\nRemark: the function tf.math.mod(x, 2) is placed on the CPU and, thus, causes unnecessary memory copies.\n\n### Parameters\n\n- **x** (`tf.Tensor`):  Tensor to which the modulo 2 operation is applied. \n\n### Returns\n\n- Output with same dimension and dtype as the input `x`.\n\nsource code:\n```python\ndef int_mod_2(x):\n    # pylint: disable=line-too-long\n    \"\"\"Efficient implementation of modulo 2 operation for integer inputs.\n\n    This function assumes integer inputs or implicitly casts to int.\n\n    Remark: the function `tf.math.mod(x, 2)` is placed on the CPU and, thus,\n    causes unncessary memory copies.\n\n    Parameters\n    ----------\n    x : tf.Tensor\n        Tensor to which the modulo 2 operation is applied.\n\n    Returns\n    -------\n    : \n        Output with same dimension and dtype as the input ``x``.\n    \"\"\"\n    # The implementation only works if x is either int32 or int64. Thus, we\n    # explicetly cast to int64.\n    z = tf.math.mod(tf.cast(x, tf.int64), 2)\n    return tf.cast(z, tf.as_dtype(x.dtype))\n```"
"Here is the detailed information of SymbolSource:   \n  \n[sionna.utils.SymbolSource(name, output_dtype, trainable=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/utils/misc.html#SymbolSource)  \n\nLayer generating random QAM symbols. The symbol constellations are not normalized to facilitate channel SNR testing. It is assumed that the expected energy per (QAM) symbol is $E_s = 1$. The generated symbols are not normalized and symbol are generated with unit-variance are not modified which is different to (https://doi.org/10.1109/JSAC.2017.2771159) where the symbol are scaled1.  \n  \n### Parameters\n\n- `name` (str):  Name of the layer.\n- `output_dtype` (tf.DType): Output dtype of the layer.\n- `trainable` (bool): If `True`, the symbol source is trainable, i.e, for each\n    invocation a random symbol is generated. Defaults to `False`.\n- `dtype` (tf.DType): The dtype of the output. Defaults to `tf.complex64`.\n\n### Input\n\n- `batch_size` (int): Batch size. Must be provided at the invocation.\n\n### Output\n\n- `batch_size` (,tf.int): Batch size\n- `dtype` (,tf.DType): The generated symbols.\n\n**Note: **For convenience in (graph) execution, the exact batch dimensions `[, tf.Dimension(None)]` are not specified here but when the class is instantiated.\n\nsource code:\n```python\nclass SymbolSource(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"SymbolSource(name, output_dtype, trainable=False, dtype=tf.complex64, **kwargs)\n\n    Layer generating random QAM symbols. The symbol constellations are not\n    normalized to facilitate channel SNR testing. It is assumed that the\n    expected energy per (QAM) symbol is :math:`E_s = 1`. The generated symbols\n    are not normalized and symbol are generated with unit-variance are not\n    modified which is different to [WCP+17]_ where the symbol are scaled\n\n    to :math:`E_s`.\n\n    Parameters\n    ----------\n    name : str\n        Name of the layer.\n\n    output_dtype : tf.DType\n        Output dtype of the layer.\n\n    trainable : bool\n        If `True`, the symbol source is trainable, i.e, for each\n        invocation a random symbol is generated.\n        Defaults to `False`.\n\n    dtype : tf.DType\n        The dtype of the output.\n        Defaults to `tf.complex64`.\n\n    Input\n    -----\n    batch_size : int\n        Batch size. Must be provided at the invocation.\n\n    Output\n    ------\n    : [batch_size, tf.Dimension(None)]\n        The generated symbols.\n\n    Note\n    ----\n    For convenience in (graph) execution, the exact batch dimensions\n    `[, tf.Dimension(None)]` are not specified here but when the\n    class is instantiated.\n    \"\"\"\n\n    def __init__(self,\n                 name,\n                 output_dtype,\n                 trainable=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(name=name, dtype=dtype, **kwargs)\n\n        self._output_dtype = output_dtype\n\n        # the constellations are not normalized to facilitate channel SNR\n        # testing. It is assumed that the expected energy per (QAM) symbol is\n        # Es = 1. The generated symbols are not normalized and symbol are\n        # generated with unit-variance are not modified which is different to\n        # [WCP17] where the symbol are scaled to Es.\n        self._constellation = Constellation(\"qam\", num_bits=1, dtype=dtype)\n        self._trainable = trainable\n\n    # as the constellations are not normalized to facilitate channel SNR\n    # testing. It is assumed that the expected energy per (QAM) symbol is\n    # Es = 1. The generated symbols are not normalized and symbol are\n    # generated with unit-variance are not modified which is different to\n    # [WCP17] where the symbol are scaled to Es.\n    def _get_constellation(self):\n        bits = sn.utils.int_to_bits([x for x in range(2**self.num_bits)],\n                                     self.num_bits)\n        symbols = 2 * bits - 1 # QAM symbols {-1, 1}\n        if issubclass(self._output_dtype, tf.complex):\n            symbols = sn.utils.expand_to_rank(tf.complex(symbols, 0),\n                                               len(symbols.shape))\n        return tf.cast(symbols, self._output_dtype)\n\n    def build(self, input_shape): #pylint: disable=unused-argument\n        if self._trainable:\n            self._ind = self.add_weight(shape=[1],\n                                      initializer=\"uniform\",\n                                      trainable=False,\n                                      dtype=tf.int32)\n        else:\n            self._ind = tf.constant(0, tf.int32)\n\n    def call(self,  batch_size): #pylint: disable=unused-argument\n        ind = self._ind # pylint: disable=used-before-define\n        c = self.constellation\n        x = tf.gather(c, ind, axis=0)\n        x = tf.cast(x, self._output_dtype)\n        if self._trainable:\n            # setting the symbol to be trainable\n            x = tf.Variable(x,\n                             trainable=True,\n                             dtype=x.dtype)\n            ind.assign_add(1)\n        return x\n```\n\n  "
"Here is the detailed information of ChannelModel:   \n  \nInput\n\nbatch_size (int): Batch size\n\nnum_rx (int): Number of receivers ($N_R})\n\nnum_rx_ant (int): Number of antennas per receiver ($N_{RA}$)\n\nnum_tx (int): Number of transmitters ($N_T$)\n\nnum_tx_ant (int): Number of antennas per transmitter ($N_{TA}$)\n\nnum_paths (int): Number of paths ($M$)\n\nnum_time_steps (int): Number of time steps\n\nsampling_frequency (float): Sampling frequency [Hz]\n\ndtype (tf.DType): Defines the datatype for internal calculations and the output dtype. Defaults to tf.complex64. Channel impulse responses ($a_\\ell, \\tau_\\ell$) are computed in this dtype, but coefficients ($a$) and delays ($\\tau$) can be cast to another dtype (e.g., tf.float32) if required.\n\nOutput\n\na ([batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex) \u2013 Path coefficients\n\ntau ([batch size, num_rx, num_tx, num_paths], tf.float) \u2013 Path delays [s]\n\nThe source code of ChannelModel is here:  \n```python\nclass ChannelModel(ABC):\n    r\"\"\"Abstract class that defines an interface for channel models.\n\n    Any channel model which generates channel impulse responses\n    must implement this interface.\n    All the channel models available in Sionna, such as\n    :class:`~sionna.channel.wireless.RayleighBlockFading`, or\n    :class:`~sionna.channel.wireless.TDL`, implement this\n    interface.\n\n    Input\n    ------\n    batch_size : int\n        Batch size\n\n    num_time_steps : int\n        Number of time steps\n\n    sampling_frequency : float\n        Sampling frequency [Hz]\n\n    Output\n    -------\n    a : [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex\n        Path coefficients\n\n    tau : [batch size, num_rx, num_tx, num_paths], tf.float\n        Path delays [s]\n    \"\"\"\n\n    @abstractmethod\n    def __call__(self, batch_size, num_time_steps, sampling_frequency):\n        # pragma: no cover\n        pass\n```  \n  "
"There are two ways to build a custom `RadioMaterial` in Sionna and attach it to a `SceneObject`. The first way involves setting the material properties directly, and the second way entails defining a callback function that computes the material properties from the frequency. \n\nHere's how you can create a custom `RadioMaterial` and add it to a `SceneObject` using the first approach:\n\n1. Define the material properties\n```python\ncustom_material = RadioMaterial(\"my_material\",\n                                relative_permittivity=2.0,\n                                conductivity=5.0,\n                                scattering_coefficient=0.3,\n                                xpd_coefficient=0.1,\n                                scattering_pattern=LambertianPattern())\n```\nIn the above code, `my_material` is the name of your custom material, and you can replace the values after the equals sign with the desired material properties. The properties include `relative_permittivity`, `conductivity`, `scattering_coefficient`, `xpd_coefficient`, and `scattering_pattern`. \n\n2. Once you've defined your material, you can attach it to a `SceneObject`. For example, if you have a `SceneObject` named `obj`, you can set the material as follows:\n```python\nobj = scene.get(\"my_object\") # Getting the SceneObject\nobj.radio_material = \"my_material\" # Setting the material\n```\nPlease ensure to replace `\"my_object\"` with the actual name of your object in the `Scene`. The `radio_material` attribute is used to set the material of the `SceneObject`.\n\nThe second method for creating a custom `RadioMaterial` involves a callback function that computes the material properties from the frequency. This method is particularly useful if you want the material properties to be dependent on the frequency. The callback function takes the frequency as an input and must return the material properties (relative permittivity and conductivity) as a tuple.\n\nHere's an example of how you can define a callback function for the custom `RadioMaterial`:\n```python\ndef my_material_callback(f_hz):\n   relative_permittivity = compute_relative_permittivity(f_hz)\n   conductivity = compute_conductivity(f_hz)\n   return (relative_permittivity, conductivity)\ncustom_material = RadioMaterial(\"my_material\",\n                                frequency_update_callback=my_material_callback)\n```\nIn the `my_material_callback` function, you would need to compute the relative permittivity and conductivity for the given frequency. This could involve complex operations, such as fetching the permittivity and conductivity from an external database and possibly doing some numerical transformations on the obtained values. Please note that the `compute_relative_permittivity` and `compute_conductivity` functions are hypothetical and you would need to write your own functions to compute the material properties based on the frequency.\n\nAfter defining the callback function, you can attach the custom material to a `SceneObject` as shown in the first method.\n\nRemember to replace `\"my_object\"` with the actual name of your `SceneObject` and `\"my_material\"` with a unique name for your material. The material properties in these examples (`\"my_material\"`) should be replaced with actual properties according to your needs.\n\nCreating custom materials can be very intricate depending on the physical properties you want to emulate. The Sionna RT API documentation provides detailed information about the parameters accepted for material creation and the requirements for a material update callback function, which would be necessary for implementing a custom material."
"For maximum a posteriori (MAP) decoding using the `BCJRDecoder` instance from the Sionna library, you would set up the decoder and then call its `decode()` method with the appropriate input LLRs. The `hard_out` parameter in this context controls whether the decoded output is represented as hard or soft decisions, and it is related to the way that the decoder outputs are mapped from bit representations to the actual decoded bits.\n\nHere's what each possible type of input for the `llr_ch` parameter means:\n\n1. If `llr_ch` is a single 2+D tensor (no a priori information):\n```python\nllr_ch = tf.random.normal(shape, dtype=tf.float32)\ndecoder = sionna.fec.conv.BCJRDecoder(conn)\nb_hat = decoder(llr_ch)\n```\nIn this case, `llr_ch` should be a 2+D tensor that contains the channel Log-Likelihood Ratios (LLRs) with a data type of `tf.float32`. The `hard_out` parameter for this type of input is boolean, and if set to `True`, the decoder will output hard decisions (0/1) for each bit. The shape of the output `b_hat` would match the trailing dimensions of the input `llr_ch`.\n\n2. If `llr_ch` is a tuple including a 2+D tensor for the channel and an (optional) 2+D tensor for the a priori information:\n```python\nllr_ch = (tf.random.normal(shape, dtype=tf.float32), tf.random.normal(shape, dtype=tf.float32))\ndecoder = sionna.fec.conv.BCJRDecoder(conn)\nb_hat = decoder(llr_ch)\n```\nFor this case, if the `hard_out` parameter is set to `True`, the decoder will provide hard decisions on the decoded bits, which would be a 2+D tensor of integers with the actual decoded bit values. The `hard_out` parameter being `True` implies that each bit is decoded as 0 or 1 (i.e., a hard decision). The output `b_hat` tensor would match the trailing dimensions of the input `llr_ch` tuple.\n\nThe type of output tensor (`b_hat`) that the `BCJRDecoder` produces is controlled by the `hard_out` parameter:\n\n- If `hard_out` is `True`, the output is a hard-decided binary sequence of bits. The data type of the output tensor would be `tf.int32` and would have the same shape as the last dimension of the input LLR tensor.\n- If `hard_out` is `False` or not provided, the output is a soft-decision LLR sequence, which represents the likelihood of each bit being a 0 or 1. The data type of the output tensor would be `tf.float32` and would have the same shape as the last dimension minus one of the input LLR tensor (since the parity bits are not part of the output).\n\nIt's important to note that when performing MAP decoding, a hard decision is equivalent to obtaining the most likely (most probable) output bit, which, in the case of the BCJR algorithm, involves considering the accumulated path metrics to find the most likely state and, subsequently, the most likely bit transition at each stage of the trellis.\n\nThe specific shape of the output tensor depends on the shape of the input LLR tensor. The output tensor is a 2+D tensor because the decoding process may generate multiple decoded bit streams (for the `ViterbiDecoder`, for instance, you would have a separate bit stream for each possible decoded codeword). The decoding algorithm produces, for each potential bit sequence, a result that captures the estimated/corrected bits for the information word, along with corresponding estimated/corrected parity bits. This is represented in the form of a 2+D tensor because there could be multiple possible decoded codewords that need to be considered."
"Using the `sionna.utils.ebnodb2no` function is pretty straightforward. This function is utilized to compute the noise variance per complex dimension given an Eb/No value in dB, the number of bits per constellation symbol, the coderate, and for optional use, specific resource grid configuration for OFDM transmissions.\n\nHere is the breakdown of the inputs:\n- **ebno_db** (float): This is the Eb/No value in dB. This value is used to compute the noise variance, and it's effectively the signal-to-noise ratio.\n- **num_bits_per_symbol** (int): You need to specify the number of bits per constellation symbol. For, e.g., a 16-QAM modulation, there are 16 constellation symbols, and for each symbol, you would need to transmit a specified number of bits.\n- **coderate** (float): The coderate is the rate of a forward error correction code. It's equal to the ratio of the number of data bits (or source symbols) to the number of coded bits (or channel symbols).\n- **resource_grid** (sionna.ofdm.ResourceGrid): This is an instance of the `ResourceGrid` class and is optional. It's used to compute the number of transmitted streams and the energy per resource grid element. An OFDM resource grid defines on which of the  resource elements a stream is transmitted.\n\nHere is the breakdown of the output:\n- **no** (float): This function outputs the value of the noise variance per complex dimension in linear scale. This value is derived from the input parameters and is essentially the theoretical noise power that you'd expect in the received signal. \n\nTo use the function, you would input your own values for the above-listed parameters that suit your specific simulation scenario. Based on the given context, the function would be called like this:\n\n```python\nimport sionna\n\n# Other parameter values from your scenario\nebno_db = 5.0\nnum_bits_per_symbol = 4\ncoderate = 0.8\n# Assuming you have an instance of ResourceGrid\nrg = sionna.ofdm.ResourceGrid()\nno = sionna.utils.ebnodb2no(ebno_db, num_bits_per_symbol, coderate, rg)\n```\nKeep in mind that the actual values for `ebno_db`, `num_bits_per_symbol`, and `coderate` should be selected based on your specific simulation requirements. If you're simulating an OFDM-based system, you'd also need to create an instance of the `ResourceGrid` to pass as the `resource_grid` parameter. If you don't have or need an instance of `ResourceGrid`, you can omit that parameter."
"To evaluate the baseline and the two autoencoder-based communication systems, you can follow these steps:\n\n1. **Baseline Model** (provided in the context as `Baseline`):\n   - Create an instance of the `Baseline` model, which is set up for LDPC encoding and decoding with a 5G-compliant code and QAM modulation with Gray labeling.\n   - Use the `Simulation` class to run a bit-wise simulation of the model over a range of SNRs (defined earlier in the context as `ebno_dbs`).\n   - The `Simulation` class will automatically stop and start TensorBoard, so you can set the `stop_tensorboard=False` to prevent it from stopping, or set `auto_stop=True` to make it stop after the simulation.\n   - The results of the simulation will be recorded in a log directory, which you can specify when creating the instance of the `Baseline` model.\n\n2. **Autoencoder-Based Communication System 1** (not provided, you need to implement it):\n   - Create a class for the first autoencoder-based system, let's call it `AESystem1`. This class should be based on the `Baseline` model and include the necessary components for the first autoencoder-based system. It should use the binary cross entropy (BCE) as the loss function.\n   - Create an instance of the `AESystem1` model by specifying the autoencoder-based parameters and using them to initialize the model.\n\n3. **Autoencoder-Based Communication System 2** (not provided, you need to implement it):\n   - Create a class for the second autoencoder-based system, let's call it `AESystem2`. This class should be based on the `Baseline` model and include the necessary components for the second autoencoder-based system. It should use the binary cross entropy (BCE) as the loss function.\n   - Create an instance of the `AESystem2` model by specifying the autoencoder-based parameters and using them to initialize the model.\n\n4. **Evaluating the Models**:\n   - To evaluate the models, you can use the `plot_ber` function from the `notebooks.utils` module. This function will plot the bit error rate (BER) for each model over a range of SNRs.\n   - You can also use the `PlotBER` class for a more detailed and customized plot of the BER.\n\nRemember to ensure that the implemented models (`AESystem1` and `AESystem2`) match the descriptions provided in the context. You may need to refer to additional source code or resources that were not provided in the context to complete this."
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can follow these steps:\n\n1. List all the available GPUs using the `tf.config.list_physical_devices('GPU')` command. This will return a list of all the available GPU devices.\n\n2. Print the list of available GPUs to the console to inform you about which GPUs are available for computation.\n\n3. If multiple GPUs are available, you can choose to use only one of them. For example, if you want to use the first GPU, you can set `gpu_num = 0`. This number will be used to refer to the selected GPU throughout the configuration.\n\n4. To allocate only as much memory as needed, you need to set `tf.config.experimental.set_memory_growth` to `True`. This will allow TensorFlow to allocate only as much GPU memory as needed for the runtime allocations. \n\n5. If you encounter any RuntimeError, such as when the set of visible devices is non-empty, you can catch the error and print it to the console.\n\n6. If you want to be able to switch back to GPU memory, you can set `tf.config.set_visible_devices([], 'GPU')`. This will list all the available GPU devices that are available for TensorFlow. \n\n7. Finally, to avoid any warnings from TensorFlow, you can set `tf.get_logger().setLevel('ERROR')` to ensure that only the important messages are printed to the console.\n\nPlease note that the code provided in the context is written in Python using the TensorFlow library. The code is written within a Python notebook environment, and it is used to configure the notebook to use only a single GPU and allocate only as much memory as needed. \n\nThe context provides the following code snippets to illustrate the configuration:\n\n```python\ngpus = tf.config.list_physical_devices('GPU')\nprint('Number of GPUs available :', len(gpus))\nif gpus:\n    gpu_num = 0 # Index of the GPU to be used\n    try:\n        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n        print('Only GPU number', gpu_num, 'used.')\n        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n    except RuntimeError as e:\n        print(e)\n```\n\n```python\ntf.config.set_visible_devices([], 'GPU')\ntf.get_logger().setLevel('ERROR')\n```\n\nThis code first lists all the available GPUs and then tries to set the notebook to use only a single GPU. If the set of visible devices is non-empty, it will catch a RuntimeError and print the error message. The `tf.config.set_visible_devices` function is used to ensure that the system is not limited to the GPU memory. The `tf.get_logger().setLevel('ERROR')` is used to set the level of the logger to ensure that only the important messages are printed."
"To calculate the J-function in the Sionna package, you can use the `j_fun` function, which is part of the `sionna.mimo.utils` module. The `j_fun` function is used to measure the quality of a numerical Moebius (or log-Euclidean) approximation by relating it to a matrix with a similar eigenvalue distribution but different condition number. \n\nHere's how you can use the `j_fun` function:\n\n```python\nfrom sionna.mimo.utils import j_fun\n\n# Replace 'T' and 'T_inv' with your own tensors\nj = j_fun(T, T_inv)\n```\n\nYou need to pass two arguments to the `j_fun` function:\n\n1. The first argument (`T`) is a tensor of shape `(..., n, n)` containing numerical Moebius (or log-Euclidean) transformations. \n2. The second argument (`T_inv`) is a tensor of the same shape and type as `T` containing the inverses of the transformations in `T`.\n\nThe function will return the `J` values as an output, which is a tensor of shape `(..., n)`. Please note that the `(..., n)` shape for the `J` values means that `J` is computed for each pair of numerical transformations in `T`.\n\nMake sure that the tensors you pass as arguments to the `j_fun` function are of the correct type and shape, as an error will be raised if they are not. The `T` and `T_inv` tensors should contain numerical Moebius transformations, which are typically obtained as outputs from functions that calculate Moebius or log-Euclidean transformations."
"Here is the definition of PUSCHTransmitter: sionna.nr.PUSCHTransmitter(pusch_configs, channel_estimator=None, add_awgn=True, return_channel_freq=False, l_min=None, dtype=tf.complex64, **kwargs).  \n\n[source code](https://nvlabs.github.io/sionna/_modules/sionna/nr/pusch_transmitter.html#PUSCHTransmitter)\n\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"Transmitter components for simulating 5G NR PUSCH Slots\"\"\"\"\"\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Layer\nimport numpy as np\nimport sionna\nfrom sionna.ofdm import OFDMModulator\nfrom sionna.channel import ChannelTime\nfrom sionna.nr.pusch_config import PUSCHConfig\nfrom sionna.mimo import StreamManagement\nfrom sionna.utils import insert_dims\nfrom .prach_transmitter import PRACHTransmitter\nfrom .pusch_resources_grid import PUSCHResourcesGrid\nfrom .dmrs import DMRS\n\nclass PUSCHTransmitter(Layer):\n    # pylint: disable=line-too-long\n    def __init__(self,\n                 pusch_configs,\n                 channel_estimator=None,\n                 add_awgn=True,\n                 return_channel_freq=False,\n                 l_min=None,\n                 dtype=tf.complex64,\n                 **kwargs):\n        r\"\"\"\n        Initializes the PUSCH Transmitter.\n\n        If ``channel_estimator`` is not `None`, the transmitter will\n        use the previded channel estimate for precoding. This can be used\n        to implement closed-loop MIMO.\n\n        Parameters\n        ----------\n        pusch_configs : list, [PUSCHConfig, ...], tf.complex\n            List of :class:`~sionna.nr.PUSCHConfig` objects for every\n            transmitter.\n\n        channel_estimator : :class:`~sionna.channel.ChannelEstimator` or None\n            :class:`~sionna.channel.ChannelEstimator` object to be used for\n            estimation and/or ``None``.\n\n        add_awgn : bool\n            If set to `False`, no white Gaussian noise is added.\n            Defaults to `True`.\n\n        return_channel_freq : bool\n            If set to `True`, the frequency domain channel\n            response is returned.\n            Defaults to `False`.\n\n        l_min : int or None\n            An integer defining the first OFDM\n            resource to be used for data transmission for all transmitters.\n            If set to `None`, :math:`l_\\mathrm{min} = 0` for all transmitters\n            will be internally used.\n            Defaults to `None`.\n\n        dtype : tf.Dtype\n            Data type for internal calculations and output.\n            Defaults to `tf.complex64`.\n        \"\"\"\n        super().__init__(**kwargs)\n        assert isinstance(pusch_configs, list), \\\n                        \"pusch_configs must be a list\"\n        for c in pusch_configs:\n            assert isinstance(c, PUSCHConfig), \\\n                                \"Each element of pusch_configs must be a PUSCHConfig\"\n        self._n_Tx = len(pusch_configs)\n\n        # Instantiate one OFDM Modulator that will be shared by all transmitters\n        self._ofdm_modulator = OFDMModulator(fft_size=channel_estimator.fft_size,\n                                              l_subcarrier=1,\n                                              l_cyclic_prefix=0)\n\n        # Determine maximum length of PDSCH and DMRS mask\n        max_pdsch_len = 0\n        max_dmrs_len = 0\n        for pusch_config in pusch_configs:\n            max_pdsch_len = max(max_pdsch_len,\n                               PUSCHResourcesGrid(pusch_config).pdsch_data.size)\n            num_cdm_groups_without_data = pusch_config.dmrs.num_cdm_groups_without_data\n            num_cdm_groups = np.prod(num_cdm_groups_without_data)\n            max_dmrs_len = max(max_pdsch_len, num_cdm_groups*pusch_config.dmrs.num_layers)\n        max_pdsch_len = max(max_pdsch_len, 1)\n        max_dmrs_len = max(max_dmrs_len, 1)\n        l_pdsch_max = int(np.sqrt(max_pdsch_len))\n        l_dmrs_max = int(np.sqrt(max_dmrs_len))\n\n        # The cyclic shift l_min must not be larger that the smallest cyclic delay\n        # in the channel. We do not verify this condition as it\n        # is impossible to do for all channel realizations.\n        # However, this will result in a non-circularly shifted PUSCH\n        # (and hence a inter-symbol interference) if l_min is choosen\n        # to small. l_min=0 is always safe for TDL.\n        l_min = np.array(l_min)\n        self.l_min = l_min\n\n        self._add_awgn = add_awgn\n        self._return_channel_freq = return_channel_freq\n        self._channel_estimator = channel_estimator\n        self._dmrs = DMRS(pusch_configs[0].dmrs) # All DMRS Configurations are alike\n        self._resource_grid = PUSCHResourcesGrid(self._dmrs, l_min, add_pilot=True)\n\n        # Determine how the DMRS is mapped on the resource grid for every\n        # PUSCH transmitter.\n        mask = self._resource_grid.build_grid(self._dmrs, num_bp=0)\n        num_cdm_groups_without_data = pusch_configs[0].dmrs.num_cdm_groups_without_data\n        num_cdm_groups = np.prod(num_cdm_groups_without_data)\n        cdm_index = np.arange(num_cdm_groups) + 1\n        cdm_index = np.take(cdm_index, np.argsort(np.mod(cdm_index, 4)))\n        self._dmrs_ind = np.zeros([self._n_Tx, self._dmrs.num_layers,\n                                    self._resource_grid.num_ofdm_symbols,\n                                    l_pdsch_max, 12], dtype=np.int32)\n        dmrs_symbols = np.where(np.sum(np.abs(mask), axis=-1) > 0)[0]\n        for tx_num in range(self._n_Tx):\n            for l in range(self._dmrs.num_layers):\n                for k in dmrs_symbols:\n                    self._dmrs_ind[tx_num, l, k] = \\\n                        np.transpose(np.vstack(\n                            [np.zeros([num_cdm_groups_without_data[0], 12]),\n                             np.transpose(np.zeros([12, num_cdm_groups_without_data[1]]),\n                                          [1,0])],\n                            [cdm_index[2*tx_num  , :],\n                             cdm_index[2*tx_num+1, :]]),\n                            [1,0])\n\n        self._stream_management = StreamManagement(\n                                    num_rx=channel_estimator.num_rx,\n                                    num_streams_per_rx=channel_estimator.num_streams_per_rx,\n                                    num_tx=self._n_Tx,\n                                    num_streams_per_tx = pusch_configs[0].num_layers if \"num_layers\" in pusch_configs[0].dmrs else 1,\n                                    \"p2s\",\n                                    l_min=l_min)\n\n        # Instantiate an scrambler with seed 1 which will be used to\n        # \"randomly\" generate the information bits. As the seed is set to \"1\",\n        # the scrambler will always produce the same sequence of \"random\"\n        # bits, which is required to be able to serialize the scrambler.\n        self._scrambler = sionna.channel.Scrambler(seed=1)\n\n        if self._add_awgn:\n            self._no = sionna.utils.expand_to_rank(sionna.constants.NO,\n                                                3, \"last\")\n        self._dtype = dtype\n\n    #########################################\n    # Public methods and properties\n    #########################################\n\n    @property\n    def resource_grid(self):\n        \"\"\"\n        :class:`~sionna.nr.PUSCHResourcesGrid`: The resource grid\n            that is used to map the PUSCH and DMRS.\n        \"\"\"\n        return self._resource_grid\n\n    @property\n    def dmrs_grid(self):\n        \"\"\"\n        :class:`~sionna.nr.PUSCHDMRSMask`: Provides the indices\n            on the resource grid that are DMRS mapped.\n        \"\"\"\n        return self._dmrs.dmrs_grid\n\n    @property\n    def pdsch_grid(self):\n        \"\"\"\n        :class:`~sionna.nr.PUSCHPDSCHMask`: Provides the indices\n            on the resource grid that are PDSCH mapped.\n        \"\"\"\n        return self._resource_grid.pdsch_grid\n\n    def call(self, inputs):\n        \"\"\"This method is used to get the channel outputs of all transmitters.\n\n        This method returns differentiable channel outputs of all transmitters\n        and corresponding noise if ``add_awgn`` is `True`.\n\n        Args:\n            inputs (tuple):\n                * info_bits : Tensor, transmitted information bits.\n                               The last dimension must be equal `pusch_config.tb_size`.\n                * no (or None): Tensor, the noise variance that will be\n                               added to the channel. Set to `None` to disable\n                               the noise. The noise variance can be\n                               either a scalar or of any shape which can be\n                               broadcasted to the shape of the channel outputs.\n\n        Returns:\n            * `x` or `(x,no)` \u2013 Channel outputs of all transmitters.\n                `x` is a tensor of tf.complex64 containing the channel outputs.\n                `no` is a tensor of tf.float containing the noise.\n                It is only returned if ``no`` is not `None`.\n        \"\"\"\n        if len(inputs)>2:\n            raise ValueError(\"to many inputs\")\n\n        if self._add_awgn:\n            if len(inputs)<2:\n                raise ValueError(\"no information bits and noise variance provided.\")\n            else:\n                info_bits, no = inputs\n        else:\n            info_bits = inputs\n\n        # Convert info bits to complex-valued channel inputs\n        x = self._scrambler(info_bits)\n        x = 2*x-1\n        #\n        # Generate PDSCH and DMRS Configurations\n        #\n        # An empty pdsch_config is generated as its parameters depend on the\n        # (optional) provided dmrs_config.\n        dmrs_config = self._dmrs.generate_config()\n        pdsch_config = PUSCHConfig(modulation_order=dmrs_config.modulation_order)\n        num_bits_per_symbol = pdsch_config.modulation_order\n        num_cdm_groups_without_data = pdsch_config.dmrs.num_cdm_groups_without_data\n        num_data_symbols = np.sum(self.pdsch_grid) # Number of data-carrying symbols\n\n        # Scrambler\n        # ---------\n        # For TB9, the input seed should be 127 and for TBn (n>=0) it should be in\n        # the range from 0 to 2**31-1.\n        # We do not support TBn with n>0 as this is deprecated.\n        if pdsch_config.tb_size==0: # TB0\n            seed = 127\n        elif pdsch_config.tb_size==1:  # TB1\n            seed = 0\n        else:\n            raise ValueError(\"TBn with n>0 are deprecated.\")\n\n        if pdsch_config.crc.scrambler\n            # Only use if rnti is set. This is not required for n!=0 TDD as the\n            # system level model would set the n_rnti and the PUSCH transmitter\n            # uses the same scrambler as for PUSCH.\n            if dmrs_config.rnti is not None:\n                seed = dmrs_config.rnti\n        x_out =  self._scrambler([x, seed])\n        x = x_out[0]\n\n        # TB Encoder\n        # -----------\n        # The TB encoder produced LDPC codeword. For now, we ignore the\n        # puncturing and shortening.\n        # So we get num_bits_per_symbol from the TB encoder...\n        tb_encoder = sionna.nr.TBEncoder(pdsch_config.tb_size,\n                                         pdsch_config.crc.crc_degree,\n                                         \"Z38499\")\n        cw = tb_encoder(x) # LDPC Codeword\n\n        # Constellation Mapper\n        # ---------------------\n        # We use a Mapper that maps the bit labels 0 and 1 to -1 and +1\n        # We support \"d\" and \"c\" as two different \"null\" subcarrier indicators.\n        # The \"c\" configuration is alignet to the 3GPP \"c\" table, according to\n        # which the last (!) two subcarriers are nulled.\n        if pdsch_config.mapping_type == \"dft\" :\n            # Apply DMRS scrambling if required\n            if self._channel_estimator is not None:\n                # For the \"estimation-first\" approach, we use the nulled\n                # subcarrier configuration \"c\"\n                if dmrs_config.dmrs_type==\"port\":\n                    n_symb = self._channel_estimator.num_symb[\"dft\"]\n                    ifl = np.zeros([n_symb, num_cdm_groups_without_data*2])\n                    for l in dmrs_symbols:\n                        if np.mod(l,2)==0:\n                            ifl[l] = dmrs_config.c[\"d\"]\n                        else:\n                            ifl[l] = dmrs_config.c[\"d\"] + 1\n                else:\n                    n_symb = self._channel_estimator.num_symb[\"dft\"]\n                    ifl = np.zeros([n_symb, num_cdm_groups_without_data])\n                    for l in dmrs_symbols:\n                        if np.mod(l,2)==0:\n                            ifl[l] = 0\n                        else:\n                            ifl[l] = 1\n                x = x[0]\n            else: # \"perfect-csi\"\n                n_symb = 14\n                ifl = np.zeros([n_symb, num_cdm_groups_without_data*2])\n                for l in dmrs_symbols:\n                    if np.mod(l,2)==0:\n                        ifl[l] = 0\n                    else:\n                        ifl[l] = 1\n                cw = insert_dims(cw, 2, num_cdm_groups_without_data)\n                x = np.zeros([num_cdm_groups_without_data*2, 12])\n                for m in range(num_cdm_groups_without_data):\n                    k = 0\n                    for l in dmrs_symbols:\n                        x[2*m,  2*k]   = np.complex(\n                            (-1)**ifl[l,2*m  ], (-1)**ifl[l,2*m  +1])\n                        x[2*m,  2*k+1] = np.complex(\n                            (-1)**ifl[l,2*m  ], (-1)**ifl[l,2*m  +1])\n                        x[2*m+1, 2*k]   = np.complex(\n                            (-1)**ifl[l,2*m  ], (-1)**ifl[l,2*m  +1])\n                        x[2*m+1, 2*k+1] = np.complex(\n                            (-1)**ifl[l,2*m  ], (-1)**ifl[l,2*m  +1])\n                        k = k + 1\n\n        z =  self._ofdm_modulator(x[..., :num_bits_per_symbol])\n        z = z[:, self.l_min-l_pdsch_max:self.l_min-l_pdsch_max+num_data_symbols]\n        z = tf.signal.fft(z)\n\n        # Apply DMRS\n        # ------------\n        if self._channel_estimator is not None:\n            # n_rnti must be set if used with \"estimation-first\" approach\n            z = self._dmrs.apply_dmrs(z, ifl=ifl)\n\n        if self._return_channel_freq and not self._add_awgn:\n            return z\n        elif not self._add_awgn:\n            return z, no\n        else:\n            # Add noise\n            e = self._no*tf.complex(tf.random.normal(\n                                    tf.shape(cw), json_config[\"dtype\"].real_dtype),\n                                    tf.random.normal(\n                                    tf.shape(cw), json_config[\"dtype\"].real_dtype))\n            z = z + e\n            return z\n```"
"Here is the detailed information of the function: \n\nInput parameters: \n   - gm (ndarray) \u2013 Binary generator matrix of shape [k, n].\n   - pcm (ndarray) \u2013 Binary parity-check matrix of shape [n-k, n].\n\nReturn: \n    bool: True if gm and pcm are orthogonal, False otherwise.  \n  \nNote: \n    For full understanding, one should know the concept of parity-check matrices and the code structure related to linear block code, which is beyond the scope of providing here.     \n  \nThe source code link of the function: [verify_gm_pcm](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#verify_gm_pcm)  \n  \nsource code:\n```python\ndef verify_gm_pcm(gm, pcm):\n     # pylint: disable=line-too-long\n    r\"\"\"\n    Verify that generator matrix :math:`\\mathbf{G}` `gm` and parity-check\n    \n    matrix :math:`\\mathbf{H}``pcm`` are orthogonal in GF(2).\n\n    For an all-zero syndrome, it must hold that\n\n    .. math::\n\n        \\mathbf{H} \\mathbf{c}^t = \\mathbf{H} * (\\mathbf{u} * \\mathbf{G})^t =\n        \\mathbf{H} * \\mathbf{G} ^t * \\mathbf{u}^t =: \\mathbf{0}\n\n    where :math:`\\mathbf{c}` denotes an arbitrary codeword and\n    :math:`\\mathbf{u}` the corresponding information bits.\n\n    As :math:`\\mathbf{u}` can be arbitrary it follows that\n\n    .. math::\n\n        \\mathbf{H} * \\mathbf{G} ^t =: \\mathbf{0}.\n\n    Input\n    -----\n    gm : ndarray\n        Binary generator matrix of shape `[k, n]`.\n\n    pcm : ndarray\n        Binary parity-check matrix of shape `[n-k, n]`.\n\n    Output\n    ------\n    : bool\n        True if ``gm`` and ``pcm`` are orthogonal, False otherwise.\n\n    Note\n    ----\n    One should be careful when this function returns ``True``.\n    This doesn't mean that ``pcm`` is actually a valid parity-check matrix!\n    It just means that the all-one codeword is part of the linear code\n    spanned by the rows of the generator matrix.\n    \"\"\"\n    # This function returns True if G and H are orthogonal,\n    # i.e. if all non-vanishing dot products equal 0.\n    # This can tell us if the PCM can be generated from the GM.\n\n    k = np.shape(gm)[0]\n    n = np.shape(gm)[1]\n\n    # Quick check if the shapes are consistent with a generator and\n    # parity-check matrix\n    if (np.shape(pcm)[0] == n-k) & (set_ones(np.zeros(n), gm=gm) is not None):\n        # If this code is reached, the all-one codeword is part of the code.\n        # We can therefore initialize the dot product matrix with ones.\n        # We do not need to check the exact positions where the dot product\n        # is non-zero (i.e. the other codewords), as the all-one codeword is\n        # part of the set of all codewords.\n\n        dot_mat = np.ones((n, n), np.uint8)\n        # Codeword bits set to 0\n        pcm_zero = np.logical_not(pcm).astype(np.uint8)\n        dot_mat =  dot_mat - mat_bin.cdot(pcm_zero, pcm_zero.T)\n        # Generator bits set to 0\n        gm_zero = np.logical_not(gm).astype(np.uint8)\n        dot_mat =  dot_mat - mat_bin.cdot(gm_zero, gm_zero.T)\n        if np.any(dot_mat):\n            # There is at least one non-orthogonal dot product\n            return False\n    else:\n        # Invalid matrix conditions\n        return False\n    # All dot products are zero\n    return True\n```  \n  "
"To define the concepts of permittivity and permeability, it is necessary to understand the context in which they are used. In the given context, these concepts are related to electromagnetics, specifically in the context of modeling the propagation of electromagnetic waves.\n\nPermittivity:\nPermittivity is a measure of how an electric field affects and subsequently, polarizes a dielectric or insulating material. It is denoted by the symbol epsilon (\u03b5) and is a function of the material in question. The formula for calculating permittivity is given as:\n\n    \u03b5 = \u03b5\u1d63 + j(\u03c3 / \u03c9)\n    \nwhere:\n    - \u03b5\u1d63 is the real part of permittivity, known as absolute permittivity\n    - \u03c3 is the conductivity of the material\n    - \u03c9 is the angular frequency of the signal\n\nPermeability:\nPermeability, on the other hand, is a measure of the ability of a material to support the formation of a magnetic field within itself. It is denoted by the symbol 'mu' (\u03bc) and also depends on the material. The formula for calculating permeability is:\n\n    \u03bc = \u03bc\u1d63 + j(\u03c3 / \u03c9)\n    \nwhere:\n    - \u03bc\u1d63 is the real part of permeability, known as absolute permeability\n    - \u03c3 is the conductivity of the material\n    - \u03c9 is the angular frequency of the signal\n\nIn the context provided, the text mentions that the electric permittivity (\u03b5) and magnetic permeability (\u03bc) are two of the most important material parameters in electromagnetics. These two parameters are used to calculate the wave number, which is a fundamental quantity in wave propagation theory.\n\nIt should be noted that the given context does not provide specific details on how the conductivity (\u03c3) and the angular frequency (\u03c9) are determined or what units are used for these quantities. For a complete understanding, one would need to refer to additional reference materials that discuss these topics in more detail."
"\u8fd4\u56de\u7684\u94fe\u63a5\u662f\u6e90\u4ee3\u7801\u94fe\u63a5\uff0c\u653e\u5728\u4e0b\u65b9\u56de\u7b54\u4e2d\u3002  \nsource code: https://nvlabs.github.io/sionna/_modules/sionna/channel/utils.html#RemoveNulledSubcarriers  \n  \n\n```python\nclass RemoveNulledSubcarriers(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"RemoveNulledSubcarriers(nulled_subcarrier_ind, num_subcarriers, dtype=tf.complex64)\n\n    This class removes nulled subcarriers from an OFDM resource grid.\n    The resource grid is structured as :math:`[N, num\\_ofdm\\_symbols]` or\n    :math:`[num\\_ofdm\\_symbols, N]` , i.e., ``[num_subcarriers, num_ofdm_symbols]``.\n    Note that the  nulled subcarriers  are removed (and not nulled) by this\n    layer.\n\n    Parameters\n    ----------\n        nulled_subcarrier_ind : int\n            Index of the nulled subcarrier.\n\n        num_subcarriers : int\n            Number of subcarriers.\n\n        dtype : tf.Dtype\n            Datatype of the input. Defaults to `tf.complex64`.\n            The output dtype is the same as the input dtype.\n\n    Input\n    -----\n        : [batch_size, num_ofdm_symbols, num_subcarriers]\n            A batch of OFDM resource grids. The resource grids are fft-ized\n            time-domain signals. An exponent of -1 is applied to the\n            corresponding dimension, i.e., ``[batch_size, num_ofdm_symbols, num_subcarriers]``\n            -> ``[batch_size, num_ofdm_symbols, nulled_subcarrier_ind,num_subcarriers-num_nulled_subcarriers]``.\n            The resource grid is then re-organized with the last dimension\n            and and second-to-last dimension to form a rank-2 tensor of shape\n            ``[batch_size, num_ofdm_symbols, num_subcarriers-num_nulled_subcarriers].``\n\n    Output\n    ------\n        : [batch_size, num_ofdm_symbols, num_subcarriers-num_nulled_subcarriers]\n            A batch of OFDM resource grids with nulled subcarriers removed.\n            An exponent of -1 is applied to the corresponding dimension, i.e.,\n            ``[batch_size, num_ofdm_symbols, num_subcarriers-num_nulled_subcarriers]``\n            -> ``[batch_size, num_ofdm_symbols, nulled_subcarrier_ind, num_subcarriers-num_nulled_subcarriers].``\n```\n\n\n    def __init__(self,\n                 nulled_subcarrier_ind,\n                 num_subcarriers,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(trainable=False, dtype=dtype, **kwargs)\n        assert nulled_subcarrier_ind < num_subcarriers, \\\n            \"nulled_subcarrier_ind must be smaller num_subcarriers.\"\n        self._nulled_subcarrier_ind = nulled_subcarrier_ind\n        self._num_subcarriers = num_subcarriers\n\n    #########################################\n    # Public methods and properties\n    #########################################\n\n    def call(self, inputs):\n        # Note: inputs can be X or [X,nu], where X is the resource grid to\n        # flatten and nu is the number of nulled subcarriers.\n        # This allows that also a single nulled dimension batc is given.\n\n        # To support also [x,nu], we can't use the following assert\n        #if isinstance(inputs, (tuple, list)):\n        #    assert len(inputs) == 2\n        \"\"\"Removes nulled subcarriers from `y`.\n\n        `y` is expected to have shape\n        `[...,num_ofdm_symbols,num_subcarriers]` where `num_subcarriers`\n        is the original number of subcarriers and must be larger than\n        `nulled_subcarrier_ind`.\n\n        The function will return a tensor of shape\n        `[...,num_ofdm_symbols, num_subcarriers-num_nulled_subcarriers]`.\n\n        \"\"\"\n\n        # Gather the nulled subcarriers to be removed\n        input_shape = inputs.shape.as_list()\n        gather_ind = list(range(self._nulled_subcarrier_ind))\n        gather_ind.extend(range(self._nulled_subcarrier_ind+1, \\\n                                 self._num_subcarriers))\n        gather_ind = tf.constant(gather_ind, tf.int32)\n\n        # Remove nulled subcarriers\n        if len(input_shape) == 3:\n            # Transpose tensor to move subcarrier-ind dim to the end\n            x = tf.transpose(inputs, perm=[0, 2, 1])\n            x = tf.gather(x, gather_ind, axis=-1)\n            # Transpose tensor to move time-dim to the end\n            x = tf.transpose(x, perm=[0, 2, 1])\n        elif len(input_shape) == 2:\n            x = tf.gather(inputs, gather_ind, axis=-1)\n\n        return x\n    @property\n    def nulled_subcarrier_ind(self):\n        return self._nulled_subcarrier_ind\n\n    @property\n    def num_nulled_subcarriers(self):\n        return self._num_subcarriers - self._nulled_subcarrier_ind\n```"
"The definition of LLRs2SymbolLogits:  \n\nComputes logits (i.e., unnormalized log-probabilities) or hard decisions\non constellation points from a tensor of log-likelihood ratios (LLRs) on bits.\n\nThe source code of LLRs2SymbolLogits: [LLRs2SymbolLogits](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#LLRs2SymbolLogits\n)  \n\nHere is the explanation:  \nThis class is a special version of the LLRs2Logits class where  \nit is assumed that the demapper will be used with a \"bitlabel to constellation point\"  \nor a \"prior to constellation update\" loss function, but not with the \n\"soft-symbol to bits\" function.  \nThe class computes the logits (i.e., unnormalized log-likelihood ratios)  \non the constellation points from a tensor of LLRs (i.e., soft-decisions) on the bits.  \nIt is assumed that the following relation with a channel model and  \n\n$\n\\begin{split}\\mathbf{\\hat{y}} = \\mathbf{p}\\in\\mathcal{X}^M \\Leftrightarrow\n\\begin{bmatrix}\n    \\hat{p}_0\\\\\n    \\hat{p}_1\\\\\n    \\dots\\\\\n    \\hat{p}_M\n\\end{bmatrix}\n\\in \\mathbb{C}^M\n\\end{split}\n$\n\nexists. $\\mathbf{\\hat{y}}$ is the channel output that this layer outputs.\n$M$ is the number of constellation points. $\\mathbf{p}\\in\\mathcal{X}^M$ is the vector of LLRs on the bits that this class takes as input. Note that the reversal of the bit labels (0<->1) is performed if `inversed` is set to True.\n\n**Examples**\nA layer of this class can be used as follows:\n```python\nllr_source = DummyLLRSource()\nllrs = llr_source([batch_size, num_bits_per_symbol])\nlogit_layer = LLRs2SymbolLogits(num_bits_per_symbol)\nlogits = logit_layer(llrs)\n```\n\n**Parameters**\n\n- `num_bits_per_symbol` (int): The number of bits per constellation symbol, e.g., 4 for QAM16.\n- `hard_out` (bool): If True, the layer provides hard-decided symbols instead of soft values. Defaults to False.\n- `inversed` (bool): If True, the bit labels are flipped (i.e., 0<->1). Defaults to False.\n- `dtype` (tf.DType): The dtype of the input and output. Defaults to tf.float32.\n\n**Input**\n\n- `llrs` ([..., n], tf.float): LLRs on the bits.\n\n**Output**\n\n- `logits` ([..., 2**num_bits_per_symbol], tf.float or [...,], tf.int32): Logits or hard-decisions on the constellation symbols.\n\nThe class is based on the following function.  The relation   to the logits is also derived from this function.\n  - sionna.mapping.llrs2symbollogits(llr, num_bits_per_symbol, hard_out=False, with_prior=False, inversed=False, dtype=tf.float32) "
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can follow these steps:\n\n1. Use the TensorFlow `list_physical_devices` function to list the available GPUs. If multiple GPUs are available, you can select the one you want to use.\n\n```python\ngpus = tf.config.list_physical_devices('GPU')\n```\n\n2. Print the list of available GPUs to identify which one you want to use. The GPUs are indexed from 0.\n\n```python\nfor gpu in gpus:\n    print(\"Name:\", gpu.name, \"Type:\", gpu.device_type)\n```\n\n3. If you want to use only a specific GPU, you can set the environment variables `CUDA_VISIBLE_DEVICES` to the index of the GPU you want to use and `TF_CPP_MIN_LOG_LEVEL` to '2' to avoid warnings from TensorFlow.\n\n```python\ngpu_num = 0 # Index of the GPU to be used\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n```\n\n4. You can then set the memory growth of the selected GPU to True, which causes TensorFlow to gradually allocate more GPU memory as it is needed.\n\n```python\ntf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n```\n\n5. If you want to avoid warnings from TensorFlow, you can set the log level to 'ERROR'.\n\n```python\ntf.get_logger().setLevel('ERROR')\n```\n\nPlease note that the GPU number depends on your specific setup. If you have only one GPU, you can set `gpu_num` to 0. If you have multiple GPUs, you can select the one you want to use."
"Here is the demonstration to compute codeword bits from information bits using the `LinearEncoder`.\n\nFirstly, you should load or define a parity-check matrix. In the provided context, a utility function `load_parity_check_examples` is used to load an example parity-check matrix. \n\n```python\nfrom sionna.fec.linear import load_parity_check_examples\n\n# Load an example parity-check matrix\npcm, k, n, coderate = load_parity_check_examples(pcm_id=1)\n```\n\nNext, you need to create an instance of the `LinearEncoder` and provide it with the parity-check matrix. You must specify whether the matrix provided is a parity-check matrix (with `is_pcm=True`) or a generator matrix by using `is_pcm=False`.\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n\n# Create a LinearEncoder instance with the parity-check matrix\nencoder = LinearEncoder(enc_mat=pcm, is_pcm=True)\n```\n\nThis `encoder` instance can now be used to encode information bits to obtain codeword bits.\n\nFor demonstration, let's assume we have an array (`u`) containing information bits that we want to encode. The array `u` should have the shape `[..., k]`, where `k` is the number of information bits per codeword. The following code shows how to use the `LinearEncoder` to encode `u` and obtain the codeword bits.\n\n```python\n# Import necessary library\nimport tensorflow as tf\n\n# Number of information bits per codeword (k)\nk = 4\n\n# Generate a random u with values in {0,1} and shape [...,k]\n# For demonstration, we will set u to all ones.\n# Note that u must be an array of float\nu = tf.constant([[[1.0, 1.0, 1.0, 1.0]]], tf.float32)\n# Encode u to obtain the codeword bits\nc = encoder(u)\n\n# c has the shape [...,n] containing the codeword bits\nprint(\"Shape of codeword bits:\", c.shape)\n```\n\nThe output shows the shape of the codeword bits, confirming that the encoding process was successful.\n\nThe corresponding bit output from the encoder is `c`, which contains the codeword bits. The shape of `c` will match the shape of the input array `u`, but the last dimension will change from `k` to `n`, as it reflects the transformation from information bits to codeword bits. The output `c` is an array of float, with values of either `0.0` or `1.0`.\n\nKeep in mind that the provided code for the creation of the `LinearEncoder` must match your actual use case. If you load a parity-check matrix or a generator matrix that has a different structure or format, it will cause an error. Be sure to verify the details of your matrices and enter them accurately in the appropriate place in the code."
"Here is the detailed information of sionna.utils.flatten_last_dims:  \n\n[sionna.utils.flatten_last_dims(tensor)](https://nvlabs.github.io/sionna/_modules/sionna/utils/tensors.html#flatten_last_dims)\n\nFlattens the last dimensions of a tensor.\n\nFlattens the last dimension of a tensor.\n\n### Parameters\n\n- **tensor**: Tensor to be flattened.\n\n### Returns\n\n- Tensor with the same type as the input tensor.  \n  \nsource code:\n```python\ndef flatten_last_dims(tensor):\n    \"\"\"Flattens the last dimensions of a tensor.\n\n    Flattens the last dimension of a tensor.\n\n    Args:\n        tensor : Tensor.\n\n    Returns:\n        Tensor: with same type as ``tensor``.\n    \"\"\"\n    for _ in tensor.shape[:-1]:\n        tensor = tf.cast(tensor, tf.float32)\n    return tf.reshape(tensor, [-1, tensor.shape[-1]])\n```"
"Here is the definition of Mapper: sionna.mapping.Mapper(constellation, binary=False, check_constellation=True, dtype=tf.complex64, **kwargs)  \n  \nThe link of the source code of [Mapper](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Mapper)  \n  "
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, you can follow these steps:\n\n1. Import the `tensorflow` module in Python.\n\n2. List the physical devices available for TensorFlow to use, specifically the GPUs, using `tf.config.list_physical_devices('GPU')`.\n\n3. Print the list of GPUs to confirm their availability.\n\n4. If GPUs are available, set the notebook to use only the first one by specifying the GPU number (in this case, `gpu_num = 0`).\n\n5. Check the memory growth setting of the GPU. If the memory growth is not already enabled, set it to `True` using `tf.config.experimental.set_memory_growth(gpus[gpu_num], True)`.\n\n6. To avoid warnings, set the log level of the TensorFlow logger to 'ERROR'.\n\n7. If the notebook is running in a Colab environment, it can be set to use only a single GPU and allocate only as much memory as needed by using the `tf.config.experimental.set_memory_growth` method. This will allocate only as much GPU memory as needed for the runtime.\n\n8. If the notebook is running in a non-Eager context, it should define a function that returns a list of the available GPU devices, and another function that sets the index of the GPU to be used. The `tf.config.experimental.set_memory_growth` method should be called within the second function.\n\n9. It is also recommended to run the `nvidia-smi` command to see the current GPU memory usage and processes running on the GPU.\n\nPlease note that the exact code and commands may vary depending on the specific requirements of your notebook and the GPU you are using."
"Here is the definition of BinaryErasureChannel: sionna.channel.BinaryErasureChannel(return_llrs=False, bipolar_input=False, llr_max=100.0, dtype=tf.float32, **kwargs)  \n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/discrete_channel.html#BinaryErasureChannel)  \n  \nsource code:\n```python\nclass BinaryErasureChannel(BinaryChannel):\n    # pylint: disable=line-too-long\n    r\"\"\"BinaryErasureChannel(return_llrs=False, bipolar_input=False, llr_max=100., dtype=tf.float32, **kwargs)\n\n    Layer that implements a binary erasure channel.\n\n    ..  code-block:: none\n\n        y = e : (x, p_b)\n\n    In the Binary Erasure Channel, bits are either correctly received or\n    erased with erasure probability :math:`p_\\text{b}`.\n\n    The class can also return log-likelihood ratios (LLRs) defined as\n\n    ..  code-block:: none\n\n         LLR = ln(Prb(x=1) / Prb(x=0)).\n\n    If the ``bipolar_input`` parameter is set to `True`, bit values of `0` are\n    mapped to `-1`.\n\n\n    Parameters\n    ----------\n    return_llrs: bool\n        Defaults to `False`. If `True`, the layer returns log-likelihood ratios\n        instead of binary values based on ``pb``.\n\n    bipolar_input: bool, False\n        Defaults to `False`. If `True`, expected input is given as {-1,1}\n        instead of {0,1}.\n\n    llr_max: tf.float\n        Defaults to 100. Defines the clipping value of the LLRs.\n\n    dtype : tf.DType\n        Defaults to `tf.float32`. Defines the datatype for internal\n        calculations and the output dtype.\n\n    Input\n    -----\n    (x, p_b) :\n        Tuple:\n\n    x : tf.float32\n        Tensor of bit values to be transmitted. Expected to be\n        either [0,1] or [-1,1], unless ``bipolar_input`` is set to `True`, then\n        it should be [-1,1].\n\n    p_b : tf.float32\n        Scalar or tensor of same shape as ``x`` defining the bit\n        erasure probability.\n\n    Output\n    -------\n        : tf.float32\n            Tensor of same shape as the input ``x``. If\n            ``return_llrs`` is set to `False`, the output is ternary where a\n            `-1` and a `0` indicate an erasure for the binary and bipolar\n            input, respectively.\n            If ``return_llrs`` is set to `True`, the output is a log-likelihood\n            ratio.\n    \"\"\"\n\n    def __init__(self, return_llrs=False, bipolar_input=False, llr_max=100., dtype=tf.float32, **kwargs):\n\n        super().__init__(return_llrs=return_llrs,\n                         bipolar_input=bipolar_input,\n                         llr_max=llr_max,\n                         erasure=True,\n                         dtype=dtype,\n                         **kwargs)\n```\n  "
"To simulate the 5G NR LDPC code, the following components are required:\n\n1. **LDPC BP Decoder (also referred to as the LDPC BP Demapper Decoder)**: This is an iterative decoder that performs belief propagation (BP) to decode the received bit-stream. In the context, the LDPC BP Decoder is instantiated using the `LDPCBPDecoder` class from the Sionna library and is provided with the parity check matrix and the *log-likelihood ratio (LLR) calculation method*. The decoder is also fed with Gaussian LLRs, which are the a priori probabilities of the received bits calculated based on the received signal levels and the noise variance. The `output_dtype` parameter defines the datatype of the output.\n\n2. **Gaussian LLR Source (or Demapper)**: The Gaussian LLR source is not explicitly shown in the context, but it is necessary to provide the decoder with the a priori information. The source generates the LLRs using the formula defined in the 3GPP TS 38.212 standard, taking into account the signal-to-noise ratio (SNR) and other transmission parameters.\n\nThese components will be part of a simulation setup that aims to achieve the following:\n- Generate an info bit sequence \n- Encode the bits using the 5G NR LDPC encoder\n- Map the encoded bits to modulated symbols using a 5G NR compliant Mapper\n- Simulate the transmission of the modulated symbols over an AWGN channel at different SNR points\n- Generate Gaussian LLRs from the received symbols\n- Decode the received symbols using an (optional) 5G LDPC Decoder (using the aforementioned BP Decoder and Gaussian LLR Source)\n\nThe simulation will allow estimating the Bit Error Rate (BER) and Block Error Rate (BLER) performance of the communication system based on the 5G NR LDPC code."
"To use the PUSCHDMRSConfig class and its properties you have to follow these steps:\n\n1. Import the PUSCHDMRSConfig class from the sionna nr module.\n\n```python\nfrom sionna.nr import PUSCHDMRSConfig\n```\n\n2. Create an instance of the PUSCHDMRSConfig class. You can pass the configuration type as an argument.\n\n```python\npusch_dmrs_config = PUSCHDMRSConfig(config_type=1)\n```\n\n3. Once the instance is created, you can access the properties of the PUSCH DMRS configuration directly. For example, you can set the additional DMRS position as follows:\n\n```python\npusch_dmrs_config.additional_position = 1\n```\n\nIn this example, `additional_position` is a property of the PUSCHDMRSConfig class that represents the maximum number of additional DMRS positions. By setting it to 1, you are indicating that one additional DMRS position is reserved. \n\nPlease note that the actual number of used DMRS positions depends on the length of the PUSCH symbol allocation. If you change the symbol allocation, the number of used DMRS positions will be adjusted accordingly."
"To demonstrate the encoding of information bits using an instance of `ConvEncoder`, let's refer to the context provided which includes the Python code for the encoder and decoder functions. \n\nFirst, initialize the `ConvEncoder` with the generator polynomials that represent the desired rate and constraint length for the convolutional encoder.\n\nThe generator polynomials, `gen_poly` in this context, are defined as:\n- `rate` = $\\frac{1}{2}$, so the encoder will be a rate-1/2 encoder\n- `constraint_length` = 4, which means the encoder will be a 4-state encoder (for each output bit, 4 input bits are needed to explain how it is generated)\n\nThe generator polynomials are specified to define the encoder's behavior over 2 distinct \"code bits\" paths (separated by the comma in the list definition). As per the context, the generator polynomial list `gen_poly` is expressed as:\n- `gen_poly` = `['1001', '1011']` \n\nOn initializing the `ConvEncoder` with these generator polynomials, the encoder is configured to accept information bits in the form of a tensor with the final dimension size `k` and will output the encoded codewords as a tensor with the final dimension size `n`, where, as explained before, `k` is the number of information bits and `n` is the number of codeword bits.\n\nTo encode information bits using this instance of `ConvEncoder`, you will feed the information bits tensor `u` to the encoder, which will produce the encoded codewords tensor `c`.\n\nHere is the code snippet to illustrate this:\n\n```python\nfrom sionna.fec.conv import ConvEncoder\n\n# Create an instance of ConvEncoder with the generator polynomials\nencoder = ConvEncoder(gen_poly=['1001', '1011'], rate=1/2, constraint_length=4)\n\n# u contains the information bits to be encoded and has shape [...,k].\n# Create a tensor of random 0s and 1s as the information bits\n# Ensure dtype is tf.float32 for the encoding operation\nu = tf.random.uniform((16, k), 0, 2, tf.float32)\n\n# Verify the shapes and types of the input tensor\nprint(\"Shape of the input information bits tensor u:\", u.shape)\nprint(\"Datatype of the input information bits tensor u:\", u.dtype)\n\n# Now encode the information bits to get the codewords\nc = encoder(u)\n\n# c contains the convolutional encoded codewords and has shape [...,n].\nprint(\"Shape of the output codewords tensor c:\", c.shape)\nprint(\"Datatype of the output codewords tensor c:\", c.dtype)\n```\n\nPlease replace the `...` in the shape outputs with the actual values once you run the code. The actual shapes and types of tensors will depend on the specific details of the information bits and the generator polynomial settings. The illustration provides a general example for context based on the provided code. \n\nThe output from this code snippet will be the shapes and types of the input and output tensors, demonstrating the operation of the `ConvEncoder`."
"The DMRS (Deprecated: Downlink Reference Signal) configuration refers to a feature in wireless communication where a special signal is used by a mobile terminal (or user equipment) to channel state information reference. This signal is used by the base station (or NodeB) to map the channel state information to specific resource elements. The DMRS configuration includes parameters like `additional_position`, `allowed_dmrs_ports`, `beta`, `cdm_groups`, `config_type`, `deltas`, `dmrs_port_set`, `length`, `n_id`, `n_scid`, `num_cdm_groups_without_data`, `type_a_position`, `w_f`, and `w_t`.\n\nTo visualize the pilot pattern, the configured pilot patterns can be mapped on top of a resource grid. For example, a pilot pattern in the 4x4 block indicated by the top-left element `[0,0]` and a 2x2 element indicated by the `type_a_position`=2 may look like this:\n\n```python\n[1000] \ud83e\udc72 [1000****] \ud83e\udc72 [1000****]\n[****] \ud83e\udc72 [1000****]\n[****] \ud83e\udc72 [1000****]\n[****] \ud83e\udc72 [****]\n```\n\nwhere `*` represents a data-carrying resource element and the DMRS port 0 pilot symbol is shown in bold.\n\nThe pilot pattern can be visualized on a complex-valued baseband channel. For example, the pilot pattern for a 4x4 MIMO system with `dmrs_port_set` equal to [0,1,6,7] can be shown as frequency-domain pilot pattern in the channel frequency response:\n\n```python\nfig, ax = plt.subplots(figsize=(7,14))\nplt.imshow(np.abs(h_f)[::-1].T, aspect=\"auto\", extent=[0, 20, -14, -3], origin=\"lower\")\nplt.colorbar(label=\"Magnitude\")\nplt.xlabel(\"Subcarrier index\")\nplt.ylabel(\"BS antenna index\")\n# DMRS\n[slant]_python\ndmrs_start = pusch_config.position"
"To visualize common scattering patterns using the Sionna package, you can follow these steps:\n\n1. First, create a `LambertianPattern` or `DirectivePattern` with the necessary parameters that define the radiation or reception characteristics.\n   \n    ```python\n    from sionna.rt import LambertianPattern, DirectivePattern\n    \n    # Example of LambertianPattern\n    l_pattern = LambertianPattern(\"iso\", 1.0)\n    \n    # Example of DirectivePattern\n    d_pattern = DirectivePattern(alpha_r=10)\n    ```\n   \n2. Next, call the `visualize` method of the pattern.\n\n    ```python\n    l_pattern.visualize()\n    # Output: Visualizes the radiation pattern\n    ```\n   \n    ```python\n    d_pattern.visualize()\n    # Output: Visualizes the reception pattern\n    ```\n\nThis will generate a 3D visualization of the pattern. The visualization shows the pattern in both the vertical and horizontal planes."
"To handle import errors for the Sionna package, the code first attempts to import the Sionna package using the `import sionna` statement within a `try/except` block. If the import is successful, the package is made available for use in the current session. \n\nHowever, if the import statement raises an `ImportError`, the code then goes on to handle this error. The first step is to install the Sionna package using the `os.system(\"pip install sionna\")` statement. This uses the `os.system` function to execute a command in the system shell, in this case the command is to install the Sionna package via pip. \n\nAfter the package is installed, the code attempts to import the Sionna package again. This is done to verify that the package was installed successfully. If the package is imported successfully after it was installed, it is then made available for use in the current session. If the package still cannot be imported after it was installed, an `ImportError` is raised with an associated error message.\n\nIt's important to note that the `try/except` block uses a specific syntax to handle `ImportError` specifically. If an error is of type `ImportError`, the `except` block is executed. In the context provided, the `except` block attempts to handle the `ImportError` by installing the package and verifying the installation was successful before raising an `ImportError` if the package still cannot be imported."
"To import the necessary Sionna APIs, you can use the following code:\n\n```python\nfrom sionna import Pci, CyclicPrefix, CyclicPrefixRemoval, OFDMModulator, OFDMDemodulator, NormalizedCrossCorrelator, LinearFilter, MatchedFilter, Nonlinearity, LayerNonlinearity, nn, upsample\nfrom sionna.channel import FlatFadingChannel, KroneckerModel, OFDMChannel\nfrom sionna.channel.utils import exp_corr_mat, to_undelayed_channel, wideband_circ_corr\nfrom sionna.decoder import LinearDecoder\nfrom sionna.encoder import OSEightKbCoder\nfrom sionna.resource_grid import ResourceGrid\nfrom sionna.utils import BinarySource, ebnodb2no, log10, compute_ser, Q, sim_ber\n```\n\nThis code will import all the necessary APIs from Sionna for the given context. The APIs include various components for the 5G simulation, such as the encoder, decoder, resource grid, binary source, error vector magnitude (EVM) calculator, and also components for the 3GPP system simulation, like the `Pci`, `CyclicPrefix`, `CyclicPrefixRemoval`, `CyclicPrefixRemoval`, `OFDMModulator`, `OFDMDemodulator`, `FlatFadingChannel`, `KroneckerModel`, `LinearDecoder`, `OSEightKbCoder`, `ResourceGrid`, `BinarySource`, `ebnodb2no`, `log10`, `compute_ser`, `Q`, and `sim_ber`."
"To learn about the class, parameters, input, output, raised errors, and properties of the Descrambler, you can refer to the context information given. Here, we provide a detailed breakdown.\n\n### Class\n\nThe `Descrambler` class is a scrambling module part of the 'sionna.fec.scrambling' utility. It implements a scrambling operation that is the reverse of the Scrambler. \n\n### Parameters\n\n- `scrambler`: Associated Scrambler instance to be descrambled. \n- `binary`: A boolean parameter (default is True). If true, the bit sequence is flipped (0 to 1 and 1 to 0). If false, the sign of the sequence is flipped. \n- `dtype`: Specifies the datatype for internal calculations and the output dtype. If no explicit dtype is provided, the dtype from the associated interleaver is used. \n\n### Input\n\n- `(x, seed)`: Tuple:\n  - `x` ([..., n], tf.float32): 2+D tensor containing the values to be descrambled.\n  - `seed` (int): An integer that defines the state of the random number generator. If explicitly given, the global internal seed is replaced by this seed. This can be used to realize random Scrambler/Descrambler pairs (i.e., they are called with the same random seed).\n\n### Output\n\n- `[...,n]`, tf.float32: 2+D tensor of the same shape as 'x' containing the descrambled values.\n\n### Raised Errors\n\n- `AssertionError`: If the `scrambler` is not an instance of Scrambler.\n- `ValueError`: If the shape of `seed` is not scalar or not an int.\n\n### Properties\n\n- `scrambler`: Associated Scrambler instance.\n\n### DescramblerTB5G and Descrambler\nThe `DescramblerTB5G` is a class that provides parameters for the scrambling/descrambling operation following 3GPP TS 38.211 for \"PDCCH DMRS.\"\n  \nThe `Descrambler` class is a parameterized scrambling module. It can be used to create a Descrambler instance where the scrambling parameters are provided as input, unlike `DescramblerTB5G`, which has parameters specific to the PDCCH DMRS format.\n\nIt's important to note that `DescramblerTB5G` implements the advanced scrambling as defined in the 3GPP specification for 5G New Radio, and is only relevant if you are working in a telecommunications setting and implementing standards like PDCCH DMRS. For general use cases, the `Descrambler` class should suffice."
"Code snippets from the context that demonstrate how to use an instance of `Polar5GDecoder` with log-likelihood ratios (LLRs) as inputs are:\n\n1. First, you need to initialize the encoder and the decoder:\n\n```python\nfrom sionna.fec.polar.encoding import Polar5GEncoder\nfrom sionna.fec.polar.decoding import Polar5GDecoder\nfrom sionna.fec.polar.decoding import  estimate_channel_llr\n\n# Parameters for the Polar 5G encoding\nn = 256 # Codeword length\nk = 100 # Number of information bits\n\n# Inialize the encoder and the decoder\nencoder = Polar5GEncoder(n, k)\ndecoder = Polar5GDecoder(encoder, \"SCL\") # you can also use \"SCL\" for list-based decoding\n```\n2. Assume you have a channel output represented by `y`, and the LLRs of the channel reliability represented by `l_ch`, you need to estimate the LLRs of the frozen positions. This can be done using the `estimate_channel_llr` function:\n\n```python\nfrozen_pos, a_hat, err_var = estimate_channel_llr(y, l_ch, encoder.channel)\n```\n\nIn the above code snippet:\n   - `y` represents the channel output\n   - `l_ch` represents the LLRs of the channel reliability\n   - `encoder.channel` represents the channel transition function of the Polar code\n\n3. After estimating the LLRs of the frozen positions, you can apply to the `Polar5GDecoder`. The following is an example of how to feed the LLRs into the decoder to perform a list-based decoding:\n\n```python\n# Assuming llr is a Tensor with shape [batch_size, n] containing the llrs to be decoded\nu_hat = decoder(llr, estimate_frozen_bits=(frozen_pos, a_hat, err_var))\n```\n   - `llr` is a tensor containing the LLRs to be decoded\n   - `estimate_frozen_bits` is a tuple containing the estimated frozen bit positions (`frozen_pos`), the estimated LLRs of the frozen bits (`a_hat`), and the error variance of the LLRs (`err_var`).\n\nThis is how you perform Polar Decoding using an instance of `Polar5GDecoder` with log-likelihood ratios as inputs. However, please note that the code within the provided context that actually calls the decoder with the input LLRs is in a way that a hypothetical `NeuralPolarDecoder` class might do it, and does not match exactly the initialization of a `Polar5GDecoder` with LLRs. The former is more of a conceptual demonstration, while the latter is the practical implementation demonstrated in the code lines above. Make sure the actual implementation matches the practical demonstration for the code in a real-world application."
"To load a scene from a file using the `load_scene()` function from the `sionna.rt` module of the Sionna package, you can follow these steps:\n\n1. First, make sure you have the necessary import statement in your code. If not, you can add the following line to import the `load_scene()` function:\n\n    ```python\n    from sionna.rt import load_scene\n    ```\n\n2. Determine the filename of the scene you want to load. The filename is a string which should end with \".xml\" or it can also be an URL (http or https).\n\n3. Call the `load_scene()` function and pass the filename as an argument. Assign the result of this function to a variable. This result is an instance of the `Scene` class, which represents your loaded scene.\n\n    ```python\n    scene = load_scene('filename.xml')\n    ```\n\nIn the above code, replace 'filename.xml' with the actual filename of the scene you wish to load.\n\nPlease note that the `load_scene()` function can raise an error if it's unable to load the scene. This could happen if the scene file is not valid or if the function doesn't have the necessary permissions to access the file. You should ensure that you have appropriate error handling to deal with these situations, such as printing an informative message for the user or logging the details of the error."
