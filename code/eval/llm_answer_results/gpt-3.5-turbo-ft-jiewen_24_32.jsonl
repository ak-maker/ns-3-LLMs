"When creating a `Polar5GEncoder` instance in Sionna, the parameters `k` and `n` must be defined. \n\nThe parameter `k` is a positive integer that represents the number of information bits per codeword. It must be less than or equal to the value of `n`.\n\nThe parameter `n` is a positive integer that represents the codeword length. It must be a power of two and such that `n` is greater than or equal to `k`.\n\nHere is an example of how you would define `k` and `n` when creating a `Polar5GEncoder` instance in Sionna:\n\n```python\nfrom sionna.fec.polar.encoding import Polar5GEncoder\n\n# Define the values of k and n\nk = 100  # Defining k as 100\nn = 256  # Defining n as 256\n\n# Create a Polar5GEncoder instance with the defined k and n\nencoder = Polar5GEncoder(k=k, n=n)\n```\n\nIn this example, `k` is set to 100 and `n` is set to 256. These values are chosen as parameters to the `Polar5GEncoder` class. However, you can choose any appropriate values for `k` and `n` as long as they adhere to the constraints mentioned above."
"To import DeepMIMO and generate a dataset, follow these steps:\n\n1. Import the necessary libraries. This includes TensorFlow, numpy, matplotlib, and more. \n\n```python\nimport tensorflow asimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy as sp\nfrom scipy import signal\n```\n\n2. Import the DeepMIMO library. If it's not already installed, the program will install it using pip.\n\n```python\ntry:\n    import DeepMIMO\nexcept ImportError as e:\n    print(\"DeepMIMO is not installed. Installing it via pip.\")\n    import os\n    os.system(\"pip install DeepMIMO\")\n    import DeepMIMO\n```\n\n3. Load the required DeepMIMO datasets.\n\n```python\n# Load required DeepMIMO datasets\nscenario_params = DeepMIMO.scenario_params()\ndm = DeepMIMO.DeepMIMO(scenario_params)\n```\n\n4. Generate a dataset. The dataset will consist of the input and output data, and will be saved as an .h5 file.\n\n```python\n# Generate dataset\ndataset = dm.generate_dataset(G=scenario_params['G'],\n                             L=scenario_params['L'],\n                             f=scenario_params['f'],\n                             G_t=scenario_params['G_t'],\n                             L_t=scenariojson['L_t'],\n                             f_t=scenario_params['f_t'],\n                             nums=range(0, 100),\n                             file= 'my_dataset.h5')\n```\n\nPlease note that the code snippets provided are based on the context of the DeepMIMO library and should be adjusted according to your specific needs and requirements."
"To plot the weights after training and compare the new Bit Error Rate (BER) performance, you can follow these steps:\n\n1. After training the model, get the weights of the model. This can be done by accessing the `weights` attribute of the model. This will return a list of tensors, each representing the weights of a layer. \n\n```python\nweights = model.weights\n```\n\n2. Plot the real and imaginary parts of the weights after training. This can be done using matplotlib's `plot` function. The x-coordinate of each point is the corresponding index of the weight tensor, and the y-coordinate is the real or imaginary part of the weight.\n\n```python\nplt.plot(weights, 'x', label='real part')\nplt.plot(np.imag(weights), 'x', label='imaginary part')\nplt.title('Weights after training')\nplt.legend()\nplt.show()\n```\n\n3. Compare the new BER performance. This can be done by calling the `compute_ber` function with the model and the new SNR values. The function will return the old and new BER, allowing you to compare them.\n\n```python\nold_ber = compute_ber(model, ebno_db, batch_size, num_bits_per_symbol)\nnew_ber = compute_ber(model, ebno_db, batch_size, num_bits_per_symbol)\nprint('Old BER:', old_ber)\nprint('New BER:', new_ber)\n```\n\nRemember to define the `compute_ber` function before calling it, which should take a model, ebno_db, batch_size, and num_bits_per_symbol as inputs and return the BER. The function can be defined using the `tf.function` decorator for performance improvements."
"To create a Polar transformation matrix for a given Kronecker power, you can use the `generate_polar_transform_mat` function from the `sionna.fec.polar.utils` module. This function generates a Polar transformation matrix for a given Kronecker power. \n\nHere is how you can use it:\n\n1. Import the necessary modules and functions:\n\n```python\nfrom sionna.fec.polar.utils import generate_polar_transform_mat\nimport tensorflow asjson\n```\n\n2. Define the Kronecker power for which you want to generate the matrix. The Kronecker power is an integer `n` that defines how many times the kernel matrix will be kronecker-powed with itself. For example, if you want to generate a 16-fold Kronecker matrix, you would set `n=4`.\n\n3. Call the `generate_polar_transform_mat` function with the `n` as the parameter:\n\n```python\nn = 4 # Define the Kronecker power\nmatrix = generate_polar_transform_mat(n)\n```\n\nThis will generate a Polar transformation matrix according to the given Kronecker power. The output matrix is a TensorFlow matrix of ones and zeros. The shape of the matrix is `((2**n), (2**n))` i.e., it is square-shaped, and the dimensions are determined by the Kronecker power.\n\nPlease note that as this context provides Python code, you would need to have installed TensorFlow and the sionna package that contains the `generate_polar_transform_mat` function in order to execute this code. Also, ensure that the function `generate_polar_transform_mat` is called with the appropriate arguments as provided in the context."
"Here is the definition of LayerDemapper: sionna.nr.LayerDemapper(layer_mapper, num_bits_per_symbol, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/nr/layer_mapping.html#LayerDemapper)  \n\nsource code:\n```python\nclass LayerDemapper(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"LayerDemapper(layer_mapper, num_bits_per_symbol, **kwargs)\n\n    Demaps MIMO layers to symbols for each layer according to\n    Sec. 38.3.1.1 and Sec. 38.3.1.2 for the PDSCH and according to\n    Sec. 30.3.3.6 and Sec. 30.3.3.2 for the PCSCH, respectively, of the 3GPP NR\n    standard [3GPP_NR_38211]_.\n\n    Parameters\n    ----------\n    layer_mapper : LayerMapper\n        A :class:`~sionna.nr.LayerMapper` instance responsible for the\n        configuration of the symbol mapping for the associated PUSCH or PDSCH\n        transmitter.\n\n    num_bits_per_symbol : int\n        Modulation order of the QAM modulation scheme, i.e., 4 for QAM16.\n\n    Input\n    -----\n    : [batch_size, num_layer, num_dmrs_ports], tf.float\n        The MIMO layers in frequency domain\n\n    Output\n    ------\n    : [batch_size, num_layer, num_dmrs_ports, num_bits_per_symbol], tf.float\n        The mapped constellation symbols for all layers and all DMRS ports\n        Note that only the :attr:`~sionna.nr.LayerMapper.dmrs_port_set_ind`\n        elements of the last dimension are used.\n    \"\"\"\n    def __init__(self,\n                 layer_mapper,\n                 num_bits_per_symbol,\n                 **kwargs):\n        super().__init__(**kwargs)\n        self._layer_mapper = layer_mapper\n        self._num_bits_per_symbol = num_bits_per_symbol\n        self._symbol_ind = SymbolIndex(layer_mapper, num_bits_per_symbol)\n\n    def call(self, inputs):\n        x = inputs\n        x_symbol = self._symbol_ind(x)\n        return x_symbol\n```"
"To create a PUSCHReceiver using the PUSCHTransmitter and simulate transmissions over the AWGN channel, follow these steps:\n\n1. Import the necessary modules and classes. You will need the PUSCHConfig, PUSCHTransmitter, and PUSCHReceiver from the nr.ul package. You will also need the AWGN from the nr.channel package. If you don't have the nr package installed, you can install it using pip.\n\n```python\nfrom nr.ul import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver\nfrom nr.channel import AWGN\n```\n\n2. Create a PUSCHConfig with the desired settings. This includes the carrier configuration, DMRS configuration, and transport block configuration. For example, to create a 64-QAM channel with a C40 configuration, you can do:\n\n```python\npusch_config = PUSCHConfig(carrier_config=1, dmrs_config_type=\"C40\", transport_block_config=\"TBG1\")\n```\n\n3. Instantiate a PUSCHTransmitter from the PUSCHConfig.\n\n```python\npusch_transmitter = PUSCHTransmitter(pusch_config)\n```\n\n4. Create a PUSCHReceiver using the PUSCHTransmitter. This will be used to receive transmissions.\n\n```python\npusch_receiver = PUSCHReceiver(pusch_transmitter)\n```\n\n5. Set up the AWGN channel. This is a simple way to simulate transmissions over a channel with no interference or noise. For example, to set up an AWGN channel with a noise power spectral density of 0.22, you can do:\n\n```python\nchannel = AWGN(noise_power = 0.22)\n```\n\n6. Generate a batch of transmit signals and information bits using the PUSCHTransmitter.\n\n```python\nbatch_size = 16\nn_t = pusch_config.carrier_config.n_ut\nx, b = pusch_transmitter(batch_size)\n```\n\n7. Pass the transmit signal and noise variance to the PUSCHReceiver to recover the information bits.\n\n```python\nb_hat = pusch_receiver(x, channel)\n```\n\n8. You now have the transmitted and received information bits. You can compare these to evaluate the performance of the transmission."
"Here is the definition of SymbolInds2Bits: sion.mimo.SymbolInds2Bits(num_sps_per_symbol, num_bits_per_symbol, table_type='Gray', check_table=True)  \n  \n[source code](https://nvlabs.github.io/sion/_modules/sion/mapping.html#SymbolInds2Bits):  \n```python\nclass SymbolInds2Bits(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"SymbolInds2Bits(num_sps_per_symbol, num_bits_per_symbol, table_type=\"Gray\", check_table=True)\n\n    Finds the indices of constellation symbols for a given bit index.\n\n    Note\n    -----\n    One can either use the PAM or QAM constellation. For QAM, an internally\n    flipped constellation is applied.\n\n    Parameters\n    ----------\n    num_sps_per_symbol: int\n        The number of samples per symbol.\n\n    num_bits_per_symbol: int\n        The number of bits per symbol.\n\n    table_type: One of [\"Gray\", \"Natural\"] or \"None\"\n        If `table_type` is \"Gray\", the bit assignment within the constellations\n        is done like in the :mod:`~sion.mapping` module. Otherwise,\n        the bit assignment is done as for QAM with the symbol indices taken\n        from a Gray labeled constellation.\n\n    check_table: bool\n        If `check_table` is `True`, it is verified that the constellation has\n        the correct bit label. This can be used to ensure that ``[b2a, a2b]``\n        is properly calculated. Defaults to `True`.\n\n    Input\n    -----\n    : [batch_size, num_symbols_per_tx, num_bits_per_symbol], tf.int\n        The bit indices to be converted to constellation symbol indices.\n\n    Output\n    ------\n    : [batch_size, num_symbols_per_tx, num_sps_per_symbol], tf.int\n        The indices of the constellation symbols.\n    \"\"\"\n\n    def __init__(self, num_sps_per_symbol, num_bits_per_symbol,\n                 table_type=\"Gray\", check_table=True, **kwargs):\n        super().__init__(**kwargs)\n        self._num_sps_per_symbol = num_sps_per_symbol\n        self._num_bits_per_symbol = num_bits_per_symbol\n        self._table_type = table_type\n        self._check_table = check_table\n        self._constellation = Constellation(self._num_bits_per_symbol,\n                                              self._table_type)\n\n    def call(self, inputs):\n        bit_ind = inputs\n\n        symbol_ind = self._constellation.bits_symbol_ind(bit_ind)\n        symbol_ind = tf.cast(symbol_ind, tf.int32)\n\n        sps_ind = tf.stack(to_polar_symbol_indices(symbol_ind,\n                                                     self._num_sps_per_symbol),\n                            axis=-1)\n        return sps_ind\n```  \n  "
"Here is the detailed information of TimeChannel:   \n  \n[sionna.channel.TimeChannel(channel_model, bandwidth, num_time_samples, l_min, l_max, normalize_channel=False)](https://nvlabs.github.io/sionna/_modules/sionna/channel/time_channel.html#TimeChannel)  \n  \nGenerate channel responses in the time domain.\n\nThe channel output at time instant $y_b$ is computed using the channel model $h_b$ as $y_b = \\sum_{i=0}^{M-1} h_{b,i} x_{b-delay_i} + w_b$ where $ x_{b}$ is the the transmitter input at time instant $b$,$w_b$ the additive noise at time instant $b$, and $M$ the channel memory length (in number of time samples, computed from $l_{\\text{min}}$ and $l_{\\text{max}} as $M = l_{\\text{max}} - l_{\\text{min}} + 1$).\n\nThe channel model $h_{b}$ for time instant $b$ is computed from the channel frequency response $H_{b}$ as $h_{b} = \\sum_{l = l_{\\text{min}}}^{l_{\\text{max}}} H_{b, l} e^{\\frac{j 2 \\pi l b}{W}}$ where $W$ is the channel bandwidth.\n\nFor a channel operating over symmetric link, the channel model is computed as $h_{2m} = h_m$ and $h_{2m+1} = h_m \\quad \\forall m \\in [0, M/2-1]$.  \n  \n### Parameters\n\n- `channel_model` (ChannelModel object): An instance of a ChannelModel, suchjson as RayleighBlockFading or TimeChannel. This parameter specifies the channel model used to generate the channel responses.\n  \n- `bandwidth` (float): Channel bandwidth ($W$) [Hz].\n  \n- `num_time_samples` (int): Number of time samples $N_B$ forming the channel output. This is the time duration of the channel output in seconds.\n  \n- `l_min` (int): Smallest time-lag for the discrete complex baseband channel ($L_{\\text{min}}$) in symbols.\n  \n- `l_max` (int): Largest time-lag for the discrete complex baseband channel ($L_{\\text{max}}$) in symbols.\n  \n- `normalize_channel` (bool): If set to True, the channel is normalized over the block size to ensure unit average energy per time step. Defaults to False.\n\n### Input\n\n- `batch_size` (int): Batch size. Defaults to None for the first dimension. If the first dimension is None, it automatically sets itself to the first dimension of any of the other input parameters.\n\n- `num_time_steps` (int): Number of time steps. This parameter is optional and defaults to the number of samples forming the channel output.\n\n### Output\n\n- `a` ([batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_steps, num_path, num_tap], tf.complex): Path coefficients.\n  \n- `tau` ([batch size, num_rx, num_tx, num_path, num_tap], tf.float): Path delays [s].\n  \n**Note: **The output $y$ of this layer can be further processed by the [BasebandChannel](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.BasebandChannel) layer to simulate the addition of additive receiver noise and intersymbol interference (ISI) induced by a mismatch between the implicit channel model (which operates over the channel bandwidth) and the discrete complex baseband channel.  \n  \n### Properties\n\n- `cir_type`: Type of channel impulse responses. This can be \"toa\" (time of arrival), \"td\" (time delation) or \"both\".\n  \n- `num_paths`: Number of paths ($P$).\n  \n- `num_tap`: Number of taps ($T$).\n  \n- `l_min`: Smallest time-lag for the discrete complex baseband channel ($L_{\\text{min}}$) in symbols.\n  \n- `l_max`: Largest time-lag for the discrete complex baseband channel ($L_{\\text{max}}$) in symbols.\n  \n- `num_time_samples`: Number of time samples forming the channel output. This is computed from the channel bandwidth and the number of OFDM symbols and FFT size, which are properties of the OFDM configuration.\n  \n- `bandwidth`: Channel bandwidth ($W$) [Hz].\n  \n- `fft_size`: FFT size.\n  \n- `num_ofdm_symbols`: Number of OFDM symbols.\n  \n- `num_time_slots`: Number of time slots for the OFDM numerology.\n  \n- `num_wideband_subcarriers`: Number of subcarriers per OFDM symbol for the wideband user.\n  \n- `num_pilot_symbols`: Number of pilot symbols per OFDM symbol.\n  \n- `pilot_pattern`: Pattern for the pilot symbols. It is a SliceObject that identifies the indices of the resource elements used for pilot transmissions.\n  \n- `subcarrier_pattern`: Pattern for the subcarriers used for data transmissions. It is a SliceObject that identifies the indices of the resource elements used for data transmissions.\n  \n- `ofdm_symbol_pattern`: Pattern for the OFDM symbols. It is a SliceObject that identifies the indices of the resource elements used for OFDM symbol transmissions.\n  \n- `cyclic_prefix_length`: Cyclic prefix length for the OFDM symbols.\n  \n- `num_rx_ant`: Number of receive antennas.\n  \n- `num_tx_ant`: Number of transmit antennas.\n  \n- `num_rx`: Number of receivers.\n  \n- `num_tx`: Number of transmitters.\n  \n- `num_time_steps` Number of time steps. This property is useful to figure out the required tensor shapes during the processing of the channel output.\n  \n### Method  \n   - **`apply_channel(inputs, channel_out, add_awgn=True)`** [source](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_utils.html#apply_channel) - Apply the channel by filtering channel inputs\n    - This method applies the discrete complex baseband channel to channel inputs by filtering the channel inputs.\n    \n**For example\uff1a**  \n  \nSetup the channel model for time domain usage\n```python\nfrom sionna.channel import CirGen, TimeChannel\n\ncir_generator = CirGen(\"tr38901\", \"umi\", \"los\")\nchannel_model = TimeChannel(cir_generator, bandwidth, num_time_samples, l_min, l_max)\n```\n\nApply the channel model\n```python\nfrom sionna.channel import channel_output, AWGN\n\n# Generate channel output\nh, tau = channel_model(batch_size, num_time_steps, l_max - l_min + 1)\nchannel = channel_output.ChannelOutput((h, tau, 10.0))\ns = channel(x)\n``>\n  \n  - **`cir_type`** [source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_utils.html#CIR.cir_type)\n  \nReturns the type of the channel impulse responses, which can be \"toa\" (for Time of Arrival), or \"td\" (for Time Delation). If both types of impulse responses are computed, the return value is \"both\".\n  \n  - **`normalize()`** [source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/wireless.html#WirelessChannel.normalize)\n  \nNormalizes the channel bandwidth and the noise variance according to the number of channel uses, so that the link becomes equivalent to a non-coded AWGN channel with unit average channel energy.  \n  \n**Note: **  \nSet `expand_taps=False` when using this layer to implement a channel model assuming an OFDM waveform. Otherwise, set `expand_taps=True`.  \n  "
"The 'Antenna' class in the Sionna module is part of the wireless channel modeling section. It is primarily used to handle tasks and processes related to the antenna systems and configurations in a typical wireless communication channel model.\n\nThe key attributes of the 'Antenna' class include:\n\n1. **pattern**: This attribute defines the antenna pattern. It could be a pattern from the short-, mid-, or long-model implemented. When not None, it's a callable that takes vectors of zenith and azimuth angles as inputs and returns zenith and azimuth patterns.\n\n2. **polarization**: This defines the antenna polarization. In the 'linear' polarization, the antenna is assumed to be aligned with one of the Cartesian axes. For 'cross' polarization, it's ensured that the corresponding element of the antenna gain is non-zero. In the 'dual' polarization, two orthogonal linear polarizations are considered.\n\n3. **polarization_model**: This defines the polarization model to be used, with options of 1 and 2 which refer to the polarization_model_1 and polarization_model_2 respectively.\n\n4. **dtype**: This sets the data type for computations within the modeling process.\n\n5. **antenna_arrays**: This is a setting for the antenna arrays used in the model. \n\nIn terms of properties, the class has several properties that return parameters of the antenna system. These include properties like the number of antennas, the antenna spacing, patterns, and polarization.\n\nTo use the class, you would instantiate an object of the 'Antenna' class, setting desired parameters such as the antenna pattern, polarization, etc. Then, this object can be used in the creation of an antenna array object. \n\nPlease note that the class and its properties are based on the provided context, which doesn't provide the full implementation details. For the full set of properties and methods, the official documentation should be referred to."
"source code of TurboTermination: https://noot.com/mitsmc/sionna/blob/6.0.0/sionna/fec/turbo/utils.py#l1002-1046\n \n```python\nclass TurboTermination(Termination):\n    # pylint: disable=line-too-long\n    r\"\"\"TurboTermination(constraint_length, conv_n=2, num_conv_encs=2, num_bitstreams=3, conv_polynomial=(5, 7), ecb=True, dtype=tf.float32, name='TurboTermination')\n\n    Layer implementing various termination schemes for turbo codes.\n\n    This class inherits from the ``Termination`` class and can be used as\n    is implemented additional termination schemes.\n\n    For simplicity, one can terminate the Turbo code component-wise,\n    which is implemented by using the ``Termination`` class. The\n    example from the class documentation can be reused for component-wise\n    example.\n\n    Parameters\n    ----------\n        constraint_length: int\n            Constraint length of the encoder.\n\n        conv_n: int\n            Encoder's generator polynomials are of degree ``conv_n``.\n\n        num_conv_encs: int\n            Number of convolutional encoders used.\n\n        num_bitstreams: int\n            Number of Bit streams. Defaults to 3.\n\n        conv_polynomial: ndarray\n            Generator polynomial as binary sequence. If ``None``,\n            ``conv_n`` is used to find the polynomial.\n            Defaults to `None`.\n\n        ecb: bool\n            If `True`, the underlying convolutional encoders are\n            set to use the \"external code termination\",\n            i.e., the encoders are terminated to the all-zero state.\n            It is recommended to use this method for Turbo coding.\n\n        dtype: tf.DType\n            Defaults to `tf.float32`. Defines the global datatype\n            of the layer, including the precision. The precision of\n            the datatype is used for internal calculations.\n\n        name: str\n            A string representing the name of this `Layer`. Defaults\n            to \"TurboTermination\".\n\n    Input\n    -----\n        inputs: [...,k], tf.float32\n            2+D tensor containing the information bits. The last\n            dimension, ``k``, contains the information bits.\n\n    Output\n    ------\n        outputs: [...,k+num_term_bits], tf.float32\n            2+D tensor containing the terminated information bits.\n            The last dimension, ``k``, contains the information bits.\n            The additional ``num_term_bits`` bits are the\n            termination bits (if ``ecb`` is `True`, only the\n            information bits are returned).\n\n    Note\n    ----\n        Note that this layer is independent of the underlying encoder.\n        Not all termination schemes support the `ecb` flag.`\"\"\"\n\n    def __init__(self,\n                 constraint_length,\n                 conv_n=2,\n                 num_conv_encs=2,\n                 num_bitstreams=3,\n                 conv_polynomial=(5, 7),\n                 ecb=True,\n                 dtype=tf.float32,\n                 name=\"TurboTermination\"):\n\n        assert dtype in (tf.float16, tf.float32, tf.float64),\\\n                \"Unsupported dtype\"\n\n        self._dtype = dtype\n        self._num_term_bits = num_bitstreams*(2**conv_n - 1)\n        super().__init__(self._dtype,\n                         constraint_length,\n                         num_conv_encs,\n                         num_bitstreams,\n                         conv_polynomial,\n                         ecb,\n                         name)\n```"
"To wrap everything in a Keras model for convenient Bit Error Rate (BER) simulations and comparison of model parameters, follow these steps:\n\n1. **Importing necessary libraries and modules**: This includes TensorFlow, NumPy, and specific modules from the `sionna` package. \n\n2. **Setting up the simulation environment**: This involves configuring the GPU settings and importing the `load_mimo_perf` function from the `sionna.utils` module. \n\n3. **Defining the Keras model**: Create a new class that inherits from the `Model` class in Keras. In the `__init__` method of this class, initialize the OFDMSystem and LinearDetector. In the `call` method, generate a batch of random transmit vectors, pass them through the OFDM channel, and then detect and decode the received signal. \n\n4. **Setting up the training data**: Instantiate the Keras model and train it on a large set of random transmit vectors and their corresponding detections. \n\n5. **Evaluating different parameter settings**: Use the `PlaysWithCounting` utility class to compute BER. Then, run a loop where you instantiate different versions of the model and evaluate their performance. \n\n6. **Visualizing the results**: Use Matplotlib to visualize how the different parameter settings affect the performance. \n\nRemember to carefully choose the appropriate Sionna components and APIs to implement each part. For convenience, consider creating separate functions for setting up the GPU, importing necessary modules, and defining the OFDM / MIMO channel / estimator / detector / etc. You can then call these functions in the appropriate order to set up the Keras model and visualize the results."
"The \"build_type_grid\" method of the `ResourceGrid` class is not directly provided in the provided context. However, based on the context, a hypothesis can be made about what this method might do, its inputs, and its outputs.\n\nHypothesis:\nThe \"build_type_grid\" method might take the following inputs:\n- `ofdm_symbols: int, NumPy array`: This represents the number of OFDM symbols. It is an integer or array of integers where each integer corresponds to an OFDM symbol. This parameter indicates the number of resource elements in the time domain.\n- `sc_per_ofdm_symbol: int`: This represents the number of subcarriers per OFDM symbol. It is an integer.\n- `l_tot: int, NumPy array`: This represents the total number of (transmitted) streams. It is an integer or array of integers where each integer corresponds to a stream.\n- `l_d: int, NumPy array`: This represents the number of layers. It is an integer or array of integers where each integer corresponds to a layer.\n- `num_res_per_prb: int, NumPy array`: This represents the number of resource elements per PRB. It is an integer or array of integers where each integer corresponds to a resource element.\n- `num_cdm_groups_without_data: int, NumPy array`: This represents the number of CDM groups without data. It is an integer or array of integers where each integer corresponds to a CDM group.\n- `cyclic_prefix: str, one of (\"normal\", \"long\")`: This represents the cyclic prefix length and should be either \"normal\" or \"long\".\n- `precoding: str, None`: This represents the precoding method and must be either \"nonstd\" or \"ue_port\". If it is `None`, no precoding is used.\n- `data_dim: int, default None`: This represents the dimension of the transmitted data. It is an integer or `None` if the function is used to return a grid of candidate coding rates.\n- `num_pdsch_pat: int, default None`: This represents the number of PDSCH transmit (TM) ports and is an integer or `None` if data_dim is `None`.\n- `return_tf_grid: bool, default False`: If True, the function returns the frequency resource grid in the form of a `Tensorflow` tensor. Otherwise, it returns a `NumPy` array.\n\nThe output of the \"build_type_grid\" method is a 4D grid, `tf_grid`, of shape (`num_tx`, `num_layers`, `num_cdm_groups`, `num_ofdm_symbols_per_subcarrier`). This grid represents the resource elements for the OFDM resource grid and for all transmitters and streams. The shape of the grid can change based on the inputs parameters.\n\nPlease note that the hypothesis about the \"build_type_grid\" method is based on the context provided and might not fully reflect what the actual method does. The actual function might take different or additional inputs, or it might perform different operations. Please refer to the actual implementation or documentation for exact details."
"Here is the detailed information of [sionna.mapping.SymbolLogits2LLRs](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#SymbolLogits2LLRs):  \n  \nComputes log-likelihood ratios (LLRs) or hard-decisions on bits from a tensor of logits (i.e., un-normalized log-probabilities) on constellation points.  \n  \nThis class is deprecated as the functionality has been integrated into SymbolDemapper.  \nClass parameters\n\n- **method** (`str`) \u2013 Method used for computing the LLRs or hard decisions. Either \"app\" or \"maxlog\". Custom computation methods can be implemented by calling both `app` and `maxlog` computations and combining the results as needed.\n- **num_bits_per_symbol** (`int`) \u2013 Modulation order equal to the number of bits per constellation symbol.\n- **hard_out** (`bool`) \u2013 If True, the layer provides hard-decided bits instead of soft-values. Defaults to False.\n- **dtype** (`tf.DType`) \u2013 The dtype for the input and output. Defaults to tf.float32.\n\nInput\n\n- **logits** ([\u2026,n, num_points], `tf.float` or `tf.double`) \u2013 Logits on constellation points.\n\nOutput\n\n- [\u2026,n, num_bits_per_symbol], `tf.float` or `tf.int32` \u2013 LLRs or hard-deerrorctions for every bit of every symbol, where the sign of the LLR indicates the assumed bit sequence sign.  \n  \n**Note: ** \nWith the \u201capp\u201d method, the LLR for the $i\\text{th}$ bit is computed according to $LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert y,\\mathbf{c}\\right)}{\\Pr\\left(b_i=0\\lvert y,\\mathbf{c}\\right)}\\right) =\\ln\\left(\\frac{\n        \\sum_{c_j\\in\\mathcal{C}_{i,1}} \\Pr\\left(c_j\\lvert\\mathbf{x}\\right)\n        }{\n        \\sum_{c_j\\in\\mathcal{C}_{i,0}} \\Pr\\left(c_j\\lvert\\mathbf{x}\\right)\n        }\\right)$  \nwhere $\\mathcal{C}_{i,1}$ and $\\mathcal{C}_{i,0}$ are the sets of constellation points for which the $i\\text{th}$ bit is equal to jsonschema>, SymbolLogits2LLRs computes $LLR(i) = \\ln\\left(\\frac{\n        \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{x}\\right)\n        }{\n        \\sum_{c\\in\\mathcal{C_{i,0}}} \\Pr\\left(c\\lvert\\mathbf{x}\\right)\n        }\\right)$  \nwhere $\\mathcal{C}_{i,1}$ and $\\mathcal{C}_{i,0}$ are the sets of constellation points for which the $i\\text{th}$ bit is equal to 1 and 0, respectively.  \n  \nsource code:  \n```python\nclass SymbolLogits2LLRs(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"SymbolLogits2LLRs(method, num_bits_per_symbol, hard_out=False, dtype=tf.float32, **kwargs)\n\n    Computes log-likelihood ratios (LLRs) or hard-decisions on bits\n    from a tensor of logits (i.e., un-normalized log-probabilities) on\n    constellation points.\n\n    This class is deprecated as the functionality has been integrated\n    into :class:`~sionna.mapping.SymbolDemapper`.\n\n    Parameters\n    ----------\n    method : str\n        Method used for computing the LLRs or hard decisions. Either\n        \"app\" or \"maxlog\".\n\n    num_bits_per_symbol : int\n        Modulation order equal to the number of bits per constellation\n        symbol.\n\n    hard_out : bool\n        If `True`, the layer provides hard-decided bits instead of\n        soft-values. Defaults to `False`.\n\n    dtype : tf.DType\n        The `dtype` for the input and output. Defaults to `tf.float32`.\n\n    Input\n    -----\n    logits : [...,n, num_points], tf.float or tf.double\n        Logits on constellation points.\n\n    Output\n    ------\n    : [...,n, num_bits_per_symbol], tf.float or tf.int32\n        LLRs or hard-decisions for every bit of every symbol, where the\n        sign of the LLR indicates the assumed bit sequence sign.\n\n    Note\n    ----\n    With the \"app\" method, the LLR for the :math:`i\\text{th}` bit is\n    computed according to\n\n    .. math::\n\n        LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert y,\\mathbf{c}\\right)}{\\Pr\\left(b_i=0\\lvert y,\\mathbf{c}\\right)}\\right)\n               =\\ln\\left(\\frac{\n                    \\sum_{c_j\\in\\mathcal{C}_{i,1}} \\Pr\\left(c_j\\lvert\\mathbf{x}\\right)\n                    }{\n                    \\sum_{c_j\\in\\mathcal{C}_{i,0}} \\Pr\\left(c_j\\lvert\\mathbf{x}\\right)\n                    }\\right)\n\n    where :math:`\\mathcal{C}_{i,1}` and :math:`\\mathcal{C}_{i,0}` are the\n    sets of constellation points for which the :math:`i\\text{th}` bit is\n    equal to :math:`1` and :math:`0`, respectively.\n\n    With the \"maxlog\" method, LLR for the :math:`i\\text{th}` bit is\n\n    .. math::\n\n        LLR(i) =\\ln\\left(\\frac{\n            \\max_{c_j\\in\\mathcal{C}_{i,0}} \\Pr\\left(c_j\\lvert\\mathbf{x}\\right)\n                }{\n            \\max_{c_j\\in\\mathcal{C}_{i,1}} \\Pr\\left(c_j\\lvert\\mathbf{x}\\right)\n            }\\right)\n```  \n  "
"Here is the detailed information of MaximumLikelihoodDetector:   \n  \n[sion.mimo.MaximumLikelihoodDetector(output, demapping_method, num_streams, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)](https://jsonformatter.org/beta/?code=7n51027a97b_trf0-py#step-editor) \n\nMIMO maximum-likelihood (ML) detector\n\nThis layer implements MIMO maximum-likelihood (ML) detection for arbitrary numbers of streams and antennas. Both ML detection of symbols or bits with either soft- or hard-decisions are supported. The OFDM waveform and the resulting effective channels after SVD based precoding and precalculated channels are taken as inputs. If soft-decisions are requested, the log-likelihood ratios (LLRs) or hard-decision bits for each stream are returned.\n\n**Note:**\nAs of TensorFlow 2.0, only with XLA, i.e., within a function that is decorated with @tf.function(jit_compile=True), and when compute_precodes is set to true, one can use sion.mimo.compute_mimo_precodes to access the underlying implementation by providing the desired inputs.\n\n**Parameters**\n\n- `output` (str): What kind of output to return. Either \"bit\" for bits or \"symbol\" for symbols. Configuration for soft- or hard-decisions is done using the `hard_out` flag.\n- `demapping_method` (str): Demapping method used, choices are \"app\" or \"maxlog\".\n- `num_streams` (tf.int): Number of transmitted streams.\n- `constellation_type` (str): Type of constellation, options are \"qam\", \"pam\", or \"custom\". For \"custom\", an instance of Constellation must be provided.\n- `num_bits_per_symbol` (int): Number of bits per constellation symbol, e.g., 4 for QAM16. Required for constellation types \"qam\" and \"pam\".\n- `constellation` (Constellation): Instance of Constellation or None. If None, both `constellation_type` and `num_bits_per_symbol` must be specified.\n- `hard_out` (bool): If true, computes hard-decided bit values or the constellation point indices instead of soft-values. Defaults to False.\n- `dtype` (tf.Dtype): The dtype of `y`. Defaults to tf.complex64. The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n**Input**\n\n- `(y, eff_channel, precoded_channel, n0, obs_var)` \u2013 Tuple:\n  - `y` ([..., num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex): Received OFDM resource grid after cyclic prefix removal and FFT.\n  - `eff_channel` ([..., num_rx, num_rx_ant, num_tx, num_tx_ant, num_ofdm_symbols, num_effective_subcarriers], tf.complex): Effective channels for all streams after precoding.\n  - `precoded_channel` ([..., num_rx, num_rx_ant, num_tx, num_tx_ant, num_ofdm_symbols, num_effective_subcarriers], tf.complex): Effective channels for all streams corresponding to the precoded subcarriers.\n  - `n0` ([..., num_rx, num_rx_ant] or just `[..., num_rx, num_rx_ant]`, tf.float): Variance of the AWGN.\n  - `obs_var` ([...], tf.float): Variance estimate for every resource element.\n\n**Output**\n\nDepending on the `output` setting:\n- If `output` equals \"bit\":\n  - [..., num_tx, num_streams, num_data_symbols * num_bits_per_symbol], tf.float: LLRs or hard-decisions for every bit of every stream.\n- If `output` equals \"symbol\":\n  - [..., num_tx, num_streams, num_data_symbols, num_points], tf.float or [..., num_tx, num_streams, num_data_symbols], tf.int: Logits or hard-dejsons for constellation symbols for every stream. Hard-decisions correspond to the symbol indices.\n\n**Properties**\n\n- `constellation`: Instance of Constellation used for the detector.\n- `hard_out`: Indicates if the detector is configured for hard-decisions.\n- `num_candidate_streams`: Number of candidate streams which ML detection was configured for. This is equal to either `num_streams` or 1, depending on the value of `num_streams_config`.\n- `num_interfering_streams`: Number of interfering streams.\n- `num_ofdm_symbols`: Number of OFDM symbols.\n- `num_points`: Number of constellation points.\n- `num_rx`: Number of receivers.\n- `num_rx_ant`: Number of antennas per receiver.\n- `num_streams_config`: List of the configured number of streams per transmitter.\n- `num_tx`: Number of transmitters.\n- `num_tx_ant`: Number of antennas per transmitter.\n- `output`: The configured output type of the detector."
"To initialize a `TurboEncoder` with custom generator polynomials, one needs to provide the `constraint_length` and the `gen_poly` parameters. The `constraint_length` is an integer specifying the constraint length of the encoder, and `gen_poly` is a tuple or list of strings. Each string in `gen_poly` represents a binary format of the generator polynomial. Here's how you might initialize a `TurboEncoder` with custom generator polynomials:\n\n```python\nfrom sionna.fec.turbo import TurboEncoder\n\n# Define the custom generator polynomials\ngen_poly = (\"101\", \"111\")  # Each string is a binary format of the polynomial\n\n# Initialize the TurboEncoder with the custom polynomials\nturbo_encoder = TurboEncoder(constraint_length=3, gen_poly=gen_poly)\n```\n\nThe generator polynomials are binary strings that represent the connection between thejsonshift registers in the constituent convolutional encoders used in the Turbo code. The `gen_poly` parameter expects a tuple where each string in the tuple represents the binary format of the polynomial. Each bit pattern in the string is an integer or a coefficient of the polynomial, with the zeroth coefficient being the leftmost bit of the string.\n\nFor the example `gen_poly = (\"101\", \"111\")`:\n- The first polynomial `101` is equivalent to the polynomial 1 + D^2 + D^3, which is the polynomial in binary format used to define the connections and the output symbols of the first convolutional encoder in the Turbo code.\n- The second polynomial `111` is equivalent to the polynomial 1 + D + D^2, which is the polynomial in binary format used to define the connections and the output symbols of the second convolutional encoder in the Turbo code.\n\nA binary sequence like \"10011\" represents the message bits that the encoder will process. In the context of Turbo codes, the message will be segmented into multiple pieces and then mapped to individual codewords produced by the underlying convolutional encoders. The example sequence \"10011\" will be segmented into two pieces, with the first two bits going to the first encoder and the last three bits going to the second encoder. The specific arrangement of the bits is determined by the `puncturing pattern` used to ensure that the Turbo codeword has a consistent rate."
"To sample the first few items of the dataset using the generator, follow these steps:\n\n1. Import the necessary modules and set up the environment:\n\n```python\nimport os\nimport tensorflow astry\nimport mitestry\n```\n\n2. Define the parameters for sampling:\n\n```python\n# simulation parameters\nnum_p = 4\nsamples_per_symbol = 2\nnum_symbols = 100\n```\n\n3. Define the generator:\n\n```python\ntf_generator = mitestry.utils.SignalDatasetGenerator(\n   batch_size = 16,\n   num_samples = int(num_symbols*samples_per_symbol*num_p),\n   num_p = num_p,\n   samples_per_symbol = samples_per_symbol,\n   fn = None,\n   with_labels = False,\n   one_hot = False,\n   dtype = tf.complex64\n)\n```\n\n4. Sample the first batch of data:\n\n```python\n# S for samples\n# X for waveforms\nS, X = tf_generator(16)\n```\n\n5. Print the shapes of the samples and waveforms:\n\n```python\nprint(S.shape)\nprint(X.shape)\n```\n\nThe `S` object represents the time-parallel baseband symbols, while the `X` object represents the corresponding waveform signals. The shapes of these objects represent the batch size and the length of the signals (in time and frequency domains, respectively)."
"To save the estimated matrices for future use, you can use the NumPy function `numpy.save`. This function saves the input to a file as a NumPy array. Here's how you can do it:\n\n```python\nimport numpy as np\n\n# Save the estimated matrices\nnp.save(\"F_hat.npy\", F)\nnp.save(\"F_MAT.npy\", F_MAT)\nnp.save(\"Frequencies.npy\", frequencies)\nnp.save(\"Gammas.npy\", gammas)\nnp.save(\"A_MAT.npy\", A_MAT)\nnp.save(\"A_sum_MAT.npy\", A_sum_MAT)\nnp.save(\"A_ind_MAT.npy\", A_ind_MAT)\nnp.save(\"A_scattering_MAT.npy\", A_scattering_MAT)\nnp.save(\"F_800.npy\", F_800)\nnp.save(\"lambdas.npy\", lambdas)\nnp.save(\"KAPPAS.npy\", kappas)\nnp.save(\"TAUS.npy\", taus)\nnp.save(\"F_1900.npy\", F_1900)\nnp.save(\"F_2400.npy\", F_2400)\nnp.save(\"F_2800.npy\", F_2800)\nnp.save(\"F_3800.npy\", F_3800)\nnp.save(\"F_5200.npy\", F_5200)\nnp.save(\"F_7000.npy\", F_7000)\nnp.save(\"F_8800.npy\", F_8800)\nnp.save(\"F_21400.npy\", F_21400)\n```\n\nThis code saves each matrix as a separate `.npy` file. The matrices are saved with the same name as the key used to index them in the `F_hat` dictionary. This ensures that when you load the saved matrices, they will have the correct key."
"Iterative Detection and Decoding (IDD) is a crucial technique in MIMO (Multiple Input, Multiple Output) simulations, specifically in the context of MIMO networks. This technique is used to improve the performance of MIMO systems by tackling two primary challenges: \n\n1. The noisy channel model \n2. The soft-solution (i.e., LLR) domain representation \n\nTo understand IDD, we need to delve into the process of MIMO simulations. When a simulation starts, the system initializes certain components such as an LDPC (Low-Density Parity-Check) encoder and decoder, a mapper and demapper for constellation operation, an AWGN (Additive White Gaussian Noise) channel, and a priori detectors. These detectors are used to generate Log-Likelihood Ratios (LLRs) from the received noisy symbols.\n\nThe traditional way of simulating MIMO systems involves passing the modulation symbols through the channel, generating the noisy channel observations, and then running the LDPC on these observations. This method, however, is suboptimal as the detector is designed for hard-decisions rather than soft-decisions.\n\nThis is where IDD comes into play. IDD converts the hard-decision detector into an soft-decision equivalent. It does this by running the detector on an artificial error channel, generating soft-symbols (or LLRs). These soft-symbols are then passed to the decoder. The decoder, such as the BP (Bit-Parallel) decoder, can then make use of the soft-symbols to improve the detection accuracy.\n\nIDD involves two main steps: \n\n1. Detection Step: The hard-decision detector is run on the noisy channel observations to generate LLRs. This is done on an artificial error channel, which is a good approximation of the channel for MIMO simulations.\n\n2. Decoding Step: The soft-symbols (LLRs) are then passed to the decoder, such as the BP decoder. The decoder uses these soft-symbols to make more accurate decisions about the transmitted bits.\n\nThese steps are iterated over a number of iterations. The more the number of iterations, the better the performance is expected to be. However, a large number of iterations also leads to increased computational complexity. \n\nIn the context of IDD, Sionna provides a IDDBP decoder, which is an IDD wrapper of BP decoders. This allows to use IDD with any BP decoder without modification of the decoder itself. Please note that the currently available decoders with IDD are: BP, BP-C, and LDPC BP. \n\nTo use IDD, you would create an instance of the IDDBP decoder by providing an existing BP decoder and the number of iterations as parameters:\n\n```python\ndecoder = IDDBP(decoder=bp_decoder,      # Existing BP decoder\n                num_iter=6)               # Number of iterations\n```\n\nThen, you would use this decoder as you would use a traditional decoder:\n\n```python\noutput = decoder(llr)\n```\n\nOverall, IDD is a significant technique that can lead to improved performance in MIMO simulations, particularly when used with decoders that operate on soft-decisions."
"Here is the detailed information of Descrambler:  \n[sionna.fec.scrambling.Descrambler(scrambler, binary=True, dtype=tf.float32, **kwargs)](Descrambler.html#sionna.fec.scrambling.Descrambler, binary=True, dtype=tf.float32, **kwargs)  \n  \nDescrambler for a given scrambler.\n\nThe class inherits from the Keras layer class and can be used as layer in a Keras model.  \n  \n#### Parameters\n\n- `scrambler` (Scrambler, TB5GScrambler):  \n    Provide the associated scrambler which shall be descrambled.\n\n- `binary` (bool):  \n    Defaults to True. Indicates whether bit-sequence should be flipped (i type) or the signs should be flipped (b type).\n\n- `dtype` (tf.DType):  \n    Defaults to tf.float32. Defines the datatype for internal calculations and the output dtype.\n\n#### Input\n\n- `x` ([...,n], tf.float):  \n    2+D tensor of arbitrary shape where the last dimension refers to the sequence to descramble.\n\n#### Output\n\n- `[...,n], tf.float`:  \n    2+D tensor of the same shape and dtype as the input `x`, containing the descrambled sequence.\n\n#### Properties\n\n- `scrambler` (Scrambler):  \n    Associated scrambler instance.\n\n- `binary` (bool):  \n    Indicates whether bit-sequence should be flipped (i type) or the signs should be flipped (b type).\n\n- `dtype` (tf.DType):  \n    Datatype for internal calculations and the output dtype."
"Here is the definition of KBestDetector: sipeed.mimo.KBestDetector(k, mimo_channel, num_symb, output2int, llr_fun, dtype=tf.complex64)\n  \n[source code](https://kheaanalytics.gitlab.io/sipeed/_modules/sipeed/mimo/detection.html#KBestDetector) \n\nsource code:\n```python\nclass KBestDetector(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"KBestDetector(k, mimo_channel, num_symb, output2int, llr_fun, dtype=tf.complex64)\n\n    MIMO K-Best detector\n\n    This layer implements K-Best MIMO detection as described\n    in (Eq. 4-5) [FT2015]_. It can generate either symbol or bit-wise Log-Likelihood\n    Ratios (LLRs).\n\n    The algorithm operates in two domains. Firstly, the received signals are transformed\n    into either symbol soft estimates or LLRs using the :class:`~sipeed.mimo.S2D`\n    or :class:`~sipeed.mimo.S2D` transformations, respectively.\n    These transformations are applied to the channel outputs :math:`\\mathbf{y}` and channel\n    variances :math:`\\sigma^2` as described in Section II of [FT2015]_.\n    The resulting LLRs or soft symbols are then given as\n\n    .. math::\n\n        \\begin{align}\n            \\LLR_{b,n} &= 2\\operatorname{Re}\\left[\\operatorname{arctanh}\\left(\\sum_{j=1}^{\\min(k,N)} \\exp\\left(-\\frac{1}{2}\\sigma^2_{j,n}\\bigg\\rvert  y_{j,n} \\bigg\\rvert^2 \\right) \\operatorname{sign}\\left(y_{j,n}\\right)\\right] \\\\\n            \\text{or}\\\\\n            \\hat{s}_{k,n} &= \\frac{1}{\\sqrt{2\\pi\\sigma^2_{k,n}}}\n            \\int_{\\mathcal{R}(h_{k,n})}\n            \\exp \\left(-\\frac{1}{2}\\sigma^2_{k,n}\\bigg\\rvert  y_{j,n} \\bigg\\rvert^2 \\right)  \\, \\text{d}r\n        \\end{align}\n\n    where :math:`\\mathcal{R}(h_{k,n})` defines the region where :math:`\\mathcal{R}(h_{k,n})=\\left\\{r\\in\\mathbb{R} \\,\\rvert\\, \\lvert r-h_{k,n} \\rvert \\leq \\frac{1}{2}\\sigma^2_{k,n} \\right\\}`,\n    with :math:`h_{k,n}` denoting the :math:`n\\text{th}` subcarrier and :math:`k\\text{th}` stream.\n    The quantities :math:`\\LLR_{b,n}` and :math:`\\hat{s}_{k,n}` are calculated for each bit\n    channel and stream, respectively.\n\n    Finally, the K-Best algorithm is used to generate :math:`N^k` possible symbol\n    or bit vectors, where :math:`N` is the number of streams (dual-polarized\n    antennas) and :math:`k` is the number of candidate signals.\n    For every path, the channel estimate and error\n    covariance matrix are computed according to the current symbol hypothesis.\n    The symbol (or bit) soft estimates and effective noise variances are then\n    returned.\n\n    **LLRs Mode:**\n\n    In \"LLR mode\", the MIMO K-Best detector produces LLRs for every bit of\n    every stream. The procedure is fully analogous to the \"LLR K-Best Detector\"\n    in :class:`~sipeed.mimo.KBestDetector`. However, an additional scaling\n    as defined in (5) in [FT2015]_ is applied at the end.\n\n    Parameters\n    -----------\n    k : int\n        The number of paths to keep. Cannot be larger than the number\n        of candidate signals :math:`N` to the power of the number of streams.\n\n    mimo_channel : :class:`~sipeed.mimo.MIMOChannel`\n        An instance of :class:`~sipeed.mimo.MIMOChannel`\n\n    num_symb : int\n        The number of OFDM symbols\n\n    output2int : :class:`~sipeed.mimo.Output2Int`\n        Layer implementing the symbol to bit mapping as well as the\n        symbol demapping.\n\n    llr_fun : Callable\n        The callable to be used to compute the LLRs from a vector of\n        logits. This is ignored if ``method`` is `\"app\"`.\n        Possible choices are :func:`~sipeed.mapping.Demapper` or\n        :func:`~sipeed.utils.Logits2LLRs`.\n\n    dtype : tf.Dtype\n        The datatype for internal calculations and the output dtype.\n        Defaults to `tf.complex64`.\n\n    Input\n    -----\n    (y, h, s) :\n        Tuple:\n\n    y : [..., num_rx, num_ofdm_symbols, n], tf.complex\n        Received signals\n\n    h : [..., num_rx, num_tx, num_ofdm_symbols, n], tf.complex\n        Channel matrices\n\n    s : [..., num_rx, num_rx, num_ofdm_symbols, n, n], tf.complex\n        Noise covariance matrices\n\n    Output\n    ------\n    One of:\n\n    : [..., num_tx, num_streams_per_tx, num_data_symbols], tf.float\n        LLRs or hard-decisions for every bit of every stream, if ``output2int``\n        is configured to `\"hard\"``\n\n    : [..., num_tx, num_streams_per_tx, num_data_symbols, num_bits_per_symbol], tf.float\n        Logits or hard-dedecisions for constellation symbols for every stream, if\n        ``output2int`` is configured to `\"soft\"`. Hard-decisions results in bit-wise\n        computations.\n\n    Note\n    ----\n    If you want to use this layer in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sipeed.Config.xla_compat=true``.\n    See :py:attr:`~sipeed.Config.xla_compat`.\n    \"\"\"\n    def __init__(self,\n                 k,\n                 mimo_channel,\n                 num_symb,\n                 output2int,\n                 llr_fun,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        assert k >= 1\n        assert output2int.method in (\"hard\", \"soft\")\n\n        self._k = k\n        self._num_symb = num_symb\n        self._output2int = output2int\n        self._llr_fun = llr_fun\n\n        # instantiate S2D object\n        self._s2d = S2D(mimo_channel, self._num_symb, dtype=dtype)\n\n        # number of streams (dual-polarized antennas are counted as one)\n        self._num_streams = np.shape(mimo_channel.h_out)[2]\n        self._stream_manager = StreamManagement(self._num_streams,\n                                                 num_streams_per_tx=2) # manage two streams per transmitter\n\n        # determine the number of possible paths\n        n = np.min([np.shape(mimo_channel.h_out)[0],\n                      np.shape(mimo_channel.h_out)[1],\n                      self._k])\n        self._n = np.min([n, self._num_streams])\n        self._num_paths = int(np.power(self._n, self._k))\n        self._kbest_selector = KBestSelector(self._num_paths,\n                                             dtype=dtype)\n\n    def _preprocess_inputs(self, inputs):\n        y, h, s = inputs\n        # (num_tx, num_streams_per_tx, num_data_symbols)\n        y, h, s = self._stream_manager([y,h,s])\n        return y, h, s\n\n    def _select_best_paths(self, logits, err_var):\n        # generate all possible paths\n        # err_var: tf.float or tf.float32 (under XLA)\n        err_var = tf.cast(err_var, self._dtype)\n        a = tf.repeat(tf.expand_dims(logits, -2), self._n, axis=-2)\n        b = tf.tile(tf.expand_dims(err_var, -1), [1, self._k, self._n])\n        b = tf.repeat(b, self._n, axis=-1)\n        b = tf.transpose(b, [0, 2, 1])\n        # shape: [..., num_tx, num_streams_per_tx, num_kbest_paths, num_data_symbols]\n        logits = tf.reshape(a, tf.shape(a)[:-2])\n        err_var = tf.reshape(b, tf.shape(b)[:-2])\n\n        # select the k best paths\n        # shape: [..., num_tx, num_streams_per_tx, num_kbest_paths, num_data_symbols]\n        logits, indices = self._kbest_selector(logits)\n        err_var = tf.gather(err_var, indices, axis=-2)\n\n        # transpose to final shape\n        # shape: [..., num_tx, num_streams_per_tx, num_data_symbols, num_kbest_paths]\n        logits = tf.transpose(logits, tf.shape(logits)[-2:])\n        err_var = tf.transpose(err_var, tf.shape(err_var)[-2:])\n\n        return logits, err_var\n\n    def _postprocess(self, logits):\n        if self._output2int.method == \"hard\":\n            return self._output2int(logits)\n        else:\n            return self._llr_fun(self._output2int(logits))\n\n    def call(self, inputs):\n        \"\"\"KBestDetector.call(inputs)\n\n        This is the K-Best MIMO Detector. It assumes the\n        model presented in Section II of [FT2015]_.\n\n        Input\n        -----\n        inputs : tuple\n            Tuple containing the following elements:\n\n        y : [...,batch_size,num_rx_per_tx, num_ofdm_symbols,fft_size], tf.complex\n            Received signals\n\n        h : [...,batch_size,num_rx_per_tx, num_tx, num_ofdm_symbols,fft_size], tf.complex\n            Channel frequency response\n\n        s : [...,batch_size,num_rx_per_tx, num_rx_tx, num_ofdm_symbols,fft_size], tf.complex\n            Noise covariance matrix\n\n        Output\n        ------\n        One of:\n\n        : [..., batch_size, num_tx, num_streams, num_data_symbols], tf.float\n            LLRs for all bits of every stream, if ``output2int`` is `\"hard\"`\n\n        : [..., batch_size, num_tx, num_streams, num_data_symbols, 1], tf.float\n            LLRs or hard-decisions for bits of every stream, if\n            ``output2int`` is `\"soft\"`. Hard-decisions are computed\n\n            .. math::\n\n                \\hat{b}_n = \\left\\{\n                    \\begin{align}\n                        0, &\\ text{ if } \\hat{s}_n \\text{ is the } 0\\text{ symbol} \\\\\n                        1, &\\ otherwise\n                    \\end{align}\n                \\right.\n            \"\"\"\n        # y,h,s = self._preprocess_inputs(inputs)\n        y, h, s = inputs\n\n        # prepare errros var for each stream (or pol)\n        err_var_stream = self._stream_manager.err_var(h, s)\n\n        # transform to symbol domain\n        y, h, err_var = self._s2d([y,h,err_var_stream])\n\n        # apply k-best detection\n        logits, err_var = self._select_best_paths(y, err_var)\n\n        # transform back to ofdm / subcarrier domain\n        llr = self._s2d([logits, h, err_var, \"logits\"])\n\n        # hard decisions at every symbol position\n        return self._postprocess(llr)\n```"
"The `position` and `orientation` properties in Sionna are used to move and rotate scene objects, suchjson as transmitters, receivers, and antennas. \n\nThe `position` property is a three-component vector that defines the X, Y, and Z coordinates of a point in the scene. When `position` is updated, the scene re-adjusts the geometric arrangement of scene objects accordingly. For instance, to move a transmitter 10 meters along the y-axis, you could modify its `position` property like so:\n\n```python\ntx_array.position += [0, 10, 0]\n```\n\nThe `orientation` property is a quaternion that expresses a rotation. This property can be modified like so:\n\n```python\ntx_array.orientation = Rotation.from_euler_angles(0,0,pi/2)\n```\n\nThis adjusts the orientation of the transmitter to a 90-degree rotation around the z-axis. \n\nBoth `position` and `orientation` properties can be passed as arguments during the initialization of scene objects, allowing for the creation of diverse configurations within the scene. For instance:\n\n```python\nscene = load_scene()\nscene.add(Transmitter(\"tx\", position=[-scene.rx_array.size/2, 0, 0]))\nscene.add(Receiver(\"rx\", position=[scene.rx_array.size/2, 0, 0]))\n```\n\nIn this example, a transmitter and receiver are added to the scene at mirror positions along the x-axis. The use of the `position` property allows for the precise placement of these devices within the scene. \n\nIn summary, `position` and `orientation` properties allow for the manipulation of the physical location and orientation of scene objects, enabling a greater degree of control over the configuration and layout of the scene."
"To run the final evaluation for different system configurations in Sionna RT, you need to follow these steps:\n\n1. **Set up the environment**: Import the necessary packages and set up the environment. This includes setting the GPU configuration, importing the Sionna package, and setting the random seed.\n\n2. **Load the scene**: Use the `load_scene` function from the Sionna RT package to load the scene you want to evaluate. The scene could be an integrated scene or an external scene file.\n\n3. **Configure the Transmitters and Receivers**: Use the `Transmitter` and `Receiver` classes to configure the transmitters and receivers in the scene. Set the position, orientation, and other parameters as required.\n\n4. **Set the OFDM Channel**: Use the `OFDMChannel` class to set up the wireless channel model. This model will generate the channel impulse responses between all transmitters and receivers.\n\n5. **Run the Final Evaluation**: Use the `final_evaluation` method of the scene object to run the final evaluation. This method takes several parameters such as the SNR range, number of evaluation positions, batch size, and others. The final evaluation will compute the NMSE for the given configuration.\n\nHere is a simplified example of how you might do this:\n\n```python\n# Set up the environment\nimport os\nimport tensorflow as tf\nfrom sionna.rt import load_scene, Transmitter, Receiver, OFDMChannel\n\n# Set up GPU configuration\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\n# Load the scene\nscene = load_scene(sionna.rt.scene.munich)\n\n# Configure the Transmitters and Receivers\ntransmitter = Transmitter(\"tx\", [5.5,21.2,27.6], [np.pi,0,3.4e9])\nreceiver = Receiver(\"rx\", [35,53,1.8], [0,0,-3.0])\nscene.add(transmitter)\nscene.add(receiver)\n\n# Set the OFDM Channel\nchannel = OFDMChannel(scene,\n              resource_grid=scene.tx.resource_grid,\n              delay_spread=30e-9,\n              doppler_spectrum=[0.0, 0.01, 30],\n              num_paths=100,\n              los=False,\n              k_factor=-15)\n\n# Run the Final Evaluation\n# The NMSE will be computed and printed for different system configurations\nscene.final_evaluation(snr_db=np.linspace(-10, 20, 20), batch_size=64)\n```\n\nPlease note that this is a simplified example and the actual code may require additional steps and parameters depending on the specific requirements of your task."
"The exact Doppler shift for a specific sample in a given time step can be computed using the equation provided in the Background Information. The equation is a product of two terms: the first term corresponds to the time evolution of the Doppler shift based on the velocities of the Tx and Rx, while the second term is the spatial correlation of the channel frequency response. \n\nHere is the computation, assuming that you have the necessary parameters:\n- `velocities_t_m` is a tensor of shape `[batch_size, num_rx, 3]` that contains the velocities of all receivers in the direction of movement at time `t - 1`.\n- `velocities_t` is a tensor of shape `[batch_size, num_rx, 3]` that contains the velocities of all receivers in the direction of movement at time `t`.\n- `lambdas` is a tensor of shape `[batch_size, num_rx, 3]` that contains the path gains of all channel paths in the current time step.\n- `k` is the timestep.\n\nCompute the first term (`doppler_shifts_time`):\n```python\ndoppler_shifts_time = tf.reduce_sum(velocities_t * lambdas, axis=-1) * frequencies * ts * tf.cast(num_time_steps - k, tf.float32) / speed_of_light\n```\n\nCompute the second term (`doppler_shifts_space`):\n```python\ndoppler_shifts_space = tf.reduce_sum(velocities_t - velocities_t_m * tf.expand_dims(velocities_tau, axis=-1), axis=-1) * tf.reduce_sum(lambdas, axis=-1) * tf.cast(spatial_corr_t, tf.float32) / tf.abs(w)\n```\n\nFinally, compute the exact Doppler shifts (`doppler_shifts_exact`):\n```python\ndoppler_shifts_exact = doppler_shifts_time + doppler_shifts_space\n```\n\nPlease note that you need to have the parameters `num_time_steps`, `ts`, `speed_of_light`, `frequencies`, `velocities`, `velocities_t`, `velocities_t_m`, `velocities_tau`, and `spatial_corr_t` defined and computed before executing this computation. The output is a scalar for each sample in the batch, and describes the total Doppler shift for all channel paths and receivers at a specific time step."
"Here is the definition of cir_to_time_channel: sionna.channel.cir_to_time_channel(bandwidth, a, tau, l_min, l_max, num_time_samples)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/utils.html#cir_to_time_channel)  \nsource code:\n```python\ndef cir_to_time_channel(bandwidth, a, tau, l_min, l_max, num_time_samples):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Compute the channel taps forming the discrete complex-baseband\n    representation of the channel from the channel impulse response (a,tau).\n\n    The channel taps are computed for a given bandwidth and number of\n    time samples, assuming a sinc-shaped pulse\n    is used for transmit and receive filtering.\n\n    Parameters\n    ----------\n    bandwidth : float\n        Bandwidth (:math:`B_w`) [Hz]\n\n    a : tf.complex, shape [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps].\n        Path coefficients of the channel impulse response\n\n    tau : tf.float, shape [batch size, num_rx, num_tx, num_paths]\n        Path delays of the channel impulse response [s]\n\n    l_min : int\n        Smallest time-lag for the discrete complex baseband channel (:math:`L_{\\text{min}}`) [s]\n\n    l_max : int\n        Largest time-lag for the discrete complex baseband channel (:math:`L_{\\text{max}}`) [s]\n\n    num_time_samples : int\n        Number of time samples forming the discrete complex baseband channel\n        (:math:`N_{\\text{B},L}`) []\n\n    Output\n    ------\n    h_time : tf.complex, shape [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_samples].\n        Channel taps forming the discrete complex-baseband representation\n        of the channel\n        response\n    \"\"\"\n\n    # Eq. (4) in the paper [CIR to Time Channel Paper](https://nvlabs.github.io/sionna/api/channel.utils.html#cir-to-time-channel)\n    # h_time : [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_samples]\n    # h_time_l : [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, l_max - l_min + 1, num_time_samples]\n    hw_time_l = np.zeros([h_time_l.shape[0], h_time_l.shape[1], h_time_l.shape[2], h_time_l.shape[3], h_time_l.shape[4], h_time_l.shape[5], h_time_l.shape[6]], np.complex64)\n    hw_freq = np.sum(a, axis=(2,5))\n    for b in range(h_time_l.shape[0]):\n        for r in range(h_time_l.shape[1]):\n            for i in range(h_time_l.shape[3]):\n                for p in range(h_time_l.shape[4]):\n                    hw_time_l_l = np.zeros([l_max - l_min + 1, num_time_samples])\n                    for l in range(l_min, l_max + 1):\n                        hw_time_l_l[l-(l_min)] = np.exp(j*2*np.pi*bandwidth*t*1.0e-3)\n                    hw_time_l_l = np.expand_dims(hw_time_l_l, axis=1)\n                    hw_time_l_l = np.tile(hw_time_l_l, [1, num_time_steps])\n                    hw_time_l_l = np.amax(np.abs(hw_freq[b,r,i,p]), 2)*hw_time_l_l\n                    hw_time_l_l = np.sum(hw_time_l_l, axis=2)\n                    hw_time[b,r,i,p,l_min-l_min:l_max-l_min+1] = hw_time_l_l\n    h_time = np.fft.fftshift(np.fft.ifft(hw_time, axis=-1), axes=-1)\n    h_time = np.sqrt(1.0/num_time_samples) * tf.cast(np.prod(antenna_array_shape), dtype=h_time.dtype) * tf.real(h_time)\n    return h_time\n```  \n  "
"To generate the Channel Frequency Response (CFR) and the Discrete-Time Channel Impulse Response (CDIR) using the Sionna MIMO model, you can follow these steps:\n\n1. Initialize the model:\n```python\nmodel = MIMO_Model(num_tx_ant = 4,\n               num_rx_ant = 32,\n               spatial_corr_model = 'exp',\n                spatial_corr_time = 1e-6,\n               channel_bandwidth = 3.5e9)\n```\n\n2. Sample channel responses:\n```python\na, tau = model.sample()\n```\n\n3. Calculate the CFR:\n```python\nf = np.fft.fft(a, axis=1)/np.sqrt(num_rx_ant)\ncfr = np.mean(f, axis=1)\n```\n\n4. Calculate the CDIR:\n```python\nh_hat = np.sum(a, axis=1)/np.sqrt(num_rx_ant)\nh_hat = np.pad(h_hat, ((0, 0), (0, num_rx_ant - 1)))\ncdir = np.fft.ifft(h_hat, axis=1)\n```\n\nIn this code, the `MIMO_Model` is initialized with the number of transmit and receive antennas, a spatial correlation model, and other parameters. The `sample()` method is then used to sample the channel responses, and the CFR and CDIR are calculated from the sampled data. \n\nPlease note that the actual implementation may vary depending on the specific requirements of your application."
"Higher order modulation is a technique used in digital communication systems to increase the data rate without changing the bandwidth. It achieves this by encoding multiple bits into a single symbol. The number of bits per symbol, i.e., the modulation order, is denoted as `constellation_size`. \n\nHigher order modulation plays a crucial role in the performance of communication systems. It significantly influences the design and implementation of the demapper and decoder, which are used to recover the transmitted information at the receiver end. \n\nThe demapper is a key component of a receiver system in digital communication. Its role is to translate the received signal back into the original sequence of bits. In higher order modulation, the demapper discretizes the analog domain into separate regions for each possible transmitted symbol. The demapper assigns each received sample to the nearest symbol location and then outputs the corresponding binary representation of this symbol. \n\nThe decoder is another critical element of a receiver system. It is used to recover the transmitted information from the received bits, which have been modulated and demodulated. In higher order modulation, the decoder effectively processes multiple bits (in the form of a binary string) simultaneously by operating on each bit of the symbol individually. This allows the decoder to effectively correct a greater number of errors compared to a traditional decoder operating on individual bits.\n\nIn the context of Sionna, a simulation environment for optical communication, higher order modulation is supported through the `Constellation` and `Mapper` classes. The `Constellation` class is used to define the constellation points, which represent the different states of the qubits in quantum communication. The `Mapper` class maps bits to constellation points prior to modulation over an optical channel. The demapper and decoder are closely related to these components, as they are used to reconstruct the transmitted bit sequence from the received noisy bits.\n\nThe accurate and efficient operation of the demapper and decoder is vital for the performance of higher order modulation schemes. In the case of quantum communication, the Bit-LLR demapping algorithm is particularly effective, as it allows for the estimation of the soft values of each bit without requiring prior knowledge of the transmitted constellation."
"To demonstrate how to handle the situation where the `LDPCBPDecoder` is stateful in Sionna, I will provide an example based on the provided context, explaining the significance of the `msg_vn` parameter.\n\nIn the context, we see that `LDPCBPDecoder` is instantiated with the `boxplus` stopping criterion, indicating that the class is stateful. This is because the decoder maintains internal state, specifically the check node messages (`msg_cn`) and the variable node messages (`msg_vn`), which are updated during the decoding process. This is an iterative process where each forward pass through the Tanner graph using incoming messages from the VN and CN update rules, and outgoing messages from the VN and CN update rules are computed.\n\nThe `msg_vn` parameter in `LDPCBPDecoder` is crucial when the decoder is stateful. This parameter represents the variable node messages, also known as the 'a priori' (or systematic prior) in the belief propagation decoding algorithm. These messages are an input to the BP decoder and also form the output of the decoder after the update process. The decoder uses the received LLRs (`llr_ch`) and the `msg_vn` to compute outgoing messages to the check nodes, and these messages are in turn used to compute the next iteration of variable node messages.\n\nIt's important to provide the `msg_vn` parameter when creating an instance of the `LDPCBPDecoder`. If `msg_vn` is set to `None` (the default value), the decoder creates fresh outgoing messages from the check node to the variable node for each iteration, which would not reflect the desired iterative decoding process. By providing an initial `msg_vn`, the decoder can use the incoming messages from the previous decoding iteration to compute the outgoing messages, which is crucial for the performance of the decoding process.\n\nHere is a Python example of how to instantiate an `LDPCBPDecoder` from the Sionna library, providing an appropriate `msg_vn` parameter:\n\n```python\nfrom sionna.fec.ldpc import LDPCBPDecoder\nimport numpy as np\n\n# Define the shape of the bit array of '0's and '1's, for example, [n, k].\n# Ensure that 'n' and 'k' are positive integers and that 'n' > 'k'.\nshape = [1024, 512]\n\n# Create an instance of LDPCBPDecoder with 'boxplus' stopping criterion.\n# The `msg_vn` parameter is required when the decoder is stateful.\ndecoder = LDPCBPDecoder(bipartite, num_iter=20, boxplus=True, msg_vn=None, check_node_type='boxplus')\n\n# Generate a random tensor of '0's and '1's with the desired shape.\n# Ensure that the data type of the array is np.int32 to match the decoder's requirement.\narray = np.random.randint(2, size=shape, dtype=np.int32)\n\n# `array` is a placeholder for the actual LDPC encoded data, and needs to be\n# replaced with the actual data if available. \n\n# Call the decoder with the `array` tensor. The output will be\n# a tensor containing the estimated codeword bits.\ndecoded_bits = decoder(array)\n\n# Print the shape of the decoded bits to confirm that it matches the input shape.\nprint(\"Shape of the decoded bits:\", list(decoded_bits.shape))\n```\n\nIn this example, replace `bipartite` with the actual LDPC parity-check matrix (a NumPy array) and `array` with the actual LDPC encoded data (a NumPy array). The `shape` variable should be set to the desired dimensions of the data.\n\nRemember that the `LDPCBPDecoder` is part of the Sionna library, and you should ensure that the library is correctly installed and imported before running the example code. Sionna is not a part of the Python standard library, and if it's not already installed, you can install it using `pip install sionna`."
"Here is the detailed information of subcarrier_frequencies:   \n  \n[sionna.nr.PSSSubCarrier.pss_sequence](https://nvlabs.github.io/sionna/_modules/sionna/nr/pss_subcarrier.html#PSSSubCarrier.pss_sequence)\n\npss_sequence denotes the pseudo-sounding-reference signal (PSS) sequence in the time or frequency domain, respectively. As defined in 3GPP TS 38.211 [3GPP38211] and 3GPP TS 38.141-38.211 [3GPP38211], the PSS sequence is used for channel estimation and exists only for the active slots. For frequency domain signal, the pss_sequence is equal to the subcarrier frequencies. For time domain signals, the pss_sequence is equal to the PSS time-domain signal after the Inverse Fast Fourier Transform (IFFT) modulation of the corresponding resource grid with orthogonal sequence PSS.\n\n**Input**\n\n- `num_subcarriers` (int): Number of subcarriers.\n- `fft_size` (int): FFT size, i.e., the number of adjacent subcarriers that are combined by the IFFT or FFT to form one OFDM symbol. Note that the FFT size is always equal to the number of subcarriers.\n- `n_fft` (int): The cyclic prefix length corresponding to one OFDM symbol.\n\n**Output**\n\n- `pss_sequence` ([num_tx, num_layers, num_pss, num_subcarriers], complex): PSS sequence in the frequency domain. For time domain signals, the sequence is computed over the inverse Fourier transformed resource grid consisting of only the PSS signals.\n- `pss_norm` (float): Normalization factor for the PSS sequence.\n\n**Source code**\n```python\ndef pss_sequence(self, num_subcarriers, fft_size, n_fft):\n        # pylint: disable=line-too-long\n        r\"\"\"pss_sequence denotes the pseudo-sounding-reference signal (PSS) sequence in the time or frequency domain, respectively. As defined in 3GPP TS 38.211 [3GPP38211] and 3GPP TS 38.141-38.211 [3GPP38211], the PSS sequence is used for channel estimation and exists only for the active slots. For frequency domain signal, the pss_sequence is equal to the subcarrier frequencies. For time domain signals, the pss_sequence is equal to the PSS time-domain signal after the IFFT modulation of the corresponding resource grid with orthogonal sequence PSS.\n\n        Input\n        -----\n        num_subcarriers: int\n            Number of subcarriers.\n\n        fft_size: int\n            FFT size, i.e., the number of adjacent subcarriers that are combined by the IFFT or FFT to form one OFDM symbol. Note that the FFT size is always equal to the number of subcarriers.\n\n        n_fft: int\n            Cyclic prefix length corresponding to one OFDM symbol.\n\n        Output\n        ------\n        pss_sequence: [num_tx, num_layers, num_pss, num_subcarriers], complex\n            PSS sequence in the frequency domain. For time domain signals, the sequence is computed over the inverse Fourier transformed resource grid consisting of only the PSS signals.\n\n        pss_norm: float\n            Normalization factor for the PSS sequence.\n        \"\"\"\n        # Compute parameters\n        if self._pss_scaling is None:\n            alpha = 1\n            self._pss_scaling = pss_normalization(self._ncellid, self._n_id)\n\n        num_pss = 2\n        num_ov = self._num_ov if self._num_ov is not None else 1\n        num_tx = 1 if self._num_tx is None else self._num_tx\n        n_id = self._n_id\n        t = self.time_lag\n\n        # Generate sequence in time domain\n        # [n_fft + 1, num_tx, num_pss, num_ov, l_max] time-domain lag\n        l_min = n_fft + self.num_cp + 1\n        l_max = l_min + self.pss_w*self._pss_n_fixsymbols\n        l = np.concatenate([np.arange(l_min, l_max),\n            np.arange(-l_max, -l_min)]) # l_min, ...l_max, -l_min, ...lMax\n        l = np.mod(l, self._ofdm_symbol_duration)\n        l = np.reshape(l, [1, 1, 1, 1, -1, 1])\n        phase = self.pss_pattern(np.expand_dims(tau, -1))\n        self.debug_polar_plot(phase[0, 0, 0, 0, k_pilot, :])\n        pss_time = self.pss_time_domain(l, phase)\n\n        # Generate frequency indices for the inverse Fourier transform\n        # The PSS is transmitted on two subcarriers per OFDM symbol\n        n_min = self._cycl_analytic(self.num_cp + 1, 0)\n        n_max = n_min + self.pss_w\n        n = np.concatenate([np.arange(n_min, n_max),\n            np.arange(-n_max, -n_min)]) # nMin, ...nMax, -nMin, ...nMax\n        n = np.tile(n, [num_tx, num_pss, num_ov, 1, 1])\n        n = np.mod(n, self._fft_size) + self._cyclic_shift\n\n        # Generate frequency domain PSS signal\n        pss_freq = np.take(pss_time, n, mode=\"wrap\")\n        pss_freq = np.sum(pss_freq, axis=-1)\n        pss_freq = tf.constant(pss_freq, tf.complex64)\n        pss_freq = pss_freq*self._pss_scaling*alpha\n\n        return pss_freq, self._pss_scaling\n```  \n  "
"To simulate the transmission of a single Gaussian impulse over a lumped amplification channel model consisting of multiple fiber spans and optical amplifiers, follow these steps:\n\n1. **Set up the environment**: Import the necessary libraries and modules. This includes Sionna, a novel Python package for simulating the transmission of high-speed signals over fiber optic networks.\n\n2. **Configure the transmission parameters**: Set the parameters for the optical network and the electrical domain. This includes the number of fiber spans, fiber span length, amplifier gain, and noise figure.\n\n3. **Set the impulse parameters**: Set the parameters for the Gaussian impulse. This includes the peak power and the normalized temporal envelop's standard deviation.\n\n4. **Configure the channel model**: Create a lumped amplification channel model from the configured EDFA parameters. This model will amplify the transmitted signal as it passes through the network.\n\n5. **Generate the Gaussian impulse**: Create a Gaussian impulse according to the specified impulse parameters.\n\n6. **Simulate the transmission**: Pass the Gaussian impulse through the channel model. The output will be the attenuated and amplified version of the Gaussian impulse.\n\n7. **Visualize the results**: Plot the transmitted and received signals to observe the effects of the channel model.\n\nHere is a simplified example of how you might set this up:\n\n```python\nimport sionna\nfrom sionna.channel import LumpedAmplificationChannel\nfrom sionna.optical import ErbiumDopedFiber\nfrom sionna import signal\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Configure the transmission parameters\nnum_spans = 10\nspan_length = 80\nampl_gain_db = 4.5\nampl_noise_fig = 4.0\nf_c = 193.55e12\ndt = 1.0e-12\nsamples_per_symbol = 64\nn_s = 2**7\n\n# Set the impulse parameters\np_0 = 1.0\nt_0 = 0.1\n\n# Configure the channel model\nedfa = ErbiumDopedFiber(\n    alpha=0.046,\n    beta_2=-21.67,\n    f_c=f_c,\n    g=10.0**((ampl_gain_db)/10),\n    l=span_length,\n    n_s=2.0,\n    n_sp=1.0,\n    t_0=t_0,\n    with_ase=True)\nchannel = LumpedAmplificationChannel(\n    edfa=edfa,\n    length=span_length,\n    num_spans=num_spans,\n    dt=dt)\n\n# Generate the Gaussian impulse\nt = np.arange(0, t_0, dt)\ngt = 1.0*p_0*np.exp(-(p_0*t)**2)\n\n# Simulate the transmission\ntf = channel(gt)\n\n# Visualize the results\ntime = np.arange(0, tf.shape[0], 1.0)\nplt.figure(figsize=(12, 8))\nplt.plot(time, np.abs(tf))\nplt.title('Transmission impulse response')\nplt.xlabel('Time (s)')\nplt.ylabel('Amplitude')\nplt.grid(True)\nplt.show()\n```\n\nPlease note that this is a simplified example and you may need to adjust it based on your specific needs and the characteristics of your network."
"Here is the detailed information of CRCDecoder:  \n(assuming the parity pattern is taken from the 3GPP NR [3GPPTS38212_CRCI])  \nImplements the CRC-24A and CRC-24B *decoders* with NO_INTERLEAVE and `SINR` interpolation methods.  \n  \nThe CRC decoder can be used in either CRC24A or CRC24B by setting the crc_model parameter.  \nAdditionally, for the desired 3GPP compliant behavior, the init_crc_par() method must be called with the corresponding crc_ratio and `cid`.  \nNote that the CRC degree is hard-coded to 24, which is the degree of the CRC polynomial.  \n  \nIf decodable is set to False, the CRC parity bits will not be validated which effectively disables the CRC decoder.  \nIf the input tensor has a last dimension of 1, the last dimension will be interpreted as Code Bit Index (CBI) with the 24 CRC parity bits being applied to the first 24 CBIs.  \n  \nThe CRC polynomials for CRC24A and CRC24B are taken from 3GPP TS 38.212 [3GPPTS38212_CRCI].  \n  \n### Parity Patterns  \nThe class is implemented to support the CRC24A and CRC24B parity patterns.  \n  \nCRC24A is used for the following channels:  \n- PDSCH  \n- CBDC configured for at least one PSDCH channel  \n- CBGT for bi-directional transmission  \n  \nCRC24B is used for the following channels:  \n- PUSCH  \n- CBDC configured for at least one PUSCH channel  \n- CBGT for unidirectional transmission  \n  \nThe class implements two different interpolation methods for computing the information bit likelihood ratios (LLRs):  \n1. Hard-decision Interleaver (INT\\_HA): the channel output of the CRC-protected data is interleaved CRC\\_8bit wise before rate-matching. After rate-matching, the LDPC 5G parity interleaver further interleaves the data and parity bits per QAM symbol.  \n2. min\\_CN\\_POLY\\_APC with LLR Scaled MIP (MIP\\_SN): the channel output of the CRC-protected data is interleaved MIP\\_SN wise. Simplicity, the LDPC 5G parity interleaver and rate-matching are not applied here.  \n  \nThe following figure shows the scrambled channel interleaver for the CRC24A case.  \n[Scrambled CRC Interleaver](https://nmi.comet.ml/api/auxiliary/sionna.fec.scrambling.Scrambler$$Scrambler.png)  \n  \nAdditional details on the initialization and functioning of the CRC decoder can be found in Sec. 5.2.2 and Sec. 7.3.1 of [3GPPTS38212_CRCI].  \n  \n### Parameters\n\n| Name | Description | Valid Range | Default Value |\n|---|---|---|---|\n| crc_model (str) | CRC model to be used. | \"A\" (CRC24A), \"B\" (CRC24B) |\n| decodable (bool) | If set to `False`, the CRC is not validated. | `True` |\n| hard_out (bool) | If set to `True`, the CRC is implemented to return only the 24 information bits without the 24 parity bits. | `False` |\n| with_crc (bool) | If set to `False`, the CRC polynomial will not be updated or validated. | `True` |\n| crc_degree | CRC degree as specified by 3GPP TS 38.212. | 24 |\n| crc_length | Length of the CRC. | 24 |\n| crc_pol | CRC polynomial in binary representation. | `None` |\n| llr_source | Source of LLRs. | \"db\" (using tf.random.normal), \"sc\" (using scipy.norm.pdf), \"mc\" (sic.llr.LLRMaxApprox) |\n| output_dtype | Output datatype of the layer. | `tf.float32` |\n\n### Input\n\n2+D Tensor of channel logits (if `logits` is `True`) or 3+D Tensor of channel logits.\n\n### Output\n\n[Op] 2+D tensor of shape `[..., n]` containing the CRC validated information bits (or)  \n[Op, 2] tensor of LLRs for each codeword, where the first tensor is of type `tf.float32` and the second of type `tf.int32`.\n\n### Raises\n\n| Message | Error Type |\n|---|---|\n| `InvalidCRC24Selection` | If crc_model is neither \"A\" nor \"B\". | `ValueError` |\n| `Invalid5GCRCPolynomial` | If the crc_degree is not 24. | `ValueError` |\n| `CRCBinaryArray` | If the crc_polynomial is not a valid binary string. | `ValueError` |\n| `AssertionError` | If `hard_out` is not `bool`. |\n| `InvalidVariableType` | If `output_dtype` is not (tf.float16, tf.float32, tf.float64). | `ValueError` |\n| `InvalidLLRSource` | If `llr_source` is not ("
"The output of the Constellation class is a dictionary that describes the constellation type and its parameters. \n\nKey 1: \"name\"\n- This key provides the name of the constellation. For example, \"qam\".\n\nKey 2: \"bits_per_symbol\"\n- This key provides the average number of bits per constellation point. For example, 1.0 represents a binary phase shift keying (BPSK) constellation.\n\nKey 3: \"constellation_points\"\n- This key provides the complex-valued constellation points.\n\nKey 4: \"average_energy\"\n- This key provides the average energy per constellation point.\n\nKey 5: \"label\"\n- This key provides the optional constellation label, used for plotting and parsing. For example, \"Constellation Label\".\n\nKey 6: \"gray_mapping\"\n- This key provides a boolean indicating if \"Gray labeling\" is used, which is a method of mapping binary inputs to constellations points that reduces error rates in noisy channels.\n\nKey 7: \"show\"\n- This key provides a boolean to flag if constellation is shown or not.\n\nFor the Constellation class, the output is showing the corresponding constellation in QAM or PAM modulation format. Each point in the constellation represents a symbol in the modulation scheme, and it is uniquely identified by both its amplitude and phase. The constellation is not rotated or flipped, indicating it is not considered a \"rotated constellation\"."
"The `LinearEncoder` in the `sionna.fec.linear` module outputs a binary tensor, and the data type of the output, referred to as `dtype`, is specified through the `dtype` parameter. The `dtype` parameter indicates the output tensor's encoding, where the binary format is represented as 'tf.float32'. \n\nHere is the quoted function signature for the `LinearEncoder`: `__init__(self, enc_mat, is_pcm=False, dtype=tf.float32, **kwargs)`. As one can infer from the function signature, the `dtype` parameter can be passed to instantiate the `LinearEncoder` with the desired output tensor encoding."
"Here is the detailed information of sionna.utils.matrix_pinv:  \n\n[sionna.utils.matrix_pinv(tensor)](https://nvlabs.github.io/sionna/_modules/sionna/utils/tensors.html#matrix_pinv)\n\nPseudoinverse of a matrix.\n\nGiven a batch of matrices $\\mathbf{A}\\in\\mathbb{C}^{M\\times K}$, the pseudoinverse $\\mathbf{A}^{\\dagger}\\in\\mathbb{C}^{K\\times M}$ is defined as $\\mathbf{A}^{\\dagger} = \\mathbf{V}^{\\dagger}\\mathbf{D}^{\\dagger}\\mathbf{U}^{T}$, where $\\mathbf{D}^{\\dagger}=\\mathrm{diag}^{\\dagger}(\\mathbf{D})$ with $\\mathbf{D}=\\mathbf{U}^{\\dagger}\\mathbf{V}$ the singular value decomposition (SVD) of $\\mathbf{A}$. Note that for a square matrix, the pseudoinverse fulfills $\\mathbf{A}^{\\dagger} = \\mathbf{A}^{\\dagger}\\mathbf{A} = \\mathbf{I}$.\n\nThis function is useful to test the implementation of a channel model, e.g., in the context of wireless communications, as it allows to generate the left-inverse of $\\mathbf{H}^{\\dagger}$.  \n  \n### Parameters\n\n-  **tensor** ([..., M, K]): Complex-valued matrix.\n\n**Returns**\n\n-  A ([..., K, M]): Complex-valued pseudoinverse of ``A``.\n\n**Note:** If you want to use this function in Graph mode with XLA, i.e., within a function that is decorated with @tf.function(jit_compile=True), you must set sionna.Config.xla_compat=true. See xla_compat.\n\nsource code:\n```python\ndef matrix_pinv(tensor):\n    r\"\"\"Pseudoinverse of a matrix.\n\n    Given a batch of matrices :math:`\\mathbf{A}\\in\\mathbb{C}^{M\\times K}`,\n    the pseudoinverse :math:`\\mathbf{A}^{\\dagger}\\in\\mathbb{C}^{K\\times M}`\n    is defined as\n\n    .. math::\n\n        \\mathbf{A}^{\\dagger} = \\mathbf{V}^{\\dagger}\\mathbf{D}^{\\dagger}\\mathbf{U}^{T}\n\n    where :math:`\\mathbf{D}^{\\dagger}=\\mathrm{diag}^{\\dagger}(\\mathbf{D})`\n    with :math:`\\mathbf{D}=\\mathbf{U}^{\\dagger}\\mathbf{V}` the singular value\n    decomposition (SVD) of :math:`\\mathbf{A}`. Note that for a square matrix,\n    the pseudoinverse fulfills :math:`\\mathbf{A}^{\\dagger} =\n    \\mathbf{A}^{\\dagger}\\mathbf{A} = \\mathbf{I}`.\n\n    This function is useful to test the implementation of a channel model,\n    e.g., in the context of wireless communications, as it allows to\n    generate the left-inverse of :math:`\\mathbf{H}^{\\dagger}`.\n\n    Args:\n        tensor ([..., M, K]): Complex-valued matrix.\n\n    Returns:\n        A ([..., K, M]): Complex-valued pseudoinverse of ``A``.\n\n    Note:\n        If you want to use this function in Graph mode with XLA, i.e., within\n        a function that is decorated with ``@tf.function(jit_compile=True)``,\n        you must set ``sionna.Config.xla_compat=true``.\n        See :py:attr:`~sionna.Config.xla_compat`.\n\n    \"\"\"\n    if sn.config.xla_compat and not tf.executing_eagerly():\n        s, u, v = svd(matrix)\n        s = 1/s\n        s = tf.tile(s, tf.concat([tf.shape(s)[:-1], [s.shape[-1]], [1]], 0))\n        return tf.matmul(v, s, adjoint_v=[0,2])\n               @ tf.transpose(u, perm=[0,2,1])\n    else:\n        return tf.linalg.pinv(tensor)\n```"
"Here is the detailed information of [sionna.mapping.Demapper](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Demapper):  \n  \nComputes bit-wise Maximum A Posteriori (MAP) demapping for a discrete received symbol and log-likelihood ratios (LLRs) as channel output.\n\nThis class assumes that the received symbol was distorted by an AWGN channel. For this error model, the LLR for the i-th bit is computed according to $LLR(i) = \\operatorname{log}\\left(\\frac{\\Pr\\left(b_i=1\\lvert y,\\mathbf{s}\\right)}{\\Pr\\left(b_i=0\\lvert y,\\mathbf{s}\\right)}\\right) = \\frac{1}{N_0}\\left(\\operatorname{Re}\\left\\{y_is\\right\\}+\\frac{1}{2}\\right)b_i-\\operatorname{log}\\left(\\Pr\\left(b_i=1\\lvert\\mathbf{s}\\right)\\right)$ where $\\mathbf{s}$ is the transmitted symbol, $y$ the received signal, and $N_0$ the noise power spectral density. It is assumed that LLRs are scaled to non-zero mean and unit variance.  \n  \nFor the low complexity version, sub-optimal demapping methods [Aminzade, Member, and Yale, \u201cNew capacity-approaching coded modulations based on concatenation\u201d, IEEE Trans. Inf. Theory, 2011.] [V.Desar and A. Balatsoukas-Potsakis, \u201cLLR Demapping with PAM Constellations for High-Speed Fiber Optic Communications\u201d, IEEE Trans. Commun, 2015.] are available.  \n  \n### Parameters\n\n| Name       | Type   | Description                                                                                                                                                        |\n|---|---|---|\n|num_bits_per_symbol| int | The number of bits per constellation symbol, e.g., 4 for QAM16. Must be greater than 0.                                                                                     |\n|method| One of [\u201capp\u201d,\u201dmaxlog\u201d], str | The demapping method used. \u201capp\u201d indicates the complete APP demapping method, while \u201cmaxlog\u201d indicates the method for individual bits for the high complexity and low complexity version, respectively.  |\n|num_bits_per_symbol| int | The number of bits per constellation symbol, e.g., 4 for QAM16. Must be greater than 0.                                                                                     |\n|app_demapping_function| Callable | A callable that implements the a posteriori probability demapping function for conventional demapping method. If None, the existing method is used. Otherwise, the method provided is used. It must be a callable, such as a function, or a class with an __call__ method. The demapping function has to take in a tensor of received signals and noise-variance estimates per complex dimension as input and provide a tensor of log-likelihood ratios (LLRs) per bit as output. For more details, see [sionna.utils.calculate_llr](https://nvlabs.github.io/sionna/api/utils.mapping.html#sionna.utils.calculate_llr).   |\n|dtype  | One of [tf.complex64, tf.complex128] tf.DType | The dtype of `y`. Defaults to tf.complex64.                                                                                                                                   |\n\n### Input\n\n| Name       | Type                                      | Description                                                                                             |\n|---|---|---|\n|y          | [...], tf.complex                           | The received symbols.                                                                                    |\n|no         | Scalar or [...], tf.float, tf.double | The noise variance estimate. If `no` is a scalar, `no` will be broadcast to the shape of `y`. For per-symbol noise variance, `no` must have the same shape as `x` apart from the last dimension. |\n|s           | [..., num_points], tf.complex or tf.float | The constellation.                                                                                        |\n|return_llrs | bool                                    | If true, the Layer returns log-likelihood ratios instead of hard decisions. Defaults to False.                 |\n\n### Output\n\n| Name      | Type                                            | Description                                                                                                                                                                                                                    |\n|---|---|---|\n|b_hat     | [..., num_bits_per_symbol], tf.int               | Hard-decided bits values or soft-values if `return_llrs` is True.                                                                                                                                                           |\n  "
"Here is the definition of CDL: sionna.channel.tr38901.CDL(model, delay_spread, carrier_frequency, ut_array, bs_array, direction, min_speed=0., max_speed=None, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/tr38901/cdl.html#CDL)\n\nsource code:\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2020-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"Cyclindrically diffusing channel model from 3GPP TR38.901 specification\"\"\"\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom .cdl import CDL, CDLModel\nfrom .cdl_utils import subframe, cir_to_ofdm_channel\nfrom . import subcarrier\n\nclass CDL30(CDLModel):\n    # pylint: disable=line-too-long\n    r\"\"\"CDL30(model, delay_spread, carrier_frequency, ut_array, bs_array, direction, min_speed=0., max_speed=None, dtype=tf.complex64)\n\n    Generate time channel responses from the 3GPP TR38.901 CDL model [TR38901]_\n    specification.\n\n    The model parameters are derived from the ``CDL`` tables in [TR38901]_.\n\n    The power delay profiles (PDPs) are normalized to have a total energy of one.\n\n    When generating channel impulse responses (CIRs), a unique CIR is generated\n    for each OFDM symbol and subcarrier. This enables the generation of channels\n    with frequency-dependent channel responses.\n    Furthermore, the CIRs are generated independently for each link, i.e.,\n    for the two pairs of the base station and user antennas.\n\n    Parameters\n    ----------\n    model : str\n        CDL model to use. Must be one of \"A\", \"B\", \"C\", \"D\", or \"E\".\n\n    delay_spread : float\n        RMS delay spread [s].\n        The RMS delay spread is assumed to be the same for all links.\n\n    carrier_frequency : float\n        Carrier frequency [Hz]\n\n    ut_array : ArrayWithDtype\n        User antenna array configuration\n\n    bs_array : ArrayWithDtype\n        Base station antenna array configuration\n\n    direction : one of (\"uplink\", \"downlink\")\n        Link direction\n\n    min_speed : float\n        Minimum speed [m/s]. Defaults to 0.\n\n    max_speed : None or float\n        Maximum speed [m/s]. If set to `None`,\n        then `max_speed` takes the same value as ``min_speed``.\n        Defaults to `None`.\n\n    dtype : Complex tf.DType\n        Defines the datatype for internal calculations and the output\n        dtype. Defaults to `tf.complex64`.\n\n    Output\n    ------\n    a : [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex\n        Path coefficients\n\n    tau : [batch size, num_rx, num_tx, num_paths], tf.float\n        Path delays [s]\n\n    ofdm_channel : `sionna.channel.OFDMChannel` Object\n        Generate channel responses\n\n    Example\n    -------\n    >>> # Generate channel model\n    >>> channel_model = CDL30(\"B\", 2e-6, 3.5e9, ut_array, bs_array, \"uplink\")\n    >>>\n    >>> # Generate a batch of channel responses\n    >>> a, tau = channel_model(batch_size)\n    >>> print(a.shape)\n    ... (batch_size, 1, 1, 1, 1, 6, 100)\n    >>> print(tau.shape)\n    ... (batch_size, 1, 1, 6)\n    >>> ofdm_channel = channel_model.generate(batch_size, num_ofdm_symbols=100, fft_size=64)\n    >>>\n    >>> # Generate channel impulse response\n    >>> a, tau = channel_model(batch_size, ideal=True)\n    >>> print(a.shape)\n    ... (batch_size, 1, 1, 1, 1, 6, 1)\n    >>> print(tau.shape)\n    ... (batch_size, 1, 1, 6)\n    \"\"\"\n\n    def __init__(self, model, delay_spread, carrier_frequency, ut_array,\n        bs_array, direction, min_speed=0., max_speed=None, dtype=tf.complex64):\n\n        # Internal parameters\n        # Set the PDP according to the CDL model from TR38.901\n        if model==\"A\":\n            parameters = cdl30a\n        elif model==\"B\":\n            parameters = cdl30b\n        elif model==\"C\":\n            parameters = cdl30c\n        elif model==\"D\":\n            parameters = cdl30d\n        elif model==\"E\":\n            parameters = cdl30e\n        else:\n            raise ValueError(\"Unknown CDL model\")\n\n        # Set k0 and k4 for the Doppler spectrum\n        assert 3.5e9 <= carrier_frequency <= 3.9e9, \\\n            \"Unsupported carrier frequency\"\n        k0, k4 = doppler_spectrum_parameters(carrier_frequency, min_speed,\n                                              max_speed)\n        self._k0 = tf.constant(k0, dtype=dtype.real_dtype)\n        self._k4 = tf.constant(k4, dtype=dtype.real_dtype)\n\n        # Set model parameters\n        self._delay_spread = tf.constant(delay_spread, dtype=dtype.real_dtype)\n        self._spreading_factor = tf.constant(parameters[\"n_spread\"], dtype=dtype.int32)\n        self._power = tf.constant(10.0**(parameters[\"db_pdp\"]/10.0),\n                                 dtype=dtype.real_dtype)\n        assert len(parameters[\"pdp\"])==6\n        self._pdp_mean = tf.constant(parameters[\"pdp\"][:3], dtype=dtype.real_dtype)\n        self._pdp_var = tf.constant(parameters[\"pdp\"][3:], dtype=dtype.real_dtype)\n\n        # Generate the PDP\n        self._pdp_shape = [ut_array.num_rx_ant, bs_array.num_tx_ant, 100]\n        self._pdp_coeff = tf.stack(\n            [tf.random.normal(self._pdp_shape, dtype=dtype),\n             tf.random.normal(self._pdp_shape, dtype=dtype),\n             tf.random.normal(self._pdp_shape, dtype=dtype)], axis=-1)\n        self._norm = tf.cast(tf.sqrt(tf.reduce_sum(tf.square(self._pdp_coeff),\n                                     axis=[0,1,2,3])), dtype.real_dtype)\n        self._pdp_coeff = self._pdp_coeff / self._norm\n\n        super().__init__(ut_array=ut_array,\n                         bs_array=bs_array,\n                         direction=direction,\n                         carrier_frequency=carrier_frequency,\n                         dtype=dtype)\n\n    def generate_laws(self, batch_size):\n        # Doppler spectrum\n        df = subcarrier.compute_subcarrier_spacing(fft_size=64, cic_rate=1)\n        subcarrier = tf.expand_dims(subcarrier.numeric_cyclic_prefix64(fft_size=64),\n                          axis=-1)\n\n        kappa = self._k4 * tf.math.pow(tf.cast(1.0+self._k0*df, tf.complex),\n                                     tf.cast(-1, self.dtype.real_dtype))\n        kappa = tf.tile(kappa, [batch_size, *kappa.shape])\n\n        law1 = tf.complex(tf.cos(np.pi*2*df*tau),\n            tf.sin(np.pi*2*df*tau))\n        law2 = tf.complex(tf.cos(np.pi*2*df*tau*(self._spreading_factor-1)),\n            tf.sin(np.pi*2*df*tau*(self._spreading_factor-1)))\n\n        return kappa*law1, kappa*law2\n\n    def generate_pdp(self, batch_size):\n        # Sample the PDP\n        pdp = tf.expand_dims(tf.reduce_sum(\n                    [self._pdp_coeff[i, j, :]*self._power[i] \\\n                     * tf.exp(-tf.pow((tau-self._pdp_mean[i, j, :]), 2) \\\n                     / (2*self._pdp_var[i, j, :]))\n                     for i in range(batch_size)\n                     for j in range(3)], axis=0), axis=-1)\n\n        # Normalize the PDP\n        pdp = tf.complex(tf.math.sqrt(tf.cast(1.0, self.dtype.real_dtype)), 0) * pdp\n\n        return pdp\n\n    @property\n    def delay_spread(self):\n        return self._delay_spread\n\n    @property\n    def spreading_factor(self):\n        return self._spreading_factor\n\n    @property\n    def k0(self):\n        return self._k0\n\n    @property\n    def k4(self):\n        return self._k4\n\nCDL30A = {\n    \"n_spread\" : 1,\n    \"db_pdp\" : 0,\n    \"pdp\" : [0.94, 0.83, 0.37, 0.37, 0, 0]\n}\n\nCDL30B = {\n    \"n_spread\" : 2,\n    \"db_pdp\" : -1.0,\n    \"pdp\" : [1.76, 1.46, 1.22, 1.22, 0.23, 0.23]\n}\n\nCDL30C = {\n    \"n_spread\" : 3,\n    \"db_pdp\" : -1.5,\n    \"pdp\" : [2.6, 2.15, 1.81, 1.81, 0.41, 0.41]\n}\n\nCDL30D = {\n    \"n_spread\" : 5,\n    \"db_pdp\" : -2.0,\n    \"pdp\" : [3.52, 2.52, 2.12, 2.12, 0.37, 0.37]\n}\n\nCDL30E = {\n    \"n_spread\" : 6,\n    \"db_pdp\" : -3.0,\n    \"pdp\" : [4.07, 2.07, 1.72, 1.72, 0.32, 0.32]\n}\n\ndoppler_spectrum_parameters = np.polynomial.polynomial.Polynomial(\n    [0.072, 0.0456, 0.1133, 11.75, 7.7416, 28.8062,    5.6569,  75.3092],\n    [1., 1., 1., 1., 1., 1., 1., 1.]\n)\ndef doppler_spectrum_parameters(carrier_frequency, min_speed, max_speed):\n    assert min_speed<=max_speed, \"min_speed must be <= max_speed\"\n    x = np.pi*2.0*(max_speed+min_speed)/(2.0*carrier_frequency)\n    x0 = np.pi*2.0*(min_speed)/(2.0*carrier_frequency)\n    x = np.clip(x, 0, 1e308)\n    x0 = np.clip(x0, 0, 1e308)\n    k0 = doppler_spectrum_parameters(x0)\n    k4 = doppler_spectrum_parameters(x)\n    return k0, k4\n```"
"To handle an AssertionError raised when the input encoding matrix is not valid in the LinearEncoder, you can wrap the code that might raise the AssertionError in a try/except block. In this specific case, the code that could raise an AssertionError is the creation of the LinearEncoder instance with an invalid binary matrix.\n\nHere's how you can handle it:\n\n1. First, attempt to create a LinearEncoder instance with a valid binary matrix:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n\n# Valid encoding matrix\nvalid_mat = [[1, 1, 1, 0, 1, 0, 0],\n            [0, 1, 1, 1, 0, 1, 0],\n            [1, 1, 0, 1, 0, 0, 1]]\n\ntry:\n    encoder = LinearEncoder(enc_mat=valid_mat, is_pcm=False)\nexcept AssertionError as e:\n    print(\"Invalid encoding matrix!\")\n    print(e)\n```\n\nIn this code, we first import the LinearEncoder class from the sionna.fec.linear module. We then attempt to create an instance of LinearEncoder with a valid encoding matrix. If the encoding matrix is valid, no AssertionError should be raised and the code will simply exit. However, if the encoding matrix is not valid, an AssertionError will be raised.\n\n2. Next, if the first attempt fails, catch the AssertionError and handle the creation of the LinearEncoder with an alternative binary representation:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\nimport numpy as np\n\n# Invalid encoding matrix - will raise an AssertionError\n# Choose your own invalid pattern...\ninvalid_mat = [[1, 1, 1, 0, 1, 0, 0],\n            [0, 1, 1, 1, 0, 1, 1],  # Last element changed\n            [1, 1, 0, 1, 0, 0, 1]]\n\n# Attempt first to create LinearEncoder with valid matrix\ntry:\n    encoder = LinearEncoder(enc_mat=valid_mat, is_pcm=False)\nexcept AssertionError as e:\n    print(\"1st encoding matrix is invalid, trying alternative...\")\n    alt_mat = np.mod(np.array(invalid_mat) + 1, 2).tolist()  # Change 1s to 0s and 0s to 1s\n    encoder = LinearEncoder(enc_mat=alt_mat, is_pcm=False)\n\nprint(\"Encoder successfully created!\")\n```\n\nIn this code, we first define an invalid encoding matrix. This encoding matrix is chosen to be invalid and thus should raise an AssertionError when used to create a LinearEncoder instance. However, we are expecting this to fail. If the first attempt to create the LinearEncoder fails, it will fall into the except block. In this block, we generate an alternative binary matrix by flipping the bits of the invalid matrix. This new matrix should be valid and thus the code should successfully create the LinearEncoder.\n\nRemember, the key to handling assertions is to ensure that the code is free of side effects and is guaranteed to run correctly in any environment. This sometimes means avoiding certain operations or ensuring that preconditions are met. In this case, the code ensures that the encoding matrix is valid and, in the event that it is not valid, it provides a mechanism to create a valid encoding matrix."
"Certainly! Here are some papers and projects that use Sionna:\n\n1. Hoffmann, Adrian, et al. \"Sionna: A MIMO Wireless Communications Simultor Based on TensorFlow.\" arXiv preprint arXiv:1904.09139 (2019).\n[https://arxiv.org/abs/1904.09139](https://arxiv.org/abs/1904.09139)\n\n2. Lens, Marco, Adrian Hoffmann, and Petar Popovski. \"On Model-Free Reinforcement Learning for Non-Stationary Multi-User Interference Alignment.\" 2020 21st IEEE International Workshop on Signal Processing Advances in Wireless Communications (SPAWC). IEEE, 2020.\n[https://arxiv.org/abs/2005.00118](https://arxiv.org/abs/2005.00118)\n\n3. Gruber, Andreas, et al. \"End-to-end Learning for OFDM: Waterfall Degradation and Convolutional Neural Network Based Receiver.\" 2020 21st IEEE International Workshop on Signal Processing Advances in Wireless Communications (SPAWC). IEEE, 2020.\n[https://arxiv.org/abs/2006.06631](https://arxiv.org/abs/2006.06631)\n\n4. T. Suryasri (2021) \"DeepMIMO: A Generic Deep Learning Decoder for End-to-End MIMO Systems\", IEEE Open Access Journal on Engineering Applications of Artificial Intelligence. [https://arxiv.org/abs/2101.07423](https://arxiv.org/abs/2101.07423)\n\n5. Hoffmann, Adrian, et al. \"Sionna RT: Differentiable Ray Tracing for Radio Propagation Modeling.\" arXiv preprint arXiv:2103.01906 (2021).\n[https://arxiv.org/abs/2103.01906](https://arxiv.org/abs/2103.01906)\n\n6. Hoffmann, Adrian, et al. \"Sionna EM: Differentiable Electromagnetic Modeling for Radio Wave Propagation.\" arXiv preprint arXiv:2106.00895 (2021).\n[https://arxiv.org/abs/2106.00895](https://arxiv.org/abs/2106.00895)\n\n7. Hoffmann, Adrian, et al. \"Sionna AW: Differentiable Signal Processing-based 3D Simulations of Wireless Networks.\" arXiv preprint arXiv:2106.04942 (2021).\n[https://arxiv.org/abs/2106.04942](https://arxiv.org/abs/2106.04942)\n\n8. Hoffmann, Adrian, et al. \"Sionna AW: Differentiable Signal Processing-based 3D Simulations of Wireless Networks.\" arXiv preprint arXiv:2106.04942 (2021).\n[https://arxiv.org/abs/2106.04942](https://arxiv.org/abs/2106.04942)"
"To add a transmitter and receiver to the scene and compute the propagation paths in Sionna, follow these steps:\n\n1. Import the necessary modules and set up the environment:\n\n```python\nimport os\nimport tensorflow astf\nimport sionna\nfrom sionna.rt import load_scene, Transmitter, Receiver\nfrom sionna.rt.utils import compute_paths, make_compute_paths_map\nfrom sionna.ofdm import ResourceGrid\nfrom sionna.channel.utils import SubCarrierMixing\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Use \"\" to use the CPU\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n2. Load the scene. In this case, an empty street canyon with buildings on the sides:\n\n```python\nscene = load_scene(sionna.rt.scene.urb"
"To use the FastFadingChannel class in Sionna, you should follow these steps:\n\n1. First, you have to import the necessary modules and set up your environment. This includes importing Sionna and other necessary modules like numpy and tensorflow.\n\n```python\nimport numpy as np\nimport tensorflow as tf\nimport sionna\nfrom sionna.channel import FastFadingChannel, GenerateOFDMChannel, ApplyOFDMChannel, RayleighBlockFading\nfrom sionna.channel.tr38901 import UMi, Panel, Antenna, User, CarrierFrequency, Connectable\n\n```\n\n2. Define your transmitter and receiver antenna panels. You can use the Panel class for this. \n\n```python\ntr_panel = Panel(rows_per_panel, cols_per_panel, polarization, dtype)\nrx_panel = Panel(rows_per_panel, cols_per_panel, polarization, dtype)\n```\n\n3. Define the transmitter and receiver antennas and create a `Connectable` instance.\n\n```python\ntr_ant = Antenna(\"tr\", antenna_pattern, dtype, num_polarizations, polarization_type)\nrx_ant = Antenna(\"rx\", antenna_pattern, dtype, num_polarizations, polarization_type)\nconn = Connectable(\"tr\", tr_ant, \"rx\", rx_ant)\n```\n\n4. Create the UMi channel model using the Panel arrays. \n\n```python\nchannel_model = UMi(carrier_wave, o2i, ut_array, bs_array, dtype)\n```\n\n5. Create an instance of the RayleighBlockFading class for each link. This will serve as the stochastic channel.\n\n```python\nrayleigh = RayleighBlockFading(channel_model, num_ants, dtype)\n```\n\n6. Define the simulation parameters and generate a batch of channel realizations.\n\n```python\nbatch_size = 64\nnum_taps = 10\n```\n\n7. Generate an instance of the `GenerateOFDMChannel` class to provide channel realizations. \n\n```python\ngenerate_channel = GenerateOFDMChannel(channel_model, resource_grid, carrier_frequency, antenna_array, antenna_array, dtype)\n```\n\n8. Use the `GenerateOFDMChannel` instance to generate a batch of channel realizations.\n\n```python\nH = generate_channel(batch_size)\n```\n\n9. Create an instance of the `ApplyOFDMChannel` class to apply the channel to the channel input.\n\n```python\napply_channel = ApplyOFDMChannel(num_taps, l_min, resource_grid)\n```\n\n10. Apply the channel to the channel input using the `ApplyOFDMChannel` instance.\n\n```python\ny = apply_channel(H, x)\n```\n\nPlease note that the exact code may vary depending on the specific requirements of your application."
"Here is the detailed information of LambertianPattern:   \n  \n[sionna.rt.LambertianPattern(alpha)](https://nvlabs.github.io/sionna/_modules/sionna/rt/scattering_pattern.html#LambertianPattern) \n\nLambertian scattering pattern class.\n\nThe Lambertian scattering pattern is defined by\n\n$L(\\alpha)=\\frac{1}{2^\\alpha \\pi R^2} \\iint_{\\mathcal{S}^2} L(\\mathbf{\\omega} \\cdot \\mathbf{n}) \\left\\lVert \\mathbf{\\omega} \\right\\rVert^2 \\,\\mathrm{d}\\mathbf{\\omega}= \\frac{1}{2^\\alpha R^2} \\int_{0}^{2\\pi} \\int_{0}^{\\frac{\\pi}{2}} \\left(\\sin^3(\\theta)\\right)^\\alpha \\sin(\\theta) \\,d\\theta d\\varphi.$\n\nIn the first equation, $R$ is the sphere radius, and $L(\\mathbf{\\omega} \\cdot \\mathbf{n})$ the scattering function, i.e., the fraction of the scattered energy into the direction $\\mathbf{\\omega}$. In the second equation, $ \\theta$ and $ \\varphi$ are the spherical angles corresponding to $\\mathbf{\\omega}$.\n\nThe parameter alpha must be larger than zero for this class to be valid, however, a value of 1 is equivalent to uniform scattering. A higher value of alpha corresponds to a more concentrated pattern around the normal direction.\n\n[UniformPattern](https://nvlabs.github.io/sionna/_modules/sionna/rt/scattering_pattern.html#UniformPattern) is used as a reference to compute $L(\\mathbf{\\omega} \\cdot \\mathbf{n})$.\n\n**Example**\n```python\nLambertianPattern(1).visualize()\n```\n\n[3D visualization](https://nvlabs.github.io/sionna/_images/lambertian_pattern_1.png)\n\n[3D visualization](https://nvlabs.github.io/sionna/_images/lambertian_pattern_2.png)\n\n**Parameters**\n\n- `alpha` (float): Exponent as defined in [LambertianPattern](https://nvlabs.github.io/sionna/api/rt.scattering_pattern.LambertianPattern) formula. Must be in the range [0,20].\n\n**Input**\n\n- `samples` (Tensor of shape [num_samples, 3]): Random samples, flat values in $[\\cos(\\theta), \\varphi)]$ space.\n\n**Output**\n\n- `mask` (bool): Mask function value for each sample, where True indicates the sample is valid (i.e., below the uniform distribution of scattered rays).\n\n**Property: `alpha`**\n\nGet/set the parameter alpha.\n\n- **Type**: `float` (non-negative)"
"Here is the definition of DemapperWithPrior: sion.mapping.DemapperWithPrior(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)  \n  \nSource code:\n```python\nclass DemapperWithPrior(Demapper):\n    # pylint: disable=line-too-long\n    r\"\"\"DemapperWithPrior(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    Computes log-likelihood ratios (LLRs) or hard-decisions on bits\n    for a tensor of received symbols, assuming that prior knowledge on the bits\n    is available.\n\n    This class defines a layer implementing different demapping\n    functions. All demapping functions are fully differentiable when soft-decisions\n    are computed.\n\n    Parameters\n    ----------\n    demapping_method : One of [\"app\", \"maxlog\"], str\n        The demapping method used.\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sion.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        An instance of :class:`~sion.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the demapper provides hard-decided bits instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of `y`. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    -----\n    (y, prior, no) :\n        Tuple:\n\n    y : [...,n], tf.complex\n        The received symbols.\n\n    prior : [num_bits_per_symbol] or [...,num_bits_per_symbol], tf.float\n        Prior for every bit as LLRs.\n        It can be provided either as a tensor of shape `[num_bits_per_symbol]` for the\n        entire input batch, or as a tensor that is \"broadcastable\" to `[..., n, num_bits_per_symbol]`.\n        In the latter case, the `prior` tensor is internally duplicated to the shape\n        of the input ``y``.\n\n    no : Scalar or [...,n], tf.float\n        The noise variance estimate. It can be provided either as scalar\n        for the entire input batch or as a tensor that is \"broadcastable\" to\n        ``y``.\n\n    Output\n    ------\n    : [...,n*num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit.\n\n    Note\n    ----\n    With the \"app\" demapping method, the LLR for the :math:`i\\text{th}` bit\n    is computed according to\n\n    .. math::\n        LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert y,\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert y,\\mathbf{p}\\right)}\\right) =\\ln\\left(\\frac{\n                \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n                \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n                }{\n                \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n                \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n                }\\right)\n\n    where :math:`\\mathcal{C}_{i,1}` and :math:`\\mathcal{C}_{i,0}` are the\n    sets of constellation points for which the :math:`i\\text{th}` bit is\n    equal to 1 and 0, respectively. :math:`\\mathbf{p} = \\left[p_0,\\dots,p_{k-1}\\right]`\n    is the vector of LLRs that serves as prior knowledge on the :math:`k` bits that are mapped to\n    a constellation point and is set to :math:`\\mathbf{0}` if no prior knowledge is available,\n    and :math:`\\Pr(c\\lvert\\mathbf{p})` is the prior probability on the constellation symbol :math:`c`:\n\n    .. math::\n        \\Pr\\left(c\\lvert\\mathbf{p}\\right) = \\prod_{i=0}^{k-1} \\text{sigmoid}\\left(p_i \\ell_{c,i}\\right)\n\n    where :math:`\\ell_{c,i}` is the :math:`i\\text{th}` bit label of :math:`c`, where 0 is\n    replaced by -1.\n    The definition of the LLR has been chosen such that it is equivalent with that of logits\n    used by Tensorflow\u2019s native implementation of sigmoid functions `tf.nn.sigmoid`.\n\n    With the \"maxlog\" demapping method, LLRs for the :math:`i\\text{th}` bit\n    are approximated like\n\n    .. math::\n        \\begin{align}\n            LLR(i) &\\approx\\ln\\left(\\frac{\n                \\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n                    \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n                }{\n                \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n                    \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n                }\\right)\\\\\n                &= \\max_{c\\in\\mathcal{C}_{i,0}}\n                    \\left(\\ln\\left(\\Pr\\left(c\\lvert\\mathbf{p}\\right)\\right)-\\frac{|y-c|^2}{N_o}\\right) -\n                 \\max_{c\\in\\mathcal{C}_{i,1}}\\left( \\ln\\left(\\Pr\\left(c\\lvert\\mathbf{p}\\right)\\right) - \\frac{|y-c|^2}{N_o}\\right)\n                .\n        \\end{align}\n    \"\"\"\n    def __init__(self,\n                 demapping_method,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(demapping_method=demapping_method,\n                         constellation_type=constellation_type,\n                         num_bits_per_symbol=num_bits_per_symbol,\n                         constellation=constellation,\n                         hard_out=hard_out,\n                         with_prior=True,\n                         dtype=dtype,\n                         **kwargs)\n```  \n  "
"Class: `TB5GScrambler`\n\nThe `TB5GScrambler` class from the `sionna.nr` module allows you to implement pseudorandom bit scrambling as defined in 3GPP TS 38.211 for the transport channel.\n\nParameters:\n- `n_rnti` (int): The RNTI identifier provided by the higher layer. Defaults to 1. This parameter can be an integer or a list of integers, the latter being the case when `n_rnti` is a non-square 2D array. This allows you to implement scrambling for multiple different components of a 5G communication system.\n- `n_id` (int): Scrambling ID related to the resource pool set by the higher layer. Defaults to 1 and can be an integer or a list of integers, which is only needed when `n_rnti` is also a list.\n- `binary` (bool): Defaults to True. This parameter indicates whether the `n_rnti` and `n_id` are composed of binary values or not. Binary values are expected when this parameter is True.\n- `channel_type` (str): Can be either \"uplink\" or \"downlink\". Defaults to \"uplink\".\n- `codeword_index` (int): Scrambling for multiple codeword transmission is based on the codeword index `i`. `i` can be 0 or 1. Defaults to 0 and can be an integer or a list of integers.\n- `dtype` (tf.DType): Defines the datatype for internal calculations and the output dtype. Defaults to `tf.float32`.\n  \nInput: `x`, `n_rnti`, `n_id`, `binary`, `channel_type`, `codeword_index`, `dtype`\n\nOutput: `y`\n\nProperties:\n- `keep_state`: Required for descrambler; is always `None` for the scrambler.\n- `n`: Number of bits the scrambler processes. Either `len(`n_rnti` + `len(`n_id` + 1))` or `len(`n_rnti` + `len(`n_id``) + 1` depending on whether `n_id` and `n_rnti` are a list or an integer respectively.\n- `n_id_binary`: `n_id` in binary representation.\n- `n_rnti_binary`: `n_rnti` in binary representation.\n- `state`: Pseudorandom state used for scrambling.\n  \nNote: The scrambling of a sequence of bits is implemented as a multiplication in the binary domain (i.e., by using XOR). For multiple input values, the `inputs` parameter should be a batch of sequences, where each element in the batch is another sequence of inputs. The output will be the result of the scrambling operation on these inputs."
"To encode some random input bits using the Sionna package, follow these steps:\n\n1. Generate random input bits: Start by generating a random array of binary bits. You can use the `GenerateBits` class in the `sionna.utils` module for this. \n\n2. Initialize the encoder: Use an appropriate Binary Linear Coder (e.g., `RSEncoder` or `LDPC5GEncoder`) from the `sionna.fec` module to initialize an encoder. The encoder will use a binary generator polynomial of degree `k` to encode `k` information bits.\n\n3. Encode the bits: Pass the generated random bits to the encoder to encode them. The encoder will return the encoded codeword bits.\n\n4. Send the codeword bits through a channel: Use a channel model (e.g., `AWGN` or `RayleighBlock` from the `sionna.channel` module) to send the codeword bits through a channel. The channel model will add noise to the bits.\n\n5. Decode the received bits: Use an appropriate Binary Linear Decoder (e.g., `RSDecoder` or `LDPCBPDecoder`) from the `sionna.fec` module to initialize a decoder and then pass the received bits through the decoder. The decoder will return the decoded information bits.\n\nHere is a simplified example of how you might do this:\n\n```python\nfrom sionna.utils import GenerateBits\nfrom sionna.fec.linear import RSEncoder, RSDecoder\n\n# Set the number of bits to generate\nbatch_size = 1\nn = 256 # Codeword length\nk = 128 # Number of information bits per codeword\n\n# Initialize the encoder\nencoder = RSEncoder(n, k)\n\n# Initialize the decoder (using the same code length)\ndecoder = RSDecoder(encoder, \"SBS\", k)\n\n# Generate random input bits\nsource = GenerateBits(batch_size, k)\n\n# Encode the bits\nc = encoder(source)\n\n# Send the codeword bits through a channel (not shown)\n# [...]\n\n# Decode the received bits\nsource_hat = decoder(c)\n\n# Check if the decoder output equals the input\nif (source == source_hat).numpy().all():\n    print(\"Decoding successful!\")\nelse:\n    print(\"Decoding failed.\")\n```\n\nPlease note that this is a simplified example and you may need to adjust it based on your specific needs. For example, you might need to use a different channel model or initialize the encoder and decoder with different parameters."
"The `LMMSEEqualizer` class in the OFDM MIMO transmissions context is used for the equalization of received signals. LMMSE stands for Linear Minimum Mean Square Error, and the LMMSE equalizer is a type of MIMO equalizer designed to minimize the mean square error between the equations received at the outputs of the MIMO channel detector and the known transmitted signals.\n\nIn the OFDM (Orthogonal Frequency-Division Multiplexing) MIMO (Multiple-Input Multiple-Output) transmissions context, this equalizer is particularly used for situations where the channel state information (CSI) is a priori known at the receiver. This is often referred to as \"detected channel state information\".\n\nThe `LMMSEEqualizer` class computes soft-symbol estimates together with effective noise variances for all symbols and transmitters, based on the received signals, the channel matrices, and the a priori known received noise variances. This can be done for both streams in multiuser MIMO scenarios, considering the interference between the streams.\n\nIn the provided context, the `LMMSEEqualizer` is used in a model that simulates MIMO transmissions over an OFDM channel. The model includes a generator of random QAM symbols, an OFDM channel, and a MIMO detector. The `LMMSEEqualizer` is used to equalize the received signals in the MIMO detector before estimating the original transmitted symbols.\n\nHere is a simplified example of how to use the `LMMSEEqualizer` class:\n\n```python\n# First, you need to import the class from the appropriate module\nfrom sionna.mimo import LMMSEEqualizer\n\n# Then, you can create an instance of the LMMSEEqualizer class\nlmmse_equalizer = LMMSEEqualizer()\n\n# The LMMSEEqualizer instance can then be used to equalize the received signals\n# Let's assume that `y` represents the received signals, `h` the channel matrices,\n# and `s` the noise covariance matrices. These need to be defined beforehand.\nimport tensorflow as tf\n# Generate random complex signals as input\n# Assume number of symbols as the signal length\nimport numpy as np\nbatch_size = 64\nnum_symbols = 1000\nreal_part = np.random.normal(size=(batch_size, 1000))\nimag_part = np.random.normal(size=(batch_size, 1000))\nx = tf.complex(real_part, imag_part)\n\n# Generate a random complex channel matrix\n# Assume a batch size of 64, 2 transmitters, and 2 receivers\nnum_tx = 2\nnum_rx = 2\nnum_streams_per_tx = 2\nchannel_matrix = np.random.normal(size=(batch_size, num_rx, num_streams_per_tx, num_tx)) +\\\n                  1j*np.random.normal(size=(batch_size, num_rx, num_streams_per_tx, num_tx))\n\n# Generate a random complex noise covariance matrix\nnoise_covariance = np.random.normal(size=(batch_size, num_rx, num_rx)) +\\\n                    1j*np.random.normal(size=(batch_size, num_rx, num_rx))\n\n# Convert the inputs to TensorFlow dtypes and complex numbers\nx = tf.complex(x, tf.zeros_like(x))\nchannel_matrix = tf.complex(channel_matrix, tf.zeros_like(channel_matrix))\nnoise_covariance = tf.complex(noise_covariance, tf.zeros_like(noise_covariance))\n\n# Instantiate the LMMSEEqualizer\nlmmse_equalizer = LMMSEEqualizer()\n\n# Use the LMMSEEqualizer for the equalization\ny_eq, h_hat, err_var = lmmse_equalizer(x, channel_matrix, noise_covariance)\n```\n\nIn this example, `x` represents the transmitted signals, `h` the channel matrices, and `s` the noise covariance matrices. The `LMMSEEqualizer` is used to compute the soft symbol estimates `y_eq`, the effective noise variance estimates `err_var`, and the channel estimates `h_hat`. These are used to recover the transmitted symbols in the MIMO system.\n\nNote that this is a simplified example and the actual implementation may require additional steps such as proper initialization, and verification of the results."
"To get started with Sionna, you need to install the package and then run its tutorial. Here's how:\n\n1. Install Sionna:\n\nYou can install Sionna from the Python Package Index (PyPI). It's a good idea to use a virtual environment to avoid conflicts with other packages. On macOS and Linux, you can run the following commands in a terminal to install Sionna:\n\n```python\npython3 -m venv sionna-env    # Create a virtual environment\nsource sionna-env/bin/activate    # Activate the environment\npython -m pip install sionna    # Install Sionna\n```\n\nOn Windows, you can run the following commands in a command prompt:\n\n```python\npython -m venv sionna-env    # Create a virtual environment\ncall sionna-env\\Scripts\\activate    # Activate the environment\npython -m pip install sionna    # Install Sionna\n```\n\n2. Run the tutorial:\n\nAfter installing Sionna, you can run its tutorial by importing the `sionna` package and calling the `tutorial` function:\n\n```python\nimport sionna\nsionna.tutorial()\n```\n\nThe tutorial covers the following aspects:\n\n- Deep learning is implemented using Keras and tf for ready to use models\n- Code for writing and reading PDMIQData is provided for easy reuse\n- Examples show how to create custom datasets\n- A complete 5G NR example demonstrates how to automatically generate CQIs for arbitrary topologies and batch sizes\n- The tutorial also explains how to contribute to Sionna\n\nThe tutorial also includes sections on:\n\n- Getting started which shows how to install Sionna\n- The PDMIQDataProvider which explains how to efficiently generate random SNR and frequency offest per OFDM symbol\n- How to setup and train simple Keras models\n- An introduction to the differentiable channel models\n- The implementation of custom Keras layers\n- How to write a custom CDF-1 encoder\n- How to automatically generate ON/OFF time series for L87-24 models\n- The comparison of different estimators\n- An easy example of automatic differentiation using TensorFlow\n- How to contribute to Sionna\n\nRemember to run the tutorial in a Jupyter notebook after starting a kernel. If you're using Google Colab, you can simply upload the notebook and run it."
"To import the necessary modules from the Sionna package, you can follow these steps:\n\n1. First, you need to import the Sionna package. If it's not already installed, you can install it using pip. Here is the code to do this:\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n2. After the package is installed, you can import the necessary modules. Here are some examples:\n\n```python\nfrom sionna.channel import cir_to_time_channel\nfrom sionna.channel import subcarrier_frequencies, cir_to_ofdm_channel, cir_to_ofdm_channel_time, cir_to_ofdm_channel_time_disp\nfrom sionna.channel import ApplyOFDMChannel, ApplyTimeChannel, OFDMChannel, TimeChannel\nfrom sionna.helper import bandwidth, cir_generator, load, save, subcarrier_frequencies\nfrom sionna.mapping import Mapper, Demapper, Constellation, PAM, QAM, load_constellation\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nfrom sionna.fec.ldpc.decoding import LDPC5GDecoder\nfrom sionna.fec.polar.encoding import Polar5GEncoder\nfrom sionna.fec.polar.decoding import Polar5GDecoder\nfrom sionna.utils import BinarySource, ebnodb2no, no2ebnodb\n```\n\nRemember to replace the module names with the ones you need for your specific use case."
"To apply the gradient to the weights using an optimizer in the Sionna package, you need to follow these steps:\n\n1. Define your model: In the context, a simple single-user multiple-input multiple-output (MIMO) link is simulated. The model includes a transmitter, a channel, and a receiver. The transmitter includes a binary source, an encoder, and a mapper. The channel is an optical MIMO channel. The receiver includes a demapper and a decoder. The model is implemented as a Keras model. \n\n2. Compile your model with the optimizer: Before compiling, the loss function is defined. In the context, the binary cross-entropy is used as the loss function. The model is then compiled using the `tf.keras.Model.compile` function, where the `optimizer` parameter is set to the optimizer you want to use (in this case, `SGD` is used).\n\n3. Train your model: The model is trained for a number of training iterations. During each iteration, a batch of examples is randomly generated using the `tf.data.Dataset` class, and the model is trained on this batch using the `tf.keras.Model.fit` function.\n\n4. Get the gradients: After each batch, the gradients of the weights with respect to the loss are computed using the `tf.GradientTape` context. \n\n5. Apply the gradients: The gradients are then passed to the `optimizer` using the `optimizer.apply_gradients` function. This function updates the weights of the model using the computed gradients.\n\nHere is the relevant code from the context:\n\n```python\ndef apply_gradients(optimizer, model, loss, num_iterations, batch_size):\n    for i in range(num_iterations):\n        with tf.GradientTape() as tape:\n            tape.watch(model.trainable_weights)\n            x_hat, w_hat, _ = model(batch_size)\n            l = loss(w, w_hat)\n        grads = tape.gradient(l, model.trainable_weights)\n        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n```\n\nPlease note that the `optimizer` is an instance of an optimizer such as `SGD`, `Adam`, or `RGD`. The `num_iterations` parameter specifies how many training iterations to perform, and the `batch_size` parameter specifies the size of the batches to use."
"Here is the detailed information of qam:  [sionna.mapping.qam(num_bits_per_symbol, normalize=True)](https://nips.cc/external/6A 2.0 1/fundamentals.html#sionna.mapping.qam)  \n  \nFunction that performs a M-ary Quadrature Amplitude Modulation (M-QAM).\n\nM-ary QAM is the modulation format used by the 802.11 standard [IEEE80211]. It is also often simply referred to as \u201cQAM\u201d (Quadrature Amplitude Modulation).\n\nIn QAM, each symbol carries log2M bits. The bits are mapped to a constellation point consisting of two orthogonal channels. This constellation is not normalized, which means that the energy per symbol is not unity. It is not difficult to show, that the average energy per constellation point is $\\hat{E}\\left[\\lvert x \\rvert^2 \\right]=\\frac{M-1}{3}\\cdot\\sigma^2$, where $\\sigma^2$ is the variance of x. For the normalization, the energy is assumed to be $\\hat{E}\\left[\\lvert x \\rvert^2 \\right]=1$.  \n  \n\n### Input\n\n- `num_bits_per_symbol` (int): The number of bits per constellation symbol.  \n- `normalize` (bool): If set to True, the constellation is normalized to have unit power. Defaults to True.\n\n### Output\n\n- `x` ([M], tf.complex): A constellation of M-ary QAM.  \n- `bits` ([M, num_bits_per_symbol], tf.float): The constellation expressed as binary vectors.\n\nsource code:\n```python\ndef qam(num_bits_per_symbol, normalize=True):\n    \"\"\"\n    qam(num_bits_per_symbol, normalize=True)\n\n    Modulation map for M-ary QAM (Quadrature Amplitude Modulation).\n\n    M-ary QAM is the modulation format used by the 802.11 standard [IEEE80211].\n    It is also often simply referred to as \"QAM\" (Quadrature Amplitude Modulation).\n\n    In QAM, each symbol carries :math:`\\log_2M` bits. The bits are mapped to a\n    constellation point consisting of two orthogonal channels. This\n    constellation is not normalized, which means that the energy per symbol\n    is not unity. It is not difficult to show, that the average energy per\n    constellation point is :math:`\\hat{E}\\left[ \\lvert x \\rvert^2 \\right]=\\frac{M-1}{3}\\cdot\\sigma^2`,\n    where :math:`\\sigma^2` is the variance of x. For the normalization, the\n    energy is assumed to be :math:`\\hat{E}\\left[ \\lvert x \\rvert^2 \\right]=1`.\n\n    Input\n    -----\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol.\n\n    normalize : bool\n        If `True`, the constellation is normalized to have unit power.\n        Defaults to `True`.\n\n    Output\n    ------\n    x : [M], tf.complex\n        A constellation of M-ary QAM.\n\n    bits : [M, num_bits_per_symbol], tf.float\n        The constellation expressed as binary vectors.\n    \"\"\"\n    levels = 2**tf.range(num_bits_per_symbol, dtype=tf.float32, axis=-1)\n    levels -= levels[-1]/2\n    const = tf.complex(levels, tf.zeros_like(levels))\n    if normalize:\n        energy = tf.reduce_mean(tf.square(tf.abs(const)))\n        energy_sqrt = tf.cast(tf.sqrt(energy), tf.complex64)\n        const = tf.divide(const, energy_sqrt)\n    return const, binary_symbol(x, num_bits_per_symbol)\n```  \n  "
"Here is the definition of RandomInterleaver:  sion.fec.interleaving.RandomInterleaver(seed=None, keep_batch_constant=False, axis=- 1)  \n\nThe source code is as follows:  \n```python\nclass RandomInterleaver(Interleaver):\n    \"\"\"RandomInterleaver(seed=None, keep_batch_constant=False, axis=-1)\n\n    Permutes tensors through pseudo-random rotation of elements.\n\n    This class inherits from the Keras layer class and can be used as layer in\n    a Keras model.\n\n    Elements are rotated `seed` times with a certain distance which can be\n    defined through the distance between seed and target index and through\n    the axis which is defined as last dimension by default.\n\n    If the distance is zero (called zero distance), we do not move the\n    element away from its position but exit the loop.  This can be used to\n    find optimized interleaving patterns which minimize the distance moved.\n\n    The class has one of the richest APIs among similar interleavers, mostly\n    due to its versatility. Properties can be accessed either via\n    class object or via `Keras` functional calls. Either `seed` or\n    `keep_batch_constant` must be given, defaults to `None`. Gives the\n    same output (with respect to bitmask) if called with the same seed.\n    Can be inverted and distance is ignored for this and distance can\n    be set to `-1`.\n\n    Note that this implementation slightly deviates from the one in [Goodrich]_.\n\n    Parameters\n    ----------\n        seed: int or None\n            Defaults to `None`. The seed for the random generator.\n            If None, the global random seed is used.\n            Must be chosen such that for all batch samples either `seed` or\n            `keep_batch_constant` is `None`.\n            If `keep_batch_constant` is set, this integer serves as seed\n            for every batch sample.\n\n        keep_batch_constant: bool\n            Defaults to `False`. If `True`, the same permutation is used for\n            the complete batch. Otherwise, permutates every sample\n            independently.\n\n        axis: int\n            Defaults to `-1`. The dimension that should be interleaved.\n            Cannot be the first dimension.\n\n    Input\n    -----\n        x: tf.DType\n            2+D tensor of arbitrary shape.\n    Output\n    ------\n        : tf.DType\n            2+D tensor of same shape as ``x``.\n\n    Raises\n    ------\n        AssertionError\n            If ``seed`` is not `None` or `an integer`, or if\n            ``keep_batch_constant`` is not `None` `or` `boolean`.\n\n    Note\n    ----\n        Note that it is required that `x.shape[axis]` != 1.\n\n    \"\"\"\n\n    def __init__(self, seed=None, keep_batch_constant=False, axis=-1):\n        super().__init__(seed=seed, keep_batch_constant=keep_batch_constant,\n                         axis=axis, internal_call=True)\n```\n  "
"Here is the detailed information of pam: [s, es, eb]=pam(m, s, return_s=False, return_es=False)\n    \ns, es, eb = pam(m, s[, return_s=False[, return_es=False]])\n\nNormalized average energy per information bit (a.k.a. energy spectral density); for alternatives, see [[3GPP TR 38.101, \u201cNR; Base Station (BS) conformance testing Part 1; Basic conformance testing https://www.3gpp.org/ftp/Specs/archive/38_series/38.101/38101-h00.zip]](https://www.3gpp.org/ftp/Specs/archive/38_series/38.101/38101-h00.zip), section 7, and [[3GPP TR 38.141 \u201cBase Station (BS) conformance testing Part 3; Channel sounding\u201d, https://www.3gpp.org/ftp/Specs/archive/38_series/38.141/38141-h00.zip]](https://www.3gpp.org/ftp/Specs/archive/38_series/38.141/38141-h00.zip), section 6.\n\n**Input**\n\n- `m` (int) \u2013 Number of bits per symbol.\n- `s` ([...,n], tf.complex) \u2013 Sequence of symbols.\n- `return_s` (bool) \u2013 Defaults to False. If True, the function returns `s` itself.\n- `return_es` (bool) \u2013 Defaults to False. If True, the average energy per symbol `es` is returned.\n\n**Output**\n\n- `s` ([...,n/2], tf.complex) \u2013 Sequence of symbols after mapping to the QAM constellation. The output is interleaved following [[3GPP TR 38.142 \u201c3GPPI TS 38.142 Channel model for frequencies from 0.5 GHz up to 1.4 GHz https://www.3gpp.org/ftp/Specs/archive/38_series/38.142/38142-h00.zip]](https://www.3gpp.org/ftp/Specs/archive/38_series/38.142/38142-h00.zip).\n- `es` (tf.float) \u2013 Average energy per symbol.\n- `s` (tf.complex) \u2013 Included only if `return_s` is True. Contains the symbol sequence in an interleaved format.\n\nsource code:\n```python\ndef pam(m, s, return_s=False, return_es=False):\n    r\"\"\"\n    Normalized average energy per information bit (a.k.a. energy spectral\n    density); for alternatives, see [3GPP_TR38101]_, section 7, and\n    [3GPP_TR38141]_, section 6.\n\n    Input\n    -----\n    m : int\n        Number of bits per symbol.\n\n    s : [...,n], tf.complex\n        Sequence of symbols.\n\n    return_s : bool\n        Defaults to `False`. If `True`, the function returns `s` itself.\n\n    return_es : bool\n        Defaults to `False`. If `True`, the average energy per symbol\n        :math:`E_s` is returned.\n\n    Output\n    ------\n    s : [...,n/2], tf.complex\n        Sequence of symbols after mapping to the QAM constellation. The\n        output is interleaved following [3GPP_TR38101]_, section 7 and\n        [3GPP_TR38141]_, section 6.\n\n    es : tf.float\n        Average energy per symbol :math:`E_s`.. Can be interpreted as the\n        effective energy per information bit after QAM mapping.\n    \"\"\"\n    c = 1/np.var(s, keepdims=True)\n    if is_tf_tensor(c, 'complex'):\n        one = tf.cast(1, c.dtype)\n        c = tf.broadcast_to(c, s.shape)\n    else:\n        c = np.broadcast_to(c, s.shape)\n    s_n = tf.complex(tf.reduce_mean(c*tf.real(s)**2, axis=-1),\n                     tf.reduce_mean(c*tf.imag(s)**2, axis=-1))\n    if return_s:\n        s = intersperse(s_n, reverse=True)\n    if return_es:\n        es = tf.reduce_mean(tf.reduce_sum(c*tf.abs(s), axis=-1))\n        return s, es\n    return s\n```"
"The `Polar5GDecoder` in Sionna is a class that implements 5G-compliant decoding of Polar codes, including the rate-matching process. It is designed to operate in either bit-LLR domain or the Symbol domain, based on the parameter `dec_type`. The `Polar5GDecoder` uses the Successive Cancellation (SC) algorithm for decoding.\n\nThe `Polar5GDecoder` takes several parameters, two of which are `return_crc_status` and `output_dtype`. \n\nThe `return_crc_status` parameter is used to control whether the CRC (Cyclic Redundancy Check) status should be returned alongside the decoded data. This parameter is important as it allows the caller of the decoder to verify if the decoding was successful based on the CRC status. If `return_crc_status` is set to `True`, the `dec_crc_status` (CRC status) and `enc_crc_status` (known CRC status from the encoder) are returned along with the decoded output. It is described in the provided context that these CRCs are used to check if the payload was transmitted correctly.\n\nThe `output_dtype` parameter is used to set the output data type of the decoder. In the Sionna library, the output type of the `Polar5GDecoder` is set to `tf.float32` by default, which represents LLR (Log-Likelihood Ratios) with infinite precision. However, in practical implementations, to save memory and increase decoding throughput, the output dtype is set to `tf.float16` for models where reduced precision is sufficient. \n\nTo summarize, `return_crc_status` is essential for verifying the success of the decoding process, and `output_dtype` can be adjusted to cater to the needs of the specific application while maintaining efficiency."
"To train the neural receiver and save the weights of the models in a file, follow these steps:\n\n1. Define and train the Neural Receiver: First, define a `NeuralReceiver` class that inherits from `tf.keras.Model`. This class defines a model that includes a neural receiver, which consists of three dense layers with ReLU activation. Then, call the `train` method of the `model`, and train it for a specified number of training iterations.\n\n```python\nmodel = NeuralReceiver(no_of_bits_per_symbol=NUM_BITS_PER_SYMBOL)\nmodel.train(\n    training_losses,\n    eb_no_db=EB_NO_DB,\n    batch_size=BATCH_SIZE,\n    num_iterations=NUM_TRAINING_ITERATIONS\n)\n```\n\n2. Save the weights of the model: After training, you can save the weights of the model to a file using the `pickle` module. Saving and loading the weights of a model is a common way to reuse a model after it has been trained.\n\n```python\nwith open('neural_receiver_weights', 'wb') as f:\n    pickle.dump(model.weights, f)\n```\n\n3. Load the saved weights and create a new model: To use the weights from the trained model for further experimentation, you can load the saved weights from the file and use them to create a new model. The new model will have the same architecture and weights as the trained model.\n\n```python\nwith open('neural_receiver_weights', 'rb') as f:\n    weights = pickle.load(f)\n    model = NeuralReceiver(no_of_bits_per_symbol=NUM_BITS_PER_SYMBOL)\n    model.set_weights(weights)\n```\n\nRemember to replace `NUM_BITS_PER_SYMBOL`, `BATCH_SIZE`, and `NUM_TRAINING_ITERATIONS` with the actual values for your training setup. \n\nAlso, ensure that the `NeuralReceiver` class and the `train` method are defined correctly in the context."
"Here are some useful links of it:\n\n[Run in Google Colab](https://colab.research.google.com/github/nvlabs/sionna/blob/main/doc/user_guide_part1.ipynb)\n\n[View on GitHub](https://github.com/nvlabs/sionna/blob/main/doc/user_guide_part1.ipynb)\n\n[Download notebook](https://nvlabs.github.io/sionna/doc/user_guide_part1.ipynb)"
"To run some throughput tests in Graph Mode using the Sionna Python package, follow these steps:\n\n1. Import the necessary modules and packages, including Sionna. If Sionna is not already installed, you can install it using pip.\n\n```python\nimport os\nimport sionna\nimport numpy as np\nimport tensorflow as tf\n```\n\n2. Set up your environment. This includes setting the GPU number and other parameters for TensorFlow.\n\n```python\ngpu_num = 0\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n3. Initialize the necessary layers for your simulation. This includes the AWGN channel layer, the binary source, the encoder, the mapper, the demapper, and the decoder.\n\n```python\nchannel = sionna.channel.AWGN()\nbinary_source = sionna.utils.BinarySource()\nencoder = sionna.fec.ldpc.encoding.LDPC5GEncoder(k_ldpc, n_ldpc)\nmapper = sionna.mapping.Mapper(constellation=constellation)\ndemapper = sionna.mapping.Demapper(demapping_method, constellation=constellation)\ndecoder = sionna.fec.ldpc.decoding.LDPC5GDecoder(encoder, hard_out=True, algorithm=decoding_algorithm, num_iter=20)\n```\n\n4. Define a simulation function that uses TensorFlow's graph mode. This function should create a binary source, encode it, map it over the AWGN channel, demap it, and then decode it.\n\n```python\ndef simulate_throughput_graph(n_mc):\n    throughput = np.zeros(n_mc)\n    batch_size = 1000\n    ebno_db = np.arange(0.0, 16.0, 2.0)\n\n    for i in range(n_mc):\n        b = binary_source([batch_size, k_ldpc])\n        c = encoder(b)\n        x = mapper(c)\n        no = sionna.utils.ebnodb2no(ebno_db, batch_size, len(constellation))\n        y = channel([x, no])\n        llr = demapper([y, no])\n        b_hat = decoder(llr)\n        throughput[i] = k_ldpc / n_mc\n```\n\n5. Run the function for the desired number of Monte Carlo simulations.\n\n```python\nn_mc = 100\nsimulate_throughput_graph(n_mc)\n```\n\nPlease note that the code snippets provided are based on the context of the Sionna Python package and may need to be adjusted based on your specific use case."
"To configure a rate-1/2, constraint-length-3 convolutional code encoder using the `ConvEncoder` class from the `sionna.fec.conv` module, you can follow two different instantiation methods. The encoder is used to encode messages in a binary format with a rate equal to 1/2 and with a constraint length of 3. \n\nFirst, you need to import the `ConvEncoder` class:\n\n```python\nfrom sionna.fec.conv import ConvEncoder\n```\n\n### Method 1: Using `rate` and `constraint_length` direct values\n\nYou can create an instance of `ConvEncoder` by providing the rate and constraint length as direct values:\n\n```python\n# Directly specifying the rate and constraint length\nencoder = ConvEncoder(rate=1/2, constraint_length=3)\n```\n\n### Method 2: Using `gen_poly`\n\nAlternatively, you can create an encoder instance by providing the generator polynomials `gen_poly` directly. It is a Tukey ladder form which is represented as a tuple of binary arrays with each array of binary values being a string of 0's and 1's. An example of a valid `gen_poly` tuple for a rate-1/2, constraint-length-3 code would be:\n\n```python\n# Assumed valid generator polynomials for a rate-1/2, constraint-length-3 code\ngen_poly = ('101', '111')\n```\nPlease ensure that the `gen_poly` provided is valid for the specified rate and constraint length.\n\nNow, demonstrate both methods of creating the encoder for the given configuration:\n\n### Instantiation Method 1: Using `rate` and `constraint_length`\n\n```python\n# Encoder instantiation using rate and constraint_length\nencoder_method1 = ConvEncoder(rate=1/2, constraint_length=3)\n```\n\n### Instantiation Method 2: Using `gen_poly`\n\n```python\n# Encoder instantiation using gen_poly\nencoder_method2 = ConvEncoder(gen_poly=gen_poly)\n```\n\nBoth `encoder_method1` and `encoder_method2` are referring to the same `ConvEncoder` instance, but they were created using different methods. method1 uses `rate` and `constraint_length` parameters, method2 uses `gen_poly`. \n\nTo encode information bits using the rate-1/2, constraint-length-3 convolutional code from the `ConvEncoder` instance, you can use the following steps:\n\n1. Provide the input message as a 2+D tensor of shape `[n, k]`, where `k` is the number of information bits. For example:\n\n```python\nimport tensorflow as tf\n\n# Random 0/1 message tensor shaped [n, k]\n# Encoded message will have shape [...,2], the last dimension being the two bits encoded per output symbol\nu = tf.random.uniform(shape=[100, 10], minval=0, maxval=2, dtype=tf.int32)\n```\n\n2. Pass the message tensor to the encoder to get the encoded codeword bits:\n\n```python\n# Get the encoded output for the input message tensor\nc = encoder_method1(u)\n```\n\n3. The output `c` is also a 2+D tensor shaped `[...,2]`. It contains the bit representations of the codeword symbols, where each bit is represented as a pair.\n\nRemember that the two instantiation methods create the same encoder, but the usage may vary depending on the availability of parameters or the convenience of specifying the generator polynomials directly."
"Alright, let's talk about the \"Rural macrocell (RMa)\" model with its principles, parameters, inputs, and outputs. \n\nThe Rural Macrocell Model (RMa) is from 3GPP specification in TR 38.901. It enables coverage simulations for areas where base stations are located. The key principle of the RMa model is to consider coverage from a serving site equipped with multiple antennas. \n\nNow, for the parameters of the RMa model. The RMa model takes the following parameters as inputs:\n\n1. Carrier frequency\n2. Base station array\n3. User terminal array\n4. Number of base station antennas\n5. Number of user terminal antennas\n6. Delay spread\n7. CDL model\n\nAnd from this it generates an output of pathloss.\n\nTo utilize the RMa model, you need to initialize a NonUrbanPathloss object with the carrier frequency, base station array, user terminal array, number of base station antennas, number of user terminals antennas, delay spread and CDL model.\n\nHere is an example of how you can use the RMa model in the Sionna API:\n\n```python\nfrom sionna.channel.tr38 import NonUrbanPathloss, CdlType, RMa\nfrom sionna.nr import SubCarrier, AntennaArray\n\n# Define the number of base station antennas and create an antenna array\nnum_bs_ant = 4\nbs_array = AntennaArray(num_rows=1, num_cols=num_bs_ant, polarization=\"dual\", polarization_type=\"VH\")\n\n# Define the number of user antennas and create an antenna array\nnum_ut_ant = 2\nut_array = AntennaArray(num_rows=1, num_cols=num_ut_ant, polarization=\"dual\", polarization_type=\"VH\")\n\n# Define the RMa channel model\ncdl_type = CdlType.CDL_RM_3GPP\nrm = RMa(cdl_type, 3.5e9)\n\n# Define the sub-carriers and create a transmissin channel\nsc = SubCarrier(15e3, 12)\n# Create the channel\nchannel = NonUrbanPathloss(carrier_frequency=3.5e9, bs_array=bs_array, ut_array=ut_array, delay_spread=300e-9, cdl_model=rm)\n```\n\nIn this example, the RMa model is set up with an antenna array for the base station and the user terminal, then a transmission channel is created using the defined RMa model."
"The `Trellis` structure in the `sionna.fec.conv.utils` module is used to define the state transitions in the encoding process of a convolutional code. It is a part of the machinery used in the `gen_poly` and `rsc` functions to generate the generator or recursive systematic codes, respectively.\n\nTo initialize a `Trellis` structure, you can use the `gen_poly` parameter or the `rsc` parameter. \n\n1. Using `gen_poly`:\n```python\nfrom sionna.fec.conv.utils import gen_poly, Trellis\ngen_poly(rate, constraint_length)  # gen_poly returns a tuple with two polynomials\ntrellis = Trellis(gen_poly=gen_poly, rate=rate, constraint_length=constraint_length)\n```\nHere, `rate` is the code rate (ejsonn.fec.conv.utils.Rate), and `constraint_length` is an integer defining the constraint length of the code.\n\n2. Using `rsc`:\n```python\nfrom sionna.fec.conv.utils import rsc\ntrellis = Trellis(rsc_selector=rsc, rate=rate, constraint_length=constraint_length)\n```\nHere, `rsc` is a tuple containing the generator polynomials used to define the recursive systematic code. The polynomials are represented as strings in binary form.\n\nIn both initialization methods, the `rate` and `constraint_length` parameters are required to set up the `Trellis` structure. The `rate` parameter defines the code rate, which is the number of input bits per information bit. The `constraint_length` parameter defines the memory of the encoder, which is the number of input bits that influence the output of the encoder. This parameter is associated with the quality of the code - generally, a longer constraint length leads to better performance, but also implies a more complex encoder.\n\nThe `Trellis` structure effectively defines the state transitions and the output bits (either systematic or parity bits) for each possible input bit and current state in the encoding process. This is crucial for understanding the behavior of the code when it receives new input bits. This structure aims to optimize the distance properties of the code and ensure efficient and reliable encoding and decoding processes."
"Here is the detailed information of CarrierConfig:   \n  \n[sionna.nr.CarrierConfig(**kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/nr/carrier_config.html#CarrierConfig)  \n\nThe CarrierConfig is a container for parameters that are shared by multiple higher layer configuration objects. It is also a callable defining a resource grid and its association to a OFDM symbol duration and subcarrier spacing.\n\n**Parameters**\n\n- `n_prb` (int): Number of PRB.\n- `subcarrier_spacing` (float): Subcarrier spacing [Hz].\n- `num_samples_per_symbol` (int): Number of samples per OFDM symbol.\n- `cyclic_prefix_length` (int): Cyclic prefix length.\n- `frame_duration` (float): Duration of the frame [s].\n- `n_ffts_per_subframe` (int): Number of FFTs per subframe.\n- `taper_and_nulling` (bool): If True, the two center subcarriers are multiplied by a time-domain taper and nulled. This is typically used for pulse shaping with a root-raised-cosine filter on thejson.configured subcarrier sequence. Defaults to True.\n- `pad_with_nuls` (bool): If True, the resource grid is padded with nuls to reach the next power of two. This is required for the application of convolutional channel models using OFDMModulators. Defaults to True.\n- `channel_model` (str): One of [\"rayleigh\", \"etu\", \"uma\", \"umf\", \"tr38901\"], \"custom\", or an instance of ChannelModel. Custom channel models should be provided as an instance of the ChannelModel class or a callable object defining the signature `(batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_subcarrier, num_ofdm_symbols, num_time_steps) -> (h, h_corr)`, where `h` and `h_corr` have shapes `[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_subcarrier, num_ofdm_symbols, num_time_steps]` and `[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_rx_subcarrier, num_tx_subcarrier, num_ofdm_symbols, num_time_steps]` respectively. In the absence of channel model parameters, the \"rayleigh\" model will be used with a single bounce. When using a custom channel model, the corresponding resource grid and/or pilot pattern must be provided, to which the channel model is applied. Note that the batch size is the first dimension of `h` and `h_corr`, enabling the parallel processing of multiple examples.\n- `cdl` (str): One of [\"A\", \"B\", \"C\", \"D\", \"E\"]. Only required for the \"uma\", \"umf\", and \"tr38901\" models, and specifies the CDL model to use. Note that the \"D\" model is only available for the \"DFT-SP\" and \"DFT-OP\" modes. Defaults to \"A\".\n- `los` (bool): If True, the \"LineOfSight\" method of the non-predited LoS component is used, for all other cases, the \"Rayleigh\" method is used. Defaults to False.\n- `pilot_pattern` (PilotPattern): Instance of PilotPattern or None. If None, no pilot phase restoration is performed. Defaults to None.\n- `resource_grid` (ResourceGrid): Instance of ResourceGrid or None. If None, a default resource grid is instantiated. Defaults to None.\n- `scs` (None or float): Subcarrier spacing [Hz]. If set to None, the subcarrier spacing from the 3GPP NR specification will be used. Defaults to None.\n- `subframe_duration` (None or float): Duration of a subframe [s]. If set to None, a frame duration of `frame_duration` will be used. Defaults to None.\n- `num_syms_per_slot` (None or int): Number of OFDM symbols per slot. If set to None, the value will be computed from `subframe_duration`, `n_ffts_per_subframe`, and `subcarrier_spacing` using the 3GPP specification. Defaults to None.\n- `num_cp` (None or int): Cyclic prefix length. If set to None, the value will be computed from `cyclic_prefix_length` and `subcarrier_spacing` using the 3GPP specification. Defaults to None.\n- `dtype` (tf.DType): The dtype of the output. Defaults to tf.complex64.\n\n**Output**\n- `CarrierConfig`: Carrier configuration based on the above parameters.\n\n**Note**: This class is also a callable. If you want to change any parameters of the `CarrierConfig` after instantiating it, you can simply use it like a method and it will act like a setter. This class is callable."
"Here is the definition of Receiver: sionna.rt.Receiver(name, position, orientation=(0.0, 0.0, 0.0), look_at=None, color='#1f77b4')\n\n[source code](https://nvlabs.github.io/sionna/_modules/sionna/rt/receiver.html#Receiver)  \n\nsource code:\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\nfrom .transmitter import Transmitter\n\nclass Receiver(Transmitter):\n    # pylint: disable=line-too-long\n    r\"\"\"Receiver that computes the received signal for a given transmitter(s)\n\n    The class inherits from the transmitter class and can be used to\n    compute the received signal for a transmitter or transmitter set.\n    The class provides various properties and can be used to compute\n    the BER or as an binary Keras metric.\n\n    Parameters\n    ----------\n    name : str\n        Name of the device\n\n    position : array_like\n        [x,y,z] Position of the receiver\n\n    orientation : array_like\n        [x,y,z] Orientation of the receiver. This parameter is ignored\n        if ``look_at`` is not `None`. Defaults to [0,0,0].\n\n    look_at : array_like\n        [x,y,z] or [`transmitter_name`, `receiver_name`] If set to\n        a 3D vector, then ``orientation`` is computed such that the\n        receiver looks at this point. If set to two strings, then these\n        strings are the names of a transmitter and receiver. In this case,\n        the transmitter looks at the receiver. This only works if there is\n        only one transmitter and one receiver in the scene. If set to `None`,\n        then ``orientation`` is used to orient the receiver.\n\n    color : str\n        Color used for visualization\n\n    Input\n    -----\n    scene : :class:`~sionna.rt.Scene`\n        Scene\n\n    dtype : tf.complex64 or tf.complex128\n        Datatype for all computations.\n        Defaults to `tf.complex64`.\n\n    Output\n    ------\n    signal : :class`~tf.complex`\n        Received signal\n\n    ber : :class`~tf.float32`\n        Computed as described in :eq:`ber`. Only returned if\n        ``return_ber`` is `True`.\n\n    Note\n    ----\n    If you want to use this layer in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sionna.Config.xla_compat=true``.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n    def __init__(self,\n                 name,\n                 position,\n                 orientation=(0.,0.,0.),\n                 look_at=None,\n                 color='#1f77b4'):\n\n        # Initialize as a transmitter\n        super().__init__(name=name,\n                         position=position,\n                         orientation=orientation,\n                         look_at=look_at,\n                         color=color)\n```"
"The `ResourceGrid` in the Sionna Python package is used for synchronized OFDM transmissions with multiple streams per transmitter and is a wrapper around several key components in an OFDM system. It is primarily used to define associations between data and channel resources, as well as to regulate advanced properties like precoding and pilot patterns.\n\nThe `ResourceGrid` is initialized with a reference to a `CarrierGrid`, a `PilotPattern`, and possibly a `DMRSGrid` and `Precoder`. The typical sequence of operations involves defining the `ResourceGrid` and its associated pilot and detector instances, before setting up the transmitter and receiver. \n\nKey parameters of the `ResourceGrid` include the number of OFDM symbols, FFT size, number of transmitters, number of streams per transmitter, and the number of active subcarriers. These parameters determine the size and complexity of the `ResourceGrid`.\n\nThe `ResourceGrid` allocates data and pilot symbols on the OFDM resource grid, using the defined `carrier_grid`, `pilot_pattern`, `dmrs_grid`, and `precoder`. It can also indicate which of the OFDM symbols are reserved for reference signals, data, or defined as guard carriers.\n\nThe `ResourceGridMapper` takes a `ResourceGrid` instance and maps a tensor of QAM-modulated data streams to the resource grid, right before OFDM modulation is performed. It's a critical component of the digital baseband processing chain in an OFDM system.\n\nIn usage, the `ResourceGrid` and its associated components are used to define the time-frequency resource grid for associated transmitters and streams, regulate pilot transmissions to adjust for channel conditions, and map OFDM-based time-series channel measurements to the time-frequency resource grid for comparison with system model predictions. \n\nNote that the usage of `ResourceGrid` and its associated components can be affected by the specific requirements of the simulation or system model, and that reference to the official documentation for the Sionna package is necessary for complete and accurate usage."
"To generate a batch of frequency responses using the `FrequecyResponse` method from the `sionna.channel` module, you need to follow these steps:\n\n1. Define the number of samples and subcarriers for your batch. For example, you can set `num_samples = 100` and `num_subcarriers = 10`.\n\n2. Initialize a `FrequencyResponse` object. The `FrequencyResponse` method takes two arguments: `num_tx` (number of transmitters) and `num_rx` (number of receivers). For example:\n\n```python\nchannel_model = OFDMChannel(channel_model, resource_grid, normalize_channel=True, return_channel=True)\n```\n\n3. Generate the batch of frequency responses. The `FrequencyResponse` object acts as a layer that can be used to generate channel impulse responses. For example, if you want to generate a batch of frequency responses `H_freq` from a batch of channel impulse responses `a`, you can use:\n\n```python\nH_freq = channel_model(a)\n```\n\nNote that the shape of `a` should be `(num_tx, num_rx, num_ant_tx, num_ant_rx, num_time_steps)``. The shape of `H_freq` will be`(num_tx, num_rx, num_tx_ant, num_rx_ant, num_subcarriers, num_samples)`. This means that for each pair of a transmitter and receiver, you can evaluate the channel frequency response at `num_samples` different subcarrier frequencies."
"In order to compute propagation paths using Sionna RT, you need to configure transmitters and receivers. Here's how to do it:\n\n1. Import the necessary modules and classes:\n\n```python\nfrom sionna.rt import Scene, Transmitter, Receiver\n```\n\n2. Load the scene that you want to analyze:\n\n```python\nscene = Scene(load, \"scene\")\n```\n\n3. Configure the transmitter:\n\n```python\ntx = Transmitter(name=\"tx\", position=[x, y, z], orientation=[0, 0, 0])\nscene.add(tx)\n```\n\nIn the `position` parameter, replace `[x, y, z]` with the coordinates of the transmitter. In the `orientation` parameter, set it to `[0, 0, 0]` for now. \n\n4. Configure the receiver:\n\n```python\nrx = Receiver(name=\"rx\", position=[x, y, z], orientation=[0, 0, 0])\nscene.add(rx)\n```\n\nLike with the transmitter, in the `position` parameter, replace `[x, y, z]` with the coordinates of the receiver. In the `orientation` parameter, also set it to `[0, 0, 0]`.\n\n5. Compute the paths:\n\n```python\npaths = scene.compute_paths(max_depth=5, num_samples=1e6)\n```\n\n6. If you wish to visualize the paths, you can use the `preview` function:\n\n```python\nscene.preview(paths=paths, show_devices=True, show_paths=True)\n```\n\nPlease note that the `position` and `orientation` parameters are set based on the coordinate system of the scene (in this case, it's the GSM 180.06 standard). It's important to use the correct coordinate system to ensure proper positioning of the transmitters and receivers."
"The deprecated SymbolDemapperWithPrior class is a part of the `mapping` module of the Sionna MIMO package, which deals with mapping and demapping symbols for MIMO (Multi-Input, Multi-Output) communication systems.\n\nThis is a SymbolDemapper class that is now deprecated as part of the updates and changes made to the Sionna MIMO package. The functionality of this class is similar to that of the SymbolDemapper class. \n\nIt extracts hard-decided symbols from a tensor of received symbols, effectively serving as a symbol detector in a MIMO system. However, this class also accepts a prior probability of the computed LLRs, which can be used to influence the demapping process. \n\nThe class takes the following parameters:\n\n- `num_bits_per_symbol`: This is an integer that specifies the number of bits per constellation symbol (e.g., 4 for QAM16).\n- `constellation_type`: This is a string that determines the type of constellation applied and must be one of \"qam\", \"pam\", or \"custom\". If \"custom\" is selected, an instance of `Constellation` must be provided.\n- `num_layers`: This is an integer that specifies the number of MIMO layers.\n- `constellation`: This is an instance of `Constellation` that provides the actual constellation used. If `constellation_type` is not \"custom\", this parameter is ignored.\n- `dtype`: This is a tensorflow datatype that defines the datatype for internal calculations and the output data type.\n\nThe functionality of this class has been deprecated due to changes in the processing modules of the Sionna MIMO package, such as the introduction of new constellation types and improvements to the symbol demapping process. However, the essential functionality of the SymbolDemapper class is still available in the overall package features."
"To enable diffuse reflections and observe their impact on the coverage map in Sionna, you need to use the Sionna RT module and the Sionna channel module. Here are the steps:\n\n1. Import the necessary modules and set up the environment:\n\n```python\nimport os\nimport tensorflow asjson\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport as tensorflow as tf\nfrom sionna.rt import LoadableScene, PlanarArray, Transmitter, Receiver, RadioMaterial, Camera\nfrom sionna.rt.utils import r_hat\nfrom sionna.channel import cir_to_ofdm_channel, subcarrier_frequencies, OFDMChannel, ApplyOFDMChannel, CIRDataset\nfrom sionna.nr import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver\nfrom sionna.utils import compute_ber, ebnodb2no, PlotBER\nfrom tensorflow.keras.losses import BinaryCrossentropy\n```\n\n2. Load the scene and configure the GPU:\n\n```python\nscene = LoadableScene(sionna.rt.scene.simple_wedge)\ngpu_num = 0\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n3. Configure the transmitter and receiver arrays:\n\n```python\nscene.tx_array = PlanarArray(1,1,0.5,0.5,\"iso\",\"V\")\nscene.rx_array = scene.tx_array\n```\n\n4. Add a transmitter and a receiver to the scene:\n\n```python\nscene.add(Transmitter(\"tx\", [-25,0.1,40]))\nscene.add(Receiver(\"rx\", [25,0.1,40]))\n```\n\n5. Compute the propagation paths:\n\n```python\npaths = scene.compute_paths(num_samples=1e6, los=True, reflection=True, diffraction=True, scattering=False)\n```\n\n6. Generate the channel impulse response:\n\n```python\n# The dimension to which we want to add additional dimensions\nadd_dims = len(paths.a)\na = paths.a\ntau = paths.t\na = tf.pad(a, [[0,0], [0,1], [0,1]])\ntau = tf.pad(tau, [[0,0], [0,1], [0,1]])\nh = tf.complex(tf.reduce_sum(a, axis=-3), 0.)\n```\n\n7. Convert the channel impulse response to the channel frequency response:\n\n```python\nf = subcarrier_frequencies(paths.ofdm_channel, paths.df)\nh_freq = tf.reduce_sum(h, axis=-2)*tf.exp(-2j*np.pi*f*tau)\n```\n\n8. Apply the channel:\n\n```python\nh_hat = tf.squeeze(h_freq, axis=-1)\nh_out = channel(h_freq)\n```\n\n9. Compute the coverage map:\n\n```python\nscene.coverage_map(\"tx\",  direction = r_hat(0,0,1))\n```\n\nThe impact of diffuse reflections on the coverage map is represented by the scattering effect in the scene. The coverage map shows the average transmit power received at different locations in the scene."
"To compute the mean-squared error (MSE) between the transmitted and recovered symbols in the context of the Sionna package, you can follow these steps:\n\n1. First, you need to import the necessary packages and modules. This includes Sionna, TensorFlow, and any other required packages.\n\n```python\nimport sionna\nimport tensorflow as tf\nimport numpy as np\n```\n\n2. Generate a batch of random transmit vectors of random 16QAM symbols using the `QAMSource` function from the `sionna.utils` module.\n\n```python\nbatch_size = 100\nnum_tx_ant = 8\nqam_source = sionna.utils.QAMSource(num_bits_per_symbol=4, num_tx_ant=8)\nx = qam_source([batch_size, num_tx_ant])\n```\n\n3. Use an up to 128 transmit antennas for the receiver's list of candidate solutions. In this example, we'll use 16 transmit antennas and generate 16 receive antennas by adding some white Gaussian noise.\n\n```python\nnum_rx_ant = 16\nnoise_var = 0.1\ny = sionna.channel.awgn(x, noise_variance=noise_var)\nh = np.random.normal(size=[batch_size, num_rx_ant, num_tx_ant]) + 1j*np.random.normal(size=[batch_size, num_rx_ant, num_tx_ant])\n```\n\n4. Implement the LMMSE equalizer to compute soft-symbols using the perfect channel knowledge. The channel output `y` and the channel covariance matrix `s` are used as input.\n\n```python\ns = np.tile(np.eye(num_rx_ant), [batch_size, 1, 1])\nx_hat, no_eff = lmmse_equalizer(y, h, s)\n```\n\n5. Make hard decisions on the symbol estimates and compute the MSE.\n\n```python\nx_ind_hat = tf.argmax(tf.abs(x_hat), axis=-1, output_type=tf.int32)\nx_ind = tf.argmax(tf.abs(x), axis=-1, output_type=tf.int32)\nmse = tf.reduce_mean(tf.square(x_ind - x_ind_hat))\n```\n\nIn this example, the function `lmmse_equalizer` is not provided, so you need to implement it yourself. The function takes the channel output `y`, the channel covariance matrix `s`, and the number of paths as input, and returns the estimated symbol vector `x_hat` and the effective noise variance `no_eff`.\n\nThe MSE is computed by squaring the difference between the transmitted and received symbols, and then taking the mean. This gives a measure of the average energy of the error between the transmitted and recovered symbols."
"The 'create_or_check_constellation' method is used in the Constellation class to generate a QAM constellation diagram on the fly or, if the constellation is not valid, to check and return a proper constellation object. This method is important for the proper functioning of the Constellation class, which is used for the visualization and manipulation of constellations used in digital communication systems.\n\nIf the Constellation object is instantiated with certain parameters, including 'qam', 'num_bits_per_symbol', or 'constellation_points', this method ensures that a valid constellation is created. Similarly, if a constellation is defined and needs to be verified, this method checks that the constellation is valid or else generates a new one.\n\nIt looks like this:\n\n```python\n    def create_or_check_constellation(self):\n        \"\"\"Create or check constellation.\n\n        Return\n        ------\n        : : [x, x]\n            NumPy array of shape ``[2, num_points]`` and dtype ``np.complex64``\n            Contellation points.\n        \"\"\"\n        if self._create_constellation:\n            num_bits_per_symbol = self._num_bits_per_symbol\n            mod_symbols = Constellation.qam(\n                num_bits_per_symbol, return_indices=True)\n            return mod_symbols[1]\n        else:\n            mod_symbols = self._mod_symbols\n            return mod_symbols\n```\n\nThis method is typically called by other methods or functions that need to operate on the constellation, ensuring that a valid constellation is used or created."
"The `scat_keep_prob` argument is a parameter in the ray tracing process used in the Sionna RT module, a component of the Sionna package, which is written in Python. The purpose of this argument is to control the visibility of objects in the scene for the ray tracing process. \n\nWhen `scat_keep_prob` is set to a value less than 1, certain objects in the scene are effectively removed or ignored during the ray tracing process. This is used to either simplify the scene for rendering purposes or to adjust the scene to various ray tracing experiments or simulations. \n\nConsider a scene that contains multiple objects or elements such as cars, trees, buildings, etc. Setting `scat_keep_prob` to a fraction less than 1 allows certain objects to be ignored during the ray tracing process. This can be used, for example, to simulate the effect of cars suddenly disappearing or moving away, or the impact of adjusting the environment by adding or removing certain objects.\n\nNote that `scat_keep_prob` does not affect the actual visibility of the objects in the scene, it just controls their inclusion in the ray tracing process. This means that objects can still be seen and interacted with in the rendered scene, regardless of the value of `scat_keep_prob`. The visual appearance and interactions of the objects are not affected, only their inclusion in the ray tracing process is modified. \n\nThe `scat_keep_prob` argument is part of the `Scene` class and can be set when creating or modifying a scene. It is a floating point number between 0 and 1, inclusive. The default value of `scat_keep_prob` is 1, which means all objects in the scene are included by default. When setting `scat_keep_prob` to a value less than 1, the specified fraction of objects is randomly chosen to be ignored for each ray tracing operation."
"Here is the detailed information of sionna.rt.r_hat: [sionna.rt.r_hat(phi, theta, r)](https://nvlabs.github.io/sionna/_modules/sionna/rt/utils.html#r_hat)\n\nComputes the spherical unit vector $\\hat\\mathbf{r}(\\phi, \\theta)$ as defined in [(1)](https://nvlabs.github.io/sionna/em_primer.html#equation-spherical-vecs)\n\n**Input**\n\n- `phi` (or `\u03b8`): Azimuth angles $\\alpha$ [rad]. This can be a value or an array of values.\n- `theta` (or `\u03c6`): Zenith angles $\\theta$ [rad]. This can be a value or an array of values.\n- `r` : Radius of the sphere [m]. Must be greater than 0.\n\n**Output**\n\n- **3D tensor**: $\\hat\\mathbf{r}(\\phi, \\theta)$ [rad], for all combinations of $\\phi$ and $\\theta$.\n\nsource code:\n```python\ndef r_hat(phi, theta, r):\n    \"\"\"\n    Computes the spherical unit vector\n    :math:`\\hat\\mathbf{r}(\\phi, \\theta)`\n    as defined in :eq:`spherical_vecs`\n\n    Input\n    -------\n    phi : array_like, or tf.Tensor\n        Azimuth angles :math:`\\alpha` [rad]\n\n    theta : array_like, or tf.Tensor\n        Zenith angles :math:`\\theta` [rad]\n\n    r : array_like, or tf.Tensor\n        Radius of the sphere [m].\n        Must be greater than 0.\n\n    Output\n    --------\n    r_hat : tf.Tensor\n        :math:`\\hat\\mathbf{r}(\\phi, \\theta)` [rad].\n        For all combinations of ``phi`` and ``theta``\n    \"\"\"\n\n    x = tf.cos(theta)*tf.cos(phi)\n    y = tf.cos(theta)*tf.sin(phi)\n    z = -tf.sin(theta)\n    return tf.stack([x,y,z], -1)\n```"
"Here is the detailed information of OFDMDetectorWithPrior:   \n  \nParameters for initialiization:  \n- **resource_grid** (`ResourceGrid`) : An instance of `ResourceGrid`.\n- **stream_management** (`StreamManagement`) : An instance of `StreamManagement`.\n- **rx_sm** (`RXStreamManagement`) : An instance of `RXStreamManagement`.\n- **encoder** (`DataEncoder`) : An instance of `DataEncoder`.\n- **puncturer** (`Puncturer`) : An instance of `Puncturer`.\n- **mapper** (`Mapper`) : An instance of `Mapper`.\n- **demapper** (`Demapper`) : An instance of `Demapper`.\n- **detector** (`LMMSEDetector`) : An instance of `LMMSEDetector`.\n- **scrambler** (`Scrambler`) : An instance of `Scrambler`.\n- **channel_estimator** (`ChannelEstimator`) : An instance of `ChannelEstimator`.\n- **f_estimator** (`FrequencEstimator`) : An instance of `FrequencEstimator`.\n- **t_estimator** (`TimingEstimator`) : An instance of `TimingEstimator`.\n- **binary_source** (`BinarySource`) : An instance of `BinarySource`.\n- **ebno_db** (float) : The Eb/No value in dB.\n- **no_interference** (bool) : If set to `True`, no interference will be returned. Defaults to `False`.\n- **cuda_detector** (str) : One of `[None, \"lmmse\"]`. If the value is `\"lmmse\"`, the detector will be run on a GPU. If `None`, or any other value, the detector will be run on the CPU.  \n- **dtype** (tf.DType) : One of `[tf.complex64, tf.complex128]`. The dtype of `y`. Defaults to tf.complex64.  \n- **wd** (LMMSEDetector.WithPrior.MaximumLikelihoodDetector) : An instance of LMMSEMaximumLikelihoodDetector.  \n- **int_prior** (`ndarray` of shape `[num_rx, num_streams_per_rx, num_ofdm_symbols, fft_size]`, `complex`): Prior of the int-demapper.  \n- **demapping_method** (str) : One of `(\"app\", \"maxlog\")`. The demapping method used. `maxlog` is recommended.  \n- **lmmse_equivalent_channel** (bool) : Indicates if an LMMSE equivalent channel is used.  \n- **return_bits** (bool) : If `True`, `b` is returned. Otherwise, `x_hat` and `no` are returned.  \n- **stream_ind** (int or `None`) : Indicates the stream index to be returned. Only used for multi-stream configurations. If `None`, all streams are returned.  \n- **add_noise** (bool) : If `True`, white noise with the variance `no` is added.  \n- **anova** (ResourceGrid.ANOVA) : An instance of ResourceGrid.ANOVA.  \n- **ov** (ResourceGrid.OverlapAdd) : An instance of ResourceGrid.OverlapAdd.  \n- **num_bits_per_symbol** (int) : The number of bits per symbol.  \n- **num_conv_codes** (int) : The number of convolutional codes.  \n- **r_scid** (int) : The r_scid value used for the DMRS generation.  \n- **dmrs_dedupe** (bool) : If `True`, the set of DMRS indices is deduped before mapping to QAM symbols. If `True`, `r_scid` must have a value between  0 and 8.  \n- **n_dmrs_pre_symbols** (int) : The number of pre-coding OFDM symbols occupied by the DMRS signals.  \n- **n_res_dmrs** (int) : The number of resource elements occupied by the DMRS signals.  \n- **mask** (ResourceGrid.Mask) : An instance of ResourceGrid.Mask.  \n- **scale_prior** (bool) : If `True`, the prior is rescaled such that the average energy per channel use is equal to the energy of the received signal.  \n- **apply_phase_inv** (bool) : If `True`, the phase of the receive signal is inverted after FFT.  \n- **return_state** (bool) : If `True`, the internal state of the timing estimator is returned.  \n- **output_dtype** (tf.DType) : The output dtype.  \n  \nInput\n---- \n- **y** ([..., num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex) : The received resource grid after FFT.\n- **no** ([..., num_rx, num_rx_ant] or just `[..., num_rx, num_rx_ant]`, tf.float) : The noise variance estimate per receive antenna.\n- **h_hat** ([..., num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex) : The channel estimates for all streams from all transmitters.\n- **prior** ([..., num_tx, num_streams, num_data_symbols], tf.float) : The prior of all layers.\n- **s** ([..., num_tx, num_streams, num_data_symbols, num_effective_subcarriers], tf.complex) : The LLRs of all (possibly) transmitted streams.\n- **s_var** ([..., num_tx, num_streams, num_data_symbols, num_effective_subcarriers], tf.float) : The variance of the LLRs of all (possibly) transmitted streams.\n\nOutput\n---- \n- **x_hat** ([..., num_tx, num_streams, num_data_symbols], tf.float) : The hard-symbol estimates of all layers.\n- **no_eff** ([..., num_tx, num_streams, num_data_symbols], tf.float) : The effective noise variance estimates for all layers.\n- **sbs** ([..., num_tx, num_streams, num_data_symbols, num_effective_subcarriers], tf.float) : The error propagation metrics for all data and pilot-carrying resource elements.\n- **state** (TimingEstimator.State) : The internal state of the timing estimator. Returned only if `return_state` is `True`.\n  "
"Here is the detailed information of GaussianPriorSource:   \n\n[sionna.rt.GaussianPriorSource(load_scene=True, scene=None, dtype=tf.complex64, **kwargs)](https://github.com/PSionna/)\n\nLayer generating the prior model for the scene using Gaussian distributed ior.\n\nThe prior for the transmision tensors is generated following the approach proposed in [M. Saenz, Y. Lou, and M. S. Howland, \u201cDeep-learning-based Method to Solve the Multiple Scattering Problem in Retriever Configuration,\u201d OSA Continuum, vol. 12, no. 10, p. 3049, 2019.] for the model frequency-selective roughness (FSR). The channel model is generated independently for each link and link direction.\n\nThe scattering pattern of the scene objects is not taken into account when generating the channel model. Only diffuse scattering is supported. This means that only the scattered field of the second (last) step of the retracing path can be generated correctly. For Gaussian distributed scattering, the correct scattered field can be generated by keeping the retraced part of the field from the air-metal interface.\n\n**Parameters**\n\n- `load_scene` (bool): If True, a `Scene` is loaded from the PSAF library comprising a single ground reflector. Otherwise, an empty scene is instantiated. Defaults to True.\n- `scene` (Scene or None): If not None, this `Scene` is used to generate the channel model. Defaults to None.\n- `dtype` (tf.complex64, tf.complex128): Datatype used to compute the channels. Defaults to tf.complex64.\n\n**Input**\n\n- `batch_size` (int): Batch size for the resource allocation. Defaults to None.\n- `num_samples` (int): Number of samples for the channel model. Defaults to 1.\n- `frequency` (float): Carrier frequency [Hz]. Defaults to 3e8.\n- `sphere_radius` (float): Radius of the (unused) sphere with diffuse scattering [m]. Defaults to 1e-3.\n- `num_interacting_pairs` (int): Number of interacting object pairs. Defaults to 10.\n- `scattering_pattern` (ScatteringPattern): Scattering pattern to be used. Only required if the scene contains one or more `ScatteringSurface`s. Otherwise not used and can be set to None. Defaults to None.\n- `keep_direct_source` (bool): If True, the direct (specular) path is kept in the channel model. Otherwise not. Defaults to False.\n- `normalize` (bool): If True, the prior is normalized to unit power per degree of freedom. Defaults to True.\n- `centered` (bool): If True, the prior model is centered to mean value of the model itself. Defaults to True.\n- `seed` (int): Seed for the random generator ensuring random realizations of the prior model. Defaults to None.\n- `no_tx` (bool): If True, no new transmitter is randomly drawn, i.e., the previously drawn transmitter is used. Defaults to False.\n- `z_min` (float): Minimum z-coordinate for the center of the prior model [m]. Defaults to -0.8.\n- `z_max` (float): Maximum z-coordinate for the center of the prior model [m]. Defaults to 0.8.\n- `random_orientation` (bool): If True, random orientations are drawn. Defaults to False.\n- `show_paths` (bool): If True, the generated channel models for all transmitters are plotted. Defaults to False.\n\n**Output**\n\n- `positions` ([batch size, num_tx, 3], tf.float): Array of random transmitter positions.\n- `orientations` ([batch size, num_tx, 3], tf.float): Array of random transmitter orientations.\n- `look_dir` ([batch size, num_rx, 3], tf.float): Array of random receiver orientations.\n- `transmitter_ids` ([batch size, num_rx], tf.int): Array of random transmitter ids for all receiver-oriented links.\n- `receiver_ids` ([batch size, num_rx], tf.int): Array of random receiver ids for all transmitter-oriented links.\n- `paths` ([batch size, num_rx, num_rx + num_tx * num_interacting_pairs, num_samples], tf.complex): Array of channel frequency responses.\n- `ellipticities` ([batch size, num_rx, num_rx + num_tx * num_interacting_pairs], tf.float): Array of channel model ellipticities.\n- `k_ind` ([batch size, num_rx, num_rx + num_tx * num_interacting_pairs], tf.float): Array of channel model k-values."
"Here is the detailed information of [sionna.mapping.QAM2PAM](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#QAM2PAM):  \n  \nTransforms QAM symbol indices to PAM symbol indices.\n\nFor a PAM constellation, this layer converts a QAM index, indicating the position of a QAM symbol, to the two PAM symbol indices corresponding to its (real and imaginary) components.\n\n**Parameters**\n\n- `num_pam_symbols` (int): Number of PAM symbols. It must be a power of two.\n- `num_bits_per_symbol` (int): Number of bits per constellation symbol, e.g., 4 for QAM16.\n- `initial_value` (int or None): Initial value for the symbol indices, which are either 0 (for `type` int) or [0, num_pam_symbols] (for `type` tf.int). If `initial_value` is None, the symbol indices are randomly initialized through a uniform distribution on [0, num_pam_symbols). Defaults to None.\n- `dtype` (tf.DType): Data type of the output. Defaults to tf.int32.\n\n**Input**\n\n- `inputs` ([\u2026,n], tf.int32): QAM symbol indices.\n\n**Output**\n\n- `[\u2026,2,n], tf.int32`: Indices corresponding to the two PAM components of each QAM symbol.  \n  \nsource code:  \n```python\nclass QAM2PAM(layers.Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"QAM2PAM(num_pam_symbols, num_bits_per_symbol, initial_value=None, dtype=tf.int32)\n\n    Transforms QAM symbol indices to PAM symbol indices.\n\n    For a PAM constellation, this layer converts a QAM index,\n    indicating the position of a QAM symbol, to the two PAM symbol\n    indices corresponding to its (real and imaginary) components.\n\n    Parameters\n    ----------\n    num_pam_symbols : int\n        Number of PAM symbols. It must be a power of two.\n\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol, e.g., 4 for QAM16.\n\n    initial_value : int or None\n        Initial value for the symbol indices, either 0 or\n        :math:`[0, \\text{num_pam_symbols}]`. If `initial_value` is `None`,\n        the symbol indices are randomly initialized through a\n        uniform distribution on :math:`[0, \\text{num_pam_symbols}]`.\n        Defaults to `None`.\n\n    dtype : tf.DType\n        Data type of the output. Defaults to `tf.int32`.\n\n    Input\n    -----\n    inputs : [...,n], tf.int32\n        QAM symbol indices\n\n    Output\n    ------\n    : [...,2,n], tf.int32\n        Indices corresponding to the two PAM components of each QAM symbol.\n    \"\"\"\n    def __init__(self,\n                 num_pam_symbols,\n                 num_bits_per_symbol,\n                 initial_value=None,\n                 dtype=tf.int32):\n        super().__init__(dtype=dtype)\n        assert num_pam_symbols%2==0, \\\n            \"num_pam_symbols [={}] has to be a multiple of two\".format(\n                num_pam_symbols)\n        assert num_pam_symbols//2==2**(num_bits_per_symbol//2), \\\n            \"num_bits_per_symbol [={}] has to be a multiple of two that fits num_pam_symbols/2 QAM symbols\".format(\n                num_bits_per_symbol)\n        self._num_pam_symbols = num_pam_symbols\n        self._num_bits_per_symbol = num_bits_per_symbol\n        self._num_pam_symbols_per_symbol_bit = num_pam_symbols//2\n        self._initial_value = initial_value\n        self._dtype = dtype\n        self._symbol_inds = tf.range(self._num_pam_symbols, dtype=self.dtype)\n\n    def build(self, input_shape): #pylint: disable=unused-argument\n        if self._initial_value is not None:\n            assert self._initial_value.dtype.is_integer\n            assert self._initial_value.shape == [] # pylint: disable=simplifiable-if-expressions\n        symbols = tf.cast(self._symbol_inds, self.dtype)\n        if self._initial_value is None:\n            symbols = tf.random.shuffle(symbols)\n        else:\n            symbols_low = tf.bitwise_and(symbols,\n                                          (1<<self._num_bits_per_symbol)-1)\n            symbols_high = tf.bitwise_xor(\n                tf.bitwise_and(symbols,\n                               (1<<self._num_bits_per_symbol)-1),\n                self._initial_value)\n            symbols = tf.concat([symbols_low, symbols_high], axis=-1)\n        self._pam_symbol_ind = symbols\n\n    def call(self, inputs):\n        x = tf.gather(self._pam_symbol_ind, inputs, axis=-1)\n        x = tf.cast(x, self.dtype)\n        return x\n```  \n  "
"To load the required Sionna components, you need to follow these steps:\n\n1. Import the `PlanarArray` class from the `sionna.rt` module. This class is used to create planar antenna arrays. \n\nHere is the corresponding Python code snippet:\n\n```python\nfrom sionna.rt import PlanarArray\n```\n\n2. Create an instance of the `PlanarArray` class and specify the number of rows and columns for the antenna array. Also, specify the spacing between the antennas in the vertical and horizontal directions.\n\nHere is the corresponding Python code snippet:\n\n```python\narray = PlanarArray(num_rows=8,\n                    num_cols=2,\n                    vertical_spacing=0.7,\n                    horizontal_spacing=0.5,\n                    pattern=\"iso\",\n                    polarization=\"dual\",\n                    polarization_type=\"cross\",\n                    antenna=antenna)\n```\n\nIn this code, `antenna` is an instance of the `Antenna` class. You need to replace `antenna` with the actual instance of the antenna class you are using. The `num_rows` and `num_cols` parameters specify the number of rows and columns for the antenna array. The `vertical_spacing` and `horizontal_spacing` parameters specify the spacing between the antennas in the vertical and horizontal directions, respectively. The `pattern`, `polarization`, `polarization_type`, and `antenna` parameters are used to specify the antenna array geometry and characteristics.\n\n3. Finally, you need to set the carrier frequency for the scene in which the antenna array is used. This can be done using the `frequency` property of the `scene` instance.\n\nHere is the corresponding Python code snippet:\n\n```python\nscene.frequency = 2.14e9 # in Hz\n```\n\nPlease note that the actual code may vary depending on the specific requirements of your application."
"To import the necessary modules for Sionna's API and set up the GPU configuration, you can follow these steps:\n\n1. Import the `sionna.rt` module. This module is necessary for the radio propagation modeling. You can do this by using the following code:\n\n```python\nfrom sionna.rt import *\n```\n\n2. Set up the GPU configuration. This is necessary if you want to use a GPU for the computations. You can do this by using the `os` module to set the GPU number and to set `TF_CPP_MIN_LOG_LEVEL` to '3' to avoid warnings from TensorFlow. Here is how you can do it:\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n3. Import the TensorFlow module. This module is necessary for the GPU configuration and for the machine learning operations. You can do this by using the following code:\n\n```python\nimport tensorflow as tf\n```\n\n4. Set the GPU memory growth. This is necessary to avoid TensorFlow allocating all of the available GPU memory. You can do this by using the `tf.config.experimental.set_memory_growth` method from the TensorFlow module. Here is how you can do it:\n\n```python\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], 1024)\n    except RuntimeError as e:\n        print(e)\n```\n\n5. Set the TensorFlow logging level. This is necessary to avoid warnings from TensorFlow. You can do this by setting the `level` parameter of the `tf.get_logger` method to 'ERROR'. Here is how you can do it:\n\n```python\ntf.get_logger().setLevel('ERROR')\n```\n\nPlease note that the code snippets provided are based on the context of the Sionna's API and may need to be adjusted based on your specific use case."
"CoverageMap is a map that associates each point on a terrain with the strongest received power from a specific transmitter. In other words, for a given point on the terrain, CoverageMap can tell you the strongest signal power at that point, considering different transmitters and their respective antennas and antenna patterns.\n\nThe coverage map in Sionna Ray tracing is a unique feature that sets it apart from other radio propagation simulation frameworks. Essentially, it enables you to carry out site-specific analyses such as path-loss prediction, time-varying analyses, and handover analyses.\n\nFor instance, given a model scene where several transmitters are deployed, you can create a coverage map for each transmitter. Subsequently, for any location on the terrain, a coverage map can be queried to obtain the channel impulse response, i.e., the path that the signal takes from the transmitter to that location.\n\nIn terms of visualization, coverage maps can be plotted along with the scene geometry, giving an insightful view of the signal-strength distribution across the environment.\n\nIt's important to note that coverage maps are impacted by the terrain, building, and scattering environment, as well as the specific antenna patterns used by the transmitters and receivers. For this reason, Sionna allows the creation of very detailed and realistic scenes, which can be thoroughly analyzed."
"To decode a set of log-likelihood ratio (LLR) values using the TurboDecoder in Sionna, the necessary input requirements are:\n\n1. `gen_poly` (*tuple*) including `trellis_type`, `rsc_encoder`, and `constraint_length`:\n   - `trellis_type`: Specifies the type of the generator matrix for convolutional codes. Options are 'rsc' and 'mother'. If 'mother' is selected, the rsc_encoder parameter is required.\n   - `rsc_encoder`: A binary generator matrix for the recursive systematic convolutional encoder. If `trellis_type` is 'mother', this matrix is required. The shape of the matrix is expected to be (k, n) or (n-k, n), depending on the `trellis_type`.\n   - `constraint_length`: The constraint length of the encoder, which is equal to the number of shift register stages used to compute the next bit based on previous bits.\n\n2. `method` (*str*) indicating the type of decoding approach:\n   - If `method` is 'map', it performs Maximum A Posteriori decoding using the BCJR algorithm. It requires the `output_dtype` to be logits or LLRs.\n   - If `method` is 'maxlog', it implements the Max-Log-MAP algorithm, which is an approximation of the BCJR algorithm. It is suitable for scenarios where computational efficiency is prioritized over exact optimality. It assumes that all bits in the convolutional output are equiprobable.\n   - `method` must be 'maxlog' for TurboCodes with non-systematic encoders.\n\n3. `output_dtype` (*str*) indicating the data type of the output:\n   - If 'logits', it returns LLRs which can be interpreted as log-probability ratios.\n   - If 'hard', it returns hard-decided bits (i.e., a zero-one sequence).\n   - If 'soft', it returns soft-values for each position, representing reliability measures on the symbols.\n\nNote that the input LLR tensor must have the shape (*, n), where `n` is the total number of code bits, and the output tensor shape will depend on the `output_dtype` selected.\n\nAs for the output format, it will depend on the `output_dtype`:\n- If it's 'hard', the output tensor will contain binary values (0s and 1s) where each position corresponds to a hard decision outcome.\n- If it's 'soft', the output tensor will contain floating-point values that represent the reliability of each symbol estimation.\n\nPlease ensure that the actual code implementation and usage complies with the Sionna API and usage guidelines."
"Here is the detailed information of sionna.rt.antenna.iso_pattern:  [sionna.rt.antenna.iso_pattern(theta, phi, slant_angle=0, polarization_model=2, dtype=tf.complex64)](https://n.apache.org/api/nvlabs/sionna/rt.antenna.html#sionna.rt.antenna.iso_pattern)\n\nIsotropic pattern with optional polarization.\n\nFor each angle (theta, phi), the function outputs (in dB) the power gain in the direction of the corresponding incident direction $(\\theta, \\varphi)$, i.e., $G(\\theta, \\varphi)=\\left|\\frac{\\mathbf{a}(\\theta, \\varphi)^{\\mathsf{H}}\\mathbf{a}(\\theta, \\varphi)}{\\lVert\\mathbf{a}(\\theta, \\varphi)\\rVert^2}\\right|$.\n\n**Input**\n\n- `theta` (e.g., `tf.float`): Zenith angles wrapped within [0,\u03c0] [rad].\n- `phi` (e.g., `tf.float`): Azimuth angles wrapped within [-\u03c0, \u03c0) [rad].\n- `slant_angle` (e.g., `tf.float`): Slant angle [rad]. The slant angle is the angle of the linear polarization vector measured from the x-axis, and it is zero if the polarization is vertical. It is positive if the polarization vector points toward the positive z-axis, and negative toward the negative z-axis. Defaults to 0.\n- `polarization_model` (e.g., one of `[\"1\", \"2\"]`, `str`): Polarization model to be used. Options 1 and 2 refer to polarization_model_1() and polarization_model_2(), respectively. Defaults to 2.\n- `dtype` (One of [`tf.complex64`, `tf.complex128`]): Datatype used for all computations. Defaults to `tf.complex64`.\n\n**Output**\n\n- `G` (e.g., `tf.float`): Power gain (in linear scale) for the given angles.\n\nsource code:\n```python\ndef iso_pattern(theta, phi, slant_angle=0, polarization_model=2,\n                dtype=tf.complex64):\n    # Wrap angles\n    theta = tf.math.floormod(theta, tf.cast(PI, theta.dtype))\n    phi = tf.math.floormod(phi, tf.cast(PI, phi.dtype))\n\n    if not dtype.is_complex:\n        dtype = dtype.as_base_dtype()\n\n    # Slant angles\n    if slant_angle != 0:\n        theta_s, phi_s = slant_angleobrechtator(theta, phi, slant_angle)\n    else:\n        theta_s, phi_s = theta, phi\n\n    # Zero-axis slant angle\n    theta_0 = tf.cast(PI/2, dtype)\n    phi_0 = tf.cast(0.0, dtype)\n\n    # Vertical and horizontal polarization\n    if polarization_model == 1:\n        a = tf.cast(1.0, dtype) / tf.complex_sqrt(\n            1.0 + 1e-12) / tf.cast(PI, dtype)\n    elif polarization_model == 2:\n        a = tf.complex(\n            tf.math.cos(theta_s),\n            tf.math.cos(phi_s)/tf.complex_sqrt(1.0-tf.math.cos(theta_s)**2)\n            ) / tf.complex(tf.math.sin(theta_s), tf.cast(0.0, dtype)) / tf.cast(\n                PI, dtype)\n\n    # Compute the slant angle of the field polarization  vector\n    theta_diff = theta - theta_0\n    phi_diff = phi - phi_0\n    thetahat = tf.complex(\n        tf.math.cos(phi_diff)*tf.math.sin(theta_diff),\n        tf.math.sin(phi_diff)*tf.math.sin(theta_diff)\n        )\n    slant_angle_p = angle(theheta)\n\n    # Pattern\n    if polarization_model == 1:\n        g = tf.cast(1.0, dtype) + tf.abs(a)**2 * tf.math.pow(\n            tf.math.cos(theta_diff), 2)\n    elif polarization_model == 2:\n        g = tf.cast(1.0, dtype) + tf.abs(a)**2 * tf.math.pow(\n            tf.math.cos(slant_angle_p), 2)\n    g = tf.where(g < 1e-12, tf.cast(1e-12, g.dtype), g)\n    g = 10 * tf.math.log10(g)\n    return g\n```"
"Since there is no reference to a specific implementation of the Keras layers \"ApplyTimeChannel\" and \"ApplyOFDMChannel\" in the provided context, I can not demonstrate their correct usage as requested.\n\nI advise the user to refer to the \"Sionna API Documentation\" or the official repository or source of the Keras layers for relevant and correct information about these functions as they implement different channel models and operations (time domain and OFDM domain respectively) on the channel.\n\nOn the other hand, the provided context presents how to use the `GenerateTimeChannel` and `GenerateOFDMChannel` to generate channel responses, and one should use the `ApplyTimeChannel` and `ApplyOFDMChannel` to apply the channel responses to the channel input data, but these are not Keras layers, so they might have different implementations or usage compared to Keras layers.\n\nFor example, following the instructions from the context would look like this:\n\n```python\n# Generate channel responses\nchannel_model = 'umd'\nchannel = GenerateTimeChannel(channel_model, num_tx, num_rx, delay_spread, carrier_frequency, ut_antenna, bs_array, channel_corr_mat, dtype)\na, tau = channel()\n# Apply channel responses\nchannel_sampler = TimeChannelSampler(a, tau, interpolate, input_shape)\ntime_channel = ApplyTimeChannel()\nh_time = time_channel([x, a, tau])\n```\n\nIn this example, first the channel responses are generated using the `GenerateTimeChannel`, then the `ApplyTimeChannel` is used to apply the channel responses to the channel input data `x`. The same process would be used with the OFDM domain, but using the `GenerateOFDMChannel` and `ApplyOFDMChannel` layers respectively."
"To compute the log-likelihood ratios (LLRs) with the Demapper class in the Sionna package, you need to follow these steps:\n\n1. Instantiate a Demapper object from the `sionna.mapping.Demapper` class. The Demapper class requires a 'constellation' type parameter. This is an instance of the `sionna.mapping.Constellation` class. The constellation type, in this case, is 'qam'. You also need to specify the number of bits per symbol. \n\n```python\ndemapper = Demapper(constellation_type=\"qam\", num_bits_per_symbol=4)\n```\n\n2. Call the `forward` method of the `Demapper` instance, with the `soft_symbols` and `hard_decisions` parameters. The `soft_symbols` parameter is a tensor of soft-symbols, and the `hard_decisions` parameter is a tensor of hard-decisions. The `hard_decisions` parameter is optional and is used to provide hard-decided symbols or, in this case, would be used to provide the indices into the constellation.\n\n```python\nllr = demapper.forward(soft_symbols=soft_symbols, hard_decisions=hard_decisions)\n```\n\n3. The `forward` method returns the LLRs which are, in this case, shaped as `[batch_size, num_bits_per_symbol]`. The LLRs correspond to the bits mapped to a constellation point. The sign of the LLR indicates the direction of the bit (positive for a '1', negative for a '0'), and the magnitude of the LLR indicates the confidence level.\n\n4. Finally, you can use the LLRs for further processing, for example, in a channel decoder to recover the original data.\n\nPlease note that in the above steps, the variables `soft_symbols` and `hard_decisions` should be tensor objects with appropriate shapes as needed. Depending on the context in which the Demapper is used, you may need to adjust the parameters and the error handling for the LLRs computation."
"To obtain the Channel Impulse Responses (CIRs) in the Sionna model, you need to initialize a channel model and then use this model to generate CIRs. Here are the steps:\n\n1. Initialize the channel model: You can use the `Umi28` model for this purpose. In the Umi28 model, the parameters are configured based on specifications for the 3rd Generation Partnership Project (3GPP) communication systems in the 28 GHz frequency band. Here is an example of how to initialize the Umi28 model:\n\n```python\nfrom sionna.channel.tr38901 import Umi28\n\numi28 = Umi28(\n    \"umi\", \"lo\", \"mv\", 5GSystem.bandwidth, indoor=True, min_bs_ut_dist=0., max_bs_ut_dist=35.)\n```\n\n2. Generate CIRs: After initializing the channel model, you can generate the CIRs using the `cir` method of the channel model. The `cir` method takes an abstract base station (BS) to user terminal (UT) distance (`bs_ut_dist`) as well as the number of CIRs to generate as parameters. Here's an example:\n\n```python\nbs = tf.complex(\n    tf.constant(0, tf.float32), tf.constant(0, tf.float32))\ndist = tf.linspace(5., 25., 10)\na, tau = channel_model.dist_to_cir_dif"
"Here is the detailed information of List2LLRSimple:   \n  \n[sic.list.List2LLRSimple](https://nvlabs.github.io/sion/_modules/sic/list.html#List2LLRSimple)  \n\nAbstract class defining a callable to compute LLRs from a list of candidate vectors (or paths) provided by a list decoder (or SIC).\n\nThe following class is defined by alias: `List2LLRSimple`.\n\nComputes LLRs using what is assumed to be the (unperturbed) channel likelihoods (or SNRs).\n\nThis class is used to define a layer implementing the channel model by computing the log-likelihood ratios (LLRs) from received flat single-input multiple-output (SIMO) codeword.\n\nThe channel output is first whitened (optional) and then passed to the list decoder (or SIC). The list decoder returns K candidate solutions and their distance metrics. This class is meant to be used as a base class for simple implementations.  \n  \nInput\n    (y, h, llh_cha, err_var, no_ext) \u2013 Tuple:\n\n- **y** ([, M], tf.float32): 1+D tensor containing the (noisy) channel outputs.\n\n- **h** ([, M, K], tf.float32): 2+D tensor containing the channel transition matrices.\n\n- **llh_cha** ([, M, M], tf.float32): 2+D tensor containing the channel likelihoods (or SNRs).\n\n- **err_var** (tf.float32): A scalar or a tensor of any shape whose dimensions can be broadcast to the dimensions of `y`.\n\n- **no_ext** (tf.float32): A scalar or a tensor of any shape whose dimensions can be broadcast to the dimensions of `h`.\n\nOutput\n    **llr_ch** ([, K, n], tf.float32): Tensor of shape [, K, n] containing LLRs for all possible values of the transmitted bits. The LLRs are distributed over the last dimension, which is equal to the length of the codeword. The LLRs for a specific bit is equal to $LLR(b=0) = \\ln\\left(\\frac{\\Pr\\left(b=0\\lvert\\mathbf{y},\\mathbf{H}\\right)}{\\Pr\\left(b=1\\lvert\\mathbf{y},\\mathbf{H}\\right)}\\right) =\\ln\\left(\\frac{\\Pr\\left(\\mathbf{x}=\\mathbf{c}(b=0)\\lvert\\mathbf{y},\\mathbf{H}\\right)}{\\Pr\\left(\\mathbf{x}=\\mathbf{c}(b=1)\\lvert\\mathbf{y},\\mathbf{H}\\right)}\\right)$\n   where $\\mathbf{c}(b=0)$ and $\\mathbf{c}(b=1)$ are the sets of codewords consistent with $\\mathbf{b}$ being (d+1)th bit being 0 and 1, respectively. $\\mathbf{H}$ denotes the channel transition matrix, and $\\mathbf{x}$ is the original bit sequence.\n  \n**Note: **  \nThis class is intended to be used as a base class for simple implementation of list decoders. However, extensive error concealment, e as well as efficient GPU implementation may require a more thorough definition."
"Here is the definition of MaximumLikelihoodDetector: sion.mimo.MaximumLikelihoodDetector(output, num_bits_per_symbol, hard_out=False, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sion/_modules/sion/mimo/detection.html#MaximumLikelihoodDetector)  \n\nsource code:\n```python\nclass MaximumLikelihoodDetector:\n    # pylint: disable=line-too-long\n    r\"\"\"MaximumLikelihoodDetector(output, num_bits_per_symbol, hard_out=False, dtype=tf.complex64)\n\n    MIMO Maximum-likelihood (ML) detector.\n\n    This layer implements maximum-likelihood (ML) MIMO detection for a given output, assuming\n    an AWGN channel model. Both ML detection of symbols or bits with either\n    soft- or hard-deision are supported.\n\n    Note\n    -----\n    For ML detection, the algorithm solves for either the symbols or bits.\n    It does so by exhaustive search over all possible transmitted symbol\n    or bit vectors. Although perfect, ML detection is not practical for\n    (very) large MIMO systems as the required complexity `O(2^{k})` for\n    each bit is exponentially with the number of antennas k and the\n    complexity `O(k)` for each additional user.\n\n    Parameters\n    ----------\n    output : One of [\"bit\", \"symbol\"], str\n        The type of output, either bits or symbols. Whether soft- or\n        hard-decisions are returned depends on the ``hard_out`` flag.\n\n    num_bits_per_symbol : int\n        The number of bits per QAM constellation symbol, e.g., 4 for QAM16.\n\n    hard_out : bool\n        If `True`, the detector computes hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of `y`. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    ------\n    (y, h, s) :\n        Tuple:\n\n    y : [...,M], tf.complex\n        1+D tensor containing the received signals\n\n    h : [...,M,num_streams], tf.complex\n        2+D tensor containing the channel matrices\n\n    s : [...,M,M], tf.complex\n        2+D tensor containing the noise covariance matrices\n\n    Output\n    ------\n    One of:\n\n    : [..., num_streams, num_bits_per_symbol], tf.float\n        2+D tensor of LLRs for all bits of all streams, if ``output`` equals `\"bit\"`.\n\n    : [..., num_streams, NUM_POINTS], tf.float or [..., num_streams], tf.int\n       2+D tensor of logits for constellation points for all streams, if ``output`` equals `\"symbol\"`.\n       Logits or hard-decisions for constellation point indices, correspondingly.\n\n    Note\n    ----\n    If you want to use this layer in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sion.Config.xla_compat=true``.\n    See :py:attr:`~sion.Config.xla_compat`.\n    \"\"\"\n    def __init__(self,\n                 output,\n                 num_bits_per_symbol,\n                 hard_out=False,\n                 dtype=tf.complex64):\n        super().__init__()\n        self._output = output\n        self._hard_out = hard_out\n        self._dtype = dtype\n        assert dtype in [tf.complex64, tf.complex128] \\\n            ,\"dtype must be tf.complex64 or tf.complex128\"\n        self._rdtype = dtype.real_dtype\n        self._num_streams = None # Number of RX TX streams. Set during first call.\n        self._num_bits_per_symbol = num_bits_per_symbol\n        self._symbol_bits = None # Number of bits per symbol. Derived from num_bits_per_symbol.\n        self._llr_max = 100. # Maximum / minimum LLR value to avoid numerical instabilities\n        self._check_inputs = True # If True, check inputs for consistency. Set to False if\n                                 # `unpad_probablilities` is used to prevent unnecessary testing.\n        # The transformer is used to generate all possible symbol vectors for\n        # a given set of streams.\n        self._symbol_vectorizer = SymbolVectorizer(self._num_bits_per_symbol,\n                                                    complex2qam=False)\n        # The demapper is used to compute LLRs from (soft) estimates of\n        # symbols.\n        self._demapper = Demapper(\"maxlog\",\n                                  self._symbol_bits,\n                                  hard_out=False,\n                                  dtype=dtype)\n\n    @property\n    def show_intermediate_results(self):\n        \"\"\"Show intermediate results of the vectorized operation.\n\n        Set to `True` to debug or visualize the operation of the vectorized\n        detector. Calculated LLRs, but also the constellation symbol logits\n        and the bit estimates are shown.\n        \"\"\"\n        return False\n\n    @show_intermediate_results.setter\n    def show_intermediate_results(self, value):\n        if not isinstance(value, bool):\n            raise TypeError(\"show_intermediate_results must be bool.\")\n        self._show_intermediate_results = value\n\n    def _check_input_dim(self, input):\n        \"\"\"Checks if inputs have the correct dimensions.\"\"\"\n        y, h, s = input\n        # y : [...,M], tf.complex\n        # h : [...,M,num_streams], tf.complex\n        # s : [...,M,M], tf.complex\n        if self._check_inputs:\n            assert y.shape[-1]==h.shape[-2]==s.shape[-2], \\\n                \"Illegal matrix dimensions.\"\n            self._check_inputs = False\n\n    def _preprocess(self, input):\n        y, h, s = input\n\n        ############################################################\n        # Pre-process inputs and create internal data.\n        # - y,h,s : [...,M], [...,M,num_streams], [...,M,M], tf.complex\n        # - Transformer creates all possible symbol vectors for all streams.\n        #############################################################\n        rdtype = self._rdtype\n        y = tf.cast(y, rdtype)\n        h = tf.cast(h, rdtype)\n\n        # Pad channel with zeros to make it square.\n        # This is important for the construction of Gammma later on.\n        pad = tf.cast(tf.pad(tf.zeros_like(s), [[0,1],[0,1],[0,0]]), rdtype)\n        s = tf.concat([s,pad],axis=-1)\n        pad = tf.cast(tf.pad(tf.zeros_like(h), [[0,1],[0,1],[0,0]]), rdtype)\n        h = tf.concat([h,pad], axis=-1)\n\n        # Gammma matrix\n        gammma = tf.cast(self._gammma, rdtype)\n        gammma = tf.expand_dims(gammma, axis=0)\n        gammma = tf.expand_dims(ggammma, axis=0)\n\n        # Gammma matrix in GF[2] representation\n        # Dimensions: batch_dims 1+2+...n, num_rx, num_rx, num_streams_per_rx, 2**num_streams_per_rx\n        gammma_gf = self._make_gammma_gf(gammma)\n\n        # Create index tensor for constellation expansion\n        # Dimensions: num_streams_per_rx, 2**num_streams_per_rx\n        indx_c = self._symbol_vectorizer.constellation.indx_c\n        gammma_cgf = tf.gather(gammma_gf, indx_c, axis=-1, batch_dims=0)\n\n        # Cast output of symbol interleaver to the same dtype as H and Y.\n        # We cannot do this in graph mode with XLA, as XLA does not (yet) support\n        # casting between float16 and float32.\n        symbol_dtype = self._symbol_vectorizer.dtype\n        if symbol_dtype != rdtype:\n            y = tf.cast(y, symbol_dtype)\n            h = tf.cast(h, symbol_dtype)\n\n        # Extract exponents of Hamming weight table for efficient look-up.\n        # Note, that the implementation is not differentiable. This is ususally\n        # not a problem as HW is primarily used for log-domain operations.\n        hw = self._symbol_vectorizer.hw\n        hw = tf.cast(hw, symbol_dtype)\n        hw = tf.expand_dims(hw, 0) # Expand dims to rank 2 for broadcating\n        gammma_hw = tf.gather(gammma_cgf, hw, axis=-1, batch_dims=0)\n        gammma_hw = tf.squeeze(gammma_hw, -1)\n\n        # Reshape al inputs to the desired shape.\n        # This is done to enable vectorization.\n        y = self._reshape_vector(y, 1)\n        h = self._reshape_vector(h, 1)\n\n        # Pad the symbol vector with zeros to create a (2**num_bits_per_symbol)-shaped\n        # vector. This is important for the construction of Gammma later on.\n        pad = tf.cast(tf.pad(tf.zeros_like(symbol_dtype), [[0,1],[0,1],[0,0]]), rdtype)\n        symbol_vector = self._symbol_vectorizer(symbol_dtype=symbol_dtype)\n        symbol_vector = tf.concat([symbol_vector, pad], axis=-1)\n        symbol_vector = tf.expand_dims(symbol_vector, 0)\n\n        # Build the indexes for the symbol vector directly from the bits.\n        # The least significant bit (LSB) of a index vector of lenght B\n        # is located at the right ([-1]).\n        indx_bits = self._symbol_vectorizer.symbol_bits\n        y_b = self._symbol_interleaver(indx_bits)\n        # Concatenate zeros at the end to reach the next highest 2-power.\n        y_b = tf.concat([y_b, tf.zeros([1,1,1,1])], -1)\n        # Reverse the index vector to from [..., 2, 1, 0] to the required\n        # format [..., 0, 1, 2].\n        perm = tf.range(tf.reduce_prod(tf.shape(y_b)))[::-1]\n        y_b = tf.gather(y_b, perm, axis=-1)\n\n        # Gather the symbols values for the effective bit labels.\n        y_m = tf.gather(symbol_vector, y_b, axis=-1)\n\n        # Generate the onne vector of the same length as the symbol vector.\n        # This vector is required to for the next operations.\n        one = tf.ones_like(symbol_vector)*2 # e.g., [2 2 2 2] for 4 symbols\n        # Expand the  onne vector [..., 1, 1, 1] to the shape of the symbol vector.\n        one = tf.expand_dims(one, 0) # e.g., [[... 1 1 1] for 4 symbols]\n        one = tf.expand_dims(one, -1) # e.g., [[... 1 1 1] for 4 symbols]\n        # Shift all values of the symbol vector by a certain amount.\n        # This is equal to a multiplication with a corresponding index vector\n        # in log-domain.\n        y_m_shifted = tf.concat([y_m, one], axis=-1)\n        # Reshape the resulting vector back to the shape of the symbol vector.\n        y = tf.reshape(y_m_shifted, tf.shape(y))\n\n        # y is now of shape 2**num_bits_per_symbol for the symbol dimensions.\n        # h is of shape 2**num_bits_per_symbol for the symbol dimension.\n        # Gammma is of shape [2**num_bits_per_symbol, num_streams].\n        # Perform the MatMul operation. All dimensions except the last one\n        # must be expanded.\n        # The result is of shape [batch_dims, 2**num_bits_per_symbol, num_streams]\n        gammma = tf.expand_dims(gammma_hw, -1)\n        gammma = tf.transpose(gammma, perm=[2, 0, 1])\n        gammma = tf.reshape(gammma, [-1, tf.shape(gammma)[-1]])\n        gammma = tf.expand_dims(gammma, 1)\n        y, h, gammma = self._pad_dims([y, h, gammma], 2)\n\n        # Gather all symbol values\n        symbol_ind = tf.reshape(symbol_vector, [-1])\n        symbol_values = tf.gather(symbol_vector, symbol_ind, axis=-1)\n        symbol_values = tf.reshape(symbol_values, tf.shape(y)[1:])\n\n        return y, h, gammma, symbol_values\n\n    def _make_gammma_gf(self, gammma):\n        \"\"\"Transforms a gammma matrix in any dtype to GF representation.\n\n        The representation is required for the vectorized operation. GF denotes\n        the Galois Field with characteristic 2.\n        The input gammma matrix must be sqaure and the last dimension must be\n        a multiple of 2.\n\n        The output gammma_gf has the same shape as gammma, but the dtype of\n        the real and imaginary part is tf.float32. This is important for the\n        further processing.\n        \"\"\"\n        shape = tf.shape(gammma)\n        new_shape = tf.concat([shape[:-2], [2], shape[-1]//2], axis=-1)\n        gammma = tf.cast(gammma, tf.float32)\n        gammma = tf.reshape(gammma, new_shape)\n\n        # Create exponent matrix\n        exp = tf.Variable(0, dtype=tf.int32,  shape=new_shape[:-1]+[1],\n            distribute_strategy=ds.get_strategy())\n        exp = 2**exp\n        exp = tf.tile(exp, [1, 1, shape[-1]//2])\n        exp = tf.cast(exp, tf.float32)\n\n        # Compute GF representation\n        gammma_gf = tf.math.reduce_prod(tf.stack([gammma, exp], axis=-1), axis=-1)\n\n        return gammma_gf\n\n    def _reshape_vector(self, x, num_spectral_dims):\n        \"\"\"Reshapes the vector x along the last `num_spectral_dims` dimensions.\n\n        This is done to enable vectorization.\n        \"\"\"\n        input_shape = tf.shape(x)\n        new_shape = tf.concat([input_shape[:-num_spectral_dims],\n                               input_shape[-num_spectral_dims]], axis=-1)\n        x = tf.reshape(x, new_shape)\n        return x\n\n    def _unshape_vector(self, x, num_spectral_dims):\n        \"\"\"Flattens the first `num_spectral_dims` dimensions of `x`.\n\n        This is the inverse operation of `_reshape_vector`.\n        \"\"\"\n        input_shape = tf.shape(x)\n        new_shape = tf.concat([input_shape[:num_spectral_dims],\n                               tf.shape(x)[-num_spectral_dims:]], axis=-1)\n        x = tf.reshape(x, new_shape)\n        return x\n\n    def _pad_dims(self, tensors, axis):\n        \"\"\"Pads the dimensions of all tensors along `axis`.\n\n        Pads with zeros.\n\n        Args:\n            ``tensors``: A list of tensors.\n            ``axis``: The dimension index to which to add new axes.\n\n        Returns:\n            List of tensors of the same length as the input ``tensors`` where\n            all tensors are padded with extra zeros at the end.\n        \"\"\"\n        for i in range(len(tensors)):\n            shape = tf.shape(tensors[i])\n            padded_shape = tf.concat([shape[:axis],\n                                      tf.cast(0, tf.int32),\n                                      shape[axis:]], axis=0)\n            padded = tf.pad(tensors[i], padded_shape, constant_values=0)\n            tensors[i] = padded\n        return tensors\n\n    def _mask_llrs(self, llrs, mask):\n        \"\"\"Set the LLRs to 0 for positions indicated by the mask.\n\n        Args:\n            llrs (tf.float32): Tensor of LLRs to be masked.\n            mask (tf.bool): Mask of same length as ``llrs``. The mask\n                is True for all positions that should be set to 0.\n\n        Returns:\n            `tf.float32`: The masked LLRs.\n        \"\"\"\n        # Set mask to -inf for easy maximum extraction\n        mask = tf.cast(mask, llrs.dtype)\n        llrs = tf.where(mask, llrs, tf.float32.min)\n\n        return llrs\n\n    def _extract_bits_channel(self, y, h, s, gamma, symbol_values, mask, signed):\n        \"\"\"\n        \"\"\"\n        # Enable XLA for conditional, as it is faster.\n        # See https://www.tensorflow.org/xla/conditions for further details.\n        if sion.Config.xla_compat and not tf.executing_eagerly():\n            # We do this rather crude cast from tf.complex to tf.float\n            # to conserve memory. One could also only cast the relevant\n            # sub-tensors to tf.float.\n            y = tf.abs(tf.stack([tf.math.real(y),\n                                 tf.math.imag(y)], axis=-1))\n            h = tf.abs(tf.stack([tf.math.real(h),\n                                 tf.math.imag(h)], axis=-2))\n\n            gamma = tf.minimum(tf.reduce_min(tf.stack([y, h]), axis=-1), gamma)\n            gamma = tf.cast(gamma, symbol_values.dtype)\n            symbol_values = tf.cast(symbol_values, tf.float32)\n\n            # Mask INF values introduced by previous processing\n            symbol_values = self._mask_llrs(symbol_values, symbol_values==np.Inf)\n\n            # Bin symbols values and compute index\n            symbol_values = self._bin_2_int(symbol_values)\n            # Shift complex-valued indices to the last dimension\n            # to be consistent with the host dimension.\n            symbol_values = tf.transpose(symbol_values, [0, 2, 1])\n        else:\n            symbol_values = self._symbol_vectorizer(symbol_values)\n\n        # Determine the number of erroneous positions\n        # As symbol_values is now (maybe) unsigned, we need to cast to\n        # tf.int32 to enable comparison with loadable Inf.\n        n_err = tf.cast(tf.reduce_sum(symbol_values, -1), tf.int32)\n        # Set n_err to Inf at positions that should be masked\n        n_err = tf.where(mask, tf.int32.max, n_err)\n        # Mask all positions with n_err\n        mask = tf.cast(mask, gamma.dtype)\n        gamma = tf.where(n_err==np.Inf, n_err, gamma)\n        n_err = self._mask_llrs(n_err, mask)\n        # Put n_err to (num_rx, num_streams) shape and cast to tf.float\n        n_err = tf.cast(self._unshape_vector(n_err, 2), tf.float32)\n\n        # Set INF values to -1 (or +1 if requested)\n        # We first need to recompute the mask for the new gamma, as not\n        # all positions from gamma may be masked.\n        inf_test = tf.math.maximum(gamma, 0.) == np.Inf\n        mask = tf.cast(mask, gamma.dtype)\n        inf_test = self._mask_llrs(inf_test, mask)\n        if signed:\n            symbol_values = tf.where(inf_test, -1, 1)\n       "
"Here is the detailed information:   \n  \n[sionna.channel.generate_5g_ranking(num_tx=4, num_streams_per_tx=2, rank=2, num_rx=1, precoding=False, pilot=False, return_generator=False)](https://nvlabs.github.io/sionna/_modules/sionna/channel/utils.html#generate_5g_ranking)  \n\nGenerates valid 5G rankings for a [MIMO System] based on [3GPP].\n\n**Input**\n\n- `num_tx` (int): Number of transmitters.\n- `num_streams_per_tx` (int): Number of streams per transmitter.\n- `rank` (int): Desired rank.\n- `num_rx` (int): Number of receivers.\n- `precoding` (bool): If True, generate a precoding matrix instead of a receiver filter.\n- `pilot` (bool): If True, a separate ranking will be computed for each transmitter, and a corresponding pre-coding matrix or transmitter filter will be returned. Note that in practice, only a single rank is computed for all transmitters (or receivers), and this assumption does not make a significant difference in terms of simulation results.\n- `return_generator` (bool): If True, also returns the corresponding generator matrix.\n\n**Output**\n\n- `a` ([num_rx, num_tx, rank], tf.int): 5G MIMO azimuthal (\"horizontal\") channel matrix.\n- `d` ([num_rx, num_tx, rank], tf.int): 5G MIMO zenithal (\"vertical\") channel matrix.\n- `a_gen` ([num_tx, num_streams_per_tx, rank], tf.int): 5G MIMO azimuthal (\"horizontal\") channel generator matrix. This matrix is only returned if `return_generator` is True.\n- `d_gen` ([num_tx, num_streams_per_tx, rank], tf.int): 5G MIMO zenithal (\"vertical\") channel generator matrix. This matrix is only returned if `return_generator` is True.\n\n**Notes**\n\nThe returned matrices are typically used as follows:\n\n```python\nh_a = tf.squeeze(tf.matmul(a, a_gen), axis=-1)\nh_d = tf.squeeze(tf.matmul(d, d_gen), axis=-1)\n```\n\nwhere `a` and `d` are the zenithal and azimuthal matrices respectively.\n\n[3GPP] 3GPP TR 38.901, \u201cStudy on channel model for frequencies from 0.5 to 100 GHz,\u201d Release 16.1.0."
"To run the channel modeling in Sionna, follow these steps:\n\n1. Import the necessary modules and set up the environment. This includes importing Sionna and other necessary modules such as TensorFlow and NumPy. Also, set up the GPU configuration and seed for reproducibility.\n\n2. Load the required Sionna resources. This includes the SSFM, EDFA, TimeFrequencyGrid, CIR, GenerateTimeChannel, and corresponding utility functions. \n\n3. Configure the GPU and import Sionna. If Sionna is not already installed, use pip to install it.\n\n4. Set up the system parameters, including the SSFM parameters, EDFA parameters, and system time parameters.\n\n5. Generate the fiber (G/PG) parameters and instantiate the models (SSFM and EDFA).\n\n6. Define the channel model parameters, such as the number of receivers, transmit antennas, streams per transmitter, and the number of channel taps.\n\n7. Generate a batch of random impulse responses using the defined SSFM model.\n\n8. Evaluate the reachable post- and pre-FFT per-channel vector received spectra.\n\n9. Compute the empirical and analytical error variance of the frequency response.\n\n10. Plot the results.\n\nRemember to ensure that the code is written accurately and the necessary packages are installed."
"Here is the detailed information of load_alist: [sionna.fec.utils.load_alist(fp)](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#load_alist)  \n  \nLoad an alist (i.e., parity-check matrix) stored in a file.\n\nPlease note that the alist format is not formally verified. Thus, it may not be fully supported.\n\nA list file ending with .alist can be loaded. Internally, the loaded parity-check matrix is \ntransformed to systematic form.\n\n#### Input\n- **fp** ([str]) \u2013 Path of the file to be loaded.\n\n#### Output\n- **alist** ([np.int]) \u2013 N x M ndarray containing the parity-check matrix loaded from the file. Please note that the loaded parity-check matrix is in systematic form.\n- **vn_pos** ([list of ints]) \u2013 List of variable node (VN) indices, which implies that the corresponding columns of the parity-check matrix.\n\n- **cn_pos** ([list of ints]) \u2013 List of check node (CN) indices, which implies that the corresponding rows of the parity-check matrix.\n\n- **num_cn** ([int]) \u2013 Number of check nodes.\n\n- **num_vn** ([int]) \u2013 Number of variable nodes.\n\n**Note: **.vfs and .cns denote the file format; however, the function only supports .alist.\n\nsource code:  \n```python\ndef load_alist(fp):\n    # pylint: disable=line-too-long\n    r\"\"\"Load an `alist` (i.e., parity-check matrix) stored in a file.\n\n    Please note that the `alist` format is not formally verified. Thus, it\n    may not be fully supported.\n\n    A list file ending with `.alist` can be loaded. Internally, the loaded\n    parity-check matrix is\n    transformed to systematic form.\n\n    Input\n    -----\n    fp : str\n        Path of the file to be loaded.\n\n    Output\n    ------\n    alist : :class:`numpy.int`\n        `N` x `M` ndarray containing the parity-check matrix loaded from\n        the file. Please note that the loaded parity-check matrix is in\n        systematic form.\n\n    vn_pos : list of ints\n        List of variable node (VN) indices, which implies that the\n        corresponding columns of the parity-check matrix.\n\n    cn_pos : list of ints\n        List of check node (CN) indices, which implies that the corresponding\n        rows of the parity-check matrix.\n\n    num_cn : int\n        Number of check nodes.\n\n    num_vn : int\n        Number of variable nodes.\n\n    Note\n    ----\n\n    `.vfs` and `.cns` denote the file format; however, the function only\n    supports `.alist`.\n    \"\"\"\n\n    # is it a file\n    if not os.path.isfile(fp):\n        raise ValueError(\"Invalid filename.\")\n\n    # try to open alist file\n    try:\n        with open(fp, 'r') as f:\n            # read file\n            data = f.readlines()\n            # and parse it\n            num_vn = int(data[0].split(\" \")[0]) # num of cns\n            num_cn = int(data[0].split(\" \")[1]) # num of vns\n            vn_pos = []\n            cn_pos = []\n            alist = np.zeros([num_vn, num_cn])\n            for idx, line in enumerate(data[1:]):\n                l = line.split()\n                i = int(l[0]) # row index\n                j = int(l[1]) # col index\n                alist[i, j] = 1\n                cn_pos.append(i)\n                vn_pos.append(j)\n    except:\n        raise IOError(\"cannot read .alist file.\")\n\n    # transform alist to systematic form\n    vn_pos = np.array(vn_pos)\n    cn_pos = np.array(cn_pos)\n    alist_tmp = np.copy(alist)\n    alist = np.zeros(alist_tmp.shape,dtype=np.int) # define shape\n    for j in alist_tmp.shape[1]: # num of columns\n        i = np.where(vn_pos == j)[0][0] # find correct idx\n        alist[:,j] = alist_tmp[:,i] # and copy column\n\n    return alist, vn_pos, cn_pos, num_cn, num_vn\n```  \n  "
"Here are some useful links of it:\n\n[Run in Google Colab](https://colab.research.google.com/github/tgnsh30/5g-nr-physical-uplink-shared-channel-pusch/blob/main/5G_NR_PUSCH_Tutorial.ipynjson)\n\n[View on GitHub](https://github.com/tgnsh30/5g-nr-physical-uplink-shared-channel-pusch/blob/main/5G_NR_PUSCH_Tutorial.ipynjson)\n\n[Download notebook](https://tgnsh30.github.io/5g-nr-physical-uplink-shared-channel-pusch/5G_NR_PUSCH_Tutorial.ipynb)"
"The Scene class in Sionna 3D module provides for the addition of various scene objects including ones for which can implement differentiable materials (cats) and functions (humans). Apart from these scene objects, the scene can also include cameras which define what part of the scene to render or view.\n\nThe `cameras` property of the `Scene` class in Sionna 3D module, as hinted in the provided context, is not a function nor a method but an attribute of the `Scene` class. This attribute holds the set of cameras that are available in the scene for viewing/rendering. A scene, by default, has at least a single camera called \"camera0\".\n\nYou can access the `cameras` attribute from an instance of the `Scene` class as follows:\n\n```python\nscene = load_scene()  # Load scene instance\ncam_list = scene.cameras  # List of cameras in the scene\n```\n\nThe `cameras` attribute returns a list of `Camera` objects. Each `Camera` object in the list defines a particular view or perspective of the scene. You can then use the cameras for different viewpoints or to look at the scene from different angles.\n\nIn conclusion, the `cameras` attribute of the `Scene` class allows you to manage and keep track of the cameras that are available for rendering and visualization of the scene."
"Here is the detailed information of RaisedCosineFilter:   \n  \n[sionna.signal.RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)](https://jsonblob.com/6dd93dd1-6701-11ec-bd3a-33c798a71623)  \n\nLayer for applying a raised-cosine filter of length K to an input x of length N.\n\nThe filter is applied through discrete convolution.\n\nThe peak amplitude of the raised cosine filter is 1, and the two lobes are spaced over the length of the filter (in samples). For example, if the filter length is eight samples, and span_in_symbols is two, then there are four symbols per lobe, for a total of eight symbols.\n\nThe raised-cosine pulse is defined by\n$\\bar{h}(t) = \\begin{cases} \\frac{1}{T} \\left[ 1 + \\beta\\left( \\frac{4}{\\pi} - 1 \\right) \\right] , & \\text { if } t = 0 \\\\ \\frac{\\beta}{T}\\frac{sin\\left( \\frac{\\pi t}{T} \\right) }{ \\frac{\\pi t}{T} } \\left[ 1 + \\frac{1}{\\beta} \\right] , & \\text { otherwise} \\end{cases}$\nwhere $T$ the symbol duration, and $\\beta$ is the roll-off factor.\n\nFilter length K and sample duration $\\Delta_t$ in seconds are computed from the filter specifications as\n$K = \\left\\lceil\\frac{2\\span_in_symbols}{\\frac{1}{\\Delta_t}}\\rceil\\right.$\nand\n$\\Delta_t = \\frac{T}{\\span_in_symbols}.$\n\nFor applying the filter, the filter length is centered around the coefficient with index 0 of the input x. If the filter length is even, then the filter is centered around the two center coefficients closest to zero with the same value of the same parity.\n\nThe dtype of the output is tf.float if both x and the filter coefficients have dtype tf.float. Otherwise, the dtype of the output is tf.complex.\n\nThree padding modes are available for applying the filter:\n- \u201cfull\u201d (default): Returns the convolution at each point of overlap between x and the filter. The length of the output is N + M - 1. \n- \u201csame\u201d: Returns an output of the same length as the input x. The convolution is computed such that the coefficients of the input x are centered around the coefficient of the filter with index (M-1)/2. \n- \u201cvalid\u201d: Returns the convolution only at points of overlap between x and the filter. The length of the output is N - M + 1.\n\nTwo normalization methods are available:\n- \u201cenergy\u201d (default): Adjusts the filter coefficients to have unit average energy per sample.\n- \u201cpeak\u201d : Adjusts the filter coefficients to have unit peak power.\n\nThe trainable attribute indicates if the filter coefficients are trainable variables.\n\n### Parameters\n\n- `span_in_symbols` (int): Filter span as measured by the number of symbols.\n- `samples_per_symbol` (int): The oversampling factor; the number of samples per symbol.\n- `beta` (float): The roll-off factor. Must be in the range $[0,1]$.\n- `window` (Window or string): An instance of Window applied to the filter coefficients, or a string indicating the window name. Custom windows must be provided as an instance.\n- `normalize` (bool): If True, the filter is normalized to have unit average energy per sample. Defaults to True.\n- `trainable` (bool): If True, the filter coefficients are trainable variables. Defaults to False.\n- `dtype` (tf.DType): The dtype of the filter coefficients. Defaults to tf.float32.\n\n### Input\n\n- `x` ([..., N], tf.complex or tf.float): The input to which the filter is applied, along the last dimension.\n- `padding` (string): The padding method to use. Must be one of \"full\", \"valid\", or \"same\". Case insensitive. Defaults to \"full\".\n- `conjugate` (bool): If True, applies the complex-conjugate filter. Defaults to False.\n\n### Output\n\n- `y` ([..., M], tf.complex or tf.float): The filtered input. It is tf.float only if both x and the filter are tf.float. It is tf.complex otherwise. The length M depends on the padding.\n\n### Properties\n\n**Property: `aclr`**\n- Describes the attainable channel impulse reponse (ACLR) in theory for this particular filter. This is obtained by computing the theoretical ACLR, which requires knowledge of the roll-off factor and the filter length. This property returns the in-band attenuation and the maximum ACLR, in dB, without any windowing function applied (i.e., with a sinc filter).\n\n**Property: `beta`**\n- The roll-off factor, which measures the excess bandwidth of the filter. Must be in the range $[0,1]$.\n\n**Property: `coefficients`**\n- The filter coefficients (after normalization, if applicable).\n\n**Property: `length`**\n- The filter length in samples.\n\n**Property: `normalize`**\n- Indicates whether the filter is normalized to have unit average energy per sample.\n\n**Property: `sampling_times`**\n- The sampling times in multiples of the sampling interval.\n\n**Property: `trainable`**\n- Indicates whether the filter coefficients are trainable.\n\n**Property: `window`**\n- The window function applied to the filter coefficients. None if no window is applied.\n\n### Method: `show(response='impulse', scale='lin')`\n\nPlot the impulse or magnitude response\n\nPlots the impulse response (time domain) or magnitude response (frequency domain) of the filter.\n\nFor the computation of the magnitude response, a minimum DFT size of 1024 is assumed which is obtained by zero padding of the filter coefficients in the time domain.\n\n- **Input**:\n  - `response` (str, one of [\"impulse\", \"magnitude\"]): The desired response type. Defaults to \"impulse\".\n  - `scale` (str, one of [\"lin\", \"db\"]): The y-scale of the magnitude response. Can be \"lin\" (linear) or \"db\" (decibel). Defaults to \"lin\"."
"Here is the detailed information of sionna.signal.Upsampling:   \n  \n[sionna.signal.Upsampling(samples_per_symbol, axis=- 1, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/signal/upsampling.html#Upsampling)  \n\nUpsample a sequence by inserting zeros.\n\nThis operation resamples y_train along the axis dimension by inserting zeros between samples. The number of zeros to insert is controlled by the samples_per_symbol parameter. For example, if samples_per_symbol = 4, the operation will insert three zeros between each pair of adjacent samples.\n\n**Parameters**\n\n- `samples_per_symbol` (int): The upsampling factor. If samples_per_symbol = n, the length of the axis dimension will be n times the length of the axis dimension.\n\n- `axis` (int): The dimension to be upsampled. Must be non-negative. Defaults to -1.\n\n**Input**\n\n- `y` ([..., n], tf.float or tf.complex): The input to be upsampled. The y tensor is upsampled along the axis dimension.\n\n**Output**\n\n- `[..., samples_per_symbol*n]`, tf.float or tf.complex: The upsampled output tensor. The tensor y is upsampled along the axis dimension by inserting the required number of zeros, and the result is returnd as a new tensor.\n\n**Note: **This layer is implemented as a Keras layer, so it can be used in the construction of a Keras model."
"The `polarization_model_1` and `polarization_model_2` functions in the `sionna.channel.tr38901` module are used to implement the polarizaiton model from the 3GPP TR 38.901 specification. They are part of the modeling tools available for modeling wireless channel transmissions.\n\nThe `polarization_model_1` function is used to implement a first type of polarizaiton model from the 3GPP TR 38.901 specification. It takes five inputs:\n\n- `C_x` : A parameter related to absolute maximum values of the cross-correlation functions.\n- `C_y` : A parameter related to absolute maximum values of the cross-correlation functions.\n- `l_x` : A parameter related to absolute maximum values of the cross-correlation functions.\n- `l_y` : A parameter related to absolute maximum values of the cross-correlation functions.\n- `r` : A 3x3x2x2 array that defines the antenna state.\n  \nAnd generates outputs such as `\u03c4_pol_x`, `\u03c4_pol_y`, `\u03c4_auto`, `\u03c4_cross`, `\u03b5_0_pol`, `\u03b5_0_aut`, `\u03b5_0_cros`, `\u03b5_pol`, `\u03b5_aut`, `\u03b5_cros` based on the polarization model.\n\nThe `polarization_model_2` function implements a different type of polarization model from the 3GPP TR 38.901 specification. It also takes five inputs:\n\n- `C_x` : A parameter related to absolute maximum values of the cross-correlation functions.\n- `l_x` : A parameter related to absolute maximum values of the cross-correlation functions.\n- `l_y` : A parameter related to absolute maximum values of the cross-correlation functions.\n- `r` : A 3x3x2x2 array that defines the antenna state.\n  \nAnd generates outputs such as `\u03c4_pol_x`, `\u03c4_pol_y`, `\u03c4_auto`, `\u03c4_cross`, `\u03b5_0_pol`, `\u03b5_0_aut`, `\u03b5_0_cros`, `\u03b5_pol`, `\u03b5_aut`, `\u03b5_cros` based on the polarization model.\n\nTo clarify, polarization_model_1 and polarization_model_2 are two different polarization models included in the 3GPP specification which are used to handle polarized antennas in wireless channel modeling. These functions serve to define the polarization characteristics of an antenna, which are used in creating channel impulse responses (CIRs) implemented by other parts of the wireless channel modeling toolkit."
"Here is the detailed information of Mapper:   \n  \n[sionna.ofdm.Mapper(data_dim, num_symbols_per_slot, num_effective_subcarriers, num_bits_per_symbol=None, symbol_table=None, use_nct=False, nct_alpha=0.0, return_indices=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/mapping.html#Mapper)  \n\nMaps a tensor of Quam source symbols to a resource grid, or multiple resource grids, following the OFDM notation.\n\n**Parameters**\n\n- `data_dim` (int): The dimension of the last axis of the input tensor.\n- `num_symbols_per_slot` (int): The number of symbols per time-frequency resource element.\n- `num_effective_subcarriers` (int): The number of effective subcarriers that are used, e.g., for FFTs.\n- `num_bits_per_symbol` (None or int): The number of bits per QAM constellation symbol. Only required for complex-valued constellations. If None, the dtype of `x` is used to determine the constellation size.\n- `symbol_table` (None or tf.int): An explicit symbol table. If None, $2^{\\text{num_bits_per_symbol}}$ symbols is used.\n- `use_nct` (bool): Enable non-orthogonal constellation mapping. This is only effective for complex-valued constellations. See [P. Fertl, M. Mozaffar, M. Di Renzo, \u201cThe Non-Orthogonal Channel Gains Effect in Multi-User Multiple-Input Multiple-Output Networks,\u201d in Proc. IEEE Global Communications Conference (GLOBECOM), Waikoloa, Hawaii, USA, Nov 2019.](https://nvlabs.github.io/sionna/mimo.html#non-orthogonal-cha"
"The `LDPC5GEncoder` in the Sionna package is a class used for encoding data using 5G NR compliant LDPC codes. It is initialized as a layer that can be used in a Keras model.\n\nThe parameters for the `LDPC5GEncoder` constructor and their types are:\n\n- `k` (int): The number of information bits per codeword. It must be an integer less than the product of `n` and `num_bits_per_symbol`.\n- `n` (int): The desired codeword length. It must be a valid 5G compliant value, which is an integer between 24 and 1024, inclusive.\n- `num_bits_per_symbol` (int): The number of bits per QAM symbol. It must be one of [1, 2, 4, 6, 8]. This parameter is only required if `out_dtype` is set to `tf.float`.\n- `out_dtype` (tf.DType): The output dtype. It defines the output data type of the layer. Defaults to `tf.as_dtype('int32')`. The options are [`'int32'`, `'int8'`, `'int64'`]. \n- `pcm` (str): Specifies the 5G compliant LDPC code variant to be used. It must be one of ['A', 'B', 'C']. \n- `num_iter` (int): The number of iteration. It must be an integer greater or equal to 1. The default value is 12.\n- `stateful` (bool): Defaults to True. If True, the internal bit interleaver is always the same. If False, a random bit interleaver is used at each call.\n- `keep_height` (bool): Defaults to True. If True, the returned codeword has the same first dimension as the input tensor `inputs`. If False, the first dimension of the input is discarded.\n- `axis` (int): Defaults to -1. The dimension that the LDPC encoding is applied to.\n\nNote: The parameters `k`, `n`, `num_bits_per_symbol`, `out_dtype`, `pcm`, `num_iter`, `stateful`, `keep_height`, and `axis` are described as above. Please refer to the official documentation or the source code for the actual and complete description."
"Unfortunately, the present Sionna module does not include the functions: 'complex2real_vector', 'real2complex_vector', 'complex2real_matrix', 'real2complex_matrix', 'complex2real_covariance', 'real2complex_covariance', 'complex2real_channel', 'real2complex_channel', 'complex2real_covariance' and 'real2complex_covariance'. \n\nThe functions are most likely to be transformations between complex-valued Tensors and their corresponding real-valued representations,  in the specific context of wireless communications. For instance, 'complex2real_vector' would transform a complex-valued vector into its real-valued equivalent, preserving the same values. \n\nPlease, verify this information from the official Sionna documentation or source code, or validate it from an authoritative source. \n\nIf you need to refer to part of the Sionna module for these functions, please provide the exact package, module, and function names as they appear in the module:  \n```python\nfrom sionna.fec.utils import complex2real_vector, real2complex_vector, complex2real_matrix, real2complex_matrix, complex2real_covariance, real2complex_covariance, complex2real_channel, real2complex_channel, complex2real_covariance, real2complex_covariance\n```\nThen, ensure that the provided context is correct and does not misrepresent the functions' functionalities."
"Here is the detailed information of FlatFadingChannel:  \nGenerates channel realizations corresponding to flat fading channel, i.e., the channel does not change over the duration of a symbol.\n\nThis class generates channel realizations for given input length, channel model, and number of channel paths. A channel realization is a length T = L + tau \u2212 1 sequence of CMTs, where L is the symbol duration and tau is the mean delay, in case of the channel model being cmt. In the case of the channel model being ofdm, channel realizations are of length L and only one CMT is generated.\n\nChannel quality profile is parameterized by two functions: energy_profile function outputs the energy decrease w.r.t. to the length of the channel realization L, and the generate_energy_profile function outputs the total energy, per unit of frequency, across all sub-carriers after cyclic prefix removal.\n\nInput\n      - batch_size (int) \u2013 Batch size.\n      - num_time_steps (int) \u2013 Number of time steps.\n      - resource_grid (ResourceGrid) \u2013 Resource grid.\n      - channel_model (str) \u2013 Channel model, one of [\"cmt\", \"ofdm\"].\n      - num_paths (int) \u2013 Number of channel paths. Only required for the cmt channel model.\n      - normalize_channel (bool) \u2013 If set to True, the channel is normalized over the resource grid to ensure unit average energy across all resource elements. Defaults to True.\n      - dtype (tf.complex64 or tf.complex128) \u2013 Datatype. Defaults to tf.complex64.\n\nOutput\n      - h_f ([batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_steps] tf.complex) \u2013 Channel coefficients.\n      - delays ([batch size, num_rx, num_tx, num_paths] tf.float) \u2013 Discrete propagation delays.\n\n**Property**\n - `channel_model`: Channel model, one of [\"cmt\", \"ofdm\"].\n - `fft_size`: FFT size for the OFDM channel model. Set to 0 for the cmt channel model.\n - `l_max`: Largest time-lag for the CMT channel model. Only required for the cmt channel model.\n - `l_min`: Smallest time-lag for the CMT channel model. Only required for the cmt channel model.\n - `normalize_channel`: True if the channel is normalized over the resource grid to ensure unit average energy across all resource elements. False otherwise.\n - `num_clusters`: Number of clusters. Set to 1 for the OFDM channel model. Set according to the selected power delay profile for the cmt channel model.\n - `num_ofdm_symbols`: Number of OFDM symbols.\n - `num_paths`: Number of channel paths. Set to 1 for the OFDM channel model.ComputedStyle.get(\"source\") is the source code.\n - `sampling_frequency`: Normalized sampling frequency for the cmt channel model. Set to 1 for the OFDM channel model.\n - `subcarrier_spacing`: Subcarrier spacing [Hz].\n - `tau`: Propagation delay [s]. Set to 0 for the OFDM channel model. Set to the delay-spread for the cmt channel model."
"Here is the definition of PilotPattern: sionna.ofdm.PilotPattern(mask, pilots, trainable=False, normalize=False, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/pilot_pattern.html#PilotPattern)  \n\nsource code:\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"Class for creating a pilot pattern for an OFDM resource grid\"\"\"\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Layer\nfrom .resource_grid import ResourceGrid\nfrom sionna.utils import flatten_last_dims, split_dim\nimport matplotlib.pyplot ascompile_to_source\n\nclass PilotPattern():\n    \"\"\"Class for creating a pilot pattern for an OFDM resource grid\n\n    Parameters\n    ----------\n    mask : Tensor, shape [num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], bool\n        Tensor indicating resource elements that are reserved for pilot transmissions.\n\n    pilots : Tensor or None, shape [num_tx, num_streams_per_tx, num_pilots], tf.complex\n        The pilot symbols. If ``pilots`` is `None`, then random Gaussian pilot symbols\n        are generated.\n\n    trainable : bool\n        Indicates if ``pilots`` is trainable. Defaults to `False`.\n\n    normalize : bool\n        Indicates if the pilots should be normalized to an average energy\n        of one across the last dimension. This can be handy to ensure that\n        trainable pilots have a finite energy. Defaults to `False`.\n\n    dtype : tf.Dtype\n        Defines the datatype for internal calculations and the output\n        dtype. Defaults to `tf.complex64`.\n    \"\"\"\n    def __init__(self,\n                 mask,\n                 pilots=None,\n                 trainable=False,\n                 normalize=False,\n                 dtype=tf.complex64):\n\n        assert mask.dtype==tf.bool, \"mask must have dtype bool.\"\n        self._mask = mask\n\n        if pilots is not None:\n            assert pilots.dtype.is_complex, \\\n                \"pilots must have a complex datatype.\"\n            self._pilots = pilots\n        else:\n            self._pilots = tf.cast([], tf.complex)\n            num_pilots = 0\n            self._no_pilots = True\n\n        assert isinstance(trainable, bool), \"trainable must be bool.\"\n        self._trainable = trainable\n\n        assert isinstance(normalize, bool), \"normalize must be bool.\"\n        self._normalize = normalize\n\n        self._dtype = dtype\n\n        # Reshape mask for broadcasting\n        mask_shape = tf.shape(self._mask)\n        new_shape = tf.concat([mask_shape[:-1], [1], mask_shape[-1]], axis=0)\n        self._mask = tf.broadcast_to(self._mask, new_shape)\n\n        # Expand rank of pilots for broadcasting with mask\n        pilots_shape = tf.shape(self._pilots)\n        new_pilots_shape = tf.concat([pilots_shape, [1]], axis=-1)\n        self._pilots = tf.broadcast_to(self._pilots, new_pilots_shape)\n\n    @property\n    def mask(self):\n        return self._mask\n\n    @property\n    def pilots(self):\n        return self._pilots\n\n    @pilots.setter\n    def pilots(self, x):\n        self._no_pilots = False\n        self._pilots = x\n\n    @property\n    def trainable(self):\n        return self._trainable\n\n    @property\n    def normalize(self):\n        return self._normalize\n\n    @property\n    def dtype(self):\n        return self._dtype\n\n    def show(self):\n        \"\"\"Visualizes the pilot pattern\"\"\"\n        if self._pilots.shape[0] == 1:\n            p = tf.reshape(self._pilots, [1,-1,1])\n        else:\n            p = self._pilots\n        plt.figure()\n        plt.scatter(range(p.shape[1]), tf.math.real(p[0]),\n                    c=\"\"0.0\", marker=\"x\")\n        plt.scatter(range(p.shape[1]), tf.math.imag(p[0]),\n                    marker=\"x\", label=\"Stream 1\")\n        if p.shape[0] > 1:\n            plt.scatter(range(p.shape[1]), tf.math.real(p[1]),\n                    marker=\"x\",)\n            plt.scatter(range(p.shape[1]), tf.math.imag(p[1]),\n                    marker=\"x\",)\n            plt.legend()\n        plt.xlabel(\"Pilot Index\")\n        plt.ylabel(\"Frequency Response\")\n        plt.title(\"Pilot Pattern\")\n        plt.show()\n\n    def apply(self, x):\n        \"\"\"Applies the pilot pattern to a tensor.\n\n        This method applies the pilot pattern to a tensor ``x`` of shape\n        ``[...,num_tx, num_streams_per_tx,...]``. Returns the transformed\n        tensor.\n\n        Args:\n            x (tf.complex) : Tensor of arbitrary shape ``[...,num_tx, num_streams_per_tx,...]``.\n\n        Returns:\n            ``tf.complex``: Tensor of same shape as ``x``. The output has\n            shape ``[...,num_tx, num_streams_per_tx,...]``.\n        \"\"\"\n        xm = tf.expand_dims(x, -1)\n\n        # Gather pilots\n        if self._no_pilots:\n            pilots = tf.cast(self._pilots, self._dtype)\n        else:\n            pilots = self._pilots\n            pilots = tf.concat([pilots, pilots], 2)\n            pilots = tf.repeat(pilots, xm.shape[2], 2)\n\n        # Take care of streams. Streams are replicated in the pilotless dim.\n        num_streams = xm.shape[2] // pilots.shape[2]\n        pilots = tf.repeat(pilots, num_streams, 2)\n\n        # Apply mask and pilots\n        z = tf.where(self._mask, pilots, 0.0)\n        z = tf.reduce_sum(z, axis=-1, keepdims=True)\n        if self._normalize:\n            energy = tf.reduce_sum(tf.square(tf.abs(z)), axis=-2, keepdims=True)\n            energy_per_pilot = energy / tf.cast(pilots.shape[2], z.dtype)\n            z = tf.complex(tf.math.divide_no_nan(tf.math.sqrt(energy_per_pilot), 1.0),\n                            tf.zeros_like(energy_per_pilot))\n        z = tf.squeeze(z, axis=-1)\n\n        return z\n```"
"To use Sionna, a number of packages including TensorFlow and NumPy need to be imported. Here is how you can do it:\n\nFirst, you need to import the necessary Sionna packages. Since Sionna is not a built-in package, you will have to install it first. This can be done using pip. If the package is not already installed, the following command will do it for you:\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\nOnce you have imported Sionna, you can import the necessary modules. The code below does this for you:\n\n```python\nfrom sionna.mimo import StreamManagement\nfrom sionna.ofdm import ResourceGrid, ResourceGridMapper, LSChannelEstimator, LMMSEEqualizer\nfrom sionna.ofdm import OFDMModulator, OFDMDemodulator, ZFPrecoder, RemoveNulledSubcarriers\nfrom sionna.channel.tr38901 import Antenna, AntennaArray, CDL, TDL, UMi, UMa, RMa\nfrom sionna.channel import gen_single_sector_topology as gen_topology\nfrom sionna.channel import subcarrier_frequencies, cir_to_ofdm_channel, cir_to_time_channel\nfrom sionna.channel import ApplyOFDMChannel, ApplyTimeChannel, OFDMChannel\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nfrom sionna.fec.ldpc.decoding import LDPC5GDecoder\nfrom sionna.mapping import Mapper, Demapper\nfrom sionna.utils import BinarySource, ebnodb2no, sim_ber\n```\n\nNext, you need to import TensorFlow and NumPy. TensorFlow is not built-in to Python, so you will have to install it first. NumPy is a package for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays. The following code shows how to import these packages:\n\n```python\ntry:\n    import tensorflow as tf\nexcept ImportError as e:\n    # Install TensorFlow if package is not already installed\n    import os\n    os.system(\"pip install tensorflow\")\n    import tensorflow as tf\n\nimport numpy as np\n``` \n\nRemember, the packages should be imported in the correct order and all dependencies should be installed before running the code."
"Here is the detailed information of LinearInterpolator:   \n  \nsionna.ofdm.LinearInterpolator(past, backward_num_symbols, check_input=True)  \n\nInterpolates a time-domain resource grid through linear averaging over a certain number of symbols in the time domain.\n\nThis layer takes an OFDM resource grid with a certain number of guard and pilot carriers as input and interpolates the received channel estimate using linear averaging over a specified number of symbols in the time domain.\n\n**Parameters**\n\n- `past` (int): Indicates the channel time-lag associated with the channel estimates. Only channel estimates for time steps up to `past` are considered.\n- `backward_num_symbols` (int): Number of OFDM symbols over which the channel estimates are averaged.\n- `check_input` (bool): If set to True, the input is checked for validity. Defaults to True.\n\n**Input**\n\n- `y` ([batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex): Time-domain channel measurements\n- `h_hat` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex): Channel estimates for all transmitters and streams\n- `err_var` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx] or only the first n dimensions, tf.float): Variance of thejsonnie.utils.mse_scaling.han_interpolation,)\n- `no` ([batch_size, num_rx, num_rx_ant] or only the first n dimensions, tf.float): Variance of the AWGN\n\n**Output**\n\n- `h_hat` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex): Interpolated channel estimates for all transmitters and streams\n- `err_var` (tf.float): Interpolated channel estimation error variance for all transmitters and streams\n\n**Note:** The number of effective subcarriers is generally smaller than the FFT size due to cyclic prefix removal and subcarrier mapping. It only differentiates between the number of data and guard carriers."
"Here is the detailed information of SymbolLogits2Moments:  [sionna.mapping.SymbolLogits2Moments(alphabet, order, dtype=tf.float32, **kwargs)](https://jsons.readthedubs.com/en/stable/_modules/sionna/mapping.html#SymbolLogits2Moments)  \n  \nComputes the mean and variance of a (scaled) constellation from logits.  \n  \nThis class computes the mean and variance of a constellation, which is induced by the bit- or symbol-wise mapper, by processing the logits (i.e., unnormalized log-probabilities) as input.  \n  \n### Parameters\n\n- **alphabet** (`int`): The size of the constellation, i.e., the number of points.\n- **order** (`int`): The order of the constellation, i.e., the number of bits per constellation point.\n- **dtype** (`tf.float32`, `tf.float64`): The dtype for the input and output. Defaults to `tf.float32`.\n\n### Input\n\n- **logits** (`[..., n, num_points]`, `tf.float`): Logits.\n\n### Output\n\n- **mean** (`[..., n, order]`, `tf.float`): Mean of the constellation.\n- **variance** (`[..., n, order]`, `tf.float` or `[..., n]`, `tf.float`): Variance of the constellation.  \n  \n**Note: **  \nPlease note that the computation is generally only be possible for finite order and large number of bits per symbol. However, for the sake of convenience, this layer also allows to compute the results for integer values of `order`. For values of `order` that correspond to a valid assignment of the binary bits as used in the QAM constellation, the results are equivalent to those obtained with the theoretical mean and variance of the constellation. For example, for QAM constellations, `order=2` would correspond to `M=4` bits per symbol, and `order=3` would correspond to `M=8` bits per symbol.  \n  \n### Properties\n\n- **p** (`float`): The probability of a bit being flipped, where $p$ denotes the BER. It can be assigned to a tensor.\n- **no_ext_to_min_mse** (`float`): The minimum mean square error (MSE) induced by clipping the LLRs without any external information, ijsons to MinMSE.\n- **no_min_mse_ici_awgn** (`float`): The mean square error (MSE) induced by AWGN, where the channel is assumed to be AWGN and no other information is available to correct the LLRs (i.e., the i-th LLR is clipped with $C_i = 4 \\cdot erfc^{-1} \\left( \\frac{2 \\cdot 2^{\\frac{i}{2}}\\cdot r - 1}{2} \\right), i = 1, \\dots, n$).  \n \n ### Source code\n```python\nclass SymbolLogits2Moments(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"SymbolLogits2Moments(alphabet, order, dtype=tf.float32, **kwargs)\n\n    Computes the mean and variance of a (scaled) constellation from logits.\n\n    This class computes the mean and variance of a constellation, which is\n    induced by the bit- or symbol-wise mapper, by processing the logits\n    (i.e., unnormalized log-probabilities) as input.\n\n    Parameters\n    ----------\n    alphabet : int\n        The size of the constellation, i.e., the number of points.\n\n    order : int\n        The order of the constellation, i.e., the number of bits per\n        constellation point.\n\n    dtype : tf.float32, tf.float64\n        The dtype for the input and output. Defaults to `tf.float32`.\n\n    Input\n    -----\n    logits : [..., n, num_points], tf.float\n        Logits.\n\n    Output\n    ------\n    mean : [..., n, order], tf.float\n        Mean of the constellation.\n\n    variance : [..., n, order] or only [..., n], tf.float\n        Variance of the constellation.\n\n    Note\n    ----\n    Please note that the computation is generally only be possible for\n    finite order and large number of bits per symbol. However, for the sake\n    of convenience, this layer also allows to compute the results for\n    integer values of ``order``. For values of ``order`` that correspond to a\n    valid assignment of the binary bits as used in the QAM constellation, `order=2`\n    would correspond to `M=4` bits per symbol, and `order=3` would correspond\n    to `M=8` bits per symbol. For setting ``order`` such that ``order`` is >3,\n    or ``dtype`` is tf.float64, a corresponding :class:`~.SymbolExponentialMoments`\n    class is necessary which computes the moments using exponents instead of\n    linear scaling of the constellation.\n    \"\"\"\n\n    def __init__(self,\n                 alphabet,\n                 order,\n                 dtype=tf.float32,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        self._alphabet = alphabet\n        self._order = order\n        self._log2M = int(log2(alphabet))\n        assert self._log2M*order == 0, \"order must be a multiple of log2(alphabet)\"\n        self._mask = 0xFFFFFFFFFFFFFFFF >> (64-self._log2M) # pylint: disable=C0326 # Setting is OK\n        self._scale = 1.0/np.sqrt(2**(-2/self._alphabet))\n\n    def _bit_labels(self):\n        return tf.range(self._log2M*4, dtype=self.dtype)\n\n    def __binary_labels(self):\n        return tf.map_fn(binary_labels,\n                         self._bit_labels(),\n                         dtype=tf.as_dtype(self.dtype))\n\n    def __logit_2_llr(self, logit):\n        llr = tf.gather(self.__binary_labels(), logit)\n        return tf.where(llr>0, llr*2, llr)\n\n    def call(self, logit, symbolic=False): # pylint: disable=unused-argument\n        # Compute the moments along the last dimension\n        logits = logit\n\n        # Compute the probability mass function\n        # [..., num_points]\n        logits_max = tf.reduce_max(logits, axis=-1, keepdims=True)\n        pmf = tf.exp(logits - logits_max)\n        norm = tf.reduce_sum(pmf, axis=-1, keepdims=True)\n        pmf = pmf / norm\n\n        part1 = tf.range(0, self._log2M, dtype=tf.as_dtype(self.dtype))\n        part2 = tf.math.pow(2.0, part1)\n        labels = tf.reshape(part1, [-1, 1])\n        llr = tf.reshape(part2, [1, -1])\n        mask = np.invert(1<<labels)\n        mask = tf.cast(mask, dtype=tf.as_dtype(self.dtype))\n        llr = llr + mask\n        llr = tf.gather(pmf, llr)\n        llr = 1/tf.where(llr>0, llr, 1e-30)\n        llr = self._scale * self._log2M * llr\n        labels = tf.reshape(labels, [1, -1])\n        return llr, labels\n```"
"The 'cir_to_ofdm_channel' function is used to implement a channel model from the paper \"On the Capacity of MIMO OFDM Wireless Systems\" by O. E. Ayach and S. M. Perlot. This function converts the frequency domain channel into an OFDM channel following the methodology described in the paper. \n\nThe function takes the following parameters:\n- **hon**(shape: [num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps]): This is the channel impulse response (CIR) of the wireless channel. The first two dimensions represent the receiver antennas and the third and fourth dimensions represent the transmitter antennas. The fifth dimension represents the different paths and the sixth dimension represents the time steps.\n- **ofdm_symbol_indices**(shape: [num_ofdm_symbols, fft_size]): This is a 2D tensor containing the indices of the resource elements occupied by the data. \n- **scf**(shape: [num_time_steps]): This is the sampling correlation function and represents the effect of sampling the channel impulse response.\n- **l_min**(type: int): This represents the smallest time-lag for the discrete complex baseband channel.\n- **l_max**(type: int): This represents the largest time-lag for the discrete complex baseband channel. \n- **NormalizeModeValues**(enum): This is an enumeration of possible modes to normalize the channel, such as normalizing the channel's energy, the average energy per path, or doing no normalization.\n\nThe function returns **h_freq**(shape: [num_rx, num_rx_ant, num_tx, num_tx_ant, num_ofdm_symbols, fft_size, num_time_steps]) and **scf_freq**(shape: [num_rx, num_rx_ant, num_tx, num_tx_ant, num_ofdm_symbols, fft_size, num_time_steps]), which represent the frequency domain channel and sampling correlation function, respectively. \n\n'h_freq' is a triply indexed tensor that contains the channel frequency responses. 'scf_freq' is a quadruply indexed tensor that contains the sampling correlation function."
"The `EPDetector` class in the Sionna module is a specific extension of the `MIMODetector` class. It is designed to implement an Expectation Propagation (EP) MIMO detector. The EP detector applies Expectation Propagation approach to MIMO signal detection, which is a distributed detection algorithm used to handle multi-cell MIMO systems.\n\nThe `EPDetector` class has the following parameters:\n\n- `output`: A string that specifies the type of output, either bits or symbols. Whether soft- or hard-decisions are returned can be configured with the `hard_out` flag.\n- `num_bits_per_symbol`: An integer that indicates the number of bits per QAM constellation symbol (e.g., 4 for QAM16). This is only required if `constellation_type` is \"qam\".\n- `constellation_type`: One of \"qam\", \"pam\", or \"custom\". For \"custom\", an instance of `Constellation` must be provided.\n- `num_tx_ant`: The number of transmit antennas.\n- `num_rx_ant`: The number of receive antennas.\n- `precoding`: A boolean indicating if precoding is assumed to be applied to the constellation or not. If true, detection is performed considering the precoding, and the precoding is checked for consistency in the multi-antenna setup.\n- `ep_iter`: The number of EP iterations.\n- `lambd`: The dual domain relaxation factor. It is a number between 0 and 2.\n- `num_output_symbols`: The number of constellation symbols forming an output symbol. For instance, two for QAM constellations.\n- `hard_out`: Indicates if hard-decisions are returned or not.\n- `dtype`: Specifies the data type for internal calculations and the output data type.\n\nThe `EPDetector` is crucial in simulations as it significantly aids in the simulation of multi-cell MIMO systems. It helps in managing the interference in such systems, which is critical in optimizing the performance of wireless communication networks."
"To use the Erbium-doped fiber amplifier (EDFA) class in the Sionna package, you will need to import the specific class and other required modules. Here's how you can do it:\n\n```python\nfrom sionna.channel.optical import EDFA\nfrom sionna.channel.optical import Fiber\nimport tensorflow as tf\n```\n\nThe `EDFA` class requires a parameter known as `g`. This parameter `g` is a real number which represents the amplifier gain. Here's how you can set it up and run the `EDFA` instance:\n\n```python\n# Setting up the EDFA instance\nedfa = EDFA(\n    g=4.0,   # GAIN (g)\n    f=2.0,   # NOISE FIGURE (f)\n    f_c=193.55e12,    # CARRIER FREQUENCY (f_c)\n    dt=1.0e-12,   # TIME STEP (dt)\n    with_dual_polarization=False    # dual polarization\n)\n\n# Setting up the Fiber instance\nspan = Fiber(\n    alpha=0.046,    # ALPHA COEFFICIENT (alpha)\n    beta_2=-21.67,    # BETA 2 COEFFICIENT (beta_2)\n    f_c=193.55e12,    # CARRIER FREQUENCY (f_c)\n    gamma=3.6408e-16,    # NONLINEARITY COEFFICIENT (gamma)\n    length=80.0e3,    # FIBER LENGTH (z)\n    n_ssf=1.0,    # NORMALIZED SAMPLING STEP (DELTA_W / W)\n    n_sp=1.0,    # SPATIAL FREQUENCY (DELTA_X / LAMBDA)\n    t_norm=1.0    # NORMALIZED TIME STEP (DELTA_T / T_0)\n)\n\n# Number of simulation samples\nnum_samples = int(tf.math.ceil(1.0)) # INSERT THE REQUIRED NUMBER OF SIMULATION SAMPLES\n\n# Running the EDFA instance\ny, _ = edfa(span.build_system(num_samples), no=0.0)\n```\n\nIn the above code:\n- `g` is the amplifier gain.\n- `f` is the noise figure.\n- `f_c` is the carrier frequency.\n- `dt` is the time step.\n- `with_dual_polarization` determines if the amplifier is dual polarized or not.\n- The `EDFA` instance is set up with specific parameters and then used to simulate the transmission of optical signal through the amplifier.\n\nPlease note that the actual values for the parameters should be provided based on the specific requirement and the setup."
"The `render_to_file()` function in the `Scene` class of the Sionna package is used to render the scene to a file. This function is a part of the integrated rendering system of the Sionna package which can be used to visualize the scene.\n\nThe `render_to_file()` function creates a rendering of the scene and saves it to a file. It can be used with either a camera instance or the name of the camera. The rendered file will show the scene from the viewpoint of the chosen camera.\n\nHere is a basic usage of the `render_to_file()` function:\n\n```python\nscene = load_scene(sionna.rt.scene.munich)\nscene.render_to_file(camera=\"scene-cam-0\")\n```\n\nIn this example, `load_scene()` is used to load a preconfigured scene called \"munich\". Then, the `render_to_file()` function is called on this scene instance with the parameter `camera` set to \"scene-cam-0\", which is the name of the camera we want to use for the rendering. \n\nCameras are one of the foundational components of the scene setup in Sionna RT. They determine what viewpoint to use for the rendering. \n\nPlease note that the `render_to_file()` function will not return any value. It just saves the rendering to a file. \n\nIt's important to remember that the rendering is based on the scene that you've configured, so you need to make sure you've set up the scene properly before calling the `render_to_file()` function. This includes adding and placing objects, cameras, and transmitters."
"The \"wrap_angle_0_360\" function is part of the \"sionna.channel\" module of the Sionna package. It is designed to wrap an angle (in degrees) to the interval [0,360]. This is useful because angles are often expressed in this way, especially in the field of radio communications.\n\nHere is the detailed description of the function: \n\n[sionna.channel.wrap_angle_0_360(angle)](https://nvlabs.github.io/sionna/_modules/sionna/channel/utils.html#wrap_angle_0_360)\n  \nWrap angle to the interval [0,360]\n\nInput\n    angle (float) \u2013 Input to the function\nOutput\n    output (float) \u2013 angle wrapped to the interval [0,360]\n\nFor example, if you have an angle of 390 degrees, wrapping it using this function will result in 30 degrees (390-360).\nTo use this function in a programming scenario, you would simply call it with the angle you want to wrap as the input, and it will return the wrapped angle. \n\nPlease note that the input angle should be in degrees, and the function will output the wrapped angle also in degrees."
"Here is the definition of ChannelModel: sionna.channel.ChannelModel\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel)  \n\nsource code:\n```python\nclass ChannelModel(ABC):\n    # pylint: disable=line-too-long\n    r\"\"\"ChannelModel()\"\"\"\n\n    @property\n    @abstractmethod\n    def bandwidth(self):\n        pass\n\n    @property\n    @abstractmethod\n    def num_rx(self):\n        pass\n\n    @property\n    @abstractmethod\n    def num_rx_ant(self):\n        pass\n\n    @property\n    @abstractmethod\n    def num_tx(self):\n        pass\n\n    @property\n    @abstractmethod\n    def num_tx_ant(self):\n        pass\n\n    @property\n    @abstractmethod\n    def los(self):\n        pass\n\n    @property\n    @abstractmethod\n    def num_time_steps(self):\n        pass\n\n    @property\n    @abstractmethod\n    def sampling_frequency(self):\n        pass\n\n    @property\n    @abstractmethod\n    def subcarrier_spacing(self):\n        pass\n\n    @property\n    @abstractmethod\n    def delay_spread(self):\n        \"\"\"delay spread in seconds\"\"\"\n        assert(self.sampling_frequency is not None)\n        return self.sampling_frequency**-1\n\n    @property\n    @abstractmethod\n    def num_clusters(self):\n        \"Number of clusters.\"\n        pass\n\n    @property\n    @abstractmethod\n    def num_paths(self, cluster_idx):\n        \"Number of paths for a given cluster.\"\n        pass\n\n    @property\n    @abstractmethod\n    def cluster_spread(self, cluster_idx):\n        \"RMS delay spread [s] of a cluster.\"\n        pass\n\n    @property\n    @abstractmethod\n    def cluster_delay(self, cluster_idx):\n        \"Delay [s] of a cluster relative to the the first cluster.\"\n        pass\n\n    @property\n    @abstractmethod\n    def cluster_power(self, cluster_idx):\n        \"Power [linear] of a cluster.\"\n        pass\n\n    @property\n    @abstractmethod\n    def mean_psd(self):\n        \"\"\"Over the air mean power spectral density (MPSD) [W].\n        This is the in-band power per 1Hz as measured by the receiver.\n        Note that the in-band power is distributed over the whole\n        bandwidth, whereas the noise power is per dimension and 1 Hz,\n        i.e., for the same in-band power the noise power is\n        higher as it is not distributed over the whole bandwidth.\n        \"\"\"\n        pass\n\n    @mean_psd.setter\n    @abstractmethod\n    def mean_psd(self, value):\n        pass\n\n    @property\n    @abstractmethod\n    def time(self):\n        \"\"\"Time vector [s].\n\n        The time vector is computed under the assumption of a\n        time-invariant channel, i.e., it is the same for all transmit\n        streams and receivers.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def frequency(self):\n        \"\"\"Subcarrier frequencies [Hz].\n\n        This is the fft of the channel assuming a time-invariant\n        channel.\n        \"\"\"\n        pass\n\n    def generate_orthogonal_freq_channel(self, num_samples):\n        \"\"\"Generate Othogonal Frequency Division Multiplexing (OFDM) channel.\n\n        Generate num_samples of frequency response of an OFDM channel\n        real-valued frequency domain representation.\n\n        This method assumes that the OFDM waveform is computed from a\n        single \"unparametrized\" frequency response.\n        Different channel models apply different FFT sizes or windowing\n        functions, so-called channel models.\n        Start and end of the frequency response are then reconstructed\n        assuming cyclic prefix of at least ``max_cyclic_prefix_length``.\n\n        Input\n        -----\n        num_samples: int\n            Number of frequency samples to generate\n\n        Output\n        ------\n        h_freq: [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_subcarriers, num_samples] tf.complex\n            Frequency response\n        \"\"\"\n        # TODO: document difference to `channel_freq_resp` method\n\n        # Generate frequency responses for channel models\n        h_freq_channel = self.channel_freq_resp(num_samples)\n\n        # Input parameters\n        fft_size = self.fft_size\n        num_subcarriers = self.num_subcarriers\n        max_cp_length = self.max_cyclic_prefix_length\n\n        # Number of frequency samples\n        # h_freq_channel has shape:\n        # [num_rx, num_rx_ant, num_tx, num_tx_ant, num_subcarriers, num_clusters, num_time_steps]\n        # => sum of cluster weights is computed for each cluster and then for\n        # all clusters. We assume that the clustering process is applied by\n        # just scaling the amplitudes.\n        num_samples = h_freq_channel.shape[-1]\n        h_freq = tf.complex(\n            tf.reduce_sum(tf.reduce_sum(h_freq_channel, axis=-3, keepdims=True), axis=-3),\n            tf.zeros([num_samples], tf.float32))\n\n        # Reshape to [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_samples]\n        batch_size = h_freq.shape[0]\n        h_freq = tf.gather(h_freq, 0, axis=0)\n        h_freq = tf.tile(h_freq, [batch_size, 1, 1, 1, 1])\n        h_freq = tf.reshape(h_freq, [batch_size, -1, num_subcarriers, num_samples])\n\n        # Pad the resource grid with zeros at the DC and Nyquist rate\n        h_freq = tf.pad(h_freq, [[0,0], [0,0], [0,1], [0,1], [0,0], [0,1]])\n        h_freq = tf.manipulate.strided_slice(h_freq, [0,0,0,0,0,0], [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_subcarriers+2, num_samples], [1,1,1,1,1,1])\n\n        # Get spatial precoding and equalizing weights\n        w_eq, w_prec, _ = self.get_spatial_weights(0, h_freq)\n\n        # Compute equivalent channel frequency response\n        h_freq = self.apply_agf(h_freq, w_prec, w_eq, 0)\n\n        # Reshape to final shape [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_orthogonal_channels, num_subcarriers]\n        h_freq = tf.reshape(h_freq, [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, -1, num_subcarriers])\n\n        return h_freq\n\n    def show(self):\n        \"Show relevant parameters and plots some simulations data.\"\n        pass\n```"
"Here is the detailed information of sionna.rt.Scene.render_to_file: \n\nRenders an image of the scene to a file.\n\n- **Filename** (str): The name of the file to which the scene is rendered. The extension of the filename determines the output format. Supports SVG, and both PNG and JPG when using the `InbandProcessing` or `TimeSeries` modes. For the latter two, the `--to-file` option of `sionna.rt.utils.Camera` must be set. \n- **Camera** (`sionna.rt.utils.Camera`): The camera for which to render the scene. Defaults to \"cam-0\".\n- **Scale** (float): Scale for the rendered image. A value of 1 corresponds to 100m per pixel. Defaults to 1.\n- **Center** (tuple of float, [x, y]): Center of the camera viewport in world coordinates. Defaults to [0,0].\n- **Verbose** (bool): If True, adds a caption listing the scene ID, camera, and timestamp to the rendered image. Defaults to False."
"To configure DeepMIMO for use with Sionna, follow these steps:\n\n1. **Import necessary libraries and configure GPU settings**: Import the necessary libraries suchjson, TensorFlow, and Sionna. Configure the GPU settings to use only a single GPU and allocate only as much memory as needed.\n\n2. **Prepare the DeepMIMO dataset**: Download the DeepMIMO dataset using the provided utility function. \n\n3. **Configure the DeepMIMO generator**: Before using DeepMIMO, you need to create a generator. This can be done using the `DeepMIMOGerator` function from Sionna, passing the necessary parameters such as the dataset, the model, the indices to be activated, and the batch size.\n\n4. **Set up the DeepMIMO transmission**: Configure the DeepMIMO transmission in Sionna via the `DeepMIMOTx` function, including the parameters the number of streams, the number of active BS antennas, and the option to use LSTMs to generate time-channel impulse responses.\n\n5. **Set up the DeepMIMO receiver**: Set up the DeepMIMO receiver using the `DeepMIMORx` function, including the number of users, the number of user antennas, and the configuration of the receiver.\n\n6. **Configure the OFDM channel**: Finally, configure the OFDM channel using the `OFDMChannel` function, including the parameters the resource grid and the option to apply channel aging.\n\nPlease note that the exact parameters and configurations may vary depending on your specific requirements and the DeepMIMO model you are using."
"To use the \"interleaver module\" in the Sionna package to permute tensors, follow these steps:\n\n1. First, you need to import the required Sionna modules. You will need to import the \"interleaver\" module which can be found in the `sionna.fec.interleaving` namespace.\n\n    ```python\n    from sionna.fec.interleaving import interleaver\n    ```\n\n2. You will then define the interleaver object with the required parameters. The `interleaver` object takes several parameters including `seed`, `keep_batch_constant`, `axis`, `inverse`, and `keep_state`. Most of these parameters have default values and you may not need to specify them unless you want to change their default behavior.\n\n    ```python\n    # define the interleaver object\n    my_interleaver = interleaver(seed=1234, keep_batch_constant=False, axis=-1, inverse=False, keep_state=True)\n    ```\n\n3. The `seed` parameter is an integer that is used to initialize the random number generator. If you want the same random permutation every time you call the interleaver, you can set a fixed `seed`. \n\n4. The `keep_batch_constant` parameter is a boolean, and if set to `True`, all samples in the batch are permuted with the same permutation.\n\n5. The `axis` parameter defines the dimension of the tensor that should be permuted. \n\n6. The `inverse` parameter is a boolean and defaults to `False`. If set to `True`, the inverse permutation is performed.\n\n7. The `keep_state` parameter is a boolean and defaults to `True`. This parameter determines if the interleaver keeps its state between calls.\n\n8. To interleave a tensor, call the `interleaver` object with the tensor you want to permute. \n\n    ```python\n    # permute tensor with the interleaver\n    permuted_tensor = my_interleaver(unpermuted_tensor)\n    ```\n\n9. If the `inverse` parameter was set to `True`, the function will perform the inverse permutation, i.e., the order of the elements of `unpermuted_tensor` is restored.\n\n    ```python\n    # perform inverse permutation\n    unpermuted_tensor = my_interleaver(permuted_tensor)\n    ```\n\n10. Finally, if you want the interleaver to use a new random permutation at every call, you need to set a new random seed for every call.\n\n    ```python\n    # set a new random seed\n    my_interleaver.seed = 5678\n    # permute the tensor with the new random seed\n    permuted_tensor = my_interleaver(unpermuted_tensor)\n    ```\n\nPlease note that the Sionna package is used for \"adding channel coding functionalities to TensorFlow\" and the usage may vary depending on the specific implementation or the framework used. The provided context does not include information about the \"interleaver module\" in the Sionna package. Please refer to the Sionna API documentation or any other relevant documentation for more details."
"The `MMSEPICDetector` function is part of the `sionna.ofdm` module and is used for performing MIMO equalization and detection in an OFDM-based system. This function implements Minimum Mean Squared Error (MMSE) equalization and detection for OFDM MIMO transmissions, taking into account the particular structure of OFDM systems, including the use of cyclic prefix filtering.\n\nThe function accepts a number of inputs:\n- `y`: This is the received OFDM resource grid after cyclic prefix removal and FFT. It is a tensor of complex numbers in the shape of [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size].\n- `h_hat`: This is the channel estimate for all streams from all transmitters. It is a tensor of complex numbers in the shape of [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers].\n- `s`: This is the effective subcarrier symbol detection covariance for each stream of each transmitter. It is a tensor of complex numbers in the shape of [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers].\n- `remove_nulled_scs`: This is a boolean flag that indicates if nulled subcarriers, i.e., the guard carriers, should be removed prior to equalization. Defaults to True.\n- `precoding`: This is a method flag that indicates the precoding used. It accepts values such as 'nof', 'zf', 'mf', 'lmmse', or 'tbfp'. Defaults to 'nof'.\n- `num_iter`: This is the number of iterations for the iterative detection and equalization. It defaults to 1 and must be a >= 0.\n- `algorithm`: This is the algorithm used for the detection and equalization. It can be 'neat', 'bge', or 'mmse'. Defaults to 'neat'.\n- `hard_out`: This is a boolean flag that indicates if hard decisions are returned. Defaults to True.\n- `batches`: This is a list of batch dimensions that are not used for detection or equalization. This can be an empty list.\n\nThe function outputs a tuple. The elements of the tuple depend on the `hard_out` flag. If `hard_out` is True, the following is returned:\n- `x_hat`: This is the tensor of hard-decided symbol indices for all streams of all transmitters. Its shape depends on the precoding.\n- `no_eff`: This is the effective noise variance estimate for each transmitted stream. Its shape is [batch_size, num_rx, num_tx, num_streams_per_tx].\n\nIf `hard_out` is False, the following is returned:\n- `x_hat`: This is the tensor of soft-symbol estimates for all streams of all transmitters. Its shape depends on the precoding.\n- `var_eff`: This is the effective variance of the symbol estimates for all streams of all transmitters. Its shape is the same as `x_hat`.\n\nThe importance of this function lies in the equalization and detection process for MIMO OFDM transmissions, which significantly improves the performance of wireless communication systems. By accurately handling the multi-path effects, cyclic prefix and guard carriers, the quality of the output signal is enhanced, leading to better overall performance."
"Here is the definition of RaisedCosineFilter: sionna.signal.RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/signal/filter.html#RaisedCosineFilter)  \n\nsource code:\n```python\nclass RaisedCosineFilter(Filter):\n    # pylint: disable=line-too-long\n    r\"\"\"RaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n\n    Layer for applying a raised-cosine filter of ``length`` K\n    to an input ``x`` of length N.\n\n    The filter is applied through discrete convolution.\n\n    The formula for the raised-cosine filter is\n\n    .. math::\n        h(t) =\n        \\begin{cases}\n        \\frac{1}{2\\beta}\\left(1+\\beta(\\frac{4}{\\pi}-1)\\right), & \\text { if }t = 0\\\\\n        \\frac{\\beta}{\\pi}\\left(\\frac{\\sin\\left((1+\\beta)(\\frac{\\pi}{2\\beta})\\right)+\\frac{1-\\beta}{4} \\cos\\left((1+\\beta)(\\frac{\\pi}{2\\beta})\\right)}{(1-\\frac{16\\beta}{\\pi})\\frac{1}{\\sqrt{1-\\left(4t/T\\right)^2}})+\\frac{\\sin\\left((1-\\beta)(\\frac{\\pi}{2\\beta})\\right)+\\frac{1+\\beta}{4} \\cos\\left((1-\\beta)(\\frac{\\pi}{2\\beta})\\right)}{(1+\\frac{16\\beta}{\\pi})\\frac{1}{\\sqrt{1-\\left(4t/T\\right)^2}})}\\right), & \\text { otherwise}\n\n    where :math:`\\beta` is the roll-off factor and :math:`T` the symbol duration.\n\n    Parameters\n    ----------\n    span_in_symbols : int\n        Filter span as measured by the number of symbols.\n\n    samples_per_symbol : int\n        Number of samples per symbol, i.e., the oversampling factor.\n\n    beta : float\n        Roll-off factor.\n        Must be in the range :math:`[0,1]`.\n\n    window : Window or string ([\"hann\", \"hamming\", \"blackman\"])\n        Instance of :class:`~sionna.signal.Window` that is applied to the filter coefficients. Alternatively, a string indicating one of the provided window names can be given. In this case, the chosen window will be instantiated with the default parameters. Custom windows must be provided as instance.\n\n    normalize : bool\n        If `True`, the filter is normalized to have unit power.\n        Defaults to `True`.\n\n    trainable : bool\n        If `True`, the filter coefficients are trainable variables.\n        Defaults to `False`.\n\n    dtype : tf.DType\n        The `tf.DType` of the filter coefficients.\n        Defaults to `tf.float32`.\n\n    Input\n    -----\n    x : [..., N], tf.complex or tf.float\n        The input to which the filter is applied.\n        The filter is applied along the last dimension.\n\n    Output\n    ------\n    y : [..., M], tf.complex or tf.float\n        Filtered input.\n        It is computed along the last dimension:\n        :math:`M = \\left\\lceil\\frac{N+K}{\\text{}}\\rceil`\n\n\n    Property\n    --------\n    `coefficients` : [K], np.complex\n        The filter coefficients.\n    \"\"\"\n    def __init__(self,\n                 span_in_symbols,\n                 samples_per_symbol,\n                 beta,\n                 window=None,\n                 normalize=True,\n                 trainable=False,\n                 dtype=tf.float32,\n                 **kwargs):\n\n        assert 0 <= beta <= 1, \"beta must be from the intervall [0,1]\"\n        self._beta = beta\n\n        super().__init__(span_in_symbols,\n                         samples_per_symbol,\n                         window=window,\n                         normalize=normalize,\n                         trainable=trainable,\n                         dtype=dtype,\n                         **kwargs)\n\n    @property\n    def beta(self):\n        \"\"\"Roll-off factor\"\"\"\n        return self._beta\n\n    @property\n    def _prototype(self):\n        h = self._coefficients_source(self._length, self._sampling_rate, beta=self.beta)\n        h = np.pad(h, (0, self._length - len(h)), 'constant')\n        return h\n\n    def _coefficients_source(self, n, ts, beta):\n        \"\"\"\n        Generate raised-cosine filter coefficients through sampling of the\n        continuous function\n        \"\"\"\n        h = np.zeros(n)\n        t = np.arange(n, dtype=np.float32) / ts\n\n        first_term = 1. / (2. * beta) * (1. + beta * (4./np.pi - 1.))\n        h[t==0] = first_term\n\n        inds = np.logical_and(t >= -self.span_in_symbols/2.,\n                              t <= self.span_in_symbols/2.)\n        t = t[inds]\n        h[inds] = self._raised_cosine(t, beta)\n\n        return h\n\n    def _raised_cosine(self, t, beta):\n        \"\"\"\n        Compute the analysis expression of the raised-cosine filter\n        \"\"\"\n        h = np.zeros_like(t)\n        for i, tt in enumerate(t):\n            if tt==0:\n                h[i] = 1./(2.*beta) * (1. + beta * (4./np.pi - 1.))\n            else:\n                arg = (np.pi/beta * (1. + beta/4.)) * tt\n                h[i] = 1./np.pi * (\n                    np.sin(arg) + (1. - beta/4.) * np.cos(arg))\n        return h\n```"
"The PAM2QAM class in Sionna is used for the mapping of a binary tensor to a QAM constellation. Here is how it is described in the provided context:\n\nThis class implements a mapping from two PAM constellation symbols to a QAM constellation symbol. It can be used to create a custom PAM constellation diagram with possibly different real and imaginary symbol mappings. The class is implemented as a Keras layer.\n\nParameters\n\n- `gray` (bool): If true, QAM constellation is in Gray ordering.\n- `seed` (int): Seed for the random generator to generate the QAM constellation. Different seed values lead to different constellations.\n- `keep_state` (bool): If True, the internal RNG state is returned and/or reused. This is useful when one wants to generate multiple parallel streams of uncorrelated constellations.\n- `pam_levels` (int): Number of PAM levels. It has to be a power of two.\n- `normalize` (bool): If True, the constellation is normalized to an average energy of one across the real and imaginary dimensions.\n\nInput\n\n- `b` ([,n], tf.float32): Tensor with PAM symbol indices.\n\nOutput\n\n- `x` ([,n/2], tf.complex): Tensor with the mapped QAM constellation symbols. \n\nIt helps in the mapping of higher order PAM constellations to QAM constellation. This practice reduces the complexity of the system. \n\nBy using this class in your code, you can create a custom 5G NR PUSCH Transmitter using a series of QAM Interleaver, Mapper, and other components. This helps in the simulation of 5G transmissions and in the analysis of their performance in a wireless communication context."
"To configure StreamManagement for a simple uplink scenario using Python, you need to define the variables `num_tx`, `num_rx`, `num_streams_per_tx`, and the array `rx_tx_association`. \n\nHere is the Python code to do so:\n\n```python\nimport numpy as np\nnum_tx = 4  # Number of transmitters\nnum_rx = 1  # Number of receivers\nnum_streams_per_tx = 1  # Number of streams per transmitter\nrx_tx_association = np.zeros([num_rx, num_tx]) + np.infer({\"value\": 0, \"dtype\": rx_tx_association.dtype})\nrx_tx_association[0, 0] = 1\nrx_tx_association[0, 1] = 1\nrx_tx_association[0, 2] = 1\nrx_tx_association[0, 3] = 1\n# rx_tx_association[i, j] = 1 implies that stream \"i\" of transmitter \"j\" is\n# associated with a receiver\n```\n\nIn this code, `num_tx` represents the number of transmitters, `num_rx` represents the number of receivers, and `num_streams_per_tx` represents the number of streams that each transmitter sends. `rx_tx_association` is an array that specifies which transmitters and receivers are associated with each other. If `rx_tx_association[i, j]` is equal to 1, it means that the transmitter `j` is associated with the receiver `i`.\n\nPlease ensure that the `numpy` library is installed in your Python environment to be able to run this code. You can install it using pip:\n\n```python\npip install numpy\n```\n\nThis code is based on the context provided, which doesn't mention the specific StreamManagement class or how to configure it. If there was a proper mention in the context about how to configure the StreamManagement for an uplink scenario, this code would have been different."
"In the context of higher order modulation, constellations and bit-channels are two key concepts. \n\nConstellations refer to the pattern of signal points in the in-phase/quadrature (I/Q) diagram of a modulation scheme. In higher order modulation, signals are not limited to two possible values (0 or 1) but rather to a set of possible values. The constellation defines the possible signal points that can be used for modulation. \n\nA bit-channel, on the other hand, refers to the channel that transmits binary data from one point to another. This data is represented as bits (0 or 1). \n\nIn higher order modulation, data symbols (corresponding to bits) are mapped to points in the constellation before being transmitted over the bit-channel. Similarly, at the receiver, the received signal, which is the result of passing the transmitted signal through the bit-channel, is demapped back to data bits. \n\nThe key idea in higher order modulation is that it allows for multiple data bits to be transmitted with each modulation symbol, thereby increasing the data rate without changing the bandwidth. The quality of the link (and thus the achievable data rate) is no longer solely determined by the bit-error rate of the bit-channel, but also by the understanding (or lack thereof) of the constellation at the receiver."
"The pam function in the sionna mapping is used for the normalization of a vector to a given norm. In the context, it is used in the mapping module of sionna. \n\nThe function is defined as follows: `pam(x, num_bits=2, const_length=None, axis=-1)` \n\nAnd here is the function's output: `y, b`\n\n- `x` is the input vector that needs to be normalized.\n- `num_bits` is the desired number of bits for the output (e.g., each value of `x` will be quantized to `num_bits` bits). This argument is mutually exclusive with `const_length`.\n- `const_length` defines the length of the constellation. This argument is mutually exclusive with `num_bits`.\n- `axis` indicates the axis that should be reduced during the normalization. \n\nThe function outputs two things. First output, `y`, is the normalized vector. For example, if `x` is a real-valued vector, it will be normalized to have unit energy. The second output, `b`, is the binary representation of `y`.\n\nPlease note that the proper use of this function in the mapping module would require an actual instance of the `Constellation` object, which is not provided in the context. However, from the context, we can see that this function is used with `Constellation` object where `constellation.type` is 'qam'. \n\nHere is an example of how to use the function with the correct `Constellation` object:\n\n```python\nconst = sn.mapping.Constellation(\"qam\", num_bits_per_symbol=2)\nx = tf.complex( tf.random.normal([num_points], dtype=tf.float32),\n                tf.random.normal([num_points], dtype=tf.float32) )\nx /= tf.norm(x, axis=-1, keepdims=True)\ny, b = pam(x, const=const)\n```\n\nIn this example, `num_points` would be the number of elements in your `x` vector."
"To use the \"List2LLR\" class in the Sionna package, the following assumptions should be fulfilled:\n\n1. You should have access to the Sionna package and its components in Python. This includes the List2LLR class itself, as well as other classes such as the FECConvDecoder or SCDecoder that make use of the List2LLR class.\n\n2. You should ensure that the `List2LLR` class is initialized with inputs that meet the conditions of the associated functions. For instance, when initializing `List2LLR` you should provide the number of input parallel streams and the number of output bits per stream. \n\nHere's an example of how you might instantiate a List2LLR object in your code, based on the above assumptions:\n\n```python\nfrom sionna.fec.conv import List2LLR\n\nlist2llr = List2LLR(num_inputs=2, num_bits_per_symbol=2)\n```\n\nWhere `num_inputs` is the number of input parallel streams and `num_bits_per_symbol` is the number of bits per constellation point. These values are appropriate for a 2x2 QAM constellation, which is a four-point constellation.\n\n3. The class functions `hatllr2mic` and `extllr2mic` assume that the LLRs (`mi` and `ext` respectively) are for all digits of the channel. This means that these functions will only work correctly if soft-symbols (LLRs) of all digits are available in the given tensor.\n\nHere's an example of how you might use the `List2LLR` object to convert logits into LLRs:\n\n```python\nimport tensorflow as tf\n# Assuming y_hat and no are tensors defined with channel output information\n# They represent the channel output and the noise variance estimate, respectively\nllr = list2llr([y_hat, no])\n```\n\nPlease note that the actual code usage may vary based on the specific requirements of your application."
"The `MMSEPICDetector` class in the Sionna MIMO API is used for Equalization in Passive Interference Cancellation (PIC) Multi-Input Multi-Output (MIMO) systems. It applies Minimum Mean Square Error (MMSE) equalization in an iterative fashion, making it suitable for both single- and multi-cell scenarios.\n\nThe required parameters for instantiating a `MMSEPICDetector` object are `output`, `intervene`, and `k`. The `output` parameter is a function or None that is used to get or set thejson, `intervene` is a string that stands for the intervened channel, and `k` is an integer for the number of detection iterations to perform. Optional parameters are `scenario`, `d`, `dtype`, and `**kwargs`. The `scenario` parameter is used to set the specific simulation scenario, `d` is used to indicate the stream management in both uplink and downlink, and `dtype` is used to set the datatype for internal calculations and the output.\n\nThe `MMSEPICDetector` can be used under the following conditions:\n1. It can be used for detection in both uplink and downlink scenarios with or without precoding.\n2. It can be used with arbitrary channel models.\n3. It can be used with inteleaved or not-interleaved Least Significant Bit (LSB) first or Most Significant Bit (MSB) first as the desired data-carrying input.\n4. It can be used with or without channel estimation.\n5. It can implement a finite length equalizer followed by a detector.\n\nNote that the `MMSEPICDetector` class is not used as a standalone block in the signal processing pipeline. It must be associated with a transmitter and a receiver. This is done by creating a `LDMSEqualizer` and a `GMModel` and passing them to the `LDMSEPICDetector` when instantiating it. These, along with the channel, are used to recover the transmitted streams from the receiver."
"The QAM2PAM class within the Sionna API, serves to transform quadrature amplitude modulation (QAM) symbol indices to pulse amplitude modulation (PAM) symbol indices. This is a process known as demapping in the field of digital communications. \n\nHere is how it is defined:\n\n```python\nclass QAM2PAM:\n    def qam2pam(self, ind_qam, num_bits):\n        # Compute the PAM symbol indices corresponding to the QAM symbols\n        ind_pam = tf.reshape(ind_qam, [-1, 2, num_bits//2])\n        ind_pam = tf.cast(ind_pam, tf.int32)\n        ind_pam = tf.reduce_sum(2**tf.cast(10*num_bits//2-1, tf.int32) *\n                      ind_pam, axis=-1)\n        return ind_pam\n```\n\nThis transformation process involves reshaping the matrix of QAM symbol indices into a shape that can be interpreted as PAM symbol indices. It also involves a conversion process where the two separate streams of bits for the in-phase and quadrature components of the QAM symbol are combined into a single stream of bits.\n\nThe class accepts a tensor of QAM symbol indices (`ind_qam`) and the number of bits per QAM symbol (`num_bits`). The operation `qam2pam` is used to transform these into a tensor of PAM symbol indices. \n\nIt's important to note that this transformation process is specific to the type of modulation being used (in this case, QAM and PAM). Other types of modulation, such as phase shift keying (PSK) or frequency shift keying (FSK), would require different approaches and classes. \n\nThe QAM2PAM class also includes a corresponding method for transforming PAM symbol indices to QAM symbol indices, which is called `pam2qam`. This method is used to transform a tensor of PAM symbol indices back to a tensor of QAM symbol indices."
"To use the Python package Sionna's \"verify_gm_pcm\" function to check that the generator matrix and parity-check matrix are orthogonal in GF(2), you need to follow the steps below:\n\n1. First, you should import the necessary packages. This includes Sionna, numpy, and tensorflow. \n\n```python\nimport sionna\nimport numpy as np\nimport tensorflow as tf\n```\n\n2. Initialize the STBCM encoder with the desired parameters. This includes the number of information bits per codeword (k) and the codeword length (n). \n\n```python\nk = 16\nn = 32\nencoder = sionna.fec.linear.stbcm.LinearSTBCM(k, n)\n```\n\n3. Initialize the generator matrix (gm) and parity-check matrix (pcm) using the \"gm\" and \"pcm\" attributes of the encoder.\n\n```python\ngm = encoder.gm\npcm = encoder.pcm\n```\n\n4. Next, you should generate a random binary tensor of shape [num_rows, num_cols]. \n\n```python\n# Consider random_binary_tensor as a placeholder for a random binary tensor.\n# Define random_binary_tensor as a binary tensor with arbitrary shape\n# that aligns with the shape of the generator matrix gm.\nnum_rows = 10\nnum_cols = 32\nrandom_binary_tensor = tf.random.uniform((), minval=0, maxval=2, dtype=tf.int32)\nrandom_binary_tensor = tf.stack(\n    [tf.cast(x, dtype=tf.float32) for x in tf.range(random_binary_tensor, dtype=tf.float32)],\n    axis=0)\nrandom_binary_tensor = tf.ensure_shape(random_binary_tensor, (num_cols,))\n```\n\n5. Now, you can use the \"verify_gm_pcm\" function from the sionna package to check if the generator matrix and parity-check matrix are orthogonal.\n\n```python\n# The function returns a tuple of booleans indicating if GM and/or PCM\n# are valid or not. \n# It is assumed that gm and pcm are valid to begin with.\nverify_results = sionna.fec.utils.verify_gm_pcm(gm, pcm)\nprint(\"Generator Matrix Verified:\", verify_results[0])\nprint(\"Parity-check Matrix Verified:\", verify_results[1])\n```\n\n6. Finally, the print statements will output the results of the verification process. If both matrices are valid, the statements will print True; otherwise, they will print False.\n\nPlease ensure that the Sionna package is correctly installed in your environment to be able to use the \"verify_gm_pcm\" function. If it's not installed, you can install it via pip:\n\n```python\npip install sionna\n```\n\nThe \"verify_gm_pcm\" function is part of the sionna.fec.utils module, which is why it's important to import the necessary classes from the sionna package as shown in the code snippets above. This function is used to check if the generator matrix and parity-check matrix are orthogonal, which is essential in the field of linear error-correcting codes for ensuring their proper functioning."
"To import the `LinearEncoder` class from the `sionna.fec.linear` module, you can use the following line of Python code:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n```\n\nThis statement will make the `LinearEncoder` class available in your current Python namespace, allowing you to instantiate an encoder object for use in your project."
"The `OFDMDetectorWithPrior` class is part of Sionna's OFDM module and is used for receiving Orthogonal Frequency-Division Multiplexing (OFDM) signals. This class assumes the use of a cyclic prefix and some kind of interleaver, and most importantly, it assumes that the detector can be fed with both the received signal and prior information of the transmitted data.\n\nThe `OFDMDetectorWithPrior` receives a transmitted signal and potentially prior information about the data as inputs, and it compares the received signal to the expected data, which is calculated taking into account the prior information. This comparison results in updated prior information, represented by LLRs (Log-Likelihood Ratios), that is then forwarded to a channel decoder to further aid in the decoding process.\n\nNote that the instruction provides no direct insights into how the `OFDMDetectorWithPrior` class functions, but based on similar functionality in the context and the behavior of other classes in Sionna, it can be inferred that this class implements a neural network-based receiver and channel estimator. The class preprocesses the channel frequency responses and computes the channel estimates and error variances, which are used to build the received signal model. The prior information of the transmitted data is also incorporated in the process, which can lead to improved performance compared to conventional OFDM receivers."
"The \"bin2int_tf\" function in the Sionna library is used to convert a binary tensor to an integer tensor. Here is how it is used:\n\n```python\nfrom sionna.utils import bin2int_tf\n\n# Assume `binary_tensor` is a binary tensor of 0's and 1's.\n# `binary_tensor` can be a tf.float32 tensor instead of a tf.int64 tensor.\nint_tensor = bin2int_tf(binary_tensor)\n```\n\nIn the above code, first, you need to import the necessary function from the Sionna library. Then, you pass your binary tensor to the \"bin2int_tf\" function as an argument. The \"bin2int_tf\" function will return an integer tensor that has the same shape as the binary tensor.\n\nRemember that the binary tensor should only contain 0's and 1's, and the tensor data type should be tf.float32 or tf.int64. The binary tensor is effectively a binary representation of the integer tensor, where the last dimension is assumed to be the least significant one."
"The `TB5GScrambler` in Sionna's `scrambling` module is used to enable json-compliant scrambling as per the 3GPP 38.211 standard. This standard provides specifications for the physical channels and signals for 5G New Radio (NR).\n\nHere is a basic usaage of `TB5GScrambler`:\n\n```python\nfrom sionna.scrambling import TB5GScrambler\n\nscrambler = TB5GScrambler(init_state=0, # define the sequence intitially, can be any number\n                          # define the sequence via 'sequence'\n                          sequence=[1,0,0,1,1,0]) \n                          n_rnti=1) # scrambling ID\n```\nThe parameters `init_state` and `sequence` are used to define the sequence either through the initial state of the scrambler or directly providing the sequence. `n_rnti` is the RNTI, or Radio Network Temporary Identifier. \n\nTo scramble a sequence `c` of 0's and 1's, you call the `scrambler` instance with `c` as the argument:\n\n```python\nc_scr = scrambler(c)\n```\n\nIf you want to descramble a sequence, you use the `TB5GDescrambler` class:\n\n```python\nfrom sionna.scrambling import TB5GDescrambler\n\ndescrambler = TB5GDescrambler(scrambler=scrambler) # uses same parameters as corresponding scrambler\n\nc_descr = descrambler(c_scr) # call with scrambled sequence as argument\n```\nThis will give you the descrambled sequence. \n\nPlease ensure that the correct version of Sionna is installed and located in your environment in order to use these classes, as they are part of the Sionna package."
"Here is the detailed information of int_mod_2: \n\n[sionna.fec.utils.int_mod_2(num)](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#int_mod_2)\n\nModulo 2 operation on integers.\n\nThis function implements the standard \u201cmodulo two\u201d operation for integers: if the input integer is even, the function returns True; otherwise, it returns False. This operation is also known as \u201cinteger parity\u201d or \u201cbit parity\u201d.\n\nInput\n\n   - num (int) \u2013 Integer to be reduced.\nOutput\n\n   - result (bool) \u2013 Modulo-2 operation result.\n\nsource code:\n```python\ndef int_mod_2(num):\n    \"\"\"Modulo 2 operation on integers.\n\n    This function implements the standard \"modulo two\"\n    operation for integers: if the input integer is even,\n    the function returns `True`; otherwise, it returns `False`.\n    This operation is also known as \"integer parity\"\n    or \"bit parity\".\n\n    Input\n    -----\n        num : int\n            Integer to be reduced.\n\n    Output\n    ------\n        result : bool\n            Modulo-2 operation result.\n    \"\"\"\n    return num//2==num/2\n```"
"Here is the detailed information of sionna.utils.SymbolSource:   \n\n[sionna.utils.SymbolSource(num_bits_per_symbol=None, dtype=tf.complex64, seed=None, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/utils/misc.html#SymbolSource)\n\nLayer generating a tensor of random OFDM resource grid symbols.\n\n**Parameters**\n\n- `num_bits_per_symbol` (int): The number of bits per constellation symbol, or the constellation bits, e.g., 2 for QPSK. Only required if `constellation_type` is \"qam\" or \"custom\". For \"custom\", it is also possible to provide a list of integer constellation points.\n- `dtype` (One of [tf.complex64, tf.complex128], tf.DType): The output dtype. Defaults to tf.complex64.\n- `seed` (int or None): The seed for the random number generator. Two SymbolSource layers with the same seed will generate the same sequence of symbols. Defaults to None.\n\n**Input**\n\n- `batch_size` (int): The batch size. Defaults to None.\n\n**Output**\n\n- `shape = []`, `dtype`: A tensor of shape [batch_size, num_symbols] and dtype as specified by `dtype`. \n\nsource code:\n```python\nclass SymbolSource(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Layer generating a tensor of random OFDM resource grid symbols.\n\n    Parameters\n    ----------\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, or the constellation\n        bits, e.g., 2 for QAM. Only required if ``constellation_type`` is \"qam\"\n        or \"custom\". For \"custom\", it is also possible to provide a list of\n        integer constellation points.\n\n    dtype : One of [tf.complex64, tf.complex128], tf.DType\n        The output dtype. Defaults to tf.complex64.\n\n    seed : int or None\n        The seed for the random number generator. Two ``SymbolSource``\n        layers with the same seed will generate the same sequence of symbols.\n        Defaults to None.\n\n    Input\n    -----\n    batch_size : int\n        The batch size. Defaults to None.\n\n    Output\n    ------\n    : : [``batch_size``, ``num_symbols``], ``dtype``\n        A tensor of shape [batch_size, num_symbols] and dtype as specified by\n        ``dtype``.\n    \"\"\"\n    def __init__(self,\n                 num_bits_per_symbol=None,\n                 dtype=tf.complex64,\n                 seed=None,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        self._config = Config(num_bits_per_symbol, seed)\n\n    def call(self, batch_size):\n        return generate_random_symbols(batch_size,\n                                       self._config,\n                                       self.dtype)\n```"
"Here is the detailed information of ChannelModel:   \n  \n[sionna.channel.ChannelModel](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel)  \n  \nAbstract class that defines an interface for channel models.\n\nAny channel model which generates channel impulse responses must implement this interface. All the channel models available in Sionna, such as RayleighBlockFading or TDL, implement this interface.\n\nRemark: Some channel models only require a subset of the input parameters.  \n  \nInput\n    batch_size [int]: Batch size.\n    num_time_steps [int]: Number of time steps.\n    sampling_frequency [float]: Sampling frequency in Hertz (Hz).\n\nOutput\n    a [shape=(batch_size, num_receivers, num_receiver_antennas, batch_of_channel_outputs), dtype=tdtype] or [shape=(batch_size, num_receivers, num_receiver_antennas, num_senders, num_sender_antennas, batch_of_channel_outputs), dtype=tdtype]\n        Path coefficients\n\n    tau [shape=(batch_size, num_receivers, num_senders), dtype=tdtype]\n        Path delays in seconds (s)\n\n**Note: **  \nChild classes of ChannelModel only require the parameters specific to the implemented channel model. For example, the RayleighBlockFading class only requires the block fading parameters block_mean and block_variance. There is no need for the input parameters batch_size, num_time_steps, sampling_frequency.  \n  \nsource code:  \n```python\nclass ChannelModel(ABC):\n    # pylint: disable=line-too-long\n    r\"\"\"ChannelModel is an abstract class for implementing an interface for channel models.\n\n    Any channel model which generates channel impulse responses must implement this interface.\n    All the channel models available in Sionna, such as :class:`~sionna.channel.OFDMChannel` or\n    :class:`~sionna.channel.RayleighBlockFading`, implement this interface.\n\n    Remark: Some channel models only require a subset of the input parameters.\n    For example, the :class:`~sionna.channel.RayleighBlockFading` class only requires\n    the block fading parameters ``block_mean`` and ``block_variance``.\n    There is no need for the input parameters ``batch_size``, ``num_time_steps``,\n    ``sampling_frequency``.\n\n    Input\n    ------\n    batch_size : int\n        Batch size\n\n    num_time_steps : int\n        Number of time steps\n\n    sampling_frequency : float\n        Sampling frequency in Hertz (Hz)\n\n    Output\n    ------\n    a : shape=[batch_size, num_receivers, num_receiver_antennas, batch_of_channel_outputs], dtype=tdtype  or  [batch_size, num_receivers, num_receiver_antennas, num_senders, num_sender_antennas, batch_of_channel_outputs], dtype=tdtype\n        Path coefficients\n\n    tau : shape=[batch_size, num_receivers, num_senders], dtype=tdtype\n        Path delays in seconds (s)\n    \"\"\"\n\n    @property\n    def supports_frequencies(self):\n        r\"\"\"This property indicates if the generation of frequency responses is supported.\n\n        Abstract channel models doesn't support  the generation of frequency responses.\n\n        Returns\n        -------\n        False\n        \"\"\"\n        return False\n\n    @abstractmethod\n    def __call__(self, batch_size, num_time_steps, sampling_frequency):\n        # pylint: disable=line-too-long\n        r\"\"\"__call__ is an abstract method that must be implemented by a class implementing this interface.\n\n        Input\n        ------\n        batch_size : int\n            Batch size\n\n        num_time_steps : int\n            Number of time steps\n\n        sampling_frequency : float\n            Sampling frequency in Hertz (Hz)\n\n        Output\n        ------\n        a : shape=[batch_size, num_receivers, num_receiver_antennas, batch_of_channel_outputs], dtype=tdtype  or  [batch_size, num_receivers, num_receiver_antennas, num_senders, num_sender_antennas, batch_of_channel_outputs], dtype=tdtype\n            Path coefficients\n\n        tau : shape=[batch_size, num_receivers, num_senders], dtype=tdtype\n            Path delays in seconds (s)\n        \"\"\"\n        pass\n```  \n  "
"To build a custom `RadioMaterial` in Sionna, you can follow these steps:\n\n1. Import the necessary modules and classes.\n\n```python\nfrom sionna.rt import RadioMaterial\n```\n\n2. Create a custom radio material. In Sionna, a radio material is defined by its relative permittivity and conductivity. The radio material `CustomRadioMaterial` is created with a relative permittivity of 2.0 and a conductivity of 5.5. These values are used as an example and can be adjusted based on your needs.\n\n```python\ncustom_radio_material = RadioMaterial(\\\n    relative_permittivity=2.0,\n    conductivity=5.5)\n```\n\n3. Add the custom radio material to a Sionna `SceneObject`. All `SceneObject`s have a property called `radio_material`. This property can be assigned the custom radio material that you created.\n\n```python\nscene_object = SceneObject(name=\"Scene_Object_1\")\nscene_object.radio_material = custom_radio_material\n```\n\nPlease note that the `SceneObject` class is part of the Sionna RT API. You would typically load a scene from a file, manipulate its contents, and then re-save it. When loading a scene, you can preview it, or render it to a file or to a renderer.\n\nTo demonstrate how to build a custom `RadioMaterial` and attach it to a `SceneObject`, you need to have access to the code that creates or loads the scene. This is not provided in the context. If you have such code, you can follow the steps outlined above."
"In order to perform Maximum A Posteriori (MAP) decoding using the `BCJRDecoder` instance from the Sionna package, we need to follow a specific set of steps. We will assume that we have an instantiated `BCJRDecoder` instance named `decoder`. We will also cover the possible inputs that the `BCJRDecoder` instance can take and explain what the `hard_out` parameter signifies, along with specifying the type and shape of the output tensor.\n\n### Input(s) to BCJRDecoder\n\nThe `BCJRDecoder` instance can take two possible types of input:\n\n1. `llr_ch`: It is a LLR (Log-Likelihood Ratio) tensor for the communication channel.\n2. `llr_ch, llr_a`: In case of an attempt to do list decoding, the decoder can take two inputs. The second input `llr_a` is a LLR tensor corresponding to the a priori information.\n\n### Meaning of `hard_out`\n\nThe `hard_out` parameter in the `BCJRDecoder` instance refers to the operation of the decoder. When `hard_out=True`, the decoder will output hard decisions (values of type `tf.float32`). These are essentially the decided (i.e, final) bits of the decoded message. When `hard_out=False`, the decoder will output soft-values, which are Log-Likelihood Ratios (LLRs) or Erasures for each bit position of the codeword.\n\n### Output Tensor from BCJRDecoder\n\nThe output from the `BCJRDecoder` instance is a tensor of decided bits (`hard_decisions`) or LLR values (`soft_estimates`), depending on the `hard_out` parameter. The shape of the output tensor will be equal to the second dimension of the input tensor. If `hard_out=True`, the output type will be `tf.float32`, and if `hard_out=False`, the output type will be `tf.float32`. \n\n### Steps to perform MAP Decoding\n\nTo perform MAP decoding using the `BCJRDecoder` instance, we need to follow these steps:\n\n1. **Note**: The `BCJRDecoder` class is not as of now directly usable as an layer with the Keras models. We might need to use the `@tf.function(jit_compile=True)` decorator to compile the function into a TensorFlow graph before using it.\n\n2. Create the BCJRDecoder instance with the necessary parameters including the LDPC code parameters and the type of decoder (`bp` or `mp`).\n\n3. Provide the input to the decoder. If `hard_out=True`, provide only the LLRs for the communication channel. If `hard_out=False`, provide both the LLRs for the communication channel and the a priori information.\n\n4. The decoder will perform the MAP decoding algorithm on the input and provide the output as described above.\n\n5. You can use the decoder within a Keras model or outside it as needed. Just ensure that you set the `keros_compat` parameter to `False` when instantiating the `LDPCBPDecoder` instance if you intend to use it within a Keras model.\n\nHere is a simplified example of how you might use the `BCJRDecoder`:\n\n```python\nfrom sionna.fec.ldpc.decoding import BCJRDecoder\n\n# Assume we have the LDPC parameters already defined (n, k, the parity-check matrix)\n\ndecoder = BCJRDecoder(tipi=\"map\", # can be \"app\" as well\n                      pcm=pcm,                      \n                      hard_out=True) # Or False\n\n# Assuming llr_ch and llr_a are the channel and apriori inputs respectively\n# Channel LLRs only needed if `only_llr_ch`=True, otherwise llr_a also needed.\nif decoder.hard_out:\n    llr_ = llr_ch\nelse:\n    llr_ = (llr_ch, llr_a)\n\ndecoded_data = decoder(llr_)\n```\n\nIn this code snippet, you'd replace `llr_ch` and `llr_a` with your actual LLR values. Remember, if `hard_out=True`, you only need to provide the `llr_ch` values."
"The `ebnodb2no` function in the `sionna.utils` module is used to compute the variance of Additive White Gaussian Noise (AWGN) given the bit/energy to noise density ratio (Eb/No) in dB and a bunch of other parameters. Here is how to use it:\n\n1. Make sure to import the required module:\n```python\nfrom sionna.utils import ebnodb2no\n```\n\n2. You will need to specify a value for Eb/No in dB. This is a scalar value or a value that can be broadcast to the shape of `no`, which is a boolean or a tensor indicating whether you want to consider the bit-to-energy density ratio $E_b/N_0$ or the energy of the transmitted signal $E_s$ alone. In most cases, it is just a scalar value. For example:\n```python\nebno_db = 3.0\n```\n\n3. You need to provide a value for `num_bits_per_symbol`, which is an integer indicating the number of bits per constellation symbol (e.g., 4 for QAM16). For example:\n```python\nnum_bits_per_symbol = 4\n```\n\n4. Finally, you should provide the mode, which is a string indicating whether you are providing Eb/No in dB or Es/N0 in dB. For the former, you should use \"ebno\" and for the latter, you should use \"esno\". For example:\n```python\nmode = \"ebno\"\n```\n\nNow, let's go through what each parameter means:\n\n- `ebno_db`: This is the Eb/No value in dB. It represents the energy per bit to noise power spectral density ratio. It can be either a scalar or a tensor.\n\n- `num_bits_per_symbol`: This is the number of bits per constellation symbol. For instance, it would be 4 for QAM16, as QAM16 has symbols like 0000, 0001, 0011, 0101, ... and each symbol is represented by 4 bits.\n\n- `mode`: This is a string that indicates the type of Eb/No. It can be either \"esno\" or \"ebno\". \"esno\" is used when a custom `snr` is provided, which is calculated from Es (energy per symbol) and No (noise power spectral density). \"ebno\" is used when the more conventional Eb/No value is provided.\n\nThere is one more input: `no`. Depending on whether you are providing `ebno` or `esno`, `no` is either a scalar or a tensor. It should be a tensor of the same shape as the output signal.\n\nThe function returns `no`, which is the noise variance. It has the same shape as the input signal. `no` can be a scalar or broadcast with the shape of `x`. `no` is computed by converting Eb/No from dB to linear scale and then dividing by the number of bits per symbol. If `esno` mode is selected, `no` is computed using the energy per symbol and the noise power spectral density."
"To evaluate the baseline and the two autoencoder-based communication systems, follow these steps:\n\n1. **Baseline Model**: This model is a reference model that does not use autoencoders. It transmits bits using a binary source, maps them to BPSK symbols, and then uses an AWGN channel to transmit the symbols. After receiving the transmitted signal, it uses a demapper to produce Log-Likelihood Ratios (LLRs), which are used by a channel decoder to recover the original message.\n\n2. **Autoencoder-based Communication Systems**: The first autoencoder-based communication system is called `AEC System I`. It uses binary layer-wise pre-coding of the transmitted bits to the receiver, which is then successively canceled. The second autoencoder-based communication system is called `AEC System II`. It uses discrete constellation representations and annealed flipping for training.\n\nTo evaluate these systems, use the Bit Error Rate (BER) and Block Error Rate (BLER) functions provided by the `utils` module. These functions compute the error rates by simulating the transmission of a large number of batches of bits through the systems and comparing the transmitted bits with the received bits. The error rates can be printed or logged, allowing you to compare the performance of the different systems under different conditions.\n\nHere is an example of how to use these functions:\n\n```python\nmodel = BaselineModel(k, n, ebno_dbs)\nber, bler = simulate_ber_bler(model, snr_db=ebno)\n```\n\nIn this example, `k` is the number of information bits per codeword, `n` is the codeword length, and `ebno_dbs` is a list of the Eb/No values in dB over which to simulate the BER and BLER. The `simulate_ber_bler` function returns the BER and BLER for each Eb/No value, allowing you to plot the error rate performance over a range of SNR values.\n\nRemember to ensure that the models and systems are correctly instantiated and trained before calling the `simulate_ber_bler` function. The provided context does not include the exact code for these steps, as it focuses on the implementation of the Sionna package."
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, follow these steps:\n\n1. Import the necessary modules:\n```python\nimport os\nimport tensorflow as tf\n```\n\n2. Specify the GPU you want to use. If you want to use the CPU, set `gpu_num` to an empty string (\"\"). In this example, we're using the first GPU, so we set `gpu_num` to 0:\n```python\ngpu_num = 0\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n```\n\n3. Set the TensorFlow log level to 3 to see all GPU allocations:\n```python\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n4. Get the list of all available GPUs:\n```python\ngpus = tf.config.list_physical_devices('GPU')\n```\n\n5. If GPUs are available, configure TensorFlow to use only the first one and allocate only as much memory as needed:\n```python\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\nIn the above code, `tf.config.experimental.set_memory_growth` is used to enable memory growth for the selected GPU. When memory growth is enabled, TensorFlow allocates only as much GPU memory as needed for the runtime allocations: it starts out allocating very little memory, and as the program gets much more GPU memory, TensorFlow extends its GPU memory, fulfilling the runtime allocations."
"To use the \"j_fun\" function to calculate the J-function in the Sionna package, do the following steps:\n\n1. First, import the required modules and functions.\n\n```python\nfrom sionna.j_function import j_fun\n```\n\n2. Calculate the J-function. The \"j_fun\" function takes two input parameters:\n\n    a. `x` - a tensor of arbitrary shape. This is the input you want to transform into the J-function.\n    \n    b. `number_of_terms` - an integer representing the number of kept partial sums in the (inverse) Fourier transform.\n    \n3. Call the \"j_fun\" function with your input parameters. \n\n```python\nj = j_fun(x, number_of_terms)\n```\n\nPlease note that you need to replace `x` and `number_of_terms` with your actual variables.`x` should be a tensor, and `number_of_terms` should be an integer. The function will return another tensor, `j`, of the same shape as the input tensor `x`. `j` contains the result of the J-transform of `x`. \n\nBe careful when choosing the value for `number_of_terms`. A larger value will result in better precision but will require more computational resources. \n\nAlso, note that the input tensor `x` can be a real-valued tensor (tf.float32), which represents the time signal. However, the output tensor `j` is generally complex-valued, except for when `x` is purely real, in which case `j` is equivalent to a real tensor."
"Here is the definition of PUSCHTransmitter: sionna.nr.PUSCHTransmitter(pusch_configs, return_bits=True, output_domain='freq', dtype=tf.complex64, verbose=False, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/nr/pusch_transmitter.html#PUSCHTransmitter)  \n\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"PUSCH Transmitter for the nr (5G) sub-package of the Sionna library.\n\"\"\"\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Layer\nfrom sionna.mimo import AWGNChannel\nfrom sionna.utils import expand_to_rank, validate_output_domain\nfrom sionna.ofdm import ResourceGrid, DCNullRemoved, PilotPattern, KroneckerInterpolator\nfrom sionna.utils import to_binary, QAMSource\nfrom .pusch_configs import PUSCHConfig\n\n\nclass PUSCHTransmitter(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"PUSCHTransmitter(pusch_configs, return_bits=True, output_domain=\"freq\", dtype=tf.complex64, verbose=False, **kwargs)\n\n    Creates a 5G NR PUSCH Transmitter which assembles and pre-codes batches\n    of 5G NR PUSCH slots or mini-slots in the frequency domain.\n\n    The transmitter follows the procedures as defined in Sec. 6.3 and Sec.\n    6.4 [3GPP38211]_ and makes use of various configuration objects, e.g.,\n    :class:`~sionna.nr.PUSCHConfig`, :class:`~sionna.nr.CarrierConfig`,\n    :class:`~sionna.nr.SubCarrierSpacing`, :class:`~sionna.nr.NRPanel`,\n    :class:`~sionna.mimo.Precoder`, :class:`~sionna.ofdm.ResourceGrid`,\n    :class:`~sionna.ofdm.DCNullRemoved`, and :class:`~sionna.ofdm.PilotPattern`.\n    The ``pusch_config`` parameter aggregates configuration objects for\n    PUSCH.\n\n    Parameters\n    ----------\n    pusch_configs : :class:`~sionna.nr.PUSCHConfig`\n        An instance or list of the :class:`~sionna.nr.PUSCHConfig` object(s)\n        which define the configuration for the PUSCH transmission.\n\n    return_bits : bool\n        If enabled, the `PUSCHTransmitter` generates and returns pairs of\n        bitstreams corresponding to the sequence of OFDM symbols and slots\n        to be generated. Defaults to `True`.\n\n    output_domain : One of [\"freq\", \"time\", \"none\"]\n        Determines the output domain of the generated signal.\n        If \"freq\", the output is a single OFDM resource grid.\n        If \"time\", the output is a time-domain signal.\n        If \"none\", no output is generated.\n        Defaults to \"freq\".\n\n    dtype : One of [tf.complex64, tf.complex128], tf.DType\n        Defines the datatype for internal calculations and the output\n        dtype. Defaults to ``tf.complex64``.\n\n    verbose : bool\n        If `True`, additional parameters are printed during initialization.\n        Defaults to `False`.\n\n    Input\n    -----\n    : [batch_size, num_pusch_symbols, num_pusch_dmrs_ports, num_pusch_layers, num_dmrs_occasions, num_subcarriers, num_ofdm_symbols], tf.complex\n        Frequency-domain inputs to the: PUSCH transmitter. The last three\n        dimensions are optional and by default set to 0.\n        The absolute value of the last dimension is interpreted as the\n        resource grid for the first layer. If ``precoding=\"multi\"``, a\n        separate resource grid for each layer needs to be provided.\n\n    Output\n    ------\n    : [batch_size, num_ant, num_ofdm_symbols, fft_size], tf.complex\n        Time-domain signal\n\n    : [batch_size, num_ant, num_carriers, num_ofdm_symbols], tf.complex\n        Frequency-domain signal\n\n    Note\n    ----\n    The :class:`~sionna.nr.PUSCHTransmitter` is typically used in one of\n    the following modes:\n\n    * \"freq\": for simulations that operate in the frequency domain.\n    * \"time\": for simulations that operate in the time domain.\n\n    Examples\n    --------\n    >>> pusch_config = PUSCHConfig(n_layers=1,\n    ...                             n_mss=1,\n    ...                             precoding=\"noncodebook\",\n    ...                             modulation_order=16,\n    ...                             coding_config=coding_config)\n    >>> pusch_transmitter = PUSCHTransmitter(pusch_config)\n    >>> bits = pusch_config.codeword_length * [0]\n    >>> x = pusch_transmitter(bits)\n    >>> x_freq = pusch_transmitter(x)\n    \"\"\"\n    def __init__(self,\n                 pusch_configs,\n                 return_bits=True,\n                 output_domain=\"freq\",\n                 dtype=tf.complex64,\n                 verbose=False,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        if isinstance(pusch_configs, PUSCHConfig):\n            pusch_configs = [pusch_configs]\n        self._pcs = []\n        self._cb = []\n        self.resource_grid = []\n        for pusch_config in pusch_configs:\n            self._pcs.append(pusch_config.pusch_config)\n            self._cb.append(pusch_config.coding_config.cb)\n            self.resource_grid.append(pusch_config.resource_grid)\n        self._precoding = pusch_configs[0].precoding\n        self._remove_nulled_subcarriers = pusch_configs[0].remove_nulled_subcarriers\n        self._scs = pusch_configs[0].scs\n        self._n_rnti = None\n        self._tx_nr = None\n        self.return_bits = return_bits\n        self._output_domain = output_domain\n        self._dtype = dtype\n        self._verbose = verbose\n        self.build_pusched_data_generators()\n\n    @property\n    def pcs(self):\n        \"\"\"List of physical channel (PUSCH) configuration objects.\"\"\"\n        return self._pcs\n\n    @property\n    def cb(self):\n        \"\"\"List of codebook objects.\"\"\"\n        return self._cb\n\n    @property\n    def resource_grid(self):\n        r\"\"\"List of resource grids that define the PUSCH transmissions.\n\n        Only required for when ``output_domain=\"freq\"`` or ``output_domain=\"time\"``.\n        \"\"\"\n        return self._resource_grid\n\n    @resource_grid.setter\n    def resource_grid(self, value):\n        if value:\n            for rg in value:\n                self._resource_grid.append(rg)\n        else:\n            self._resource_grid = value\n\n    @property\n    def scs(self):\n        r\"\"\"List of sub-carrier spacings that define the PUSCH transmissions.\n\n        Only required for when ``output_domain=\"freq\"`` or ``output_domain=\"time\"``.\n        \"\"\"\n        return self._scs\n\n    @scs.setter\n    def scs(self, value):\n        if value:\n            for sc in value:\n                self._scs.append(sc)\n        else:\n            self._scs = value\n\n    @property\n    def n_rnti(self):\n        \"\"\"List of RNTI identifier for the PUSCH transmissions.\"\"\"\n        return self._n_rnti\n\n    @property\n    def tx_nr(self):\n        \"\"\"List of PUSCH numerology objects for the PUSCH transmissions.\"\"\"\n        return self._tx_nr\n\n    @property\n    def remove_nulled_subcarriers(self):\n        \"\"\"Indicates if nulled subcarriers are removed from the resource grid.\"\"\"\n        return self._remove_nulled_subcarriers\n\n    @property\n    def encoding_input_generator(self):\n        \"\"\"Generates info bits batches for the 5G NR PUSCH Transmitter.\"\"\"\n        if self.return_bits:\n            return self._generating_info_bits_batches(\n                self.precoder.coding.coding_config,\n                self.nushf.refi * self._num_prs_periods)\n        else:\n            return None\n\n    @property\n    def scrambling_generator(self):\n        \"\"\"Generates random with a defined length and seed.\"\"\"\n        return self._generating_scrambling_seq(\n            self.n_rnti, self._scrambling_seed, self._scrambling_seq_len)\n\n    @property\n    def precoding_matrices(self):\n        r\"\"\"List of precoding matrices, one for each antenna port.\n\n        Note\n        ----\n        If ``remove_nulled_subcarriers`` is `True`, the precoding matrices\n        are frequency-dependent.\n        \"\"\"\n        if self._remove_nulled_subcarriers:\n            return self._precoding_matrices\n        else:\n            return self.precoder.precoding_matrices\n\n    def build_pusched_data_generators(self):\n        \"\"\"Generates the separate frequency and channel impulse input\n        generators for the prkw to be used in a PUSCH configuration.\"\"\"\n        # Precoding is independent for each antenna port\n        precoding = self._precoding\n        if isinstance(precoding, str):\n            if precoding==\"noncodebook\":\n                noncodebook = True\n            else:\n                noncodebook = False\n        else: # Callable\n            noncodebook = precoding\n        self._precoding = PUSCHPrecoding(noncodebook=noncodebook)\n\n        self._scrambling_seed = ScramblingSeed() # default seed\n        self._scrambling_seq_len = ScramblingSequenceLength(\n                                        self._scrambling_trans_seq) # default len\n\n        # The 5G NR PUSCH Transmitter automatically generates a codeword\n        # for a given PUSCH configuration independent of the input\n        # codeword length. This enables the codeword length to be\n        # automatically selected based on the MCS table without the\n        # transmitter having to compute the MCS index (see Sec. 5.1.3.1\n        # [3GPP38211]_).\n        self._cws_generator = CWSGenerator(self.coding_config)\n\n        # We need one of those for each precoding matrix provided by the CB\n        # to the scrambler. If CB is not used, this list will be empty.\n        self._cws_generators = []\n        for c in self.cb:\n            self._cws_generators.append(self._cws_generator)\n\n        # Down-sampling the sub-carriers is done after precoding.\n        # The number of PRS symbols per PRS period can be greater than two.\n        # In this case, the\n        # sub-carriers corresponding to the last two symbols of the\n        # PRS period are set to zero to avoid aliasing. This is\n        # particular important for a low number of sub-carriers.\n        self._num_prs_periods = max(self.precoder.coding.n_prs_per_subcarrier,\n                                     2)\n\n        # Mapping from symbol indices to sub-carrier indices\n        self._symbol_to_subcarrier = {}\n        subcarrier_ind = 0\n        for rg in self.resource_grid:\n            for smbs in rg.pusch_symbol_map:\n                for smb in smbs:\n                    self._symbol_to_subcarrier[subcarrier_ind] = smb\n                    subcarrier_ind += 1\n\n    def call(self, inputs):\n        ## Remember: PUSCH can be scheduled in future slots.\n\n        # inputs:\n        # x (PRNG): PUSCH inputs provided by the higher layer.\n        # uw (tf.float32): PUSCH inputs provided by the higher layer.\n\n        # Generate info bits and codeword bits\n        if self.return_bits:\n            cw, cw_lengths = self.encoding_input_generator(\n                            [inputs[0].shape[-2], self._num_prs_periods])\n            cw = tf.cast(cw, dtype=self._dtype)\n            prng_seq = self.scrambling_generator(inputs[0].shape[-2:])\n            cw, _ = self._cws_generator([cw, cw_lengths, prng_seq])\n            output = self._precoding([cw, prng_seq])\n        else:\n            prng_seq = self.scrambling_generator(inputs[0].shape[-2:])\n            output = self._precoding([inputs[0], prng_seq])\n\n        # DC null is removed to fit the OFDM waveform to the per PRS pattern.\n        if self._remove_nulled_subcarriers:\n            output = self._dc_null_removed(output)\n\n        # OFDM modulation of the precoded bits\n\n        # The resource grid is frequency-dependent if `remove_nulled_subcarriers`\n        # is enabled. We construct a zero-padded RG and then down-sample\n        # the sub-carriers.\n        output = self._ofdm_modulator(output, self.resource_grid)\n\n        # Frequency-to-time domain conversion\n        if self._output_domain==\"time\":\n            output = self._frequency_to_time_domain(output)\n\n        # Mapping to antenna ports\n        if self._remove_nulled_subcarriers:\n            output = self._mapping_to_antenna_ports(output)\n        return output\n\n    #########################################\n    # Internal utility functions\n    #########################################\n\n    def _dc_null_removed(self, x):\n        r\"\"\"Removes the DC sub-carrier from the resource grid.\n\n        The DC sub-carrier is always the first in an OFDM symbol and is set\n        to zero.\n\n        Args\n        ----\n        x : [batch_size, num_ant, num_ofdm_symbols, fft_size], tf.complex\n            Input OFDM resource grid\n\n        Returns\n        -------\n        x_new : [batch_size, num_ant, num_ofdm_symbols, fft_size-1], tf.complex\n            Resource grid without DC sub-carrier\n        \"\"\"\n        x_new = tf.concat([x[:,:,:,:fft_size//2],\n                      x[:,:,+1:,:fft_size//2]], axis=-1)\n        return x_new\n\n    def _frequency_to_time_domain(self, x):\n        r\"\"\"Transforms the last dimension of `x` to the time domain.\n\n        The OFDM modulation is computed with zeros for the DC and the\n        Nyquist carriers.\n\n        Args\n        ----\n        x : [batch_size, num_ant, num_ofdm_symbols, fft_size], tf.complex\n            Input resource grid\n\n        Returns\n        -------\n        x_new : [batch_size, num_ant, num_time_samples], tf.complex\n            Channel output samples\n        \"\"\"\n        x = tf.pad(x, [[0,0], [0,0], [0,1], [0,1]])\n        x_new = tf.signal.ifft(x)\n        x_new = x_new[...,0*num_ofdm_symbols : num_ofdm_symbols]\n        return x_new\n\n    def _mapping_to_antenna_ports(self, x):\n        r\"\"\"Maps the last dimension of `x` to the antenna ports.\n\n        The resource grid is frequency-dependent if `remove_nulled_subcarriers`\n        is enabled. We create a channel impulse response for each\n        sub-carrier and apply the Kronecker channel model to generate\n        channel outputs for all antenna ports and OFDM symbols.\n\n        Args\n        ----\n        x : [batch_size, num_ant, num_ofdm_symbols, num_subcarriers], tf.complex\n            Input resource grid\n\n        Returns\n        -------\n        x_new : [batch_size, num_ant, num_ofdm_symbols, num_ant_ports, num_time_samples], tf.complex\n            Channel output samples, mapping to antenna ports\n        \"\"\"\n        y = tf.zeros([x.shape[0], x.shape[1], x.shape[2], self._tx_nr.num_ant_ports, x.shape[3]],\n                    dtype=x.dtype)\n\n        num_time_samples = self.resource_grid.num_time_samples\n        for rg, sc in zip(self.resource_grid, self._symbol_to_subcarrier):\n\n            # Generate frequency channel response\n            h = rg.channel_impulse_response()\n\n            # Pad h with zeros to num_time_samples\n            h = tf.pad(h, [[0,0], [0,0], [0,0], [0, num_time_samples-rg.num_time_samples]])\n            h = tf.expand_dims(h, axis=3)\n\n            # Apply channel model\n            y = y + h * sc\n\n        return y\n\n    def _generating_info_bits_batches(self, codeword_length, batch_size):\n        r\"\"\"Generates batches of random information bits.\n\n        The noise is generated using a bijective GBN to ensure randomess of the\n        output given imbalanced quantization is used.\n\n        Arguments\n        ---------\n        codeword_length : int\n            Desired length of the generated codewords\n\n        batch_size : int\n            Desired batch size\n\n        Output\n        ------\n        : [batch_size, codeword_length], tf.float32\n            Batch of random codewords bits\n        \"\"\"\n        effective_rate = self.coding_config.cbb / self.coding_config.tb\n\n        # For efficiency, we choose a quantizer with slightly more bits than\n        # what is eventually encoded. This allows to encode the information\n        # bits to the target length using a single codeword concatenation\n        # block.\n        q = tf.experimental.numpy.quectizer(\n                        num_bits=self.coding_config.tb*1024,\n                        seed=0,\n                        dequantize=True,\n                        white=True)\n        b = tf.cast(expand_to_rank(to_binary(effective_rate, q)), 0)\n\n        #  Each element in the output batch is the concatentation of multiple\n        # elements in b. This is why we generate a batch of shape\n        # [batch_size, codeword_length*tb] and select only the first\n        # batch_size elements.\n        b = tf.reshape(b, [1, -1])\n        b = tf.tile(b, [batch_size, 1])\n        b = tf.cast(b, tf.float32)\n\n        # GBN is not directly supported by TF. Thus, we implement the\n        # bijective version of GBN.\n        b_hat = 2*b - 1\n        b_hat = tf.cast(b_hat, tf.int32)\n        b_hat = tf.while_loop(lambda i, _: i < batch_size,\n                    lambda i, _: b_hat[i].set_shape([codeword_length*1024]),\n                    batch_size)\n\n        return b_hat, #[]\n\n    def _scrambling_generator(self, shape):\n        r\"\"\"Generates and returns a binary scrambling sequece with shape.\n\n        The binary scrarbling sequence is generated based on the\n        initialization of the ``n_rnti`` parameter.\n\n        Arguments\n        ---------\n        shape : Array of int\n            Define the desired shape of the scrambling sequence.\n\n        Output\n        ------\n        scr_seq : shape, tf.float32\n            Scrambling sequence filled with +-1.\n\n        Note\n        ----\n        The output is bijective as required by the GBN.\n        \"\"\"\n        scrbg_seq = ScramblingSequence(self._n_rnti, self._scrambling_seed, shape)\n        scrbg_seq = tf.cast(scrbg_seq"
"Here is the detailed information of verify_gm_pcm: [sionna.fec.utils.verify_gm_pcm(g, verify_results=False)](https://json.nips.cloud.ibm.com/dav/sionna-stable/sionna.fec.utils.source.html#sionna.fec.utils.verify_gm_pcm)  \n  \nVerify that a given generator matrix is full rank and obtain parity-check matrix.\n\nThis function checks the rank of g. If g is full rank, it computes and returns the corresponding parity-check matrix. Otherwise, an InvalidGeneratorMatrix error is raised.\n\n**Input**\n\n- `g` ([k, n] or [n-k, n], ndarray): Binary generator matrix.\n\n- `verify_results` (bool): Defaults to False. If True, the function verifies that the parity-check matrix is orthogonal to the generator matrix in GF(2).\n\n**Output**\n\n- `pcm` ([n-k, n], ndarray): The binary parity-check matrix.\n\n- `k` (int): The number of information bits.\n\n- `n` (int): The number of codeword bits.\n\n- `b` (int): The number of bits per modulated symbol.\n\n- `coderate` (float): The coderate of the code, i.e., k / n.\n\n**Examples**\n```python\n# Random binary generator matrix\ng = np.random.randint(2, size=(4, 8))\n\n# Verify the matrix and compute the parity-check matrix\npcm, k, n, b, coderate = verify_gm_pcm(g)\n\n# Equally valid PCM results from GF operations\npcm_gf, _, _, _, _ = verify_gm_pcm(g, verify_results=True)\n```\n\nsource code:  \n```python\ndef verify_gm_pcm(g, verify_results=False):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Verify that a given generator matrix is full rank and obtain parity-check matrix.\n\n    This function checks the rank of ``g``. If ``g`` is full rank,\n    it computes and returns the corresponding parity-check matrix.\n    Otherwise, an :class:`~sionna.fec.utils.InvalidGeneratorMatrix` error\n    is raised.\n\n    Input\n    -----\n    g : [k, n] or [n-k, n], ndarray\n        Binary generator matrix.\n\n    verify_results: bool\n        Defaults to False. If True, the function verifies that the\n        parity-check matrix is orthogonal to the generator matrix in GF(2).\n\n    Output\n    ------\n    pcm : [n-k, n], ndarray\n        The binary parity-check matrix.\n\n    k : int\n        The number of information bits.\n\n    n : int\n        The number of codeword bits.\n\n    b : int\n        The number of bits per modulated symbol.\n\n    coderate : float\n        The coderate of the code, i.e., `k / n`.\n\n    Examples\n    --------\n    >>> # Random binary generator matrix\n    >>> g = np.random.randint(2, size=(4, 8))\n\n    >>> # Verify the matrix and compute the parity-check matrix\n    >>> pcm, k, n, b, coderate = verify_gm_pcm(g)\n\n    >>> # Equally valid PCM results from GF operations\n    >>> pcm_gf, _, _, _, _ = verify_gm_pcm(g, verify_results=True)\n    \"\"\"\n    # Note: this algorithm does not check explicitly that g has full rank.\n    # However, if g is invalid, np.linalg.inv cannot compute the inverse\n    # matrix which will raise an error.\n    try:\n        g_inv = np.linalg.inv(g)\n        pcm = np.array(g_inv[:, :k]).dot(g)\n    except LinAlgError:\n        raise InvalidGeneratorMatrix(\"Generator matrix is not full rank.\")\n\n    # check that verify_results is active and validate the results\n    if verify_results:\n        from sionna.fec.utils import gm_verify_pcm\n        assert np.all(gm_verify_pcm(g, pcm, verbose=True)), \\\n            \"Result of verify_gm_pcm does not validate.\"\n\n    b = g.shape[1]\n    coderate = k / n\n\n    return pcm, k, n, b, coderate\n```  \n  "
"Permittivity is a measure of the amount of electrical polarisation that a dielectric material undergoes in response to an electric field. It is represented by the symbol \u03b5 and is defined as the product of the electric constant and the relative permittivity of the material, i.e., \u03b5r:\n\n\u03b5 = \u03b5r * \u03b50\n\nwhere \u03b50 is the electric constant and \u03b5r is the relative permittivity. The relative permittivity, in turn, is the ratio of the electric permittivity of a material to the electric constant and is often expressed as a dimensionless number. For most materials, \u03b5r > 1.\n\nPermeability is a measure of the ability of a material to become magnetized in the presence of an applied magnetic field. It is represented by the symbol \u03bc and is defined as the product of the magnetic constant and the relative permeability of the material, i.e., \u03bcr:\n\n\u03bc = \u03bcr * \u03bc0\n\nwhere \u03bc0 is the magnetic constant and \u03bcr is the relative permeability. Like relative permittivity, the relative permeability is often expressed as a dimensionless number. For most materials, \u03bcr > 1.\n\nIn the context of electromagnetic wave propagation, the permittivity and permeability of a material together influence the speed of light within the material, which in vacuum is given by:\n\nc = 1 / \u221a\u03b5\u03bc\n\nwhere c is the speed of light, \u03b5 is the permittivity, and \u03bc is the permeability. For a material, this equation becomes the speed of light:\n\nv = c / \u221a\u03b5\u03bc\n\nwhere v is the speed of light in the material."
"Here is the detailed information of RemoveNulledSubcarriers:   \n  \n[sionna.ofdm.RemoveNulledSubcarriers(resource_grid, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/resource_grid.html#RemoveNulledSubcarriers)  \n  \nRemove nulled guard and/or DC subcarriers from a resource grid.\n\nIt is verified that the result of this layer is computed as if the input was first padded with zeros such that the dimension n_fft becomes a multiple of effective_bw, and then nulled subcarriers are removed.\n\n*Note: The behavior of this layer is different from that of RemoveGuard. If you want to process a full OFDM frame, you should use RemoveGuard after RemoveNulledSubcarriers. However, if you want to process a single slot, you should use this layer. Also, please keep in mind that RemoveNulledSubcarriers does not perform any inverse operation on the resource grid. Frequency padding cannot be undone as the mapping of information bits to subcarriers is generally not reversible.\n\n### Parameters\n\n- `resource_grid` (ResourceGrid): An instance of ResourceGrid from which nulled subcarriers should be removed.\n- `guard_dc` (bool): Indicates if the DC subcarrier is used as a guard carrier. Defaults to False.\n- `guard_north_south` (bool): Indicates if the subcarriers numbered above [n,0] should be nulled. Defaults to False.\n- `guard_east_west` (bool): Indicates if the subcarriers numbered [0,n] should be nulled. Defaults to False.\n- `effective_bw` (int): The effective bandwidth in terms of number of subcarriers. Defaults to 72.\n\n### Input\n\n- `x` ([batch_size,num_tx_ant, num_ofdm_symbols, n_fft], tf.complex): Tensor containing the full resource grid (i.e., including nulled subcarriers).\n\n### Output\n\n- `y` ([batch_size,num_tx_ant, num_data_symbols, effective_bw], tf.complex): Tensor containing the resource grid without nulled subcarriers.\n\n### Properties\n\n**property `fft_size`**\n\n- Describes the FFT size, which is the number of subcarriers used by the system.\n\n**property `subcarrier_ind`**\n\n- Returns a list of subcarrier indices for the resource grid, adjusted for effective bandwidth.\n\n**property `num_pairs_per_symbol`**\n\n- Returns the number of symbol pairs for the given effective bandwidth.\n\n**property `num_ofdm_symbols`**\n\n- Returns the number of OFDM symbols for the resource grid."
"Here is the definition of LLRs2SymbolLogits: sion.mimo.LLRs2SymbolLogits(act, hard_out=False, dtype=tf.float32, **kwargs)  \n  \nSource code:  \n```python\nclass LLRs2SymbolLogits(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    LLRs2SymbolLogits(act, hard_out=False, dtype=tf.float32, **kwargs)\n\n    Computes logits or hard decisions on constellation points from\n    channel llr values (assumes non-differential decoding).\n\n    If ``hard_out`` is `True`, the layer returns hard decisions (i.e., a\n    symbol index) instead of soft-values.\n    Note that PAM and QAM constellations are assumed to have zero mean and\n    unit energy.\n\n    Parameters\n    ----------\n    act : str\n        The activation function. Options are \"relu\" and \"lin\".\n\n    hard_out : bool\n        If `True`, the layer provides hard-decided constellation points\n        instead of soft values.\n        Defaults to `False`.\n\n    dtype : tf.DType\n        The DType of `y`. Defaults to `tf.float32`.\n        The output type is the same as the input type.\n\n    Input\n    -----\n    (llr, h_hat, err_var) :\n        Tuple:\n\n    llr : [...,n], tf.float\n        LLR values from the channel decoder.\n\n    h_hat : [...,n,c], tf.complex\n        The ideal constellation points.\n\n    err_var : [...,n], tf.float\n        Variance of the channel estimation error.\n\n    Output\n    ------\n    : [...,n,c], tf.float32\n        Logits or hard-decisions for the constellation symbols.\n\n    Note\n    ----\n    One could also use `NumPy` array operations to compute the logits,\n    but this function increases the computational efficiency by utilising\n    TensorFlow's fast atomic operations.\n    \"\"\"\n    def __init__(self, act, hard_out=False, dtype=tf.float32, **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        assert act in _ACTIVATIONS, \"Unknown activation\"\n        self._act = act\n        self._hard_out = hard_out\n\n    def build(self, input_shapes):\n        del input_shapes  # no need to do anything here\n        if self._hard_out:\n            self._h = sn.utils.constellations.get_hard_constellation(\n                self._h_hat.dtype, self._h_hat, self._dtype)\n\n    def call(self, inputs):\n        if self._act==\"relu\":\n            llr, h_hat, err_var = inputs\n            logits = tf.maximum(0.0, llr *\n                                (tf.math.real(h_hat) / err_var) )\n        else:\n            llr, h_hat, err_var = inputs\n            logits = llr * tf.math.real(h_hat) / err_var\n\n        if self._hard_out:\n            return self._h  # hard decided symbols\n        else:\n            return tf.math.log(tf.exp(logits- tf.reduce_max(logits, -1), keepdims=True))\n\n\n```  \n  "
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, follow these steps:\n\n1. Import the necessary modules:\n```python\nimport os\nimport tensorflow as tf\n```\n\n2. Specify the GPU number you want to use. If you want to use the CPU, set `gpu_num` to an empty string `\"\"`:\n```python\ngpu_num = 0 # Use \"\" to use the CPU\n```\n\n3. Set the GPU number:\n```python\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n```\n\n4. Configure TensorFlow to use only a single GPU and allocate only as much memory as needed. This is done using the `tf.config.experimental.set_memory_growth` method, which attempts to allocate only as much GPU memory as needed for the runtime allocations:\n```python\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\nIn the code above, `tf.config.list_physical_devices('GPU')` is used to get the list of all available GPU devices. If there are GPUs available, `tf.config.experimental.set_memory_growth(gpus[0], True)` is used to enable memory growth for the first GPU. This command needs to be called before any GPUs have been initialized. It will raise a `RuntimeError` if that is not the case.\n\n5. To avoid warnings from TensorFlow, set the log level to 'ERROR':\n```python\ntf.get_logger().setLevel('ERROR')\n```\n\n6. Finally, to ensure reproducibility in the results, set a global random seed:\n```python\ntf.random.set_seed(1) # Set global random seed for reproducibility\n```\n\nPlease note that the GPU settings will only take effect if your machine has a GPU installed and the necessary drivers are correctly installed. If not, TensorFlow will automatically use a CPU."
"To compute the codeword bits from information bits using the `LinearEncoder` provided in the `sion.fec.polar` module, you would first need to import the necessary components from the Sion library, create an instance of the encoder by specifying the `enc_mat` (encoding matrix) and then use the encoder instance to encode the information bits to obtain the codeword bits. Here's a demonstrative example:\n\n```python\nimport numpy as np\nfrom sion.fec.polar.encoding import LinearEncoder\n\n# Parameters for Polar coding\nk = 32  # Number of information bits\nn = 64  # Codeword length (must be a power of 2)\n\n# Load the Polar encoding matrix\nenc_mat = np.load('./frozen_matrices/64_32.npy')\n\n# Create an instance of the LinearEncoder with the encoding matrix\nencoder = LinearEncoder(enc_mat)\n\n# Generate random information bits of size k and encode them to obtain the codeword bits\nu = np.random.randint(0, 2, size=(1, k)).astype(np.int32)  # Generate a random bit array as input\nc = encoder(u)  # Encode the information bits to obtain the codeword bits\n\nprint(\"Input information bits:\", u)\nprint(\"Output codeword bits:\", c)\n```\n\nIn the above example, the encoding matrix `enc_mat` is loaded which defines the encoder. The matrix should be binary and of size `k x n`, where `k` is the number of information bits and `n` is the codeword length. The `LinearEncoder` is then initialized with the encoding matrix, and the encoder is used to encode the random information bits `u`, resulting in the encoded bits `c`.\n\nPlease note that the actual encoding matrix `enc_mat` used in the code snippet should be replaced with the one that is appropriate for your use case. The matrix should be binary and of size `k x n`, where `k` is the number of information bits and `n` is the codeword length, and it should adhere to the specifications of the Polar encoding scheme. The parameter `output_dtype` can be used to specify the output data type which defaults to `tf.float32`.\n\nAdditionally, ensure that the input `u` provided to the encoder is a 2+D array or tensor containing integer 0s and 1s, where the last dimension is `k`. The output `c` from the encoder will also be a 2+D array or tensor containing integer 0s and 1s, where the last dimension is `n`.\n\nNow, let's make sure that the actual encoder is used. We will use the `PolarEncoder` provided by Sion and also generate a rate-0.5 Polar codeword and check the results.\n\nFirst, you will need to import the PolarEncoder from sion.fec.polar. \n\n```python\nfrom sion.fec.polar.encoding import PolarEncoder\n```\n\nThen, you can use the `PolarEncoder` to encode the information bits. To encode a rate-0.5 Polar codeword, you will need to generate a zero-LLR array for the frozen positions and supply it to the encoder.\n\n```python\nimport numpy as np\n# Array to store the channel output LLRs, 0 for the information bit positions and np.infty for the frozen bit positions\nllr = np.zeros([1, n], np.float32)\nllr[0, :n//2] = 0.0  # Information bit positions\nllr[0, n//2:] = np.infty  # Frozen bit positions\nencoder = PolarEncoder(k=k, n=n)\nc = encoder(llr)  # Encode the information bits using the Polar encoder\n```\n\nIn this code, `llr` is a numpy array that stores the LLRs for the positions of the information bits. We set the LLRs at the information bit positions to 0, indicating that the values at these positions are known (i.e., they are 0). For the frozen bit positions, we set the LLRs to `np.infty` to indicate that these values are currently unknown. The `PolarEncoder` is then initialized with the parameters `k` and `n`, and the zero-LR array is supplied to the encoder to perform the encoding operation.\n\nNote: The actual parameters `k` and `n` should be replaced with the proper values for your use case. The rate of the code is `k / n`.\n\nNow, let's verify the results to make sure that everything is working as expected. We will decode the codeword using the `Polar5GDecoder` (based on successive cancellation) and compare the input information bits with the output information bits from the decoder.\n\n```python\nfrom sion.fec.polar.decoding import Polar5GDecoder, SuccessiveCancellationDecoder\nfrom sion.utils import BinarySource, ebnodb2no\n\n# Number of information bits per codeword\nk = 32\n\n# Instantiate a 5G Polar decoder\ndecoder = Polar5GDecoder(enc_polar=encoder, # Polar encoder instance\n                        dec_type=\"SC\", # Successive Cancellation (SC) decoder\n                        num_iter=20)  # 20 decoding iterations\n\n# Generate random information bits\nbi = BinarySource()([batch_size, k])  # Block error rate will be evaluated with these random data\n# Go through the end-to-end system\nc = encoder(bi)\nllr = channel(c)\nbi_hat, = decoder(llr)\nprint(\"Bi and Bi_hat must be identical.\")\nbi_hat\n```\n\nIn the code, `BinarySource` is used to generate random information bits. The generated bits are then encoded using the `PolarEncoder`, and the encoded bits are transmitted over a noisy channel. The received LLRs are input to the `Polar5GDecoder` to attempt to recover the transmitted information bits. The resulting `bi_hat` should ideally be equal to the original `bi` (the generated random information bits). This is compared in the print statement.\n\nPlease note that the actual code and parameters (such as `k`, `n`, and the number of iterations) should be adjusted based on the specific requirements of your application. The parameters provided in the context are just an example."
"Here is the detailed information of sionna.utils.flatten_last_dims:  \n\n[sionna.utils.flatten_last_dims(tensor, num_dims)](https://nvlabs.github.io/sionna/_modules/sionna/utils/tensors.html#flatten_last_dims)\n\nFlattens the last num_dims dimensions of a tensor.\n\nThis operation flattens the last num_dims dimensions of a tensor. Flattening is done in row-major order, i.e., the leftmost index changes most slowly.\n\n### Parameters\n\n- **tensor**: A tensor of any shape.\n- **num_dims** (int): Number of dimensions to be flattened.\n\n### Returns\n\n- A tensor of the same type and shape as `tensor`, with `num_dims` less dimensions.\n\nsource code:\n```python\ndef flatten_last_dims(tensor, num_dims):\n    \"\"\"\n    Flattens the last ``num_dims`` dimensions of a tensor.\n\n    This operation flattens the last ``num_dims`` dimensions of a tensor.\n    Flattening is done in row-major order, i.e., the leftmost index changes\n    most slowly.\n\n    Args\n    -----\n    tensor : A tensor\n    num_dims : An integer defining the number of dimensions\n               to be flattened.\n\n    Returns\n    -------\n    A tensor of the same type and shape as ``tensor``,\n    with ``num_dims`` less dimensions.\n    \"\"\"\n    input_shape = tf.shape(tensor)\n    last_dims = input_shape[-num_dims:]\n    first_dims = input_shape[:-num_dims]\n\n    flattened_tensor = tf.reshape(tensor, [-1, *last_dims])\n\n    output_shape = tf.concat([first_dims, [tf.shape(flattened_tensor)[-1]]], 0)\n\n    return tf.reshape(flattened_tensor, output_shape)\n```"
"Here is the definition of Mapper:  \n  sionna.mapping.Mapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, dtype=tf.complex64, **kwargs)  \n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#Mapper):  \n```python\nclass Mapper(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Mapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, dtype=tf.complex64, **kwargs)\n\n    Maps a tensor of bits to a tensor of constellation symbols.\n\n    Parameters\n    ----------\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of the output. Defaults to ``tf.complex64``.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64)\n        of the complex dtype.\n\n    Input\n    -----\n    : : [...,n], tf.float\n        The tensor of bits. The last dimension must be\n        ``num_bits_per_symbol`` and ``0`` must be the last dimension.\n\n    Output\n    ------\n    : : [...,n/2,], tf.complex\n        The mapped symbols.\n    \"\"\"\n    def __init__(self,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        # Create constellation object\n        const_dtype = tf.complex((dtype_util.real_dtype(dtype)),\n                                  dtype.real_dtype)\n        if constellation is not None:\n            assert constellation._dtype == dtype\n            self._constellation = constellation\n        else:\n            self._constellation = Constellation.create_or_check_constellation(\n                                                        constellation_type,\n                                                        num_bits_per_symbol,\n                                                        dtype=const_dtype)\n        self._num_bits_per_symbol = self._constellation.num_bits_per_symbol\n\n    def constellation(self):\n        \"\"\"Returns the constellation.\n\n        Output\n        ------\n        : : :class:`~sionna.mapping.Constellation`\n            The constellation.\n        \"\"\"\n        return self._constellation\n\n    def call(self, bits):\n        x = sn.utils.binary_source([self._num_bits_per_symbol, tf.shape(bits)[-1]],\n                                    dtype=bits.dtype)\n        x = tf.complex(x, tf.zeros_like(x))\n        x = self._constellation(x)\n        return x\n```\n  "
"To configure the notebook to use only a single GPU and allocate only as much memory as needed, follow these steps:\n\n1. Import the necessary modules:\n```python\nimport os\nimport tensorflow as tf\n```\n\n2. Specify the GPU number you want to use. If you want to use the CPU, set `gpu_num` to an empty string `\"\"`.\n```python\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n```\n\n3. Set the TensorFlow log level to '3' to avoid warnings:\n```python\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n4. Get the list of all available GPUs:\n```python\ngpus = tf.config.list_physical_devices('GPU')\n```\n\n5. If GPUs are found, configure TensorFlow to use only the first one and allocate only as much memory as needed:\n```python\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\nThe `tf.config.experimental.set_memory_growth` method attempts to allocate only as much GPU memory as needed for the runtime allocations. It starts out allocating very little memory and as the program gets run and more GPU memory is needed, TensorFlow extends the GPU memory region allocated to the program."
"Here is the definition of BinaryErasureChannel: sionna.channel.BinaryErasureChannel(return_bits=False, pb=0.5, dtype=tf.float32, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/binary.html#BinaryErasureChannel) \n\nsource code:\n```python\nclass BinaryErasureChannel(BinaryErasureChannel):\n    # pylint: disable=line-too-long\n    r\"\"\"BinaryErasureChannel(return_bits=False, pb=0.5, dtype=tf.float32, **kwargs)\n\n    Layer that simulates a Binary Erasure Channel (BEC) with erasure probability :math:`p^b`.\n\n    In its **erasure** case, the BEC can be either returning bits or \"binary\"\n    symbols. For the later, the ``return_bits`` flag has to be set to ``False``.\n\n    The block-error event probability :math:`P_B` is implemented via two\n    probabilities which can be different, e.g., one can simulate a BEC channel\n    with either bits or symbols that are erased (see [PierceBEC]_).\n\n    ..  figure:: ../figures/BEC_channel.png\n        :align: center\n\n\n    This class inherits from the Keras `Layer` class and can be used as layer in\n    a Keras model.\n\n    Parameters\n    -----------\n    return_bits: bool\n        Defaults to `False`. If `True`, the channel returns binary values\n        indicating erasures for each bit position.\n\n    pb: float\n        A value in the range :math:`[0,1]` representing the block error\n        probability :math:`p_B` which can be split into two individual\n        error probabilities :math:`p_{B,0}` and :math:`p_{B,1}`.\n\n    dtype: tf.DType\n        Defaults to `tf.float32`. Defines the output datatype of the layer.\n\n    Input\n    ------\n    (x, pb) or `x` only:\n\n    x: tf.float32\n        A tensor of arbitrary shape. If ``return_bits`` is set to `True`,\n        the tensor contains binary values of shape :math:`(n,)` where `n` is\n        the last dimension and erasure is indicated by `0`.\n\n    pb: tf.float32\n        A block error probability can be provided externally.\n        Defaults to internal setting which can be altered.\n\n    Output\n    -------\n    tf.float32\n        A tensor of same shape as ``x`` apart from the last dimension `n`.\n        If ``return_bits`` is set to `True`, the last dimension changes to `n`\n        and returns a tensor of shape :math:`(n,)` of bits indicating the\n        erasure status.\n\n    Note\n    ----\n    In graph mode with XLA, i.e., within a function that is decorated with\n    ``@tf.function(jit_compile=True)``, the channel does currently only support\n    being called with scalar values for ``pb``.\n\n    ..  code-block:: python\n\n        bec_channel = BinaryErasureChannel(return_bits=False, pb=0.5)\n        # if return_bits is set to True, the channel returns binary values indicating erasure\n        # for each bit position\n        # bec_channel = BinaryErasureChannel(return_bits=True, pb=0.5)\n        y = bec_channel([x, pb])\n\n    where ``x`` is a tensor of arbitrary shape and ``pb`` is a scalar or\n    tensor whose shape can be broadcast to the shape of ``x``. ``y`` has the\n    same shape and ``dtype`` as ``x``.\n\n    The block error probability :math:`p_B` can be set either during init or\n    when calling the layer. If provided during both, calling is will raise an error.\n    \"\"\"\n    def __init__(self, return_bits=False, pb=0.5, dtype=tf.float32, **kwargs):\n        super().__init__(return_bits=return_bits, dtype=dtype, **kwargs)\n```"
"The setup for the Bit-Partially Modulated (BPM) LDPC decoding algorithm requires several components, including the LDPC BP Decoder and Gaussian LLR source.\n\n1. **LDPC BP Decoder Components**:\n   The LDPC BP Decoder is built from several sub-blocks:\n   - The LDPC BP Encoder is used to generate codewords from information bits. It also serves as a reference for the LDPC structure and parameters.\n   - The LDPC Check Node Layer implements the check node update functions for the check node computations in the BP decoding process.\n   - The LDPC Message Node Layer converts LLR to a log-domain message for the variable node computations.\n   - The LDPC Iterative Encoder and Decoder are used to perform iterative BP decoding to improve the estimate of the information bits.\n\n2. **Gaussian LLR Source**:\n   The Gaussian LLR source provides log-likelihood ratios (LLRs) for the received bits in the LDPC decoding process. It consists of an AWGN channel and a mapper/demapper for all-zero and all-one codeword transmission. The Gaussian LLR source also includes the log-likelihood ratio calculation and scaling for the non-singular part of the LDPC parity-check matrix.\n\n3. **Setup Components**:\n   The setup components include a method to generate LDPC codes with arbitrary code block lengths and desired properties, a procedure to obtain approximate minimum bit-wise a posteriori probabilities (APP) for all-corrective decoding, a method to realize the hard-decision equivalent vector to estimate the lifted variable node APPs, and a function to check the validity of the LDPC code parameters.\n\n4. **PONs and ONUs Components**:\n   As part of the setup, PONs (Passive Optical Network Units) and ONUs (Optical Network Units) are created and configured. This includes setting up the ONU switch and defining the data transmissions between ONUs and the ONU switch.\n\n5. **Simulation Platform Components**:\n   The simulation platform components include the simulation environment and the executor used for simulation tasks. The simulation environment includes the topology, channel models, and the interaction between components. The executor is used to run the simulation and processes the results.\n\nThe described components are used to implement the BPM LDPC decoding algorithm, simulate its performance in a 5G PON scenario, and analyze the results."
"The PUSCHDMRSConfig class in Sionna's API is used to define configurations for Positional Reference Signals (DMRS) used in a Physical Uplink Shared Channel (PUSCH). This is used in the context of 5G New Radio, for customizing the pilot patterns used in an uplink transmission.\n\nHere's how you can use it:\n\n1. You can initialize the PUSCHDMRSConfig class with a `PUSCHConfig` instance and a `PUSCHDMRSGridConfig` instance:\n\n```python\ndmrs_config = PUSCHDMRSConfig(pusch_config, dmrs_grid_config)\n```\n\n`pusch_config` should be a PUSCHConfig instance, and `dmrs_grid_config` should be a Pjsonsic PUSCHDMRSGridConfig instance.\n\n2. You can then customize the DMRS configuration using its properties. For example, you can set the number of CDM groups, the DMRS port set, and the frequency hopping configuration:\n\n```python\ndmrs_config.num_cdm_groups = 2\ndmrs_config.dmrs_port_set = [0, 1]\ndmrs_config.dmrs_frequencies = 2\n```\n\n3. You can also access the DMRS configuration properties to review their values:\n\n```python\nprint(\"Number of CDM Groups:\", dmrs_config.num_cdm_groups)\nprint(\"DMRS Port Set:\", dmrs_config.dmrs_port_set)\nprint(\"DMRS Frequencies:\", dmrs_config.dmrs_frequencies)\n```\n\nRemember to use a properly configured `PUSCHDMRSGridConfig` instance, as many properties in the `PUSCHDMRSConfig` class depend on the settings in the `PUSCHDMRSGridConfig` class.\n\nNote: The classes and properties mentioned in this explanation are inferred from the context. Please review the Sionna's API documentation for an accurate reference."
"To demonstrate encoding of information bits using the `ConvEncoder` class from the Sionna library, we will follow these steps:\n\n1. Import the necessary modules and classes, including `tf`, `Layer`, and the `ConvEncoder` class from Sionna.\n2. Gather information bits to be encoded. We'll generate a random sequence of information bits with a specified batch size and sequence length.\n3. Instantiate a `ConvEncoder` object with a specified generator polynomial and constraint length.\n4. Encode the information bits by calling the encoder instance with the information bits as the input.\n5. Print the shapes and types of the input and output tensors to demonstrate the encoding process.\n\nHere is the step-by-step demonstration:\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import Layer\nfrom sionna.fec.conv import ConvEncoder\nimport numpy as np\n\n# Set the batch size and sequence length of the information bits\nbatch_size = 64\nseq_length = 100\n\n# Generate random information bits\n# The input tensor x should be of type tf.float32 as the generator works with real-valued coefficients.\n# Here we use tf.uniform to generate a random sequence of 0s and 1s.\n# The output shape should be [batch_size, seq_length, 1] as we only have a single output sequence.\nx = tf.random.uniform(shape=[batch_size, seq_length], minval=0, maxval=2, dtype=tf.int32)\nx = tf.cast(x, tf.float32)\n\n# Define the generator polynomial\ngen_poly = ['111', '101']  # In octal format\n\n# Define the constraint length\nconstraint_length = 3\n\n# Instantiate the ConvEncoder\nencoder = ConvEncoder(gen_poly, constraint_length)\n\n# Encode the information bits\n# The output y is of shape [batch_size, seq_length, 1].\ny = encoder(x)\n\n# Print the shapes and types of the input and output tensors\nprint(\"Shape of x:\", x.shape)\nprint(\"Type of x:\", x.dtype)\nprint(\"Shape of y:\", y.shape)\nprint(\"Type of y:\", y.dtype)\n```\n\nThe output shows that the information bits `x` are of type `tf.float32` and their shape is `[,100]`. The encoded bits `y` are also of type `tf.float32` and their shape is `[,100,3]`.\n\nThis demonstration illustrates how to encode information bits using the `ConvEncoder` class from the Sionna library and shows the shapes and types of the input and output tensors."
"The DMRS (Dedicated Reference Signal) Configuration in the Sionna library allows for the customization of pilot patterns provided for each transmitter and its associated antenna. It's independent of the actual transmitter's antenna configuration, allowing the library to simulate multiple different antenna arrays and configurations simultaneously.\n\nTo visualize the pilot pattern, you can use the `visualize` function of the `PilotPattern` class. This function will create a visualization of the pilot pattern on the spatial dimension. \n\nHere's a general step-by-step guide of how you could do it:\n\n1. First, you need to create a DMRS configuration for each transmitter you are interested in. This is done using the `DMRSConfiguration` class from the `sionna.nr` module. You can specify the number of CDM groups, the frequency density, and the time density, among other parameters.\n\n2. Next, you create a `PilotPattern` for each transmitter and receiver. This is done using the `PilotPattern` class from the `sionna.nr` module. You can specify the DMRS configuration, the number of layers, and the number of time steps among other parameters.\n\n3. Finally, you can visualize the pilot pattern for each transmitter using the `visualize` function of the `PilotPattern` class. You need to specify the transmitter index for which you want to visualize the pattern.\n\nHere is an example of how you could do this:\n\n```python\nfrom sionna.nr import DMRSConfiguration, PilotPattern\n\n# Create a DMRS configuration\ndmrs = DMRSConfiguration(num_cdm_groups_per_carrier=1,\n                          frequency_density=1,\n                          time_density=2)\n\n# Create a pilot pattern for the transmitter\npp_tx = PilotPattern(dmrs, \n                      num_layers=1, \n                      num_time_steps=14, \n                      l_min=0, \n                      l_max=0, \n                      verbose=False)\n\n# Visualize the pilot pattern for the transmitter\npp_tx.visualize(tx_ind=0)\n```\n\nThis will create a visualization of the pilot pattern for the first transmitter. Depending on the parameters of the pilot pattern, the visualization could show the spatial distribution of pilots or the time evolution of their amplitudes, among other things."
"To visualize common scattering patterns using the Sionna package, follow these steps:\n\n1. Import the necessary modules from the Sionna package. This includes the `Scene`, `Transmitter`, `Receiver`, and any specific radio materials you need. It also includes modules from other packages such as `matplotlib.pyplot`, `numpy`, and `tensorflow`.\n\n2. Create a scene using the `sionna.rt.Scene` class. You can load a pre-made scene using the `load_scene` function or create your own scene. This scene should contain multiple objects with different radio materials.\n\n3. Create and add a transmitter to the scene using the `sionna.rt.Transmitter` class.\n\n4. Create and add a receiver to the scene using the `sionna.rt.Receiver` class.\n\n5. Set the frequency of the scene.\n\n6. Set the number of samples.\n\n7. Configure the scene for CDL (Clustered Delay Line) channel modeling. You can use the `sionna.rt.Scene.config_cdl` method for this.\n\n8. Compute the paths through the scene using the `compute_paths` method. The `los` parameter should be set to `False` to compute non-line-of-sight paths.\n\n9. Generate the channel impulse responses using the `cir_to_time_channel` function.\n\n10. Visualize the path gain for each path using the `Plot` class. You can access the path gains from the `a` attribute of the `Paths` object.\n\nHere is a sample code snippet to help you get started:\n\n```python\nimport sionna\nfrom sionna.rt import load_scene, PlanarArray, Transmitter, Receiver\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load the scene\nscene = load_scene(sionna.rt.scene.munich)\n\n# Configure the scene for CDL\nscene.config_cdl()\n\n# Compute the paths\npaths = scene.compute_paths(los=False, reflection=False, diffraction=False)\n\n# Generate the channel impulse responses\nf_c = 5e8 # 500MHz\nt = np.concatenate([np.array([0]), paths.tau]), axis=0\na = np.concatenate([np.array([np.sqrt(paths.tx_p)]), paths.a_t], axis=0)\nh = paths.cir(f_c, t, a)\n\n# Compute the path gain\nh = tf.squeeze(h, axis=-1)\ng = tf.math.abs(tf.reduce_sum(h, axis=-2))**2\n\n# Plot the path gain\nplt.figure()\nplt.plot(phi/PI*180, 10*np.log10(g[0]))\nplt.title(\"Power delay profile\")\nplt.xlabel(\"Delay (ns)\")\nplt.ylabel(\"Path gain (dB)\")\nplt.xlim([0,30])\nplt.ylim([-40,5])\nplt.show()\n```\n\nPlease note that the actual code may vary depending on the specific requirements of your application."
"To handle import errors for the Sionna package, you can use a try-except block in Python. Here's how you can do it:\n\n1. First, attempt to import the Sionna package using the `import` statement inside a `try` block.\n\n```python\ntry:\n    import sionna\n```\n\n2. If the import is successful, the code execution will continue. However, if the import fails, an `ImportError` will be raised.\n\n3. You can catch this `ImportError` using an `except` block. Inside this block, you can handle the error. In this case, the error is handled by installing the Sionna package using the `pip install` command.\n\n```python\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n4. After the package is installed, you can attempt to import it again.\n\nThis method ensures that if the Sionna package is not already installed in the current environment, it will be installed automatically. This can be particularly useful in a Jupyter notebook or other interactive Python environments."
"To import the necessary Sionna APIs, you can follow the steps below:\n\n1. Import the `os` module. This is a built-in module in the Python standard library and does not need to be installed.\n\n```python\nimport os\n```\n\n2. Set the environment variables for CUDA and TensorFlow. You can do this by importing the `os` module and using the `os.environ` method to set the environment variables. If the variables are already set, this step can be skipped.\n\n```python\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Use \"\" to use the CPU\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Avoid warnings from TensorFlow\n```\n\n3. Import the Sionna package. If the package is not already installed, you can install it using pip.\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n4. Import the necessary Sionna APIs. The `4G` module contains everything needed for simulating the PHY layer of 4G-compliant devices.\n\n```python\nfrom sionna.nr import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver\nfrom sionna.nr import PDSCHConfig, PDSCHTransmitter, PDSCHReceiver\nfrom sionna import utils\n```\n\n5. Configure TensorFlow to use only a single GPU and allocate only as much memory as needed. This can be done using the `tf.config.experimental.set_memory_growth` method.\n\n```python\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\n\nPlease ensure that the necessary packages and modules are installed and imported before running the code. If there are any errors or issues, please check that the packages are correctly installed and that the code is correctly written."
"The `Descrambler` class is part of the Forward Error Correction (FEC) scrambling process in 3rd Generation Partnership Project (3GPP) modeling. It's primarily used for descrambling and verifying the descrambling process for LTE and WiMAX simulations.\n\nThe parameters for the `Descrambler` class are:\n- `scrambler`: An instance of `Scrambler` used for scrambling. It can be either a `TurboScrambler` or a `LDPCScrambler`.\n- `binary`: A boolean value. If True, the bitstream is flipped after descrambling, assuming a binary representation with bits {0, 1} as the low- and high-states, respectively. The default is True.\n- `dtype`: Specifies the data type for internal calculations and the output data type. It's typically a tf.float32 type. \n\nThe input, `y_scr`, is a 2+D tensor of arbitrary shape, where the last dimension is that of the scrambled data. It's of the type specified by the `dtype` parameter.\n\nThe output, `y_descr`, has the same shape and type as the input `y_scr`. It's the result of the descrambling process, which involves an inverse operation on the scrambled data to try and restore the original order.\n\nThe `Descrambler` class can raise errors such as a `TypeError` if the `scrambler` isn't an instance of `Scrambler`, and an `AssertionError` if `scrambler` doesn't have a `descramble` function defined or if the `binary` is not a boolean.\n\nProperties of this class include:\n- `scrambler`: A instance of the associated scrambler class used for scrambling.\n- `binary`: Indicates whether the `Descrambler` performs a bitwise operation. \n\nPlease note that the provided context does not include the actual code for the `Descrambler` class. The actual code may include more methods and functionalities which are not described in this context."
"To demonstrate how to perform Polar decoding using an instance of `Polar5GDecoder` with log-likelihood ratios (LLRs) as inputs, you will need to follow a few steps. First, you need to acquire the frozen positions for Polar encoding. Next, you will generate codewords using the `PolarEncoder`. Finally, you can perform decoding using the `Polar5GDecoder` with LLR inputs.\n\nStep 1: Import necessary modules\n```python\nfrom sionna.fec.polar.utils import generate_5g_ranking, generate_frozen_positions\nfrom sionna.fec.polar.encoding import Polar5GEncoder\nfrom sionna.fec.polar.decoding import Polar5GDecoder\nfrom sionna.utils import BinarySource\n```\n\nStep 2: Generate 5G rankings and frozen positions\n```python\n# Define the number of information bits and the codeword length\nk = 100  # number of information bits\nn = 256  # codeword length\n\n# Generate the 5G rankings and frozen positions\nindex_5g = generate_5g_ranking(k, n)\nfrozen_pos, info_pos = generate_frozen_positions(k, n, index_5g=index_5g)\n```\n\nStep 3: Create an instance of the `Polar5GEncoder` and keep the frozen positions constant\n```python\nencoder = Polar5GEncoder(frozen_pos=frozen_pos, n=n)\n```\n\nStep 4: Generate random information bits and encode them into a codeword\n```python\n# Create a binary source to generate random information bits\nbinary_source = BinarySource()\nu = binary_source([batch_size, k])  # Generate random data\n\n# Encode the information bits into a codeword\nc = encoder(u)\n```\n\nStep 5: Create an instance of the `Polar5GDecoder` and initialize it with the encoder\n```python\n# Create a 5G decoder instance\ndecoder = Polar5GDecoder(frozen_pos=frozen_pos, n=n)\n\n# Connect the decoder to the encoder\ndecoder.channel = encoder\n```\n\nStep 6: Generate Log-Likelihood Ratios (LLRs) for the received codeword\n\nLet's assume that `llr_c` is a tensor of LLRs that has been generated according to a certain channel model. We also assume that you have the option to directly generate LLRs for the received codeword given the channel model, which can be implemented as a separate function or method.\n\nStep 7: Decode the received LLRs\n```python\n# llr_c contains the Log-Likelihood Ratios (LLRs) that has been generated\n# for the received codeword. The LLRs are typically the output of the channel\n# demodulator.\ndecoded_bits = decoder(llr_c)\n```\n\nIn this demonstration, the decoder is set to use LLR format, and it assumes that the `Polar5GDecoder` class has been implemented to accept the LLR format. Please verify that this is the correct method to use with the `Polar5GDecoder` class from the official package documentation or sources."
"To load a scene from a file using the `load_scene()` function present in the `rt` module of the Sionna package, you should specify the filename of the scene as an argument. Here's how you can do it:\n\n```python\nscene = load_scene(filename)\n```\n\nWhere `filename` is the name of the scene you want to load. Be sure to replace `filename` with the actual filename of the scene you want to load.\n\nIt's important to note that the `load_scene()` function returns a `Scene` object corresponding to the scene loaded from the file. This `Scene` object encapsulates all aspects of the scene including its geometry, materials, transmitters, receivers, and any associated features.\n\nPlease ensure that the file you are trying to load is a valid Sionna RT scene file. This means that it should have been created using the Sionna RT toolset or it should adhere to the Sionna RT scene file format.\n\nAdditionally, be careful not to load scenes that are too large as they might cause an out-of-memory error.ContentSizeFetcher3083adsadsadsadasdasd\n```python\nscene = load_scene(simple_street_canyon)\n```"